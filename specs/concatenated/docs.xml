<directory_structure>
    better-auth.json
    next-js-16.json
    polar-sh.json
    prisma.json
    react-19.json
    trpc.json
    zod.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="output/jobs/next-js-16.json">
[
  {
    "title": "API Reference: Directives | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/directives",
    "html": "App Router\nAPI Reference\nDirectives\nCopy page\nDirectives\n\nThe following directives are available:\n\nuse cache\nLearn how to use the use cache directive to cache data in your Next.js application.\nuse cache: private\nLearn how to use the `\"use cache: private\"` directive to enable runtime prefetching of personalized content in your Next.js application.\nuse cache: remote\nLearn how to use the `\"use cache: remote\"` directive to enable caching in dynamic contexts in your Next.js application.\nuse client\nLearn how to use the use client directive to render a component on the client.\nuse server\nLearn how to use the use server directive to execute code on the server.\nPrevious\nAPI Reference\nNext\nuse cache\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "App Router: API Reference | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference",
    "html": "Next.js Docs\nApp Router\nAPI Reference\nCopy page\nAPI Reference\nDirectives\nDirectives are used to modify the behavior of your Next.js application.\nComponents\nAPI Reference for Next.js built-in components.\nFile-system conventions\nAPI Reference for Next.js file-system conventions.\nFunctions\nAPI Reference for Next.js Functions and Hooks.\nConfiguration\nLearn how to configure Next.js applications.\nCLI\nAPI Reference for the Next.js Command Line Interface (CLI) tools.\nEdge Runtime\nAPI Reference for the Edge Runtime.\nTurbopack\nTurbopack is an incremental bundler optimized for JavaScript and TypeScript, written in Rust, and built into Next.js.\nPrevious\nVideos\nNext\nDirectives\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Directives: use cache | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/directives/use-cache",
    "html": "API Reference\nDirectives\nuse cache\nCopy page\nuse cache\n\nThe use cache directive allows you to mark a route, React component, or a function as cacheable. It can be used at the top of a file to indicate that all exports in the file should be cached, or inline at the top of function or component to cache the return value.\n\nGood to know: For caching user-specific content that requires access to cookies or headers, see 'use cache: private'.\n\nUsage\n\nuse cache is a Cache Components feature. To enable it, add the cacheComponents option to your next.config.ts file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n \nexport default nextConfig\n\nThen, add use cache at the file, component, or function level:\n\n// File level\n'use cache'\n \nexport default async function Page() {\n  // ...\n}\n \n// Component level\nexport async function MyComponent() {\n  'use cache'\n  return <></>\n}\n \n// Function level\nexport async function getData() {\n  'use cache'\n  const data = await fetch('/api/data')\n  return data\n}\nHow use cache works\nCache keys\n\nA cache entry's key is generated using a serialized version of its inputs, which includes:\n\nBuild ID (generated for each build)\nFunction ID (a secure identifier unique to the function)\nThe serializable\n function arguments (or props).\n\nThe arguments passed to the cached function, as well as any values it reads from the parent scope automatically become a part of the key. This means, the same cache entry will be reused as long as its inputs are the same.\n\nNon-serializable arguments\n\nAny non-serializable arguments, props, or closed-over values will turn into references inside the cached function, and can be only passed through and not inspected nor modified. These non-serializable values will be filled in at the request time and won't become a part of the cache key.\n\nFor example, a cached function can take in JSX as a children prop and return <div>{children}</div>, but it won't be able to introspect the actual children object. This allows you to nest uncached content inside a cached component.\n\napp/ui/cached-component.tsx\nTypeScript\nJavaScript\nTypeScript\nfunction CachedComponent({ children }: { children: ReactNode }) {\n  'use cache'\n  return <div>{children}</div>\n}\nReturn values\n\nThe return value of the cacheable function must be serializable. This ensures that the cached data can be stored and retrieved correctly.\n\nuse cache at build time\n\nWhen used at the top of a layout or page, the route segment will be prerendered, allowing it to later be revalidated.\n\nThis means use cache cannot be used with runtime data like cookies or headers.\n\nNote: If you need to cache content that depends on cookies, headers, or search params, use 'use cache: private' instead.\n\nuse cache at runtime\n\nOn the server, the cache entries of individual components or functions will be cached in-memory.\n\nThen, on the client, any content returned from the server cache will be stored in the browser's memory for the duration of the session or until revalidated.\n\nDuring revalidation\n\nBy default, use cache has server-side revalidation period of 15 minutes. While this period may be useful for content that doesn't require frequent updates, you can use the cacheLife and cacheTag APIs to configure when the individual cache entries should be revalidated.\n\ncacheLife: Configure the cache entry lifetime.\ncacheTag: Create tags for on-demand revalidation.\n\nBoth of these APIs integrate across the client and server caching layers, meaning you can configure your caching semantics in one place and have them apply everywhere.\n\nSee the cacheLife and cacheTag API docs for more information.\n\nExamples\nCaching an entire route with use cache\n\nTo prerender an entire route, add use cache to the top of both the layout and page files. Each of these segments are treated as separate entry points in your application, and will be cached independently.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\n'use cache'\n \nexport default function Layout({ children }: { children: ReactNode }) {\n  return <div>{children}</div>\n}\n\nAny components imported and nested in page file are part of the cache output associated with the page.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use cache'\n \nasync function Users() {\n  const users = await fetch('/api/users')\n  // loop through users\n}\n \nexport default function Page() {\n  return (\n    <main>\n      <Users />\n    </main>\n  )\n}\n\nGood to know:\n\nIf use cache is added only to the layout or the page, only that route segment and any components imported into it will be cached.\nIf any of the nested children in the route use Dynamic APIs, then the route will opt out of pre-rendering.\nCaching a component's output with use cache\n\nYou can use use cache at the component level to cache any fetches or computations performed within that component. The cache entry will be reused as long as the serialized props produce the same value in each instance.\n\napp/components/bookings.tsx\nTypeScript\nJavaScript\nTypeScript\nexport async function Bookings({ type = 'haircut' }: BookingsProps) {\n  'use cache'\n  async function getBookingsData() {\n    const data = await fetch(`/api/bookings?type=${encodeURIComponent(type)}`)\n    return data\n  }\n  return //...\n}\n \ninterface BookingsProps {\n  type: string\n}\nCaching function output with use cache\n\nSince you can add use cache to any asynchronous function, you aren't limited to caching components or routes only. You might want to cache a network request, a database query, or a slow computation.\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function getData() {\n  'use cache'\n \n  const data = await fetch('/api/data')\n  return data\n}\nInterleaving\n\nIn React, composition with children or slots is a well-known pattern for building flexible components. When using use cache, you can continue to compose your UI in this way. Anything included as children, or other compositional slots, in the returned JSX will be passed through the cached component without affecting its cache entry.\n\nAs long as you don't directly reference any of the JSX slots inside the body of the cacheable function itself, their presence in the returned output won't affect the cache entry.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page() {\n  const uncachedData = await getData()\n  return (\n    // Pass compositional slots as props, e.g. header and children\n    <CacheComponent header={<h1>Home</h1>}>\n      {/* DynamicComponent is provided as the children slot */}\n      <DynamicComponent data={uncachedData} />\n    </CacheComponent>\n  )\n}\n \nasync function CacheComponent({\n  header, // header: a compositional slot, injected as a prop\n  children, // children: another slot for nested composition\n}: {\n  header: ReactNode\n  children: ReactNode\n}) {\n  'use cache'\n  const cachedData = await fetch('/api/cached-data')\n  return (\n    <div>\n      {header}\n      <PrerenderedComponent data={cachedData} />\n      {children}\n    </div>\n  )\n}\n\nYou can also pass Server Actions through cached components to Client Components without invoking them inside the cacheable function.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport ClientComponent from './ClientComponent'\n \nexport default async function Page() {\n  const performUpdate = async () => {\n    'use server'\n    // Perform some server-side update\n    await db.update(...)\n  }\n \n  return <CacheComponent performUpdate={performUpdate} />\n}\n \nasync function CachedComponent({\n  performUpdate,\n}: {\n  performUpdate: () => Promise<void>\n}) {\n  'use cache'\n  // Do not call performUpdate here\n  return <ClientComponent action={performUpdate} />\n}\napp/ClientComponent.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nexport default function ClientComponent({\n  action,\n}: {\n  action: () => Promise<void>\n}) {\n  return <button onClick={action}>Update</button>\n}\nPlatform Support\nDeployment Option\tSupported\nNode.js server\tYes\nDocker container\tYes\nStatic export\tNo\nAdapters\tPlatform-specific\n\nLearn how to configure caching when self-hosting Next.js.\n\nVersion History\nVersion\tChanges\nv16.0.0\t\"use cache\" is enabled with the Cache Components feature.\nv15.0.0\t\"use cache\" is introduced as an experimental feature.\nRelated\nView related API references.\nuse cache: private\nLearn how to use the `\"use cache: private\"` directive to enable runtime prefetching of personalized content in your Next.js application.\ncacheComponents\nLearn how to enable the cacheComponents flag in Next.js.\ncacheLife\nLearn how to set up cacheLife configurations in Next.js.\ncacheTag\nLearn how to use the cacheTag function to manage cache invalidation in your Next.js application.\ncacheLife\nLearn how to use the cacheLife function to set the cache expiration time for a cached function or component.\nrevalidateTag\nAPI Reference for the revalidateTag function.\nPrevious\nDirectives\nNext\nuse cache: private\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Directives: use cache: private | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/directives/use-cache-private",
    "html": "API Reference\nDirectives\nuse cache: private\nCopy page\nuse cache: private\n\nThe 'use cache: private' directive enables runtime prefetching of personalized content that depends on cookies, headers, or search params.\n\nGood to know: 'use cache: private' is a variant of use cache designed specifically for user-specific content that needs to be prefetchable but should never be stored in server-side cache handlers.\n\nUsage\n\nTo use 'use cache: private', enable the cacheComponents flag in your next.config.ts file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n \nexport default nextConfig\n\nThen add 'use cache: private' to your function along with a cacheLife configuration and export unstable_prefetch from your page.\n\nBasic example\napp/product/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Suspense } from 'react'\nimport { cookies } from 'next/headers'\nimport { cacheLife, cacheTag } from 'next/cache'\n \n// REQUIRED: Enable runtime prefetching\nexport const unstable_prefetch = {\n  mode: 'runtime',\n  samples: [\n    { params: { id: '1' }, cookies: [{ name: 'session-id', value: '1' }] },\n  ],\n}\n \nexport default async function ProductPage({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n \n  return (\n    <div>\n      <ProductDetails id={id} />\n      <Suspense fallback={<div>Loading recommendations...</div>}>\n        <Recommendations productId={id} />\n      </Suspense>\n    </div>\n  )\n}\n \nasync function Recommendations({ productId }: { productId: string }) {\n  const recommendations = await getRecommendations(productId)\n \n  return (\n    <div>\n      {recommendations.map((rec) => (\n        <ProductCard key={rec.id} product={rec} />\n      ))}\n    </div>\n  )\n}\n \nasync function getRecommendations(productId: string) {\n  'use cache: private'\n  cacheTag(`recommendations-${productId}`)\n  cacheLife({ stale: 60 }) // Minimum 30 seconds required for runtime prefetch\n \n  // Access cookies within private cache functions\n  const sessionId = (await cookies()).get('session-id')?.value || 'guest'\n \n  return getPersonalizedRecommendations(productId, sessionId)\n}\n\nNote: Private caches require a cacheLife stale time of at least 30 seconds to enable runtime prefetching. Values below 30 seconds are treated as dynamic.\n\nDifference from use cache\n\nWhile regular use cache is designed for static, shared content that can be cached on the server, 'use cache: private' is specifically for dynamic, user-specific content that needs to be:\n\nPersonalized - varies based on cookies, headers, or search params\nPrefetchable - can be loaded before the user navigates to the page\nClient-only - never persisted to server-side cache handlers\nFeature\tuse cache\t'use cache: private'\nAccess to await cookies()\tNo\tYes\nAccess to await headers()\tNo\tYes\nAccess to await searchParams\tNo\tYes\nStored in cache handler\tYes (server-side)\tNo (client-side only)\nRuntime prefetchable\tN/A (already static)\tYes (when configured)\nCache scope\tGlobal (shared)\tPer-user (isolated)\nUse case\tStatic, shared content\tPersonalized, user-specific content\nHow it works\nRuntime prefetching\n\nWhen a user hovers over or views a link to a page with unstable_prefetch = { mode: 'runtime' }:\n\nStatic content is prefetched immediately (layouts, page shell)\nPrivate cache functions are executed with the user's current cookies/headers\nResults are stored in the client-side Resume Data Cache\nNavigation is instant - both static and personalized content are already loaded\n\nGood to know: Without 'use cache: private', personalized content cannot be prefetched and must wait until after navigation completes. Runtime prefetching eliminates this delay by executing cache functions with the user's current request context.\n\nStorage behavior\n\nPrivate caches are never persisted to server-side cache handlers (like Redis, Vercel Data Cache, etc.). They exist only to:\n\nEnable runtime prefetching of personalized content\nStore prefetched data in the client-side cache during the session\nCoordinate cache invalidation with tags and stale times\n\nThis ensures user-specific data is never accidentally shared between users while still enabling fast, prefetched navigation.\n\nStale time requirements\n\nNote: Functions with a cacheLife stale time less than 30 seconds will not be runtime prefetched, even when using 'use cache: private'. This prevents prefetching of rapidly changing data that would likely be stale by navigation time.\n\n// Will be runtime prefetched (stale ≥ 30s)\ncacheLife({ stale: 60 })\n \n// Will be runtime prefetched (stale ≥ 30s)\ncacheLife({ stale: 30 })\n \n// Will NOT be runtime prefetched (stale < 30s)\ncacheLife({ stale: 10 })\nRequest APIs allowed in private caches\n\nThe following request-specific APIs can be used inside 'use cache: private' functions:\n\nAPI\tAllowed in use cache\tAllowed in 'use cache: private'\ncookies()\tNo\tYes\nheaders()\tNo\tYes\nsearchParams\tNo\tYes\nconnection()\tNo\tNo\n\nNote: The connection()\n API is prohibited in both use cache and 'use cache: private' as it provides connection-specific information that cannot be safely cached.\n\nNesting rules\n\nPrivate caches have specific nesting rules to prevent user-specific data from leaking into shared caches:\n\nPrivate caches can be nested inside other private caches\nPrivate caches cannot be nested inside public caches ('use cache', 'use cache: remote')\nPublic caches can be nested inside private caches\n// VALID: Private inside private\nasync function outerPrivate() {\n  'use cache: private'\n  const result = await innerPrivate()\n  return result\n}\n \nasync function innerPrivate() {\n  'use cache: private'\n  return getData()\n}\n \n// INVALID: Private inside public\nasync function outerPublic() {\n  'use cache'\n  const result = await innerPrivate() // Error!\n  return result\n}\n \nasync function innerPrivate() {\n  'use cache: private'\n  return getData()\n}\nExamples\nPersonalized product recommendations\n\nThis example shows how to cache personalized product recommendations based on a user's session cookie. The recommendations are prefetched at runtime when the user hovers over product links.\n\napp/product/[id]/page.tsx\nimport { cookies } from 'next/headers'\nimport { cacheLife, cacheTag } from 'next/cache'\n \nexport const unstable_prefetch = {\n  mode: 'runtime',\n  samples: [\n    { params: { id: '1' }, cookies: [{ name: 'user-id', value: 'user-123' }] },\n  ],\n}\n \nasync function getRecommendations(productId: string) {\n  'use cache: private'\n  cacheTag(`recommendations-${productId}`)\n  cacheLife({ stale: 60 })\n \n  const userId = (await cookies()).get('user-id')?.value\n \n  // Fetch personalized recommendations based on user's browsing history\n  const recommendations = await db.recommendations.findMany({\n    where: { userId, productId },\n  })\n \n  return recommendations\n}\nUser-specific pricing\n\nCache pricing information that varies by user tier, allowing instant navigation to the pricing page with personalized rates already loaded.\n\napp/pricing/page.tsx\nimport { cookies } from 'next/headers'\nimport { cacheLife } from 'next/cache'\n \nexport const unstable_prefetch = {\n  mode: 'runtime',\n  samples: [{ cookies: [{ name: 'user-tier', value: 'premium' }] }],\n}\n \nasync function getPricing() {\n  'use cache: private'\n  cacheLife({ stale: 300 }) // 5 minutes\n \n  const tier = (await cookies()).get('user-tier')?.value || 'free'\n \n  // Return tier-specific pricing\n  return db.pricing.findMany({ where: { tier } })\n}\nLocalized content based on headers\n\nServe localized content based on the user's Accept-Language header, prefetching the correct language variant before navigation.\n\napp/page.tsx\nimport { headers } from 'next/headers'\nimport { cacheLife, cacheTag } from 'next/cache'\n \nexport const unstable_prefetch = {\n  mode: 'runtime',\n  samples: [{ headers: [{ name: 'accept-language', value: 'en-US' }] }],\n}\n \nasync function getLocalizedContent() {\n  'use cache: private'\n  cacheTag('content')\n  cacheLife({ stale: 3600 }) // 1 hour\n \n  const headersList = await headers()\n  const locale = headersList.get('accept-language')?.split(',')[0] || 'en-US'\n \n  return db.content.findMany({ where: { locale } })\n}\nSearch results with user preferences\n\nPrefetch search results that include user-specific preferences, ensuring personalized search results load instantly.\n\napp/search/page.tsx\nimport { cookies } from 'next/headers'\nimport { cacheLife } from 'next/cache'\n \nexport const unstable_prefetch = {\n  mode: 'runtime',\n  samples: [\n    {\n      searchParams: { q: 'laptop' },\n      cookies: [{ name: 'preferences', value: 'compact-view' }],\n    },\n  ],\n}\n \nasync function getSearchResults(query: string) {\n  'use cache: private'\n  cacheLife({ stale: 120 }) // 2 minutes\n \n  const preferences = (await cookies()).get('preferences')?.value\n \n  // Apply user preferences to search results\n  return searchWithPreferences(query, preferences)\n}\n\nGood to know:\n\nPrivate caches are ephemeral and only exist in the client-side cache for the session duration\nPrivate cache results are never written to server-side cache handlers\nThe unstable_prefetch export is required for runtime prefetching to work\nA minimum stale time of 30 seconds is required for private caches to be prefetched\nYou can use cacheTag() and revalidateTag() to invalidate private caches\nEach user gets their own private cache entries based on their cookies/headers\nPlatform Support\nDeployment Option\tSupported\nNode.js server\tYes\nDocker container\tYes\nStatic export\tNo\nAdapters\tYes\nVersion History\nVersion\tChanges\nv16.0.0\t'use cache: private' introduced as an experimental feature.\nRelated\nView related API references.\nuse cache\nLearn how to use the use cache directive to cache data in your Next.js application.\ncacheComponents\nLearn how to enable the cacheComponents flag in Next.js.\ncacheLife\nLearn how to use the cacheLife function to set the cache expiration time for a cached function or component.\ncacheTag\nLearn how to use the cacheTag function to manage cache invalidation in your Next.js application.\nPrefetching\nLearn how to configure prefetching in Next.js\nPrevious\nuse cache\nNext\nuse cache: remote\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Directives: use client | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/directives/use-client",
    "html": "API Reference\nDirectives\nuse client\nCopy page\nuse client\n\nThe 'use client' directive declares an entry point for the components to be rendered on the client side and should be used when creating interactive user interfaces (UI) that require client-side JavaScript capabilities, such as state management, event handling, and access to browser APIs. This is a React feature.\n\nGood to know:\n\nYou do not need to add the 'use client' directive to every file that contains Client Components. You only need to add it to the files whose components you want to render directly within Server Components. The 'use client' directive defines the client-server boundary\n, and the components exported from such a file serve as entry points to the client.\n\nUsage\n\nTo declare an entry point for the Client Components, add the 'use client' directive at the top of the file, before any imports:\n\napp/components/counter.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useState } from 'react'\n \nexport default function Counter() {\n  const [count, setCount] = useState(0)\n \n  return (\n    <div>\n      <p>Count: {count}</p>\n      <button onClick={() => setCount(count + 1)}>Increment</button>\n    </div>\n  )\n}\n\nWhen using the 'use client' directive, the props of the Client Components must be serializable\n. This means the props need to be in a format that React can serialize when sending data from the server to the client.\n\napp/components/counter.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nexport default function Counter({\n  onClick /* ❌ Function is not serializable */,\n}) {\n  return (\n    <div>\n      <button onClick={onClick}>Increment</button>\n    </div>\n  )\n}\nNesting Client Components within Server Components\n\nCombining Server and Client Components allows you to build applications that are both performant and interactive:\n\nServer Components: Use for static content, data fetching, and SEO-friendly elements.\nClient Components: Use for interactive elements that require state, effects, or browser APIs.\nComponent composition: Nest Client Components within Server Components as needed for a clear separation of server and client logic.\n\nIn the following example:\n\nHeader is a Server Component handling static content.\nCounter is a Client Component enabling interactivity within the page.\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Header from './header'\nimport Counter from './counter' // This is a Client Component\n \nexport default function Page() {\n  return (\n    <div>\n      <Header />\n      <Counter />\n    </div>\n  )\n}\nReference\n\nSee the React documentation\n for more information on 'use client'.\n\nPrevious\nuse cache: remote\nNext\nuse server\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Directives: use cache: remote | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/directives/use-cache-remote",
    "html": "API Reference\nDirectives\nuse cache: remote\nCopy page\nuse cache: remote\n\nThe 'use cache: remote' directive enables caching of shared data in dynamic contexts where regular use cache would not work, for example after calling await connection(), await cookies() or await headers().\n\nGood to know:\n\nResults are stored in server-side cache handlers and shared across all users.\nFor user-specific data that depends on await cookies() or await headers(), use 'use cache: private' instead.\nUsage\n\nTo use 'use cache: remote', enable the cacheComponents flag in your next.config.ts file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n \nexport default nextConfig\n\nThen add 'use cache: remote' to your function that needs to cache data in a dynamic context.\n\nBasic example\n\nCache product pricing that needs to be fetched at request time but can be shared across all users. Use cacheLife to set the cache lifetime of the price.\n\napp/product/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Suspense } from 'react'\nimport { connection } from 'next/server'\nimport { cacheTag, cacheLife } from 'next/cache'\n \nexport default async function ProductPage({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n \n  return (\n    <div>\n      <ProductDetails id={id} />\n      <Suspense fallback={<div>Loading price...</div>}>\n        <ProductPrice productId={id} />\n      </Suspense>\n    </div>\n  )\n}\n \nfunction ProductDetails({ id }: { id: string }) {\n  return <div>Product: {id}</div>\n}\n \nasync function ProductPrice({ productId }: { productId: string }) {\n  // Calling connection() makes this component dynamic, preventing\n  // it from being included in the static shell. This ensures the price\n  // is always fetched at request time.\n  await connection()\n \n  // Now we can cache the price in a remote cache handler.\n  // Regular 'use cache' would NOT work here because we're in a dynamic context.\n  const price = await getProductPrice(productId)\n \n  return <div>Price: ${price}</div>\n}\n \nasync function getProductPrice(productId: string) {\n  'use cache: remote'\n  cacheTag(`product-price-${productId}`)\n  cacheLife({ expire: 3600 }) // 1 hour\n \n  // This database query is cached and shared across all users\n  return db.products.getPrice(productId)\n}\n\nNote: Regular use cache will not cache anything when used in a dynamic context (after await connection(), await cookies(), await headers(), etc.). Use 'use cache: remote' to enable runtime caching in these scenarios.\n\nHow use cache: remote differs from use cache and use cache: private\n\nNext.js provides three caching directives, each designed for different use cases:\n\nFeature\tuse cache\t'use cache: remote'\t'use cache: private'\nWorks in dynamic context\tNo (requires static context)\tYes (designed for dynamic contexts)\tYes\nAccess to await cookies()\tNo\tNo\tYes\nAccess to await headers()\tNo\tNo\tYes\nAfter await connection()\tNo (won't cache)\tNo\tNo\nStored in cache handler\tYes (server-side)\tYes (server-side)\tNo (client-side only)\nCache scope\tGlobal (shared)\tGlobal (shared)\tPer-user (isolated)\nSupports runtime prefetching\tN/A (pre-rendered at build)\tNo\tYes (when configured)\nUse case\tStatic, shared content (build-time)\tDynamic, shared content in runtime contexts (per-request)\tPersonalized, user-specific content\n\nNote: While you can't call await cookies() or await headers() inside 'use cache: remote', you can read the values before calling a function that is wrapped by 'use cache: remote' and the arguments will be included in the cache key. Note that this is not recommended as it will dramatically increase the cache size and reduce the cache hit rate.\n\nWhen to use each directive\n\nChoose the right caching directive based on your use case:\n\nUse use cache when:\n\nContent can be prerendered at build time\nContent is shared across all users\nContent doesn't depend on request-specific data\n\nUse 'use cache: remote' when:\n\nYou need caching within dynamic context\nContent is shared across users but must be rendered per-request (after await connection())\nYou want to cache expensive operations in a server-side cache handler\n\nUse 'use cache: private' when:\n\nContent is personalized per-user (depends on cookies, headers)\nYou need runtime prefetching of user-specific content\nContent should never be shared between users\nHow it works\n\nThe 'use cache: remote' directive enables runtime caching of shared data in dynamic contexts by storing results in server-side cache handlers rather than prerendering at build time.\n\nDynamic context detection\n\nWhen Next.js encounters certain APIs like connection(), cookies(), or headers(), the context becomes \"dynamic\". In a dynamic context:\n\nRegular use cache stops working - it won't cache anything\n'use cache: remote' continues to work - it is cached by a remote cache handler.\nResults are stored server-side in a key-value store configured for your deployment\nCached data is shared across requests - reducing database load and origin requests\n\nGood to know: Without 'use cache: remote', functions in dynamic contexts would execute on every request, potentially creating performance bottlenecks. Remote caching eliminates this issue by storing results in server-side cache handlers.\n\nStorage behavior\n\nRemote caches are persisted using server-side cache handlers, which may include:\n\nDistributed key-value stores (in-memory or persistent storage solutions)\nFile system or in-memory storage (often used in development or for custom deployments)\nEnvironment-specific caches (provided by your hosting infrastructure)\nCustom or configured cache handlers (depending on your application's setup)\n\nThis means:\n\nCached data is shared across all users and requests\nCache entries persist beyond a single session\nCache invalidation works via cacheTag and revalidateTag\nCache expiration is controlled by cacheLife configuration\nDynamic context example\nasync function UserDashboard() {\n  // Calling connection() makes the context dynamic\n  await connection()\n \n  // Without any caching directive, this runs on every request\n  const stats = await getStats()\n \n  // With 'use cache: remote', this is cached in the remote handler\n  const analytics = await getAnalytics()\n \n  return (\n    <div>\n      <Stats data={stats} />\n      <Analytics data={analytics} />\n    </div>\n  )\n}\n \nasync function getAnalytics() {\n  'use cache: remote'\n  cacheLife({ expire: 300 }) // 5 minutes\n \n  // This expensive operation is cached and shared across all requests\n  return fetchAnalyticsData()\n}\nRequest APIs and remote caches\n\nWhile 'use cache: remote' technically allows access to request-specific data by calling API's like cookies() and headers() before calling a function that is wrapped by 'use cache: remote', it's generally not recommended to use them together:\n\nAPI\tAllowed in use cache\tAllowed in 'use cache: remote'\tRecommended\ncookies()\tNo\tNo\tUse 'use cache: private' instead\nheaders()\tNo\tNo\tUse 'use cache: private' instead\nconnection()\tNo\tNo\tNo - these cannot ever be cached\nsearchParams\tNo\tNo\tUse 'use cache: private' instead\n\nImportant: If you need to cache based on cookies, headers, or search params, use 'use cache: private' instead. Remote caches are shared across all users, so caching user-specific data in them can lead to incorrect results being served to different users.\n\nNesting rules\n\nRemote caches have specific nesting rules:\n\nRemote caches can be nested inside other remote caches ('use cache: remote')\nRemote caches can be nested inside regular caches ('use cache')\nRemote caches cannot be nested inside private caches ('use cache: private')\nPrivate caches cannot be nested inside remote caches\n// VALID: Remote inside remote\nasync function outerRemote() {\n  'use cache: remote'\n  const result = await innerRemote()\n  return result\n}\n \nasync function innerRemote() {\n  'use cache: remote'\n  return getData()\n}\n \n// VALID: Remote inside regular cache\nasync function outerCache() {\n  'use cache'\n  // If this is in a dynamic context, the inner remote cache will work\n  const result = await innerRemote()\n  return result\n}\n \nasync function innerRemote() {\n  'use cache: remote'\n  return getData()\n}\n \n// INVALID: Remote inside private\nasync function outerPrivate() {\n  'use cache: private'\n  const result = await innerRemote() // Error!\n  return result\n}\n \nasync function innerRemote() {\n  'use cache: remote'\n  return getData()\n}\n \n// INVALID: Private inside remote\nasync function outerRemote() {\n  'use cache: remote'\n  const result = await innerPrivate() // Error!\n  return result\n}\n \nasync function innerPrivate() {\n  'use cache: private'\n  return getData()\n}\nExamples\n\nThe following examples demonstrate common patterns for using 'use cache: remote'. For details about cacheLife parameters (stale, revalidate, expire), see the cacheLife API reference.\n\nPer-request database queries\n\nCache expensive database queries that are accessed in dynamic contexts, reducing load on your database:\n\napp/dashboard/page.tsx\nimport { connection } from 'next/server'\nimport { cacheLife, cacheTag } from 'next/cache'\n \nexport default async function DashboardPage() {\n  // Make context dynamic\n  await connection()\n \n  const stats = await getGlobalStats()\n \n  return <StatsDisplay stats={stats} />\n}\n \nasync function getGlobalStats() {\n  'use cache: remote'\n  cacheTag('global-stats')\n  cacheLife({ expire: 60 }) // 1 minute\n \n  // This expensive database query is cached and shared across all users,\n  // reducing load on your database\n  const stats = await db.analytics.aggregate({\n    total_users: 'count',\n    active_sessions: 'count',\n    revenue: 'sum',\n  })\n \n  return stats\n}\nAPI responses in streaming contexts\n\nCache API responses that are fetched during streaming or after dynamic operations:\n\napp/feed/page.tsx\nimport { Suspense } from 'react'\nimport { connection } from 'next/server'\nimport { cacheLife, cacheTag } from 'next/cache'\n \nexport default async function FeedPage() {\n  return (\n    <div>\n      <Suspense fallback={<Skeleton />}>\n        <FeedItems />\n      </Suspense>\n    </div>\n  )\n}\n \nasync function FeedItems() {\n  // Dynamic context\n  await connection()\n \n  const items = await getFeedItems()\n \n  return items.map((item) => <FeedItem key={item.id} item={item} />)\n}\n \nasync function getFeedItems() {\n  'use cache: remote'\n  cacheTag('feed-items')\n  cacheLife({ expire: 120 }) // 2 minutes\n \n  // This API call is cached, reducing requests to your external service\n  const response = await fetch('https://api.example.com/feed')\n  return response.json()\n}\nComputed data after dynamic checks\n\nCache expensive computations that occur after dynamic security or feature checks:\n\napp/reports/page.tsx\nimport { connection } from 'next/server'\nimport { cacheLife } from 'next/cache'\n \nexport default async function ReportsPage() {\n  // Dynamic security check\n  await connection()\n \n  const report = await generateReport()\n \n  return <ReportViewer report={report} />\n}\n \nasync function generateReport() {\n  'use cache: remote'\n  cacheLife({ expire: 3600 }) // 1 hour\n \n  // This expensive computation is cached and shared across all authorized users,\n  // avoiding repeated calculations\n  const data = await db.transactions.findMany()\n \n  return {\n    totalRevenue: calculateRevenue(data),\n    topProducts: analyzeProducts(data),\n    trends: calculateTrends(data),\n  }\n}\nMixed caching strategies\n\nCombine static, remote, and private caching for optimal performance:\n\napp/product/[id]/page.tsx\nimport { Suspense } from 'react'\nimport { connection } from 'next/server'\nimport { cookies } from 'next/headers'\nimport { cacheLife, cacheTag } from 'next/cache'\n \n// Static product data - prerendered at build time\nasync function getProduct(id: string) {\n  'use cache'\n  cacheTag(`product-${id}`)\n \n  // This is cached at build time and shared across all users\n  return db.products.find({ where: { id } })\n}\n \n// Shared pricing data - cached at runtime in remote handler\nasync function getProductPrice(id: string) {\n  'use cache: remote'\n  cacheTag(`product-price-${id}`)\n  cacheLife({ expire: 300 }) // 5 minutes\n \n  // This is cached at runtime and shared across all users\n  return db.products.getPrice({ where: { id } })\n}\n \n// User-specific recommendations - private cache per user\nasync function getRecommendations(productId: string) {\n  'use cache: private'\n  cacheLife({ expire: 60 }) // 1 minute\n \n  const sessionId = (await cookies()).get('session-id')?.value\n \n  // This is cached per-user and never shared\n  return db.recommendations.findMany({\n    where: { productId, sessionId },\n  })\n}\n \nexport default async function ProductPage({ params }) {\n  const { id } = await params\n \n  // Static product data\n  const product = await getProduct(id)\n \n  return (\n    <div>\n      <ProductDetails product={product} />\n \n      {/* Dynamic shared price */}\n      <Suspense fallback={<PriceSkeleton />}>\n        <ProductPriceComponent productId={id} />\n      </Suspense>\n \n      {/* Dynamic personalized recommendations */}\n      <Suspense fallback={<RecommendationsSkeleton />}>\n        <ProductRecommendations productId={id} />\n      </Suspense>\n    </div>\n  )\n}\n \nfunction ProductDetails({ product }) {\n  return (\n    <div>\n      <h1>{product.name}</h1>\n      <p>{product.description}</p>\n    </div>\n  )\n}\n \nasync function ProductPriceComponent({ productId }) {\n  // Make this component dynamic\n  await connection()\n \n  const price = await getProductPrice(productId)\n  return <div>Price: ${price}</div>\n}\n \nasync function ProductRecommendations({ productId }) {\n  const recommendations = await getRecommendations(productId)\n  return <RecommendationsList items={recommendations} />\n}\n \nfunction PriceSkeleton() {\n  return <div>Loading price...</div>\n}\n \nfunction RecommendationsSkeleton() {\n  return <div>Loading recommendations...</div>\n}\n \nfunction RecommendationsList({ items }) {\n  return (\n    <ul>\n      {items.map((item) => (\n        <li key={item.id}>{item.name}</li>\n      ))}\n    </ul>\n  )\n}\n\nGood to know:\n\nRemote caches are stored in server-side cache handlers and shared across all users\nRemote caches work in dynamic contexts where regular use cache would fail\nUse cacheTag() and revalidateTag() to invalidate remote caches on-demand\nUse cacheLife() to configure cache expiration\nFor user-specific data, use 'use cache: private' instead of 'use cache: remote'\nRemote caches reduce origin load by storing computed or fetched data server-side\nPlatform Support\nDeployment Option\tSupported\nNode.js server\tYes\nDocker container\tYes\nStatic export\tNo\nAdapters\tYes\nVersion History\nVersion\tChanges\nv16.0.0\t'use cache: remote' introduced as an experimental feature.\nRelated\nView related API references.\nuse cache\nLearn how to use the use cache directive to cache data in your Next.js application.\nuse cache: private\nLearn how to use the `\"use cache: private\"` directive to enable runtime prefetching of personalized content in your Next.js application.\ncacheComponents\nLearn how to enable the cacheComponents flag in Next.js.\ncacheLife\nLearn how to use the cacheLife function to set the cache expiration time for a cached function or component.\ncacheTag\nLearn how to use the cacheTag function to manage cache invalidation in your Next.js application.\nconnection\nAPI Reference for the connection function.\nPrevious\nuse cache: private\nNext\nuse client\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Directives: use server | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/directives/use-server",
    "html": "API Reference\nDirectives\nuse server\nCopy page\nuse server\n\nThe use server directive designates a function or file to be executed on the server side. It can be used at the top of a file to indicate that all functions in the file are server-side, or inline at the top of a function to mark the function as a Server Function\n. This is a React feature.\n\nUsing use server at the top of a file\n\nThe following example shows a file with a use server directive at the top. All functions in the file are executed on the server.\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\nimport { db } from '@/lib/db' // Your database client\n \nexport async function createUser(data: { name: string; email: string }) {\n  const user = await db.user.create({ data })\n  return user\n}\nUsing Server Functions in a Client Component\n\nTo use Server Functions in Client Components you need to create your Server Functions in a dedicated file using the use server directive at the top of the file. These Server Functions can then be imported into Client and Server Components and executed.\n\nAssuming you have a fetchUsers Server Function in actions.ts:\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\nimport { db } from '@/lib/db' // Your database client\n \nexport async function fetchUsers() {\n  const users = await db.user.findMany()\n  return users\n}\n\nThen you can import the fetchUsers Server Function into a Client Component and execute it on the client-side.\n\napp/components/my-button.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\nimport { fetchUsers } from '../actions'\n \nexport default function MyButton() {\n  return <button onClick={() => fetchUsers()}>Fetch Users</button>\n}\nUsing use server inline\n\nIn the following example, use server is used inline at the top of a function to mark it as a Server Function\n:\n\napp/posts/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { EditPost } from './edit-post'\nimport { revalidatePath } from 'next/cache'\n \nexport default async function PostPage({ params }: { params: { id: string } }) {\n  const post = await getPost(params.id)\n \n  async function updatePost(formData: FormData) {\n    'use server'\n    await savePost(params.id, formData)\n    revalidatePath(`/posts/${params.id}`)\n  }\n \n  return <EditPost updatePostAction={updatePost} post={post} />\n}\nSecurity considerations\n\nWhen using the use server directive, it's important to ensure that all server-side logic is secure and that sensitive data remains protected.\n\nAuthentication and authorization\n\nAlways authenticate and authorize users before performing sensitive server-side operations.\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { db } from '@/lib/db' // Your database client\nimport { authenticate } from '@/lib/auth' // Your authentication library\n \nexport async function createUser(\n  data: { name: string; email: string },\n  token: string\n) {\n  const user = authenticate(token)\n  if (!user) {\n    throw new Error('Unauthorized')\n  }\n  const newUser = await db.user.create({ data })\n  return newUser\n}\nReference\n\nSee the React documentation\n for more information on use server.\n\nPrevious\nuse client\nNext\nComponents\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "API Reference: Components | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/components",
    "html": "App Router\nAPI Reference\nComponents\nCopy page\nComponents\nFont\nOptimizing loading web fonts with the built-in `next/font` loaders.\nForm Component\nLearn how to use the `<Form>` component to handle form submissions and search params updates with client-side navigation.\nImage Component\nOptimize Images in your Next.js Application using the built-in `next/image` Component.\nLink Component\nEnable fast client-side navigation with the built-in `next/link` component.\nScript Component\nOptimize third-party scripts in your Next.js application using the built-in `next/script` Component.\nPrevious\nuse server\nNext\nFont\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Components: Form Component | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/components/form",
    "html": "API Reference\nComponents\nForm Component\nCopy page\nForm Component\n\nThe <Form> component extends the HTML <form> element to provide prefetching of loading UI, client-side navigation on submission, and progressive enhancement.\n\nIt's useful for forms that update URL search params as it reduces the boilerplate code needed to achieve the above.\n\nBasic usage:\n\n/app/ui/search.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Form from 'next/form'\n \nexport default function Page() {\n  return (\n    <Form action=\"/search\">\n      {/* On submission, the input value will be appended to\n          the URL, e.g. /search?query=abc */}\n      <input name=\"query\" />\n      <button type=\"submit\">Submit</button>\n    </Form>\n  )\n}\nReference\n\nThe behavior of the <Form> component depends on whether the action prop is passed a string or function.\n\nWhen action is a string, the <Form> behaves like a native HTML form that uses a GET method. The form data is encoded into the URL as search params, and when the form is submitted, it navigates to the specified URL. In addition, Next.js:\nPrefetches the path when the form becomes visible, this preloads shared UI (e.g. layout.js and loading.js), resulting in faster navigation.\nPerforms a client-side navigation instead of a full page reload when the form is submitted. This retains shared UI and client-side state.\nWhen action is a function (Server Action), <Form> behaves like a React form\n, executing the action when the form is submitted.\naction (string) Props\n\nWhen action is a string, the <Form> component supports the following props:\n\nProp\tExample\tType\tRequired\naction\taction=\"/search\"\tstring (URL or relative path)\tYes\nreplace\treplace={false}\tboolean\t-\nscroll\tscroll={true}\tboolean\t-\nprefetch\tprefetch={true}\tboolean\t-\naction: The URL or path to navigate to when the form is submitted.\nAn empty string \"\" will navigate to the same route with updated search params.\nreplace: Replaces the current history state instead of pushing a new one to the browser's history\n stack. Default is false.\nscroll: Controls the scroll behavior during navigation. Defaults to true, this means it will scroll to the top of the new route, and maintain the scroll position for backwards and forwards navigation.\nprefetch: Controls whether the path should be prefetched when the form becomes visible in the user's viewport. Defaults to true.\naction (function) Props\n\nWhen action is a function, the <Form> component supports the following prop:\n\nProp\tExample\tType\tRequired\naction\taction={myAction}\tfunction (Server Action)\tYes\naction: The Server Action to be called when the form is submitted. See the React docs\n for more.\n\nGood to know: When action is a function, the replace and scroll props are ignored.\n\nCaveats\nformAction: Can be used in a <button> or <input type=\"submit\"> fields to override the action prop. Next.js will perform a client-side navigation, however, this approach doesn't support prefetching.\nWhen using basePath, you must also include it in the formAction path. e.g. formAction=\"/base-path/search\".\nkey: Passing a key prop to a string action is not supported. If you'd like to trigger a re-render or perform a mutation, consider using a function action instead.\nonSubmit: Can be used to handle form submission logic. However, calling event.preventDefault() will override <Form> behavior such as navigating to the specified URL.\nmethod\n, encType\n, target\n: Are not supported as they override <Form> behavior.\nSimilarly, formMethod, formEncType, and formTarget can be used to override the method, encType, and target props respectively, and using them will fallback to native browser behavior.\nIf you need to use these props, use the HTML <form> element instead.\n<input type=\"file\">: Using this input type when the action is a string will match browser behavior by submitting the filename instead of the file object.\nExamples\nSearch form that leads to a search result page\n\nYou can create a search form that navigates to a search results page by passing the path as an action:\n\n/app/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Form from 'next/form'\n \nexport default function Page() {\n  return (\n    <Form action=\"/search\">\n      <input name=\"query\" />\n      <button type=\"submit\">Submit</button>\n    </Form>\n  )\n}\n\nWhen the user updates the query input field and submits the form, the form data will be encoded into the URL as search params, e.g. /search?query=abc.\n\nGood to know: If you pass an empty string \"\" to action, the form will navigate to the same route with updated search params.\n\nOn the results page, you can access the query using the searchParams page.js prop and use it to fetch data from an external source.\n\n/app/search/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getSearchResults } from '@/lib/search'\n \nexport default async function SearchPage({\n  searchParams,\n}: {\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}) {\n  const results = await getSearchResults((await searchParams).query)\n \n  return <div>...</div>\n}\n\nWhen the <Form> becomes visible in the user's viewport, shared UI (such as layout.js and loading.js) on the /search page will be prefetched. On submission, the form will immediately navigate to the new route and show loading UI while the results are being fetched. You can design the fallback UI using loading.js:\n\n/app/search/loading.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Loading() {\n  return <div>Loading...</div>\n}\n\nTo cover cases when shared UI hasn't yet loaded, you can show instant feedback to the user using useFormStatus\n.\n\nFirst, create a component that displays a loading state when the form is pending:\n\n/app/ui/search-button.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\nimport { useFormStatus } from 'react-dom'\n \nexport default function SearchButton() {\n  const status = useFormStatus()\n  return (\n    <button type=\"submit\">{status.pending ? 'Searching...' : 'Search'}</button>\n  )\n}\n\nThen, update the search form page to use the SearchButton component:\n\n/app/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Form from 'next/form'\nimport { SearchButton } from '@/ui/search-button'\n \nexport default function Page() {\n  return (\n    <Form action=\"/search\">\n      <input name=\"query\" />\n      <SearchButton />\n    </Form>\n  )\n}\nMutations with Server Actions\n\nYou can perform mutations by passing a function to the action prop.\n\n/app/posts/create/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Form from 'next/form'\nimport { createPost } from '@/posts/actions'\n \nexport default function Page() {\n  return (\n    <Form action={createPost}>\n      <input name=\"title\" />\n      {/* ... */}\n      <button type=\"submit\">Create Post</button>\n    </Form>\n  )\n}\n\nAfter a mutation, it's common to redirect to the new resource. You can use the redirect function from next/navigation to navigate to the new post page.\n\nGood to know: Since the \"destination\" of the form submission is not known until the action is executed, <Form> cannot automatically prefetch shared UI.\n\n/app/posts/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\nimport { redirect } from 'next/navigation'\n \nexport async function createPost(formData: FormData) {\n  // Create a new post\n  // ...\n \n  // Redirect to the new post\n  redirect(`/posts/${data.id}`)\n}\n\nThen, in the new page, you can fetch data using the params prop:\n\n/app/posts/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getPost } from '@/posts/data'\n \nexport default async function PostPage({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n  const data = await getPost(id)\n \n  return (\n    <div>\n      <h1>{data.title}</h1>\n      {/* ... */}\n    </div>\n  )\n}\n\nSee the Server Actions docs for more examples.\n\nPrevious\nFont\nNext\nImage Component\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Components: Font | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/components/font",
    "html": "API Reference\nComponents\nFont\nCopy page\nFont Module\n\nnext/font automatically optimizes your fonts (including custom fonts) and removes external network requests for improved privacy and performance.\n\nIt includes built-in automatic self-hosting for any font file. This means you can optimally load web fonts with no layout shift\n.\n\nYou can also conveniently use all Google Fonts\n. CSS and font files are downloaded at build time and self-hosted with the rest of your static assets. No requests are sent to Google by the browser.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Inter } from 'next/font/google'\n \n// If loading a variable font, you don't need to specify the font weight\nconst inter = Inter({\n  subsets: ['latin'],\n  display: 'swap',\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={inter.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\n\n🎥 Watch: Learn more about using next/font → YouTube (6 minutes)\n.\n\nReference\nKey\tfont/google\tfont/local\tType\tRequired\nsrc\t\n\t\n\tString or Array of Objects\tYes\nweight\t\n\t\n\tString or Array\tRequired/Optional\nstyle\t\n\t\n\tString or Array\t-\nsubsets\t\n\t\n\tArray of Strings\t-\naxes\t\n\t\n\tArray of Strings\t-\ndisplay\t\n\t\n\tString\t-\npreload\t\n\t\n\tBoolean\t-\nfallback\t\n\t\n\tArray of Strings\t-\nadjustFontFallback\t\n\t\n\tBoolean or String\t-\nvariable\t\n\t\n\tString\t-\ndeclarations\t\n\t\n\tArray of Objects\t-\nsrc\n\nThe path of the font file as a string or an array of objects (with type Array<{path: string, weight?: string, style?: string}>) relative to the directory where the font loader function is called.\n\nUsed in next/font/local\n\nRequired\n\nExamples:\n\nsrc:'./fonts/my-font.woff2' where my-font.woff2 is placed in a directory named fonts inside the app directory\nsrc:[{path: './inter/Inter-Thin.ttf', weight: '100',},{path: './inter/Inter-Regular.ttf',weight: '400',},{path: './inter/Inter-Bold-Italic.ttf', weight: '700',style: 'italic',},]\nif the font loader function is called in app/page.tsx using src:'../styles/fonts/my-font.ttf', then my-font.ttf is placed in styles/fonts at the root of the project\nweight\n\nThe font weight\n with the following possibilities:\n\nA string with possible values of the weights available for the specific font or a range of values if it's a variable\n font\nAn array of weight values if the font is not a variable google font\n. It applies to next/font/google only.\n\nUsed in next/font/google and next/font/local\n\nRequired if the font being used is not variable\n\nExamples:\n\nweight: '400': A string for a single weight value - for the font Inter\n, the possible values are '100', '200', '300', '400', '500', '600', '700', '800', '900' or 'variable' where 'variable' is the default)\nweight: '100 900': A string for the range between 100 and 900 for a variable font\nweight: ['100','400','900']: An array of 3 possible values for a non variable font\nstyle\n\nThe font style\n with the following possibilities:\n\nA string value\n with default value of 'normal'\nAn array of style values if the font is not a variable google font\n. It applies to next/font/google only.\n\nUsed in next/font/google and next/font/local\n\nOptional\n\nExamples:\n\nstyle: 'italic': A string - it can be normal or italic for next/font/google\nstyle: 'oblique': A string - it can take any value for next/font/local but is expected to come from standard font styles\nstyle: ['italic','normal']: An array of 2 values for next/font/google - the values are from normal and italic\nsubsets\n\nThe font subsets\n defined by an array of string values with the names of each subset you would like to be preloaded. Fonts specified via subsets will have a link preload tag injected into the head when the preload option is true, which is the default.\n\nUsed in next/font/google\n\nOptional\n\nExamples:\n\nsubsets: ['latin']: An array with the subset latin\n\nYou can find a list of all subsets on the Google Fonts page for your font.\n\naxes\n\nSome variable fonts have extra axes that can be included. By default, only the font weight is included to keep the file size down. The possible values of axes depend on the specific font.\n\nUsed in next/font/google\n\nOptional\n\nExamples:\n\naxes: ['slnt']: An array with value slnt for the Inter variable font which has slnt as additional axes as shown here\n. You can find the possible axes values for your font by using the filter on the Google variable fonts page\n and looking for axes other than wght\ndisplay\n\nThe font display\n with possible string values\n of 'auto', 'block', 'swap', 'fallback' or 'optional' with default value of 'swap'.\n\nUsed in next/font/google and next/font/local\n\nOptional\n\nExamples:\n\ndisplay: 'optional': A string assigned to the optional value\npreload\n\nA boolean value that specifies whether the font should be preloaded or not. The default is true.\n\nUsed in next/font/google and next/font/local\n\nOptional\n\nExamples:\n\npreload: false\nfallback\n\nThe fallback font to use if the font cannot be loaded. An array of strings of fallback fonts with no default.\n\nOptional\n\nUsed in next/font/google and next/font/local\n\nExamples:\n\nfallback: ['system-ui', 'arial']: An array setting the fallback fonts to system-ui or arial\nadjustFontFallback\nFor next/font/google: A boolean value that sets whether an automatic fallback font should be used to reduce Cumulative Layout Shift\n. The default is true.\nFor next/font/local: A string or boolean false value that sets whether an automatic fallback font should be used to reduce Cumulative Layout Shift\n. The possible values are 'Arial', 'Times New Roman' or false. The default is 'Arial'.\n\nUsed in next/font/google and next/font/local\n\nOptional\n\nExamples:\n\nadjustFontFallback: false: for next/font/google\nadjustFontFallback: 'Times New Roman': for next/font/local\nvariable\n\nA string value to define the CSS variable name to be used if the style is applied with the CSS variable method.\n\nUsed in next/font/google and next/font/local\n\nOptional\n\nExamples:\n\nvariable: '--my-font': The CSS variable --my-font is declared\ndeclarations\n\nAn array of font face descriptor\n key-value pairs that define the generated @font-face further.\n\nUsed in next/font/local\n\nOptional\n\nExamples:\n\ndeclarations: [{ prop: 'ascent-override', value: '90%' }]\nExamples\nGoogle Fonts\n\nTo use a Google font, import it from next/font/google as a function. We recommend using variable fonts\n for the best performance and flexibility.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Inter } from 'next/font/google'\n \n// If loading a variable font, you don't need to specify the font weight\nconst inter = Inter({\n  subsets: ['latin'],\n  display: 'swap',\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={inter.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\n\nIf you can't use a variable font, you will need to specify a weight:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Roboto } from 'next/font/google'\n \nconst roboto = Roboto({\n  weight: '400',\n  subsets: ['latin'],\n  display: 'swap',\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={roboto.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\n\nYou can specify multiple weights and/or styles by using an array:\n\napp/layout.js\nconst roboto = Roboto({\n  weight: ['400', '700'],\n  style: ['normal', 'italic'],\n  subsets: ['latin'],\n  display: 'swap',\n})\n\nGood to know: Use an underscore (_) for font names with multiple words. E.g. Roboto Mono should be imported as Roboto_Mono.\n\nSpecifying a subset\n\nGoogle Fonts are automatically subset\n. This reduces the size of the font file and improves performance. You'll need to define which of these subsets you want to preload. Failing to specify any subsets while preload is true will result in a warning.\n\nThis can be done by adding it to the function call:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nconst inter = Inter({ subsets: ['latin'] })\n\nView the Font API Reference for more information.\n\nUsing Multiple Fonts\n\nYou can import and use multiple fonts in your application. There are two approaches you can take.\n\nThe first approach is to create a utility function that exports a font, imports it, and applies its className where needed. This ensures the font is preloaded only when it's rendered:\n\napp/fonts.ts\nTypeScript\nJavaScript\nTypeScript\nimport { Inter, Roboto_Mono } from 'next/font/google'\n \nexport const inter = Inter({\n  subsets: ['latin'],\n  display: 'swap',\n})\n \nexport const roboto_mono = Roboto_Mono({\n  subsets: ['latin'],\n  display: 'swap',\n})\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { inter } from './fonts'\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return (\n    <html lang=\"en\" className={inter.className}>\n      <body>\n        <div>{children}</div>\n      </body>\n    </html>\n  )\n}\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { roboto_mono } from './fonts'\n \nexport default function Page() {\n  return (\n    <>\n      <h1 className={roboto_mono.className}>My page</h1>\n    </>\n  )\n}\n\nIn the example above, Inter will be applied globally, and Roboto Mono can be imported and applied as needed.\n\nAlternatively, you can create a CSS variable and use it with your preferred CSS solution:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Inter, Roboto_Mono } from 'next/font/google'\nimport styles from './global.css'\n \nconst inter = Inter({\n  subsets: ['latin'],\n  variable: '--font-inter',\n  display: 'swap',\n})\n \nconst roboto_mono = Roboto_Mono({\n  subsets: ['latin'],\n  variable: '--font-roboto-mono',\n  display: 'swap',\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={`${inter.variable} ${roboto_mono.variable}`}>\n      <body>\n        <h1>My App</h1>\n        <div>{children}</div>\n      </body>\n    </html>\n  )\n}\napp/global.css\nhtml {\n  font-family: var(--font-inter);\n}\n \nh1 {\n  font-family: var(--font-roboto-mono);\n}\n\nIn the example above, Inter will be applied globally, and any <h1> tags will be styled with Roboto Mono.\n\nRecommendation: Use multiple fonts conservatively since each new font is an additional resource the client has to download.\n\nLocal Fonts\n\nImport next/font/local and specify the src of your local font file. We recommend using variable fonts\n for the best performance and flexibility.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport localFont from 'next/font/local'\n \n// Font files can be colocated inside of `app`\nconst myFont = localFont({\n  src: './my-font.woff2',\n  display: 'swap',\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={myFont.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\n\nIf you want to use multiple files for a single font family, src can be an array:\n\nconst roboto = localFont({\n  src: [\n    {\n      path: './Roboto-Regular.woff2',\n      weight: '400',\n      style: 'normal',\n    },\n    {\n      path: './Roboto-Italic.woff2',\n      weight: '400',\n      style: 'italic',\n    },\n    {\n      path: './Roboto-Bold.woff2',\n      weight: '700',\n      style: 'normal',\n    },\n    {\n      path: './Roboto-BoldItalic.woff2',\n      weight: '700',\n      style: 'italic',\n    },\n  ],\n})\n\nView the Font API Reference for more information.\n\nWith Tailwind CSS\n\nnext/font integrates seamlessly with Tailwind CSS\n using CSS variables.\n\nIn the example below, we use the Inter and Roboto_Mono fonts from next/font/google (you can use any Google Font or Local Font). Use the variable option to define a CSS variable name, such as inter and roboto_mono for these fonts, respectively. Then, apply inter.variable and roboto_mono.variable to include the CSS variables in your HTML document.\n\nGood to know: You can add these variables to the <html> or <body> tag, depending on your preference, styling needs or project requirements.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Inter, Roboto_Mono } from 'next/font/google'\n \nconst inter = Inter({\n  subsets: ['latin'],\n  display: 'swap',\n  variable: '--font-inter',\n})\n \nconst roboto_mono = Roboto_Mono({\n  subsets: ['latin'],\n  display: 'swap',\n  variable: '--font-roboto-mono',\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html\n      lang=\"en\"\n      className={`${inter.variable} ${roboto_mono.variable} antialiased`}\n    >\n      <body>{children}</body>\n    </html>\n  )\n}\n\nFinally, add the CSS variable to your Tailwind CSS config:\n\nglobal.css\n@import 'tailwindcss';\n \n@theme inline {\n  --font-sans: var(--font-inter);\n  --font-mono: var(--font-roboto-mono);\n}\nTailwind CSS v3\ntailwind.config.js\n/** @type {import('tailwindcss').Config} */\nmodule.exports = {\n  content: [\n    './pages/**/*.{js,ts,jsx,tsx}',\n    './components/**/*.{js,ts,jsx,tsx}',\n    './app/**/*.{js,ts,jsx,tsx}',\n  ],\n  theme: {\n    extend: {\n      fontFamily: {\n        sans: ['var(--font-inter)'],\n        mono: ['var(--font-roboto-mono)'],\n      },\n    },\n  },\n  plugins: [],\n}\n\nYou can now use the font-sans and font-mono utility classes to apply the font to your elements.\n\n<p class=\"font-sans ...\">The quick brown fox ...</p>\n<p class=\"font-mono ...\">The quick brown fox ...</p>\nApplying Styles\n\nYou can apply the font styles in three ways:\n\nclassName\nstyle\nCSS Variables\nclassName\n\nReturns a read-only CSS className for the loaded font to be passed to an HTML element.\n\n<p className={inter.className}>Hello, Next.js!</p>\nstyle\n\nReturns a read-only CSS style object for the loaded font to be passed to an HTML element, including style.fontFamily to access the font family name and fallback fonts.\n\n<p style={inter.style}>Hello World</p>\nCSS Variables\n\nIf you would like to set your styles in an external style sheet and specify additional options there, use the CSS variable method.\n\nIn addition to importing the font, also import the CSS file where the CSS variable is defined and set the variable option of the font loader object as follows:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Inter } from 'next/font/google'\nimport styles from '../styles/component.module.css'\n \nconst inter = Inter({\n  variable: '--font-inter',\n})\n\nTo use the font, set the className of the parent container of the text you would like to style to the font loader's variable value and the className of the text to the styles property from the external CSS file.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n<main className={inter.variable}>\n  <p className={styles.text}>Hello World</p>\n</main>\n\nDefine the text selector class in the component.module.css CSS file as follows:\n\nstyles/component.module.css\n.text {\n  font-family: var(--font-inter);\n  font-weight: 200;\n  font-style: italic;\n}\n\nIn the example above, the text Hello World is styled using the Inter font and the generated font fallback with font-weight: 200 and font-style: italic.\n\nUsing a font definitions file\n\nEvery time you call the localFont or Google font function, that font will be hosted as one instance in your application. Therefore, if you need to use the same font in multiple places, you should load it in one place and import the related font object where you need it. This is done using a font definitions file.\n\nFor example, create a fonts.ts file in a styles folder at the root of your app directory.\n\nThen, specify your font definitions as follows:\n\nstyles/fonts.ts\nTypeScript\nJavaScript\nTypeScript\nimport { Inter, Lora, Source_Sans_3 } from 'next/font/google'\nimport localFont from 'next/font/local'\n \n// define your variable fonts\nconst inter = Inter()\nconst lora = Lora()\n// define 2 weights of a non-variable font\nconst sourceCodePro400 = Source_Sans_3({ weight: '400' })\nconst sourceCodePro700 = Source_Sans_3({ weight: '700' })\n// define a custom local font where GreatVibes-Regular.ttf is stored in the styles folder\nconst greatVibes = localFont({ src: './GreatVibes-Regular.ttf' })\n \nexport { inter, lora, sourceCodePro400, sourceCodePro700, greatVibes }\n\nYou can now use these definitions in your code as follows:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { inter, lora, sourceCodePro700, greatVibes } from '../styles/fonts'\n \nexport default function Page() {\n  return (\n    <div>\n      <p className={inter.className}>Hello world using Inter font</p>\n      <p style={lora.style}>Hello world using Lora font</p>\n      <p className={sourceCodePro700.className}>\n        Hello world using Source_Sans_3 font with weight 700\n      </p>\n      <p className={greatVibes.className}>My title in Great Vibes font</p>\n    </div>\n  )\n}\n\nTo make it easier to access the font definitions in your code, you can define a path alias in your tsconfig.json or jsconfig.json files as follows:\n\ntsconfig.json\n{\n  \"compilerOptions\": {\n    \"paths\": {\n      \"@/fonts\": [\"./styles/fonts\"]\n    }\n  }\n}\n\nYou can now import any font definition as follows:\n\napp/about/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { greatVibes, sourceCodePro400 } from '@/fonts'\nPreloading\n\nWhen a font function is called on a page of your site, it is not globally available and preloaded on all routes. Rather, the font is only preloaded on the related routes based on the type of file where it is used:\n\nIf it's a unique page, it is preloaded on the unique route for that page.\nIf it's a layout, it is preloaded on all the routes wrapped by the layout.\nIf it's the root layout, it is preloaded on all routes.\nVersion Changes\nVersion\tChanges\nv13.2.0\t@next/font renamed to next/font. Installation no longer required.\nv13.0.0\t@next/font was added.\nPrevious\nComponents\nNext\nForm Component\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Components: Image Component | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/components/image",
    "html": "API Reference\nComponents\nImage Component\nCopy page\nImage Component\n\nThe Next.js Image component extends the HTML <img> element for automatic image optimization.\n\napp/page.js\nimport Image from 'next/image'\n \nexport default function Page() {\n  return (\n    <Image\n      src=\"/profile.png\"\n      width={500}\n      height={500}\n      alt=\"Picture of the author\"\n    />\n  )\n}\nReference\nProps\n\nThe following props are available:\n\nProp\tExample\tType\tStatus\nsrc\tsrc=\"/profile.png\"\tString\tRequired\nalt\talt=\"Picture of the author\"\tString\tRequired\nwidth\twidth={500}\tInteger (px)\t-\nheight\theight={500}\tInteger (px)\t-\nfill\tfill={true}\tBoolean\t-\nloader\tloader={imageLoader}\tFunction\t-\nsizes\tsizes=\"(max-width: 768px) 100vw, 33vw\"\tString\t-\nquality\tquality={80}\tInteger (1-100)\t-\npreload\tpreload={true}\tBoolean\t-\nplaceholder\tplaceholder=\"blur\"\tString\t-\nstyle\tstyle={{objectFit: \"contain\"}}\tObject\t-\nonLoadingComplete\tonLoadingComplete={img => done())}\tFunction\tDeprecated\nonLoad\tonLoad={event => done())}\tFunction\t-\nonError\tonError(event => fail()}\tFunction\t-\nloading\tloading=\"lazy\"\tString\t-\nblurDataURL\tblurDataURL=\"data:image/jpeg...\"\tString\t-\nunoptimized\tunoptimized={true}\tBoolean\t-\noverrideSrc\toverrideSrc=\"/seo.png\"\tString\t-\ndecoding\tdecoding=\"async\"\tString\t-\nsrc\n\nThe source of the image. Can be one of the following:\n\nAn internal path string.\n\n<Image src=\"/profile.png\" />\n\nAn absolute external URL (must be configured with remotePatterns).\n\n<Image src=\"https://example.com/profile.png\" />\n\nA static import.\n\nimport profile from './profile.png'\n \nexport default function Page() {\n  return <Image src={profile} />\n}\n\nGood to know: For security reasons, the Image Optimization API using the default loader will not forward headers when fetching the src image. If the src image requires authentication, consider using the unoptimized property to disable Image Optimization.\n\nalt\n\nThe alt property is used to describe the image for screen readers and search engines. It is also the fallback text if images have been disabled or an error occurs while loading the image.\n\nIt should contain text that could replace the image without changing the meaning of the page\n. It is not meant to supplement the image and should not repeat information that is already provided in the captions above or below the image.\n\nIf the image is purely decorative\n or not intended for the user\n, the alt property should be an empty string (alt=\"\").\n\nLearn more about image accessibility guidelines\n.\n\nwidth and height\n\nThe width and height properties represent the intrinsic\n image size in pixels. This property is used to infer the correct aspect ratio used by browsers to reserve space for the image and avoid layout shift during loading. It does not determine the rendered size of the image, which is controlled by CSS.\n\n<Image src=\"/profile.png\" width={500} height={500} />\n\nYou must set both width and height properties unless:\n\nThe image is statically imported.\nThe image has the fill property\n\nIf the height and width are unknown, we recommend using the fill property.\n\nfill\n\nA boolean that causes the image to expand to the size of the parent element.\n\n<Image src=\"/profile.png\" fill={true} />\n\nPositioning:\n\nThe parent element must assign position: \"relative\", \"fixed\", \"absolute\".\nBy default, the <img> element uses position: \"absolute\".\n\nObject Fit:\n\nIf no styles are applied to the image, the image will stretch to fit the container. You can use objectFit to control cropping and scaling.\n\n\"contain\": The image will be scaled down to fit the container and preserve aspect ratio.\n\"cover\": The image will fill the container and be cropped.\n\nLearn more about position\n and object-fit\n.\n\nloader\n\nA custom function used to generate the image URL. The function receives the following parameters, and returns a URL string for the image:\n\nsrc\nwidth\nquality\n'use client'\n \nimport Image from 'next/image'\n \nconst imageLoader = ({ src, width, quality }) => {\n  return `https://example.com/${src}?w=${width}&q=${quality || 75}`\n}\n \nexport default function Page() {\n  return (\n    <Image\n      loader={imageLoader}\n      src=\"me.png\"\n      alt=\"Picture of the author\"\n      width={500}\n      height={500}\n    />\n  )\n}\n\nGood to know: Using props like onLoad, which accept a function, requires using Client Components\n to serialize the provided function.\n\nAlternatively, you can use the loaderFile configuration in next.config.js to configure every instance of next/image in your application, without passing a prop.\n\nsizes\n\nDefine the sizes of the image at different breakpoints. Used by the browser to choose the most appropriate size from the generated srcset.\n\nimport Image from 'next/image'\n \nexport default function Page() {\n  return (\n    <div className=\"grid-element\">\n      <Image\n        fill\n        src=\"/example.png\"\n        sizes=\"(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw\"\n      />\n    </div>\n  )\n}\n\nsizes should be used when:\n\nThe image is using the fill prop\nCSS is used to make the image responsive\n\nIf sizes is missing, the browser assumes the image will be as wide as the viewport (100vw). This can cause unnecessarily large images to be downloaded.\n\nIn addition, sizes affects how srcset is generated:\n\nWithout sizes: Next.js generates a limited srcset (e.g. 1x, 2x), suitable for fixed-size images.\nWith sizes: Next.js generates a full srcset (e.g. 640w, 750w, etc.), optimized for responsive layouts.\n\nLearn more about srcset and sizes on web.dev\n and mdn\n.\n\nquality\n\nAn integer between 1 and 100 that sets the quality of the optimized image. Higher values increase file size and visual fidelity. Lower values reduce file size but may affect sharpness.\n\n// Default quality is 75\n<Image quality={75} />\n\nIf you’ve configured qualities in next.config.js, the value must match one of the allowed entries.\n\nGood to know: If the original image is already low quality, setting a high quality value will increase the file size without improving appearance.\n\nstyle\n\nAllows passing CSS styles to the underlying image element.\n\nconst imageStyle = {\n  borderRadius: '50%',\n  border: '1px solid #fff',\n  width: '100px',\n  height: 'auto',\n}\n \nexport default function ProfileImage() {\n  return <Image src=\"...\" style={imageStyle} />\n}\n\nGood to know: If you’re using the style prop to set a custom width, be sure to also set height: 'auto' to preserve the image’s aspect ratio.\n\npreload\n\nA boolean that indicates if the image should be preloaded.\n\n// Default preload is false\n<Image preload={false} />\ntrue: Preloads\n the image by inserting a <link> in the <head>.\nfalse: Does not preload the image.\n\nWhen to use it:\n\nThe image is the Largest Contentful Paint (LCP)\n element.\nThe image is above the fold, typically the hero image.\nYou want to begin loading the image in the <head>, before its discovered later in the <body>.\n\nWhen not to use it:\n\nWhen you have multiple images that could be considered the Largest Contentful Paint (LCP)\n element depending on the viewport.\nWhen the loading property is used.\nWhen the fetchPriority property is used.\n\nIn most cases, you should use loading=\"eager\" or fetchPriority=\"high\" instead of preload.\n\npriority\n\nStarting with Next.js 16, the priority property has been deprecated in favor of the preload property in order to make the behavior clear.\n\nloading\n\nControls when the image should start loading.\n\n// Defaults to lazy\n<Image loading=\"lazy\" />\nlazy: Defer loading the image until it reaches a calculated distance from the viewport.\neager: Load the image immediately, regardless of its position in the page.\n\nUse eager only when you want to ensure the image is loaded immediately.\n\nLearn more about the loading attribute\n.\n\nplaceholder\n\nSpecifies a placeholder to use while the image is loading, improving the perceived loading performance.\n\n// defaults to empty\n<Image placeholder=\"empty\" />\nempty: No placeholder while the image is loading.\nblur: Use a blurred version of the image as a placeholder. Must be used with the blurDataURL property.\ndata:image/...: Uses the Data URL\n as the placeholder.\n\nExamples:\n\nblur placeholder\nShimmer effect with data URL placeholder prop\nColor effect with blurDataURL prop\n\nLearn more about the placeholder attribute\n.\n\nblurDataURL\n\nA Data URL\n to be used as a placeholder image before the image successfully loads. Can be automatically set or used with the placeholder=\"blur\" property.\n\n<Image placeholder=\"blur\" blurDataURL=\"...\" />\n\nThe image is automatically enlarged and blurred, so a very small image (10px or less) is recommended.\n\nAutomatic\n\nIf src is a static import of a jpg, png, webp, or avif file, blurDataURL is added automatically—unless the image is animated.\n\nManually set\n\nIf the image is dynamic or remote, you must provide blurDataURL yourself. To generate one, you can use:\n\nA online tool like png-pixel.com\nA library like Plaiceholder\n\nA large blurDataURL may hurt performance. Keep it small and simple.\n\nExamples:\n\nDefault blurDataURL prop\nColor effect with blurDataURL prop\nonLoad\n\nA callback function that is invoked once the image is completely loaded and the placeholder has been removed.\n\n<Image onLoad={(e) => console.log(e.target.naturalWidth)} />\n\nThe callback function will be called with one argument, the event which has a target that references the underlying <img> element.\n\nGood to know: Using props like onLoad, which accept a function, requires using Client Components\n to serialize the provided function.\n\nonError\n\nA callback function that is invoked if the image fails to load.\n\n<Image onError={(e) => console.error(e.target.id)} />\n\nGood to know: Using props like onError, which accept a function, requires using Client Components\n to serialize the provided function.\n\nunoptimized\n\nA boolean that indicates if the image should be optimized. This is useful for images that do not benefit from optimization such as small images (less than 1KB), vector images (SVG), or animated images (GIF).\n\nimport Image from 'next/image'\n \nconst UnoptimizedImage = (props) => {\n  // Default is false\n  return <Image {...props} unoptimized />\n}\ntrue: The source image will be served as-is from the src instead of changing quality, size, or format.\nfalse: The source image will be optimized.\n\nSince Next.js 12.3.0, this prop can be assigned to all images by updating next.config.js with the following configuration:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    unoptimized: true,\n  },\n}\noverrideSrc\n\nWhen providing the src prop to the <Image> component, both the srcset and src attributes are generated automatically for the resulting <img>.\n\ninput.js\n<Image src=\"/profile.jpg\" />\noutput.html\n<img\n  srcset=\"\n    /_next/image?url=%2Fprofile.jpg&w=640&q=75 1x,\n    /_next/image?url=%2Fprofile.jpg&w=828&q=75 2x\n  \"\n  src=\"/_next/image?url=%2Fprofile.jpg&w=828&q=75\"\n/>\n\nIn some cases, it is not desirable to have the src attribute generated and you may wish to override it using the overrideSrc prop.\n\nFor example, when upgrading an existing website from <img> to <Image>, you may wish to maintain the same src attribute for SEO purposes such as image ranking or avoiding recrawl.\n\ninput.js\n<Image src=\"/profile.jpg\" overrideSrc=\"/override.jpg\" />\noutput.html\n<img\n  srcset=\"\n    /_next/image?url=%2Fprofile.jpg&w=640&q=75 1x,\n    /_next/image?url=%2Fprofile.jpg&w=828&q=75 2x\n  \"\n  src=\"/override.jpg\"\n/>\ndecoding\n\nA hint to the browser indicating if it should wait for the image to be decoded before presenting other content updates or not.\n\n// Default is async\n<Image decoding=\"async\" />\nasync: Asynchronously decode the image and allow other content to be rendered before it completes.\nsync: Synchronously decode the image for atomic presentation with other content.\nauto: No preference. The browser chooses the best approach.\n\nLearn more about the decoding attribute\n.\n\nOther Props\n\nOther properties on the <Image /> component will be passed to the underlying img element with the exception of the following:\n\nsrcSet: Use Device Sizes instead.\nDeprecated props\nonLoadingComplete\n\nWarning: Deprecated in Next.js 14, use onLoad instead.\n\nA callback function that is invoked once the image is completely loaded and the placeholder has been removed.\n\nThe callback function will be called with one argument, a reference to the underlying <img> element.\n\n'use client'\n \n<Image onLoadingComplete={(img) => console.log(img.naturalWidth)} />\n\nGood to know: Using props like onLoadingComplete, which accept a function, requires using Client Components\n to serialize the provided function.\n\nConfiguration options\n\nYou can configure the Image Component in next.config.js. The following options are available:\n\nlocalPatterns\n\nUse localPatterns in your next.config.js file to allow images from specific local paths to be optimized and block all others.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    localPatterns: [\n      {\n        pathname: '/assets/images/**',\n        search: '',\n      },\n    ],\n  },\n}\n\nThe example above will ensure the src property of next/image must start with /assets/images/ and must not have a query string. Attempting to optimize any other path will respond with 400 Bad Request error.\n\nGood to know: Omitting the search property allows all search parameters which could allow malicious actors to optimize URLs you did not intend. Try using a specific value like search: '?v=2' to ensure an exact match.\n\nremotePatterns\n\nUse remotePatterns in your next.config.js file to allow images from specific external paths and block all others. This ensures that only external images from your account can be served.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    remotePatterns: [new URL('https://example.com/account123/**')],\n  },\n}\n\nYou can also configure remotePatterns using the object:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: 'example.com',\n        port: '',\n        pathname: '/account123/**',\n        search: '',\n      },\n    ],\n  },\n}\n\nThe example above will ensure the src property of next/image must start with https://example.com/account123/ and must not have a query string. Any other protocol, hostname, port, or unmatched path will respond with 400 Bad Request.\n\nWildcard Patterns:\n\nWildcard patterns can be used for both pathname and hostname and have the following syntax:\n\n* match a single path segment or subdomain\n** match any number of path segments at the end or subdomains at the beginning. This syntax does not work in the middle of the pattern.\nnext.config.js\nmodule.exports = {\n  images: {\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: '**.example.com',\n        port: '',\n        search: '',\n      },\n    ],\n  },\n}\n\nThis allows subdomains like image.example.com. Query strings and custom ports are still blocked.\n\nGood to know: When omitting protocol, port, pathname, or search then the wildcard ** is implied. This is not recommended because it may allow malicious actors to optimize urls you did not intend.\n\nQuery Strings:\n\nYou can also restrict query strings using the search property:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: 'assets.example.com',\n        search: '?v=1727111025337',\n      },\n    ],\n  },\n}\n\nThe example above will ensure the src property of next/image must start with https://assets.example.com and must have the exact query string ?v=1727111025337. Any other protocol or query string will respond with 400 Bad Request.\n\nloaderFile\n\nloaderFiles allows you to use a custom image optimization service instead of Next.js.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    loader: 'custom',\n    loaderFile: './my/image/loader.js',\n  },\n}\n\nThe path must be relative to the project root. The file must export a default function that returns a URL string:\n\nmy/image/loader.js\n'use client'\n \nexport default function myImageLoader({ src, width, quality }) {\n  return `https://example.com/${src}?w=${width}&q=${quality || 75}`\n}\n\nExample:\n\nCustom Image Loader Configuration\n\nAlternatively, you can use the loader prop to configure each instance of next/image.\n\npath\n\nIf you want to change or prefix the default path for the Image Optimization API, you can do so with the path property. The default value for path is /_next/image.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    path: '/my-prefix/_next/image',\n  },\n}\ndeviceSizes\n\ndeviceSizes allows you to specify a list of device width breakpoints. These widths are used when the next/image component uses sizes prop to ensure the correct image is served for the user's device.\n\nIf no configuration is provided, the default below is used:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840],\n  },\n}\nimageSizes\n\nimageSizes allows you to specify a list of image widths. These widths are concatenated with the array of device sizes to form the full array of sizes used to generate image srcset\n.\n\nIf no configuration is provided, the default below is used:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    imageSizes: [32, 48, 64, 96, 128, 256, 384],\n  },\n}\n\nimageSizes is only used for images which provide a sizes prop, which indicates that the image is less than the full width of the screen. Therefore, the sizes in imageSizes should all be smaller than the smallest size in deviceSizes.\n\nqualities\n\nqualities allows you to specify a list of image quality values.\n\nIf not configuration is provided, the default below is used:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    qualities: [75],\n  },\n}\n\nGood to know: This field is required starting with Next.js 16 because unrestricted access could allow malicious actors to optimize more qualities than you intended.\n\nYou can add more image qualities to the allowlist, such as the following:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    qualities: [25, 50, 75, 100],\n  },\n}\n\nIn the example above, only four qualities are allowed: 25, 50, 75, and 100.\n\nIf the quality prop does not match a value in this array, the closest allowed value will be used.\n\nIf the REST API is visited directly with a quality that does not match a value in this array, the server will return a 400 Bad Request response.\n\nformats\n\nformats allows you to specify a list of image formats to be used.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    // Default\n    formats: ['image/webp'],\n  },\n}\n\nNext.js automatically detects the browser's supported image formats via the request's Accept header in order to determine the best output format.\n\nIf the Accept header matches more than one of the configured formats, the first match in the array is used. Therefore, the array order matters. If there is no match (or the source image is animated), it will use the original image's format.\n\nYou can enable AVIF support, which will fallback to the original format of the src image if the browser does not support AVIF\n:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    formats: ['image/avif'],\n  },\n}\n\nGood to know:\n\nWe still recommend using WebP for most use cases.\nAVIF generally takes 50% longer to encode but it compresses 20% smaller compared to WebP. This means that the first time an image is requested, it will typically be slower, but subsequent requests that are cached will be faster.\nIf you self-host with a Proxy/CDN in front of Next.js, you must configure the Proxy to forward the Accept header.\nminimumCacheTTL\n\nminimumCacheTTL allows you to configure the Time to Live (TTL) in seconds for cached optimized images. In many cases, it's better to use a Static Image Import which will automatically hash the file contents and cache the image forever with a Cache-Control header of immutable.\n\nIf no configuration is provided, the default below is used.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    minimumCacheTTL: 14400, // 4 hours\n  },\n}\n\nYou can increase the TTL to reduce the number of revalidations and potentially lower cost:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    minimumCacheTTL: 2678400, // 31 days\n  },\n}\n\nThe expiration (or rather Max Age) of the optimized image is defined by either the minimumCacheTTL or the upstream image Cache-Control header, whichever is larger.\n\nIf you need to change the caching behavior per image, you can configure headers to set the Cache-Control header on the upstream image (e.g. /some-asset.jpg, not /_next/image itself).\n\nThere is no mechanism to invalidate the cache at this time, so its best to keep minimumCacheTTL low. Otherwise you may need to manually change the src prop or delete the cached file <distDir>/cache/images.\n\ndisableStaticImages\n\ndisableStaticImages allows you to disable static image imports.\n\nThe default behavior allows you to import static files such as import icon from './icon.png' and then pass that to the src property. In some cases, you may wish to disable this feature if it conflicts with other plugins that expect the import to behave differently.\n\nYou can disable static image imports inside your next.config.js:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    disableStaticImages: true,\n  },\n}\nmaximumRedirects\n\nThe default image optimization loader will follow HTTP redirects when fetching remote images up to 3 times.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    maximumRedirects: 3,\n  },\n}\n\nYou can configure the number of redirects to follow when fetching remote images. Setting the value to 0 will disable following redirects.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    maximumRedirects: 0,\n  },\n}\ndangerouslyAllowLocalIP\n\nIn rare cases when self-hosting Next.js on a private network, you may want to allow optimizing images from local IP addresses on the same network. This is not recommended for most users because it could allow malicious users to access content on your internal network.\n\nBy default, the value is false.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    dangerouslyAllowLocalIP: false,\n  },\n}\n\nIf you need to optimize remote images hosted elsewhere in your local network, you can set the value to true.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    dangerouslyAllowLocalIP: true,\n  },\n}\ndangerouslyAllowSVG\n\ndangerouslyAllowSVG allows you to serve SVG images.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    dangerouslyAllowSVG: true,\n  },\n}\n\nBy default, Next.js does not optimize SVG images for a few reasons:\n\nSVG is a vector format meaning it can be resized losslessly.\nSVG has many of the same features as HTML/CSS, which can lead to vulnerabilities without proper Content Security Policy (CSP) headers.\n\nWe recommend using the unoptimized prop when the src prop is known to be SVG. This happens automatically when src ends with \".svg\".\n\n<Image src=\"/my-image.svg\" unoptimized />\n\nIn addition, it is strongly recommended to also set contentDispositionType to force the browser to download the image, as well as contentSecurityPolicy to prevent scripts embedded in the image from executing.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    dangerouslyAllowSVG: true,\n    contentDispositionType: 'attachment',\n    contentSecurityPolicy: \"default-src 'self'; script-src 'none'; sandbox;\",\n  },\n}\ncontentDispositionType\n\ncontentDispositionType allows you to configure the Content-Disposition\n header.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    contentDispositionType: 'inline',\n  },\n}\ncontentSecurityPolicy\n\ncontentSecurityPolicy allows you to configure the Content-Security-Policy\n header for images. This is particularly important when using dangerouslyAllowSVG to prevent scripts embedded in the image from executing.\n\nnext.config.js\nmodule.exports = {\n  images: {\n    contentSecurityPolicy: \"default-src 'self'; script-src 'none'; sandbox;\",\n  },\n}\n\nBy default, the loader sets the Content-Disposition\n header to attachment for added protection since the API can serve arbitrary remote images.\n\nThe default value is attachment which forces the browser to download the image when visiting directly. This is particularly important when dangerouslyAllowSVG is true.\n\nYou can optionally configure inline to allow the browser to render the image when visiting directly, without downloading it.\n\nDeprecated configuration options\ndomains\n\nWarning: Deprecated since Next.js 14 in favor of strict remotePatterns in order to protect your application from malicious users.\n\nSimilar to remotePatterns, the domains configuration can be used to provide a list of allowed hostnames for external images. However, the domains configuration does not support wildcard pattern matching and it cannot restrict protocol, port, or pathname.\n\nSince most remote image servers are shared between multiple tenants, it's safer to use remotePatterns to ensure only the intended images are optimized.\n\nBelow is an example of the domains property in the next.config.js file:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    domains: ['assets.acme.com'],\n  },\n}\nFunctions\ngetImageProps\n\nThe getImageProps function can be used to get the props that would be passed to the underlying <img> element, and instead pass them to another component, style, canvas, etc.\n\nimport { getImageProps } from 'next/image'\n \nconst { props } = getImageProps({\n  src: 'https://example.com/image.jpg',\n  alt: 'A scenic mountain view',\n  width: 1200,\n  height: 800,\n})\n \nfunction ImageWithCaption() {\n  return (\n    <figure>\n      <img {...props} />\n      <figcaption>A scenic mountain view</figcaption>\n    </figure>\n  )\n}\n\nThis also avoid calling React useState() so it can lead to better performance, but it cannot be used with the placeholder prop because the placeholder will never be removed.\n\nKnown browser bugs\n\nThis next/image component uses browser native lazy loading\n, which may fallback to eager loading for older browsers before Safari 15.4. When using the blur-up placeholder, older browsers before Safari 12 will fallback to empty placeholder. When using styles with width/height of auto, it is possible to cause Layout Shift\n on older browsers before Safari 15 that don't preserve the aspect ratio\n. For more details, see this MDN video\n.\n\nSafari 15 - 16.3\n display a gray border while loading. Safari 16.4 fixed this issue\n. Possible solutions:\nUse CSS @supports (font: -apple-system-body) and (-webkit-appearance: none) { img[loading=\"lazy\"] { clip-path: inset(0.6px) } }\nUse loading=\"eager\" if the image is above the fold\nFirefox 67+\n displays a white background while loading. Possible solutions:\nEnable AVIF formats\nUse placeholder\nExamples\nStyling images\n\nStyling the Image component is similar to styling a normal <img> element, but there are a few guidelines to keep in mind:\n\nUse className or style, not styled-jsx. In most cases, we recommend using the className prop. This can be an imported CSS Module, a global stylesheet, etc.\n\nimport styles from './styles.module.css'\n \nexport default function MyImage() {\n  return <Image className={styles.image} src=\"/my-image.png\" alt=\"My Image\" />\n}\n\nYou can also use the style prop to assign inline styles.\n\nexport default function MyImage() {\n  return (\n    <Image style={{ borderRadius: '8px' }} src=\"/my-image.png\" alt=\"My Image\" />\n  )\n}\n\nWhen using fill, the parent element must have position: relative or display: block. This is necessary for the proper rendering of the image element in that layout mode.\n\n<div style={{ position: 'relative' }}>\n  <Image fill src=\"/my-image.png\" alt=\"My Image\" />\n</div>\n\nYou cannot use styled-jsx because it's scoped to the current component (unless you mark the style as global).\n\nResponsive images with a static export\n\nWhen you import a static image, Next.js automatically sets its width and height based on the file. You can make the image responsive by setting the style:\n\nimport Image from 'next/image'\nimport mountains from '../public/mountains.jpg'\n \nexport default function Responsive() {\n  return (\n    <div style={{ display: 'flex', flexDirection: 'column' }}>\n      <Image\n        alt=\"Mountains\"\n        // Importing an image will\n        // automatically set the width and height\n        src={mountains}\n        sizes=\"100vw\"\n        // Make the image display full width\n        // and preserve its aspect ratio\n        style={{\n          width: '100%',\n          height: 'auto',\n        }}\n      />\n    </div>\n  )\n}\nResponsive images with a remote URL\n\nIf the source image is a dynamic or a remote URL, you must provide the width and height props so Next.js can calculate the aspect ratio:\n\ncomponents/page.js\nimport Image from 'next/image'\n \nexport default function Page({ photoUrl }) {\n  return (\n    <Image\n      src={photoUrl}\n      alt=\"Picture of the author\"\n      sizes=\"100vw\"\n      style={{\n        width: '100%',\n        height: 'auto',\n      }}\n      width={500}\n      height={300}\n    />\n  )\n}\n\nTry it out:\n\nDemo the image responsive to viewport\nResponsive image with fill\n\nIf you don't know the aspect ratio of the image, you can add the fill prop with the objectFit prop set to cover. This will make the image fill the full width of its parent container.\n\nimport Image from 'next/image'\nimport mountains from '../public/mountains.jpg'\n \nexport default function Fill() {\n  return (\n    <div\n      style={{\n        display: 'grid',\n        gridGap: '8px',\n        gridTemplateColumns: 'repeat(auto-fit, minmax(400px, auto))',\n      }}\n    >\n      <div style={{ position: 'relative', width: '400px' }}>\n        <Image\n          alt=\"Mountains\"\n          src={mountains}\n          fill\n          sizes=\"(min-width: 808px) 50vw, 100vw\"\n          style={{\n            objectFit: 'cover', // cover, contain, none\n          }}\n        />\n      </div>\n      {/* And more images in the grid... */}\n    </div>\n  )\n}\nBackground Image\n\nUse the fill prop to make the image cover the entire screen area:\n\nimport Image from 'next/image'\nimport mountains from '../public/mountains.jpg'\n \nexport default function Background() {\n  return (\n    <Image\n      alt=\"Mountains\"\n      src={mountains}\n      placeholder=\"blur\"\n      quality={100}\n      fill\n      sizes=\"100vw\"\n      style={{\n        objectFit: 'cover',\n      }}\n    />\n  )\n}\n\nFor examples of the Image component used with the various styles, see the Image Component Demo\n.\n\nRemote images\n\nTo use a remote image, the src property should be a URL string.\n\napp/page.js\nimport Image from 'next/image'\n \nexport default function Page() {\n  return (\n    <Image\n      src=\"https://s3.amazonaws.com/my-bucket/profile.png\"\n      alt=\"Picture of the author\"\n      width={500}\n      height={500}\n    />\n  )\n}\n\nSince Next.js does not have access to remote files during the build process, you'll need to provide the width, height and optional blurDataURL props manually.\n\nThe width and height attributes are used to infer the correct aspect ratio of image and avoid layout shift from the image loading in. The width and height do not determine the rendered size of the image file.\n\nTo safely allow optimizing images, define a list of supported URL patterns in next.config.js. Be as specific as possible to prevent malicious usage. For example, the following configuration will only allow images from a specific AWS S3 bucket:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: 's3.amazonaws.com',\n        port: '',\n        pathname: '/my-bucket/**',\n        search: '',\n      },\n    ],\n  },\n}\nTheme detection\n\nIf you want to display a different image for light and dark mode, you can create a new component that wraps two <Image> components and reveals the correct one based on a CSS media query.\n\ncomponents/theme-image.module.css\n.imgDark {\n  display: none;\n}\n \n@media (prefers-color-scheme: dark) {\n  .imgLight {\n    display: none;\n  }\n  .imgDark {\n    display: unset;\n  }\n}\ncomponents/theme-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport styles from './theme-image.module.css'\nimport Image, { ImageProps } from 'next/image'\n \ntype Props = Omit<ImageProps, 'src' | 'preload' | 'loading'> & {\n  srcLight: string\n  srcDark: string\n}\n \nconst ThemeImage = (props: Props) => {\n  const { srcLight, srcDark, ...rest } = props\n \n  return (\n    <>\n      <Image {...rest} src={srcLight} className={styles.imgLight} />\n      <Image {...rest} src={srcDark} className={styles.imgDark} />\n    </>\n  )\n}\n\nGood to know: The default behavior of loading=\"lazy\" ensures that only the correct image is loaded. You cannot use preload or loading=\"eager\" because that would cause both images to load. Instead, you can use fetchPriority=\"high\"\n.\n\nTry it out:\n\nDemo light/dark mode theme detection\nArt direction\n\nIf you want to display a different image for mobile and desktop, sometimes called Art Direction\n, you can provide different src, width, height, and quality props to getImageProps().\n\napp/page.js\nimport { getImageProps } from 'next/image'\n \nexport default function Home() {\n  const common = { alt: 'Art Direction Example', sizes: '100vw' }\n  const {\n    props: { srcSet: desktop },\n  } = getImageProps({\n    ...common,\n    width: 1440,\n    height: 875,\n    quality: 80,\n    src: '/desktop.jpg',\n  })\n  const {\n    props: { srcSet: mobile, ...rest },\n  } = getImageProps({\n    ...common,\n    width: 750,\n    height: 1334,\n    quality: 70,\n    src: '/mobile.jpg',\n  })\n \n  return (\n    <picture>\n      <source media=\"(min-width: 1000px)\" srcSet={desktop} />\n      <source media=\"(min-width: 500px)\" srcSet={mobile} />\n      <img {...rest} style={{ width: '100%', height: 'auto' }} />\n    </picture>\n  )\n}\nBackground CSS\n\nYou can even convert the srcSet string to the image-set()\n CSS function to optimize a background image.\n\napp/page.js\nimport { getImageProps } from 'next/image'\n \nfunction getBackgroundImage(srcSet = '') {\n  const imageSet = srcSet\n    .split(', ')\n    .map((str) => {\n      const [url, dpi] = str.split(' ')\n      return `url(\"${url}\") ${dpi}`\n    })\n    .join(', ')\n  return `image-set(${imageSet})`\n}\n \nexport default function Home() {\n  const {\n    props: { srcSet },\n  } = getImageProps({ alt: '', width: 128, height: 128, src: '/img.png' })\n  const backgroundImage = getBackgroundImage(srcSet)\n  const style = { height: '100vh', width: '100vw', backgroundImage }\n \n  return (\n    <main style={style}>\n      <h1>Hello World</h1>\n    </main>\n  )\n}\nVersion History\nVersion\tChanges\nv16.0.0\tqualities default configuration changed to [75], preload prop added, priority prop deprecated, dangerouslyAllowLocalIP config added, maximumRedirects config added.\nv15.3.0\tremotePatterns added support for array of URL objects.\nv15.0.0\tcontentDispositionType configuration default changed to attachment.\nv14.2.23\tqualities configuration added.\nv14.2.15\tdecoding prop added and localPatterns configuration added.\nv14.2.14\tremotePatterns.search prop added.\nv14.2.0\toverrideSrc prop added.\nv14.1.0\tgetImageProps() is stable.\nv14.0.0\tonLoadingComplete prop and domains config deprecated.\nv13.4.14\tplaceholder prop support for data:/image...\nv13.2.0\tcontentDispositionType configuration added.\nv13.0.6\tref prop added.\nv13.0.0\tThe next/image import was renamed to next/legacy/image. The next/future/image import was renamed to next/image. A codemod is available to safely and automatically rename your imports. <span> wrapper removed. layout, objectFit, objectPosition, lazyBoundary, lazyRoot props removed. alt is required. onLoadingComplete receives reference to img element. Built-in loader config removed.\nv12.3.0\tremotePatterns and unoptimized configuration is stable.\nv12.2.0\tExperimental remotePatterns and experimental unoptimized configuration added. layout=\"raw\" removed.\nv12.1.1\tstyle prop added. Experimental support for layout=\"raw\" added.\nv12.1.0\tdangerouslyAllowSVG and contentSecurityPolicy configuration added.\nv12.0.9\tlazyRoot prop added.\nv12.0.0\tformats configuration added.\nAVIF support added.\nWrapper <div> changed to <span>.\nv11.1.0\tonLoadingComplete and lazyBoundary props added.\nv11.0.0\tsrc prop support for static import.\nplaceholder prop added.\nblurDataURL prop added.\nv10.0.5\tloader prop added.\nv10.0.1\tlayout prop added.\nv10.0.0\tnext/image introduced.\nPrevious\nForm Component\nNext\nLink Component\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Components: Link Component | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/components/link",
    "html": "API Reference\nComponents\nLink Component\nCopy page\nLink Component\n\n<Link> is a React component that extends the HTML <a> element to provide prefetching and client-side navigation between routes. It is the primary way to navigate between routes in Next.js.\n\nBasic usage:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Page() {\n  return <Link href=\"/dashboard\">Dashboard</Link>\n}\nReference\n\nThe following props can be passed to the <Link> component:\n\nProp\tExample\tType\tRequired\nhref\thref=\"/dashboard\"\tString or Object\tYes\nreplace\treplace={false}\tBoolean\t-\nscroll\tscroll={false}\tBoolean\t-\nprefetch\tprefetch={false}\tBoolean or null\t-\nonNavigate\tonNavigate={(e) => {}}\tFunction\t-\n\nGood to know: <a> tag attributes such as className or target=\"_blank\" can be added to <Link> as props and will be passed to the underlying <a> element.\n\nhref (required)\n\nThe path or URL to navigate to.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \n// Navigate to /about?name=test\nexport default function Page() {\n  return (\n    <Link\n      href={{\n        pathname: '/about',\n        query: { name: 'test' },\n      }}\n    >\n      About\n    </Link>\n  )\n}\nreplace\n\nDefaults to false. When true, next/link will replace the current history state instead of adding a new URL into the browser's history\n stack.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Page() {\n  return (\n    <Link href=\"/dashboard\" replace>\n      Dashboard\n    </Link>\n  )\n}\nscroll\n\nDefaults to true. The default scrolling behavior of <Link> in Next.js is to maintain scroll position, similar to how browsers handle back and forwards navigation. When you navigate to a new Page, scroll position will stay the same as long as the Page is visible in the viewport. However, if the Page is not visible in the viewport, Next.js will scroll to the top of the first Page element.\n\nWhen scroll = {false}, Next.js will not attempt to scroll to the first Page element.\n\nGood to know: Next.js checks if scroll: false before managing scroll behavior. If scrolling is enabled, it identifies the relevant DOM node for navigation and inspects each top-level element. All non-scrollable elements and those without rendered HTML are bypassed, this includes sticky or fixed positioned elements, and non-visible elements such as those calculated with getBoundingClientRect. Next.js then continues through siblings until it identifies a scrollable element that is visible in the viewport.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Page() {\n  return (\n    <Link href=\"/dashboard\" scroll={false}>\n      Dashboard\n    </Link>\n  )\n}\nprefetch\n\nPrefetching happens when a <Link /> component enters the user's viewport (initially or through scroll). Next.js prefetches and loads the linked route (denoted by the href) and its data in the background to improve the performance of client-side navigations. If the prefetched data has expired by the time the user hovers over a <Link />, Next.js will attempt to prefetch it again. Prefetching is only enabled in production.\n\nThe following values can be passed to the prefetch prop:\n\n\"auto\" or null (default): Prefetch behavior depends on whether the route is static or dynamic. For static routes, the full route will be prefetched (including all its data). For dynamic routes, the partial route down to the nearest segment with a loading.js boundary will be prefetched.\ntrue: The full route will be prefetched for both static and dynamic routes.\nfalse: Prefetching will never happen both on entering the viewport and on hover.\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Page() {\n  return (\n    <Link href=\"/dashboard\" prefetch={false}>\n      Dashboard\n    </Link>\n  )\n}\nonNavigate\n\nAn event handler called during client-side navigation. The handler receives an event object that includes a preventDefault() method, allowing you to cancel the navigation if needed.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Page() {\n  return (\n    <Link\n      href=\"/dashboard\"\n      onNavigate={(e) => {\n        // Only executes during SPA navigation\n        console.log('Navigating...')\n \n        // Optionally prevent navigation\n        // e.preventDefault()\n      }}\n    >\n      Dashboard\n    </Link>\n  )\n}\n\nGood to know: While onClick and onNavigate may seem similar, they serve different purposes. onClick executes for all click events, while onNavigate only runs during client-side navigation. Some key differences:\n\nWhen using modifier keys (Ctrl/Cmd + Click), onClick executes but onNavigate doesn't since Next.js prevents default navigation for new tabs.\nExternal URLs won't trigger onNavigate since it's only for client-side and same-origin navigations.\nLinks with the download attribute will work with onClick but not onNavigate since the browser will treat the linked URL as a download.\nExamples\n\nThe following examples demonstrate how to use the <Link> component in different scenarios.\n\nLinking to dynamic route segments\n\nWhen linking to dynamic segments, you can use template literals and interpolation\n to generate a list of links. For example, to generate a list of blog posts:\n\napp/blog/post-list.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \ninterface Post {\n  id: number\n  title: string\n  slug: string\n}\n \nexport default function PostList({ posts }: { posts: Post[] }) {\n  return (\n    <ul>\n      {posts.map((post) => (\n        <li key={post.id}>\n          <Link href={`/blog/${post.slug}`}>{post.title}</Link>\n        </li>\n      ))}\n    </ul>\n  )\n}\nChecking active links\n\nYou can use usePathname() to determine if a link is active. For example, to add a class to the active link, you can check if the current pathname matches the href of the link:\n\napp/ui/nav-links.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { usePathname } from 'next/navigation'\nimport Link from 'next/link'\n \nexport function Links() {\n  const pathname = usePathname()\n \n  return (\n    <nav>\n      <Link className={`link ${pathname === '/' ? 'active' : ''}`} href=\"/\">\n        Home\n      </Link>\n \n      <Link\n        className={`link ${pathname === '/about' ? 'active' : ''}`}\n        href=\"/about\"\n      >\n        About\n      </Link>\n    </nav>\n  )\n}\nScrolling to an id\n\nIf you'd like to scroll to a specific id on navigation, you can append your URL with a # hash link or just pass a hash link to the href prop. This is possible since <Link> renders to an <a> element.\n\n<Link href=\"/dashboard#settings\">Settings</Link>\n \n// Output\n<a href=\"/dashboard#settings\">Settings</a>\n\nGood to know:\n\nNext.js will scroll to the Page if it is not visible in the viewport upon navigation.\nReplace the URL instead of push\n\nThe default behavior of the Link component is to push a new URL into the history stack. You can use the replace prop to prevent adding a new entry, as in the following example:\n\napp/page.js\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Page() {\n  return (\n    <Link href=\"/about\" replace>\n      About us\n    </Link>\n  )\n}\nDisable scrolling to the top of the page\n\nThe default scrolling behavior of <Link> in Next.js is to maintain scroll position, similar to how browsers handle back and forwards navigation. When you navigate to a new Page, scroll position will stay the same as long as the Page is visible in the viewport.\n\nHowever, if the Page is not visible in the viewport, Next.js will scroll to the top of the first Page element. If you'd like to disable this behavior, you can pass scroll={false} to the <Link> component, or scroll: false to router.push() or router.replace().\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Page() {\n  return (\n    <Link href=\"/#hashid\" scroll={false}>\n      Disables scrolling to the top\n    </Link>\n  )\n}\n\nUsing router.push() or router.replace():\n\n// useRouter\nimport { useRouter } from 'next/navigation'\n \nconst router = useRouter()\n \nrouter.push('/dashboard', { scroll: false })\nPrefetching links in Proxy\n\nIt's common to use Proxy for authentication or other purposes that involve rewriting the user to a different page. In order for the <Link /> component to properly prefetch links with rewrites via Proxy, you need to tell Next.js both the URL to display and the URL to prefetch. This is required to avoid un-necessary fetches to proxy to know the correct route to prefetch.\n\nFor example, if you want to serve a /dashboard route that has authenticated and visitor views, you can add the following in your Proxy to redirect the user to the correct page:\n\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse } from 'next/server'\n \nexport function proxy(request: Request) {\n  const nextUrl = request.nextUrl\n  if (nextUrl.pathname === '/dashboard') {\n    if (request.cookies.authToken) {\n      return NextResponse.rewrite(new URL('/auth/dashboard', request.url))\n    } else {\n      return NextResponse.rewrite(new URL('/public/dashboard', request.url))\n    }\n  }\n}\n\nIn this case, you would want to use the following code in your <Link /> component:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Link from 'next/link'\nimport useIsAuthed from './hooks/useIsAuthed' // Your auth hook\n \nexport default function Page() {\n  const isAuthed = useIsAuthed()\n  const path = isAuthed ? '/auth/dashboard' : '/public/dashboard'\n  return (\n    <Link as=\"/dashboard\" href={path}>\n      Dashboard\n    </Link>\n  )\n}\nBlocking navigation\n\nYou can use the onNavigate prop to block navigation when certain conditions are met, such as when a form has unsaved changes. When you need to block navigation across multiple components in your app (like preventing navigation from any link while a form is being edited), React Context provides a clean way to share this blocking state. First, create a context to track the navigation blocking state:\n\napp/contexts/navigation-blocker.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { createContext, useState, useContext } from 'react'\n \ninterface NavigationBlockerContextType {\n  isBlocked: boolean\n  setIsBlocked: (isBlocked: boolean) => void\n}\n \nexport const NavigationBlockerContext =\n  createContext<NavigationBlockerContextType>({\n    isBlocked: false,\n    setIsBlocked: () => {},\n  })\n \nexport function NavigationBlockerProvider({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  const [isBlocked, setIsBlocked] = useState(false)\n \n  return (\n    <NavigationBlockerContext.Provider value={{ isBlocked, setIsBlocked }}>\n      {children}\n    </NavigationBlockerContext.Provider>\n  )\n}\n \nexport function useNavigationBlocker() {\n  return useContext(NavigationBlockerContext)\n}\n\nCreate a form component that uses the context:\n\napp/components/form.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useNavigationBlocker } from '../contexts/navigation-blocker'\n \nexport default function Form() {\n  const { setIsBlocked } = useNavigationBlocker()\n \n  return (\n    <form\n      onSubmit={(e) => {\n        e.preventDefault()\n        setIsBlocked(false)\n      }}\n      onChange={() => setIsBlocked(true)}\n    >\n      <input type=\"text\" name=\"name\" />\n      <button type=\"submit\">Save</button>\n    </form>\n  )\n}\n\nCreate a custom Link component that blocks navigation:\n\napp/components/custom-link.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Link from 'next/link'\nimport { useNavigationBlocker } from '../contexts/navigation-blocker'\n \ninterface CustomLinkProps extends React.ComponentProps<typeof Link> {\n  children: React.ReactNode\n}\n \nexport function CustomLink({ children, ...props }: CustomLinkProps) {\n  const { isBlocked } = useNavigationBlocker()\n \n  return (\n    <Link\n      onNavigate={(e) => {\n        if (\n          isBlocked &&\n          !window.confirm('You have unsaved changes. Leave anyway?')\n        ) {\n          e.preventDefault()\n        }\n      }}\n      {...props}\n    >\n      {children}\n    </Link>\n  )\n}\n\nCreate a navigation component:\n\napp/components/nav.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { CustomLink as Link } from './custom-link'\n \nexport default function Nav() {\n  return (\n    <nav>\n      <Link href=\"/\">Home</Link>\n      <Link href=\"/about\">About</Link>\n    </nav>\n  )\n}\n\nFinally, wrap your app with the NavigationBlockerProvider in the root layout and use the components in your page:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { NavigationBlockerProvider } from './contexts/navigation-blocker'\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body>\n        <NavigationBlockerProvider>{children}</NavigationBlockerProvider>\n      </body>\n    </html>\n  )\n}\n\nThen, use the Nav and Form components in your page:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Nav from './components/nav'\nimport Form from './components/form'\n \nexport default function Page() {\n  return (\n    <div>\n      <Nav />\n      <main>\n        <h1>Welcome to the Dashboard</h1>\n        <Form />\n      </main>\n    </div>\n  )\n}\n\nWhen a user tries to navigate away using CustomLink while the form has unsaved changes, they'll be prompted to confirm before leaving.\n\nVersion history\nVersion\tChanges\nv15.4.0\tAdd auto as an alias to the default prefetch behavior.\nv15.3.0\tAdd onNavigate API\nv13.0.0\tNo longer requires a child <a> tag. A codemod is provided to automatically update your codebase.\nv10.0.0\thref props pointing to a dynamic route are automatically resolved and no longer require an as prop.\nv8.0.0\tImproved prefetching performance.\nv1.0.0\tnext/link introduced.\nPrevious\nImage Component\nNext\nScript Component\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Components: Script Component | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/components/script",
    "html": "API Reference\nComponents\nScript Component\nCopy page\nScript Component\n\nThis API reference will help you understand how to use props available for the Script Component. For features and usage, please see the Optimizing Scripts page.\n\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Script from 'next/script'\n \nexport default function Dashboard() {\n  return (\n    <>\n      <Script src=\"https://example.com/script.js\" />\n    </>\n  )\n}\nProps\n\nHere's a summary of the props available for the Script Component:\n\nProp\tExample\tType\tRequired\nsrc\tsrc=\"http://example.com/script\"\tString\tRequired unless inline script is used\nstrategy\tstrategy=\"lazyOnload\"\tString\t-\nonLoad\tonLoad={onLoadFunc}\tFunction\t-\nonReady\tonReady={onReadyFunc}\tFunction\t-\nonError\tonError={onErrorFunc}\tFunction\t-\nRequired Props\n\nThe <Script /> component requires the following properties.\n\nsrc\n\nA path string specifying the URL of an external script. This can be either an absolute external URL or an internal path. The src property is required unless an inline script is used.\n\nOptional Props\n\nThe <Script /> component accepts a number of additional properties beyond those which are required.\n\nstrategy\n\nThe loading strategy of the script. There are four different strategies that can be used:\n\nbeforeInteractive: Load before any Next.js code and before any page hydration occurs.\nafterInteractive: (default) Load early but after some hydration on the page occurs.\nlazyOnload: Load during browser idle time.\nworker: (experimental) Load in a web worker.\nbeforeInteractive\n\nScripts that load with the beforeInteractive strategy are injected into the initial HTML from the server, downloaded before any Next.js module, and executed in the order they are placed.\n\nScripts denoted with this strategy are preloaded and fetched before any first-party code, but their execution does not block page hydration from occurring.\n\nbeforeInteractive scripts must be placed inside the root layout (app/layout.tsx) and are designed to load scripts that are needed by the entire site (i.e. the script will load when any page in the application has been loaded server-side).\n\nThis strategy should only be used for critical scripts that need to be fetched as soon as possible.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Script from 'next/script'\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body>\n        {children}\n        <Script\n          src=\"https://example.com/script.js\"\n          strategy=\"beforeInteractive\"\n        />\n      </body>\n    </html>\n  )\n}\n\nGood to know: Scripts with beforeInteractive will always be injected inside the head of the HTML document regardless of where it's placed in the component.\n\nSome examples of scripts that should be fetched as soon as possible with beforeInteractive include:\n\nBot detectors\nCookie consent managers\nafterInteractive\n\nScripts that use the afterInteractive strategy are injected into the HTML client-side and will load after some (or all) hydration occurs on the page. This is the default strategy of the Script component and should be used for any script that needs to load as soon as possible but not before any first-party Next.js code.\n\nafterInteractive scripts can be placed inside of any page or layout and will only load and execute when that page (or group of pages) is opened in the browser.\n\napp/page.js\nimport Script from 'next/script'\n \nexport default function Page() {\n  return (\n    <>\n      <Script src=\"https://example.com/script.js\" strategy=\"afterInteractive\" />\n    </>\n  )\n}\n\nSome examples of scripts that are good candidates for afterInteractive include:\n\nTag managers\nAnalytics\nlazyOnload\n\nScripts that use the lazyOnload strategy are injected into the HTML client-side during browser idle time and will load after all resources on the page have been fetched. This strategy should be used for any background or low priority scripts that do not need to load early.\n\nlazyOnload scripts can be placed inside of any page or layout and will only load and execute when that page (or group of pages) is opened in the browser.\n\napp/page.js\nimport Script from 'next/script'\n \nexport default function Page() {\n  return (\n    <>\n      <Script src=\"https://example.com/script.js\" strategy=\"lazyOnload\" />\n    </>\n  )\n}\n\nExamples of scripts that do not need to load immediately and can be fetched with lazyOnload include:\n\nChat support plugins\nSocial media widgets\nworker\n\nWarning: The worker strategy is not yet stable and does not yet work with the App Router. Use with caution.\n\nScripts that use the worker strategy are off-loaded to a web worker in order to free up the main thread and ensure that only critical, first-party resources are processed on it. While this strategy can be used for any script, it is an advanced use case that is not guaranteed to support all third-party scripts.\n\nTo use worker as a strategy, the nextScriptWorkers flag must be enabled in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  experimental: {\n    nextScriptWorkers: true,\n  },\n}\n\nworker scripts can only currently be used in the pages/ directory:\n\npages/home.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Script from 'next/script'\n \nexport default function Home() {\n  return (\n    <>\n      <Script src=\"https://example.com/script.js\" strategy=\"worker\" />\n    </>\n  )\n}\nonLoad\n\nWarning: onLoad does not yet work with Server Components and can only be used in Client Components. Further, onLoad can't be used with beforeInteractive – consider using onReady instead.\n\nSome third-party scripts require users to run JavaScript code once after the script has finished loading in order to instantiate content or call a function. If you are loading a script with either afterInteractive or lazyOnload as a loading strategy, you can execute code after it has loaded using the onLoad property.\n\nHere's an example of executing a lodash method only after the library has been loaded.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Script from 'next/script'\n \nexport default function Page() {\n  return (\n    <>\n      <Script\n        src=\"https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.20/lodash.min.js\"\n        onLoad={() => {\n          console.log(_.sample([1, 2, 3, 4]))\n        }}\n      />\n    </>\n  )\n}\nonReady\n\nWarning: onReady does not yet work with Server Components and can only be used in Client Components.\n\nSome third-party scripts require users to run JavaScript code after the script has finished loading and every time the component is mounted (after a route navigation for example). You can execute code after the script's load event when it first loads and then after every subsequent component re-mount using the onReady property.\n\nHere's an example of how to re-instantiate a Google Maps JS embed every time the component is mounted:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useRef } from 'react'\nimport Script from 'next/script'\n \nexport default function Page() {\n  const mapRef = useRef()\n \n  return (\n    <>\n      <div ref={mapRef}></div>\n      <Script\n        id=\"google-maps\"\n        src=\"https://maps.googleapis.com/maps/api/js\"\n        onReady={() => {\n          new google.maps.Map(mapRef.current, {\n            center: { lat: -34.397, lng: 150.644 },\n            zoom: 8,\n          })\n        }}\n      />\n    </>\n  )\n}\nonError\n\nWarning: onError does not yet work with Server Components and can only be used in Client Components. onError cannot be used with the beforeInteractive loading strategy.\n\nSometimes it is helpful to catch when a script fails to load. These errors can be handled with the onError property:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Script from 'next/script'\n \nexport default function Page() {\n  return (\n    <>\n      <Script\n        src=\"https://example.com/script.js\"\n        onError={(e: Error) => {\n          console.error('Script failed to load', e)\n        }}\n      />\n    </>\n  )\n}\nVersion History\nVersion\tChanges\nv13.0.0\tbeforeInteractive and afterInteractive is modified to support app.\nv12.2.4\tonReady prop added.\nv12.2.2\tAllow next/script with beforeInteractive to be placed in _document.\nv11.0.0\tnext/script introduced.\nPrevious\nLink Component\nNext\nFile-system conventions\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "API Reference: File-system conventions | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions",
    "html": "App Router\nAPI Reference\nFile-system conventions\nCopy page\nFile-system conventions\ndefault.js\nAPI Reference for the default.js file.\nDynamic Segments\nDynamic Route Segments can be used to programmatically generate route segments from dynamic data.\nerror.js\nAPI reference for the error.js special file.\nforbidden.js\nAPI reference for the forbidden.js special file.\ninstrumentation.js\nAPI reference for the instrumentation.js file.\ninstrumentation-client.js\nLearn how to add client-side instrumentation to track and monitor your Next.js application's frontend performance.\nIntercepting Routes\nUse intercepting routes to load a new route within the current layout while masking the browser URL, useful for advanced routing patterns such as modals.\nlayout.js\nAPI reference for the layout.js file.\nloading.js\nAPI reference for the loading.js file.\nmdx-components.js\nAPI reference for the mdx-components.js file.\nnot-found.js\nAPI reference for the not-found.js file.\npage.js\nAPI reference for the page.js file.\nParallel Routes\nSimultaneously render one or more pages in the same view that can be navigated independently. A pattern for highly dynamic applications.\nproxy.js\nAPI reference for the proxy.js file.\npublic\nNext.js allows you to serve static files, like images, in the public directory. You can learn how it works here.\nroute.js\nAPI reference for the route.js special file.\nRoute Groups\nRoute Groups can be used to partition your Next.js application into different sections.\nRoute Segment Config\nLearn about how to configure options for Next.js route segments.\nsrc\nSave pages under the `src` folder as an alternative to the root `pages` directory.\ntemplate.js\nAPI Reference for the template.js file.\nunauthorized.js\nAPI reference for the unauthorized.js special file.\nMetadata Files\nAPI documentation for the metadata file conventions.\nPrevious\nScript Component\nNext\ndefault.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: Dynamic Segments | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/dynamic-routes",
    "html": "API Reference\nFile-system conventions\nDynamic Segments\nCopy page\nDynamic Route Segments\n\nWhen you don't know the exact route segment names ahead of time and want to create routes from dynamic data, you can use Dynamic Segments that are filled in at request time or prerendered at build time.\n\nConvention\n\nA Dynamic Segment can be created by wrapping a folder's name in square brackets: [folderName]. For example, a blog could include the following route app/blog/[slug]/page.js where [slug] is the Dynamic Segment for blog posts.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  return <div>My Post: {slug}</div>\n}\n\nDynamic Segments are passed as the params prop to layout, page, route, and generateMetadata functions.\n\nRoute\tExample URL\tparams\napp/blog/[slug]/page.js\t/blog/a\t{ slug: 'a' }\napp/blog/[slug]/page.js\t/blog/b\t{ slug: 'b' }\napp/blog/[slug]/page.js\t/blog/c\t{ slug: 'c' }\nIn Client Components\n\nIn a Client Component page, dynamic segments from props can be accessed using the use\n hook.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\nimport { use } from 'react'\n \nexport default function BlogPostPage({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = use(params)\n \n  return (\n    <div>\n      <p>{slug}</p>\n    </div>\n  )\n}\n\nAlternatively Client Components can use the useParams hook to access the params anywhere in the Client Component tree.\n\nCatch-all Segments\n\nDynamic Segments can be extended to catch-all subsequent segments by adding an ellipsis inside the brackets [...folderName].\n\nFor example, app/shop/[...slug]/page.js will match /shop/clothes, but also /shop/clothes/tops, /shop/clothes/tops/t-shirts, and so on.\n\nRoute\tExample URL\tparams\napp/shop/[...slug]/page.js\t/shop/a\t{ slug: ['a'] }\napp/shop/[...slug]/page.js\t/shop/a/b\t{ slug: ['a', 'b'] }\napp/shop/[...slug]/page.js\t/shop/a/b/c\t{ slug: ['a', 'b', 'c'] }\nOptional Catch-all Segments\n\nCatch-all Segments can be made optional by including the parameter in double square brackets: [[...folderName]].\n\nFor example, app/shop/[[...slug]]/page.js will also match /shop, in addition to /shop/clothes, /shop/clothes/tops, /shop/clothes/tops/t-shirts.\n\nThe difference between catch-all and optional catch-all segments is that with optional, the route without the parameter is also matched (/shop in the example above).\n\nRoute\tExample URL\tparams\napp/shop/[[...slug]]/page.js\t/shop\t{ slug: undefined }\napp/shop/[[...slug]]/page.js\t/shop/a\t{ slug: ['a'] }\napp/shop/[[...slug]]/page.js\t/shop/a/b\t{ slug: ['a', 'b'] }\napp/shop/[[...slug]]/page.js\t/shop/a/b/c\t{ slug: ['a', 'b', 'c'] }\nTypeScript\n\nWhen using TypeScript, you can add types for params depending on your configured route segment — use PageProps<'/route'>, LayoutProps<'/route'>, or RouteContext<'/route'> to type params in page, layout, and route respectively.\n\nRoute params values are typed as string, string[], or undefined (for optional catch-all segments), because their values aren't known until runtime. Users can enter any URL into the address bar, and these broad types help ensure that your application code handles all these possible cases.\n\nRoute\tparams Type Definition\napp/blog/[slug]/page.js\t{ slug: string }\napp/shop/[...slug]/page.js\t{ slug: string[] }\napp/shop/[[...slug]]/page.js\t{ slug?: string[] }\napp/[categoryId]/[itemId]/page.js\t{ categoryId: string, itemId: string }\n\nIf you're working on a route where params can only have a fixed number of valid values, such as a [locale] param with a known set of language codes, you can use runtime validation to handle any invalid params a user may enter, and let the rest of your application work with the narrower type from your known set.\n\n/app/[locale]/page.tsx\nimport { notFound } from 'next/navigation'\nimport type { Locale } from '@i18n/types'\nimport { isValidLocale } from '@i18n/utils'\n \nfunction assertValidLocale(value: string): asserts value is Locale {\n  if (!isValidLocale(value)) notFound()\n}\n \nexport default async function Page(props: PageProps<'/[locale]'>) {\n  const { locale } = await props.params // locale is typed as string\n  assertValidLocale(locale)\n  // locale is now typed as Locale\n}\nBehavior\nSince the params prop is a promise. You must use async/await or React's use function to access the values.\nIn version 14 and earlier, params was a synchronous prop. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\nExamples\nWith generateStaticParams\n\nThe generateStaticParams function can be used to statically generate routes at build time instead of on-demand at request time.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport async function generateStaticParams() {\n  const posts = await fetch('https://.../posts').then((res) => res.json())\n \n  return posts.map((post) => ({\n    slug: post.slug,\n  }))\n}\n\nWhen using fetch inside the generateStaticParams function, the requests are automatically deduplicated. This avoids multiple network calls for the same data Layouts, Pages, and other generateStaticParams functions, speeding up build time.\n\nNext Steps\nFor more information on what to do next, we recommend the following sections\ngenerateStaticParams\nAPI reference for the generateStaticParams function.\nPrevious\ndefault.js\nNext\nerror.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: default.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/default",
    "html": "API Reference\nFile-system conventions\ndefault.js\nCopy page\ndefault.js\n\nThe default.js file is used to render a fallback within Parallel Routes when Next.js cannot recover a slot's active state after a full-page load.\n\nDuring soft navigation, Next.js keeps track of the active state (subpage) for each slot. However, for hard navigations (full-page load), Next.js cannot recover the active state. In this case, a default.js file can be rendered for subpages that don't match the current URL.\n\nConsider the following folder structure. The @team slot has a settings page, but @analytics does not.\n\nWhen navigating to /settings, the @team slot will render the settings page while maintaining the currently active page for the @analytics slot.\n\nOn refresh, Next.js will render a default.js for @analytics. If default.js doesn't exist, an error is returned for named slots (@team, @analytics, etc) and requires you to define a default.js in order to continue. If you want to preserve the old behavior of returning a 404 in these situations, you can create a default.js that contains:\n\napp/@team/default.js\nimport { notFound } from 'next/navigation'\n \nexport default function Default() {\n  notFound()\n}\n\nAdditionally, since children is an implicit slot, you also need to create a default.js file to render a fallback for children when Next.js cannot recover the active state of the parent page. If you don't create a default.js for the children slot, it will return a 404 page for the route.\n\nReference\nparams (optional)\n\nA promise that resolves to an object containing the dynamic route parameters from the root segment down to the slot's subpages. For example:\n\napp/[artist]/@sidebar/default.js\nTypeScript\nJavaScript\nTypeScript\nexport default async function Default({\n  params,\n}: {\n  params: Promise<{ artist: string }>\n}) {\n  const { artist } = await params\n}\nExample\tURL\tparams\napp/[artist]/@sidebar/default.js\t/zack\tPromise<{ artist: 'zack' }>\napp/[artist]/[album]/@sidebar/default.js\t/zack/next\tPromise<{ artist: 'zack', album: 'next' }>\nSince the params prop is a promise. You must use async/await or React's use\n function to access the values.\nIn version 14 and earlier, params was a synchronous prop. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\nLearn more about Parallel Routes\nParallel Routes\nSimultaneously render one or more pages in the same view that can be navigated independently. A pattern for highly dynamic applications.\nPrevious\nFile-system conventions\nNext\nDynamic Segments\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: error.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/error",
    "html": "API Reference\nFile-system conventions\nerror.js\nCopy page\nerror.js\n\nAn error file allows you to handle unexpected runtime errors and display fallback UI.\n\napp/dashboard/error.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client' // Error boundaries must be Client Components\n \nimport { useEffect } from 'react'\n \nexport default function Error({\n  error,\n  reset,\n}: {\n  error: Error & { digest?: string }\n  reset: () => void\n}) {\n  useEffect(() => {\n    // Log the error to an error reporting service\n    console.error(error)\n  }, [error])\n \n  return (\n    <div>\n      <h2>Something went wrong!</h2>\n      <button\n        onClick={\n          // Attempt to recover by trying to re-render the segment\n          () => reset()\n        }\n      >\n        Try again\n      </button>\n    </div>\n  )\n}\n\nerror.js wraps a route segment and its nested children in a React Error Boundary\n. When an error throws within the boundary, the error component shows as the fallback UI.\n\nGood to know:\n\nThe React DevTools\n allow you to toggle error boundaries to test error states.\nIf you want errors to bubble up to the parent error boundary, you can throw when rendering the error component.\nReference\nProps\nerror\n\nAn instance of an Error\n object forwarded to the error.js Client Component.\n\nGood to know: During development, the Error object forwarded to the client will be serialized and include the message of the original error for easier debugging. However, this behavior is different in production to avoid leaking potentially sensitive details included in the error to the client.\n\nerror.message\nErrors forwarded from Client Components show the original Error message.\nErrors forwarded from Server Components show a generic message with an identifier. This is to prevent leaking sensitive details. You can use the identifier, under errors.digest, to match the corresponding server-side logs.\nerror.digest\n\nAn automatically generated hash of the error thrown. It can be used to match the corresponding error in server-side logs.\n\nreset\n\nThe cause of an error can sometimes be temporary. In these cases, trying again might resolve the issue.\n\nAn error component can use the reset() function to prompt the user to attempt to recover from the error. When executed, the function will try to re-render the error boundary's contents. If successful, the fallback error component is replaced with the result of the re-render.\n\napp/dashboard/error.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client' // Error boundaries must be Client Components\n \nexport default function Error({\n  error,\n  reset,\n}: {\n  error: Error & { digest?: string }\n  reset: () => void\n}) {\n  return (\n    <div>\n      <h2>Something went wrong!</h2>\n      <button onClick={() => reset()}>Try again</button>\n    </div>\n  )\n}\nExamples\nGlobal Error\n\nWhile less common, you can handle errors in the root layout or template using global-error.jsx, located in the root app directory, even when leveraging internationalization. Global error UI must define its own <html> and <body> tags, global styles, fonts, or other dependencies that your error page requires. This file replaces the root layout or template when active.\n\nGood to know: Error boundaries must be Client Components, which means that metadata and generateMetadata exports are not supported in global-error.jsx. As an alternative, you can use the React <title>\n component.\n\napp/global-error.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client' // Error boundaries must be Client Components\n \nexport default function GlobalError({\n  error,\n  reset,\n}: {\n  error: Error & { digest?: string }\n  reset: () => void\n}) {\n  return (\n    // global-error must include html and body tags\n    <html>\n      <body>\n        <h2>Something went wrong!</h2>\n        <button onClick={() => reset()}>Try again</button>\n      </body>\n    </html>\n  )\n}\nGraceful error recovery with a custom error boundary\n\nWhen rendering fails on the client, it can be useful to show the last known server rendered UI for a better user experience.\n\nThe GracefullyDegradingErrorBoundary is an example of a custom error boundary that captures and preserves the current HTML before an error occurs. If a rendering error happens, it re-renders the captured HTML and displays a persistent notification bar to inform the user.\n\napp/dashboard/error.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport React, { Component, ErrorInfo, ReactNode } from 'react'\n \ninterface ErrorBoundaryProps {\n  children: ReactNode\n  onError?: (error: Error, errorInfo: ErrorInfo) => void\n}\n \ninterface ErrorBoundaryState {\n  hasError: boolean\n}\n \nexport class GracefullyDegradingErrorBoundary extends Component<\n  ErrorBoundaryProps,\n  ErrorBoundaryState\n> {\n  private contentRef: React.RefObject<HTMLDivElement | null>\n \n  constructor(props: ErrorBoundaryProps) {\n    super(props)\n    this.state = { hasError: false }\n    this.contentRef = React.createRef()\n  }\n \n  static getDerivedStateFromError(_: Error): ErrorBoundaryState {\n    return { hasError: true }\n  }\n \n  componentDidCatch(error: Error, errorInfo: ErrorInfo) {\n    if (this.props.onError) {\n      this.props.onError(error, errorInfo)\n    }\n  }\n \n  render() {\n    if (this.state.hasError) {\n      // Render the current HTML content without hydration\n      return (\n        <>\n          <div\n            ref={this.contentRef}\n            suppressHydrationWarning\n            dangerouslySetInnerHTML={{\n              __html: this.contentRef.current?.innerHTML || '',\n            }}\n          />\n          <div className=\"fixed bottom-0 left-0 right-0 bg-red-600 text-white py-4 px-6 text-center\">\n            <p className=\"font-semibold\">\n              An error occurred during page rendering\n            </p>\n          </div>\n        </>\n      )\n    }\n \n    return <div ref={this.contentRef}>{this.props.children}</div>\n  }\n}\n \nexport default GracefullyDegradingErrorBoundary\nVersion History\nVersion\tChanges\nv15.2.0\tAlso display global-error in development.\nv13.1.0\tglobal-error introduced.\nv13.0.0\terror introduced.\nLearn more about error handling\nError Handling\nLearn how to display expected errors and handle uncaught exceptions.\nPrevious\nDynamic Segments\nNext\nforbidden.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: forbidden.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/forbidden",
    "html": "API Reference\nFile-system conventions\nforbidden.js\nCopy page\nforbidden.js\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe forbidden file is used to render UI when the forbidden function is invoked during authentication. Along with allowing you to customize the UI, Next.js will return a 403 status code.\n\napp/forbidden.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Forbidden() {\n  return (\n    <div>\n      <h2>Forbidden</h2>\n      <p>You are not authorized to access this resource.</p>\n      <Link href=\"/\">Return Home</Link>\n    </div>\n  )\n}\nReference\nProps\n\nforbidden.js components do not accept any props.\n\nVersion History\nVersion\tChanges\nv15.1.0\tforbidden.js introduced.\nNext Steps\nforbidden\nAPI Reference for the forbidden function.\nPrevious\nerror.js\nNext\ninstrumentation.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: instrumentation.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/instrumentation",
    "html": "API Reference\nFile-system conventions\ninstrumentation.js\nCopy page\ninstrumentation.js\n\nThe instrumentation.js|ts file is used to integrate observability tools into your application, allowing you to track the performance and behavior, and to debug issues in production.\n\nTo use it, place the file in the root of your application or inside a src folder if using one.\n\nExports\nregister (optional)\n\nThe file exports a register function that is called once when a new Next.js server instance is initiated. register can be an async function.\n\ninstrumentation.ts\nTypeScript\nJavaScript\nTypeScript\nimport { registerOTel } from '@vercel/otel'\n \nexport function register() {\n  registerOTel('next-app')\n}\nonRequestError (optional)\n\nYou can optionally export an onRequestError function to track server errors to any custom observability provider.\n\nIf you're running any async tasks in onRequestError, make sure they're awaited. onRequestError will be triggered when the Next.js server captures the error.\nThe error instance might not be the original error instance thrown, as it may be processed by React if encountered during Server Components rendering. If this happens, you can use digest property on an error to identify the actual error type.\ninstrumentation.ts\nTypeScript\nJavaScript\nTypeScript\nimport { type Instrumentation } from 'next'\n \nexport const onRequestError: Instrumentation.onRequestError = async (\n  err,\n  request,\n  context\n) => {\n  await fetch('https://.../report-error', {\n    method: 'POST',\n    body: JSON.stringify({\n      message: err.message,\n      request,\n      context,\n    }),\n    headers: {\n      'Content-Type': 'application/json',\n    },\n  })\n}\nParameters\n\nThe function accepts three parameters: error, request, and context.\n\nTypes\nexport function onRequestError(\n  error: { digest: string } & Error,\n  request: {\n    path: string // resource path, e.g. /blog?name=foo\n    method: string // request method. e.g. GET, POST, etc\n    headers: { [key: string]: string | string[] }\n  },\n  context: {\n    routerKind: 'Pages Router' | 'App Router' // the router type\n    routePath: string // the route file path, e.g. /app/blog/[dynamic]\n    routeType: 'render' | 'route' | 'action' | 'proxy' // the context in which the error occurred\n    renderSource:\n      | 'react-server-components'\n      | 'react-server-components-payload'\n      | 'server-rendering'\n    revalidateReason: 'on-demand' | 'stale' | undefined // undefined is a normal request without revalidation\n    renderType: 'dynamic' | 'dynamic-resume' // 'dynamic-resume' for PPR\n  }\n): void | Promise<void>\nerror: The caught error itself (type is always Error), and a digest property which is the unique ID of the error.\nrequest: Read-only request information associated with the error.\ncontext: The context in which the error occurred. This can be the type of router (App or Pages Router), and/or (Server Components ('render'), Route Handlers ('route'), Server Actions ('action'), or Proxy ('proxy')).\nSpecifying the runtime\n\nThe instrumentation.js file works in both the Node.js and Edge runtime, however, you can use process.env.NEXT_RUNTIME to target a specific runtime.\n\ninstrumentation.js\nexport function register() {\n  if (process.env.NEXT_RUNTIME === 'edge') {\n    return require('./register.edge')\n  } else {\n    return require('./register.node')\n  }\n}\n \nexport function onRequestError() {\n  if (process.env.NEXT_RUNTIME === 'edge') {\n    return require('./on-request-error.edge')\n  } else {\n    return require('./on-request-error.node')\n  }\n}\nVersion History\nVersion\tChanges\nv15.0.0\tonRequestError introduced, instrumentation stable\nv14.0.4\tTurbopack support for instrumentation\nv13.2.0\tinstrumentation introduced as an experimental feature\nLearn more about Instrumentation\nInstrumentation\nLearn how to use instrumentation to run code at server startup in your Next.js app\nPrevious\nforbidden.js\nNext\ninstrumentation-client.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: instrumentation-client.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/instrumentation-client",
    "html": "API Reference\nFile-system conventions\ninstrumentation-client.js\nCopy page\ninstrumentation-client.js\n\nThe instrumentation-client.js|ts file allows you to add monitoring, analytics code, and other side-effects that run before your application becomes interactive. This is useful for setting up performance tracking, error monitoring, polyfills, or any other client-side observability tools.\n\nTo use it, place the file in the root of your application or inside a src folder.\n\nUsage\n\nUnlike server-side instrumentation, you do not need to export any specific functions. You can write your monitoring code directly in the file:\n\ninstrumentation-client.ts\nTypeScript\nJavaScript\nTypeScript\n// Set up performance monitoring\nperformance.mark('app-init')\n \n// Initialize analytics\nconsole.log('Analytics initialized')\n \n// Set up error tracking\nwindow.addEventListener('error', (event) => {\n  // Send to your error tracking service\n  reportError(event.error)\n})\n\nError handling: Implement try-catch blocks around your instrumentation code to ensure robust monitoring. This prevents individual tracking failures from affecting other instrumentation features.\n\nRouter navigation tracking\n\nYou can export an onRouterTransitionStart function to receive notifications when navigation begins:\n\ninstrumentation-client.ts\nTypeScript\nJavaScript\nTypeScript\nperformance.mark('app-init')\n \nexport function onRouterTransitionStart(\n  url: string,\n  navigationType: 'push' | 'replace' | 'traverse'\n) {\n  console.log(`Navigation started: ${navigationType} to ${url}`)\n  performance.mark(`nav-start-${Date.now()}`)\n}\n\nThe onRouterTransitionStart function receives two parameters:\n\nurl: string - The URL being navigated to\nnavigationType: 'push' | 'replace' | 'traverse' - The type of navigation\nPerformance considerations\n\nKeep instrumentation code lightweight.\n\nNext.js monitors initialization time in development and will log warnings if it takes longer than 16ms, which could impact smooth page loading.\n\nExecution timing\n\nThe instrumentation-client.js file executes at a specific point in the application lifecycle:\n\nAfter the HTML document is loaded\nBefore React hydration begins\nBefore user interactions are possible\n\nThis timing makes it ideal for setting up error tracking, analytics, and performance monitoring that needs to capture early application lifecycle events.\n\nExamples\nError tracking\n\nInitialize error tracking before React starts and add navigation breadcrumbs for better debugging context.\n\ninstrumentation-client.ts\nTypeScript\nJavaScript\nTypeScript\nimport Monitor from './lib/monitoring'\n \nMonitor.initialize()\n \nexport function onRouterTransitionStart(url: string) {\n  Monitor.pushEvent({\n    message: `Navigation to ${url}`,\n    category: 'navigation',\n  })\n}\nAnalytics tracking\n\nInitialize analytics and track navigation events with detailed metadata for user behavior analysis.\n\ninstrumentation-client.ts\nTypeScript\nJavaScript\nTypeScript\nimport { analytics } from './lib/analytics'\n \nanalytics.init()\n \nexport function onRouterTransitionStart(url: string, navigationType: string) {\n  analytics.track('page_navigation', {\n    url,\n    type: navigationType,\n    timestamp: Date.now(),\n  })\n}\nPerformance monitoring\n\nTrack Time to Interactive and navigation performance using the Performance Observer API and performance marks.\n\ninstrumentation-client.ts\nTypeScript\nJavaScript\nTypeScript\nconst startTime = performance.now()\n \nconst observer = new PerformanceObserver(\n  (list: PerformanceObserverEntryList) => {\n    for (const entry of list.getEntries()) {\n      if (entry instanceof PerformanceNavigationTiming) {\n        console.log('Time to Interactive:', entry.loadEventEnd - startTime)\n      }\n    }\n  }\n)\n \nobserver.observe({ entryTypes: ['navigation'] })\n \nexport function onRouterTransitionStart(url: string) {\n  performance.mark(`nav-start-${url}`)\n}\nPolyfills\n\nLoad polyfills before application code runs. Use static imports for immediate loading and dynamic imports for conditional loading based on feature detection.\n\ninstrumentation-client.ts\nTypeScript\nJavaScript\nTypeScript\nimport './lib/polyfills'\n \nif (!window.ResizeObserver) {\n  import('./lib/polyfills/resize-observer').then((mod) => {\n    window.ResizeObserver = mod.default\n  })\n}\nVersion history\nVersion\tChanges\nv15.3\tinstrumentation-client introduced\nPrevious\ninstrumentation.js\nNext\nIntercepting Routes\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: Intercepting Routes | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/intercepting-routes",
    "html": "API Reference\nFile-system conventions\nIntercepting Routes\nCopy page\nIntercepting Routes\n\nIntercepting routes allows you to load a route from another part of your application within the current layout. This routing paradigm can be useful when you want to display the content of a route without the user switching to a different context.\n\nFor example, when clicking on a photo in a feed, you can display the photo in a modal, overlaying the feed. In this case, Next.js intercepts the /photo/123 route, masks the URL, and overlays it over /feed.\n\nHowever, when navigating to the photo by clicking a shareable URL or by refreshing the page, the entire photo page should render instead of the modal. No route interception should occur.\n\nConvention\n\nIntercepting routes can be defined with the (..) convention, which is similar to relative path convention ../ but for route segments.\n\nYou can use:\n\n(.) to match segments on the same level\n(..) to match segments one level above\n(..)(..) to match segments two levels above\n(...) to match segments from the root app directory\n\nFor example, you can intercept the photo segment from within the feed segment by creating a (..)photo directory.\n\nGood to know: The (..) convention is based on route segments, not the file-system. For example, it does not consider @slot folders in Parallel Routes.\n\nExamples\nModals\n\nIntercepting Routes can be used together with Parallel Routes to create modals. This allows you to solve common challenges when building modals, such as:\n\nMaking the modal content shareable through a URL.\nPreserving context when the page is refreshed, instead of closing the modal.\nClosing the modal on backwards navigation rather than going to the previous route.\nReopening the modal on forwards navigation.\n\nConsider the following UI pattern, where a user can open a photo modal from a gallery using client-side navigation, or navigate to the photo page directly from a shareable URL:\n\nIn the above example, the path to the photo segment can use the (..) matcher since @modal is a slot and not a segment. This means that the photo route is only one segment level higher, despite being two file-system levels higher.\n\nSee the Parallel Routes documentation for a step-by-step example, or see our image gallery example\n.\n\nGood to know:\n\nOther examples could include opening a login modal in a top navbar while also having a dedicated /login page, or opening a shopping cart in a side modal.\nNext Steps\nLearn how to create modals with Intercepted and Parallel Routes.\nParallel Routes\nSimultaneously render one or more pages in the same view that can be navigated independently. A pattern for highly dynamic applications.\nPrevious\ninstrumentation-client.js\nNext\nlayout.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: layout.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/layout",
    "html": "API Reference\nFile-system conventions\nlayout.js\nCopy page\nlayout.js\n\nThe layout file is used to define a layout in your Next.js application.\n\napp/dashboard/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function DashboardLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return <section>{children}</section>\n}\n\nA root layout is the top-most layout in the root app directory. It is used to define the <html> and <body> tags and other globally shared UI.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body>{children}</body>\n    </html>\n  )\n}\nReference\nProps\nchildren (required)\n\nLayout components should accept and use a children prop. During rendering, children will be populated with the route segments the layout is wrapping. These will primarily be the component of a child Layout (if it exists) or Page, but could also be other special files like Loading or Error when applicable.\n\nparams (optional)\n\nA promise that resolves to an object containing the dynamic route parameters object from the root segment down to that layout.\n\napp/dashboard/[team]/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Layout({\n  children,\n  params,\n}: {\n  children: React.ReactNode\n  params: Promise<{ team: string }>\n}) {\n  const { team } = await params\n}\nExample Route\tURL\tparams\napp/dashboard/[team]/layout.js\t/dashboard/1\tPromise<{ team: '1' }>\napp/shop/[tag]/[item]/layout.js\t/shop/1/2\tPromise<{ tag: '1', item: '2' }>\napp/blog/[...slug]/layout.js\t/blog/1/2\tPromise<{ slug: ['1', '2'] }>\nSince the params prop is a promise. You must use async/await or React's use\n function to access the values.\nIn version 14 and earlier, params was a synchronous prop. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\nLayout Props Helper\n\nYou can type layouts with LayoutProps to get a strongly typed params and named slots inferred from your directory structure. LayoutProps is a globally available helper.\n\napp/dashboard/layout.tsx\nexport default function Layout(props: LayoutProps<'/dashboard'>) {\n  return (\n    <section>\n      {props.children}\n      {/* If you have app/dashboard/@analytics, it appears as a typed slot: */}\n      {/* {props.analytics} */}\n    </section>\n  )\n}\n\nGood to know:\n\nTypes are generated during next dev, next build or next typegen.\nAfter type generation, the LayoutProps helper is globally available. It doesn't need to be imported.\nRoot Layout\n\nThe app directory must include a root layout, which is the top-most layout in the root app directory. Typically, the root layout is app/layout.js.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html>\n      <body>{children}</body>\n    </html>\n  )\n}\nThe root layout must define <html> and <body> tags.\nYou should not manually add <head> tags such as <title> and <meta> to root layouts. Instead, you should use the Metadata API which automatically handles advanced requirements such as streaming and de-duplicating <head> elements.\nYou can use route groups to create multiple root layouts.\nNavigating across multiple root layouts will cause a full page load (as opposed to a client-side navigation). For example, navigating from /cart that uses app/(shop)/layout.js to /blog that uses app/(marketing)/layout.js will cause a full page load. This only applies to multiple root layouts.\nThe root layout can be under a dynamic segment, for example when implementing internationalization with app/[lang]/layout.js.\nCaveats\nRequest Object\n\nLayouts are cached in the client during navigation to avoid unnecessary server requests.\n\nLayouts do not rerender. They can be cached and reused to avoid unnecessary computation when navigating between pages. By restricting layouts from accessing the raw request, Next.js can prevent the execution of potentially slow or expensive user code within the layout, which could negatively impact performance.\n\nTo access the request object, you can use headers and cookies APIs in Server Components and Functions.\n\napp/shop/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport default async function Layout({ children }) {\n  const cookieStore = await cookies()\n  const theme = cookieStore.get('theme')\n  return '...'\n}\nQuery params\n\nLayouts do not rerender on navigation, so they cannot access search params which would otherwise become stale.\n\nTo access updated query parameters, you can use the Page searchParams prop, or read them inside a Client Component using the useSearchParams hook. Since Client Components re-render on navigation, they have access to the latest query parameters.\n\napp/ui/search.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useSearchParams } from 'next/navigation'\n \nexport default function Search() {\n  const searchParams = useSearchParams()\n \n  const search = searchParams.get('search')\n \n  return '...'\n}\napp/shop/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Search from '@/app/ui/search'\n \nexport default function Layout({ children }) {\n  return (\n    <>\n      <Search />\n      {children}\n    </>\n  )\n}\nPathname\n\nLayouts do not re-render on navigation, so they do not access pathname which would otherwise become stale.\n\nTo access the current pathname, you can read it inside a Client Component using the usePathname hook. Since Client Components re-render during navigation, they have access to the latest pathname.\n\napp/ui/breadcrumbs.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { usePathname } from 'next/navigation'\n \n// Simplified breadcrumbs logic\nexport default function Breadcrumbs() {\n  const pathname = usePathname()\n  const segments = pathname.split('/')\n \n  return (\n    <nav>\n      {segments.map((segment, index) => (\n        <span key={index}>\n          {' > '}\n          {segment}\n        </span>\n      ))}\n    </nav>\n  )\n}\napp/docs/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Breadcrumbs } from '@/app/ui/Breadcrumbs'\n \nexport default function Layout({ children }) {\n  return (\n    <>\n      <Breadcrumbs />\n      <main>{children}</main>\n    </>\n  )\n}\nFetching Data\n\nLayouts cannot pass data to their children. However, you can fetch the same data in a route more than once, and use React cache\n to dedupe the requests without affecting performance.\n\nAlternatively, when using fetchin Next.js, requests are automatically deduped.\n\napp/lib/data.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function getUser(id: string) {\n  const res = await fetch(`https://.../users/${id}`)\n  return res.json()\n}\napp/dashboard/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getUser } from '@/app/lib/data'\nimport { UserName } from '@/app/ui/user-name'\n \nexport default async function Layout({ children }) {\n  const user = await getUser('1')\n \n  return (\n    <>\n      <nav>\n        {/* ... */}\n        <UserName user={user.name} />\n      </nav>\n      {children}\n    </>\n  )\n}\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getUser } from '@/app/lib/data'\nimport { UserName } from '@/app/ui/user-name'\n \nexport default async function Page() {\n  const user = await getUser('1')\n \n  return (\n    <div>\n      <h1>Welcome {user.name}</h1>\n    </div>\n  )\n}\nAccessing child segments\n\nLayouts do not have access to the route segments below itself. To access all route segments, you can use useSelectedLayoutSegment or useSelectedLayoutSegments in a Client Component.\n\napp/ui/nav-link.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Link from 'next/link'\nimport { useSelectedLayoutSegment } from 'next/navigation'\n \nexport default function NavLink({\n  slug,\n  children,\n}: {\n  slug: string\n  children: React.ReactNode\n}) {\n  const segment = useSelectedLayoutSegment()\n  const isActive = slug === segment\n \n  return (\n    <Link\n      href={`/blog/${slug}`}\n      // Change style depending on whether the link is active\n      style={{ fontWeight: isActive ? 'bold' : 'normal' }}\n    >\n      {children}\n    </Link>\n  )\n}\napp/blog/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { NavLink } from './nav-link'\nimport getPosts from './get-posts'\n \nexport default async function Layout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  const featuredPosts = await getPosts()\n  return (\n    <div>\n      {featuredPosts.map((post) => (\n        <div key={post.id}>\n          <NavLink slug={post.slug}>{post.title}</NavLink>\n        </div>\n      ))}\n      <div>{children}</div>\n    </div>\n  )\n}\nExamples\nMetadata\n\nYou can modify the <head> HTML elements such as title and meta using the metadata object or generateMetadata function.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: 'Next.js',\n}\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return '...'\n}\n\nGood to know: You should not manually add <head> tags such as <title> and <meta> to root layouts. Instead, use the Metadata APIs which automatically handles advanced requirements such as streaming and de-duplicating <head> elements.\n\nActive Nav Links\n\nYou can use the usePathname hook to determine if a nav link is active.\n\nSince usePathname is a client hook, you need to extract the nav links into a Client Component, which can be imported into your layout:\n\napp/ui/nav-links.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { usePathname } from 'next/navigation'\nimport Link from 'next/link'\n \nexport function NavLinks() {\n  const pathname = usePathname()\n \n  return (\n    <nav>\n      <Link className={`link ${pathname === '/' ? 'active' : ''}`} href=\"/\">\n        Home\n      </Link>\n \n      <Link\n        className={`link ${pathname === '/about' ? 'active' : ''}`}\n        href=\"/about\"\n      >\n        About\n      </Link>\n    </nav>\n  )\n}\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { NavLinks } from '@/app/ui/nav-links'\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return (\n    <html lang=\"en\">\n      <body>\n        <NavLinks />\n        <main>{children}</main>\n      </body>\n    </html>\n  )\n}\nDisplaying content based on params\n\nUsing dynamic route segments, you can display or fetch specific content based on the params prop.\n\napp/dashboard/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function DashboardLayout({\n  children,\n  params,\n}: {\n  children: React.ReactNode\n  params: Promise<{ team: string }>\n}) {\n  const { team } = await params\n \n  return (\n    <section>\n      <header>\n        <h1>Welcome to {team}'s Dashboard</h1>\n      </header>\n      <main>{children}</main>\n    </section>\n  )\n}\nReading params in Client Components\n\nTo use params in a Client Component (which cannot be async), you can use React's use\n function to read the promise:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { use } from 'react'\n \nexport default function Page({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = use(params)\n}\nVersion History\nVersion\tChanges\nv15.0.0-RC\tparams is now a promise. A codemod is available.\nv13.0.0\tlayout introduced.\nPrevious\nIntercepting Routes\nNext\nloading.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: loading.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/loading",
    "html": "API Reference\nFile-system conventions\nloading.js\nCopy page\nloading.js\n\nThe special file loading.js helps you create meaningful Loading UI with React Suspense\n. With this convention, you can show an instant loading state from the server while the content of a route segment streams in. The new content is automatically swapped in once complete.\n\napp/feed/loading.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Loading() {\n  // Or a custom loading skeleton component\n  return <p>Loading...</p>\n}\n\nInside the loading.js file, you can add any light-weight loading UI. You may find it helpful to use the React Developer Tools\n to manually toggle Suspense boundaries.\n\nBy default, this file is a Server Component - but can also be used as a Client Component through the \"use client\" directive.\n\nReference\nParameters\n\nLoading UI components do not accept any parameters.\n\nBehavior\nNavigation\nThe Fallback UI is prefetched, making navigation immediate unless prefetching hasn't completed.\nNavigation is interruptible, meaning changing routes does not need to wait for the content of the route to fully load before navigating to another route.\nShared layouts remain interactive while new route segments load.\nInstant Loading States\n\nAn instant loading state is fallback UI that is shown immediately upon navigation. You can pre-render loading indicators such as skeletons and spinners, or a small but meaningful part of future screens such as a cover photo, title, etc. This helps users understand the app is responding and provides a better user experience.\n\nCreate a loading state by adding a loading.js file inside a folder.\n\napp/dashboard/loading.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Loading() {\n  // You can add any UI inside Loading, including a Skeleton.\n  return <LoadingSkeleton />\n}\n\nIn the same folder, loading.js will be nested inside layout.js. It will automatically wrap the page.js file and any children below in a <Suspense> boundary.\n\nSEO\nFor bots that only scrape static HTML, and cannot execute JavaScript like a full browser, such as Twitterbot, Next.js resolves generateMetadata before streaming UI, and metadata is placed in the <head> of the initial HTML.\nOtherwise, streaming metadata may be used used. Next.js automatically detects user agents to choose between blocking and streaming behavior.\nSince streaming is server-rendered, it does not impact SEO. You can use the Rich Results Test\n tool from Google to see how your page appears to Google's web crawlers and view the serialized HTML (source\n).\nStatus Codes\n\nWhen streaming, a 200 status code will be returned to signal that the request was successful.\n\nThe server can still communicate errors or issues to the client within the streamed content itself, for example, when using redirect or notFound. Because the response headers have already been sent to the client, the status code of the response cannot be updated.\n\nFor example, when a 404 page is streamed to the client, Next.js includes a <meta name=\"robots\" content=\"noindex\"> tag in the streamed HTML. This prevents search engines from indexing that URL even if the HTTP status is 200. See Google’s guidance on the robots meta tag\n.\n\nSome crawlers may label these responses as “soft 404s”. In the streaming case, this does not lead to indexation because the page is explicitly marked noindex in the HTML.\n\nIf you need a 404 status, for compliance or analytics, ensure the resource exists before the response body is streamed, so that the server can set the HTTP status code.\n\nYou can run this check in proxy to rewrite missing slugs to a not-found route, or produce a 404 response. Keep proxy checks fast, and avoid fetching full content there.\n\nWhen is the response body streamed?\nBrowser limits\n\nSome browsers\n buffer a streaming response. You may not see the streamed response until the response exceeds 1024 bytes. This typically only affects “hello world” applications, but not real applications.\n\nPlatform Support\nDeployment Option\tSupported\nNode.js server\tYes\nDocker container\tYes\nStatic export\tNo\nAdapters\tPlatform-specific\n\nLearn how to configure streaming when self-hosting Next.js.\n\nExamples\nStreaming with Suspense\n\nIn addition to loading.js, you can also manually create Suspense Boundaries for your own UI components. The App Router supports streaming with Suspense\n.\n\n<Suspense> works by wrapping a component that performs an asynchronous action (e.g. fetch data), showing fallback UI (e.g. skeleton, spinner) while it's happening, and then swapping in your component once the action completes.\n\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Suspense } from 'react'\nimport { PostFeed, Weather } from './Components'\n \nexport default function Posts() {\n  return (\n    <section>\n      <Suspense fallback={<p>Loading feed...</p>}>\n        <PostFeed />\n      </Suspense>\n      <Suspense fallback={<p>Loading weather...</p>}>\n        <Weather />\n      </Suspense>\n    </section>\n  )\n}\n\nBy using Suspense, you get the benefits of:\n\nStreaming Server Rendering - Progressively rendering HTML from the server to the client.\nSelective Hydration - React prioritizes what components to make interactive first based on user interaction.\n\nFor more Suspense examples and use cases, please see the React Documentation\n.\n\nVersion History\nVersion\tChanges\nv13.0.0\tloading introduced.\nPrevious\nlayout.js\nNext\nmdx-components.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: mdx-components.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/mdx-components",
    "html": "API Reference\nFile-system conventions\nmdx-components.js\nCopy page\nmdx-components.js\n\nThe mdx-components.js|tsx file is required to use @next/mdx with App Router and will not work without it. Additionally, you can use it to customize styles.\n\nUse the file mdx-components.tsx (or .js) in the root of your project to define MDX Components. For example, at the same level as pages or app, or inside src if applicable.\n\nmdx-components.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { MDXComponents } from 'mdx/types'\n \nconst components: MDXComponents = {}\n \nexport function useMDXComponents(): MDXComponents {\n  return components\n}\nExports\nuseMDXComponents function\n\nThe file must export a single function named useMDXComponents. This function does not accept any arguments.\n\nmdx-components.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { MDXComponents } from 'mdx/types'\n \nconst components: MDXComponents = {}\n \nexport function useMDXComponents(): MDXComponents {\n  return components\n}\nVersion History\nVersion\tChanges\nv13.1.2\tMDX Components added\nLearn more about MDX Components\nMDX\nLearn how to configure MDX and use it in your Next.js apps.\nPrevious\nloading.js\nNext\nnot-found.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: not-found.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/not-found",
    "html": "API Reference\nFile-system conventions\nnot-found.js\nCopy page\nnot-found.js\n\nNext.js provides two conventions to handle not found cases:\n\nnot-found.js: Used when you call the notFound function in a route segment.\nglobal-not-found.js: Used to define a global 404 page for unmatched routes across your entire app. This is handled at the routing level and doesn't depend on rendering a layout or page.\nnot-found.js\n\nThe not-found file is used to render UI when the notFound function is thrown within a route segment. Along with serving a custom UI, Next.js will return a 200 HTTP status code for streamed responses, and 404 for non-streamed responses.\n\napp/not-found.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function NotFound() {\n  return (\n    <div>\n      <h2>Not Found</h2>\n      <p>Could not find requested resource</p>\n      <Link href=\"/\">Return Home</Link>\n    </div>\n  )\n}\nglobal-not-found.js (experimental)\n\nThe global-not-found.js file lets you define a 404 page for your entire application. Unlike not-found.js, which works at the route level, this is used when a requested URL doesn't match any route at all. Next.js skips rendering and directly returns this global page.\n\nThe global-not-found.js file bypasses your app's normal rendering, which means you'll need to import any global styles, fonts, or other dependencies that your 404 page requires.\n\nGood to know: A smaller version of your global styles, and a simpler font family could improve performance of this page.\n\nglobal-not-found.js is useful when you can't build a 404 page using a combination of layout.js and not-found.js. This can happen in two cases:\n\nYour app has multiple root layouts (e.g. app/(admin)/layout.tsx and app/(shop)/layout.tsx), so there's no single layout to compose a global 404 from.\nYour root layout is defined using top-level dynamic segments (e.g. app/[country]/layout.tsx), which makes composing a consistent 404 page harder.\n\nTo enable it, add the globalNotFound flag in next.config.ts:\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    globalNotFound: true,\n  },\n}\n \nexport default nextConfig\n\nThen, create a file in the root of the app directory: app/global-not-found.js:\n\napp/global-not-found.tsx\nTypeScript\nJavaScript\nTypeScript\n// Import global styles and fonts\nimport './globals.css'\nimport { Inter } from 'next/font/google'\nimport type { Metadata } from 'next'\n \nconst inter = Inter({ subsets: ['latin'] })\n \nexport const metadata: Metadata = {\n  title: '404 - Page Not Found',\n  description: 'The page you are looking for does not exist.',\n}\n \nexport default function GlobalNotFound() {\n  return (\n    <html lang=\"en\" className={inter.className}>\n      <body>\n        <h1>404 - Page Not Found</h1>\n        <p>This page does not exist.</p>\n      </body>\n    </html>\n  )\n}\n\nUnlike not-found.js, this file must return a full HTML document, including <html> and <body> tags.\n\nReference\nProps\n\nnot-found.js or global-not-found.js components do not accept any props.\n\nGood to know: In addition to catching expected notFound() errors, the root app/not-found.js and app/global-not-found.js files handle any unmatched URLs for your whole application. This means users that visit a URL that is not handled by your app will be shown the exported UI.\n\nExamples\nData Fetching\n\nBy default, not-found is a Server Component. You can mark it as async to fetch and display data:\n\napp/not-found.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\nimport { headers } from 'next/headers'\n \nexport default async function NotFound() {\n  const headersList = await headers()\n  const domain = headersList.get('host')\n  const data = await getSiteData(domain)\n  return (\n    <div>\n      <h2>Not Found: {data.name}</h2>\n      <p>Could not find requested resource</p>\n      <p>\n        View <Link href=\"/blog\">all posts</Link>\n      </p>\n    </div>\n  )\n}\n\nIf you need to use Client Component hooks like usePathname to display content based on the path, you must fetch data on the client-side instead.\n\nMetadata\n\nFor global-not-found.js, you can export a metadata object or a generateMetadata function to customize the <title>, <meta>, and other head tags for your 404 page:\n\nGood to know: Next.js automatically injects <meta name=\"robots\" content=\"noindex\" /> for pages that return a 404 status code, including global-not-found.js pages.\n\napp/global-not-found.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: 'Not Found',\n  description: 'The page you are looking for does not exist.',\n}\n \nexport default function GlobalNotFound() {\n  return (\n    <html lang=\"en\">\n      <body>\n        <div>\n          <h1>Not Found</h1>\n          <p>The page you are looking for does not exist.</p>\n        </div>\n      </body>\n    </html>\n  )\n}\nVersion History\nVersion\tChanges\nv15.4.0\tglobal-not-found.js introduced (experimental).\nv13.3.0\tRoot app/not-found handles global unmatched URLs.\nv13.0.0\tnot-found introduced.\nPrevious\nmdx-components.js\nNext\npage.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: page.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/page",
    "html": "API Reference\nFile-system conventions\npage.js\nCopy page\npage.js\n\nThe page file allows you to define UI that is unique to a route. You can create a page by default exporting a component from the file:\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Page({\n  params,\n  searchParams,\n}: {\n  params: Promise<{ slug: string }>\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}) {\n  return <h1>My Page</h1>\n}\nGood to know\nThe .js, .jsx, or .tsx file extensions can be used for page.\nA page is always the leaf of the route subtree.\nA page file is required to make a route segment publicly accessible.\nPages are Server Components\n by default, but can be set to a Client Component\n.\nReference\nProps\nparams (optional)\n\nA promise that resolves to an object containing the dynamic route parameters from the root segment down to that page.\n\napp/shop/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n}\nExample Route\tURL\tparams\napp/shop/[slug]/page.js\t/shop/1\tPromise<{ slug: '1' }>\napp/shop/[category]/[item]/page.js\t/shop/1/2\tPromise<{ category: '1', item: '2' }>\napp/shop/[...slug]/page.js\t/shop/1/2\tPromise<{ slug: ['1', '2'] }>\nSince the params prop is a promise, you must use async/await or React's use\n function to access the values.\nIn version 14 and earlier, params was a synchronous prop. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\nsearchParams (optional)\n\nA promise that resolves to an object containing the search parameters\n of the current URL. For example:\n\napp/shop/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page({\n  searchParams,\n}: {\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}) {\n  const filters = (await searchParams).filters\n}\n\nClient Component pages can also access searchParams using React’s use\n hook:\n\napp/shop/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\nimport { use } from 'react'\n \nexport default function Page({\n  searchParams,\n}: {\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}) {\n  const filters = use(searchParams).filters\n}\nExample URL\tsearchParams\n/shop?a=1\tPromise<{ a: '1' }>\n/shop?a=1&b=2\tPromise<{ a: '1', b: '2' }>\n/shop?a=1&a=2\tPromise<{ a: ['1', '2'] }>\nSince the searchParams prop is a promise. You must use async/await or React's use\n function to access the values.\nIn version 14 and earlier, searchParams was a synchronous prop. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\nsearchParams is a Dynamic API whose values cannot be known ahead of time. Using it will opt the page into dynamic rendering at request time.\nsearchParams is a plain JavaScript object, not a URLSearchParams instance.\nPage Props Helper\n\nYou can type pages with PageProps to get strongly typed params and searchParams from the route literal. PageProps is a globally available helper.\n\napp/blog/[slug]/page.tsx\nexport default async function Page(props: PageProps<'/blog/[slug]'>) {\n  const { slug } = await props.params\n  const query = await props.searchParams\n  return <h1>Blog Post: {slug}</h1>\n}\n\nGood to know\n\nUsing a literal route (e.g. '/blog/[slug]') enables autocomplete and strict keys for params.\nStatic routes resolve params to {}.\nTypes are generated during next dev, next build, or with next typegen.\nAfter type generation, the PageProps helper is globally available. It doesn't need to be imported.\nExamples\nDisplaying content based on params\n\nUsing dynamic route segments, you can display or fetch specific content for the page based on the params prop.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  return <h1>Blog Post: {slug}</h1>\n}\nHandling filtering with searchParams\n\nYou can use the searchParams prop to handle filtering, pagination, or sorting based on the query string of the URL.\n\napp/shop/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page({\n  searchParams,\n}: {\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}) {\n  const { page = '1', sort = 'asc', query = '' } = await searchParams\n \n  return (\n    <div>\n      <h1>Product Listing</h1>\n      <p>Search query: {query}</p>\n      <p>Current page: {page}</p>\n      <p>Sort order: {sort}</p>\n    </div>\n  )\n}\nReading searchParams and params in Client Components\n\nTo use searchParams and params in a Client Component (which cannot be async), you can use React's use\n function to read the promise:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { use } from 'react'\n \nexport default function Page({\n  params,\n  searchParams,\n}: {\n  params: Promise<{ slug: string }>\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}) {\n  const { slug } = use(params)\n  const { query } = use(searchParams)\n}\nVersion History\nVersion\tChanges\nv15.0.0-RC\tparams and searchParams are now promises. A codemod is available.\nv13.0.0\tpage introduced.\nPrevious\nnot-found.js\nNext\nParallel Routes\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: Parallel Routes | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/parallel-routes",
    "html": "API Reference\nFile-system conventions\nParallel Routes\nCopy page\nParallel Routes\n\nParallel Routes allows you to simultaneously or conditionally render one or more pages within the same layout. They are useful for highly dynamic sections of an app, such as dashboards and feeds on social sites.\n\nFor example, considering a dashboard, you can use parallel routes to simultaneously render the team and analytics pages:\n\nConvention\nSlots\n\nParallel routes are created using named slots. Slots are defined with the @folder convention. For example, the following file structure defines two slots: @analytics and @team:\n\nSlots are passed as props to the shared parent layout. For the example above, the component in app/layout.js now accepts the @analytics and @team slots props, and can render them in parallel alongside the children prop:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Layout({\n  children,\n  team,\n  analytics,\n}: {\n  children: React.ReactNode\n  analytics: React.ReactNode\n  team: React.ReactNode\n}) {\n  return (\n    <>\n      {children}\n      {team}\n      {analytics}\n    </>\n  )\n}\n\nHowever, slots are not route segments and do not affect the URL structure. For example, for /@analytics/views, the URL will be /views since @analytics is a slot. Slots are combined with the regular Page component to form the final page associated with the route segment. Because of this, you cannot have separate static and dynamic slots at the same route segment level. If one slot is dynamic, all slots at that level must be dynamic.\n\nGood to know:\n\nThe children prop is an implicit slot that does not need to be mapped to a folder. This means app/page.js is equivalent to app/@children/page.js.\ndefault.js\n\nYou can define a default.js file to render as a fallback for unmatched slots during the initial load or full-page reload.\n\nConsider the following folder structure. The @team slot has a /settings page, but @analytics does not.\n\nWhen navigating to /settings, the @team slot will render the /settings page while maintaining the currently active page for the @analytics slot.\n\nOn refresh, Next.js will render a default.js for @analytics. If default.js doesn't exist, a 404 is rendered instead.\n\nAdditionally, since children is an implicit slot, you also need to create a default.js file to render a fallback for children when Next.js cannot recover the active state of the parent page.\n\nBehavior\n\nBy default, Next.js keeps track of the active state (or subpage) for each slot. However, the content rendered within a slot will depend on the type of navigation:\n\nSoft Navigation: During client-side navigation, Next.js will perform a partial render, changing the subpage within the slot, while maintaining the other slot's active subpages, even if they don't match the current URL.\nHard Navigation: After a full-page load (browser refresh), Next.js cannot determine the active state for the slots that don't match the current URL. Instead, it will render a default.js file for the unmatched slots, or 404 if default.js doesn't exist.\n\nGood to know:\n\nThe 404 for unmatched routes helps ensure that you don't accidentally render a parallel route on a page that it was not intended for.\nExamples\nWith useSelectedLayoutSegment(s)\n\nBoth useSelectedLayoutSegment and useSelectedLayoutSegments accept a parallelRoutesKey parameter, which allows you to read the active route segment within a slot.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useSelectedLayoutSegment } from 'next/navigation'\n \nexport default function Layout({ auth }: { auth: React.ReactNode }) {\n  const loginSegment = useSelectedLayoutSegment('auth')\n  // ...\n}\n\nWhen a user navigates to app/@auth/login (or /login in the URL bar), loginSegment will be equal to the string \"login\".\n\nConditional Routes\n\nYou can use Parallel Routes to conditionally render routes based on certain conditions, such as user role. For example, to render a different dashboard page for the /admin or /user roles:\n\napp/dashboard/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { checkUserRole } from '@/lib/auth'\n \nexport default function Layout({\n  user,\n  admin,\n}: {\n  user: React.ReactNode\n  admin: React.ReactNode\n}) {\n  const role = checkUserRole()\n  return role === 'admin' ? admin : user\n}\nTab Groups\n\nYou can add a layout inside a slot to allow users to navigate the slot independently. This is useful for creating tabs.\n\nFor example, the @analytics slot has two subpages: /page-views and /visitors.\n\nWithin @analytics, create a layout file to share the tabs between the two pages:\n\napp/@analytics/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return (\n    <>\n      <nav>\n        <Link href=\"/page-views\">Page Views</Link>\n        <Link href=\"/visitors\">Visitors</Link>\n      </nav>\n      <div>{children}</div>\n    </>\n  )\n}\nModals\n\nParallel Routes can be used together with Intercepting Routes to create modals that support deep linking. This allows you to solve common challenges when building modals, such as:\n\nMaking the modal content shareable through a URL.\nPreserving context when the page is refreshed, instead of closing the modal.\nClosing the modal on backwards navigation rather than going to the previous route.\nReopening the modal on forwards navigation.\n\nConsider the following UI pattern, where a user can open a login modal from a layout using client-side navigation, or access a separate /login page:\n\nTo implement this pattern, start by creating a /login route that renders your main login page.\n\napp/login/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Login } from '@/app/ui/login'\n \nexport default function Page() {\n  return <Login />\n}\n\nThen, inside the @auth slot, add default.js file that returns null. This ensures that the modal is not rendered when it's not active.\n\napp/@auth/default.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Default() {\n  return null\n}\n\nInside your @auth slot, intercept the /login route by importing the <Modal> component and its children into the @auth/(.)login/page.tsx file, and updating the folder name to /@auth/(.)login/page.tsx.\n\napp/@auth/(.)login/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Modal } from '@/app/ui/modal'\nimport { Login } from '@/app/ui/login'\n \nexport default function Page() {\n  return (\n    <Modal>\n      <Login />\n    </Modal>\n  )\n}\n\nGood to know:\n\nThe convention (.) is used for intercepting routes. See Intercepting Routes docs for more information.\nBy separating the <Modal> functionality from the modal content (<Login>), you can ensure any content inside the modal, e.g. forms, are Server Components. See Interleaving Client and Server Components for more information.\nOpening the modal\n\nNow, you can leverage the Next.js router to open and close the modal. This ensures the URL is correctly updated when the modal is open, and when navigating backwards and forwards.\n\nTo open the modal, pass the @auth slot as a prop to the parent layout and render it alongside the children prop.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Layout({\n  auth,\n  children,\n}: {\n  auth: React.ReactNode\n  children: React.ReactNode\n}) {\n  return (\n    <>\n      <nav>\n        <Link href=\"/login\">Open modal</Link>\n      </nav>\n      <div>{auth}</div>\n      <div>{children}</div>\n    </>\n  )\n}\n\nWhen the user clicks the <Link>, the modal will open instead of navigating to the /login page. However, on refresh or initial load, navigating to /login will take the user to the main login page.\n\nClosing the modal\n\nYou can close the modal by calling router.back() or by using the Link component.\n\napp/ui/modal.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useRouter } from 'next/navigation'\n \nexport function Modal({ children }: { children: React.ReactNode }) {\n  const router = useRouter()\n \n  return (\n    <>\n      <button\n        onClick={() => {\n          router.back()\n        }}\n      >\n        Close modal\n      </button>\n      <div>{children}</div>\n    </>\n  )\n}\n\nWhen using the Link component to navigate away from a page that shouldn't render the @auth slot anymore, we need to make sure the parallel route matches to a component that returns null. For example, when navigating back to the root page, we create a @auth/page.tsx component:\n\napp/ui/modal.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport function Modal({ children }: { children: React.ReactNode }) {\n  return (\n    <>\n      <Link href=\"/\">Close modal</Link>\n      <div>{children}</div>\n    </>\n  )\n}\napp/@auth/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Page() {\n  return null\n}\n\nOr if navigating to any other page (such as /foo, /foo/bar, etc), you can use a catch-all slot:\n\napp/@auth/[...catchAll]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function CatchAll() {\n  return null\n}\n\nGood to know:\n\nWe use a catch-all route in our @auth slot to close the modal because of how parallel routes behave. Since client-side navigations to a route that no longer match the slot will remain visible, we need to match the slot to a route that returns null to close the modal.\nOther examples could include opening a photo modal in a gallery while also having a dedicated /photo/[id] page, or opening a shopping cart in a side modal.\nView an example\n of modals with Intercepted and Parallel Routes.\nLoading and Error UI\n\nParallel Routes can be streamed independently, allowing you to define independent error and loading states for each route:\n\nSee the Loading UI and Error Handling documentation for more information.\n\nNext Steps\ndefault.js\nAPI Reference for the default.js file.\nPrevious\npage.js\nNext\nproxy.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: proxy.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/proxy",
    "html": "API Reference\nFile-system conventions\nproxy.js\nCopy page\nproxy.js\n\nNote: The middleware file convention is deprecated and has been renamed to proxy. See Migration to Proxy for more details.\n\nThe proxy.js|ts file is used to write Proxy and run code on the server before a request is completed. Then, based on the incoming request, you can modify the response by rewriting, redirecting, modifying the request or response headers, or responding directly.\n\nProxy executes before routes are rendered. It's particularly useful for implementing custom server-side logic like authentication, logging, or handling redirects.\n\nGood to know:\n\nProxy is meant to be invoked separately of your render code and in optimized cases deployed to your CDN for fast redirect/rewrite handling, you should not attempt relying on shared modules or globals.\n\nTo pass information from Proxy to your application, use headers, cookies, rewrites, redirects, or the URL.\n\nCreate a proxy.ts (or .js) file in the project root, or inside src if applicable, so that it is located at the same level as pages or app.\n\nIf you’ve customized pageExtensions, for example to .page.ts or .page.js, name your file proxy.page.ts or proxy.page.js accordingly.\n\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse, NextRequest } from 'next/server'\n \n// This function can be marked `async` if using `await` inside\nexport function proxy(request: NextRequest) {\n  return NextResponse.redirect(new URL('/home', request.url))\n}\n \nexport const config = {\n  matcher: '/about/:path*',\n}\nExports\nProxy function\n\nThe file must export a single function, either as a default export or named proxy. Note that multiple proxy from the same file are not supported.\n\nproxy.js\n// Example of default export\nexport default function proxy(request) {\n  // Proxy logic\n}\nConfig object (optional)\n\nOptionally, a config object can be exported alongside the Proxy function. This object includes the matcher to specify paths where the Proxy applies.\n\nMatcher\n\nThe matcher option allows you to target specific paths for the Proxy to run on. You can specify these paths in several ways:\n\nFor a single path: Directly use a string to define the path, like '/about'.\nFor multiple paths: Use an array to list multiple paths, such as matcher: ['/about', '/contact'], which applies the Proxy to both /about and /contact.\nproxy.js\nexport const config = {\n  matcher: ['/about/:path*', '/dashboard/:path*'],\n}\n\nAdditionally, the matcher option supports complex path specifications through regular expressions, such as matcher: ['/((?!api|_next/static|_next/image|.*\\\\.png$).*)'], enabling precise control over which paths to include or exclude.\n\nThe matcher option accepts an array of objects with the following keys:\n\nsource: The path or pattern used to match the request paths. It can be a string for direct path matching or a pattern for more complex matching.\nregexp (optional): A regular expression string that fine-tunes the matching based on the source. It provides additional control over which paths are included or excluded.\nlocale (optional): A boolean that, when set to false, ignores locale-based routing in path matching.\nhas (optional): Specifies conditions based on the presence of specific request elements such as headers, query parameters, or cookies.\nmissing (optional): Focuses on conditions where certain request elements are absent, like missing headers or cookies.\nproxy.js\nexport const config = {\n  matcher: [\n    {\n      source: '/api/*',\n      regexp: '^/api/(.*)',\n      locale: false,\n      has: [\n        { type: 'header', key: 'Authorization', value: 'Bearer Token' },\n        { type: 'query', key: 'userId', value: '123' },\n      ],\n      missing: [{ type: 'cookie', key: 'session', value: 'active' }],\n    },\n  ],\n}\n\nConfigured matchers:\n\nMUST start with /\nCan include named parameters: /about/:path matches /about/a and /about/b but not /about/a/c\nCan have modifiers on named parameters (starting with :): /about/:path* matches /about/a/b/c because * is zero or more. ? is zero or one and + one or more\nCan use regular expression enclosed in parenthesis: /about/(.*) is the same as /about/:path*\n\nRead more details on path-to-regexp\n documentation.\n\nGood to know:\n\nThe matcher values need to be constants so they can be statically analyzed at build-time. Dynamic values such as variables will be ignored.\nFor backward compatibility, Next.js always considers /public as /public/index. Therefore, a matcher of /public/:path will match.\nParams\nrequest\n\nWhen defining Proxy, the default export function accepts a single parameter, request. This parameter is an instance of NextRequest, which represents the incoming HTTP request.\n\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextRequest } from 'next/server'\n \nexport function proxy(request: NextRequest) {\n  // Proxy logic goes here\n}\n\nGood to know:\n\nNextRequest is a type that represents incoming HTTP requests in Next.js Proxy, whereas NextResponse is a class used to manipulate and send back HTTP responses.\nNextResponse\n\nThe NextResponse API allows you to:\n\nredirect the incoming request to a different URL\nrewrite the response by displaying a given URL\nSet request headers for API Routes, getServerSideProps, and rewrite destinations\nSet response cookies\nSet response headers\n\nTo produce a response from Proxy, you can:\n\nrewrite to a route (Page or Route Handler) that produces a response\nreturn a NextResponse directly. See Producing a Response\n\nGood to know: For redirects, you can also use Response.redirect instead of NextResponse.redirect.\n\nExecution order\n\nProxy will be invoked for every route in your project. Given this, it's crucial to use matchers to precisely target or exclude specific routes. The following is the execution order:\n\nheaders from next.config.js\nredirects from next.config.js\nProxy (rewrites, redirects, etc.)\nbeforeFiles (rewrites) from next.config.js\nFilesystem routes (public/, _next/static/, pages/, app/, etc.)\nafterFiles (rewrites) from next.config.js\nDynamic Routes (/blog/[slug])\nfallback (rewrites) from next.config.js\nRuntime\n\nProxy defaults to using the Node.js runtime. The runtime config option is not available in Proxy files. Setting the runtime config option in Proxy will throw an error.\n\nAdvanced Proxy flags\n\nIn v13.1 of Next.js two additional flags were introduced for proxy, skipMiddlewareUrlNormalize and skipTrailingSlashRedirect to handle advanced use cases.\n\nskipTrailingSlashRedirect disables Next.js redirects for adding or removing trailing slashes. This allows custom handling inside proxy to maintain the trailing slash for some paths but not others, which can make incremental migrations easier.\n\nnext.config.js\nmodule.exports = {\n  skipTrailingSlashRedirect: true,\n}\nproxy.js\nconst legacyPrefixes = ['/docs', '/blog']\n \nexport default async function proxy(req) {\n  const { pathname } = req.nextUrl\n \n  if (legacyPrefixes.some((prefix) => pathname.startsWith(prefix))) {\n    return NextResponse.next()\n  }\n \n  // apply trailing slash handling\n  if (\n    !pathname.endsWith('/') &&\n    !pathname.match(/((?!\\.well-known(?:\\/.*)?)(?:[^/]+\\/)*[^/]+\\.\\w+)/)\n  ) {\n    return NextResponse.redirect(\n      new URL(`${req.nextUrl.pathname}/`, req.nextUrl)\n    )\n  }\n}\n\nskipMiddlewareUrlNormalize allows for disabling the URL normalization in Next.js to make handling direct visits and client-transitions the same. In some advanced cases, this option provides full control by using the original URL.\n\nnext.config.js\nmodule.exports = {\n  skipMiddlewareUrlNormalize: true,\n}\nproxy.js\nexport default async function proxy(req) {\n  const { pathname } = req.nextUrl\n \n  // GET /_next/data/build-id/hello.json\n \n  console.log(pathname)\n  // with the flag this now /_next/data/build-id/hello.json\n  // without the flag this would be normalized to /hello\n}\nExamples\nConditional Statements\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\n \nexport function proxy(request: NextRequest) {\n  if (request.nextUrl.pathname.startsWith('/about')) {\n    return NextResponse.rewrite(new URL('/about-2', request.url))\n  }\n \n  if (request.nextUrl.pathname.startsWith('/dashboard')) {\n    return NextResponse.rewrite(new URL('/dashboard/user', request.url))\n  }\n}\nUsing Cookies\n\nCookies are regular headers. On a Request, they are stored in the Cookie header. On a Response they are in the Set-Cookie header. Next.js provides a convenient way to access and manipulate these cookies through the cookies extension on NextRequest and NextResponse.\n\nFor incoming requests, cookies comes with the following methods: get, getAll, set, and delete cookies. You can check for the existence of a cookie with has or remove all cookies with clear.\nFor outgoing responses, cookies have the following methods get, getAll, set, and delete.\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\n \nexport function proxy(request: NextRequest) {\n  // Assume a \"Cookie:nextjs=fast\" header to be present on the incoming request\n  // Getting cookies from the request using the `RequestCookies` API\n  let cookie = request.cookies.get('nextjs')\n  console.log(cookie) // => { name: 'nextjs', value: 'fast', Path: '/' }\n  const allCookies = request.cookies.getAll()\n  console.log(allCookies) // => [{ name: 'nextjs', value: 'fast' }]\n \n  request.cookies.has('nextjs') // => true\n  request.cookies.delete('nextjs')\n  request.cookies.has('nextjs') // => false\n \n  // Setting cookies on the response using the `ResponseCookies` API\n  const response = NextResponse.next()\n  response.cookies.set('vercel', 'fast')\n  response.cookies.set({\n    name: 'vercel',\n    value: 'fast',\n    path: '/',\n  })\n  cookie = response.cookies.get('vercel')\n  console.log(cookie) // => { name: 'vercel', value: 'fast', Path: '/' }\n  // The outgoing response will have a `Set-Cookie:vercel=fast;path=/` header.\n \n  return response\n}\nSetting Headers\n\nYou can set request and response headers using the NextResponse API (setting request headers is available since Next.js v13.0.0).\n\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\n \nexport function proxy(request: NextRequest) {\n  // Clone the request headers and set a new header `x-hello-from-proxy1`\n  const requestHeaders = new Headers(request.headers)\n  requestHeaders.set('x-hello-from-proxy1', 'hello')\n \n  // You can also set request headers in NextResponse.next\n  const response = NextResponse.next({\n    request: {\n      // New request headers\n      headers: requestHeaders,\n    },\n  })\n \n  // Set a new response header `x-hello-from-proxy2`\n  response.headers.set('x-hello-from-proxy2', 'hello')\n  return response\n}\n\nNote that the snippet uses:\n\nNextResponse.next({ request: { headers: requestHeaders } }) to make requestHeaders available upstream\nNOT NextResponse.next({ headers: requestHeaders }) which makes requestHeaders available to clients\n\nLearn more in NextResponse headers in Proxy.\n\nGood to know: Avoid setting large headers as it might cause 431 Request Header Fields Too Large\n error depending on your backend web server configuration.\n\nCORS\n\nYou can set CORS headers in Proxy to allow cross-origin requests, including simple\n and preflighted\n requests.\n\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextRequest, NextResponse } from 'next/server'\n \nconst allowedOrigins = ['https://acme.com', 'https://my-app.org']\n \nconst corsOptions = {\n  'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n  'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n}\n \nexport function proxy(request: NextRequest) {\n  // Check the origin from the request\n  const origin = request.headers.get('origin') ?? ''\n  const isAllowedOrigin = allowedOrigins.includes(origin)\n \n  // Handle preflighted requests\n  const isPreflight = request.method === 'OPTIONS'\n \n  if (isPreflight) {\n    const preflightHeaders = {\n      ...(isAllowedOrigin && { 'Access-Control-Allow-Origin': origin }),\n      ...corsOptions,\n    }\n    return NextResponse.json({}, { headers: preflightHeaders })\n  }\n \n  // Handle simple requests\n  const response = NextResponse.next()\n \n  if (isAllowedOrigin) {\n    response.headers.set('Access-Control-Allow-Origin', origin)\n  }\n \n  Object.entries(corsOptions).forEach(([key, value]) => {\n    response.headers.set(key, value)\n  })\n \n  return response\n}\n \nexport const config = {\n  matcher: '/api/:path*',\n}\n\nGood to know: You can configure CORS headers for individual routes in Route Handlers.\n\nProducing a response\n\nYou can respond from Proxy directly by returning a Response or NextResponse instance. (This is available since Next.js v13.1.0\n)\n\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextRequest } from 'next/server'\nimport { isAuthenticated } from '@lib/auth'\n \n// Limit the proxy to paths starting with `/api/`\nexport const config = {\n  matcher: '/api/:function*',\n}\n \nexport function proxy(request: NextRequest) {\n  // Call our authentication function to check the request\n  if (!isAuthenticated(request)) {\n    // Respond with JSON indicating an error message\n    return Response.json(\n      { success: false, message: 'authentication failed' },\n      { status: 401 }\n    )\n  }\n}\nNegative matching\n\nThe matcher config allows full regex so matching like negative lookaheads or character matching is supported. An example of a negative lookahead to match all except specific paths can be seen here:\n\nproxy.js\nexport const config = {\n  matcher: [\n    /*\n     * Match all request paths except for the ones starting with:\n     * - api (API routes)\n     * - _next/static (static files)\n     * - _next/image (image optimization files)\n     * - favicon.ico, sitemap.xml, robots.txt (metadata files)\n     */\n    '/((?!api|_next/static|_next/image|favicon.ico|sitemap.xml|robots.txt).*)',\n  ],\n}\n\nYou can also bypass Proxy for certain requests by using the missing or has arrays, or a combination of both:\n\nproxy.js\nexport const config = {\n  matcher: [\n    /*\n     * Match all request paths except for the ones starting with:\n     * - api (API routes)\n     * - _next/static (static files)\n     * - _next/image (image optimization files)\n     * - favicon.ico, sitemap.xml, robots.txt (metadata files)\n     */\n    {\n      source:\n        '/((?!api|_next/static|_next/image|favicon.ico|sitemap.xml|robots.txt).*)',\n      missing: [\n        { type: 'header', key: 'next-router-prefetch' },\n        { type: 'header', key: 'purpose', value: 'prefetch' },\n      ],\n    },\n \n    {\n      source:\n        '/((?!api|_next/static|_next/image|favicon.ico|sitemap.xml|robots.txt).*)',\n      has: [\n        { type: 'header', key: 'next-router-prefetch' },\n        { type: 'header', key: 'purpose', value: 'prefetch' },\n      ],\n    },\n \n    {\n      source:\n        '/((?!api|_next/static|_next/image|favicon.ico|sitemap.xml|robots.txt).*)',\n      has: [{ type: 'header', key: 'x-present' }],\n      missing: [{ type: 'header', key: 'x-missing', value: 'prefetch' }],\n    },\n  ],\n}\nwaitUntil and NextFetchEvent\n\nThe NextFetchEvent object extends the native FetchEvent\n object, and includes the waitUntil()\n method.\n\nThe waitUntil() method takes a promise as an argument, and extends the lifetime of the Proxy until the promise settles. This is useful for performing work in the background.\n\nproxy.ts\nimport { NextResponse } from 'next/server'\nimport type { NextFetchEvent, NextRequest } from 'next/server'\n \nexport function proxy(req: NextRequest, event: NextFetchEvent) {\n  event.waitUntil(\n    fetch('https://my-analytics-platform.com', {\n      method: 'POST',\n      body: JSON.stringify({ pathname: req.nextUrl.pathname }),\n    })\n  )\n \n  return NextResponse.next()\n}\nUnit testing (experimental)\n\nStarting in Next.js 15.1, the next/experimental/testing/server package contains utilities to help unit test proxy files. Unit testing proxy can help ensure that it's only run on desired paths and that custom routing logic works as intended before code reaches production.\n\nThe unstable_doesProxyMatch function can be used to assert whether proxy will run for the provided URL, headers, and cookies.\n\nimport { unstable_doesProxyMatch } from 'next/experimental/testing/server'\n \nexpect(\n  unstable_doesProxyMatch({\n    config,\n    nextConfig,\n    url: '/test',\n  })\n).toEqual(false)\n\nThe entire proxy function can also be tested.\n\nimport { isRewrite, getRewrittenUrl } from 'next/experimental/testing/server'\n \nconst request = new NextRequest('https://nextjs.org/docs')\nconst response = await proxy(request)\nexpect(isRewrite(response)).toEqual(true)\nexpect(getRewrittenUrl(response)).toEqual('https://other-domain.com/docs')\n// getRedirectUrl could also be used if the response were a redirect\nPlatform support\nDeployment Option\tSupported\nNode.js server\tYes\nDocker container\tYes\nStatic export\tNo\nAdapters\tPlatform-specific\n\nLearn how to configure Proxy when self-hosting Next.js.\n\nMigration to Proxy\nWhy the Change\n\nThe reason behind the renaming of middleware is that the term \"middleware\" can often be confused with Express.js middleware, leading to a misinterpretation of its purpose. Also, Middleware is highly capable, so it may encourage the usage; however, this feature is recommended to be used as a last resort.\n\nNext.js is moving forward to provide better APIs with better ergonomics so that developers can achieve their goals without Middleware. This is the reason behind the renaming of middleware.\n\nWhy \"Proxy\"\n\nThe name Proxy clarifies what Middleware is capable of. The term \"proxy\" implies that it has a network boundary in front of the app, which is the behavior of Middleware. Also, Middleware defaults to run at the Edge Runtime, which can run closer to the client, separated from the app's region. These behaviors align better with the term \"proxy\" and provide a clearer purpose of the feature.\n\nHow to Migrate\n\nWe recommend users avoid relying on Middleware unless no other options exist. Our goal is to give them APIs with better ergonomics so they can achieve their goals without Middleware.\n\nThe term “middleware” often confuses users with Express.js middleware, which can encourage misuse. To clarify our direction, we are renaming the file convention to “proxy.” This highlights that we are moving away from Middleware, breaking down its overloaded features, and making the Proxy clear in its purpose.\n\nNext.js provides a codemod to migrate from middleware.ts to proxy.ts. You can run the following command to migrate:\n\nnpx @next/codemod@canary middleware-to-proxy .\n\nThe codemod will rename the file and the function name from middleware to proxy.\n\n// middleware.ts -> proxy.ts\n \n- export function middleware() {\n+ export function proxy() {\nVersion history\nVersion\tChanges\nv16.0.0\tMiddleware is deprecated and renamed to Proxy\nv15.5.0\tMiddleware can now use the Node.js runtime (stable)\nv15.2.0\tMiddleware can now use the Node.js runtime (experimental)\nv13.1.0\tAdvanced Middleware flags added\nv13.0.0\tMiddleware can modify request headers, response headers, and send responses\nv12.2.0\tMiddleware is stable, please see the upgrade guide\nv12.0.9\tEnforce absolute URLs in Edge Runtime (PR\n)\nv12.0.0\tMiddleware (Beta) added\nLearn more about Proxy\nNextRequest\nAPI Reference for NextRequest.\nNextResponse\nAPI Reference for NextResponse.\nPrevious\nParallel Routes\nNext\npublic\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: public | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/public-folder",
    "html": "API Reference\nFile-system conventions\npublic\nCopy page\npublic Folder\n\nNext.js can serve static files, like images, under a folder called public in the root directory. Files inside public can then be referenced by your code starting from the base URL (/).\n\nFor example, the file public/avatars/me.png can be viewed by visiting the /avatars/me.png path. The code to display that image might look like:\n\navatar.js\nimport Image from 'next/image'\n \nexport function Avatar({ id, alt }) {\n  return <Image src={`/avatars/${id}.png`} alt={alt} width=\"64\" height=\"64\" />\n}\n \nexport function AvatarOfMe() {\n  return <Avatar id=\"me\" alt=\"A portrait of me\" />\n}\nCaching\n\nNext.js cannot safely cache assets in the public folder because they may change. The default caching headers applied are:\n\nCache-Control: public, max-age=0\nRobots, Favicons, and others\n\nFor static metadata files, such as robots.txt, favicon.ico, etc, you should use special metadata files inside the app folder.\n\nPrevious\nproxy.js\nNext\nroute.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: route.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/route",
    "html": "API Reference\nFile-system conventions\nroute.js\nCopy page\nroute.js\n\nRoute Handlers allow you to create custom request handlers for a given route using the Web Request\n and Response\n APIs.\n\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET() {\n  return Response.json({ message: 'Hello World' })\n}\nReference\nHTTP Methods\n\nA route file allows you to create custom request handlers for a given route. The following HTTP methods\n are supported: GET, POST, PUT, PATCH, DELETE, HEAD, and OPTIONS.\n\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET(request: Request) {}\n \nexport async function HEAD(request: Request) {}\n \nexport async function POST(request: Request) {}\n \nexport async function PUT(request: Request) {}\n \nexport async function DELETE(request: Request) {}\n \nexport async function PATCH(request: Request) {}\n \n// If `OPTIONS` is not defined, Next.js will automatically implement `OPTIONS` and set the appropriate Response `Allow` header depending on the other methods defined in the Route Handler.\nexport async function OPTIONS(request: Request) {}\nParameters\nrequest (optional)\n\nThe request object is a NextRequest object, which is an extension of the Web Request\n API. NextRequest gives you further control over the incoming request, including easily accessing cookies and an extended, parsed, URL object nextUrl.\n\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextRequest } from 'next/server'\n \nexport async function GET(request: NextRequest) {\n  const url = request.nextUrl\n}\ncontext (optional)\nparams: a promise that resolves to an object containing the dynamic route parameters for the current route.\napp/dashboard/[team]/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET(\n  request: Request,\n  { params }: { params: Promise<{ team: string }> }\n) {\n  const { team } = await params\n}\nExample\tURL\tparams\napp/dashboard/[team]/route.js\t/dashboard/1\tPromise<{ team: '1' }>\napp/shop/[tag]/[item]/route.js\t/shop/1/2\tPromise<{ tag: '1', item: '2' }>\napp/blog/[...slug]/route.js\t/blog/1/2\tPromise<{ slug: ['1', '2'] }>\nRoute Context Helper\n\nYou can type the Route Handler context using RouteContext to get strongly typed params from a route literal. RouteContext is a globally available helper.\n\napp/users/[id]/route.ts\nimport type { NextRequest } from 'next/server'\n \nexport async function GET(_req: NextRequest, ctx: RouteContext<'/users/[id]'>) {\n  const { id } = await ctx.params\n  return Response.json({ id })\n}\n\nGood to know\n\nTypes are generated during next dev, next build or next typegen.\nAfter type generation, the RouteContext helper is globally available. It doesn't need to be imported.\nExamples\nCookies\n\nYou can read or set cookies with cookies from next/headers.\n\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport async function GET(request: NextRequest) {\n  const cookieStore = await cookies()\n \n  const a = cookieStore.get('a')\n  const b = cookieStore.set('b', '1')\n  const c = cookieStore.delete('c')\n}\n\nAlternatively, you can return a new Response using the Set-Cookie\n header.\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport async function GET(request: Request) {\n  const cookieStore = await cookies()\n  const token = cookieStore.get('token')\n \n  return new Response('Hello, Next.js!', {\n    status: 200,\n    headers: { 'Set-Cookie': `token=${token.value}` },\n  })\n}\n\nYou can also use the underlying Web APIs to read cookies from the request (NextRequest):\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { type NextRequest } from 'next/server'\n \nexport async function GET(request: NextRequest) {\n  const token = request.cookies.get('token')\n}\nHeaders\n\nYou can read headers with headers from next/headers.\n\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nimport { headers } from 'next/headers'\nimport type { NextRequest } from 'next/server'\n \nexport async function GET(request: NextRequest) {\n  const headersList = await headers()\n  const referer = headersList.get('referer')\n}\n\nThis headers instance is read-only. To set headers, you need to return a new Response with new headers.\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { headers } from 'next/headers'\n \nexport async function GET(request: Request) {\n  const headersList = await headers()\n  const referer = headersList.get('referer')\n \n  return new Response('Hello, Next.js!', {\n    status: 200,\n    headers: { referer: referer },\n  })\n}\n\nYou can also use the underlying Web APIs to read headers from the request (NextRequest):\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { type NextRequest } from 'next/server'\n \nexport async function GET(request: NextRequest) {\n  const requestHeaders = new Headers(request.headers)\n}\nRevalidating Cached Data\n\nYou can revalidate cached data using the revalidate route segment config option.\n\napp/posts/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const revalidate = 60\n \nexport async function GET() {\n  const data = await fetch('https://api.vercel.app/blog')\n  const posts = await data.json()\n \n  return Response.json(posts)\n}\nRedirects\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { redirect } from 'next/navigation'\n \nexport async function GET(request: Request) {\n  redirect('https://nextjs.org/')\n}\nDynamic Route Segments\n\nRoute Handlers can use Dynamic Segments to create request handlers from dynamic data.\n\napp/items/[slug]/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET(\n  request: Request,\n  { params }: { params: Promise<{ slug: string }> }\n) {\n  const { slug } = await params // 'a', 'b', or 'c'\n}\nRoute\tExample URL\tparams\napp/items/[slug]/route.js\t/items/a\tPromise<{ slug: 'a' }>\napp/items/[slug]/route.js\t/items/b\tPromise<{ slug: 'b' }>\napp/items/[slug]/route.js\t/items/c\tPromise<{ slug: 'c' }>\nURL Query Parameters\n\nThe request object passed to the Route Handler is a NextRequest instance, which includes some additional convenience methods, such as those for more easily handling query parameters.\n\napp/api/search/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { type NextRequest } from 'next/server'\n \nexport function GET(request: NextRequest) {\n  const searchParams = request.nextUrl.searchParams\n  const query = searchParams.get('query')\n  // query is \"hello\" for /api/search?query=hello\n}\nStreaming\n\nStreaming is commonly used in combination with Large Language Models (LLMs), such as OpenAI, for AI-generated content. Learn more about the AI SDK\n.\n\napp/api/chat/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { openai } from '@ai-sdk/openai'\nimport { StreamingTextResponse, streamText } from 'ai'\n \nexport async function POST(req: Request) {\n  const { messages } = await req.json()\n  const result = await streamText({\n    model: openai('gpt-4-turbo'),\n    messages,\n  })\n \n  return new StreamingTextResponse(result.toAIStream())\n}\n\nThese abstractions use the Web APIs to create a stream. You can also use the underlying Web APIs directly.\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\n// https://developer.mozilla.org/docs/Web/API/ReadableStream#convert_async_iterator_to_stream\nfunction iteratorToStream(iterator: any) {\n  return new ReadableStream({\n    async pull(controller) {\n      const { value, done } = await iterator.next()\n \n      if (done) {\n        controller.close()\n      } else {\n        controller.enqueue(value)\n      }\n    },\n  })\n}\n \nfunction sleep(time: number) {\n  return new Promise((resolve) => {\n    setTimeout(resolve, time)\n  })\n}\n \nconst encoder = new TextEncoder()\n \nasync function* makeIterator() {\n  yield encoder.encode('<p>One</p>')\n  await sleep(200)\n  yield encoder.encode('<p>Two</p>')\n  await sleep(200)\n  yield encoder.encode('<p>Three</p>')\n}\n \nexport async function GET() {\n  const iterator = makeIterator()\n  const stream = iteratorToStream(iterator)\n \n  return new Response(stream)\n}\nRequest Body\n\nYou can read the Request body using the standard Web API methods:\n\napp/items/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function POST(request: Request) {\n  const res = await request.json()\n  return Response.json({ res })\n}\nRequest Body FormData\n\nYou can read the FormData using the request.formData() function:\n\napp/items/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function POST(request: Request) {\n  const formData = await request.formData()\n  const name = formData.get('name')\n  const email = formData.get('email')\n  return Response.json({ name, email })\n}\n\nSince formData data are all strings, you may want to use zod-form-data\n to validate the request and retrieve data in the format you prefer (e.g. number).\n\nCORS\n\nYou can set CORS headers for a specific Route Handler using the standard Web API methods:\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET(request: Request) {\n  return new Response('Hello, Next.js!', {\n    status: 200,\n    headers: {\n      'Access-Control-Allow-Origin': '*',\n      'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',\n      'Access-Control-Allow-Headers': 'Content-Type, Authorization',\n    },\n  })\n}\n\nGood to know:\n\nTo add CORS headers to multiple Route Handlers, you can use Proxy or the next.config.js file.\nWebhooks\n\nYou can use a Route Handler to receive webhooks from third-party services:\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function POST(request: Request) {\n  try {\n    const text = await request.text()\n    // Process the webhook payload\n  } catch (error) {\n    return new Response(`Webhook error: ${error.message}`, {\n      status: 400,\n    })\n  }\n \n  return new Response('Success!', {\n    status: 200,\n  })\n}\n\nNotably, unlike API Routes with the Pages Router, you do not need to use bodyParser to use any additional configuration.\n\nNon-UI Responses\n\nYou can use Route Handlers to return non-UI content. Note that sitemap.xml, robots.txt, app icons, and open graph images all have built-in support.\n\napp/rss.xml/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET() {\n  return new Response(\n    `<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<rss version=\"2.0\">\n \n<channel>\n  <title>Next.js Documentation</title>\n  <link>https://nextjs.org/docs</link>\n  <description>The React Framework for the Web</description>\n</channel>\n \n</rss>`,\n    {\n      headers: {\n        'Content-Type': 'text/xml',\n      },\n    }\n  )\n}\nSegment Config Options\n\nRoute Handlers use the same route segment configuration as pages and layouts.\n\napp/items/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const dynamic = 'auto'\nexport const dynamicParams = true\nexport const revalidate = false\nexport const fetchCache = 'auto'\nexport const runtime = 'nodejs'\nexport const preferredRegion = 'auto'\n\nSee the API reference for more details.\n\nVersion History\nVersion\tChanges\nv15.0.0-RC\tcontext.params is now a promise. A codemod is available\nv15.0.0-RC\tThe default caching for GET handlers was changed from static to dynamic\nv13.2.0\tRoute Handlers are introduced.\nPrevious\npublic\nNext\nRoute Groups\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: Route Groups | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/route-groups",
    "html": "API Reference\nFile-system conventions\nRoute Groups\nCopy page\nRoute Groups\n\nRoute Groups are a folder convention that let you organize routes by category or team.\n\nConvention\n\nA route group can be created by wrapping a folder's name in parenthesis: (folderName).\n\nThis convention indicates the folder is for organizational purposes and should not be included in the route's URL path.\n\nUse cases\nOrganizing routes by team, concern, or feature.\nDefining multiple root layouts.\nOpting specific route segments into sharing a layout, while keeping others out.\nCaveats\nFull page load: If you navigate between routes that use different root layouts, it'll trigger a full page reload. For example, navigating from /cart that uses app/(shop)/layout.js to /blog that uses app/(marketing)/layout.js. This only applies to multiple root layouts.\nConflicting paths: Routes in different groups should not resolve to the same URL path. For example, (marketing)/about/page.js and (shop)/about/page.js would both resolve to /about and cause an error.\nTop-level root layout: If you use multiple root layouts without a top-level layout.js file, make sure your home route (/) is defined within one of the route groups, e.g. app/(marketing)/page.js.\nPrevious\nroute.js\nNext\nRoute Segment Config\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: Route Segment Config | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/route-segment-config",
    "html": "API Reference\nFile-system conventions\nRoute Segment Config\nCopy page\nRoute Segment Config\n\nGood to know:\n\nThe options outlined on this page are disabled if the cacheComponents flag is on, and will eventually be deprecated in the future.\nRoute Segment options only take effect in Server Component Pages, Layouts, or Route Handlers.\ngenerateStaticParams cannot be used inside a 'use client' file.\n\nThe Route Segment options allows you to configure the behavior of a Page, Layout, or Route Handler by directly exporting the following variables:\n\nOption\tType\tDefault\ndynamic\t'auto' | 'force-dynamic' | 'error' | 'force-static'\t'auto'\ndynamicParams\tboolean\ttrue\nrevalidate\tfalse | 0 | number\tfalse\nfetchCache\t'auto' | 'default-cache' | 'only-cache' | 'force-cache' | 'force-no-store' | 'default-no-store' | 'only-no-store'\t'auto'\nruntime\t'nodejs' | 'edge'\t'nodejs'\npreferredRegion\t'auto' | 'global' | 'home' | string | string[]\t'auto'\nmaxDuration\tnumber\tSet by deployment platform\nOptions\ndynamic\n\nChange the dynamic behavior of a layout or page to fully static or fully dynamic.\n\nlayout.tsx | page.tsx | route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const dynamic = 'auto'\n// 'auto' | 'force-dynamic' | 'error' | 'force-static'\n\nGood to know: The new model in the app directory favors granular caching control at the fetch request level over the binary all-or-nothing model of getServerSideProps and getStaticProps at the page-level in the pages directory. The dynamic option is a way to opt back in to the previous model as a convenience and provides a simpler migration path.\n\n'auto' (default): The default option to cache as much as possible without preventing any components from opting into dynamic behavior.\n\n'force-dynamic': Force dynamic rendering, which will result in routes being rendered for each user at request time. This option is equivalent to:\n\nSetting the option of every fetch() request in a layout or page to { cache: 'no-store', next: { revalidate: 0 } }.\nSetting the segment config to export const fetchCache = 'force-no-store'\n\n'error': Force static rendering and cache the data of a layout or page by causing an error if any components use Dynamic APIs or uncached data. This option is equivalent to:\n\ngetStaticProps() in the pages directory.\nSetting the option of every fetch() request in a layout or page to { cache: 'force-cache' }.\nSetting the segment config to fetchCache = 'only-cache'.\n\n'force-static': Force static rendering and cache the data of a layout or page by forcing cookies, headers() and useSearchParams() to return empty values. It is possible to revalidate, revalidatePath, or revalidateTag, in pages or layouts rendered with force-static.\n\nGood to know:\n\nInstructions on how to migrate from getServerSideProps and getStaticProps to dynamic: 'force-dynamic' and dynamic: 'error' can be found in the upgrade guide.\ndynamicParams\n\nControl what happens when a dynamic segment is visited that was not generated with generateStaticParams.\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport const dynamicParams = true // true | false\ntrue (default): Dynamic segments not included in generateStaticParams are generated on demand.\nfalse: Dynamic segments not included in generateStaticParams will return a 404.\n\nGood to know:\n\nThis option replaces the fallback: true | false | blocking option of getStaticPaths in the pages directory.\nTo statically render all paths the first time they're visited, you'll need to return an empty array in generateStaticParams or utilize export const dynamic = 'force-static'.\nWhen dynamicParams = true, the segment uses Streaming Server Rendering.\nrevalidate\n\nSet the default revalidation time for a layout or page. This option does not override the revalidate value set by individual fetch requests.\n\nlayout.tsx | page.tsx | route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const revalidate = false\n// false | 0 | number\nfalse (default): The default heuristic to cache any fetch requests that set their cache option to 'force-cache' or are discovered before a Dynamic API is used. Semantically equivalent to revalidate: Infinity which effectively means the resource should be cached indefinitely. It is still possible for individual fetch requests to use cache: 'no-store' or revalidate: 0 to avoid being cached and make the route dynamically rendered. Or set revalidate to a positive number lower than the route default to increase the revalidation frequency of a route.\n0: Ensure a layout or page is always dynamically rendered even if no Dynamic APIs or uncached data fetches are discovered. This option changes the default of fetch requests that do not set a cache option to 'no-store' but leaves fetch requests that opt into 'force-cache' or use a positive revalidate as is.\nnumber: (in seconds) Set the default revalidation frequency of a layout or page to n seconds.\n\nGood to know:\n\nThe revalidate value needs to be statically analyzable. For example revalidate = 600 is valid, but revalidate = 60 * 10 is not.\nThe revalidate value is not available when using runtime = 'edge'.\nIn Development, Pages are always rendered on-demand and are never cached. This allows you to see changes immediately without waiting for a revalidation period to pass.\nRevalidation Frequency\nThe lowest revalidate across each layout and page of a single route will determine the revalidation frequency of the entire route. This ensures that child pages are revalidated as frequently as their parent layouts.\nIndividual fetch requests can set a lower revalidate than the route's default revalidate to increase the revalidation frequency of the entire route. This allows you to dynamically opt-in to more frequent revalidation for certain routes based on some criteria.\nfetchCache\nThis is an advanced option that should only be used if you specifically need to override the default behavior.\nruntime\n\nWe recommend using the Node.js runtime for rendering your application. This option cannot be used in Proxy.\n\nGood to know: Using runtime: 'edge' is not supported for Cache Components.\n\nlayout.tsx | page.tsx | route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const runtime = 'nodejs'\n// 'nodejs' | 'edge'\n'nodejs' (default)\n'edge'\npreferredRegion\nlayout.tsx | page.tsx | route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const preferredRegion = 'auto'\n// 'auto' | 'global' | 'home' | ['iad1', 'sfo1']\n\nSupport for preferredRegion, and regions supported, is dependent on your deployment platform.\n\nGood to know:\n\nIf a preferredRegion is not specified, it will inherit the option of the nearest parent layout.\nThe root layout defaults to all regions.\nmaxDuration\n\nBy default, Next.js does not limit the execution of server-side logic (rendering a page or handling an API). Deployment platforms can use maxDuration from the Next.js build output to add specific execution limits.\n\nNote: This setting requires Next.js 13.4.10 or higher.\n\nlayout.tsx | page.tsx | route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const maxDuration = 5\n\nGood to know:\n\nIf using Server Actions, set the maxDuration at the page level to change the default timeout of all Server Actions used on the page.\ngenerateStaticParams\n\nThe generateStaticParams function can be used in combination with dynamic route segments to define the list of route segment parameters that will be statically generated at build time instead of on-demand at request time.\n\nSee the API reference for more details.\n\nVersion History\nVersion\t\nv16.0.0\texport const experimental_ppr = true removed. A codemod is available.\nv15.0.0-RC\texport const runtime = \"experimental-edge\" deprecated. A codemod is available.\nPrevious\nRoute Groups\nNext\nsrc\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: src | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/src-folder",
    "html": "API Reference\nFile-system conventions\nsrc\nCopy page\nsrc Folder\n\nAs an alternative to having the special Next.js app or pages directories in the root of your project, Next.js also supports the common pattern of placing application code under the src folder.\n\nThis separates application code from project configuration files which mostly live in the root of a project, which is preferred by some individuals and teams.\n\nTo use the src folder, move the app Router folder or pages Router folder to src/app or src/pages respectively.\n\nGood to know:\n\nThe /public directory should remain in the root of your project.\nConfig files like package.json, next.config.js and tsconfig.json should remain in the root of your project.\n.env.* files should remain in the root of your project.\nsrc/app or src/pages will be ignored if app or pages are present in the root directory.\nIf you're using src, you'll probably also move other application folders such as /components or /lib.\nIf you're using Proxy, ensure it is placed inside the src folder.\nIf you're using Tailwind CSS, you'll need to add the /src prefix to the tailwind.config.js file in the content section\n.\nIf you are using TypeScript paths for imports such as @/*, you should update the paths object in tsconfig.json to include src/.\nNext Steps\nProject Structure\nLearn the folder and file conventions in Next.js, and how to organize your project.\nPrevious\nRoute Segment Config\nNext\ntemplate.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: template.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/template",
    "html": "API Reference\nFile-system conventions\ntemplate.js\nCopy page\ntemplate.js\n\nA template file is similar to a layout in that it wraps a layout or page. Unlike layouts that persist across routes and maintain state, templates are given a unique key, meaning children Client Components reset their state on navigation.\n\nThey are useful when you need to:\n\nResynchronize useEffect on navigation.\nReset the state of a child Client Components on navigation. For example, an input field.\nTo change default framework behavior. For example, Suspense boundaries inside layouts only show a fallback on first load, while templates show it on every navigation.\nConvention\n\nA template can be defined by exporting a default React component from a template.js file. The component should accept a children prop.\n\napp/template.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Template({ children }: { children: React.ReactNode }) {\n  return <div>{children}</div>\n}\n\nIn terms of nesting, template.js is rendered between a layout and its children. Here's a simplified output:\n\nOutput\n<Layout>\n  {/* Note that the template is given a unique key. */}\n  <Template key={routeParam}>{children}</Template>\n</Layout>\nProps\nchildren (required)\n\nTemplate accepts a children prop.\n\nOutput\n<Layout>\n  {/* Note that the template is automatically given a unique key. */}\n  <Template key={routeParam}>{children}</Template>\n</Layout>\nBehavior\nServer Components: By default, templates are Server Components.\nWith navigation: Templates receive a unique key for their own segment level. They remount when that segment (including its dynamic params) changes. Navigations within deeper segments do not remount higher-level templates. Search params do not trigger remounts.\nState reset: Any Client Component inside the template will reset its state on navigation.\nEffect re-run: Effects like useEffect will re-synchronize as the component remounts.\nDOM reset: DOM elements inside the template are fully recreated.\nTemplates during navigation and remounting\n\nThis section illustrates how templates behave during navigation. It shows, step by step, which templates remount on each route change and why.\n\nUsing this project tree:\n\napp\n├── about\n│   ├── page.tsx\n├── blog\n│   ├── [slug]\n│   │   └── page.tsx\n│   ├── page.tsx\n│   └── template.tsx\n├── layout.tsx\n├── page.tsx\n└── template.tsx\n\n\nStarting at /, the React tree looks roughly like this.\n\nNote: The key values shown in the examples are illustrative, the values in your application may differ.\n\nOutput\n<RootLayout>\n  {/* app/template.tsx */}\n  <Template key=\"/\">\n    <Page />\n  </Template>\n</RootLayout>\n\nNavigating to /about (first segment changes), the root template key changes, it remounts:\n\nOutput\n<RootLayout>\n  {/* app/template.tsx */}\n  <Template key=\"/about\">\n    <AboutPage />\n  </Template>\n</RootLayout>\n\nNavigating to /blog (first segment changes), the root template key changes, it remounts and the blog-level template mounts:\n\nOutput\n<RootLayout>\n  {/* app/template.tsx (root) */}\n  <Template key=\"/blog\">\n    {/* app/blog/template.tsx */}\n    <Template key=\"/blog\">\n      <BlogIndexPage />\n    </Template>\n  </Template>\n</RootLayout>\n\nNavigating within the same first segment to /blog/first-post (child segment changes), the root template key doesn't change, but the blog-level template key changes, it remounts:\n\nOutput\n<RootLayout>\n  {/* app/template.tsx (root) */}\n  <Template key=\"/blog\">\n    {/* app/blog/template.tsx */}\n    {/* remounts because the child segment at this level changed */}\n    <Template key=\"/blog/first-post\">\n      <BlogPostPage slug=\"first-post\" />\n    </Template>\n  </Template>\n</RootLayout>\n\nNavigating to /blog/second-post (same first segment, different child segment), the root template key doesn't change, but the blog-level template key changes, it remounts again:\n\nOutput\n<RootLayout>\n  {/* app/template.tsx (root) */}\n  <Template key=\"/blog\">\n    {/* app/blog/template.tsx */}\n    {/* remounts again due to changed child segment */}\n    <Template key=\"/blog/second-post\">\n      <BlogPostPage slug=\"second-post\" />\n    </Template>\n  </Template>\n</RootLayout>\nVersion History\nVersion\tChanges\nv13.0.0\ttemplate introduced.\nPrevious\nsrc\nNext\nunauthorized.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: unauthorized.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/unauthorized",
    "html": "API Reference\nFile-system conventions\nunauthorized.js\nCopy page\nunauthorized.js\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe unauthorized file is used to render UI when the unauthorized function is invoked during authentication. Along with allowing you to customize the UI, Next.js will return a 401 status code.\n\napp/unauthorized.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Login from '@/app/components/Login'\n \nexport default function Unauthorized() {\n  return (\n    <main>\n      <h1>401 - Unauthorized</h1>\n      <p>Please log in to access this page.</p>\n      <Login />\n    </main>\n  )\n}\nReference\nProps\n\nunauthorized.js components do not accept any props.\n\nExamples\nDisplaying login UI to unauthenticated users\n\nYou can use unauthorized function to render the unauthorized.js file with a login UI.\n\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { verifySession } from '@/app/lib/dal'\nimport { unauthorized } from 'next/navigation'\n \nexport default async function DashboardPage() {\n  const session = await verifySession()\n \n  if (!session) {\n    unauthorized()\n  }\n \n  return <div>Dashboard</div>\n}\napp/unauthorized.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Login from '@/app/components/Login'\n \nexport default function UnauthorizedPage() {\n  return (\n    <main>\n      <h1>401 - Unauthorized</h1>\n      <p>Please log in to access this page.</p>\n      <Login />\n    </main>\n  )\n}\nVersion History\nVersion\tChanges\nv15.1.0\tunauthorized.js introduced.\nNext Steps\nunauthorized\nAPI Reference for the unauthorized function.\nPrevious\ntemplate.js\nNext\nMetadata Files\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "File-system conventions: Metadata Files | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/metadata",
    "html": "API Reference\nFile-system conventions\nMetadata Files\nCopy page\nMetadata Files API Reference\n\nThis section of the docs covers Metadata file conventions. File-based metadata can be defined by adding special metadata files to route segments.\n\nEach file convention can be defined using a static file (e.g. opengraph-image.jpg), or a dynamic variant that uses code to generate the file (e.g. opengraph-image.js).\n\nOnce a file is defined, Next.js will automatically serve the file (with hashes in production for caching) and update the relevant head elements with the correct metadata, such as the asset's URL, file type, and image size.\n\nGood to know:\n\nSpecial Route Handlers like sitemap.ts, opengraph-image.tsx, and icon.tsx, and other metadata files are cached by default.\nIf using along with proxy.ts, configure the matcher to exclude the metadata files.\nfavicon, icon, and apple-icon\nAPI Reference for the Favicon, Icon and Apple Icon file conventions.\nmanifest.json\nAPI Reference for manifest.json file.\nopengraph-image and twitter-image\nAPI Reference for the Open Graph Image and Twitter Image file conventions.\nrobots.txt\nAPI Reference for robots.txt file.\nsitemap.xml\nAPI Reference for the sitemap.xml file.\nPrevious\nunauthorized.js\nNext\nfavicon, icon, and apple-icon\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Metadata Files: favicon, icon, and apple-icon | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/metadata/app-icons",
    "html": "File-system conventions\nMetadata Files\nfavicon, icon, and apple-icon\nCopy page\nfavicon, icon, and apple-icon\n\nThe favicon, icon, or apple-icon file conventions allow you to set icons for your application.\n\nThey are useful for adding app icons that appear in places like web browser tabs, phone home screens, and search engine results.\n\nThere are two ways to set app icons:\n\nUsing image files (.ico, .jpg, .png)\nUsing code to generate an icon (.js, .ts, .tsx)\nImage files (.ico, .jpg, .png)\n\nUse an image file to set an app icon by placing a favicon, icon, or apple-icon image file within your /app directory. The favicon image can only be located in the top level of app/.\n\nNext.js will evaluate the file and automatically add the appropriate tags to your app's <head> element.\n\nFile convention\tSupported file types\tValid locations\nfavicon\t.ico\tapp/\nicon\t.ico, .jpg, .jpeg, .png, .svg\tapp/**/*\napple-icon\t.jpg, .jpeg, .png\tapp/**/*\nfavicon\n\nAdd a favicon.ico image file to the root /app route segment.\n\n<head> output\n<link rel=\"icon\" href=\"/favicon.ico\" sizes=\"any\" />\nicon\n\nAdd an icon.(ico|jpg|jpeg|png|svg) image file.\n\n<head> output\n<link\n  rel=\"icon\"\n  href=\"/icon?<generated>\"\n  type=\"image/<generated>\"\n  sizes=\"<generated>\"\n/>\napple-icon\n\nAdd an apple-icon.(jpg|jpeg|png) image file.\n\n<head> output\n<link\n  rel=\"apple-touch-icon\"\n  href=\"/apple-icon?<generated>\"\n  type=\"image/<generated>\"\n  sizes=\"<generated>\"\n/>\n\nGood to know:\n\nYou can set multiple icons by adding a number suffix to the file name. For example, icon1.png, icon2.png, etc. Numbered files will sort lexically.\nFavicons can only be set in the root /app segment. If you need more granularity, you can use icon.\nThe appropriate <link> tags and attributes such as rel, href, type, and sizes are determined by the icon type and metadata of the evaluated file.\nFor example, a 32 by 32px .png file will have type=\"image/png\" and sizes=\"32x32\" attributes.\nsizes=\"any\" is added to icons when the extension is .svg or the image size of the file is not determined. More details in this favicon handbook\n.\nGenerate icons using code (.js, .ts, .tsx)\n\nIn addition to using literal image files, you can programmatically generate icons using code.\n\nGenerate an app icon by creating an icon or apple-icon route that default exports a function.\n\nFile convention\tSupported file types\nicon\t.js, .ts, .tsx\napple-icon\t.js, .ts, .tsx\n\nThe easiest way to generate an icon is to use the ImageResponse API from next/og.\n\napp/icon.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\n \n// Image metadata\nexport const size = {\n  width: 32,\n  height: 32,\n}\nexport const contentType = 'image/png'\n \n// Image generation\nexport default function Icon() {\n  return new ImageResponse(\n    (\n      // ImageResponse JSX element\n      <div\n        style={{\n          fontSize: 24,\n          background: 'black',\n          width: '100%',\n          height: '100%',\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n          color: 'white',\n        }}\n      >\n        A\n      </div>\n    ),\n    // ImageResponse options\n    {\n      // For convenience, we can re-use the exported icons size metadata\n      // config to also set the ImageResponse's width and height.\n      ...size,\n    }\n  )\n}\n<head> output\n<link rel=\"icon\" href=\"/icon?<generated>\" type=\"image/png\" sizes=\"32x32\" />\n\nGood to know:\n\nBy default, generated icons are statically optimized (generated at build time and cached) unless they use Dynamic APIs or uncached data.\nYou can generate multiple icons in the same file using generateImageMetadata.\nYou cannot generate a favicon icon. Use icon or a favicon.ico file instead.\nApp icons are special Route Handlers that are cached by default unless they use a Dynamic API or dynamic config option.\nProps\n\nThe default export function receives the following props:\n\nparams (optional)\n\nA promise that resolves to an object containing the dynamic route parameters object from the root segment down to the segment icon or apple-icon is colocated in.\n\nGood to know: If you use generateImageMetadata, the function will also receive an id prop that is a promise resolving to the id value from one of the items returned by generateImageMetadata.\n\napp/shop/[slug]/icon.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Icon({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  // ...\n}\nRoute\tURL\tparams\napp/shop/icon.js\t/shop\tundefined\napp/shop/[slug]/icon.js\t/shop/1\tPromise<{ slug: '1' }>\napp/shop/[tag]/[item]/icon.js\t/shop/1/2\tPromise<{ tag: '1', item: '2' }>\nReturns\n\nThe default export function should return a Blob | ArrayBuffer | TypedArray | DataView | ReadableStream | Response.\n\nGood to know: ImageResponse satisfies this return type.\n\nConfig exports\n\nYou can optionally configure the icon's metadata by exporting size and contentType variables from the icon or apple-icon route.\n\nOption\tType\nsize\t{ width: number; height: number }\ncontentType\tstring - image MIME type\nsize\nicon.tsx | apple-icon.tsx\nTypeScript\nJavaScript\nTypeScript\nexport const size = { width: 32, height: 32 }\n \nexport default function Icon() {}\n<head> output\n<link rel=\"icon\" sizes=\"32x32\" />\ncontentType\nicon.tsx | apple-icon.tsx\nTypeScript\nJavaScript\nTypeScript\nexport const contentType = 'image/png'\n \nexport default function Icon() {}\n<head> output\n<link rel=\"icon\" type=\"image/png\" />\nRoute Segment Config\n\nicon and apple-icon are specialized Route Handlers that can use the same route segment configuration options as Pages and Layouts.\n\nVersion History\nVersion\tChanges\nv16.0.0\tparams is now a promise that resolves to an object\nv13.3.0\tfavicon icon and apple-icon introduced\nPrevious\nMetadata Files\nNext\nmanifest.json\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Metadata Files: manifest.json | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/metadata/manifest",
    "html": "File-system conventions\nMetadata Files\nmanifest.json\nCopy page\nmanifest.json\n\nAdd or generate a manifest.(json|webmanifest) file that matches the Web Manifest Specification\n in the root of app directory to provide information about your web application for the browser.\n\nStatic Manifest file\napp/manifest.json | app/manifest.webmanifest\n{\n  \"name\": \"My Next.js Application\",\n  \"short_name\": \"Next.js App\",\n  \"description\": \"An application built with Next.js\",\n  \"start_url\": \"/\"\n  // ...\n}\nGenerate a Manifest file\n\nAdd a manifest.js or manifest.ts file that returns a Manifest object.\n\nGood to know: manifest.js is special Route Handlers that is cached by default unless it uses a Dynamic API or dynamic config option.\n\napp/manifest.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\n \nexport default function manifest(): MetadataRoute.Manifest {\n  return {\n    name: 'Next.js App',\n    short_name: 'Next.js App',\n    description: 'Next.js App',\n    start_url: '/',\n    display: 'standalone',\n    background_color: '#fff',\n    theme_color: '#fff',\n    icons: [\n      {\n        src: '/favicon.ico',\n        sizes: 'any',\n        type: 'image/x-icon',\n      },\n    ],\n  }\n}\nManifest Object\n\nThe manifest object contains an extensive list of options that may be updated due to new web standards. For information on all the current options, refer to the MetadataRoute.Manifest type in your code editor if using TypeScript or see the MDN\n docs.\n\nPrevious\nfavicon, icon, and apple-icon\nNext\nopengraph-image and twitter-image\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Metadata Files: robots.txt | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/metadata/robots",
    "html": "File-system conventions\nMetadata Files\nrobots.txt\nCopy page\nrobots.txt\n\nAdd or generate a robots.txt file that matches the Robots Exclusion Standard\n in the root of app directory to tell search engine crawlers which URLs they can access on your site.\n\nStatic robots.txt\napp/robots.txt\nUser-Agent: *\nAllow: /\nDisallow: /private/\nSitemap: https://acme.com/sitemap.xml\nGenerate a Robots file\n\nAdd a robots.js or robots.ts file that returns a Robots object.\n\nGood to know: robots.js is a special Route Handlers that is cached by default unless it uses a Dynamic API or dynamic config option.\n\napp/robots.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\n \nexport default function robots(): MetadataRoute.Robots {\n  return {\n    rules: {\n      userAgent: '*',\n      allow: '/',\n      disallow: '/private/',\n    },\n    sitemap: 'https://acme.com/sitemap.xml',\n  }\n}\n\nOutput:\n\nUser-Agent: *\nAllow: /\nDisallow: /private/\nSitemap: https://acme.com/sitemap.xml\nCustomizing specific user agents\n\nYou can customise how individual search engine bots crawl your site by passing an array of user agents to the rules property. For example:\n\napp/robots.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\n \nexport default function robots(): MetadataRoute.Robots {\n  return {\n    rules: [\n      {\n        userAgent: 'Googlebot',\n        allow: ['/'],\n        disallow: '/private/',\n      },\n      {\n        userAgent: ['Applebot', 'Bingbot'],\n        disallow: ['/'],\n      },\n    ],\n    sitemap: 'https://acme.com/sitemap.xml',\n  }\n}\n\nOutput:\n\nUser-Agent: Googlebot\nAllow: /\nDisallow: /private/\nUser-Agent: Applebot\nDisallow: /\nUser-Agent: Bingbot\nDisallow: /\nSitemap: https://acme.com/sitemap.xml\nRobots object\ntype Robots = {\n  rules:\n    | {\n        userAgent?: string | string[]\n        allow?: string | string[]\n        disallow?: string | string[]\n        crawlDelay?: number\n      }\n    | Array<{\n        userAgent: string | string[]\n        allow?: string | string[]\n        disallow?: string | string[]\n        crawlDelay?: number\n      }>\n  sitemap?: string | string[]\n  host?: string\n}\nVersion History\nVersion\tChanges\nv13.3.0\trobots introduced.\nPrevious\nopengraph-image and twitter-image\nNext\nsitemap.xml\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Metadata Files: opengraph-image and twitter-image | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/metadata/opengraph-image",
    "html": "File-system conventions\nMetadata Files\nopengraph-image and twitter-image\nCopy page\nopengraph-image and twitter-image\n\nThe opengraph-image and twitter-image file conventions allow you to set Open Graph and Twitter images for a route segment.\n\nThey are useful for setting the images that appear on social networks and messaging apps when a user shares a link to your site.\n\nThere are two ways to set Open Graph and Twitter images:\n\nUsing image files (.jpg, .png, .gif)\nUsing code to generate images (.js, .ts, .tsx)\nImage files (.jpg, .png, .gif)\n\nUse an image file to set a route segment's shared image by placing an opengraph-image or twitter-image image file in the segment.\n\nNext.js will evaluate the file and automatically add the appropriate tags to your app's <head> element.\n\nFile convention\tSupported file types\nopengraph-image\t.jpg, .jpeg, .png, .gif\ntwitter-image\t.jpg, .jpeg, .png, .gif\nopengraph-image.alt\t.txt\ntwitter-image.alt\t.txt\n\nGood to know:\n\nThe twitter-image file size must not exceed 5MB\n, and the opengraph-image file size must not exceed 8MB\n. If the image file size exceeds these limits, the build will fail.\n\nopengraph-image\n\nAdd an opengraph-image.(jpg|jpeg|png|gif) image file to any route segment.\n\n<head> output\n<meta property=\"og:image\" content=\"<generated>\" />\n<meta property=\"og:image:type\" content=\"<generated>\" />\n<meta property=\"og:image:width\" content=\"<generated>\" />\n<meta property=\"og:image:height\" content=\"<generated>\" />\ntwitter-image\n\nAdd a twitter-image.(jpg|jpeg|png|gif) image file to any route segment.\n\n<head> output\n<meta name=\"twitter:image\" content=\"<generated>\" />\n<meta name=\"twitter:image:type\" content=\"<generated>\" />\n<meta name=\"twitter:image:width\" content=\"<generated>\" />\n<meta name=\"twitter:image:height\" content=\"<generated>\" />\nopengraph-image.alt.txt\n\nAdd an accompanying opengraph-image.alt.txt file in the same route segment as the opengraph-image.(jpg|jpeg|png|gif) image it's alt text.\n\nopengraph-image.alt.txt\nAbout Acme\n<head> output\n<meta property=\"og:image:alt\" content=\"About Acme\" />\ntwitter-image.alt.txt\n\nAdd an accompanying twitter-image.alt.txt file in the same route segment as the twitter-image.(jpg|jpeg|png|gif) image it's alt text.\n\ntwitter-image.alt.txt\nAbout Acme\n<head> output\n<meta property=\"twitter:image:alt\" content=\"About Acme\" />\nGenerate images using code (.js, .ts, .tsx)\n\nIn addition to using literal image files, you can programmatically generate images using code.\n\nGenerate a route segment's shared image by creating an opengraph-image or twitter-image route that default exports a function.\n\nFile convention\tSupported file types\nopengraph-image\t.js, .ts, .tsx\ntwitter-image\t.js, .ts, .tsx\n\nGood to know:\n\nBy default, generated images are statically optimized (generated at build time and cached) unless they use Dynamic APIs or uncached data.\nYou can generate multiple Images in the same file using generateImageMetadata.\nopengraph-image.js and twitter-image.js are special Route Handlers that is cached by default unless it uses a Dynamic API or dynamic config option.\n\nThe easiest way to generate an image is to use the ImageResponse API from next/og.\n\napp/about/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\nimport { readFile } from 'node:fs/promises'\nimport { join } from 'node:path'\n \n// Image metadata\nexport const alt = 'About Acme'\nexport const size = {\n  width: 1200,\n  height: 630,\n}\n \nexport const contentType = 'image/png'\n \n// Image generation\nexport default async function Image() {\n  // Font loading, process.cwd() is Next.js project directory\n  const interSemiBold = await readFile(\n    join(process.cwd(), 'assets/Inter-SemiBold.ttf')\n  )\n \n  return new ImageResponse(\n    (\n      // ImageResponse JSX element\n      <div\n        style={{\n          fontSize: 128,\n          background: 'white',\n          width: '100%',\n          height: '100%',\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n        }}\n      >\n        About Acme\n      </div>\n    ),\n    // ImageResponse options\n    {\n      // For convenience, we can re-use the exported opengraph-image\n      // size config to also set the ImageResponse's width and height.\n      ...size,\n      fonts: [\n        {\n          name: 'Inter',\n          data: interSemiBold,\n          style: 'normal',\n          weight: 400,\n        },\n      ],\n    }\n  )\n}\n<head> output\n<meta property=\"og:image\" content=\"<generated>\" />\n<meta property=\"og:image:alt\" content=\"About Acme\" />\n<meta property=\"og:image:type\" content=\"image/png\" />\n<meta property=\"og:image:width\" content=\"1200\" />\n<meta property=\"og:image:height\" content=\"630\" />\nProps\n\nThe default export function receives the following props:\n\nparams (optional)\n\nA promise that resolves to an object containing the dynamic route parameters object from the root segment down to the segment opengraph-image or twitter-image is colocated in.\n\nGood to know: If you use generateImageMetadata, the function will also receive an id prop that is a promise resolving to the id value from one of the items returned by generateImageMetadata.\n\napp/shop/[slug]/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Image({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  // ...\n}\nRoute\tURL\tparams\napp/shop/opengraph-image.js\t/shop\tundefined\napp/shop/[slug]/opengraph-image.js\t/shop/1\tPromise<{ slug: '1' }>\napp/shop/[tag]/[item]/opengraph-image.js\t/shop/1/2\tPromise<{ tag: '1', item: '2' }>\nReturns\n\nThe default export function should return a Blob | ArrayBuffer | TypedArray | DataView | ReadableStream | Response.\n\nGood to know: ImageResponse satisfies this return type.\n\nConfig exports\n\nYou can optionally configure the image's metadata by exporting alt, size, and contentType variables from opengraph-image or twitter-image route.\n\nOption\tType\nalt\tstring\nsize\t{ width: number; height: number }\ncontentType\tstring - image MIME type\nalt\nopengraph-image.tsx | twitter-image.tsx\nTypeScript\nJavaScript\nTypeScript\nexport const alt = 'My images alt text'\n \nexport default function Image() {}\n<head> output\n<meta property=\"og:image:alt\" content=\"My images alt text\" />\nsize\nopengraph-image.tsx | twitter-image.tsx\nTypeScript\nJavaScript\nTypeScript\nexport const size = { width: 1200, height: 630 }\n \nexport default function Image() {}\n<head> output\n<meta property=\"og:image:width\" content=\"1200\" />\n<meta property=\"og:image:height\" content=\"630\" />\ncontentType\nopengraph-image.tsx | twitter-image.tsx\nTypeScript\nJavaScript\nTypeScript\nexport const contentType = 'image/png'\n \nexport default function Image() {}\n<head> output\n<meta property=\"og:image:type\" content=\"image/png\" />\nRoute Segment Config\n\nopengraph-image and twitter-image are specialized Route Handlers that can use the same route segment configuration options as Pages and Layouts.\n\nExamples\nUsing external data\n\nThis example uses the params object and external data to generate the image.\n\nGood to know: By default, this generated image will be statically optimized. You can configure the individual fetch options or route segments options to change this behavior.\n\napp/posts/[slug]/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\n \nexport const alt = 'About Acme'\nexport const size = {\n  width: 1200,\n  height: 630,\n}\nexport const contentType = 'image/png'\n \nexport default async function Image({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  const post = await fetch(`https://.../posts/${slug}`).then((res) =>\n    res.json()\n  )\n \n  return new ImageResponse(\n    (\n      <div\n        style={{\n          fontSize: 48,\n          background: 'white',\n          width: '100%',\n          height: '100%',\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n        }}\n      >\n        {post.title}\n      </div>\n    ),\n    {\n      ...size,\n    }\n  )\n}\nUsing Node.js runtime with local assets\n\nThese examples use the Node.js runtime to fetch a local image from the file system and pass it to the <img> src attribute, either as a base64 string or an ArrayBuffer. Place the local asset relative to the project root, not the example source file.\n\napp/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\nimport { join } from 'node:path'\nimport { readFile } from 'node:fs/promises'\n \nexport default async function Image() {\n  const logoData = await readFile(join(process.cwd(), 'logo.png'), 'base64')\n  const logoSrc = `data:image/png;base64,${logoData}`\n \n  return new ImageResponse(\n    (\n      <div\n        style={{\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n        }}\n      >\n        <img src={logoSrc} height=\"100\" />\n      </div>\n    )\n  )\n}\n\nPassing an ArrayBuffer to the src attribute of an <img> element is not part of the HTML spec. The rendering engine used by next/og supports it, but because TypeScript definitions follow the spec, you need a @ts-expect-error directive or similar to use this feature\n.\n\napp/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\nimport { join } from 'node:path'\nimport { readFile } from 'node:fs/promises'\n \nexport default async function Image() {\n  const logoData = await readFile(join(process.cwd(), 'logo.png'))\n  const logoSrc = Uint8Array.from(logoData).buffer\n \n  return new ImageResponse(\n    (\n      <div\n        style={{\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n        }}\n      >\n        {/* @ts-expect-error Satori accepts ArrayBuffer/typed arrays for <img src> at runtime */}\n        <img src={logoSrc} height=\"100\" />\n      </div>\n    )\n  )\n}\nVersion History\nVersion\tChanges\nv16.0.0\tparams is now a promise that resolves to an object\nv13.3.0\topengraph-image and twitter-image introduced.\nPrevious\nmanifest.json\nNext\nrobots.txt\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "API Reference: Functions | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions",
    "html": "App Router\nAPI Reference\nFunctions\nCopy page\nFunctions\nafter\nAPI Reference for the after function.\ncacheLife\nLearn how to use the cacheLife function to set the cache expiration time for a cached function or component.\ncacheTag\nLearn how to use the cacheTag function to manage cache invalidation in your Next.js application.\nconnection\nAPI Reference for the connection function.\ncookies\nAPI Reference for the cookies function.\ndraftMode\nAPI Reference for the draftMode function.\nfetch\nAPI reference for the extended fetch function.\nforbidden\nAPI Reference for the forbidden function.\ngenerateImageMetadata\nLearn how to generate multiple images in a single Metadata API special file.\ngenerateMetadata\nLearn how to add Metadata to your Next.js application for improved search engine optimization (SEO) and web shareability.\ngenerateSitemaps\nLearn how to use the generateSiteMaps function to create multiple sitemaps for your application.\ngenerateStaticParams\nAPI reference for the generateStaticParams function.\ngenerateViewport\nAPI Reference for the generateViewport function.\nheaders\nAPI reference for the headers function.\nImageResponse\nAPI Reference for the ImageResponse constructor.\nNextRequest\nAPI Reference for NextRequest.\nNextResponse\nAPI Reference for NextResponse.\nnotFound\nAPI Reference for the notFound function.\npermanentRedirect\nAPI Reference for the permanentRedirect function.\nredirect\nAPI Reference for the redirect function.\nrefresh\nAPI Reference for the refresh function.\nrevalidatePath\nAPI Reference for the revalidatePath function.\nrevalidateTag\nAPI Reference for the revalidateTag function.\nunauthorized\nAPI Reference for the unauthorized function.\nunstable_cache\nAPI Reference for the unstable_cache function.\nunstable_noStore\nAPI Reference for the unstable_noStore function.\nunstable_rethrow\nAPI Reference for the unstable_rethrow function.\nupdateTag\nAPI Reference for the updateTag function.\nuseLinkStatus\nAPI Reference for the useLinkStatus hook.\nuseParams\nAPI Reference for the useParams hook.\nusePathname\nAPI Reference for the usePathname hook.\nuseReportWebVitals\nAPI Reference for the useReportWebVitals function.\nuseRouter\nAPI reference for the useRouter hook.\nuseSearchParams\nAPI Reference for the useSearchParams hook.\nuseSelectedLayoutSegment\nAPI Reference for the useSelectedLayoutSegment hook.\nuseSelectedLayoutSegments\nAPI Reference for the useSelectedLayoutSegments hook.\nuserAgent\nThe userAgent helper extends the Web Request API with additional properties and methods to interact with the user agent object from the request.\nPrevious\nsitemap.xml\nNext\nafter\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Metadata Files: sitemap.xml | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/file-conventions/metadata/sitemap",
    "html": "File-system conventions\nMetadata Files\nsitemap.xml\nCopy page\nsitemap.xml\n\nsitemap.(xml|js|ts) is a special file that matches the Sitemaps XML format\n to help search engine crawlers index your site more efficiently.\n\nSitemap files (.xml)\n\nFor smaller applications, you can create a sitemap.xml file and place it in the root of your app directory.\n\napp/sitemap.xml\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n  <url>\n    <loc>https://acme.com</loc>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n    <changefreq>yearly</changefreq>\n    <priority>1</priority>\n  </url>\n  <url>\n    <loc>https://acme.com/about</loc>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n    <changefreq>monthly</changefreq>\n    <priority>0.8</priority>\n  </url>\n  <url>\n    <loc>https://acme.com/blog</loc>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n</urlset>\nGenerating a sitemap using code (.js, .ts)\n\nYou can use the sitemap.(js|ts) file convention to programmatically generate a sitemap by exporting a default function that returns an array of URLs. If using TypeScript, a Sitemap type is available.\n\nGood to know: sitemap.js is a special Route Handler that is cached by default unless it uses a Dynamic API or dynamic config option.\n\napp/sitemap.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\n \nexport default function sitemap(): MetadataRoute.Sitemap {\n  return [\n    {\n      url: 'https://acme.com',\n      lastModified: new Date(),\n      changeFrequency: 'yearly',\n      priority: 1,\n    },\n    {\n      url: 'https://acme.com/about',\n      lastModified: new Date(),\n      changeFrequency: 'monthly',\n      priority: 0.8,\n    },\n    {\n      url: 'https://acme.com/blog',\n      lastModified: new Date(),\n      changeFrequency: 'weekly',\n      priority: 0.5,\n    },\n  ]\n}\n\nOutput:\n\nacme.com/sitemap.xml\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n  <url>\n    <loc>https://acme.com</loc>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n    <changefreq>yearly</changefreq>\n    <priority>1</priority>\n  </url>\n  <url>\n    <loc>https://acme.com/about</loc>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n    <changefreq>monthly</changefreq>\n    <priority>0.8</priority>\n  </url>\n  <url>\n    <loc>https://acme.com/blog</loc>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n</urlset>\nImage Sitemaps\n\nYou can use images property to create image sitemaps. Learn more details in the Google Developer Docs\n.\n\napp/sitemap.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\n \nexport default function sitemap(): MetadataRoute.Sitemap {\n  return [\n    {\n      url: 'https://example.com',\n      lastModified: '2021-01-01',\n      changeFrequency: 'weekly',\n      priority: 0.5,\n      images: ['https://example.com/image.jpg'],\n    },\n  ]\n}\n\nOutput:\n\nacme.com/sitemap.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<urlset\n  xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"\n  xmlns:image=\"http://www.google.com/schemas/sitemap-image/1.1\"\n>\n  <url>\n    <loc>https://example.com</loc>\n    <image:image>\n      <image:loc>https://example.com/image.jpg</image:loc>\n    </image:image>\n    <lastmod>2021-01-01</lastmod>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n</urlset>\nVideo Sitemaps\n\nYou can use videos property to create video sitemaps. Learn more details in the Google Developer Docs\n.\n\napp/sitemap.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\n \nexport default function sitemap(): MetadataRoute.Sitemap {\n  return [\n    {\n      url: 'https://example.com',\n      lastModified: '2021-01-01',\n      changeFrequency: 'weekly',\n      priority: 0.5,\n      videos: [\n        {\n          title: 'example',\n          thumbnail_loc: 'https://example.com/image.jpg',\n          description: 'this is the description',\n        },\n      ],\n    },\n  ]\n}\n\nOutput:\n\nacme.com/sitemap.xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<urlset\n  xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"\n  xmlns:video=\"http://www.google.com/schemas/sitemap-video/1.1\"\n>\n  <url>\n    <loc>https://example.com</loc>\n    <video:video>\n      <video:title>example</video:title>\n      <video:thumbnail_loc>https://example.com/image.jpg</video:thumbnail_loc>\n      <video:description>this is the description</video:description>\n    </video:video>\n    <lastmod>2021-01-01</lastmod>\n    <changefreq>weekly</changefreq>\n    <priority>0.5</priority>\n  </url>\n</urlset>\nGenerate a localized Sitemap\napp/sitemap.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\n \nexport default function sitemap(): MetadataRoute.Sitemap {\n  return [\n    {\n      url: 'https://acme.com',\n      lastModified: new Date(),\n      alternates: {\n        languages: {\n          es: 'https://acme.com/es',\n          de: 'https://acme.com/de',\n        },\n      },\n    },\n    {\n      url: 'https://acme.com/about',\n      lastModified: new Date(),\n      alternates: {\n        languages: {\n          es: 'https://acme.com/es/about',\n          de: 'https://acme.com/de/about',\n        },\n      },\n    },\n    {\n      url: 'https://acme.com/blog',\n      lastModified: new Date(),\n      alternates: {\n        languages: {\n          es: 'https://acme.com/es/blog',\n          de: 'https://acme.com/de/blog',\n        },\n      },\n    },\n  ]\n}\n\nOutput:\n\nacme.com/sitemap.xml\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\" xmlns:xhtml=\"http://www.w3.org/1999/xhtml\">\n  <url>\n    <loc>https://acme.com</loc>\n    <xhtml:link\n      rel=\"alternate\"\n      hreflang=\"es\"\n      href=\"https://acme.com/es\"/>\n    <xhtml:link\n      rel=\"alternate\"\n      hreflang=\"de\"\n      href=\"https://acme.com/de\"/>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n  </url>\n  <url>\n    <loc>https://acme.com/about</loc>\n    <xhtml:link\n      rel=\"alternate\"\n      hreflang=\"es\"\n      href=\"https://acme.com/es/about\"/>\n    <xhtml:link\n      rel=\"alternate\"\n      hreflang=\"de\"\n      href=\"https://acme.com/de/about\"/>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n  </url>\n  <url>\n    <loc>https://acme.com/blog</loc>\n    <xhtml:link\n      rel=\"alternate\"\n      hreflang=\"es\"\n      href=\"https://acme.com/es/blog\"/>\n    <xhtml:link\n      rel=\"alternate\"\n      hreflang=\"de\"\n      href=\"https://acme.com/de/blog\"/>\n    <lastmod>2023-04-06T15:02:24.021Z</lastmod>\n  </url>\n</urlset>\nGenerating multiple sitemaps\n\nWhile a single sitemap will work for most applications. For large web applications, you may need to split a sitemap into multiple files.\n\nThere are two ways you can create multiple sitemaps:\n\nBy nesting sitemap.(xml|js|ts) inside multiple route segments e.g. app/sitemap.xml and app/products/sitemap.xml.\nBy using the generateSitemaps function.\n\nFor example, to split a sitemap using generateSitemaps, return an array of objects with the sitemap id. Then, use the id to generate the unique sitemaps.\n\napp/product/sitemap.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { MetadataRoute } from 'next'\nimport { BASE_URL } from '@/app/lib/constants'\n \nexport async function generateSitemaps() {\n  // Fetch the total number of products and calculate the number of sitemaps needed\n  return [{ id: 0 }, { id: 1 }, { id: 2 }, { id: 3 }]\n}\n \nexport default async function sitemap({\n  id,\n}: {\n  id: number\n}): Promise<MetadataRoute.Sitemap> {\n  // Google's limit is 50,000 URLs per sitemap\n  const start = id * 50000\n  const end = start + 50000\n  const products = await getProducts(\n    `SELECT id, date FROM products WHERE id BETWEEN ${start} AND ${end}`\n  )\n  return products.map((product) => ({\n    url: `${BASE_URL}/product/${product.id}`,\n    lastModified: product.date,\n  }))\n}\n\nYour generated sitemaps will be available at /.../sitemap/[id]. For example, /product/sitemap/1.xml.\n\nSee the generateSitemaps API reference for more information.\n\nReturns\n\nThe default function exported from sitemap.(xml|ts|js) should return an array of objects with the following properties:\n\ntype Sitemap = Array<{\n  url: string\n  lastModified?: string | Date\n  changeFrequency?:\n    | 'always'\n    | 'hourly'\n    | 'daily'\n    | 'weekly'\n    | 'monthly'\n    | 'yearly'\n    | 'never'\n  priority?: number\n  alternates?: {\n    languages?: Languages<string>\n  }\n}>\nVersion History\nVersion\tChanges\nv14.2.0\tAdd localizations support.\nv13.4.14\tAdd changeFrequency and priority attributes to sitemaps.\nv13.3.0\tsitemap introduced.\nNext Steps\nLearn how to use the generateSitemaps function.\ngenerateSitemaps\nLearn how to use the generateSiteMaps function to create multiple sitemaps for your application.\nPrevious\nrobots.txt\nNext\nFunctions\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: after | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/after",
    "html": "API Reference\nFunctions\nafter\nCopy page\nafter\n\nafter allows you to schedule work to be executed after a response (or prerender) is finished. This is useful for tasks and other side effects that should not block the response, such as logging and analytics.\n\nIt can be used in Server Components (including generateMetadata), Server Actions, Route Handlers, and Proxy.\n\nThe function accepts a callback that will be executed after the response (or prerender) is finished:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { after } from 'next/server'\n// Custom logging function\nimport { log } from '@/app/utils'\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  after(() => {\n    // Execute after the layout is rendered and sent to the user\n    log()\n  })\n  return <>{children}</>\n}\n\nGood to know: after is not a Dynamic API and calling it does not cause a route to become dynamic. If it's used within a static page, the callback will execute at build time, or whenever a page is revalidated.\n\nReference\nParameters\nA callback function which will be executed after the response (or prerender) is finished.\nDuration\n\nafter will run for the platform's default or configured max duration of your route. If your platform supports it, you can configure the timeout limit using the maxDuration route segment config.\n\nGood to know\nafter will be executed even if the response didn't complete successfully. Including when an error is thrown or when notFound or redirect is called.\nYou can use React cache to deduplicate functions called inside after.\nafter can be nested inside other after calls, for example, you can create utility functions that wrap after calls to add additional functionality.\nExamples\nWith request APIs\n\nYou can use request APIs such as cookies and headers inside after in Server Actions and Route Handlers. This is useful for logging activity after a mutation. For example:\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { after } from 'next/server'\nimport { cookies, headers } from 'next/headers'\nimport { logUserAction } from '@/app/utils'\n \nexport async function POST(request: Request) {\n  // Perform mutation\n  // ...\n \n  // Log user activity for analytics\n  after(async () => {\n    const userAgent = (await headers().get('user-agent')) || 'unknown'\n    const sessionCookie =\n      (await cookies().get('session-id'))?.value || 'anonymous'\n \n    logUserAction({ sessionCookie, userAgent })\n  })\n \n  return new Response(JSON.stringify({ status: 'success' }), {\n    status: 200,\n    headers: { 'Content-Type': 'application/json' },\n  })\n}\n\nHowever, you cannot use these request APIs inside after in Server Components. This is because Next.js needs to know which part of the tree access the request APIs to support Cache Components, but after runs after React's rendering lifecycle.\n\nPlatform Support\nDeployment Option\tSupported\nNode.js server\tYes\nDocker container\tYes\nStatic export\tNo\nAdapters\tPlatform-specific\n\nLearn how to configure after when self-hosting Next.js.\n\nReference: supporting after for serverless platforms\nVersion History\nVersion History\tDescription\nv15.1.0\tafter became stable.\nv15.0.0-rc\tunstable_after introduced.\nPrevious\nFunctions\nNext\ncacheLife\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: cacheLife | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/cacheLife",
    "html": "API Reference\nFunctions\ncacheLife\nCopy page\ncacheLife\n\nThe cacheLife function is used to set the cache lifetime of a function or component. It should be used alongside the use cache directive, and within the scope of the function or component.\n\nUsage\n\nTo use cacheLife, enable the cacheComponents flag in your next.config.js file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n \nexport default nextConfig\n\nThen, import and invoke the cacheLife function within the scope of the function or component:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use cache'\nimport { cacheLife } from 'next/cache'\n \nexport default async function Page() {\n  cacheLife('hours')\n  return <div>Page</div>\n}\nReference\nDefault cache profiles\n\nNext.js provides a set of named cache profiles modeled on various timescales. If you don't specify a cache profile in the cacheLife function alongside the use cache directive, Next.js will automatically apply the default cache profile.\n\nHowever, we recommend always adding a cache profile when using the use cache directive to explicitly define caching behavior.\n\nProfile\tstale\trevalidate\texpire\tDescription\ndefault\t5 minutes\t15 minutes\t1 year\tDefault profile, suitable for content that doesn't need frequent updates\nseconds\t30 seconds\t1 second\t1 minute\tFor rapidly changing content requiring near real-time updates\nminutes\t5 minutes\t1 minute\t1 hour\tFor content that updates frequently within an hour\nhours\t5 minutes\t1 hour\t1 day\tFor content that updates daily but can be slightly stale\ndays\t5 minutes\t1 day\t1 week\tFor content that updates weekly but can be a day old\nweeks\t5 minutes\t1 week\t30 days\tFor content that updates monthly but can be a week old\nmax\t5 minutes\t30 days\t1 year\tFor very stable content that rarely needs updating\n\nThe string values used to reference cache profiles don't carry inherent meaning; instead they serve as semantic labels. This allows you to better understand and manage your cached content within your codebase.\n\nGood to know: Updating the staleTimes and expireTime config options also updates the stale and expire properties of the default cache profile.\n\nCustom cache profiles\n\nYou can configure custom cache profiles by adding them to the cacheLife option in your next.config.ts file.\n\nCache profiles are objects that contain the following properties:\n\nProperty\tValue\tDescription\tRequirement\nstale\tnumber\tDuration the client should cache a value without checking the server.\tOptional\nrevalidate\tnumber\tFrequency at which the cache should refresh on the server; stale values may be served while revalidating.\tOptional\nexpire\tnumber\tMaximum duration for which a value can remain stale before switching to dynamic fetching; must be longer than revalidate.\tOptional - Must be longer than revalidate\n\nThe \"stale\" property differs from the staleTimes setting in that it specifically controls client-side router caching. While staleTimes is a global setting that affects all instances of both dynamic and static data, the cacheLife configuration allows you to define \"stale\" times on a per-function or per-route basis.\n\nstale time in the client router cache\n\nThe \"stale\" property does not set the Cache-control: max-age header. Instead, it controls the client-side router cache. The server sends this value to the client via the x-nextjs-stale-time response header (in seconds), which the client router uses to determine how long to cache the route before needing to revalidate.\n\nThe client enforces a minimum stale time of 30 seconds: This ensures that prefetched data remains usable long enough for users to click on links after they've been prefetched. Without this minimum, very short stale times would cause prefetched data to expire before it could be used, making prefetching ineffective.\n\nThis minimum only applies to time-based expiration. When you call revalidateTag, revalidatePath, updateTag, or refresh from a Server Action, the entire client cache is immediately cleared, bypassing the stale time entirely.\n\nExamples\nDefining reusable cache profiles\n\nYou can create a reusable cache profile by defining them in your next.config.ts file. Choose a name that suits your use case and set values for the stale, revalidate, and expire properties. You can create as many custom cache profiles as needed. Each profile can be referenced by its name as a string value passed to the cacheLife function.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n  cacheLife: {\n    biweekly: {\n      stale: 60 * 60 * 24 * 14, // 14 days\n      revalidate: 60 * 60 * 24, // 1 day\n      expire: 60 * 60 * 24 * 14, // 14 days\n    },\n  },\n}\n \nmodule.exports = nextConfig\n\nThe example above caches for 14 days, checks for updates daily, and expires the cache after 14 days. You can then reference this profile throughout your application by its name:\n\napp/page.tsx\n'use cache'\nimport { cacheLife } from 'next/cache'\n \nexport default async function Page() {\n  cacheLife('biweekly')\n  return <div>Page</div>\n}\nOverriding the default cache profiles\n\nWhile the default cache profiles provide a useful way to think about how fresh or stale any given part of cacheable output can be, you may prefer different named profiles to better align with your applications caching strategies.\n\nYou can override the default named cache profiles by creating a new configuration with the same name as the defaults.\n\nThe example below shows how to override the default “days” cache profile:\n\nnext.config.ts\nconst nextConfig = {\n  cacheComponents: true,\n  cacheLife: {\n    days: {\n      stale: 3600, // 1 hour\n      revalidate: 900, // 15 minutes\n      expire: 86400, // 1 day\n    },\n  },\n}\n \nmodule.exports = nextConfig\nDefining cache profiles inline\n\nFor specific use cases, you can set a custom cache profile by passing an object to the cacheLife function:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use cache'\nimport { cacheLife } from 'next/cache'\n \nexport default async function Page() {\n  cacheLife({\n    stale: 3600, // 1 hour\n    revalidate: 900, // 15 minutes\n    expire: 86400, // 1 day\n  })\n \n  return <div>Page</div>\n}\n\nThis inline cache profile will only be applied to the function or file it was created in. If you want to reuse the same profile throughout your application, you can add the configuration to the cacheLife property of your next.config.ts file.\n\nNested usage of use cache and cacheLife\n\nWhen defining multiple caching behaviors in the same route or component tree, if the inner caches specify their own cacheLife profile, the outer cache will respect the shortest cache duration among them. This applies only if the outer cache does not have its own explicit cacheLife profile defined.\n\nFor example, if you add the use cache directive to your page, without specifying a cache profile, the default cache profile will be applied implicitly (cacheLife(”default”)). If a component imported into the page also uses the use cache directive with its own cache profile, the outer and inner cache profiles are compared, and shortest duration set in the profiles will be applied.\n\napp/components/parent.tsx\n// Parent component\nimport { cacheLife } from 'next/cache'\nimport { ChildComponent } from './child'\n \nexport async function ParentComponent() {\n  'use cache'\n  cacheLife('days')\n \n  return (\n    <div>\n      <ChildComponent />\n    </div>\n  )\n}\n\nAnd in a separate file, we defined the Child component that was imported:\n\napp/components/child.tsx\n// Child component\nimport { cacheLife } from 'next/cache'\n \nexport async function ChildComponent() {\n  'use cache'\n  cacheLife('hours')\n  return <div>Child Content</div>\n \n  // This component's cache will respect the shorter 'hours' profile\n}\nRelated\nView related API references.\ncacheComponents\nLearn how to enable the cacheComponents flag in Next.js.\nuse cache\nLearn how to use the use cache directive to cache data in your Next.js application.\nrevalidateTag\nAPI Reference for the revalidateTag function.\ncacheTag\nLearn how to use the cacheTag function to manage cache invalidation in your Next.js application.\nPrevious\nafter\nNext\ncacheTag\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: cacheTag | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/cacheTag",
    "html": "API Reference\nFunctions\ncacheTag\nCopy page\ncacheTag\n\nThe cacheTag function allows you to tag cached data for on-demand invalidation. By associating tags with cache entries, you can selectively purge or revalidate specific cache entries without affecting other cached data.\n\nUsage\n\nTo use cacheTag, enable the cacheComponents flag in your next.config.js file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n \nexport default nextConfig\n\nThe cacheTag function takes one or more string values.\n\napp/data.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cacheTag } from 'next/cache'\n \nexport async function getData() {\n  'use cache'\n  cacheTag('my-data')\n  const data = await fetch('/api/data')\n  return data\n}\n\nYou can then purge the cache on-demand using revalidateTag API in another function, for example, a route handler or Server Action:\n\napp/action.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { revalidateTag } from 'next/cache'\n \nexport default async function submit() {\n  await addPost()\n  revalidateTag('my-data')\n}\nGood to know\nIdempotent Tags: Applying the same tag multiple times has no additional effect.\nMultiple Tags: You can assign multiple tags to a single cache entry by passing multiple string values to cacheTag.\ncacheTag('tag-one', 'tag-two')\nLimits: The max length for a custom tag is 256 characters and the max tag items is 128.\nExamples\nTagging components or functions\n\nTag your cached data by calling cacheTag within a cached function or component:\n\napp/components/bookings.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cacheTag } from 'next/cache'\n \ninterface BookingsProps {\n  type: string\n}\n \nexport async function Bookings({ type = 'haircut' }: BookingsProps) {\n  'use cache'\n  cacheTag('bookings-data')\n \n  async function getBookingsData() {\n    const data = await fetch(`/api/bookings?type=${encodeURIComponent(type)}`)\n    return data\n  }\n \n  return //...\n}\nCreating tags from external data\n\nYou can use the data returned from an async function to tag the cache entry.\n\napp/components/bookings.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cacheTag } from 'next/cache'\n \ninterface BookingsProps {\n  type: string\n}\n \nexport async function Bookings({ type = 'haircut' }: BookingsProps) {\n  async function getBookingsData() {\n    'use cache'\n    const data = await fetch(`/api/bookings?type=${encodeURIComponent(type)}`)\n    cacheTag('bookings-data', data.id)\n    return data\n  }\n  return //...\n}\nInvalidating tagged cache\n\nUsing revalidateTag, you can invalidate the cache for a specific tag when needed:\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { revalidateTag } from 'next/cache'\n \nexport async function updateBookings() {\n  await updateBookingData()\n  revalidateTag('bookings-data')\n}\nRelated\nView related API references.\ncacheComponents\nLearn how to enable the cacheComponents flag in Next.js.\nuse cache\nLearn how to use the use cache directive to cache data in your Next.js application.\nrevalidateTag\nAPI Reference for the revalidateTag function.\ncacheLife\nLearn how to use the cacheLife function to set the cache expiration time for a cached function or component.\nPrevious\ncacheLife\nNext\nconnection\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: connection | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/connection",
    "html": "API Reference\nFunctions\nconnection\nCopy page\nconnection\n\nThe connection() function allows you to indicate rendering should wait for an incoming user request before continuing.\n\nIt's useful when a component doesn't use Dynamic APIs, but you want it to be dynamically rendered at runtime and not statically rendered at build time. This usually occurs when you access external information that you intentionally want to change the result of a render, such as Math.random() or new Date().\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { connection } from 'next/server'\n \nexport default async function Page() {\n  await connection()\n  // Everything below will be excluded from prerendering\n  const rand = Math.random()\n  return <span>{rand}</span>\n}\nReference\nType\nfunction connection(): Promise<void>\nParameters\nThe function does not accept any parameters.\nReturns\nThe function returns a void Promise. It is not meant to be consumed.\nGood to know\nconnection replaces unstable_noStore to better align with the future of Next.js.\nThe function is only necessary when dynamic rendering is required and common Dynamic APIs are not used.\nVersion History\nVersion\tChanges\nv15.0.0\tconnection stabilized.\nv15.0.0-RC\tconnection introduced.\nPrevious\ncacheTag\nNext\ncookies\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: cookies | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/cookies",
    "html": "API Reference\nFunctions\ncookies\nCopy page\ncookies\n\ncookies is an async function that allows you to read the HTTP incoming request cookies in Server Components, and read/write outgoing request cookies in Server Actions or Route Handlers.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport default async function Page() {\n  const cookieStore = await cookies()\n  const theme = cookieStore.get('theme')\n  return '...'\n}\nReference\nMethods\n\nThe following methods are available:\n\nMethod\tReturn Type\tDescription\nget('name')\tObject\tAccepts a cookie name and returns an object with the name and value.\ngetAll()\tArray of objects\tReturns a list of all the cookies with a matching name.\nhas('name')\tBoolean\tAccepts a cookie name and returns a boolean based on if the cookie exists.\nset(name, value, options)\t-\tAccepts a cookie name, value, and options and sets the outgoing request cookie.\ndelete(name)\t-\tAccepts a cookie name and deletes the cookie.\nclear()\t-\tDeletes all cookies.\ntoString()\tString\tReturns a string representation of the cookies.\nOptions\n\nWhen setting a cookie, the following properties from the options object are supported:\n\nOption\tType\tDescription\nname\tString\tSpecifies the name of the cookie.\nvalue\tString\tSpecifies the value to be stored in the cookie.\nexpires\tDate\tDefines the exact date when the cookie will expire.\nmaxAge\tNumber\tSets the cookie’s lifespan in seconds.\ndomain\tString\tSpecifies the domain where the cookie is available.\npath\tString, default: '/'\tLimits the cookie's scope to a specific path within the domain.\nsecure\tBoolean\tEnsures the cookie is sent only over HTTPS connections for added security.\nhttpOnly\tBoolean\tRestricts the cookie to HTTP requests, preventing client-side access.\nsameSite\tBoolean, 'lax', 'strict', 'none'\tControls the cookie's cross-site request behavior.\npriority\tString (\"low\", \"medium\", \"high\")\tSpecifies the cookie's priority\npartitioned\tBoolean\tIndicates whether the cookie is partitioned\n.\n\nThe only option with a default value is path.\n\nTo learn more about these options, see the MDN docs\n.\n\nGood to know\ncookies is an asynchronous function that returns a promise. You must use async/await or React's use\n function to access cookies.\nIn version 14 and earlier, cookies was a synchronous function. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\ncookies is a Dynamic API whose returned values cannot be known ahead of time. Using it in a layout or page will opt a route into dynamic rendering.\nThe .delete method can only be called:\nIn a Server Action or Route Handler.\nIf it belongs to the same domain from which .set is called. For wildcard domains, the specific subdomain must be an exact match. Additionally, the code must be executed on the same protocol (HTTP or HTTPS) as the cookie you want to delete.\nHTTP does not allow setting cookies after streaming starts, so you must use .set in a Server Action or Route Handler.\nUnderstanding Cookie Behavior in Server Components\n\nWhen working with cookies in Server Components, it's important to understand that cookies are fundamentally a client-side storage mechanism:\n\nReading cookies works in Server Components because you're accessing the cookie data that the client's browser sends to the server in the HTTP request headers.\nSetting cookies cannot be done directly in a Server Component, even when using a Route Handler or Server Action. This is because cookies are actually stored by the browser, not the server.\n\nThe server can only send instructions (via Set-Cookie headers) to tell the browser to store cookies - the actual storage happens on the client side. This is why cookie operations that modify state (.set, .delete, .clear) must be performed in a Route Handler or Server Action where the response headers can be properly set.\n\nUnderstanding Cookie Behavior in Server Actions\n\nAfter you set or delete a cookie in a Server Action, Next.js re-renders the current page and its layouts on the server so the UI reflects the new cookie value. See the Caching guide.\n\nThe UI is not unmounted, but effects that depend on data coming from the server will re-run.\n\nTo refresh cached data too, call revalidatePath or revalidateTag inside the action.\n\nExamples\nGetting a cookie\n\nYou can use the (await cookies()).get('name') method to get a single cookie:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport default async function Page() {\n  const cookieStore = await cookies()\n  const theme = cookieStore.get('theme')\n  return '...'\n}\nGetting all cookies\n\nYou can use the (await cookies()).getAll() method to get all cookies with a matching name. If name is unspecified, it returns all the available cookies.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport default async function Page() {\n  const cookieStore = await cookies()\n  return cookieStore.getAll().map((cookie) => (\n    <div key={cookie.name}>\n      <p>Name: {cookie.name}</p>\n      <p>Value: {cookie.value}</p>\n    </div>\n  ))\n}\nSetting a cookie\n\nYou can use the (await cookies()).set(name, value, options) method in a Server Action or Route Handler to set a cookie. The options object is optional.\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { cookies } from 'next/headers'\n \nexport async function create(data) {\n  const cookieStore = await cookies()\n \n  cookieStore.set('name', 'lee')\n  // or\n  cookieStore.set('name', 'lee', { secure: true })\n  // or\n  cookieStore.set({\n    name: 'name',\n    value: 'lee',\n    httpOnly: true,\n    path: '/',\n  })\n}\nChecking if a cookie exists\n\nYou can use the (await cookies()).has(name) method to check if a cookie exists:\n\napp/page.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport default async function Page() {\n  const cookieStore = await cookies()\n  const hasCookie = cookieStore.has('theme')\n  return '...'\n}\nDeleting cookies\n\nThere are three ways you can delete a cookie.\n\nUsing the delete() method:\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { cookies } from 'next/headers'\n \nexport async function delete(data) {\n  (await cookies()).delete('name')\n}\n\nSetting a new cookie with the same name and an empty value:\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { cookies } from 'next/headers'\n \nexport async function delete(data) {\n  (await cookies()).set('name', '')\n}\n\nSetting the maxAge to 0 will immediately expire a cookie. maxAge accepts a value in seconds.\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { cookies } from 'next/headers'\n \nexport async function delete(data) {\n  (await cookies()).set('name', 'value', { maxAge: 0 })\n}\nVersion History\nVersion\tChanges\nv15.0.0-RC\tcookies is now an async function. A codemod is available.\nv13.0.0\tcookies introduced.\nPrevious\nconnection\nNext\ndraftMode\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: draftMode | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/draft-mode",
    "html": "API Reference\nFunctions\ndraftMode\nCopy page\ndraftMode\n\ndraftMode is an async function allows you to enable and disable Draft Mode, as well as check if Draft Mode is enabled in a Server Component.\n\napp/page.ts\nTypeScript\nJavaScript\nTypeScript\nimport { draftMode } from 'next/headers'\n \nexport default async function Page() {\n  const { isEnabled } = await draftMode()\n}\nReference\n\nThe following methods and properties are available:\n\nMethod\tDescription\nisEnabled\tA boolean value that indicates if Draft Mode is enabled.\nenable()\tEnables Draft Mode in a Route Handler by setting a cookie (__prerender_bypass).\ndisable()\tDisables Draft Mode in a Route Handler by deleting a cookie.\nGood to know\ndraftMode is an asynchronous function that returns a promise. You must use async/await or React's use\n function.\nIn version 14 and earlier, draftMode was a synchronous function. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\nA new bypass cookie value will be generated each time you run next build. This ensures that the bypass cookie can’t be guessed.\nTo test Draft Mode locally over HTTP, your browser will need to allow third-party cookies and local storage access.\nExamples\nEnabling Draft Mode\n\nTo enable Draft Mode, create a new Route Handler and call the enable() method:\n\napp/draft/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { draftMode } from 'next/headers'\n \nexport async function GET(request: Request) {\n  const draft = await draftMode()\n  draft.enable()\n  return new Response('Draft mode is enabled')\n}\nDisabling Draft Mode\n\nBy default, the Draft Mode session ends when the browser is closed.\n\nTo disable Draft Mode manually, call the disable() method in your Route Handler:\n\napp/draft/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { draftMode } from 'next/headers'\n \nexport async function GET(request: Request) {\n  const draft = await draftMode()\n  draft.disable()\n  return new Response('Draft mode is disabled')\n}\n\nThen, send a request to invoke the Route Handler. If calling the route using the <Link> component, you must pass prefetch={false} to prevent accidentally deleting the cookie on prefetch.\n\nChecking if Draft Mode is enabled\n\nYou can check if Draft Mode is enabled in a Server Component with the isEnabled property:\n\napp/page.ts\nTypeScript\nJavaScript\nTypeScript\nimport { draftMode } from 'next/headers'\n \nexport default async function Page() {\n  const { isEnabled } = await draftMode()\n  return (\n    <main>\n      <h1>My Blog Post</h1>\n      <p>Draft Mode is currently {isEnabled ? 'Enabled' : 'Disabled'}</p>\n    </main>\n  )\n}\nVersion History\nVersion\tChanges\nv15.0.0-RC\tdraftMode is now an async function. A codemod is available.\nv13.4.0\tdraftMode introduced.\nNext Steps\nLearn how to use Draft Mode with this step-by-step guide.\nDraft Mode\nNext.js has draft mode to toggle between static and dynamic pages. You can learn how it works with App Router here.\nPrevious\ncookies\nNext\nfetch\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: fetch | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/fetch",
    "html": "API Reference\nFunctions\nfetch\nCopy page\nfetch\n\nNext.js extends the Web fetch() API\n to allow each request on the server to set its own persistent caching and revalidation semantics.\n\nIn the browser, the cache option indicates how a fetch request will interact with the browser's HTTP cache. With this extension, cache indicates how a server-side fetch request will interact with the framework's persistent Data Cache.\n\nYou can call fetch with async and await directly within Server Components.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page() {\n  let data = await fetch('https://api.vercel.app/blog')\n  let posts = await data.json()\n  return (\n    <ul>\n      {posts.map((post) => (\n        <li key={post.id}>{post.title}</li>\n      ))}\n    </ul>\n  )\n}\nfetch(url, options)\n\nSince Next.js extends the Web fetch() API\n, you can use any of the native options available\n.\n\noptions.cache\n\nConfigure how the request should interact with Next.js Data Cache.\n\nfetch(`https://...`, { cache: 'force-cache' | 'no-store' })\nauto no cache (default): Next.js fetches the resource from the remote server on every request in development, but will fetch once during next build because the route will be statically prerendered. If Dynamic APIs are detected on the route, Next.js will fetch the resource on every request.\nno-store: Next.js fetches the resource from the remote server on every request, even if Dynamic APIs are not detected on the route.\nforce-cache: Next.js looks for a matching request in its Data Cache.\nIf there is a match and it is fresh, it will be returned from the cache.\nIf there is no match or a stale match, Next.js will fetch the resource from the remote server and update the cache with the downloaded resource.\noptions.next.revalidate\nfetch(`https://...`, { next: { revalidate: false | 0 | number } })\n\nSet the cache lifetime of a resource (in seconds). Data Cache.\n\nfalse - Cache the resource indefinitely. Semantically equivalent to revalidate: Infinity. The HTTP cache may evict older resources over time.\n0 - Prevent the resource from being cached.\nnumber - (in seconds) Specify the resource should have a cache lifetime of at most n seconds.\n\nGood to know:\n\nIf an individual fetch() request sets a revalidate number lower than the default revalidate of a route, the whole route revalidation interval will be decreased.\nIf two fetch requests with the same URL in the same route have different revalidate values, the lower value will be used.\nConflicting options such as { revalidate: 3600, cache: 'no-store' } are not allowed, both will be ignored, and in development mode a warning will be printed to the terminal.\noptions.next.tags\nfetch(`https://...`, { next: { tags: ['collection'] } })\n\nSet the cache tags of a resource. Data can then be revalidated on-demand using revalidateTag. The max length for a custom tag is 256 characters and the max tag items is 128.\n\nTroubleshooting\nFetch default auto no store and cache: 'no-store' not showing fresh data in development\n\nNext.js caches fetch responses in Server Components across Hot Module Replacement (HMR) in local development for faster responses and to reduce costs for billed API calls.\n\nBy default, the HMR cache applies to all fetch requests, including those with the default auto no cache and cache: 'no-store' option. This means uncached requests will not show fresh data between HMR refreshes. However, the cache will be cleared on navigation or full-page reloads.\n\nSee the serverComponentsHmrCache docs for more information.\n\nHard refresh and caching in development\n\nIn development mode, if the request includes the cache-control: no-cache header, options.cache, options.next.revalidate, and options.next.tags are ignored, and the fetch request is served from the source.\n\nBrowsers typically include cache-control: no-cache when the cache is disabled in developer tools or during a hard refresh.\n\nVersion History\nVersion\tChanges\nv13.0.0\tfetch introduced.\nPrevious\ndraftMode\nNext\nforbidden\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: generateImageMetadata | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/generate-image-metadata",
    "html": "API Reference\nFunctions\ngenerateImageMetadata\nCopy page\ngenerateImageMetadata\n\nYou can use generateImageMetadata to generate different versions of one image or return multiple images for one route segment. This is useful for when you want to avoid hard-coding metadata values, such as for icons.\n\nParameters\n\ngenerateImageMetadata function accepts the following parameters:\n\nparams (optional)\n\nAn object containing the dynamic route parameters object from the root segment down to the segment generateImageMetadata is called from.\n\nicon.tsx\nTypeScript\nJavaScript\nTypeScript\nexport function generateImageMetadata({\n  params,\n}: {\n  params: { slug: string }\n}) {\n  // ...\n}\nRoute\tURL\tparams\napp/shop/icon.js\t/shop\tundefined\napp/shop/[slug]/icon.js\t/shop/1\t{ slug: '1' }\napp/shop/[tag]/[item]/icon.js\t/shop/1/2\t{ tag: '1', item: '2' }\nReturns\n\nThe generateImageMetadata function should return an array of objects containing the image's metadata such as alt and size. In addition, each item must include an id value which will be passed as a promise to the props of the image generating function.\n\nImage Metadata Object\tType\nid\tstring (required)\nalt\tstring\nsize\t{ width: number; height: number }\ncontentType\tstring\nicon.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\n \nexport function generateImageMetadata() {\n  return [\n    {\n      contentType: 'image/png',\n      size: { width: 48, height: 48 },\n      id: 'small',\n    },\n    {\n      contentType: 'image/png',\n      size: { width: 72, height: 72 },\n      id: 'medium',\n    },\n  ]\n}\n \nexport default async function Icon({ id }: { id: Promise<string | number> }) {\n  const iconId = await id\n  return new ImageResponse(\n    (\n      <div\n        style={{\n          width: '100%',\n          height: '100%',\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n          fontSize: 88,\n          background: '#000',\n          color: '#fafafa',\n        }}\n      >\n        Icon {iconId}\n      </div>\n    )\n  )\n}\nImage generation function props\n\nWhen using generateImageMetadata, the default export image generation function receives the following props:\n\nid\n\nA promise that resolves to the id value from one of the items returned by generateImageMetadata. The id will be a string or number depending on what was returned from generateImageMetadata.\n\nicon.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Icon({ id }: { id: Promise<string | number> }) {\n  const iconId = await id\n  // Use iconId to generate the image\n}\nparams (optional)\n\nA promise that resolves to an object containing the dynamic route parameters from the root segment down to the segment the image is colocated in.\n\nicon.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Icon({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  // Use slug to generate the image\n}\nExamples\nUsing external data\n\nThis example uses the params object and external data to generate multiple Open Graph images for a route segment.\n\napp/products/[id]/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\nimport { getCaptionForImage, getOGImages } from '@/app/utils/images'\n \nexport async function generateImageMetadata({\n  params,\n}: {\n  params: { id: string }\n}) {\n  const images = await getOGImages(params.id)\n \n  return images.map((image, idx) => ({\n    id: idx,\n    size: { width: 1200, height: 600 },\n    alt: image.text,\n    contentType: 'image/png',\n  }))\n}\n \nexport default async function Image({\n  params,\n  id,\n}: {\n  params: Promise<{ id: string }>\n  id: Promise<number>\n}) {\n  const productId = (await params).id\n  const imageId = await id\n  const text = await getCaptionForImage(productId, imageId)\n \n  return new ImageResponse(\n    (\n      <div\n        style={\n          {\n            // ...\n          }\n        }\n      >\n        {text}\n      </div>\n    )\n  )\n}\nVersion History\nVersion\tChanges\nv16.0.0\tid passed to the Image generation function is now a promise that resolves to string or number\nv16.0.0\tparams passed to the Image generation function is now a promise that resolves to an object\nv13.3.0\tgenerateImageMetadata introduced.\nNext Steps\nView all the Metadata API options.\nMetadata Files\nAPI documentation for the metadata file conventions.\nPrevious\nforbidden\nNext\ngenerateMetadata\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: forbidden | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/forbidden",
    "html": "API Reference\nFunctions\nforbidden\nCopy page\nforbidden\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe forbidden function throws an error that renders a Next.js 403 error page. It's useful for handling authorization errors in your application. You can customize the UI using the forbidden.js file.\n\nTo start using forbidden, enable the experimental authInterrupts configuration option in your next.config.js file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    authInterrupts: true,\n  },\n}\n \nexport default nextConfig\n\nforbidden can be invoked in Server Components, Server Actions, and Route Handlers.\n\napp/auth/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { verifySession } from '@/app/lib/dal'\nimport { forbidden } from 'next/navigation'\n \nexport default async function AdminPage() {\n  const session = await verifySession()\n \n  // Check if the user has the 'admin' role\n  if (session.role !== 'admin') {\n    forbidden()\n  }\n \n  // Render the admin page for authorized users\n  return <></>\n}\nGood to know\nThe forbidden function cannot be called in the root layout.\nExamples\nRole-based route protection\n\nYou can use forbidden to restrict access to certain routes based on user roles. This ensures that users who are authenticated but lack the required permissions cannot access the route.\n\napp/admin/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { verifySession } from '@/app/lib/dal'\nimport { forbidden } from 'next/navigation'\n \nexport default async function AdminPage() {\n  const session = await verifySession()\n \n  // Check if the user has the 'admin' role\n  if (session.role !== 'admin') {\n    forbidden()\n  }\n \n  // Render the admin page for authorized users\n  return (\n    <main>\n      <h1>Admin Dashboard</h1>\n      <p>Welcome, {session.user.name}!</p>\n    </main>\n  )\n}\nMutations with Server Actions\n\nWhen implementing mutations in Server Actions, you can use forbidden to only allow users with a specific role to update sensitive data.\n\napp/actions/update-role.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { verifySession } from '@/app/lib/dal'\nimport { forbidden } from 'next/navigation'\nimport db from '@/app/lib/db'\n \nexport async function updateRole(formData: FormData) {\n  const session = await verifySession()\n \n  // Ensure only admins can update roles\n  if (session.role !== 'admin') {\n    forbidden()\n  }\n \n  // Perform the role update for authorized users\n  // ...\n}\nVersion History\nVersion\tChanges\nv15.1.0\tforbidden introduced.\nNext Steps\nforbidden.js\nAPI reference for the forbidden.js special file.\nPrevious\nfetch\nNext\ngenerateImageMetadata\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: generateSitemaps | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/generate-sitemaps",
    "html": "API Reference\nFunctions\ngenerateSitemaps\nCopy page\ngenerateSitemaps\n\nYou can use the generateSitemaps function to generate multiple sitemaps for your application.\n\nReturns\n\nThe generateSitemaps returns an array of objects with an id property.\n\nURLs\n\nYour generated sitemaps will be available at /.../sitemap/[id].xml. For example, /product/sitemap/1.xml.\n\nExample\n\nFor example, to split a sitemap using generateSitemaps, return an array of objects with the sitemap id. Then, use the id to generate the unique sitemaps.\n\napp/product/sitemap.ts\nTypeScript\nJavaScript\nTypeScript\nimport { BASE_URL } from '@/app/lib/constants'\n \nexport async function generateSitemaps() {\n  // Fetch the total number of products and calculate the number of sitemaps needed\n  return [{ id: 0 }, { id: 1 }, { id: 2 }, { id: 3 }]\n}\n \nexport default async function sitemap({\n  id,\n}: {\n  id: number\n}): Promise<MetadataRoute.Sitemap> {\n  // Google's limit is 50,000 URLs per sitemap\n  const start = id * 50000\n  const end = start + 50000\n  const products = await getProducts(\n    `SELECT id, date FROM products WHERE id BETWEEN ${start} AND ${end}`\n  )\n  return products.map((product) => ({\n    url: `${BASE_URL}/product/${product.id}`,\n    lastModified: product.date,\n  }))\n}\nVersion History\nVersion\tChanges\nv15.0.0\tgenerateSitemaps now generates consistent URLs between development and production\nv13.3.2\tgenerateSitemaps introduced. In development, you can view the generated sitemap on /.../sitemap.xml/[id]. For example, /product/sitemap.xml/1.\nNext Steps\nLearn how to create sitemaps for your Next.js application.\nsitemap.xml\nAPI Reference for the sitemap.xml file.\nPrevious\ngenerateMetadata\nNext\ngenerateStaticParams\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: generateMetadata | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/generate-metadata",
    "html": "API Reference\nFunctions\ngenerateMetadata\nCopy page\ngenerateMetadata\n\nYou can use the metadata object or the generateMetadata function to define metadata.\n\nThe metadata object\n\nTo define static metadata, export a Metadata object from a layout.js or page.js file.\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: '...',\n  description: '...',\n}\n \nexport default function Page() {}\n\nSee the Metadata Fields for a complete list of supported options.\n\ngenerateMetadata function\n\nDynamic metadata depends on dynamic information, such as the current route parameters, external data, or metadata in parent segments, can be set by exporting a generateMetadata function that returns a Metadata object.\n\nResolving generateMetadata is part of rendering the page. If the page can be pre-rendered and generateMetadata doesn't introduce dynamic behavior, the resulting metadata is included in the page’s initial HTML.\n\nOtherwise the metadata resolved from generateMetadata can be streamed after sending the initial UI.\n\napp/products/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata, ResolvingMetadata } from 'next'\n \ntype Props = {\n  params: Promise<{ id: string }>\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}\n \nexport async function generateMetadata(\n  { params, searchParams }: Props,\n  parent: ResolvingMetadata\n): Promise<Metadata> {\n  // read route params\n  const { id } = await params\n \n  // fetch data\n  const product = await fetch(`https://.../${id}`).then((res) => res.json())\n \n  // optionally access and extend (rather than replace) parent metadata\n  const previousImages = (await parent).openGraph?.images || []\n \n  return {\n    title: product.title,\n    openGraph: {\n      images: ['/some-specific-page-image.jpg', ...previousImages],\n    },\n  }\n}\n \nexport default function Page({ params, searchParams }: Props) {}\n\nFor type completion of params and searchParams, you can type the first argument with PageProps<'/route'> or LayoutProps<'/route'> for pages and layouts respectively.\n\nGood to know:\n\nMetadata can be added to layout.js and page.js files.\nNext.js will automatically resolve the metadata, and create the relevant <head> tags for the page.\nThe metadata object and generateMetadata function exports are only supported in Server Components.\nYou cannot export both the metadata object and generateMetadata function from the same route segment.\nfetch requests inside generateMetadata are automatically memoized for the same data across generateMetadata, generateStaticParams, Layouts, Pages, and Server Components.\nReact cache can be used if fetch is unavailable.\nFile-based metadata has the higher priority and will override the metadata object and generateMetadata function.\nReference\nParameters\n\ngenerateMetadata function accepts the following parameters:\n\nprops - An object containing the parameters of the current route:\n\nparams - An object containing the dynamic route parameters object from the root segment down to the segment generateMetadata is called from. Examples:\n\nRoute\tURL\tparams\napp/shop/[slug]/page.js\t/shop/1\t{ slug: '1' }\napp/shop/[tag]/[item]/page.js\t/shop/1/2\t{ tag: '1', item: '2' }\napp/shop/[...slug]/page.js\t/shop/1/2\t{ slug: ['1', '2'] }\n\nsearchParams - An object containing the current URL's search params\n. Examples:\n\nURL\tsearchParams\n/shop?a=1\t{ a: '1' }\n/shop?a=1&b=2\t{ a: '1', b: '2' }\n/shop?a=1&a=2\t{ a: ['1', '2'] }\n\nparent - A promise of the resolved metadata from parent route segments.\n\nReturns\n\ngenerateMetadata should return a Metadata object containing one or more metadata fields.\n\nGood to know:\n\nIf metadata doesn't depend on runtime information, it should be defined using the static metadata object rather than generateMetadata.\nfetch requests are automatically memoized for the same data across generateMetadata, generateStaticParams, Layouts, Pages, and Server Components. React cache can be used if fetch is unavailable.\nsearchParams are only available in page.js segments.\nThe redirect() and notFound() Next.js methods can also be used inside generateMetadata.\nMetadata Fields\n\nThe following fields are supported:\n\ntitle\n\nThe title attribute is used to set the title of the document. It can be defined as a simple string or an optional template object.\n\nString\nlayout.js | page.js\nexport const metadata = {\n  title: 'Next.js',\n}\n<head> output\n<title>Next.js</title>\ndefault\n\ntitle.default can be used to provide a fallback title to child route segments that don't define a title.\n\napp/layout.tsx\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: {\n    default: 'Acme',\n  },\n}\napp/about/page.tsx\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {}\n \n// Output: <title>Acme</title>\ntemplate\n\ntitle.template can be used to add a prefix or a suffix to titles defined in child route segments.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: {\n    template: '%s | Acme',\n    default: 'Acme', // a default is required when creating a template\n  },\n}\napp/about/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: 'About',\n}\n \n// Output: <title>About | Acme</title>\n\nGood to know:\n\ntitle.template applies to child route segments and not the segment it's defined in. This means:\ntitle.default is required when you add a title.template.\ntitle.template defined in layout.js will not apply to a title defined in a page.js of the same route segment.\ntitle.template defined in page.js has no effect because a page is always the terminating segment (it doesn't have any children route segments).\ntitle.template has no effect if a route has not defined a title or title.default.\nabsolute\n\ntitle.absolute can be used to provide a title that ignores title.template set in parent segments.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: {\n    template: '%s | Acme',\n  },\n}\napp/about/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: {\n    absolute: 'About',\n  },\n}\n \n// Output: <title>About</title>\n\nGood to know:\n\nlayout.js\ntitle (string) and title.default define the default title for child segments (that do not define their own title). It will augment title.template from the closest parent segment if it exists.\ntitle.absolute defines the default title for child segments. It ignores title.template from parent segments.\ntitle.template defines a new title template for child segments.\npage.js\nIf a page does not define its own title the closest parents resolved title will be used.\ntitle (string) defines the routes title. It will augment title.template from the closest parent segment if it exists.\ntitle.absolute defines the route title. It ignores title.template from parent segments.\ntitle.template has no effect in page.js because a page is always the terminating segment of a route.\ndescription\nlayout.js | page.js\nexport const metadata = {\n  description: 'The React Framework for the Web',\n}\n<head> output\n<meta name=\"description\" content=\"The React Framework for the Web\" />\nOther fields\nlayout.js | page.js\nexport const metadata = {\n  generator: 'Next.js',\n  applicationName: 'Next.js',\n  referrer: 'origin-when-cross-origin',\n  keywords: ['Next.js', 'React', 'JavaScript'],\n  authors: [{ name: 'Seb' }, { name: 'Josh', url: 'https://nextjs.org' }],\n  creator: 'Jiachi Liu',\n  publisher: 'Sebastian Markbåge',\n  formatDetection: {\n    email: false,\n    address: false,\n    telephone: false,\n  },\n}\n<head> output\n<meta name=\"application-name\" content=\"Next.js\" />\n<meta name=\"author\" content=\"Seb\" />\n<link rel=\"author\" href=\"https://nextjs.org\" />\n<meta name=\"author\" content=\"Josh\" />\n<meta name=\"generator\" content=\"Next.js\" />\n<meta name=\"keywords\" content=\"Next.js,React,JavaScript\" />\n<meta name=\"referrer\" content=\"origin-when-cross-origin\" />\n<meta name=\"color-scheme\" content=\"dark\" />\n<meta name=\"creator\" content=\"Jiachi Liu\" />\n<meta name=\"publisher\" content=\"Sebastian Markbåge\" />\n<meta name=\"format-detection\" content=\"telephone=no, address=no, email=no\" />\nmetadataBase\n\nmetadataBase is a convenience option to set a base URL prefix for metadata fields that require a fully qualified URL.\n\nmetadataBase allows URL-based metadata fields defined in the current route segment and below to use a relative path instead of an otherwise required absolute URL.\nThe field's relative path will be composed with metadataBase to form a fully qualified URL.\nlayout.js | page.js\nexport const metadata = {\n  metadataBase: new URL('https://acme.com'),\n  alternates: {\n    canonical: '/',\n    languages: {\n      'en-US': '/en-US',\n      'de-DE': '/de-DE',\n    },\n  },\n  openGraph: {\n    images: '/og-image.png',\n  },\n}\n<head> output\n<link rel=\"canonical\" href=\"https://acme.com\" />\n<link rel=\"alternate\" hreflang=\"en-US\" href=\"https://acme.com/en-US\" />\n<link rel=\"alternate\" hreflang=\"de-DE\" href=\"https://acme.com/de-DE\" />\n<meta property=\"og:image\" content=\"https://acme.com/og-image.png\" />\n\nGood to know:\n\nmetadataBase is typically set in root app/layout.js to apply to URL-based metadata fields across all routes.\nAll URL-based metadata fields that require absolute URLs can be configured with a metadataBase option.\nmetadataBase can contain a subdomain e.g. https://app.acme.com or base path e.g. https://acme.com/start/from/here\nIf a metadata field provides an absolute URL, metadataBase will be ignored.\nUsing a relative path in a URL-based metadata field without configuring a metadataBase will cause a build error.\nNext.js will normalize duplicate slashes between metadataBase (e.g. https://acme.com/) and a relative field (e.g. /path) to a single slash (e.g. https://acme.com/path)\nURL Composition\n\nURL composition favors developer intent over default directory traversal semantics.\n\nTrailing slashes between metadataBase and metadata fields are normalized.\nAn \"absolute\" path in a metadata field (that typically would replace the whole URL path) is treated as a \"relative\" path (starting from the end of metadataBase).\n\nFor example, given the following metadataBase:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  metadataBase: new URL('https://acme.com'),\n}\n\nAny metadata fields that inherit the above metadataBase and set their own value will be resolved as follows:\n\nmetadata field\tResolved URL\n/\thttps://acme.com\n./\thttps://acme.com\npayments\thttps://acme.com/payments\n/payments\thttps://acme.com/payments\n./payments\thttps://acme.com/payments\n../payments\thttps://acme.com/payments\nhttps://beta.acme.com/payments\thttps://beta.acme.com/payments\nopenGraph\nlayout.js | page.js\nexport const metadata = {\n  openGraph: {\n    title: 'Next.js',\n    description: 'The React Framework for the Web',\n    url: 'https://nextjs.org',\n    siteName: 'Next.js',\n    images: [\n      {\n        url: 'https://nextjs.org/og.png', // Must be an absolute URL\n        width: 800,\n        height: 600,\n      },\n      {\n        url: 'https://nextjs.org/og-alt.png', // Must be an absolute URL\n        width: 1800,\n        height: 1600,\n        alt: 'My custom alt',\n      },\n    ],\n    videos: [\n      {\n        url: 'https://nextjs.org/video.mp4', // Must be an absolute URL\n        width: 800,\n        height: 600,\n      },\n    ],\n    audio: [\n      {\n        url: 'https://nextjs.org/audio.mp3', // Must be an absolute URL\n      },\n    ],\n    locale: 'en_US',\n    type: 'website',\n  },\n}\n<head> output\n<meta property=\"og:title\" content=\"Next.js\" />\n<meta property=\"og:description\" content=\"The React Framework for the Web\" />\n<meta property=\"og:url\" content=\"https://nextjs.org/\" />\n<meta property=\"og:site_name\" content=\"Next.js\" />\n<meta property=\"og:locale\" content=\"en_US\" />\n<meta property=\"og:image\" content=\"https://nextjs.org/og.png\" />\n<meta property=\"og:image:width\" content=\"800\" />\n<meta property=\"og:image:height\" content=\"600\" />\n<meta property=\"og:image\" content=\"https://nextjs.org/og-alt.png\" />\n<meta property=\"og:image:width\" content=\"1800\" />\n<meta property=\"og:image:height\" content=\"1600\" />\n<meta property=\"og:image:alt\" content=\"My custom alt\" />\n<meta property=\"og:video\" content=\"https://nextjs.org/video.mp4\" />\n<meta property=\"og:video:width\" content=\"800\" />\n<meta property=\"og:video:height\" content=\"600\" />\n<meta property=\"og:audio\" content=\"https://nextjs.org/audio.mp3\" />\n<meta property=\"og:type\" content=\"website\" />\nlayout.js | page.js\nexport const metadata = {\n  openGraph: {\n    title: 'Next.js',\n    description: 'The React Framework for the Web',\n    type: 'article',\n    publishedTime: '2023-01-01T00:00:00.000Z',\n    authors: ['Seb', 'Josh'],\n  },\n}\n<head> output\n<meta property=\"og:title\" content=\"Next.js\" />\n<meta property=\"og:description\" content=\"The React Framework for the Web\" />\n<meta property=\"og:type\" content=\"article\" />\n<meta property=\"article:published_time\" content=\"2023-01-01T00:00:00.000Z\" />\n<meta property=\"article:author\" content=\"Seb\" />\n<meta property=\"article:author\" content=\"Josh\" />\n\nGood to know:\n\nIt may be more convenient to use the file-based Metadata API for Open Graph images. Rather than having to sync the config export with actual files, the file-based API will automatically generate the correct metadata for you.\nrobots\nlayout.tsx | page.tsx\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  robots: {\n    index: true,\n    follow: true,\n    nocache: false,\n    googleBot: {\n      index: true,\n      follow: true,\n      noimageindex: false,\n      'max-video-preview': -1,\n      'max-image-preview': 'large',\n      'max-snippet': -1,\n    },\n  },\n}\n<head> output\n<meta name=\"robots\" content=\"index, follow\" />\n<meta\n  name=\"googlebot\"\n  content=\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"\n/>\nicons\n\nGood to know: We recommend using the file-based Metadata API for icons where possible. Rather than having to sync the config export with actual files, the file-based API will automatically generate the correct metadata for you.\n\nlayout.js | page.js\nexport const metadata = {\n  icons: {\n    icon: '/icon.png',\n    shortcut: '/shortcut-icon.png',\n    apple: '/apple-icon.png',\n    other: {\n      rel: 'apple-touch-icon-precomposed',\n      url: '/apple-touch-icon-precomposed.png',\n    },\n  },\n}\n<head> output\n<link rel=\"shortcut icon\" href=\"/shortcut-icon.png\" />\n<link rel=\"icon\" href=\"/icon.png\" />\n<link rel=\"apple-touch-icon\" href=\"/apple-icon.png\" />\n<link\n  rel=\"apple-touch-icon-precomposed\"\n  href=\"/apple-touch-icon-precomposed.png\"\n/>\nlayout.js | page.js\nexport const metadata = {\n  icons: {\n    icon: [\n      { url: '/icon.png' },\n      new URL('/icon.png', 'https://example.com'),\n      { url: '/icon-dark.png', media: '(prefers-color-scheme: dark)' },\n    ],\n    shortcut: ['/shortcut-icon.png'],\n    apple: [\n      { url: '/apple-icon.png' },\n      { url: '/apple-icon-x3.png', sizes: '180x180', type: 'image/png' },\n    ],\n    other: [\n      {\n        rel: 'apple-touch-icon-precomposed',\n        url: '/apple-touch-icon-precomposed.png',\n      },\n    ],\n  },\n}\n<head> output\n<link rel=\"shortcut icon\" href=\"/shortcut-icon.png\" />\n<link rel=\"icon\" href=\"/icon.png\" />\n<link rel=\"icon\" href=\"https://example.com/icon.png\" />\n<link rel=\"icon\" href=\"/icon-dark.png\" media=\"(prefers-color-scheme: dark)\" />\n<link rel=\"apple-touch-icon\" href=\"/apple-icon.png\" />\n<link\n  rel=\"apple-touch-icon-precomposed\"\n  href=\"/apple-touch-icon-precomposed.png\"\n/>\n<link\n  rel=\"apple-touch-icon\"\n  href=\"/apple-icon-x3.png\"\n  sizes=\"180x180\"\n  type=\"image/png\"\n/>\n\nGood to know: The msapplication-* meta tags are no longer supported in Chromium builds of Microsoft Edge, and thus no longer needed.\n\nthemeColor\n\nDeprecated: The themeColor option in metadata is deprecated as of Next.js 14. Please use the viewport configuration instead.\n\ncolorScheme\n\nDeprecated: The colorScheme option in metadata is deprecated as of Next.js 14. Please use the viewport configuration instead.\n\nmanifest\n\nA web application manifest, as defined in the Web Application Manifest specification\n.\n\nlayout.js | page.js\nexport const metadata = {\n  manifest: 'https://nextjs.org/manifest.json',\n}\n<head> output\n<link rel=\"manifest\" href=\"https://nextjs.org/manifest.json\" />\ntwitter\n\nThe Twitter specification is (surprisingly) used for more than just X (formerly known as Twitter).\n\nLearn more about the Twitter Card markup reference\n.\n\nlayout.js | page.js\nexport const metadata = {\n  twitter: {\n    card: 'summary_large_image',\n    title: 'Next.js',\n    description: 'The React Framework for the Web',\n    siteId: '1467726470533754880',\n    creator: '@nextjs',\n    creatorId: '1467726470533754880',\n    images: ['https://nextjs.org/og.png'], // Must be an absolute URL\n  },\n}\n<head> output\n<meta name=\"twitter:card\" content=\"summary_large_image\" />\n<meta name=\"twitter:site:id\" content=\"1467726470533754880\" />\n<meta name=\"twitter:creator\" content=\"@nextjs\" />\n<meta name=\"twitter:creator:id\" content=\"1467726470533754880\" />\n<meta name=\"twitter:title\" content=\"Next.js\" />\n<meta name=\"twitter:description\" content=\"The React Framework for the Web\" />\n<meta name=\"twitter:image\" content=\"https://nextjs.org/og.png\" />\nlayout.js | page.js\nexport const metadata = {\n  twitter: {\n    card: 'app',\n    title: 'Next.js',\n    description: 'The React Framework for the Web',\n    siteId: '1467726470533754880',\n    creator: '@nextjs',\n    creatorId: '1467726470533754880',\n    images: {\n      url: 'https://nextjs.org/og.png',\n      alt: 'Next.js Logo',\n    },\n    app: {\n      name: 'twitter_app',\n      id: {\n        iphone: 'twitter_app://iphone',\n        ipad: 'twitter_app://ipad',\n        googleplay: 'twitter_app://googleplay',\n      },\n      url: {\n        iphone: 'https://iphone_url',\n        ipad: 'https://ipad_url',\n      },\n    },\n  },\n}\n<head> output\n<meta name=\"twitter:site:id\" content=\"1467726470533754880\" />\n<meta name=\"twitter:creator\" content=\"@nextjs\" />\n<meta name=\"twitter:creator:id\" content=\"1467726470533754880\" />\n<meta name=\"twitter:title\" content=\"Next.js\" />\n<meta name=\"twitter:description\" content=\"The React Framework for the Web\" />\n<meta name=\"twitter:card\" content=\"app\" />\n<meta name=\"twitter:image\" content=\"https://nextjs.org/og.png\" />\n<meta name=\"twitter:image:alt\" content=\"Next.js Logo\" />\n<meta name=\"twitter:app:name:iphone\" content=\"twitter_app\" />\n<meta name=\"twitter:app:id:iphone\" content=\"twitter_app://iphone\" />\n<meta name=\"twitter:app:id:ipad\" content=\"twitter_app://ipad\" />\n<meta name=\"twitter:app:id:googleplay\" content=\"twitter_app://googleplay\" />\n<meta name=\"twitter:app:url:iphone\" content=\"https://iphone_url\" />\n<meta name=\"twitter:app:url:ipad\" content=\"https://ipad_url\" />\n<meta name=\"twitter:app:name:ipad\" content=\"twitter_app\" />\n<meta name=\"twitter:app:name:googleplay\" content=\"twitter_app\" />\nviewport\n\nDeprecated: The viewport option in metadata is deprecated as of Next.js 14. Please use the viewport configuration instead.\n\nverification\nlayout.js | page.js\nexport const metadata = {\n  verification: {\n    google: 'google',\n    yandex: 'yandex',\n    yahoo: 'yahoo',\n    other: {\n      me: ['my-email', 'my-link'],\n    },\n  },\n}\n<head> output\n<meta name=\"google-site-verification\" content=\"google\" />\n<meta name=\"y_key\" content=\"yahoo\" />\n<meta name=\"yandex-verification\" content=\"yandex\" />\n<meta name=\"me\" content=\"my-email\" />\n<meta name=\"me\" content=\"my-link\" />\nappleWebApp\nlayout.js | page.js\nexport const metadata = {\n  itunes: {\n    appId: 'myAppStoreID',\n    appArgument: 'myAppArgument',\n  },\n  appleWebApp: {\n    title: 'Apple Web App',\n    statusBarStyle: 'black-translucent',\n    startupImage: [\n      '/assets/startup/apple-touch-startup-image-768x1004.png',\n      {\n        url: '/assets/startup/apple-touch-startup-image-1536x2008.png',\n        media: '(device-width: 768px) and (device-height: 1024px)',\n      },\n    ],\n  },\n}\n<head> output\n<meta\n  name=\"apple-itunes-app\"\n  content=\"app-id=myAppStoreID, app-argument=myAppArgument\"\n/>\n<meta name=\"mobile-web-app-capable\" content=\"yes\" />\n<meta name=\"apple-mobile-web-app-title\" content=\"Apple Web App\" />\n<link\n  href=\"/assets/startup/apple-touch-startup-image-768x1004.png\"\n  rel=\"apple-touch-startup-image\"\n/>\n<link\n  href=\"/assets/startup/apple-touch-startup-image-1536x2008.png\"\n  media=\"(device-width: 768px) and (device-height: 1024px)\"\n  rel=\"apple-touch-startup-image\"\n/>\n<meta\n  name=\"apple-mobile-web-app-status-bar-style\"\n  content=\"black-translucent\"\n/>\nalternates\nlayout.js | page.js\nexport const metadata = {\n  alternates: {\n    canonical: 'https://nextjs.org',\n    languages: {\n      'en-US': 'https://nextjs.org/en-US',\n      'de-DE': 'https://nextjs.org/de-DE',\n    },\n    media: {\n      'only screen and (max-width: 600px)': 'https://nextjs.org/mobile',\n    },\n    types: {\n      'application/rss+xml': 'https://nextjs.org/rss',\n    },\n  },\n}\n<head> output\n<link rel=\"canonical\" href=\"https://nextjs.org\" />\n<link rel=\"alternate\" hreflang=\"en-US\" href=\"https://nextjs.org/en-US\" />\n<link rel=\"alternate\" hreflang=\"de-DE\" href=\"https://nextjs.org/de-DE\" />\n<link\n  rel=\"alternate\"\n  media=\"only screen and (max-width: 600px)\"\n  href=\"https://nextjs.org/mobile\"\n/>\n<link\n  rel=\"alternate\"\n  type=\"application/rss+xml\"\n  href=\"https://nextjs.org/rss\"\n/>\nappLinks\nlayout.js | page.js\nexport const metadata = {\n  appLinks: {\n    ios: {\n      url: 'https://nextjs.org/ios',\n      app_store_id: 'app_store_id',\n    },\n    android: {\n      package: 'com.example.android/package',\n      app_name: 'app_name_android',\n    },\n    web: {\n      url: 'https://nextjs.org/web',\n      should_fallback: true,\n    },\n  },\n}\n<head> output\n<meta property=\"al:ios:url\" content=\"https://nextjs.org/ios\" />\n<meta property=\"al:ios:app_store_id\" content=\"app_store_id\" />\n<meta property=\"al:android:package\" content=\"com.example.android/package\" />\n<meta property=\"al:android:app_name\" content=\"app_name_android\" />\n<meta property=\"al:web:url\" content=\"https://nextjs.org/web\" />\n<meta property=\"al:web:should_fallback\" content=\"true\" />\narchives\n\nDescribes a collection of records, documents, or other materials of historical interest (source\n).\n\nlayout.js | page.js\nexport const metadata = {\n  archives: ['https://nextjs.org/13'],\n}\n<head> output\n<link rel=\"archives\" href=\"https://nextjs.org/13\" />\nassets\nlayout.js | page.js\nexport const metadata = {\n  assets: ['https://nextjs.org/assets'],\n}\n<head> output\n<link rel=\"assets\" href=\"https://nextjs.org/assets\" />\nbookmarks\nlayout.js | page.js\nexport const metadata = {\n  bookmarks: ['https://nextjs.org/13'],\n}\n<head> output\n<link rel=\"bookmarks\" href=\"https://nextjs.org/13\" />\ncategory\nlayout.js | page.js\nexport const metadata = {\n  category: 'technology',\n}\n<head> output\n<meta name=\"category\" content=\"technology\" />\nfacebook\n\nYou can connect a Facebook app or Facebook account to your webpage for certain Facebook Social Plugins Facebook Documentation\n\nGood to know: You can specify either appId or admins, but not both.\n\nlayout.js | page.js\nexport const metadata = {\n  facebook: {\n    appId: '12345678',\n  },\n}\n<head> output\n<meta property=\"fb:app_id\" content=\"12345678\" />\nlayout.js | page.js\nexport const metadata = {\n  facebook: {\n    admins: '12345678',\n  },\n}\n<head> output\n<meta property=\"fb:admins\" content=\"12345678\" />\n\nIf you want to generate multiple fb:admins meta tags you can use array value.\n\nlayout.js | page.js\nexport const metadata = {\n  facebook: {\n    admins: ['12345678', '87654321'],\n  },\n}\n<head> output\n<meta property=\"fb:admins\" content=\"12345678\" />\n<meta property=\"fb:admins\" content=\"87654321\" />\npinterest\n\nYou can enable or disable Pinterest Rich Pins\n on your webpage.\n\nlayout.js | page.js\nexport const metadata = {\n  pinterest: {\n    richPin: true,\n  },\n}\n<head> output\n<meta name=\"pinterest-rich-pin\" content=\"true\" />\nother\n\nAll metadata options should be covered using the built-in support. However, there may be custom metadata tags specific to your site, or brand new metadata tags just released. You can use the other option to render any custom metadata tag.\n\nlayout.js | page.js\nexport const metadata = {\n  other: {\n    custom: 'meta',\n  },\n}\n<head> output\n<meta name=\"custom\" content=\"meta\" />\n\nIf you want to generate multiple same key meta tags you can use array value.\n\nlayout.js | page.js\nexport const metadata = {\n  other: {\n    custom: ['meta1', 'meta2'],\n  },\n}\n<head> output\n<meta name=\"custom\" content=\"meta1\" /> <meta name=\"custom\" content=\"meta2\" />\nTypes\n\nYou can add type safety to your metadata by using the Metadata type. If you are using the built-in TypeScript plugin in your IDE, you do not need to manually add the type, but you can still explicitly add it if you want.\n\nmetadata object\nlayout.tsx | page.tsx\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: 'Next.js',\n}\ngenerateMetadata function\nRegular function\nlayout.tsx | page.tsx\nimport type { Metadata } from 'next'\n \nexport function generateMetadata(): Metadata {\n  return {\n    title: 'Next.js',\n  }\n}\nAsync function\nlayout.tsx | page.tsx\nimport type { Metadata } from 'next'\n \nexport async function generateMetadata(): Promise<Metadata> {\n  return {\n    title: 'Next.js',\n  }\n}\nWith segment props\nlayout.tsx | page.tsx\nimport type { Metadata } from 'next'\n \ntype Props = {\n  params: Promise<{ id: string }>\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}\n \nexport function generateMetadata({ params, searchParams }: Props): Metadata {\n  return {\n    title: 'Next.js',\n  }\n}\n \nexport default function Page({ params, searchParams }: Props) {}\nWith parent metadata\nlayout.tsx | page.tsx\nimport type { Metadata, ResolvingMetadata } from 'next'\n \nexport async function generateMetadata(\n  { params, searchParams }: Props,\n  parent: ResolvingMetadata\n): Promise<Metadata> {\n  return {\n    title: 'Next.js',\n  }\n}\nJavaScript Projects\n\nFor JavaScript projects, you can use JSDoc to add type safety.\n\nlayout.js | page.js\n/** @type {import(\"next\").Metadata} */\nexport const metadata = {\n  title: 'Next.js',\n}\nUnsupported Metadata\n\nThe following metadata types do not currently have built-in support. However, they can still be rendered in the layout or page itself.\n\nMetadata\tRecommendation\n<meta http-equiv=\"...\">\tUse appropriate HTTP Headers via redirect(), Proxy, Security Headers\n<base>\tRender the tag in the layout or page itself.\n<noscript>\tRender the tag in the layout or page itself.\n<style>\tLearn more about styling in Next.js.\n<script>\tLearn more about using scripts.\n<link rel=\"stylesheet\" />\timport stylesheets directly in the layout or page itself.\n<link rel=\"preload />\tUse ReactDOM preload method\n<link rel=\"preconnect\" />\tUse ReactDOM preconnect method\n<link rel=\"dns-prefetch\" />\tUse ReactDOM prefetchDNS method\nResource hints\n\nThe <link> element has a number of rel keywords that can be used to hint to the browser that an external resource is likely to be needed. The browser uses this information to apply preloading optimizations depending on the keyword.\n\nWhile the Metadata API doesn't directly support these hints, you can use new ReactDOM methods\n to safely insert them into the <head> of the document.\n\napp/preload-resources.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport ReactDOM from 'react-dom'\n \nexport function PreloadResources() {\n  ReactDOM.preload('...', { as: '...' })\n  ReactDOM.preconnect('...', { crossOrigin: '...' })\n  ReactDOM.prefetchDNS('...')\n \n  return '...'\n}\n<link rel=\"preload\">\n\nStart loading a resource early in the page rendering (browser) lifecycle. MDN Docs\n.\n\nReactDOM.preload(href: string, options: { as: string })\n<head> output\n<link rel=\"preload\" href=\"...\" as=\"...\" />\n<link rel=\"preconnect\">\n\nPreemptively initiate a connection to an origin. MDN Docs\n.\n\nReactDOM.preconnect(href: string, options?: { crossOrigin?: string })\n<head> output\n<link rel=\"preconnect\" href=\"...\" crossorigin />\n<link rel=\"dns-prefetch\">\n\nAttempt to resolve a domain name before resources get requested. MDN Docs\n.\n\nReactDOM.prefetchDNS(href: string)\n<head> output\n<link rel=\"dns-prefetch\" href=\"...\" />\n\nGood to know:\n\nThese methods are currently only supported in Client Components, which are still Server Side Rendered on initial page load.\nNext.js in-built features such as next/font, next/image and next/script automatically handle relevant resource hints.\nBehavior\nDefault Fields\n\nThere are two default meta tags that are always added even if a route doesn't define metadata:\n\nThe meta charset tag\n sets the character encoding for the website.\nThe meta viewport tag\n sets the viewport width and scale for the website to adjust for different devices.\n<meta charset=\"utf-8\" />\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\nGood to know: You can overwrite the default viewport meta tag.\n\nStreaming metadata\n\nStreaming metadata allows Next.js to render and send the initial UI to the browser, without waiting for generateMetadata to complete.\n\nWhen generateMetadata resolves, the resulting metadata tags are appended to the <body> tag. We have verified that metadata is interpreted correctly by bots that execute JavaScript and inspect the full DOM (e.g. Googlebot).\n\nFor HTML-limited bots that can’t execute JavaScript (e.g. facebookexternalhit), metadata continues to block page rendering. The resulting metadata will be available in the <head> tag.\n\nNext.js automatically detects HTML-limited bots by looking at the User Agent header. You can use the htmlLimitedBots option in your Next.js config file to override the default User Agent list\n.\n\nTo fully disable streaming metadata:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst config: NextConfig = {\n  htmlLimitedBots: /.*/,\n}\n \nexport default config\n\nStreaming metadata improves perceived performance by reducing TTFB\n and can help lowering LCP\n time.\n\nOverriding htmlLimitedBots could lead to longer response times. Streaming metadata is an advanced feature, and the default should be sufficient for most cases.\n\nOrdering\n\nMetadata is evaluated in order, starting from the root segment down to the segment closest to the final page.js segment. For example:\n\napp/layout.tsx (Root Layout)\napp/blog/layout.tsx (Nested Blog Layout)\napp/blog/[slug]/page.tsx (Blog Page)\nMerging\n\nFollowing the evaluation order, Metadata objects exported from multiple segments in the same route are shallowly merged together to form the final metadata output of a route. Duplicate keys are replaced based on their ordering.\n\nThis means metadata with nested fields such as openGraph and robots that are defined in an earlier segment are overwritten by the last segment to define them.\n\nOverwriting fields\napp/layout.js\nexport const metadata = {\n  title: 'Acme',\n  openGraph: {\n    title: 'Acme',\n    description: 'Acme is a...',\n  },\n}\napp/blog/page.js\nexport const metadata = {\n  title: 'Blog',\n  openGraph: {\n    title: 'Blog',\n  },\n}\n \n// Output:\n// <title>Blog</title>\n// <meta property=\"og:title\" content=\"Blog\" />\n\nIn the example above:\n\ntitle from app/layout.js is replaced by title in app/blog/page.js.\nAll openGraph fields from app/layout.js are replaced in app/blog/page.js because app/blog/page.js sets openGraph metadata. Note the absence of openGraph.description.\n\nIf you'd like to share some nested fields between segments while overwriting others, you can pull them out into a separate variable:\n\napp/shared-metadata.js\nexport const openGraphImage = { images: ['http://...'] }\napp/page.js\nimport { openGraphImage } from './shared-metadata'\n \nexport const metadata = {\n  openGraph: {\n    ...openGraphImage,\n    title: 'Home',\n  },\n}\napp/about/page.js\nimport { openGraphImage } from '../shared-metadata'\n \nexport const metadata = {\n  openGraph: {\n    ...openGraphImage,\n    title: 'About',\n  },\n}\n\nIn the example above, the OG image is shared between app/layout.js and app/about/page.js while the titles are different.\n\nInheriting fields\napp/layout.js\nexport const metadata = {\n  title: 'Acme',\n  openGraph: {\n    title: 'Acme',\n    description: 'Acme is a...',\n  },\n}\napp/about/page.js\nexport const metadata = {\n  title: 'About',\n}\n \n// Output:\n// <title>About</title>\n// <meta property=\"og:title\" content=\"Acme\" />\n// <meta property=\"og:description\" content=\"Acme is a...\" />\n\nNotes\n\ntitle from app/layout.js is replaced by title in app/about/page.js.\nAll openGraph fields from app/layout.js are inherited in app/about/page.js because app/about/page.js doesn't set openGraph metadata.\nVersion History\nVersion\tChanges\nv15.2.0\tIntroduced streaming support to generateMetadata.\nv13.2.0\tviewport, themeColor, and colorScheme deprecated in favor of the viewport configuration.\nv13.2.0\tmetadata and generateMetadata introduced.\nNext Steps\nView all the Metadata API options.\nMetadata Files\nAPI documentation for the metadata file conventions.\ngenerateViewport\nAPI Reference for the generateViewport function.\nPrevious\ngenerateImageMetadata\nNext\ngenerateSitemaps\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: generateStaticParams | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/generate-static-params",
    "html": "API Reference\nFunctions\ngenerateStaticParams\nCopy page\ngenerateStaticParams\n\nThe generateStaticParams function can be used in combination with dynamic route segments to statically generate routes at build time instead of on-demand at request time.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\n// Return a list of `params` to populate the [slug] dynamic segment\nexport async function generateStaticParams() {\n  const posts = await fetch('https://.../posts').then((res) => res.json())\n \n  return posts.map((post) => ({\n    slug: post.slug,\n  }))\n}\n \n// Multiple versions of this page will be statically generated\n// using the `params` returned by `generateStaticParams`\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  // ...\n}\n\nGood to know:\n\nYou can use the dynamicParams segment config option to control what happens when a dynamic segment is visited that was not generated with generateStaticParams.\nYou must return an empty array from generateStaticParams or utilize export const dynamic = 'force-static' in order to revalidate (ISR) paths at runtime.\nDuring next dev, generateStaticParams will be called when you navigate to a route.\nDuring next build, generateStaticParams runs before the corresponding Layouts or Pages are generated.\nDuring revalidation (ISR), generateStaticParams will not be called again.\ngenerateStaticParams replaces the getStaticPaths function in the Pages Router.\nParameters\n\noptions.params (optional)\n\nIf multiple dynamic segments in a route use generateStaticParams, the child generateStaticParams function is executed once for each set of params the parent generates.\n\nThe params object contains the populated params from the parent generateStaticParams, which can be used to generate the params in a child segment.\n\nReturns\n\ngenerateStaticParams should return an array of objects where each object represents the populated dynamic segments of a single route.\n\nEach property in the object is a dynamic segment to be filled in for the route.\nThe properties name is the segment's name, and the properties value is what that segment should be filled in with.\nExample Route\tgenerateStaticParams Return Type\n/product/[id]\t{ id: string }[]\n/products/[category]/[product]\t{ category: string, product: string }[]\n/products/[...slug]\t{ slug: string[] }[]\nSingle Dynamic Segment\napp/product/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport function generateStaticParams() {\n  return [{ id: '1' }, { id: '2' }, { id: '3' }]\n}\n \n// Three versions of this page will be statically generated\n// using the `params` returned by `generateStaticParams`\n// - /product/1\n// - /product/2\n// - /product/3\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n  // ...\n}\nMultiple Dynamic Segments\napp/products/[category]/[product]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport function generateStaticParams() {\n  return [\n    { category: 'a', product: '1' },\n    { category: 'b', product: '2' },\n    { category: 'c', product: '3' },\n  ]\n}\n \n// Three versions of this page will be statically generated\n// using the `params` returned by `generateStaticParams`\n// - /products/a/1\n// - /products/b/2\n// - /products/c/3\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ category: string; product: string }>\n}) {\n  const { category, product } = await params\n  // ...\n}\nCatch-all Dynamic Segment\napp/product/[...slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport function generateStaticParams() {\n  return [{ slug: ['a', '1'] }, { slug: ['b', '2'] }, { slug: ['c', '3'] }]\n}\n \n// Three versions of this page will be statically generated\n// using the `params` returned by `generateStaticParams`\n// - /product/a/1\n// - /product/b/2\n// - /product/c/3\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ slug: string[] }>\n}) {\n  const { slug } = await params\n  // ...\n}\nExamples\nStatic Rendering\nAll paths at build time\n\nTo statically render all paths at build time, supply the full list of paths to generateStaticParams:\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport async function generateStaticParams() {\n  const posts = await fetch('https://.../posts').then((res) => res.json())\n \n  return posts.map((post) => ({\n    slug: post.slug,\n  }))\n}\nSubset of paths at build time\n\nTo statically render a subset of paths at build time, and the rest the first time they're visited at runtime, return a partial list of paths:\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport async function generateStaticParams() {\n  const posts = await fetch('https://.../posts').then((res) => res.json())\n \n  // Render the first 10 posts at build time\n  return posts.slice(0, 10).map((post) => ({\n    slug: post.slug,\n  }))\n}\n\nThen, by using the dynamicParams segment config option, you can control what happens when a dynamic segment is visited that was not generated with generateStaticParams.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\n// All posts besides the top 10 will be a 404\nexport const dynamicParams = false\n \nexport async function generateStaticParams() {\n  const posts = await fetch('https://.../posts').then((res) => res.json())\n  const topPosts = posts.slice(0, 10)\n \n  return topPosts.map((post) => ({\n    slug: post.slug,\n  }))\n}\nAll paths at runtime\n\nTo statically render all paths the first time they're visited, return an empty array (no paths will be rendered at build time) or utilize export const dynamic = 'force-static':\n\napp/blog/[slug]/page.js\nexport async function generateStaticParams() {\n  return []\n}\n\nGood to know: You must always return an array from generateStaticParams, even if it's empty. Otherwise, the route will be dynamically rendered.\n\napp/changelog/[slug]/page.js\nexport const dynamic = 'force-static'\nDisable rendering for unspecified paths\n\nTo prevent unspecified paths from being statically rendered at runtime, add the export const dynamicParams = false option in a route segment. When this config option is used, only paths provided by generateStaticParams will be served, and unspecified routes will 404 or match (in the case of catch-all routes).\n\nMultiple Dynamic Segments in a Route\n\nYou can generate params for dynamic segments above the current layout or page, but not below. For example, given the app/products/[category]/[product] route:\n\napp/products/[category]/[product]/page.js can generate params for both [category] and [product].\napp/products/[category]/layout.js can only generate params for [category].\n\nThere are two approaches to generating params for a route with multiple dynamic segments:\n\nGenerate params from the bottom up\n\nGenerate multiple dynamic segments from the child route segment.\n\napp/products/[category]/[product]/page.tsx\nTypeScript\nJavaScript\nTypeScript\n// Generate segments for both [category] and [product]\nexport async function generateStaticParams() {\n  const products = await fetch('https://.../products').then((res) => res.json())\n \n  return products.map((product) => ({\n    category: product.category.slug,\n    product: product.id,\n  }))\n}\n \nexport default function Page({\n  params,\n}: {\n  params: Promise<{ category: string; product: string }>\n}) {\n  // ...\n}\nGenerate params from the top down\n\nGenerate the parent segments first and use the result to generate the child segments.\n\napp/products/[category]/layout.tsx\nTypeScript\nJavaScript\nTypeScript\n// Generate segments for [category]\nexport async function generateStaticParams() {\n  const products = await fetch('https://.../products').then((res) => res.json())\n \n  return products.map((product) => ({\n    category: product.category.slug,\n  }))\n}\n \nexport default function Layout({\n  params,\n}: {\n  params: Promise<{ category: string }>\n}) {\n  // ...\n}\n\nA child route segment's generateStaticParams function is executed once for each segment a parent generateStaticParams generates.\n\nThe child generateStaticParams function can use the params returned from the parent generateStaticParams function to dynamically generate its own segments.\n\napp/products/[category]/[product]/page.tsx\nTypeScript\nJavaScript\nTypeScript\n// Generate segments for [product] using the `params` passed from\n// the parent segment's `generateStaticParams` function\nexport async function generateStaticParams({\n  params: { category },\n}: {\n  params: { category: string }\n}) {\n  const products = await fetch(\n    `https://.../products?category=${category}`\n  ).then((res) => res.json())\n \n  return products.map((product) => ({\n    product: product.id,\n  }))\n}\n \nexport default function Page({\n  params,\n}: {\n  params: Promise<{ category: string; product: string }>\n}) {\n  // ...\n}\n\nNotice that the params argument can be accessed synchronously and includes only parent segment params.\n\nFor type completion, you can make use of the TypeScript Awaited helper in combination with either Page Props helper or Layout Props helper:\n\napp/products/[category]/[product]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport async function generateStaticParams({\n  params: { category },\n}: {\n  params: Awaited<LayoutProps<'/products/[category]'>['params']>\n}) {\n  const products = await fetch(\n    `https://.../products?category=${category}`\n  ).then((res) => res.json())\n \n  return products.map((product) => ({\n    product: product.id,\n  }))\n}\n\nGood to know: fetch requests are automatically memoized for the same data across all generate-prefixed functions, Layouts, Pages, and Server Components. React cache can be used if fetch is unavailable.\n\nVersion History\nVersion\tChanges\nv13.0.0\tgenerateStaticParams introduced.\nPrevious\ngenerateSitemaps\nNext\ngenerateViewport\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: generateViewport | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/generate-viewport",
    "html": "API Reference\nFunctions\ngenerateViewport\nCopy page\ngenerateViewport\n\nYou can customize the initial viewport of the page with the static viewport object or the dynamic generateViewport function.\n\nGood to know:\n\nThe viewport object and generateViewport function exports are only supported in Server Components.\nYou cannot export both the viewport object and generateViewport function from the same route segment.\nIf you're coming from migrating metadata exports, you can use metadata-to-viewport-export codemod to update your changes.\nThe viewport object\n\nTo define the viewport options, export a viewport object from a layout.jsx or page.jsx file.\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Viewport } from 'next'\n \nexport const viewport: Viewport = {\n  themeColor: 'black',\n}\n \nexport default function Page() {}\ngenerateViewport function\n\ngenerateViewport should return a Viewport object containing one or more viewport fields.\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport function generateViewport({ params }) {\n  return {\n    themeColor: '...',\n  }\n}\n\nIn TypeScript, the params argument can be typed via PageProps<'/route'> or LayoutProps<'/route'> depending on where generateViewport is defined.\n\nGood to know:\n\nIf the viewport doesn't depend on runtime information, it should be defined using the static viewport object rather than generateViewport.\nViewport Fields\nthemeColor\n\nLearn more about theme-color\n.\n\nSimple theme color\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Viewport } from 'next'\n \nexport const viewport: Viewport = {\n  themeColor: 'black',\n}\n<head> output\n<meta name=\"theme-color\" content=\"black\" />\n\nWith media attribute\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Viewport } from 'next'\n \nexport const viewport: Viewport = {\n  themeColor: [\n    { media: '(prefers-color-scheme: light)', color: 'cyan' },\n    { media: '(prefers-color-scheme: dark)', color: 'black' },\n  ],\n}\n<head> output\n<meta name=\"theme-color\" media=\"(prefers-color-scheme: light)\" content=\"cyan\" />\n<meta name=\"theme-color\" media=\"(prefers-color-scheme: dark)\" content=\"black\" />\nwidth, initialScale, maximumScale and userScalable\n\nGood to know: The viewport meta tag is automatically set, and manual configuration is usually unnecessary as the default is sufficient. However, the information is provided for completeness.\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Viewport } from 'next'\n \nexport const viewport: Viewport = {\n  width: 'device-width',\n  initialScale: 1,\n  maximumScale: 1,\n  userScalable: false,\n  // Also supported but less commonly used\n  // interactiveWidget: 'resizes-visual',\n}\n<head> output\n<meta\n  name=\"viewport\"\n  content=\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no\"\n/>\ncolorScheme\n\nLearn more about color-scheme\n.\n\nlayout.tsx | page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Viewport } from 'next'\n \nexport const viewport: Viewport = {\n  colorScheme: 'dark',\n}\n<head> output\n<meta name=\"color-scheme\" content=\"dark\" />\nTypes\n\nYou can add type safety to your viewport object by using the Viewport type. If you are using the built-in TypeScript plugin in your IDE, you do not need to manually add the type, but you can still explicitly add it if you want.\n\nviewport object\nimport type { Viewport } from 'next'\n \nexport const viewport: Viewport = {\n  themeColor: 'black',\n}\ngenerateViewport function\nRegular function\nimport type { Viewport } from 'next'\n \nexport function generateViewport(): Viewport {\n  return {\n    themeColor: 'black',\n  }\n}\nWith segment props\nimport type { Viewport } from 'next'\n \ntype Props = {\n  params: Promise<{ id: string }>\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}\n \nexport function generateViewport({ params, searchParams }: Props): Viewport {\n  return {\n    themeColor: 'black',\n  }\n}\n \nexport default function Page({ params, searchParams }: Props) {}\nJavaScript Projects\n\nFor JavaScript projects, you can use JSDoc to add type safety.\n\n/** @type {import(\"next\").Viewport} */\nexport const viewport = {\n  themeColor: 'black',\n}\nVersion History\nVersion\tChanges\nv14.0.0\tviewport and generateViewport introduced.\nNext Steps\nView all the Metadata API options.\nMetadata Files\nAPI documentation for the metadata file conventions.\nPrevious\ngenerateStaticParams\nNext\nheaders\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: headers | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/headers",
    "html": "API Reference\nFunctions\nheaders\nCopy page\nheaders\n\nheaders is an async function that allows you to read the HTTP incoming request headers from a Server Component.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { headers } from 'next/headers'\n \nexport default async function Page() {\n  const headersList = await headers()\n  const userAgent = headersList.get('user-agent')\n}\nReference\nParameters\n\nheaders does not take any parameters.\n\nReturns\n\nheaders returns a read-only Web Headers\n object.\n\nHeaders.entries()\n: Returns an iterator\n allowing to go through all key/value pairs contained in this object.\nHeaders.forEach()\n: Executes a provided function once for each key/value pair in this Headers object.\nHeaders.get()\n: Returns a String\n sequence of all the values of a header within a Headers object with a given name.\nHeaders.has()\n: Returns a boolean stating whether a Headers object contains a certain header.\nHeaders.keys()\n: Returns an iterator\n allowing you to go through all keys of the key/value pairs contained in this object.\nHeaders.values()\n: Returns an iterator\n allowing you to go through all values of the key/value pairs contained in this object.\nGood to know\nheaders is an asynchronous function that returns a promise. You must use async/await or React's use\n function.\nIn version 14 and earlier, headers was a synchronous function. To help with backwards compatibility, you can still access it synchronously in Next.js 15, but this behavior will be deprecated in the future.\nSince headers is read-only, you cannot set or delete the outgoing request headers.\nheaders is a Dynamic API whose returned values cannot be known ahead of time. Using it in will opt a route into dynamic rendering.\nExamples\nUsing the Authorization header\napp/page.js\nimport { headers } from 'next/headers'\n \nexport default async function Page() {\n  const authorization = (await headers()).get('authorization')\n  const res = await fetch('...', {\n    headers: { authorization }, // Forward the authorization header\n  })\n  const user = await res.json()\n \n  return <h1>{user.name}</h1>\n}\nVersion History\nVersion\tChanges\nv15.0.0-RC\theaders is now an async function. A codemod is available.\nv13.0.0\theaders introduced.\nPrevious\ngenerateViewport\nNext\nImageResponse\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: ImageResponse | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/image-response",
    "html": "API Reference\nFunctions\nImageResponse\nCopy page\nImageResponse\n\nThe ImageResponse constructor allows you to generate dynamic images using JSX and CSS. This is useful for generating social media images such as Open Graph images, Twitter cards, and more.\n\nReference\nParameters\n\nThe following parameters are available for ImageResponse:\n\nimport { ImageResponse } from 'next/og'\n \nnew ImageResponse(\n  element: ReactElement,\n  options: {\n    width?: number = 1200\n    height?: number = 630\n    emoji?: 'twemoji' | 'blobmoji' | 'noto' | 'openmoji' = 'twemoji',\n    fonts?: {\n      name: string,\n      data: ArrayBuffer,\n      weight: number,\n      style: 'normal' | 'italic'\n    }[]\n    debug?: boolean = false\n \n    // Options that will be passed to the HTTP response\n    status?: number = 200\n    statusText?: string\n    headers?: Record<string, string>\n  },\n)\n\nExamples are available in the Vercel OG Playground\n.\n\nSupported HTML and CSS features\n\nImageResponse supports common CSS properties including flexbox and absolute positioning, custom fonts, text wrapping, centering, and nested images.\n\nPlease refer to Satori’s documentation\n for a list of supported HTML and CSS features.\n\nBehavior\nImageResponse uses @vercel/og\n, Satori\n, and Resvg to convert HTML and CSS into PNG.\nOnly flexbox and a subset of CSS properties are supported. Advanced layouts (e.g. display: grid) will not work.\nMaximum bundle size of 500KB. The bundle size includes your JSX, CSS, fonts, images, and any other assets. If you exceed the limit, consider reducing the size of any assets or fetching at runtime.\nOnly ttf, otf, and woff font formats are supported. To maximize the font parsing speed, ttf or otf are preferred over woff.\nExamples\nRoute Handlers\n\nImageResponse can be used in Route Handlers to generate images dynamically at request time.\n\napp/api/route.js\nimport { ImageResponse } from 'next/og'\n \nexport async function GET() {\n  try {\n    return new ImageResponse(\n      (\n        <div\n          style={{\n            height: '100%',\n            width: '100%',\n            display: 'flex',\n            flexDirection: 'column',\n            alignItems: 'center',\n            justifyContent: 'center',\n            backgroundColor: 'white',\n            padding: '40px',\n          }}\n        >\n          <div\n            style={{\n              fontSize: 60,\n              fontWeight: 'bold',\n              color: 'black',\n              textAlign: 'center',\n            }}\n          >\n            Welcome to My Site\n          </div>\n          <div\n            style={{\n              fontSize: 30,\n              color: '#666',\n              marginTop: '20px',\n            }}\n          >\n            Generated with Next.js ImageResponse\n          </div>\n        </div>\n      ),\n      {\n        width: 1200,\n        height: 630,\n      }\n    )\n  } catch (e) {\n    console.log(`${e.message}`)\n    return new Response(`Failed to generate the image`, {\n      status: 500,\n    })\n  }\n}\nFile-based Metadata\n\nYou can use ImageResponse in a opengraph-image.tsx file to generate Open Graph images at build time or dynamically at request time.\n\napp/opengraph-image.tsx\nimport { ImageResponse } from 'next/og'\n \n// Image metadata\nexport const alt = 'My site'\nexport const size = {\n  width: 1200,\n  height: 630,\n}\n \nexport const contentType = 'image/png'\n \n// Image generation\nexport default async function Image() {\n  return new ImageResponse(\n    (\n      // ImageResponse JSX element\n      <div\n        style={{\n          fontSize: 128,\n          background: 'white',\n          width: '100%',\n          height: '100%',\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n        }}\n      >\n        My site\n      </div>\n    ),\n    // ImageResponse options\n    {\n      // For convenience, we can re-use the exported opengraph-image\n      // size config to also set the ImageResponse's width and height.\n      ...size,\n    }\n  )\n}\nCustom fonts\n\nYou can use custom fonts in your ImageResponse by providing a fonts array in the options.\n\napp/opengraph-image.tsx\nimport { ImageResponse } from 'next/og'\nimport { readFile } from 'node:fs/promises'\nimport { join } from 'node:path'\n \n// Image metadata\nexport const alt = 'My site'\nexport const size = {\n  width: 1200,\n  height: 630,\n}\n \nexport const contentType = 'image/png'\n \n// Image generation\nexport default async function Image() {\n  // Font loading, process.cwd() is Next.js project directory\n  const interSemiBold = await readFile(\n    join(process.cwd(), 'assets/Inter-SemiBold.ttf')\n  )\n \n  return new ImageResponse(\n    (\n      // ...\n    ),\n    // ImageResponse options\n    {\n      // For convenience, we can re-use the exported opengraph-image\n      // size config to also set the ImageResponse's width and height.\n      ...size,\n      fonts: [\n        {\n          name: 'Inter',\n          data: interSemiBold,\n          style: 'normal',\n          weight: 400,\n        },\n      ],\n    }\n  )\n}\nVersion History\nVersion\tChanges\nv14.0.0\tImageResponse moved from next/server to next/og\nv13.3.0\tImageResponse can be imported from next/server.\nv13.0.0\tImageResponse introduced via @vercel/og package.\nPrevious\nheaders\nNext\nNextRequest\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: NextRequest | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/next-request",
    "html": "API Reference\nFunctions\nNextRequest\nCopy page\nNextRequest\n\nNextRequest extends the Web Request API\n with additional convenience methods.\n\ncookies\n\nRead or mutate the Set-Cookie\n header of the request.\n\nset(name, value)\n\nGiven a name, set a cookie with the given value on the request.\n\n// Given incoming request /home\n// Set a cookie to hide the banner\n// request will have a `Set-Cookie:show-banner=false;path=/home` header\nrequest.cookies.set('show-banner', 'false')\nget(name)\n\nGiven a cookie name, return the value of the cookie. If the cookie is not found, undefined is returned. If multiple cookies are found, the first one is returned.\n\n// Given incoming request /home\n// { name: 'show-banner', value: 'false', Path: '/home' }\nrequest.cookies.get('show-banner')\ngetAll()\n\nGiven a cookie name, return the values of the cookie. If no name is given, return all cookies on the request.\n\n// Given incoming request /home\n// [\n//   { name: 'experiments', value: 'new-pricing-page', Path: '/home' },\n//   { name: 'experiments', value: 'winter-launch', Path: '/home' },\n// ]\nrequest.cookies.getAll('experiments')\n// Alternatively, get all cookies for the request\nrequest.cookies.getAll()\ndelete(name)\n\nGiven a cookie name, delete the cookie from the request.\n\n// Returns true for deleted, false is nothing is deleted\nrequest.cookies.delete('experiments')\nhas(name)\n\nGiven a cookie name, return true if the cookie exists on the request.\n\n// Returns true if cookie exists, false if it does not\nrequest.cookies.has('experiments')\nclear()\n\nRemove the Set-Cookie header from the request.\n\nrequest.cookies.clear()\nnextUrl\n\nExtends the native URL\n API with additional convenience methods, including Next.js specific properties.\n\n// Given a request to /home, pathname is /home\nrequest.nextUrl.pathname\n// Given a request to /home?name=lee, searchParams is { 'name': 'lee' }\nrequest.nextUrl.searchParams\n\nThe following options are available:\n\nProperty\tType\tDescription\nbasePath\tstring\tThe base path of the URL.\nbuildId\tstring | undefined\tThe build identifier of the Next.js application. Can be customized.\npathname\tstring\tThe pathname of the URL.\nsearchParams\tObject\tThe search parameters of the URL.\n\nNote: The internationalization properties from the Pages Router are not available for usage in the App Router. Learn more about internationalization with the App Router.\n\nVersion History\nVersion\tChanges\nv15.0.0\tip and geo removed.\nPrevious\nImageResponse\nNext\nNextResponse\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: NextResponse | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/next-response",
    "html": "API Reference\nFunctions\nNextResponse\nCopy page\nNextResponse\n\nNextResponse extends the Web Response API\n with additional convenience methods.\n\ncookies\n\nRead or mutate the Set-Cookie\n header of the response.\n\nset(name, value)\n\nGiven a name, set a cookie with the given value on the response.\n\n// Given incoming request /home\nlet response = NextResponse.next()\n// Set a cookie to hide the banner\nresponse.cookies.set('show-banner', 'false')\n// Response will have a `Set-Cookie:show-banner=false;path=/home` header\nreturn response\nget(name)\n\nGiven a cookie name, return the value of the cookie. If the cookie is not found, undefined is returned. If multiple cookies are found, the first one is returned.\n\n// Given incoming request /home\nlet response = NextResponse.next()\n// { name: 'show-banner', value: 'false', Path: '/home' }\nresponse.cookies.get('show-banner')\ngetAll()\n\nGiven a cookie name, return the values of the cookie. If no name is given, return all cookies on the response.\n\n// Given incoming request /home\nlet response = NextResponse.next()\n// [\n//   { name: 'experiments', value: 'new-pricing-page', Path: '/home' },\n//   { name: 'experiments', value: 'winter-launch', Path: '/home' },\n// ]\nresponse.cookies.getAll('experiments')\n// Alternatively, get all cookies for the response\nresponse.cookies.getAll()\ndelete(name)\n\nGiven a cookie name, delete the cookie from the response.\n\n// Given incoming request /home\nlet response = NextResponse.next()\n// Returns true for deleted, false if nothing is deleted\nresponse.cookies.delete('experiments')\njson()\n\nProduce a response with the given JSON body.\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse } from 'next/server'\n \nexport async function GET(request: Request) {\n  return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 })\n}\nredirect()\n\nProduce a response that redirects to a URL\n.\n\nimport { NextResponse } from 'next/server'\n \nreturn NextResponse.redirect(new URL('/new', request.url))\n\nThe URL\n can be created and modified before being used in the NextResponse.redirect() method. For example, you can use the request.nextUrl property to get the current URL, and then modify it to redirect to a different URL.\n\nimport { NextResponse } from 'next/server'\n \n// Given an incoming request...\nconst loginUrl = new URL('/login', request.url)\n// Add ?from=/incoming-url to the /login URL\nloginUrl.searchParams.set('from', request.nextUrl.pathname)\n// And redirect to the new URL\nreturn NextResponse.redirect(loginUrl)\nrewrite()\n\nProduce a response that rewrites (proxies) the given URL\n while preserving the original URL.\n\nimport { NextResponse } from 'next/server'\n \n// Incoming request: /about, browser shows /about\n// Rewritten request: /proxy, browser shows /about\nreturn NextResponse.rewrite(new URL('/proxy', request.url))\nnext()\n\nThe next() method is useful for Proxy, as it allows you to return early and continue routing.\n\nimport { NextResponse } from 'next/server'\n \nreturn NextResponse.next()\n\nYou can also forward headers upstream when producing the response, using NextResponse.next({ request: { headers } }):\n\nimport { NextResponse } from 'next/server'\n \n// Given an incoming request...\nconst newHeaders = new Headers(request.headers)\n// Add a new header\nnewHeaders.set('x-version', '123')\n// Forward the modified request headers upstream\nreturn NextResponse.next({\n  request: {\n    // New request headers\n    headers: newHeaders,\n  },\n})\n\nThis forwards newHeaders upstream to the target page, route, or server action, and does not expose them to the client. While this pattern is useful for passing data upstream, it should be used with caution because the headers containing this data may be forwarded to external services.\n\nIn contrast, NextResponse.next({ headers }) is a shorthand for sending headers from proxy to the client. This is NOT good practice and should be avoided. Among other reasons because setting response headers like Content-Type, can override framework expectations (for example, the Content-Type used by Server Actions), leading to failed submissions or broken streaming responses.\n\nimport { type NextRequest, NextResponse } from 'next/server'\n \nasync function proxy(request: NextRequest) {\n  const headers = await injectAuth(request.headers)\n  // DO NOT forward headers like this\n  return NextResponse.next({ headers })\n}\n\nIn general, avoid copying all incoming request headers because doing so can leak sensitive data to clients or upstream services.\n\nPrefer a defensive approach by creating a subset of incoming request headers using an allow-list. For example, you might discard custom x-* headers and only forward known-safe headers:\n\nimport { type NextRequest, NextResponse } from 'next/server'\n \nfunction proxy(request: NextRequest) {\n  const incoming = new Headers(request.headers)\n  const forwarded = new Headers()\n \n  for (const [name, value] of incoming) {\n    const headerName = name.toLowerCase()\n    // Keep only known-safe headers, discard custom x-* and other sensitive ones\n    if (\n      !headerName.startsWith('x-') &&\n      headerName !== 'authorization' &&\n      headerName !== 'cookie'\n    ) {\n      // Preserve original header name casing\n      forwarded.set(name, value)\n    }\n  }\n \n  return NextResponse.next({\n    request: {\n      headers: forwarded,\n    },\n  })\n}\nPrevious\nNextRequest\nNext\nnotFound\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: notFound | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/not-found",
    "html": "API Reference\nFunctions\nnotFound\nCopy page\nnotFound\n\nThe notFound function allows you to render the not-found file within a route segment as well as inject a <meta name=\"robots\" content=\"noindex\" /> tag.\n\nnotFound()\n\nInvoking the notFound() function throws a NEXT_HTTP_ERROR_FALLBACK;404 error and terminates rendering of the route segment in which it was thrown. Specifying a not-found file allows you to gracefully handle such errors by rendering a Not Found UI within the segment.\n\napp/user/[id]/page.js\nimport { notFound } from 'next/navigation'\n \nasync function fetchUser(id) {\n  const res = await fetch('https://...')\n  if (!res.ok) return undefined\n  return res.json()\n}\n \nexport default async function Profile({ params }) {\n  const { id } = await params\n  const user = await fetchUser(id)\n \n  if (!user) {\n    notFound()\n  }\n \n  // ...\n}\n\nGood to know: notFound() does not require you to use return notFound() due to using the TypeScript never\n type.\n\nVersion History\nVersion\tChanges\nv13.0.0\tnotFound introduced.\nPrevious\nNextResponse\nNext\npermanentRedirect\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: permanentRedirect | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/permanentRedirect",
    "html": "API Reference\nFunctions\npermanentRedirect\nCopy page\npermanentRedirect\n\nThe permanentRedirect function allows you to redirect the user to another URL. permanentRedirect can be used in Server Components, Client Components, Route Handlers, and Server Actions.\n\nWhen used in a streaming context, this will insert a meta tag to emit the redirect on the client side. When used in a server action, it will serve a 303 HTTP redirect response to the caller. Otherwise, it will serve a 308 (Permanent) HTTP redirect response to the caller.\n\nIf a resource doesn't exist, you can use the notFound function instead.\n\nGood to know: If you prefer to return a 307 (Temporary) HTTP redirect instead of 308 (Permanent), you can use the redirect function instead.\n\nParameters\n\nThe permanentRedirect function accepts two arguments:\n\npermanentRedirect(path, type)\nParameter\tType\tDescription\npath\tstring\tThe URL to redirect to. Can be a relative or absolute path.\ntype\t'replace' (default) or 'push' (default in Server Actions)\tThe type of redirect to perform.\n\nBy default, permanentRedirect will use push (adding a new entry to the browser history stack) in Server Actions and replace (replacing the current URL in the browser history stack) everywhere else. You can override this behavior by specifying the type parameter.\n\nThe type parameter has no effect when used in Server Components.\n\nReturns\n\npermanentRedirect does not return a value.\n\nExample\n\nInvoking the permanentRedirect() function throws a NEXT_REDIRECT error and terminates rendering of the route segment in which it was thrown.\n\napp/team/[id]/page.js\nimport { permanentRedirect } from 'next/navigation'\n \nasync function fetchTeam(id) {\n  const res = await fetch('https://...')\n  if (!res.ok) return undefined\n  return res.json()\n}\n \nexport default async function Profile({ params }) {\n  const { id } = await params\n  const team = await fetchTeam(id)\n  if (!team) {\n    permanentRedirect('/login')\n  }\n \n  // ...\n}\n\nGood to know: permanentRedirect does not require you to use return permanentRedirect() as it uses the TypeScript never\n type.\n\nNext Steps\nredirect\nAPI Reference for the redirect function.\nPrevious\nnotFound\nNext\nredirect\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: redirect | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/redirect",
    "html": "API Reference\nFunctions\nredirect\nCopy page\nredirect\n\nThe redirect function allows you to redirect the user to another URL. redirect can be used while rendering in Server and Client Components, Route Handlers, and Server Actions.\n\nWhen used in a streaming context, this will insert a meta tag to emit the redirect on the client side. When used in a server action, it will serve a 303 HTTP redirect response to the caller. Otherwise, it will serve a 307 HTTP redirect response to the caller.\n\nIf a resource doesn't exist, you can use the notFound function instead.\n\nReference\nParameters\n\nThe redirect function accepts two arguments:\n\nredirect(path, type)\nParameter\tType\tDescription\npath\tstring\tThe URL to redirect to. Can be a relative or absolute path.\ntype\t'replace' (default) or 'push' (default in Server Actions)\tThe type of redirect to perform.\n\nBy default, redirect will use push (adding a new entry to the browser history stack) in Server Actions and replace (replacing the current URL in the browser history stack) everywhere else. You can override this behavior by specifying the type parameter.\n\nThe RedirectType object contains the available options for the type parameter.\n\nimport { redirect, RedirectType } from 'next/navigation'\n \nredirect('/redirect-to', RedirectType.replace)\n// or\nredirect('/redirect-to', RedirectType.push)\n\nThe type parameter has no effect when used in Server Components.\n\nReturns\n\nredirect does not return a value.\n\nBehavior\nIn Server Actions and Route Handlers, redirect should be called outside the try block when using try/catch statements.\nIf you prefer to return a 308 (Permanent) HTTP redirect instead of 307 (Temporary), you can use the permanentRedirect function instead.\nredirect throws an error so it should be called outside the try block when using try/catch statements.\nredirect can be called in Client Components during the rendering process but not in event handlers. You can use the useRouter hook instead.\nredirect also accepts absolute URLs and can be used to redirect to external links.\nIf you'd like to redirect before the render process, use next.config.js or Proxy.\nExample\nServer Component\n\nInvoking the redirect() function throws a NEXT_REDIRECT error and terminates rendering of the route segment in which it was thrown.\n\napp/team/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { redirect } from 'next/navigation'\n \nasync function fetchTeam(id: string) {\n  const res = await fetch('https://...')\n  if (!res.ok) return undefined\n  return res.json()\n}\n \nexport default async function Profile({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n  const team = await fetchTeam(id)\n \n  if (!team) {\n    redirect('/login')\n  }\n \n  // ...\n}\n\nGood to know: redirect does not require you to use return redirect() as it uses the TypeScript never\n type.\n\nClient Component\n\nredirect can be directly used in a Client Component.\n\ncomponents/client-redirect.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { redirect, usePathname } from 'next/navigation'\n \nexport function ClientRedirect() {\n  const pathname = usePathname()\n \n  if (pathname.startsWith('/admin') && !pathname.includes('/login')) {\n    redirect('/admin/login')\n  }\n \n  return <div>Login Page</div>\n}\n\nGood to know: When using redirect in a Client Component on initial page load during Server-Side Rendering (SSR), it will perform a server-side redirect.\n\nredirect can be used in a Client Component through a Server Action. If you need to use an event handler to redirect the user, you can use the useRouter hook.\n\napp/client-redirect.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { navigate } from './actions'\n \nexport function ClientRedirect() {\n  return (\n    <form action={navigate}>\n      <input type=\"text\" name=\"id\" />\n      <button>Submit</button>\n    </form>\n  )\n}\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { redirect } from 'next/navigation'\n \nexport async function navigate(data: FormData) {\n  redirect(`/posts/${data.get('id')}`)\n}\nFAQ\nWhy does redirect use 307 and 308?\n\nWhen using redirect() you may notice that the status codes used are 307 for a temporary redirect, and 308 for a permanent redirect. While traditionally a 302 was used for a temporary redirect, and a 301 for a permanent redirect, many browsers changed the request method of the redirect, from a POST to GET request when using a 302, regardless of the origins request method.\n\nTaking the following example of a redirect from /users to /people, if you make a POST request to /users to create a new user, and are conforming to a 302 temporary redirect, the request method will be changed from a POST to a GET request. This doesn't make sense, as to create a new user, you should be making a POST request to /people, and not a GET request.\n\nThe introduction of the 307 status code means that the request method is preserved as POST.\n\n302 - Temporary redirect, will change the request method from POST to GET\n307 - Temporary redirect, will preserve the request method as POST\n\nThe redirect() method uses a 307 by default, instead of a 302 temporary redirect, meaning your requests will always be preserved as POST requests.\n\nLearn more\n about HTTP Redirects.\n\nVersion History\nVersion\tChanges\nv13.0.0\tredirect introduced.\nNext Steps\npermanentRedirect\nAPI Reference for the permanentRedirect function.\nPrevious\npermanentRedirect\nNext\nrefresh\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: refresh | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/refresh",
    "html": "API Reference\nFunctions\nrefresh\nCopy page\nrefresh\n\nrefresh allows you to refresh the client router from within a Server Action.\n\nUsage\n\nrefresh can only be called from within Server Actions. It cannot be used in Route Handlers, Client Components, or any other context.\n\nParameters\nrefresh(): void;\nReturns\n\nrefresh does not return a value.\n\nExamples\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { refresh } from 'next/cache'\nimport { redirect } from 'next/navigation'\n \nexport async function createPost(formData: FormData) {\n  const title = formData.get('title')\n  const content = formData.get('content')\n \n  // Create the post in your database\n  const post = await db.post.create({\n    data: { title, content },\n  })\n \n  refresh()\n}\nError when used outside Server Actions\napp/api/posts/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { refresh } from 'next/cache'\n \nexport async function POST() {\n  // This will throw an error\n  refresh()\n}\nPrevious\nredirect\nNext\nrevalidatePath\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: revalidatePath | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/revalidatePath",
    "html": "API Reference\nFunctions\nrevalidatePath\nCopy page\nrevalidatePath\n\nrevalidatePath allows you to invalidate cached data on-demand for a specific path.\n\nUsage\n\nrevalidatePath can be called in Server Functions and Route Handlers.\n\nrevalidatePath cannot be called in Client Components or Proxy, as it only works in server environments.\n\nGood to know:\n\nServer Functions: Updates the UI immediately (if viewing the affected path). Currently, it also causes all previously visited pages to refresh when navigated to again. This behavior is temporary and will be updated in the future to apply only to the specific path.\nRoute Handlers: Marks the path for revalidation. The revalidation is done on the next visit to the specified path. This means calling revalidatePath with a dynamic route segment will not immediately trigger many revalidations at once. The invalidation only happens when the path is next visited.\nParameters\nrevalidatePath(path: string, type?: 'page' | 'layout'): void;\npath: Either a route pattern corresponding to the data you want to revalidate, for example /product/[slug], or a specific URL, /product/123. Do not append /page or /layout, use the type parameter instead. Must not exceed 1024 characters. This value is case-sensitive.\ntype: (optional) 'page' or 'layout' string to change the type of path to revalidate. If path contains a dynamic segment, for example /product/[slug], this parameter is required. If path is a specific URL, /product/1, omit type.\n\nUse a specific URL when you want to refresh a single page. Use a route pattern plus type to refresh multiple URLs.\n\nReturns\n\nrevalidatePath does not return a value.\n\nWhat can be invalidated\n\nThe path parameter can point to pages, layouts, or route handlers:\n\nPages: Invalidates the specific page\nLayouts: Invalidates the layout (the layout.tsx at that segment), all nested layouts beneath it, and all pages beneath them\nRoute Handlers: Invalidates Data Cache entries accessed within route handlers. For example revalidatePath(\"/api/data\") invalidates this GET handler:\napp/api/data/route.ts\nexport async function GET() {\n  const data = await fetch('https://api.vercel.app/blog', {\n    cache: 'force-cache',\n  })\n \n  return Response.json(await data.json())\n}\nRelationship with revalidateTag and updateTag\n\nrevalidatePath, revalidateTag and updateTag serve different purposes:\n\nrevalidatePath: Invalidates a specific page or layout path\nrevalidateTag: Marks data with specific tags as stale. Applies across all pages that use those tags\nupdateTag: Expires data with specific tags. Applies across all pages that use those tags\n\nWhen you call revalidatePath, only the specified path gets fresh data on the next visit. Other pages that use the same data tags will continue to serve cached data until those specific tags are also revalidated:\n\n// Page A: /blog\nconst posts = await fetch('https://api.vercel.app/blog', {\n  next: { tags: ['posts'] },\n})\n \n// Page B: /dashboard\nconst recentPosts = await fetch('https://api.vercel.app/blog?limit=5', {\n  next: { tags: ['posts'] },\n})\n\nAfter calling revalidatePath('/blog'):\n\nPage A (/blog): Shows fresh data (page re-rendered)\nPage B (/dashboard): Still shows stale data (cache tag 'posts' not invalidated)\n\nLearn about the difference between revalidateTag and updateTag.\n\nBuilding revalidation utilities\n\nrevalidatePath and updateTag are complementary primitives that are often used together in utility functions to ensure comprehensive data consistency across your application:\n\n'use server'\n \nimport { revalidatePath, updateTag } from 'next/cache'\n \nexport async function updatePost() {\n  await updatePostInDatabase()\n \n  revalidatePath('/blog') // Refresh the blog page\n  updateTag('posts') // Refresh all pages using 'posts' tag\n}\n\nThis pattern ensures that both the specific page and any other pages using the same data remain consistent.\n\nExamples\nRevalidating a specific URL\nimport { revalidatePath } from 'next/cache'\nrevalidatePath('/blog/post-1')\n\nThis will invalidate one specific URL for revalidation on the next page visit.\n\nRevalidating a Page path\nimport { revalidatePath } from 'next/cache'\nrevalidatePath('/blog/[slug]', 'page')\n// or with route groups\nrevalidatePath('/(main)/blog/[slug]', 'page')\n\nThis will invalidate any URL that matches the provided page file for revalidation on the next page visit. This will not invalidate pages beneath the specific page. For example, /blog/[slug] won't invalidate /blog/[slug]/[author].\n\nRevalidating a Layout path\nimport { revalidatePath } from 'next/cache'\nrevalidatePath('/blog/[slug]', 'layout')\n// or with route groups\nrevalidatePath('/(main)/post/[slug]', 'layout')\n\nThis will invalidate any URL that matches the provided layout file for revalidation on the next page visit. This will cause pages beneath with the same layout to be invalidated and revalidated on the next visit. For example, in the above case, /blog/[slug]/[another] would also be invalidated and revalidated on the next visit.\n\nRevalidating all data\nimport { revalidatePath } from 'next/cache'\n \nrevalidatePath('/', 'layout')\n\nThis will purge the Client-side Router Cache, and invalidate the Data Cache for revalidation on the next page visit.\n\nServer Function\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { revalidatePath } from 'next/cache'\n \nexport default async function submit() {\n  await submitForm()\n  revalidatePath('/')\n}\nRoute Handler\napp/api/revalidate/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { revalidatePath } from 'next/cache'\nimport type { NextRequest } from 'next/server'\n \nexport async function GET(request: NextRequest) {\n  const path = request.nextUrl.searchParams.get('path')\n \n  if (path) {\n    revalidatePath(path)\n    return Response.json({ revalidated: true, now: Date.now() })\n  }\n \n  return Response.json({\n    revalidated: false,\n    now: Date.now(),\n    message: 'Missing path to revalidate',\n  })\n}\nPrevious\nrefresh\nNext\nrevalidateTag\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: revalidateTag | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/revalidateTag",
    "html": "API Reference\nFunctions\nrevalidateTag\nCopy page\nrevalidateTag\n\nrevalidateTag allows you to invalidate cached data on-demand for a specific cache tag.\n\nThis function is ideal for content where a slight delay in updates is acceptable, such as blog posts, product catalogs, or documentation. Users receive stale content while fresh data loads in the background.\n\nUsage\n\nrevalidateTag can be called in Server Functions and Route Handlers.\n\nrevalidateTag cannot be called in Client Components or Proxy, as it only works in server environments.\n\nRevalidation Behavior\n\nThe revalidation behavior depends on whether you provide the second argument:\n\nWith profile=\"max\" (recommended): The tag entry is marked as stale, and the next time a resource with that tag is visited, it will use stale-while-revalidate semantics. This means the stale content is served while fresh content is fetched in the background.\nWith a custom cache life profile: For advanced usage, you can specify any cache life profile that your application has defined, allowing for custom revalidation behaviors tailored to your specific caching requirements.\nWithout the second argument (deprecated): The tag entry is expired immediately, and the next request to that resource will be a blocking revalidate/cache miss. This behavior is now deprecated, and you should either use profile=\"max\" or migrate to updateTag.\n\nGood to know: When using profile=\"max\", revalidateTag marks tagged data as stale, but fresh data is only fetched when pages using that tag are next visited. This means calling revalidateTag will not immediately trigger many revalidations at once. The invalidation only happens when any page using that tag is next visited.\n\nParameters\nrevalidateTag(tag: string, profile?: string | { expire?: number }): void;\ntag: A string representing the cache tag associated with the data you want to revalidate. Must not exceed 256 characters. This value is case-sensitive.\nprofile: A string that specifies the revalidation behavior. The recommended value is \"max\" which provides stale-while-revalidate semantics, or any of the other default or custom profiles defined in cacheLife. Alternatively, you can pass an object with an expire property for custom expiration behavior.\n\nTags must first be assigned to cached data. You can do this in two ways:\n\nUsing the next.tags option with fetch for caching external API requests:\nfetch(url, { next: { tags: ['posts'] } })\nUsing cacheTag inside cached functions or components with the 'use cache' directive:\nimport { cacheTag } from 'next/cache'\n \nasync function getData() {\n  'use cache'\n  cacheTag('posts')\n  // ...\n}\nReturns\n\nrevalidateTag does not return a value.\n\nRelationship with revalidatePath\n\nrevalidateTag invalidates data with specific tags across all pages that use those tags, while revalidatePath invalidates specific page or layout paths.\n\nGood to know: These functions serve different purposes and may need to be used together for comprehensive data consistency. For detailed examples and considerations, see relationship with revalidateTag and updateTag for more information.\n\nExamples\n\nThe following examples demonstrate how to use revalidateTag in different contexts. In both cases, we're using profile=\"max\" to mark data as stale and use stale-while-revalidate semantics, which is the recommended approach for most use cases.\n\nServer Action\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { revalidateTag } from 'next/cache'\n \nexport default async function submit() {\n  await addPost()\n  revalidateTag('posts', 'max')\n}\nRoute Handler\napp/api/revalidate/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextRequest } from 'next/server'\nimport { revalidateTag } from 'next/cache'\n \nexport async function GET(request: NextRequest) {\n  const tag = request.nextUrl.searchParams.get('tag')\n \n  if (tag) {\n    revalidateTag(tag, 'max')\n    return Response.json({ revalidated: true, now: Date.now() })\n  }\n \n  return Response.json({\n    revalidated: false,\n    now: Date.now(),\n    message: 'Missing tag to revalidate',\n  })\n}\n\nGood to know: For webhooks or third-party services that need immediate expiration, you can pass { expire: 0 } as the second argument: revalidateTag(tag, { expire: 0 }). This pattern is necessary when external systems call your Route Handlers and require data to expire immediately. For all other cases, it's recommended to use updateTag in Server Actions for immediate updates instead.\n\nPrevious\nrevalidatePath\nNext\nunauthorized\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: unauthorized | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/unauthorized",
    "html": "API Reference\nFunctions\nunauthorized\nCopy page\nunauthorized\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe unauthorized function throws an error that renders a Next.js 401 error page. It's useful for handling authorization errors in your application. You can customize the UI using the unauthorized.js file.\n\nTo start using unauthorized, enable the experimental authInterrupts configuration option in your next.config.js file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    authInterrupts: true,\n  },\n}\n \nexport default nextConfig\n\nunauthorized can be invoked in Server Components, Server Actions, and Route Handlers.\n\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { verifySession } from '@/app/lib/dal'\nimport { unauthorized } from 'next/navigation'\n \nexport default async function DashboardPage() {\n  const session = await verifySession()\n \n  if (!session) {\n    unauthorized()\n  }\n \n  // Render the dashboard for authenticated users\n  return (\n    <main>\n      <h1>Welcome to the Dashboard</h1>\n      <p>Hi, {session.user.name}.</p>\n    </main>\n  )\n}\nGood to know\nThe unauthorized function cannot be called in the root layout.\nExamples\nDisplaying login UI to unauthenticated users\n\nYou can use unauthorized function to display the unauthorized.js file with a login UI.\n\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { verifySession } from '@/app/lib/dal'\nimport { unauthorized } from 'next/navigation'\n \nexport default async function DashboardPage() {\n  const session = await verifySession()\n \n  if (!session) {\n    unauthorized()\n  }\n \n  return <div>Dashboard</div>\n}\napp/unauthorized.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Login from '@/app/components/Login'\n \nexport default function UnauthorizedPage() {\n  return (\n    <main>\n      <h1>401 - Unauthorized</h1>\n      <p>Please log in to access this page.</p>\n      <Login />\n    </main>\n  )\n}\nMutations with Server Actions\n\nYou can invoke unauthorized in Server Actions to ensure only authenticated users can perform specific mutations.\n\napp/actions/update-profile.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { verifySession } from '@/app/lib/dal'\nimport { unauthorized } from 'next/navigation'\nimport db from '@/app/lib/db'\n \nexport async function updateProfile(data: FormData) {\n  const session = await verifySession()\n \n  // If the user is not authenticated, return a 401\n  if (!session) {\n    unauthorized()\n  }\n \n  // Proceed with mutation\n  // ...\n}\nFetching data with Route Handlers\n\nYou can use unauthorized in Route Handlers to ensure only authenticated users can access the endpoint.\n\napp/api/profile/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextRequest, NextResponse } from 'next/server'\nimport { verifySession } from '@/app/lib/dal'\nimport { unauthorized } from 'next/navigation'\n \nexport async function GET(req: NextRequest): Promise<NextResponse> {\n  // Verify the user's session\n  const session = await verifySession()\n \n  // If no session exists, return a 401 and render unauthorized.tsx\n  if (!session) {\n    unauthorized()\n  }\n \n  // Fetch data\n  // ...\n}\nVersion History\nVersion\tChanges\nv15.1.0\tunauthorized introduced.\nNext Steps\nunauthorized.js\nAPI reference for the unauthorized.js special file.\nPrevious\nrevalidateTag\nNext\nunstable_cache\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: unstable_cache | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/unstable_cache",
    "html": "API Reference\nFunctions\nunstable_cache\nCopy page\nunstable_cache\n\nWarning: This API will be replaced by use cache when it reaches stability.\n\nunstable_cache allows you to cache the results of expensive operations, like database queries, and reuse them across multiple requests.\n\nimport { getUser } from './data';\nimport { unstable_cache } from 'next/cache';\n \nconst getCachedUser = unstable_cache(\n  async (id) => getUser(id),\n  ['my-app-user']\n);\n \nexport default async function Component({ userID }) {\n  const user = await getCachedUser(userID);\n  ...\n}\n\nGood to know:\n\nAccessing dynamic data sources such as headers or cookies inside a cache scope is not supported. If you need this data inside a cached function use headers outside of the cached function and pass the required dynamic data in as an argument.\nThis API uses Next.js' built-in Data Cache to persist the result across requests and deployments.\nParameters\nconst data = unstable_cache(fetchData, keyParts, options)()\nfetchData: This is an asynchronous function that fetches the data you want to cache. It must be a function that returns a Promise.\nkeyParts: This is an extra array of keys that further adds identification to the cache. By default, unstable_cache already uses the arguments and the stringified version of your function as the cache key. It is optional in most cases; the only time you need to use it is when you use external variables without passing them as parameters. However, it is important to add closures used within the function if you do not pass them as parameters.\noptions: This is an object that controls how the cache behaves. It can contain the following properties:\ntags: An array of tags that can be used to control cache invalidation. Next.js will not use this to uniquely identify the function.\nrevalidate: The number of seconds after which the cache should be revalidated. Omit or pass false to cache indefinitely or until matching revalidateTag() or revalidatePath() methods are called.\nReturns\n\nunstable_cache returns a function that when invoked, returns a Promise that resolves to the cached data. If the data is not in the cache, the provided function will be invoked, and its result will be cached and returned.\n\nExample\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { unstable_cache } from 'next/cache'\n \nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ userId: string }>\n}) {\n  const { userId } = await params\n  const getCachedUser = unstable_cache(\n    async () => {\n      return { id: userId }\n    },\n    [userId], // add the user ID to the cache key\n    {\n      tags: ['users'],\n      revalidate: 60,\n    }\n  )\n \n  //...\n}\nVersion History\nVersion\tChanges\nv14.0.0\tunstable_cache introduced.\nPrevious\nunauthorized\nNext\nunstable_noStore\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: unstable_noStore | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/unstable_noStore",
    "html": "API Reference\nFunctions\nunstable_noStore\nCopy page\nunstable_noStore\nThis is a legacy API and no longer recommended. It's still supported for backward compatibility.\n\nIn version 15, we recommend using connection instead of unstable_noStore.\n\nunstable_noStore can be used to declaratively opt out of static rendering and indicate a particular component should not be cached.\n\nimport { unstable_noStore as noStore } from 'next/cache';\n \nexport default async function ServerComponent() {\n  noStore();\n  const result = await db.query(...);\n  ...\n}\n\nGood to know:\n\nunstable_noStore is equivalent to cache: 'no-store' on a fetch\nunstable_noStore is preferred over export const dynamic = 'force-dynamic' as it is more granular and can be used on a per-component basis\nUsing unstable_noStore inside unstable_cache will not opt out of static generation. Instead, it will defer to the cache configuration to determine whether to cache the result or not.\nUsage\n\nIf you prefer not to pass additional options to fetch, like cache: 'no-store', next: { revalidate: 0 } or in cases where fetch is not available, you can use noStore() as a replacement for all of these use cases.\n\nimport { unstable_noStore as noStore } from 'next/cache';\n \nexport default async function ServerComponent() {\n  noStore();\n  const result = await db.query(...);\n  ...\n}\nVersion History\nVersion\tChanges\nv15.0.0\tunstable_noStore deprecated for connection.\nv14.0.0\tunstable_noStore introduced.\nPrevious\nunstable_cache\nNext\nunstable_rethrow\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: unstable_rethrow | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/unstable_rethrow",
    "html": "API Reference\nFunctions\nunstable_rethrow\nCopy page\nunstable_rethrow\nThis feature is currently unstable and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nunstable_rethrow can be used to avoid catching internal errors thrown by Next.js when attempting to handle errors thrown in your application code.\n\nFor example, calling the notFound function will throw an internal Next.js error and render the not-found.js component. However, if used inside the try block of a try/catch statement, the error will be caught, preventing not-found.js from rendering:\n\n@/app/ui/component.tsx\nimport { notFound } from 'next/navigation'\n \nexport default async function Page() {\n  try {\n    const post = await fetch('https://.../posts/1').then((res) => {\n      if (res.status === 404) notFound()\n      if (!res.ok) throw new Error(res.statusText)\n      return res.json()\n    })\n  } catch (err) {\n    console.error(err)\n  }\n}\n\nYou can use unstable_rethrow API to re-throw the internal error and continue with the expected behavior:\n\n@/app/ui/component.tsx\nimport { notFound, unstable_rethrow } from 'next/navigation'\n \nexport default async function Page() {\n  try {\n    const post = await fetch('https://.../posts/1').then((res) => {\n      if (res.status === 404) notFound()\n      if (!res.ok) throw new Error(res.statusText)\n      return res.json()\n    })\n  } catch (err) {\n    unstable_rethrow(err)\n    console.error(err)\n  }\n}\n\nThe following Next.js APIs rely on throwing an error which should be rethrown and handled by Next.js itself:\n\nnotFound()\nredirect()\npermanentRedirect()\n\nIf a route segment is marked to throw an error unless it's static, a Dynamic API call will also throw an error that should similarly not be caught by the developer. Note that Partial Prerendering (PPR) affects this behavior as well. These APIs are:\n\ncookies\nheaders\nsearchParams\nfetch(..., { cache: 'no-store' })\nfetch(..., { next: { revalidate: 0 } })\n\nGood to know:\n\nThis method should be called at the top of the catch block, passing the error object as its only argument. It can also be used within a .catch handler of a promise.\nYou may be able to avoid using unstable_rethrow if you encapsulate your API calls that throw and let the caller handle the exception.\nOnly use unstable_rethrow if your caught exceptions may include both application errors and framework-controlled exceptions (like redirect() or notFound()).\nAny resource cleanup (like clearing intervals, timers, etc) would have to either happen prior to the call to unstable_rethrow or within a finally block.\nPrevious\nunstable_noStore\nNext\nupdateTag\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: updateTag | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/updateTag",
    "html": "API Reference\nFunctions\nupdateTag\nCopy page\nupdateTag\n\nupdateTag allows you to update cached data on-demand for a specific cache tag from within Server Actions.\n\nThis function is designed for read-your-own-writes scenarios, where a user makes a change (like creating a post), and the UI immediately shows the change, rather than stale data.\n\nUsage\n\nupdateTag can only be called from within Server Actions. It cannot be used in Route Handlers, Client Components, or any other context.\n\nIf you need to invalidate cache tags in Route Handlers or other contexts, use revalidateTag instead.\n\nGood to know: updateTag immediately expires the cached data for the specified tag. The next request will wait to fetch fresh data rather than serving stale content from the cache, ensuring users see their changes immediately.\n\nParameters\nupdateTag(tag: string): void;\ntag: A string representing the cache tag associated with the data you want to update. Must not exceed 256 characters. This value is case-sensitive.\n\nTags must first be assigned to cached data. You can do this in two ways:\n\nUsing the next.tags option with fetch for caching external API requests:\nfetch(url, { next: { tags: ['posts'] } })\nUsing cacheTag inside cached functions or components with the 'use cache' directive:\nimport { cacheTag } from 'next/cache'\n \nasync function getData() {\n  'use cache'\n  cacheTag('posts')\n  // ...\n}\nReturns\n\nupdateTag does not return a value.\n\nDifferences from revalidateTag\n\nWhile both updateTag and revalidateTag invalidate cached data, they serve different purposes:\n\nupdateTag:\n\nCan only be used in Server Actions\nNext request waits for fresh data (no stale content served)\nDesigned for read-your-own-writes scenarios\n\nrevalidateTag:\n\nCan be used in Server Actions and Route Handlers\nWith profile=\"max\" (recommended): Serves cached data while fetching fresh data in the background (stale-while-revalidate)\nWith custom profile: Can be configured to any cache life profile for advanced usage\nWithout profile: legacy behavior which is equivalent to updateTag\nExamples\nServer Action with Read-Your-Own-Writes\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { updateTag } from 'next/cache'\nimport { redirect } from 'next/navigation'\n \nexport async function createPost(formData: FormData) {\n  const title = formData.get('title')\n  const content = formData.get('content')\n \n  // Create the post in your database\n  const post = await db.post.create({\n    data: { title, content },\n  })\n \n  // Invalidate cache tags so the new post is immediately visible\n  // 'posts' tag: affects any page that displays a list of posts\n  updateTag('posts')\n  // 'post-{id}' tag: affects the individual post detail page\n  updateTag(`post-${post.id}`)\n \n  // Redirect to the new post - user will see fresh data, not cached\n  redirect(`/posts/${post.id}`)\n}\nError when used outside Server Actions\napp/api/posts/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { updateTag } from 'next/cache'\n \nexport async function POST() {\n  // This will throw an error\n  updateTag('posts')\n  // Error: updateTag can only be called from within a Server Action\n \n  // Use revalidateTag instead in Route Handlers\n  revalidateTag('posts', 'max')\n}\nWhen to use updateTag\n\nUse updateTag when:\n\nYou're in a Server Action\nYou need immediate cache invalidation for read-your-own-writes\nYou want to ensure the next request sees updated data\n\nUse revalidateTag instead when:\n\nYou're in a Route Handler or other non-action context\nYou want stale-while-revalidate semantics\nYou're building a webhook or API endpoint for cache invalidation\nRelated\nrevalidateTag - For invalidating tags in Route Handlers\nrevalidatePath - For invalidating specific paths\nPrevious\nunstable_rethrow\nNext\nuseLinkStatus\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: useLinkStatus | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-link-status",
    "html": "API Reference\nFunctions\nuseLinkStatus\nCopy page\nuseLinkStatus\n\nThe useLinkStatus hook lets you track the pending state of a <Link>. Use it for subtle, inline feedback, for example a shimmer effect over the clicked link, while navigation completes. Prefer route-level fallbacks with loading.js, and prefetching for instant transitions.\n\nuseLinkStatus is useful when:\n\nPrefetching is disabled or in progress meaning navigation is blocked.\nThe destination route is dynamic and doesn't include a loading.js file that would allow an instant navigation.\napp/hint.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Link from 'next/link'\nimport { useLinkStatus } from 'next/link'\n \nfunction Hint() {\n  const { pending } = useLinkStatus()\n  return (\n    <span aria-hidden className={`link-hint ${pending ? 'is-pending' : ''}`} />\n  )\n}\n \nexport default function Header() {\n  return (\n    <header>\n      <Link href=\"/dashboard\" prefetch={false}>\n        <span className=\"label\">Dashboard</span> <Hint />\n      </Link>\n    </header>\n  )\n}\n\nGood to know:\n\nuseLinkStatus must be used within a descendant component of a Link component\nThe hook is most useful when prefetch={false} is set on the Link component\nIf the linked route has been prefetched, the pending state will be skipped\nWhen clicking multiple links in quick succession, only the last link's pending state is shown\nThis hook is not supported in the Pages Router and always returns { pending: false }\nInline indicators can easily introduce layout shifts. Prefer a fixed-size, always-rendered hint element and toggle its opacity, or use an animation.\nYou might not need useLinkStatus\n\nBefore adding inline feedback, consider if:\n\nThe destination is static and prefetched in production, so the pending phase may be skipped.\nThe route has a loading.js file, enabling instant transitions with a route-level fallback.\n\nNavigation is typically fast. Use useLinkStatus as a quick patch when you identify a slow transition, then iterate to fix the root cause with prefetching or a loading.js fallback.\n\nParameters\nconst { pending } = useLinkStatus()\n\nuseLinkStatus does not take any parameters.\n\nReturns\n\nuseLinkStatus returns an object with a single property:\n\nProperty\tType\tDescription\npending\tboolean\ttrue before history updates, false after\nExample\nInline link hint\n\nAdd a subtle, fixed-size hint that doesn’t affect layout to confirm a click when prefetching hasn’t completed.\n\napp/components/loading-indicator.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useLinkStatus } from 'next/link'\n \nexport default function LoadingIndicator() {\n  const { pending } = useLinkStatus()\n  return (\n    <span aria-hidden className={`link-hint ${pending ? 'is-pending' : ''}`} />\n  )\n}\napp/shop/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\nimport LoadingIndicator from './components/loading-indicator'\n \nconst links = [\n  { href: '/shop/electronics', label: 'Electronics' },\n  { href: '/shop/clothing', label: 'Clothing' },\n  { href: '/shop/books', label: 'Books' },\n]\n \nfunction Menubar() {\n  return (\n    <div>\n      {links.map((link) => (\n        <Link key={link.label} href={link.href}>\n          <span className=\"label\">{link.label}</span> <LoadingIndicator />\n        </Link>\n      ))}\n    </div>\n  )\n}\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return (\n    <div>\n      <Menubar />\n      {children}\n    </div>\n  )\n}\nGracefully handling fast navigation\n\nIf the navigation to a new route is fast, users may see an unnecessary flash of the hint. One way to improve the user experience and only show the hint when the navigation takes time to complete is to add an initial animation delay (e.g. 100ms) and start the animation as invisible (e.g. opacity: 0).\n\napp/styles/global.css\n.link-hint {\n  display: inline-block;\n  width: 0.6em;\n  height: 0.6em;\n  margin-left: 0.25rem;\n  border-radius: 9999px;\n  background: currentColor;\n  opacity: 0;\n  visibility: hidden; /* reserve space without showing the hint */\n}\n \n.link-hint.is-pending {\n  /* Animation 1: fade in after 100ms and keep final opacity */\n  /* Animation 2: subtle pulsing while pending */\n  visibility: visible;\n  animation-name: fadeIn, pulse;\n  animation-duration: 200ms, 1s;\n  /* Appear only if navigation actually takes time */\n  animation-delay: 100ms, 100ms;\n  animation-timing-function: ease, ease-in-out;\n  animation-iteration-count: 1, infinite;\n  animation-fill-mode: forwards, none;\n}\n \n@keyframes fadeIn {\n  to {\n    opacity: 0.35;\n  }\n}\n@keyframes pulse {\n  50% {\n    opacity: 0.15;\n  }\n}\nVersion History\nVersion\tChanges\nv15.3.0\tuseLinkStatus introduced.\nNext Steps\nLearn more about the features mentioned in this page by reading the API Reference.\nLink Component\nEnable fast client-side navigation with the built-in `next/link` component.\nloading.js\nAPI reference for the loading.js file.\nPrevious\nupdateTag\nNext\nuseParams\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: useParams | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-params",
    "html": "API Reference\nFunctions\nuseParams\nCopy page\nuseParams\n\nuseParams is a Client Component hook that lets you read a route's dynamic params filled in by the current URL.\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useParams } from 'next/navigation'\n \nexport default function ExampleClientComponent() {\n  const params = useParams<{ tag: string; item: string }>()\n \n  // Route -> /shop/[tag]/[item]\n  // URL -> /shop/shoes/nike-air-max-97\n  // `params` -> { tag: 'shoes', item: 'nike-air-max-97' }\n  console.log(params)\n \n  return '...'\n}\nParameters\nconst params = useParams()\n\nuseParams does not take any parameters.\n\nReturns\n\nuseParams returns an object containing the current route's filled in dynamic parameters.\n\nEach property in the object is an active dynamic segment.\nThe properties name is the segment's name, and the properties value is what the segment is filled in with.\nThe properties value will either be a string or array of string's depending on the type of dynamic segment.\nIf the route contains no dynamic parameters, useParams returns an empty object.\nIf used in Pages Router, useParams will return null on the initial render and updates with properties following the rules above once the router is ready.\n\nFor example:\n\nRoute\tURL\tuseParams()\napp/shop/page.js\t/shop\t{}\napp/shop/[slug]/page.js\t/shop/1\t{ slug: '1' }\napp/shop/[tag]/[item]/page.js\t/shop/1/2\t{ tag: '1', item: '2' }\napp/shop/[...slug]/page.js\t/shop/1/2\t{ slug: ['1', '2'] }\nVersion History\nVersion\tChanges\nv13.3.0\tuseParams introduced.\nPrevious\nuseLinkStatus\nNext\nusePathname\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: usePathname | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-pathname",
    "html": "API Reference\nFunctions\nusePathname\nCopy page\nusePathname\n\nusePathname is a Client Component hook that lets you read the current URL's pathname.\n\nGood to know: When cacheComponents is enabled usePathname may require a Suspense boundary around it if your route has a dynamic param. If you use generateStaticParams the Suspense boundary is optional\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { usePathname } from 'next/navigation'\n \nexport default function ExampleClientComponent() {\n  const pathname = usePathname()\n  return <p>Current pathname: {pathname}</p>\n}\n\nusePathname intentionally requires using a Client Component. It's important to note Client Components are not a de-optimization. They are an integral part of the Server Components architecture.\n\nFor example, a Client Component with usePathname will be rendered into HTML on the initial page load. When navigating to a new route, this component does not need to be re-fetched. Instead, the component is downloaded once (in the client JavaScript bundle), and re-renders based on the current state.\n\nGood to know:\n\nReading the current URL from a Server Component is not supported. This design is intentional to support layout state being preserved across page navigations.\nIf your page is being statically pre-rendered and your app has rewrites in next.config or a Proxy file, reading the pathname with usePathname() can result in hydration mismatch errors—because the initial value comes from the server and may not match the actual browser pathname after routing. See our example for a way to mitigate this issue.\nCompatibility with Pages Router\nParameters\nconst pathname = usePathname()\n\nusePathname does not take any parameters.\n\nReturns\n\nusePathname returns a string of the current URL's pathname. For example:\n\nURL\tReturned value\n/\t'/'\n/dashboard\t'/dashboard'\n/dashboard?v=2\t'/dashboard'\n/blog/hello-world\t'/blog/hello-world'\nExamples\nDo something in response to a route change\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useEffect } from 'react'\nimport { usePathname, useSearchParams } from 'next/navigation'\n \nfunction ExampleClientComponent() {\n  const pathname = usePathname()\n  const searchParams = useSearchParams()\n  useEffect(() => {\n    // Do something here...\n  }, [pathname, searchParams])\n}\nAvoid hydration mismatch with rewrites\n\nWhen a page is pre-rendered, the HTML is generated for the source pathname. If the page is then reached through a rewrite using next.config or Proxy, the browser URL may differ, and usePathname() will read the rewritten pathname on the client.\n\nTo avoid hydration mismatches, design the UI so that only a small, isolated part depends on the client pathname. Render a stable fallback on the server and update that part after mount.\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useEffect, useState } from 'react'\nimport { usePathname } from 'next/navigation'\n \nexport default function PathnameBadge() {\n  const pathname = usePathname()\n  const [clientPathname, setClientPathname] = useState('')\n \n  useEffect(() => {\n    setClientPathname(pathname)\n  }, [pathname])\n \n  return (\n    <p>\n      Current pathname: <span>{clientPathname}</span>\n    </p>\n  )\n}\nVersion\tChanges\nv13.0.0\tusePathname introduced.\nPrevious\nuseParams\nNext\nuseReportWebVitals\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: useReportWebVitals | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-report-web-vitals",
    "html": "API Reference\nFunctions\nuseReportWebVitals\nCopy page\nuseReportWebVitals\n\nThe useReportWebVitals hook allows you to report Core Web Vitals\n, and can be used in combination with your analytics service.\n\nNew functions passed to useReportWebVitals are called with the available metrics up to that point. To prevent reporting duplicated data, ensure that the callback function reference does not change (as shown in the code examples below).\n\napp/_components/web-vitals.js\n'use client'\n \nimport { useReportWebVitals } from 'next/web-vitals'\n \nconst logWebVitals = (metric) => {\n  console.log(metric)\n}\n \nexport function WebVitals() {\n  useReportWebVitals(logWebVitals)\n \n  return null\n}\napp/layout.js\nimport { WebVitals } from './_components/web-vitals'\n \nexport default function Layout({ children }) {\n  return (\n    <html>\n      <body>\n        <WebVitals />\n        {children}\n      </body>\n    </html>\n  )\n}\n\nSince the useReportWebVitals hook requires the 'use client' directive, the most performant approach is to create a separate component that the root layout imports. This confines the client boundary exclusively to the WebVitals component.\n\nuseReportWebVitals\n\nThe metric object passed as the hook's argument consists of a number of properties:\n\nid: Unique identifier for the metric in the context of the current page load\nname: The name of the performance metric. Possible values include names of Web Vitals metrics (TTFB, FCP, LCP, FID, CLS) specific to a web application.\ndelta: The difference between the current value and the previous value of the metric. The value is typically in milliseconds and represents the change in the metric's value over time.\nentries: An array of Performance Entries\n associated with the metric. These entries provide detailed information about the performance events related to the metric.\nnavigationType: Indicates the type of navigation\n that triggered the metric collection. Possible values include \"navigate\", \"reload\", \"back_forward\", and \"prerender\".\nrating: A qualitative rating of the metric value, providing an assessment of the performance. Possible values are \"good\", \"needs-improvement\", and \"poor\". The rating is typically determined by comparing the metric value against predefined thresholds that indicate acceptable or suboptimal performance.\nvalue: The actual value or duration of the performance entry, typically in milliseconds. The value provides a quantitative measure of the performance aspect being tracked by the metric. The source of the value depends on the specific metric being measured and can come from various Performance API\ns.\nWeb Vitals\n\nWeb Vitals\n are a set of useful metrics that aim to capture the user experience of a web page. The following web vitals are all included:\n\nTime to First Byte\n (TTFB)\nFirst Contentful Paint\n (FCP)\nLargest Contentful Paint\n (LCP)\nFirst Input Delay\n (FID)\nCumulative Layout Shift\n (CLS)\nInteraction to Next Paint\n (INP)\n\nYou can handle all the results of these metrics using the name property.\n\napp/components/web-vitals.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useReportWebVitals } from 'next/web-vitals'\n \ntype ReportWebVitalsCallback = Parameters<typeof useReportWebVitals>[0]\n \nconst handleWebVitals: ReportWebVitalsCallback = (metric) => {\n  switch (metric.name) {\n    case 'FCP': {\n      // handle FCP results\n    }\n    case 'LCP': {\n      // handle LCP results\n    }\n    // ...\n  }\n}\n \nexport function WebVitals() {\n  useReportWebVitals(handleWebVitals)\n}\nSending results to external systems\n\nYou can send results to any endpoint to measure and track real user performance on your site. For example:\n\nfunction postWebVitals(metrics) {\n  const body = JSON.stringify(metric)\n  const url = 'https://example.com/analytics'\n \n  // Use `navigator.sendBeacon()` if available, falling back to `fetch()`.\n  if (navigator.sendBeacon) {\n    navigator.sendBeacon(url, body)\n  } else {\n    fetch(url, { body, method: 'POST', keepalive: true })\n  }\n}\n \nuseReportWebVitals(postWebVitals)\n\nGood to know: If you use Google Analytics\n, using the id value can allow you to construct metric distributions manually (to calculate percentiles, etc.)\n\nuseReportWebVitals(metric => {\n  // Use `window.gtag` if you initialized Google Analytics as this example:\n  // https://github.com/vercel/next.js/blob/canary/examples/with-google-analytics\n  window.gtag('event', metric.name, {\n    value: Math.round(metric.name === 'CLS' ? metric.value * 1000 : metric.value), // values must be integers\n    event_label: metric.id, // id unique to current page load\n    non_interaction: true, // avoids affecting bounce rate.\n  });\n}\n\nRead more about sending results to Google Analytics\n.\n\nPrevious\nusePathname\nNext\nuseRouter\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: useRouter | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-router",
    "html": "API Reference\nFunctions\nuseRouter\nCopy page\nuseRouter\n\nThe useRouter hook allows you to programmatically change routes inside Client Components.\n\nRecommendation: Use the <Link> component for navigation unless you have a specific requirement for using useRouter.\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useRouter } from 'next/navigation'\n \nexport default function Page() {\n  const router = useRouter()\n \n  return (\n    <button type=\"button\" onClick={() => router.push('/dashboard')}>\n      Dashboard\n    </button>\n  )\n}\nuseRouter()\nrouter.push(href: string, { scroll: boolean }): Perform a client-side navigation to the provided route. Adds a new entry into the browser's history stack\n.\nrouter.replace(href: string, { scroll: boolean }): Perform a client-side navigation to the provided route without adding a new entry into the browser’s history stack.\nrouter.refresh(): Refresh the current route. Making a new request to the server, re-fetching data requests, and re-rendering Server Components. The client will merge the updated React Server Component payload without losing unaffected client-side React (e.g. useState) or browser state (e.g. scroll position).\nrouter.prefetch(href: string, options?: { onInvalidate?: () => void }): Prefetch the provided route for faster client-side transitions. The optional onInvalidate callback is called when the prefetched data becomes stale.\nrouter.back(): Navigate back to the previous route in the browser’s history stack.\nrouter.forward(): Navigate forwards to the next page in the browser’s history stack.\n\nGood to know:\n\nYou must not send untrusted or unsanitized URLs to router.push or router.replace, as this can open your site to cross-site scripting (XSS) vulnerabilities. For example, javascript: URLs sent to router.push or router.replace will be executed in the context of your page.\nThe <Link> component automatically prefetch routes as they become visible in the viewport.\nrefresh() could re-produce the same result if fetch requests are cached. Other Dynamic APIs like cookies and headers could also change the response.\nThe onInvalidate callback is called at most once per prefetch request. It signals when you may want to trigger a new prefetch for updated route data.\nMigrating from next/router\nThe useRouter hook should be imported from next/navigation and not next/router when using the App Router\nThe pathname string has been removed and is replaced by usePathname()\nThe query object has been removed and is replaced by useSearchParams()\nrouter.events has been replaced. See below.\n\nView the full migration guide.\n\nExamples\nRouter events\n\nYou can listen for page changes by composing other Client Component hooks like usePathname and useSearchParams.\n\napp/components/navigation-events.js\n'use client'\n \nimport { useEffect } from 'react'\nimport { usePathname, useSearchParams } from 'next/navigation'\n \nexport function NavigationEvents() {\n  const pathname = usePathname()\n  const searchParams = useSearchParams()\n \n  useEffect(() => {\n    const url = `${pathname}?${searchParams}`\n    console.log(url)\n    // You can now use the current URL\n    // ...\n  }, [pathname, searchParams])\n \n  return '...'\n}\n\nWhich can be imported into a layout.\n\napp/layout.js\nimport { Suspense } from 'react'\nimport { NavigationEvents } from './components/navigation-events'\n \nexport default function Layout({ children }) {\n  return (\n    <html lang=\"en\">\n      <body>\n        {children}\n \n        <Suspense fallback={null}>\n          <NavigationEvents />\n        </Suspense>\n      </body>\n    </html>\n  )\n}\n\nGood to know: <NavigationEvents> is wrapped in a Suspense boundary becauseuseSearchParams() causes client-side rendering up to the closest Suspense boundary during static rendering. Learn more.\n\nDisabling scroll to top\n\nBy default, Next.js will scroll to the top of the page when navigating to a new route. You can disable this behavior by passing scroll: false to router.push() or router.replace().\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useRouter } from 'next/navigation'\n \nexport default function Page() {\n  const router = useRouter()\n \n  return (\n    <button\n      type=\"button\"\n      onClick={() => router.push('/dashboard', { scroll: false })}\n    >\n      Dashboard\n    </button>\n  )\n}\nVersion History\nVersion\tChanges\nv15.4.0\tOptional onInvalidate callback for router.prefetch introduced\nv13.0.0\tuseRouter from next/navigation introduced.\nPrevious\nuseReportWebVitals\nNext\nuseSearchParams\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: useSearchParams | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-search-params",
    "html": "API Reference\nFunctions\nuseSearchParams\nCopy page\nuseSearchParams\n\nuseSearchParams is a Client Component hook that lets you read the current URL's query string.\n\nuseSearchParams returns a read-only version of the URLSearchParams\n interface.\n\napp/dashboard/search-bar.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useSearchParams } from 'next/navigation'\n \nexport default function SearchBar() {\n  const searchParams = useSearchParams()\n \n  const search = searchParams.get('search')\n \n  // URL -> `/dashboard?search=my-project`\n  // `search` -> 'my-project'\n  return <>Search: {search}</>\n}\nParameters\nconst searchParams = useSearchParams()\n\nuseSearchParams does not take any parameters.\n\nReturns\n\nuseSearchParams returns a read-only version of the URLSearchParams\n interface, which includes utility methods for reading the URL's query string:\n\nURLSearchParams.get()\n: Returns the first value associated with the search parameter. For example:\n\nURL\tsearchParams.get(\"a\")\n/dashboard?a=1\t'1'\n/dashboard?a=\t''\n/dashboard?b=3\tnull\n/dashboard?a=1&a=2\t'1' - use getAll()\n to get all values\n\nURLSearchParams.has()\n: Returns a boolean value indicating if the given parameter exists. For example:\n\nURL\tsearchParams.has(\"a\")\n/dashboard?a=1\ttrue\n/dashboard?b=3\tfalse\n\nLearn more about other read-only methods of URLSearchParams\n, including the getAll()\n, keys()\n, values()\n, entries()\n, forEach()\n, and toString()\n.\n\nGood to know:\n\nuseSearchParams is a Client Component hook and is not supported in Server Components to prevent stale values during partial rendering.\nIf you want to fetch data in a Server Component based on search params, it's often a better option to read the searchParams prop of the corresponding Page. You can then pass it down by props to any component (Server or Client) within that Page.\nIf an application includes the /pages directory, useSearchParams will return ReadonlyURLSearchParams | null. The null value is for compatibility during migration since search params cannot be known during pre-rendering of a page that doesn't use getServerSideProps\nBehavior\nStatic Rendering\n\nIf a route is statically rendered, calling useSearchParams will cause the Client Component tree up to the closest Suspense boundary to be client-side rendered.\n\nThis allows a part of the route to be statically rendered while the dynamic part that uses useSearchParams is client-side rendered.\n\nWe recommend wrapping the Client Component that uses useSearchParams in a <Suspense/> boundary. This will allow any Client Components above it to be statically rendered and sent as part of initial HTML. Example.\n\nFor example:\n\napp/dashboard/search-bar.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useSearchParams } from 'next/navigation'\n \nexport default function SearchBar() {\n  const searchParams = useSearchParams()\n \n  const search = searchParams.get('search')\n \n  // This will not be logged on the server when using static rendering\n  console.log(search)\n \n  return <>Search: {search}</>\n}\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Suspense } from 'react'\nimport SearchBar from './search-bar'\n \n// This component passed as a fallback to the Suspense boundary\n// will be rendered in place of the search bar in the initial HTML.\n// When the value is available during React hydration the fallback\n// will be replaced with the `<SearchBar>` component.\nfunction SearchBarFallback() {\n  return <>placeholder</>\n}\n \nexport default function Page() {\n  return (\n    <>\n      <nav>\n        <Suspense fallback={<SearchBarFallback />}>\n          <SearchBar />\n        </Suspense>\n      </nav>\n      <h1>Dashboard</h1>\n    </>\n  )\n}\n\nGood to know:\n\nIn development, routes are rendered on-demand, so useSearchParams doesn't suspend and things may appear to work without Suspense.\nDuring production builds, a static page that calls useSearchParams from a Client Component must be wrapped in a Suspense boundary, otherwise the build fails with the Missing Suspense boundary with useSearchParams error.\nIf you intend the route to be dynamically rendered, prefer using the connection function first in a Server Component to wait for an incoming request, this excludes everything below from prerendering. See what makes a route dynamic in the Dynamic Rendering guide.\nIf you're already in a Server Component Page, consider using the searchParams prop and passing the values to Client Components.\nYou can also pass the Page searchParams prop directly to a Client Component and unwrap it with React's use(). Although this will suspend, so the Client Component should be wrapped with a Suspense boundary.\nDynamic Rendering\n\nIf a route is dynamically rendered, useSearchParams will be available on the server during the initial server render of the Client Component.\n\nFor example:\n\napp/dashboard/search-bar.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useSearchParams } from 'next/navigation'\n \nexport default function SearchBar() {\n  const searchParams = useSearchParams()\n \n  const search = searchParams.get('search')\n \n  // This will be logged on the server during the initial render\n  // and on the client on subsequent navigations.\n  console.log(search)\n \n  return <>Search: {search}</>\n}\napp/dashboard/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { connection } from 'next/server'\nimport SearchBar from './search-bar'\n \nexport default async function Page() {\n  await connection()\n  return (\n    <>\n      <nav>\n        <SearchBar />\n      </nav>\n      <h1>Dashboard</h1>\n    </>\n  )\n}\n\nGood to know:\n\nPreviously, setting export const dynamic = 'force-dynamic' on the page was used to force dynamic rendering. Prefer using connection() instead, as it semantically ties dynamic rendering to the incoming request.\nServer Components\nPages\n\nTo access search params in Pages (Server Components), use the searchParams prop.\n\nLayouts\n\nUnlike Pages, Layouts (Server Components) do not receive the searchParams prop. This is because a shared layout is not re-rendered during navigation which could lead to stale searchParams between navigations. View detailed explanation.\n\nInstead, use the Page searchParams prop or the useSearchParams hook in a Client Component, which is re-rendered on the client with the latest searchParams.\n\nExamples\nUpdating searchParams\n\nYou can use useRouter or Link to set new searchParams. After a navigation is performed, the current page.js will receive an updated searchParams prop.\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nexport default function ExampleClientComponent() {\n  const router = useRouter()\n  const pathname = usePathname()\n  const searchParams = useSearchParams()\n \n  // Get a new searchParams string by merging the current\n  // searchParams with a provided key/value pair\n  const createQueryString = useCallback(\n    (name: string, value: string) => {\n      const params = new URLSearchParams(searchParams.toString())\n      params.set(name, value)\n \n      return params.toString()\n    },\n    [searchParams]\n  )\n \n  return (\n    <>\n      <p>Sort By</p>\n \n      {/* using useRouter */}\n      <button\n        onClick={() => {\n          // <pathname>?sort=asc\n          router.push(pathname + '?' + createQueryString('sort', 'asc'))\n        }}\n      >\n        ASC\n      </button>\n \n      {/* using <Link> */}\n      <Link\n        href={\n          // <pathname>?sort=desc\n          pathname + '?' + createQueryString('sort', 'desc')\n        }\n      >\n        DESC\n      </Link>\n    </>\n  )\n}\nVersion History\nVersion\tChanges\nv13.0.0\tuseSearchParams introduced.\nPrevious\nuseRouter\nNext\nuseSelectedLayoutSegment\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: useSelectedLayoutSegment | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-selected-layout-segment",
    "html": "API Reference\nFunctions\nuseSelectedLayoutSegment\nCopy page\nuseSelectedLayoutSegment\n\nuseSelectedLayoutSegment is a Client Component hook that lets you read the active route segment one level below the Layout it is called from.\n\nIt is useful for navigation UI, such as tabs inside a parent layout that change style depending on the active child segment.\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useSelectedLayoutSegment } from 'next/navigation'\n \nexport default function ExampleClientComponent() {\n  const segment = useSelectedLayoutSegment()\n \n  return <p>Active segment: {segment}</p>\n}\n\nGood to know:\n\nSince useSelectedLayoutSegment is a Client Component hook, and Layouts are Server Components by default, useSelectedLayoutSegment is usually called via a Client Component that is imported into a Layout.\nuseSelectedLayoutSegment only returns the segment one level down. To return all active segments, see useSelectedLayoutSegments\nParameters\nconst segment = useSelectedLayoutSegment(parallelRoutesKey?: string)\n\nuseSelectedLayoutSegment optionally accepts a parallelRoutesKey, which allows you to read the active route segment within that slot.\n\nReturns\n\nuseSelectedLayoutSegment returns a string of the active segment or null if one doesn't exist.\n\nFor example, given the Layouts and URLs below, the returned segment would be:\n\nLayout\tVisited URL\tReturned Segment\napp/layout.js\t/\tnull\napp/layout.js\t/dashboard\t'dashboard'\napp/dashboard/layout.js\t/dashboard\tnull\napp/dashboard/layout.js\t/dashboard/settings\t'settings'\napp/dashboard/layout.js\t/dashboard/analytics\t'analytics'\napp/dashboard/layout.js\t/dashboard/analytics/monthly\t'analytics'\nExamples\nCreating an active link component\n\nYou can use useSelectedLayoutSegment to create an active link component that changes style depending on the active segment. For example, a featured posts list in the sidebar of a blog:\n\napp/blog/blog-nav-link.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Link from 'next/link'\nimport { useSelectedLayoutSegment } from 'next/navigation'\n \n// This *client* component will be imported into a blog layout\nexport default function BlogNavLink({\n  slug,\n  children,\n}: {\n  slug: string\n  children: React.ReactNode\n}) {\n  // Navigating to `/blog/hello-world` will return 'hello-world'\n  // for the selected layout segment\n  const segment = useSelectedLayoutSegment()\n  const isActive = slug === segment\n \n  return (\n    <Link\n      href={`/blog/${slug}`}\n      // Change style depending on whether the link is active\n      style={{ fontWeight: isActive ? 'bold' : 'normal' }}\n    >\n      {children}\n    </Link>\n  )\n}\napp/blog/layout.tsx\nTypeScript\nJavaScript\nTypeScript\n// Import the Client Component into a parent Layout (Server Component)\nimport { BlogNavLink } from './blog-nav-link'\nimport getFeaturedPosts from './get-featured-posts'\n \nexport default async function Layout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  const featuredPosts = await getFeaturedPosts()\n  return (\n    <div>\n      {featuredPosts.map((post) => (\n        <div key={post.id}>\n          <BlogNavLink slug={post.slug}>{post.title}</BlogNavLink>\n        </div>\n      ))}\n      <div>{children}</div>\n    </div>\n  )\n}\nVersion History\nVersion\tChanges\nv13.0.0\tuseSelectedLayoutSegment introduced.\nPrevious\nuseSearchParams\nNext\nuseSelectedLayoutSegments\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: useSelectedLayoutSegments | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/use-selected-layout-segments",
    "html": "API Reference\nFunctions\nuseSelectedLayoutSegments\nCopy page\nuseSelectedLayoutSegments\n\nuseSelectedLayoutSegments is a Client Component hook that lets you read the active route segments below the Layout it is called from.\n\nIt is useful for creating UI in parent Layouts that need knowledge of active child segments such as breadcrumbs.\n\napp/example-client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useSelectedLayoutSegments } from 'next/navigation'\n \nexport default function ExampleClientComponent() {\n  const segments = useSelectedLayoutSegments()\n \n  return (\n    <ul>\n      {segments.map((segment, index) => (\n        <li key={index}>{segment}</li>\n      ))}\n    </ul>\n  )\n}\n\nGood to know:\n\nSince useSelectedLayoutSegments is a Client Component hook, and Layouts are Server Components by default, useSelectedLayoutSegments is usually called via a Client Component that is imported into a Layout.\nThe returned segments include Route Groups, which you might not want to be included in your UI. You can use the filter\n array method to remove items that start with a bracket.\nParameters\nconst segments = useSelectedLayoutSegments(parallelRoutesKey?: string)\n\nuseSelectedLayoutSegments optionally accepts a parallelRoutesKey, which allows you to read the active route segment within that slot.\n\nReturns\n\nuseSelectedLayoutSegments returns an array of strings containing the active segments one level down from the layout the hook was called from. Or an empty array if none exist.\n\nFor example, given the Layouts and URLs below, the returned segments would be:\n\nLayout\tVisited URL\tReturned Segments\napp/layout.js\t/\t[]\napp/layout.js\t/dashboard\t['dashboard']\napp/layout.js\t/dashboard/settings\t['dashboard', 'settings']\napp/dashboard/layout.js\t/dashboard\t[]\napp/dashboard/layout.js\t/dashboard/settings\t['settings']\nVersion History\nVersion\tChanges\nv13.0.0\tuseSelectedLayoutSegments introduced.\nPrevious\nuseSelectedLayoutSegment\nNext\nuserAgent\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Functions: userAgent | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/functions/userAgent",
    "html": "API Reference\nFunctions\nuserAgent\nCopy page\nuserAgent\n\nThe userAgent helper extends the Web Request API\n with additional properties and methods to interact with the user agent object from the request.\n\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextRequest, NextResponse, userAgent } from 'next/server'\n \nexport function proxy(request: NextRequest) {\n  const url = request.nextUrl\n  const { device } = userAgent(request)\n \n  // device.type can be: 'mobile', 'tablet', 'console', 'smarttv',\n  // 'wearable', 'embedded', or undefined (for desktop browsers)\n  const viewport = device.type || 'desktop'\n \n  url.searchParams.set('viewport', viewport)\n  return NextResponse.rewrite(url)\n}\nisBot\n\nA boolean indicating whether the request comes from a known bot.\n\nbrowser\n\nAn object containing information about the browser used in the request.\n\nname: A string representing the browser's name, or undefined if not identifiable.\nversion: A string representing the browser's version, or undefined.\ndevice\n\nAn object containing information about the device used in the request.\n\nmodel: A string representing the model of the device, or undefined.\ntype: A string representing the type of the device, such as console, mobile, tablet, smarttv, wearable, embedded, or undefined.\nvendor: A string representing the vendor of the device, or undefined.\nengine\n\nAn object containing information about the browser's engine.\n\nname: A string representing the engine's name. Possible values include: Amaya, Blink, EdgeHTML, Flow, Gecko, Goanna, iCab, KHTML, Links, Lynx, NetFront, NetSurf, Presto, Tasman, Trident, w3m, WebKit or undefined.\nversion: A string representing the engine's version, or undefined.\nos\n\nAn object containing information about the operating system.\n\nname: A string representing the name of the OS, or undefined.\nversion: A string representing the version of the OS, or undefined.\ncpu\n\nAn object containing information about the CPU architecture.\n\narchitecture: A string representing the architecture of the CPU. Possible values include: 68k, amd64, arm, arm64, armhf, avr, ia32, ia64, irix, irix64, mips, mips64, pa-risc, ppc, sparc, sparc64 or undefined\nPrevious\nuseSelectedLayoutSegments\nNext\nConfiguration\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "API Reference: Configuration | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config",
    "html": "App Router\nAPI Reference\nConfiguration\nCopy page\nConfiguration\nnext.config.js\nLearn how to configure your application with next.config.js.\nTypeScript\nNext.js provides a TypeScript-first development experience for building your React application.\nESLint\nLearn how to use and configure the ESLint plugin to catch common issues and problems in a Next.js application.\nPrevious\nuserAgent\nNext\nnext.config.js\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Configuration: next.config.js | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js",
    "html": "API Reference\nConfiguration\nnext.config.js\nCopy page\nnext.config.js\n\nNext.js can be configured through a next.config.js file in the root of your project directory (for example, by package.json) with a default export.\n\nnext.config.js\n// @ts-check\n \n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  /* config options here */\n}\n \nmodule.exports = nextConfig\nECMAScript Modules\n\nnext.config.js is a regular Node.js module, not a JSON file. It gets used by the Next.js server and build phases, and it's not included in the browser build.\n\nIf you need ECMAScript modules\n, you can use next.config.mjs:\n\nnext.config.mjs\n// @ts-check\n \n/**\n * @type {import('next').NextConfig}\n */\nconst nextConfig = {\n  /* config options here */\n}\n \nexport default nextConfig\n\nGood to know: next.config with the .cjs, .cts, or .mts extensions are currently not supported.\n\nConfiguration as a Function\n\nYou can also use a function:\n\nnext.config.mjs\n// @ts-check\n \nexport default (phase, { defaultConfig }) => {\n  /**\n   * @type {import('next').NextConfig}\n   */\n  const nextConfig = {\n    /* config options here */\n  }\n  return nextConfig\n}\nAsync Configuration\n\nSince Next.js 12.1.0, you can use an async function:\n\nnext.config.js\n// @ts-check\n \nmodule.exports = async (phase, { defaultConfig }) => {\n  /**\n   * @type {import('next').NextConfig}\n   */\n  const nextConfig = {\n    /* config options here */\n  }\n  return nextConfig\n}\nPhase\n\nphase is the current context in which the configuration is loaded. You can see the available phases\n. Phases can be imported from next/constants:\n\nnext.config.js\n// @ts-check\n \nconst { PHASE_DEVELOPMENT_SERVER } = require('next/constants')\n \nmodule.exports = (phase, { defaultConfig }) => {\n  if (phase === PHASE_DEVELOPMENT_SERVER) {\n    return {\n      /* development only config options here */\n    }\n  }\n \n  return {\n    /* config options for all phases except development here */\n  }\n}\nTypeScript\n\nIf you are using TypeScript in your project, you can use next.config.ts to use TypeScript in your configuration:\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  /* config options here */\n}\n \nexport default nextConfig\n\nThe commented lines are the place where you can put the configs allowed by next.config.js, which are defined in this file\n.\n\nHowever, none of the configs are required, and it's not necessary to understand what each config does. Instead, search for the features you need to enable or modify in this section and they will show you what to do.\n\nAvoid using new JavaScript features not available in your target Node.js version. next.config.js will not be parsed by Webpack or Babel.\n\nThis page documents all the available configuration options:\n\nUnit Testing (experimental)\n\nStarting in Next.js 15.1, the next/experimental/testing/server package contains utilities to help unit test next.config.js files.\n\nThe unstable_getResponseFromNextConfig function runs the headers, redirects, and rewrites functions from next.config.js with the provided request information and returns NextResponse with the results of the routing.\n\nThe response from unstable_getResponseFromNextConfig only considers next.config.js fields and does not consider proxy or filesystem routes, so the result in production may be different than the unit test.\n\nimport {\n  getRedirectUrl,\n  unstable_getResponseFromNextConfig,\n} from 'next/experimental/testing/server'\n \nconst response = await unstable_getResponseFromNextConfig({\n  url: 'https://nextjs.org/test',\n  nextConfig: {\n    async redirects() {\n      return [{ source: '/test', destination: '/test2', permanent: false }]\n    },\n  },\n})\nexpect(response.status).toEqual(307)\nexpect(getRedirectUrl(response)).toEqual('https://nextjs.org/test2')\nexperimental.adapterPath\nConfigure a custom adapter for Next.js to hook into the build process with modifyConfig and onBuildComplete callbacks.\nallowedDevOrigins\nUse `allowedDevOrigins` to configure additional origins that can request the dev server.\nappDir\nEnable the App Router to use layouts, streaming, and more.\nassetPrefix\nLearn how to use the assetPrefix config option to configure your CDN.\nauthInterrupts\nLearn how to enable the experimental `authInterrupts` configuration option to use `forbidden` and `unauthorized`.\nbasePath\nUse `basePath` to deploy a Next.js application under a sub-path of a domain.\nbrowserDebugInfoInTerminal\nForward browser console logs and errors to your terminal during development.\ncacheComponents\nLearn how to enable the cacheComponents flag in Next.js.\ncacheLife\nLearn how to set up cacheLife configurations in Next.js.\ncompress\nNext.js provides gzip compression to compress rendered content and static files, it only works with the server target. Learn more about it here.\ncrossOrigin\nUse the `crossOrigin` option to add a crossOrigin tag on the `script` tags generated by `next/script`.\ncssChunking\nUse the `cssChunking` option to control how CSS files are chunked in your Next.js application.\ndevIndicators\nConfiguration options for the on-screen indicator that gives context about the current route you're viewing during development.\ndistDir\nSet a custom build directory to use instead of the default .next directory.\nenv\nLearn to add and access environment variables in your Next.js application at build time.\nexpireTime\nCustomize stale-while-revalidate expire time for ISR enabled pages.\nexportPathMap\nCustomize the pages that will be exported as HTML files when using `next export`.\ngenerateBuildId\nConfigure the build id, which is used to identify the current build in which your application is being served.\ngenerateEtags\nNext.js will generate etags for every page by default. Learn more about how to disable etag generation here.\nheaders\nAdd custom HTTP headers to your Next.js app.\nhtmlLimitedBots\nSpecify a list of user agents that should receive blocking metadata.\nhttpAgentOptions\nNext.js will automatically use HTTP Keep-Alive by default. Learn more about how to disable HTTP Keep-Alive here.\nimages\nCustom configuration for the next/image loader\ncacheHandler\nConfigure the Next.js cache used for storing and revalidating data to use any external service like Redis, Memcached, or others.\ninlineCss\nEnable inline CSS support.\nisolatedDevBuild\nUse isolated build outputs for development server to prevent conflicts with production builds.\nlogging\nConfigure how data fetches are logged to the console when running Next.js in development mode.\nmdxRs\nUse the new Rust compiler to compile MDX files in the App Router.\nonDemandEntries\nConfigure how Next.js will dispose and keep in memory pages created in development.\noptimizePackageImports\nAPI Reference for optimizePackageImports Next.js Config Option\noutput\nNext.js automatically traces which files are needed by each page to allow for easy deployment of your application. Learn how it works here.\npageExtensions\nExtend the default page extensions used by Next.js when resolving pages in the Pages Router.\npoweredByHeader\nNext.js will add the `x-powered-by` header by default. Learn to opt-out of it here.\nproductionBrowserSourceMaps\nEnables browser source map generation during the production build.\nproxyClientMaxBodySize\nConfigure the maximum request body size when using proxy.\nreactCompiler\nEnable the React Compiler to automatically optimize component rendering.\nreactMaxHeadersLength\nThe maximum length of the headers that are emitted by React and added to the response.\nreactStrictMode\nThe complete Next.js runtime is now Strict Mode-compliant, learn how to opt-in\nredirects\nAdd redirects to your Next.js app.\nrewrites\nAdd rewrites to your Next.js app.\nsassOptions\nConfigure Sass options.\nserverActions\nConfigure Server Actions behavior in your Next.js application.\nserverComponentsHmrCache\nConfigure whether fetch responses in Server Components are cached across HMR refresh requests.\nserverExternalPackages\nOpt-out specific dependencies from the Server Components bundling and use native Node.js `require`.\nstaleTimes\nLearn how to override the invalidation time of the Client Router Cache.\nstaticGeneration*\nLearn how to configure static generation in your Next.js application.\ntaint\nEnable tainting Objects and Values.\ntrailingSlash\nConfigure Next.js pages to resolve with or without a trailing slash.\ntranspilePackages\nAutomatically transpile and bundle dependencies from local packages (like monorepos) or from external dependencies (`node_modules`).\nturbopack\nConfigure Next.js with Turbopack-specific options\nturbopackFileSystemCache\nLearn how to enable FileSystem Caching for Turbopack builds\ntypedRoutes\nEnable support for statically typed links.\ntypescript\nNext.js reports TypeScript errors by default. Learn to opt-out of this behavior here.\nurlImports\nConfigure Next.js to allow importing modules from external URLs.\nuseLightningcss\nEnable experimental support for Lightning CSS.\nviewTransition\nEnable ViewTransition API from React in App Router\nwebpack\nLearn how to customize the webpack config used by Next.js\nwebVitalsAttribution\nLearn how to use the webVitalsAttribution option to pinpoint the source of Web Vitals issues.\nPrevious\nConfiguration\nNext\nexperimental.adapterPath\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: allowedDevOrigins | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/allowedDevOrigins",
    "html": "Configuration\nnext.config.js\nallowedDevOrigins\nCopy page\nallowedDevOrigins\n\nNext.js does not automatically block cross-origin requests during development, but will block by default in a future major version of Next.js to prevent unauthorized requesting of internal assets/endpoints that are available in development mode.\n\nTo configure a Next.js application to allow requests from origins other than the hostname the server was initialized with (localhost by default) you can use the allowedDevOrigins config option.\n\nallowedDevOrigins allows you to set additional origins that can be used in development mode. For example, to use local-origin.dev instead of only localhost, open next.config.js and add the allowedDevOrigins config:\n\nnext.config.js\nmodule.exports = {\n  allowedDevOrigins: ['local-origin.dev', '*.local-origin.dev'],\n}\nPrevious\nexperimental.adapterPath\nNext\nappDir\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: experimental.adapterPath | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/adapterPath",
    "html": "Configuration\nnext.config.js\nexperimental.adapterPath\nCopy page\nexperimental.adapterPath\n\nNext.js provides an experimental API that allows you to create custom adapters to hook into the build process. This is useful for deployment platforms or custom build integrations that need to modify the Next.js configuration or process the build output.\n\nConfiguration\n\nTo use an adapter, specify the path to your adapter module in experimental.adapterPath:\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  experimental: {\n    adapterPath: require.resolve('./my-adapter.js'),\n  },\n}\n \nmodule.exports = nextConfig\nCreating an Adapter\n\nAn adapter is a module that exports an object implementing the NextAdapter interface:\n\nexport interface NextAdapter {\n  name: string\n  modifyConfig?: (\n    config: NextConfigComplete,\n    ctx: {\n      phase: PHASE_TYPE\n    }\n  ) => Promise<NextConfigComplete> | NextConfigComplete\n  onBuildComplete?: (ctx: {\n    routes: {\n      headers: Array<ManifestHeaderRoute>\n      redirects: Array<ManifestRedirectRoute>\n      rewrites: {\n        beforeFiles: Array<ManifestRewriteRoute>\n        afterFiles: Array<ManifestRewriteRoute>\n        fallback: Array<ManifestRewriteRoute>\n      }\n      dynamicRoutes: ReadonlyArray<ManifestRoute>\n    }\n    outputs: AdapterOutputs\n    projectDir: string\n    repoRoot: string\n    distDir: string\n    config: NextConfigComplete\n    nextVersion: string\n  }) => Promise<void> | void\n}\nBasic Adapter Structure\n\nHere's a minimal adapter example:\n\nmy-adapter.js\n/** @type {import('next').NextAdapter} */\nconst adapter = {\n  name: 'my-custom-adapter',\n \n  async modifyConfig(config, { phase }) {\n    // Modify the Next.js config based on the build phase\n    if (phase === 'phase-production-build') {\n      return {\n        ...config,\n        // Add your modifications\n      }\n    }\n    return config\n  },\n \n  async onBuildComplete({\n    routes,\n    outputs,\n    projectDir,\n    repoRoot,\n    distDir,\n    config,\n    nextVersion,\n  }) {\n    // Process the build output\n    console.log('Build completed with', outputs.pages.length, 'pages')\n \n    // Access different output types\n    for (const page of outputs.pages) {\n      console.log('Page:', page.pathname, 'at', page.filePath)\n    }\n \n    for (const apiRoute of outputs.pagesApi) {\n      console.log('API Route:', apiRoute.pathname, 'at', apiRoute.filePath)\n    }\n \n    for (const appPage of outputs.appPages) {\n      console.log('App Page:', appPage.pathname, 'at', appPage.filePath)\n    }\n \n    for (const prerender of outputs.prerenders) {\n      console.log('Prerendered:', prerender.pathname)\n    }\n  },\n}\n \nmodule.exports = adapter\nAPI Reference\nmodifyConfig(config, context)\n\nCalled for any CLI command that loads the next.config to allow modification of the configuration.\n\nParameters:\n\nconfig: The complete Next.js configuration object\ncontext.phase: The current build phase (see phases)\n\nReturns: The modified configuration object (can be async)\n\nonBuildComplete(context)\n\nCalled after the build process completes with detailed information about routes and outputs.\n\nParameters:\n\nroutes: Object containing route manifests for headers, redirects, rewrites, and dynamic routes\nroutes.headers: Array of header route objects with source, sourceRegex, headers, has, missing, and optional priority fields\nroutes.redirects: Array of redirect route objects with source, sourceRegex, destination, statusCode, has, missing, and optional priority fields\nroutes.rewrites: Object with beforeFiles, afterFiles, and fallback arrays, each containing rewrite route objects with source, sourceRegex, destination, has, and missing fields\nroutes.dynamicRoutes: Array of dynamic route objects with source, sourceRegex, destination, has, and missing fields\noutputs: Detailed information about all build outputs organized by type\nprojectDir: Absolute path to the Next.js project directory\nrepoRoot: Absolute path to the detected repository root\ndistDir: Absolute path to the build output directory\nconfig: The final Next.js configuration (with modifyConfig applied)\nnextVersion: Version of Next.js being used\nbuildId: Unique identifier for the current build\nOutput Types\n\nThe outputs object contains arrays of different output types:\n\nPages (outputs.pages)\n\nReact pages from the pages/ directory:\n\n{\n  type: 'PAGES'\n  id: string           // Route identifier\n  filePath: string     // Path to the built file\n  pathname: string     // URL pathname\n  sourcePage: string   // Original source file path in pages/ directory\n  runtime: 'nodejs' | 'edge'\n  assets: Record<string, string>  // Traced dependencies (key: relative path from repo root, value: absolute path)\n  wasmAssets?: Record<string, string>  // Bundled wasm files (key: name, value: absolute path)\n  config: {\n    maxDuration?: number\n    preferredRegion?: string | string[]\n    env?: Record<string, string>  // Environment variables (edge runtime only)\n  }\n}\nAPI Routes (outputs.pagesApi)\n\nAPI routes from pages/api/:\n\n{\n  type: 'PAGES_API'\n  id: string\n  filePath: string\n  pathname: string\n  sourcePage: string   // Original relative source file path\n  runtime: 'nodejs' | 'edge'\n  assets: Record<string, string>\n  wasmAssets?: Record<string, string>\n  config: {\n    maxDuration?: number\n    preferredRegion?: string | string[]\n    env?: Record<string, string>\n  }\n}\nApp Pages (outputs.appPages)\n\nReact pages from the app/ directory with page.{js,ts,jsx,tsx}:\n\n{\n  type: 'APP_PAGE'\n  id: string\n  filePath: string\n  pathname: string     // Includes .rsc suffix for RSC routes\n  sourcePage: string   // Original relative source file path\n  runtime: 'nodejs' | 'edge'\n  assets: Record<string, string>\n  wasmAssets?: Record<string, string>\n  config: {\n    maxDuration?: number\n    preferredRegion?: string | string[]\n    env?: Record<string, string>\n  }\n}\nApp Routes (outputs.appRoutes)\n\nAPI and metadata routes from app/ with route.{js,ts,jsx,tsx}:\n\n{\n  type: 'APP_ROUTE'\n  id: string\n  filePath: string\n  pathname: string\n  sourcePage: string\n  runtime: 'nodejs' | 'edge'\n  assets: Record<string, string>\n  wasmAssets?: Record<string, string>\n  config: {\n    maxDuration?: number\n    preferredRegion?: string | string[]\n    env?: Record<string, string>\n  }\n}\nPrerenders (outputs.prerenders)\n\nISR-enabled routes and static prerenders:\n\n{\n  type: 'PRERENDER'\n  id: string\n  pathname: string\n  parentOutputId: string  // ID of the source page/route\n  groupId: number        // Revalidation group identifier (prerenders with same groupId revalidate together)\n  pprChain?: {\n    headers: Record<string, string>  // PPR chain headers (e.g., 'x-nextjs-resume': '1')\n  }\n  parentFallbackMode?: 'blocking' | false | null  // Fallback mode from getStaticPaths\n  fallback?: {\n    filePath: string\n    initialStatus?: number\n    initialHeaders?: Record<string, string | string[]>\n    initialExpiration?: number\n    initialRevalidate?: number\n    postponedState?: string  // PPR postponed state\n  }\n  config: {\n    allowQuery?: string[]     // Allowed query parameters\n    allowHeader?: string[]    // Allowed headers for ISR\n    bypassFor?: RouteHas[]    // Cache bypass conditions\n    renderingMode?: RenderingMode\n    bypassToken?: string\n  }\n}\nStatic Files (outputs.staticFiles)\n\nStatic assets and auto-statically optimized pages:\n\n{\n  type: 'STATIC_FILE'\n  id: string\n  filePath: string\n  pathname: string\n}\nMiddleware (outputs.middleware)\n\nMiddleware function (if present):\n\n{\n  type: 'MIDDLEWARE'\n  id: string\n  filePath: string\n  pathname: string      // Always '/_middleware'\n  sourcePage: string    // Always 'middleware'\n  runtime: 'nodejs' | 'edge'\n  assets: Record<string, string>\n  wasmAssets?: Record<string, string>\n  config: {\n    maxDuration?: number\n    preferredRegion?: string | string[]\n    env?: Record<string, string>\n    matchers?: Array<{\n      source: string\n      sourceRegex: string\n      has: RouteHas[] | undefined\n      missing: RouteHas[] | undefined\n    }>\n  }\n}\nRoutes Information\n\nThe routes object in onBuildComplete provides complete routing information with processed patterns ready for deployment:\n\nHeaders\n\nEach header route includes:\n\nsource: Original route pattern (e.g., /about)\nsourceRegex: Compiled regex for matching requests\nheaders: Key-value pairs of headers to apply\nhas: Optional conditions that must be met\nmissing: Optional conditions that must not be met\npriority: Optional flag for internal routes\nRedirects\n\nEach redirect route includes:\n\nsource: Original route pattern\nsourceRegex: Compiled regex for matching\ndestination: Target URL (can include captured groups)\nstatusCode: HTTP status code (301, 302, 307, 308)\nhas: Optional positive conditions\nmissing: Optional negative conditions\npriority: Optional flag for internal routes\nRewrites\n\nRewrites are categorized into three phases:\n\nbeforeFiles: Checked before filesystem (including pages and public files)\nafterFiles: Checked after pages/public files but before dynamic routes\nfallback: Checked after all other routes\n\nEach rewrite includes source, sourceRegex, destination, has, and missing.\n\nDynamic Routes\n\nGenerated from dynamic route segments (e.g., [slug], [...path]). Each includes:\n\nsource: Route pattern\nsourceRegex: Compiled regex with named capture groups\ndestination: Internal destination with parameter substitution\nhas: Optional positive conditions\nmissing: Optional negative conditions\nUse Cases\n\nCommon use cases for adapters include:\n\nDeployment Platform Integration: Automatically configure build outputs for specific hosting platforms\nAsset Processing: Transform or optimize build outputs\nMonitoring Integration: Collect build metrics and route information\nCustom Bundling: Package outputs in platform-specific formats\nBuild Validation: Ensure outputs meet specific requirements\nRoute Generation: Use processed route information to generate platform-specific routing configs\nPrevious\nnext.config.js\nNext\nallowedDevOrigins\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: appDir | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/appDir",
    "html": "Configuration\nnext.config.js\nappDir\nCopy page\nappDir\nThis is a legacy API and no longer recommended. It's still supported for backward compatibility.\n\nGood to know: This option is no longer needed as of Next.js 13.4. The App Router is now stable.\n\nThe App Router (app directory) enables support for layouts, Server Components, streaming, and colocated data fetching.\n\nUsing the app directory will automatically enable React Strict Mode\n. Learn how to incrementally adopt app.\n\nPrevious\nallowedDevOrigins\nNext\nassetPrefix\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: assetPrefix | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/assetPrefix",
    "html": "Configuration\nnext.config.js\nassetPrefix\nCopy page\nassetPrefix\n\nAttention: Deploying to Vercel automatically configures a global CDN for your Next.js project. You do not need to manually setup an Asset Prefix.\n\nGood to know: Next.js 9.5+ added support for a customizable Base Path, which is better suited for hosting your application on a sub-path like /docs. We do not suggest you use a custom Asset Prefix for this use case.\n\nSet up a CDN\n\nTo set up a CDN\n, you can set up an asset prefix and configure your CDN's origin to resolve to the domain that Next.js is hosted on.\n\nOpen next.config.mjs and add the assetPrefix config based on the phase:\n\nnext.config.mjs\n// @ts-check\nimport { PHASE_DEVELOPMENT_SERVER } from 'next/constants'\n \nexport default (phase) => {\n  const isDev = phase === PHASE_DEVELOPMENT_SERVER\n  /**\n   * @type {import('next').NextConfig}\n   */\n  const nextConfig = {\n    assetPrefix: isDev ? undefined : 'https://cdn.mydomain.com',\n  }\n  return nextConfig\n}\n\nNext.js will automatically use your asset prefix for the JavaScript and CSS files it loads from the /_next/ path (.next/static/ folder). For example, with the above configuration, the following request for a JS chunk:\n\n/_next/static/chunks/4b9b41aaa062cbbfeff4add70f256968c51ece5d.4d708494b3aed70c04f0.js\n\n\nWould instead become:\n\nhttps://cdn.mydomain.com/_next/static/chunks/4b9b41aaa062cbbfeff4add70f256968c51ece5d.4d708494b3aed70c04f0.js\n\n\nThe exact configuration for uploading your files to a given CDN will depend on your CDN of choice. The only folder you need to host on your CDN is the contents of .next/static/, which should be uploaded as _next/static/ as the above URL request indicates. Do not upload the rest of your .next/ folder, as you should not expose your server code and other configuration to the public.\n\nWhile assetPrefix covers requests to _next/static, it does not influence the following paths:\n\nFiles in the public folder; if you want to serve those assets over a CDN, you'll have to introduce the prefix yourself\nPrevious\nappDir\nNext\nauthInterrupts\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: authInterrupts | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/authInterrupts",
    "html": "Configuration\nnext.config.js\nauthInterrupts\nCopy page\nauthInterrupts\nThis feature is currently available in the canary channel and subject to change. Try it out by upgrading Next.js, and share your feedback on GitHub.\n\nThe authInterrupts configuration option allows you to use forbidden and unauthorized APIs in your application. While these functions are experimental, you must enable the authInterrupts option in your next.config.js file to use them:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    authInterrupts: true,\n  },\n}\n \nexport default nextConfig\nNext Steps\nforbidden\nAPI Reference for the forbidden function.\nunauthorized\nAPI Reference for the unauthorized function.\nforbidden.js\nAPI reference for the forbidden.js special file.\nunauthorized.js\nAPI reference for the unauthorized.js special file.\nPrevious\nassetPrefix\nNext\nbasePath\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: basePath | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/basePath",
    "html": "Configuration\nnext.config.js\nbasePath\nCopy page\nbasePath\n\nTo deploy a Next.js application under a sub-path of a domain you can use the basePath config option.\n\nbasePath allows you to set a path prefix for the application. For example, to use /docs instead of '' (an empty string, the default), open next.config.js and add the basePath config:\n\nnext.config.js\nmodule.exports = {\n  basePath: '/docs',\n}\n\nGood to know: This value must be set at build time and cannot be changed without re-building as the value is inlined in the client-side bundles.\n\nLinks\n\nWhen linking to other pages using next/link and next/router the basePath will be automatically applied.\n\nFor example, using /about will automatically become /docs/about when basePath is set to /docs.\n\nexport default function HomePage() {\n  return (\n    <>\n      <Link href=\"/about\">About Page</Link>\n    </>\n  )\n}\n\nOutput html:\n\n<a href=\"/docs/about\">About Page</a>\n\nThis makes sure that you don't have to change all links in your application when changing the basePath value.\n\nImages\n\nWhen using the next/image component, you will need to add the basePath in front of src.\n\nFor example, using /docs/me.png will properly serve your image when basePath is set to /docs.\n\nimport Image from 'next/image'\n \nfunction Home() {\n  return (\n    <>\n      <h1>My Homepage</h1>\n      <Image\n        src=\"/docs/me.png\"\n        alt=\"Picture of the author\"\n        width={500}\n        height={500}\n      />\n      <p>Welcome to my homepage!</p>\n    </>\n  )\n}\n \nexport default Home\nPrevious\nauthInterrupts\nNext\nbrowserDebugInfoInTerminal\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: cacheComponents | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/cacheComponents",
    "html": "Configuration\nnext.config.js\ncacheComponents\nCopy page\ncacheComponents\n\nThe cacheComponents flag is a feature in Next.js that causes data fetching operations in the App Router to be excluded from pre-renders unless they are explicitly cached. This can be useful for optimizing the performance of dynamic data fetching in Server Components.\n\nIt is useful if your application requires fresh data fetching during runtime rather than serving from a pre-rendered cache.\n\nIt is expected to be used in conjunction with use cache so that your data fetching happens at runtime by default unless you define specific parts of your application to be cached with use cache at the page, function, or component level.\n\nUsage\n\nTo enable the cacheComponents flag, set it to true in your next.config.ts file:\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n \nexport default nextConfig\n\nWhen cacheComponents is enabled, you can use the following cache functions and configurations:\n\nThe use cache directive\nThe cacheLife function with use cache\nThe cacheTag function\nNotes\nWhile cacheComponents can optimize performance by ensuring fresh data fetching during runtime, it may also introduce additional latency compared to serving pre-rendered content.\nVersion History\nVersion\tChange\n16.0.0\tcacheComponents introduced. This flag controls the ppr, useCache, and dynamicIO flags as a single, unified configuration.\nPrevious\nbrowserDebugInfoInTerminal\nNext\ncacheLife\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: browserDebugInfoInTerminal | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/browserDebugInfoInTerminal",
    "html": "Configuration\nnext.config.js\nbrowserDebugInfoInTerminal\nCopy page\nbrowserDebugInfoInTerminal\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe experimental.browserDebugInfoInTerminal option forwards console output and runtime errors originating in the browser to the dev server terminal.\n\nThis option is disabled by default. When enabled it only works in development mode.\n\nUsage\n\nEnable forwarding:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    browserDebugInfoInTerminal: true,\n  },\n}\n \nexport default nextConfig\nSerialization limits\n\nDeeply nested objects/arrays are truncated using sensible defaults. You can tweak these limits:\n\ndepthLimit: (optional) Limit stringification depth for nested objects/arrays. Default: 5\nedgeLimit: (optional) Max number of properties or elements to include per object or array. Default: 100\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    browserDebugInfoInTerminal: {\n      depthLimit: 5,\n      edgeLimit: 100,\n    },\n  },\n}\n \nexport default nextConfig\nSource location\n\nSource locations are included by default when this feature is enabled.\n\napp/page.tsx\n'use client'\n \nexport default function Home() {\n  return (\n    <button\n      type=\"button\"\n      onClick={() => {\n        console.log('Hello World')\n      }}\n    >\n      Click me\n    </button>\n  )\n}\n\nClicking the button prints this message to the terminal.\n\nTerminal\n[browser] Hello World (app/page.tsx:8:17)\n\nTo suppress them, set showSourceLocation: false.\n\nshowSourceLocation: Include source location info when available.\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    browserDebugInfoInTerminal: {\n      showSourceLocation: false,\n    },\n  },\n}\n \nexport default nextConfig\nVersion\tChanges\nv15.4.0\texperimental browserDebugInfoInTerminal introduced\nPrevious\nbasePath\nNext\ncacheComponents\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: cacheLife | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/cacheLife",
    "html": "Configuration\nnext.config.js\ncacheLife\nCopy page\ncacheLife\n\nThe cacheLife option allows you to define custom cache profiles when using the cacheLife function inside components or functions, and within the scope of the use cache directive.\n\nUsage\n\nTo define a profile, enable the cacheComponents flag and add the cache profile in the cacheLife object in the next.config.js file. For example, a blog profile:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n  cacheLife: {\n    blog: {\n      stale: 3600, // 1 hour\n      revalidate: 900, // 15 minutes\n      expire: 86400, // 1 day\n    },\n  },\n}\n \nexport default nextConfig\n\nYou can now use this custom blog configuration in your component or function as follows:\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cacheLife } from 'next/cache'\n \nexport async function getCachedData() {\n  'use cache'\n  cacheLife('blog')\n  const data = await fetch('/api/data')\n  return data\n}\nReference\n\nThe configuration object has key values with the following format:\n\nProperty\tValue\tDescription\tRequirement\nstale\tnumber\tDuration the client should cache a value without checking the server.\tOptional\nrevalidate\tnumber\tFrequency at which the cache should refresh on the server; stale values may be served while revalidating.\tOptional\nexpire\tnumber\tMaximum duration for which a value can remain stale before switching to dynamic.\tOptional - Must be longer than revalidate\nPrevious\ncacheComponents\nNext\ncompress\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: compress | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/compress",
    "html": "Configuration\nnext.config.js\ncompress\nCopy page\ncompress\n\nBy default, Next.js uses gzip to compress rendered content and static files when using next start or a custom server. This is an optimization for applications that do not have compression configured. If compression is already configured in your application via a custom server, Next.js will not add compression.\n\nYou can check if compression is enabled and which algorithm is used by looking at the Accept-Encoding\n (browser accepted options) and Content-Encoding\n (currently used) headers in the response.\n\nDisabling compression\n\nTo disable compression, set the compress config option to false:\n\nnext.config.js\nmodule.exports = {\n  compress: false,\n}\n\nWe do not recommend disabling compression unless you have compression configured on your server, as compression reduces bandwidth usage and improves the performance of your application. For example, you're using nginx\n and want to switch to brotli, set the compress option to false to allow nginx to handle compression.\n\nPrevious\ncacheLife\nNext\ncrossOrigin\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: crossOrigin | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/crossOrigin",
    "html": "Configuration\nnext.config.js\ncrossOrigin\nCopy page\ncrossOrigin\n\nUse the crossOrigin option to add a crossOrigin attribute\n in all <script> tags generated by the next/script component , and define how cross-origin requests should be handled.\n\nnext.config.js\nmodule.exports = {\n  crossOrigin: 'anonymous',\n}\nOptions\n'anonymous': Adds crossOrigin=\"anonymous\"\n attribute.\n'use-credentials': Adds crossOrigin=\"use-credentials\"\n.\nPrevious\ncompress\nNext\ncssChunking\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: cssChunking | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/cssChunking",
    "html": "Configuration\nnext.config.js\ncssChunking\nCopy page\ncssChunking\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nCSS Chunking is a strategy used to improve the performance of your web application by splitting and re-ordering CSS files into chunks. This allows you to load only the CSS that is needed for a specific route, instead of loading all the application's CSS at once.\n\nYou can control how CSS files are chunked using the experimental.cssChunking option in your next.config.js file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig = {\n  experimental: {\n    cssChunking: true, // default\n  },\n} satisfies NextConfig\n \nexport default nextConfig\nOptions\ntrue (default): Next.js will try to merge CSS files whenever possible, determining explicit and implicit dependencies between files from import order to reduce the number of chunks and therefore the number of requests.\nfalse: Next.js will not attempt to merge or re-order your CSS files.\n'strict': Next.js will load CSS files in the correct order they are imported into your files, which can lead to more chunks and requests.\n\nYou may consider using 'strict' if you run into unexpected CSS behavior. For example, if you import a.css and b.css in different files using a different import order (a before b, or b before a), true will merge the files in any order and assume there are no dependencies between them. However, if b.css depends on a.css, you may want to use 'strict' to prevent the files from being merged, and instead, load them in the order they are imported - which can result in more chunks and requests.\n\nFor most applications, we recommend true as it leads to fewer requests and better performance.\n\nPrevious\ncrossOrigin\nNext\ndevIndicators\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: devIndicators | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/devIndicators",
    "html": "Configuration\nnext.config.js\ndevIndicators\nCopy page\ndevIndicators\n\ndevIndicators allows you to configure the on-screen indicator that gives context about the current route you're viewing during development.\n\nTypes\n  devIndicators: false | {\n    position?: 'bottom-right'\n    | 'bottom-left'\n    | 'top-right'\n    | 'top-left', // defaults to 'bottom-left',\n  },\n\nSetting devIndicators to false will hide the indicator, however Next.js will continue to surface any build or runtime errors that were encountered.\n\nTroubleshooting\nIndicator not marking a route as static\n\nIf you expect a route to be static and the indicator has marked it as dynamic, it's likely the route has opted out of static rendering.\n\nYou can confirm if a route is static or dynamic by building your application using next build --debug, and checking the output in your terminal. Static (or prerendered) routes will display a ○ symbol, whereas dynamic routes will display a ƒ symbol. For example:\n\nBuild Output\nRoute (app)\n┌ ○ /_not-found\n└ ƒ /products/[id]\n \n○  (Static)   prerendered as static content\nƒ  (Dynamic)  server-rendered on demand\n\nThere are two reasons a route might opt out of static rendering:\n\nThe presence of Dynamic APIs which rely on runtime information.\nAn uncached data request, like a call to an ORM or database driver.\n\nCheck your route for any of these conditions, and if you are not able to statically render the route, then consider using loading.js or <Suspense />\n to leverage streaming.\n\nVersion History\nVersion\tChanges\nv16.0.0\tappIsrStatus, buildActivity, and buildActivityPosition options have been removed.\nv15.2.0\tImproved on-screen indicator with new position option. appIsrStatus, buildActivity, and buildActivityPosition options have been deprecated.\nv15.0.0\tStatic on-screen indicator added with appIsrStatus option.\nPrevious\ncssChunking\nNext\ndistDir\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: distDir | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/distDir",
    "html": "Configuration\nnext.config.js\ndistDir\nCopy page\ndistDir\n\nYou can specify a name to use for a custom build directory to use instead of .next.\n\nOpen next.config.js and add the distDir config:\n\nnext.config.js\nmodule.exports = {\n  distDir: 'build',\n}\n\nNow if you run next build Next.js will use build instead of the default .next folder.\n\ndistDir should not leave your project directory. For example, ../build is an invalid directory.\n\nPrevious\ndevIndicators\nNext\nenv\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: env | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/env",
    "html": "Configuration\nnext.config.js\nenv\nCopy page\nenv\nThis is a legacy API and no longer recommended. It's still supported for backward compatibility.\n\nSince the release of Next.js 9.4\n we now have a more intuitive and ergonomic experience for adding environment variables. Give it a try!\n\nGood to know: environment variables specified in this way will always be included in the JavaScript bundle, prefixing the environment variable name with NEXT_PUBLIC_ only has an effect when specifying them through the environment or .env files.\n\nTo add environment variables to the JavaScript bundle, open next.config.js and add the env config:\n\nnext.config.js\nmodule.exports = {\n  env: {\n    customKey: 'my-value',\n  },\n}\n\nNow you can access process.env.customKey in your code. For example:\n\nfunction Page() {\n  return <h1>The value of customKey is: {process.env.customKey}</h1>\n}\n \nexport default Page\n\nNext.js will replace process.env.customKey with 'my-value' at build time. Trying to destructure process.env variables won't work due to the nature of webpack DefinePlugin\n.\n\nFor example, the following line:\n\nreturn <h1>The value of customKey is: {process.env.customKey}</h1>\n\nWill end up being:\n\nreturn <h1>The value of customKey is: {'my-value'}</h1>\nPrevious\ndistDir\nNext\nexpireTime\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: expireTime | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/expireTime",
    "html": "Configuration\nnext.config.js\nexpireTime\nCopy page\nexpireTime\n\nYou can specify a custom stale-while-revalidate expire time for CDNs to consume in the Cache-Control header for ISR enabled pages.\n\nOpen next.config.js and add the expireTime config:\n\nnext.config.js\nmodule.exports = {\n  // one hour in seconds\n  expireTime: 3600,\n}\n\nNow when sending the Cache-Control header the expire time will be calculated depending on the specific revalidate period.\n\nFor example, if you have a revalidate of 15 minutes on a path and the expire time is one hour the generated Cache-Control header will be s-maxage=900, stale-while-revalidate=2700 so that it can stay stale for 15 minutes less than the configured expire time.\n\nPrevious\nenv\nNext\nexportPathMap\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: exportPathMap | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/exportPathMap",
    "html": "Configuration\nnext.config.js\nexportPathMap\nCopy page\nexportPathMap\nThis is a legacy API and no longer recommended. It's still supported for backward compatibility.\n\nThis feature is exclusive to next export and currently deprecated in favor of getStaticPaths with pages or generateStaticParams with app.\n\nexportPathMap allows you to specify a mapping of request paths to page destinations, to be used during export. Paths defined in exportPathMap will also be available when using next dev.\n\nLet's start with an example, to create a custom exportPathMap for an app with the following pages:\n\npages/index.js\npages/about.js\npages/post.js\n\nOpen next.config.js and add the following exportPathMap config:\n\nnext.config.js\nmodule.exports = {\n  exportPathMap: async function (\n    defaultPathMap,\n    { dev, dir, outDir, distDir, buildId }\n  ) {\n    return {\n      '/': { page: '/' },\n      '/about': { page: '/about' },\n      '/p/hello-nextjs': { page: '/post', query: { title: 'hello-nextjs' } },\n      '/p/learn-nextjs': { page: '/post', query: { title: 'learn-nextjs' } },\n      '/p/deploy-nextjs': { page: '/post', query: { title: 'deploy-nextjs' } },\n    }\n  },\n}\n\nGood to know: the query field in exportPathMap cannot be used with automatically statically optimized pages or getStaticProps pages as they are rendered to HTML files at build-time and additional query information cannot be provided during next export.\n\nThe pages will then be exported as HTML files, for example, /about will become /about.html.\n\nexportPathMap is an async function that receives 2 arguments: the first one is defaultPathMap, which is the default map used by Next.js. The second argument is an object with:\n\ndev - true when exportPathMap is being called in development. false when running next export. In development exportPathMap is used to define routes.\ndir - Absolute path to the project directory\noutDir - Absolute path to the out/ directory (configurable with -o). When dev is true the value of outDir will be null.\ndistDir - Absolute path to the .next/ directory (configurable with the distDir config)\nbuildId - The generated build id\n\nThe returned object is a map of pages where the key is the pathname and the value is an object that accepts the following fields:\n\npage: String - the page inside the pages directory to render\nquery: Object - the query object passed to getInitialProps when prerendering. Defaults to {}\n\nThe exported pathname can also be a filename (for example, /readme.md), but you may need to set the Content-Type header to text/html when serving its content if it is different than .html.\n\nAdding a trailing slash\n\nIt is possible to configure Next.js to export pages as index.html files and require trailing slashes, /about becomes /about/index.html and is routable via /about/. This was the default behavior prior to Next.js 9.\n\nTo switch back and add a trailing slash, open next.config.js and enable the trailingSlash config:\n\nnext.config.js\nmodule.exports = {\n  trailingSlash: true,\n}\nCustomizing the output directory\n\nnext export will use out as the default output directory, you can customize this using the -o argument, like so:\n\nTerminal\nnext export -o outdir\n\nWarning: Using exportPathMap is deprecated and is overridden by getStaticPaths inside pages. We don't recommend using them together.\n\nPrevious\nexpireTime\nNext\ngenerateBuildId\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: generateBuildId | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/generateBuildId",
    "html": "Configuration\nnext.config.js\ngenerateBuildId\nCopy page\ngenerateBuildId\n\nNext.js generates an ID during next build to identify which version of your application is being served. The same build should be used and boot up multiple containers.\n\nIf you are rebuilding for each stage of your environment, you will need to generate a consistent build ID to use between containers. Use the generateBuildId command in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  generateBuildId: async () => {\n    // This could be anything, using the latest git hash\n    return process.env.GIT_HASH\n  },\n}\nPrevious\nexportPathMap\nNext\ngenerateEtags\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: generateEtags | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/generateEtags",
    "html": "Configuration\nnext.config.js\ngenerateEtags\nCopy page\ngenerateEtags\n\nNext.js will generate etags\n for every page by default. You may want to disable etag generation for HTML pages depending on your cache strategy.\n\nOpen next.config.js and disable the generateEtags option:\n\nnext.config.js\nmodule.exports = {\n  generateEtags: false,\n}\nPrevious\ngenerateBuildId\nNext\nheaders\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: headers | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/headers",
    "html": "Configuration\nnext.config.js\nheaders\nCopy page\nheaders\n\nHeaders allow you to set custom HTTP headers on the response to an incoming request on a given path.\n\nTo set custom HTTP headers you can use the headers key in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  async headers() {\n    return [\n      {\n        source: '/about',\n        headers: [\n          {\n            key: 'x-custom-header',\n            value: 'my custom header value',\n          },\n          {\n            key: 'x-another-custom-header',\n            value: 'my other custom header value',\n          },\n        ],\n      },\n    ]\n  },\n}\n\nheaders is an async function that expects an array to be returned holding objects with source and headers properties:\n\nsource is the incoming request path pattern.\nheaders is an array of response header objects, with key and value properties.\nbasePath: false or undefined - if false the basePath won't be included when matching, can be used for external rewrites only.\nlocale: false or undefined - whether the locale should not be included when matching.\nhas is an array of has objects with the type, key and value properties.\nmissing is an array of missing objects with the type, key and value properties.\n\nHeaders are checked before the filesystem which includes pages and /public files.\n\nHeader Overriding Behavior\n\nIf two headers match the same path and set the same header key, the last header key will override the first. Using the below headers, the path /hello will result in the header x-hello being world due to the last header value set being world.\n\nnext.config.js\nmodule.exports = {\n  async headers() {\n    return [\n      {\n        source: '/:path*',\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'there',\n          },\n        ],\n      },\n      {\n        source: '/hello',\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'world',\n          },\n        ],\n      },\n    ]\n  },\n}\nPath Matching\n\nPath matches are allowed, for example /blog/:slug will match /blog/hello-world (no nested paths):\n\nnext.config.js\nmodule.exports = {\n  async headers() {\n    return [\n      {\n        source: '/blog/:slug',\n        headers: [\n          {\n            key: 'x-slug',\n            value: ':slug', // Matched parameters can be used in the value\n          },\n          {\n            key: 'x-slug-:slug', // Matched parameters can be used in the key\n            value: 'my other custom header value',\n          },\n        ],\n      },\n    ]\n  },\n}\nWildcard Path Matching\n\nTo match a wildcard path you can use * after a parameter, for example /blog/:slug* will match /blog/a/b/c/d/hello-world:\n\nnext.config.js\nmodule.exports = {\n  async headers() {\n    return [\n      {\n        source: '/blog/:slug*',\n        headers: [\n          {\n            key: 'x-slug',\n            value: ':slug*', // Matched parameters can be used in the value\n          },\n          {\n            key: 'x-slug-:slug*', // Matched parameters can be used in the key\n            value: 'my other custom header value',\n          },\n        ],\n      },\n    ]\n  },\n}\nRegex Path Matching\n\nTo match a regex path you can wrap the regex in parenthesis after a parameter, for example /blog/:slug(\\\\d{1,}) will match /blog/123 but not /blog/abc:\n\nnext.config.js\nmodule.exports = {\n  async headers() {\n    return [\n      {\n        source: '/blog/:post(\\\\d{1,})',\n        headers: [\n          {\n            key: 'x-post',\n            value: ':post',\n          },\n        ],\n      },\n    ]\n  },\n}\n\nThe following characters (, ), {, }, :, *, +, ? are used for regex path matching, so when used in the source as non-special values they must be escaped by adding \\\\ before them:\n\nnext.config.js\nmodule.exports = {\n  async headers() {\n    return [\n      {\n        // this will match `/english(default)/something` being requested\n        source: '/english\\\\(default\\\\)/:slug',\n        headers: [\n          {\n            key: 'x-header',\n            value: 'value',\n          },\n        ],\n      },\n    ]\n  },\n}\nHeader, Cookie, and Query Matching\n\nTo only apply a header when header, cookie, or query values also match the has field or don't match the missing field can be used. Both the source and all has items must match and all missing items must not match for the header to be applied.\n\nhas and missing items can have the following fields:\n\ntype: String - must be either header, cookie, host, or query.\nkey: String - the key from the selected type to match against.\nvalue: String or undefined - the value to check for, if undefined any value will match. A regex like string can be used to capture a specific part of the value, e.g. if the value first-(?<paramName>.*) is used for first-second then second will be usable in the destination with :paramName.\nnext.config.js\nmodule.exports = {\n  async headers() {\n    return [\n      // if the header `x-add-header` is present,\n      // the `x-another-header` header will be applied\n      {\n        source: '/:path*',\n        has: [\n          {\n            type: 'header',\n            key: 'x-add-header',\n          },\n        ],\n        headers: [\n          {\n            key: 'x-another-header',\n            value: 'hello',\n          },\n        ],\n      },\n      // if the header `x-no-header` is not present,\n      // the `x-another-header` header will be applied\n      {\n        source: '/:path*',\n        missing: [\n          {\n            type: 'header',\n            key: 'x-no-header',\n          },\n        ],\n        headers: [\n          {\n            key: 'x-another-header',\n            value: 'hello',\n          },\n        ],\n      },\n      // if the source, query, and cookie are matched,\n      // the `x-authorized` header will be applied\n      {\n        source: '/specific/:path*',\n        has: [\n          {\n            type: 'query',\n            key: 'page',\n            // the page value will not be available in the\n            // header key/values since value is provided and\n            // doesn't use a named capture group e.g. (?<page>home)\n            value: 'home',\n          },\n          {\n            type: 'cookie',\n            key: 'authorized',\n            value: 'true',\n          },\n        ],\n        headers: [\n          {\n            key: 'x-authorized',\n            value: ':authorized',\n          },\n        ],\n      },\n      // if the header `x-authorized` is present and\n      // contains a matching value, the `x-another-header` will be applied\n      {\n        source: '/:path*',\n        has: [\n          {\n            type: 'header',\n            key: 'x-authorized',\n            value: '(?<authorized>yes|true)',\n          },\n        ],\n        headers: [\n          {\n            key: 'x-another-header',\n            value: ':authorized',\n          },\n        ],\n      },\n      // if the host is `example.com`,\n      // this header will be applied\n      {\n        source: '/:path*',\n        has: [\n          {\n            type: 'host',\n            value: 'example.com',\n          },\n        ],\n        headers: [\n          {\n            key: 'x-another-header',\n            value: ':authorized',\n          },\n        ],\n      },\n    ]\n  },\n}\nHeaders with basePath support\n\nWhen leveraging basePath support with headers each source is automatically prefixed with the basePath unless you add basePath: false to the header:\n\nnext.config.js\nmodule.exports = {\n  basePath: '/docs',\n \n  async headers() {\n    return [\n      {\n        source: '/with-basePath', // becomes /docs/with-basePath\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'world',\n          },\n        ],\n      },\n      {\n        source: '/without-basePath', // is not modified since basePath: false is set\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'world',\n          },\n        ],\n        basePath: false,\n      },\n    ]\n  },\n}\nHeaders with i18n support\n\nWhen leveraging i18n support with headers each source is automatically prefixed to handle the configured locales unless you add locale: false to the header. If locale: false is used you must prefix the source with a locale for it to be matched correctly.\n\nnext.config.js\nmodule.exports = {\n  i18n: {\n    locales: ['en', 'fr', 'de'],\n    defaultLocale: 'en',\n  },\n \n  async headers() {\n    return [\n      {\n        source: '/with-locale', // automatically handles all locales\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'world',\n          },\n        ],\n      },\n      {\n        // does not handle locales automatically since locale: false is set\n        source: '/nl/with-locale-manual',\n        locale: false,\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'world',\n          },\n        ],\n      },\n      {\n        // this matches '/' since `en` is the defaultLocale\n        source: '/en',\n        locale: false,\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'world',\n          },\n        ],\n      },\n      {\n        // this gets converted to /(en|fr|de)/(.*) so will not match the top-level\n        // `/` or `/fr` routes like /:path* would\n        source: '/(.*)',\n        headers: [\n          {\n            key: 'x-hello',\n            value: 'world',\n          },\n        ],\n      },\n    ]\n  },\n}\nCache-Control\n\nNext.js sets the Cache-Control header of public, max-age=31536000, immutable for truly immutable assets. It cannot be overridden. These immutable files contain a SHA-hash in the file name, so they can be safely cached indefinitely. For example, Static Image Imports. You cannot set Cache-Control headers in next.config.js for these assets.\n\nHowever, you can set Cache-Control headers for other responses or data.\n\nLearn more about caching with the App Router.\n\nOptions\nCORS\n\nCross-Origin Resource Sharing (CORS)\n is a security feature that allows you to control which sites can access your resources. You can set the Access-Control-Allow-Origin header to allow a specific origin to access your Route Handlers.\n\nasync headers() {\n    return [\n      {\n        source: \"/api/:path*\",\n        headers: [\n          {\n            key: \"Access-Control-Allow-Origin\",\n            value: \"*\", // Set your origin\n          },\n          {\n            key: \"Access-Control-Allow-Methods\",\n            value: \"GET, POST, PUT, DELETE, OPTIONS\",\n          },\n          {\n            key: \"Access-Control-Allow-Headers\",\n            value: \"Content-Type, Authorization\",\n          },\n        ],\n      },\n    ];\n  },\nX-DNS-Prefetch-Control\n\nThis header\n controls DNS prefetching, allowing browsers to proactively perform domain name resolution on external links, images, CSS, JavaScript, and more. This prefetching is performed in the background, so the DNS\n is more likely to be resolved by the time the referenced items are needed. This reduces latency when the user clicks a link.\n\n{\n  key: 'X-DNS-Prefetch-Control',\n  value: 'on'\n}\nStrict-Transport-Security\n\nThis header\n informs browsers it should only be accessed using HTTPS, instead of using HTTP. Using the configuration below, all present and future subdomains will use HTTPS for a max-age of 2 years. This blocks access to pages or subdomains that can only be served over HTTP.\n\n{\n  key: 'Strict-Transport-Security',\n  value: 'max-age=63072000; includeSubDomains; preload'\n}\nX-Frame-Options\n\nThis header\n indicates whether the site should be allowed to be displayed within an iframe. This can prevent against clickjacking attacks.\n\nThis header has been superseded by CSP's frame-ancestors option, which has better support in modern browsers (see Content Security Policy for configuration details).\n\n{\n  key: 'X-Frame-Options',\n  value: 'SAMEORIGIN'\n}\nPermissions-Policy\n\nThis header\n allows you to control which features and APIs can be used in the browser. It was previously named Feature-Policy.\n\n{\n  key: 'Permissions-Policy',\n  value: 'camera=(), microphone=(), geolocation=(), browsing-topics=()'\n}\nX-Content-Type-Options\n\nThis header\n prevents the browser from attempting to guess the type of content if the Content-Type header is not explicitly set. This can prevent XSS exploits for websites that allow users to upload and share files.\n\nFor example, a user trying to download an image, but having it treated as a different Content-Type like an executable, which could be malicious. This header also applies to downloading browser extensions. The only valid value for this header is nosniff.\n\n{\n  key: 'X-Content-Type-Options',\n  value: 'nosniff'\n}\nReferrer-Policy\n\nThis header\n controls how much information the browser includes when navigating from the current website (origin) to another.\n\n{\n  key: 'Referrer-Policy',\n  value: 'origin-when-cross-origin'\n}\nContent-Security-Policy\n\nLearn more about adding a Content Security Policy to your application.\n\nVersion History\nVersion\tChanges\nv13.3.0\tmissing added.\nv10.2.0\thas added.\nv9.5.0\tHeaders added.\nPrevious\ngenerateEtags\nNext\nhtmlLimitedBots\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: htmlLimitedBots | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/htmlLimitedBots",
    "html": "Configuration\nnext.config.js\nhtmlLimitedBots\nCopy page\nhtmlLimitedBots\n\nThe htmlLimitedBots config allows you to specify a list of user agents that should receive blocking metadata instead of streaming metadata.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst config: NextConfig = {\n  htmlLimitedBots: /MySpecialBot|MyAnotherSpecialBot|SimpleCrawler/,\n}\n \nexport default config\nDefault list\n\nNext.js includes a default list of HTML limited bots, including:\n\nGoogle crawlers (e.g. Mediapartners-Google, AdsBot-Google, Google-PageRenderer)\nBingbot\nTwitterbot\nSlackbot\n\nSee the full list here\n.\n\nSpecifying a htmlLimitedBots config will override the Next.js' default list. However, this is advanced behavior, and the default should be sufficient for most cases.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nconst config: NextConfig = {\n  htmlLimitedBots: /MySpecialBot|MyAnotherSpecialBot|SimpleCrawler/,\n}\n \nexport default config\nDisabling\n\nTo fully disable streaming metadata:\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst config: NextConfig = {\n  htmlLimitedBots: /.*/,\n}\n \nexport default config\nVersion History\nVersion\tChanges\n15.2.0\thtmlLimitedBots option introduced.\nPrevious\nheaders\nNext\nhttpAgentOptions\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: httpAgentOptions | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/httpAgentOptions",
    "html": "Configuration\nnext.config.js\nhttpAgentOptions\nCopy page\nhttpAgentOptions\n\nIn Node.js versions prior to 18, Next.js automatically polyfills fetch() with undici and enables HTTP Keep-Alive\n by default.\n\nTo disable HTTP Keep-Alive for all fetch() calls on the server-side, open next.config.js and add the httpAgentOptions config:\n\nnext.config.js\nmodule.exports = {\n  httpAgentOptions: {\n    keepAlive: false,\n  },\n}\nPrevious\nhtmlLimitedBots\nNext\nimages\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: images | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/images",
    "html": "Configuration\nnext.config.js\nimages\nCopy page\nimages\n\nIf you want to use a cloud provider to optimize images instead of using the Next.js built-in Image Optimization API, you can configure next.config.js with the following:\n\nnext.config.js\nmodule.exports = {\n  images: {\n    loader: 'custom',\n    loaderFile: './my/image/loader.js',\n  },\n}\n\nThis loaderFile must point to a file relative to the root of your Next.js application. The file must export a default function that returns a string, for example:\n\nmy/image/loader.js\n'use client'\n \nexport default function myImageLoader({ src, width, quality }) {\n  return `https://example.com/${src}?w=${width}&q=${quality || 75}`\n}\n\nAlternatively, you can use the loader prop to pass the function to each instance of next/image.\n\nGood to know: Customizing the image loader file, which accepts a function, requires using Client Components to serialize the provided function.\n\nTo learn more about configuring the behavior of the built-in Image Optimization API and the Image Component, see Image Configuration Options for available options.\n\nExample Loader Configuration\nAkamai\nAWS CloudFront\nCloudinary\nCloudflare\nContentful\nFastly\nGumlet\nImageEngine\nImgix\nPixelBin\nSanity\nSirv\nSupabase\nThumbor\nImagekit\nNitrogen AIO\nAkamai\n// Docs: https://techdocs.akamai.com/ivm/reference/test-images-on-demand\nexport default function akamaiLoader({ src, width, quality }) {\n  return `https://example.com/${src}?imwidth=${width}`\n}\nAWS CloudFront\n// Docs: https://aws.amazon.com/developer/application-security-performance/articles/image-optimization\nexport default function cloudfrontLoader({ src, width, quality }) {\n  const url = new URL(`https://example.com${src}`)\n  url.searchParams.set('format', 'auto')\n  url.searchParams.set('width', width.toString())\n  url.searchParams.set('quality', (quality || 75).toString())\n  return url.href\n}\nCloudinary\n// Demo: https://res.cloudinary.com/demo/image/upload/w_300,c_limit,q_auto/turtles.jpg\nexport default function cloudinaryLoader({ src, width, quality }) {\n  const params = ['f_auto', 'c_limit', `w_${width}`, `q_${quality || 'auto'}`]\n  return `https://example.com/${params.join(',')}${src}`\n}\nCloudflare\n// Docs: https://developers.cloudflare.com/images/transform-images\nexport default function cloudflareLoader({ src, width, quality }) {\n  const params = [`width=${width}`, `quality=${quality || 75}`, 'format=auto']\n  return `https://example.com/cdn-cgi/image/${params.join(',')}/${src}`\n}\nContentful\n// Docs: https://www.contentful.com/developers/docs/references/images-api/\nexport default function contentfulLoader({ src, width, quality }) {\n  const url = new URL(`https://example.com${src}`)\n  url.searchParams.set('fm', 'webp')\n  url.searchParams.set('w', width.toString())\n  url.searchParams.set('q', (quality || 75).toString())\n  return url.href\n}\nFastly\n// Docs: https://developer.fastly.com/reference/io/\nexport default function fastlyLoader({ src, width, quality }) {\n  const url = new URL(`https://example.com${src}`)\n  url.searchParams.set('auto', 'webp')\n  url.searchParams.set('width', width.toString())\n  url.searchParams.set('quality', (quality || 75).toString())\n  return url.href\n}\nGumlet\n// Docs: https://docs.gumlet.com/reference/image-transform-size\nexport default function gumletLoader({ src, width, quality }) {\n  const url = new URL(`https://example.com${src}`)\n  url.searchParams.set('format', 'auto')\n  url.searchParams.set('w', width.toString())\n  url.searchParams.set('q', (quality || 75).toString())\n  return url.href\n}\nImageEngine\n// Docs: https://support.imageengine.io/hc/en-us/articles/360058880672-Directives\nexport default function imageengineLoader({ src, width, quality }) {\n  const compression = 100 - (quality || 50)\n  const params = [`w_${width}`, `cmpr_${compression}`)]\n  return `https://example.com${src}?imgeng=/${params.join('/')`\n}\nImgix\n// Demo: https://static.imgix.net/daisy.png?format=auto&fit=max&w=300\nexport default function imgixLoader({ src, width, quality }) {\n  const url = new URL(`https://example.com${src}`)\n  const params = url.searchParams\n  params.set('auto', params.getAll('auto').join(',') || 'format')\n  params.set('fit', params.get('fit') || 'max')\n  params.set('w', params.get('w') || width.toString())\n  params.set('q', (quality || 50).toString())\n  return url.href\n}\nPixelBin\n// Doc (Resize): https://www.pixelbin.io/docs/transformations/basic/resize/#width-w\n// Doc (Optimise): https://www.pixelbin.io/docs/optimizations/quality/#image-quality-when-delivering\n// Doc (Auto Format Delivery): https://www.pixelbin.io/docs/optimizations/format/#automatic-format-selection-with-f_auto-url-parameter\nexport default function pixelBinLoader({ src, width, quality }) {\n  const name = '<your-cloud-name>'\n  const opt = `t.resize(w:${width})~t.compress(q:${quality || 75})`\n  return `https://cdn.pixelbin.io/v2/${name}/${opt}/${src}?f_auto=true`\n}\nSanity\n// Docs: https://www.sanity.io/docs/image-urls\nexport default function sanityLoader({ src, width, quality }) {\n  const prj = 'zp7mbokg'\n  const dataset = 'production'\n  const url = new URL(`https://cdn.sanity.io/images/${prj}/${dataset}${src}`)\n  url.searchParams.set('auto', 'format')\n  url.searchParams.set('fit', 'max')\n  url.searchParams.set('w', width.toString())\n  if (quality) {\n    url.searchParams.set('q', quality.toString())\n  }\n  return url.href\n}\nSirv\n// Docs: https://sirv.com/help/articles/dynamic-imaging/\nexport default function sirvLoader({ src, width, quality }) {\n  const url = new URL(`https://example.com${src}`)\n  const params = url.searchParams\n  params.set('format', params.getAll('format').join(',') || 'optimal')\n  params.set('w', params.get('w') || width.toString())\n  params.set('q', (quality || 85).toString())\n  return url.href\n}\nSupabase\n// Docs: https://supabase.com/docs/guides/storage/image-transformations#nextjs-loader\nexport default function supabaseLoader({ src, width, quality }) {\n  const url = new URL(`https://example.com${src}`)\n  url.searchParams.set('width', width.toString())\n  url.searchParams.set('quality', (quality || 75).toString())\n  return url.href\n}\nThumbor\n// Docs: https://thumbor.readthedocs.io/en/latest/\nexport default function thumborLoader({ src, width, quality }) {\n  const params = [`${width}x0`, `filters:quality(${quality || 75})`]\n  return `https://example.com${params.join('/')}${src}`\n}\nImageKit.io\n// Docs: https://imagekit.io/docs/image-transformation\nexport default function imageKitLoader({ src, width, quality }) {\n  const params = [`w-${width}`, `q-${quality || 80}`]\n  return `https://ik.imagekit.io/your_imagekit_id/${src}?tr=${params.join(',')}`\n}\nNitrogen AIO\n// Docs: https://docs.n7.io/aio/intergrations/\nexport default function aioLoader({ src, width, quality }) {\n  const url = new URL(src, window.location.href)\n  const params = url.searchParams\n  const aioParams = params.getAll('aio')\n  aioParams.push(`w-${width}`)\n  if (quality) {\n    aioParams.push(`q-${quality.toString()}`)\n  }\n  params.set('aio', aioParams.join(';'))\n  return url.href\n}\nPrevious\nhttpAgentOptions\nNext\ncacheHandler\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: cacheHandler | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/incrementalCacheHandlerPath",
    "html": "Configuration\nnext.config.js\ncacheHandler\nCopy page\nCustom Next.js Cache Handler\n\nYou can configure the Next.js cache location if you want to persist cached pages and data to durable storage, or share the cache across multiple containers or instances of your Next.js application.\n\nGood to know: The cacheHandler configuration is specifically used by Next.js for server cache operations such as storing and revalidating ISR and route handler responses. It is not used by 'use cache', 'use cache: remote', nor 'use cache: private', which manage their own cache independently.\n\nnext.config.js\nmodule.exports = {\n  cacheHandler: require.resolve('./cache-handler.js'),\n  cacheMaxMemorySize: 0, // disable default in-memory caching\n}\n\nView an example of a custom cache handler and learn more about the implementation.\n\nAPI Reference\n\nThe cache handler can implement the following methods: get, set, revalidateTag, and resetRequestCache.\n\nget()\nParameter\tType\tDescription\nkey\tstring\tThe key to the cached value.\n\nReturns the cached value or null if not found.\n\nset()\nParameter\tType\tDescription\nkey\tstring\tThe key to store the data under.\ndata\tData or null\tThe data to be cached.\nctx\t{ tags: [] }\tThe cache tags provided.\n\nReturns Promise<void>.\n\nrevalidateTag()\nParameter\tType\tDescription\ntag\tstring or string[]\tThe cache tags to revalidate.\n\nReturns Promise<void>. Learn more about revalidating data or the revalidateTag() function.\n\nresetRequestCache()\n\nThis method resets the temporary in-memory cache for a single request before the next request.\n\nReturns void.\n\nGood to know:\n\nrevalidatePath is a convenience layer on top of cache tags. Calling revalidatePath will call your revalidateTag function, which you can then choose if you want to tag cache keys based on the path.\nPlatform Support\nDeployment Option\tSupported\nNode.js server\tYes\nDocker container\tYes\nStatic export\tNo\nAdapters\tPlatform-specific\n\nLearn how to configure ISR when self-hosting Next.js.\n\nVersion History\nVersion\tChanges\nv14.1.0\tRenamed to cacheHandler and became stable.\nv13.4.0\tincrementalCacheHandlerPath support for revalidateTag.\nv13.4.0\tincrementalCacheHandlerPath support for standalone output.\nv12.2.0\tExperimental incrementalCacheHandlerPath added.\nPrevious\nimages\nNext\ninlineCss\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: inlineCss | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/inlineCss",
    "html": "Configuration\nnext.config.js\ninlineCss\nCopy page\ninlineCss\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\nUsage\n\nExperimental support for inlining CSS in the <head>. When this flag is enabled, all places where we normally generate a <link> tag will instead have a generated <style> tag.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    inlineCss: true,\n  },\n}\n \nexport default nextConfig\nTrade-Offs\nWhen to Use Inline CSS\n\nInlining CSS can be beneficial in several scenarios:\n\nFirst-Time Visitors: Since CSS files are render-blocking resources, inlining eliminates the initial download delay that first-time visitors experience, improving page load performance.\n\nPerformance Metrics: By removing the additional network requests for CSS files, inlining can significantly improve key metrics like First Contentful Paint (FCP) and Largest Contentful Paint (LCP).\n\nSlow Connections: For users on slower networks where each request adds considerable latency, inlining CSS can provide a noticeable performance boost by reducing network roundtrips.\n\nAtomic CSS Bundles (e.g., Tailwind): With utility-first frameworks like Tailwind CSS, the size of the styles required for a page is often O(1) relative to the complexity of the design. This makes inlining a compelling choice because the entire set of styles for the current page is lightweight and doesn’t grow with the page size. Inlining Tailwind styles ensures minimal payload and eliminates the need for additional network requests, which can further enhance performance.\n\nWhen Not to Use Inline CSS\n\nWhile inlining CSS offers significant benefits for performance, there are scenarios where it may not be the best choice:\n\nLarge CSS Bundles: If your CSS bundle is too large, inlining it may significantly increase the size of the HTML, resulting in slower Time to First Byte (TTFB) and potentially worse performance for users with slow connections.\n\nDynamic or Page-Specific CSS: For applications with highly dynamic styles or pages that use different sets of CSS, inlining may lead to redundancy and bloat, as the full CSS for all pages may need to be inlined repeatedly.\n\nBrowser Caching: In cases where visitors frequently return to your site, external CSS files allow browsers to cache styles efficiently, reducing data transfer for subsequent visits. Inlining CSS eliminates this benefit.\n\nEvaluate these trade-offs carefully, and consider combining inlining with other strategies, such as critical CSS extraction or a hybrid approach, for the best results tailored to your site's needs.\n\nGood to know:\n\nThis feature is currently experimental and has some known limitations:\n\nCSS inlining is applied globally and cannot be configured on a per-page basis\nStyles are duplicated during initial page load - once within <style> tags for SSR and once in the RSC payload\nWhen navigating to statically rendered pages, styles will use <link> tags instead of inline CSS to avoid duplication\nThis feature is not available in development mode and only works in production builds\nPrevious\ncacheHandler\nNext\nisolatedDevBuild\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: isolatedDevBuild | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/isolatedDevBuild",
    "html": "Configuration\nnext.config.js\nisolatedDevBuild\nCopy page\nisolatedDevBuild\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe experimental isolatedDevBuild option separates development and production build outputs into different directories. When enabled, the development server (next dev) writes its output to .next/dev instead of .next, preventing conflicts when running next dev and next build concurrently.\n\nThis is especially helpful when automated tools (for example, AI agents) run next build to validate changes while your development server is running, ensuring the dev server is not affected by changes made by the build process.\n\nThis feature is enabled by default to keep development and production outputs separate and prevent conflicts.\n\nConfiguration\n\nTo opt out of this feature, set isolatedDevBuild to false in your configuration:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    isolatedDevBuild: false, // defaults to true\n  },\n}\n \nexport default nextConfig\nVersion History\nVersion\tChanges\nv16.0.0\texperimental.isolatedDevBuild is introduced.\nPrevious\ninlineCss\nNext\nlogging\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: logging | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/logging",
    "html": "Configuration\nnext.config.js\nlogging\nCopy page\nlogging\nOptions\nFetching\n\nYou can configure the logging level and whether the full URL is logged to the console when running Next.js in development mode.\n\nCurrently, logging only applies to data fetching using the fetch API. It does not yet apply to other logs inside of Next.js.\n\nnext.config.js\nmodule.exports = {\n  logging: {\n    fetches: {\n      fullUrl: true,\n    },\n  },\n}\n\nAny fetch requests that are restored from the Server Components HMR cache are not logged by default. However, this can be enabled by setting logging.fetches.hmrRefreshes to true.\n\nnext.config.js\nmodule.exports = {\n  logging: {\n    fetches: {\n      hmrRefreshes: true,\n    },\n  },\n}\nIncoming Requests\n\nBy default all the incoming requests will be logged in the console during development. You can use the incomingRequests option to decide which requests to ignore. Since this is only logged in development, this option doesn't affect production builds.\n\nnext.config.js\nmodule.exports = {\n  logging: {\n    incomingRequests: {\n      ignore: [/\\api\\/v1\\/health/],\n    },\n  },\n}\n\nOr you can disable incoming request logging by setting incomingRequests to false.\n\nnext.config.js\nmodule.exports = {\n  logging: {\n    incomingRequests: false,\n  },\n}\nDisabling Logging\n\nIn addition, you can disable the development logging by setting logging to false.\n\nnext.config.js\nmodule.exports = {\n  logging: false,\n}\nPrevious\nisolatedDevBuild\nNext\nmdxRs\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: mdxRs | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/mdxRs",
    "html": "Configuration\nnext.config.js\nmdxRs\nCopy page\nmdxRs\n\nFor experimental use with @next/mdx. Compiles MDX files using the new Rust compiler.\n\nnext.config.js\nconst withMDX = require('@next/mdx')()\n \n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  pageExtensions: ['ts', 'tsx', 'mdx'],\n  experimental: {\n    mdxRs: true,\n  },\n}\n \nmodule.exports = withMDX(nextConfig)\nPrevious\nlogging\nNext\nonDemandEntries\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: onDemandEntries | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/onDemandEntries",
    "html": "Configuration\nnext.config.js\nonDemandEntries\nCopy page\nonDemandEntries\n\nNext.js exposes some options that give you some control over how the server will dispose or keep in memory built pages in development.\n\nTo change the defaults, open next.config.js and add the onDemandEntries config:\n\nnext.config.js\nmodule.exports = {\n  onDemandEntries: {\n    // period (in ms) where the server will keep pages in the buffer\n    maxInactiveAge: 25 * 1000,\n    // number of pages that should be kept simultaneously without being disposed\n    pagesBufferLength: 2,\n  },\n}\nPrevious\nmdxRs\nNext\noptimizePackageImports\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: optimizePackageImports | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/optimizePackageImports",
    "html": "Configuration\nnext.config.js\noptimizePackageImports\nCopy page\noptimizePackageImports\n\nSome packages can export hundreds or thousands of modules, which can cause performance issues in development and production.\n\nAdding a package to experimental.optimizePackageImports will only load the modules you are actually using, while still giving you the convenience of writing import statements with many named exports.\n\nnext.config.js\nmodule.exports = {\n  experimental: {\n    optimizePackageImports: ['package-name'],\n  },\n}\n\nThe following libraries are optimized by default:\n\nlucide-react\ndate-fns\nlodash-es\nramda\nantd\nreact-bootstrap\nahooks\n@ant-design/icons\n@headlessui/react\n@headlessui-float/react\n@heroicons/react/20/solid\n@heroicons/react/24/solid\n@heroicons/react/24/outline\n@visx/visx\n@tremor/react\nrxjs\n@mui/material\n@mui/icons-material\nrecharts\nreact-use\n@material-ui/core\n@material-ui/icons\n@tabler/icons-react\nmui-core\nreact-icons/*\neffect\n@effect/*\nPrevious\nonDemandEntries\nNext\noutput\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: output | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/output",
    "html": "Configuration\nnext.config.js\noutput\nCopy page\noutput\n\nDuring a build, Next.js will automatically trace each page and its dependencies to determine all of the files that are needed for deploying a production version of your application.\n\nThis feature helps reduce the size of deployments drastically. Previously, when deploying with Docker you would need to have all files from your package's dependencies installed to run next start. Starting with Next.js 12, you can leverage Output File Tracing in the .next/ directory to only include the necessary files.\n\nFurthermore, this removes the need for the deprecated serverless target which can cause various issues and also creates unnecessary duplication.\n\nHow it Works\n\nDuring next build, Next.js will use @vercel/nft\n to statically analyze import, require, and fs usage to determine all files that a page might load.\n\nNext.js' production server is also traced for its needed files and output at .next/next-server.js.nft.json which can be leveraged in production.\n\nTo leverage the .nft.json files emitted to the .next output directory, you can read the list of files in each trace that are relative to the .nft.json file and then copy them to your deployment location.\n\nAutomatically Copying Traced Files\n\nNext.js can automatically create a standalone folder that copies only the necessary files for a production deployment including select files in node_modules.\n\nTo leverage this automatic copying you can enable it in your next.config.js:\n\nnext.config.js\nmodule.exports = {\n  output: 'standalone',\n}\n\nThis will create a folder at .next/standalone which can then be deployed on its own without installing node_modules.\n\nAdditionally, a minimal server.js file is also output which can be used instead of next start. This minimal server does not copy the public or .next/static folders by default as these should ideally be handled by a CDN instead, although these folders can be copied to the standalone/public and standalone/.next/static folders manually, after which server.js file will serve these automatically.\n\nTo copy these manually, you can use the cp command-line tool after you next build:\n\nTerminal\ncp -r public .next/standalone/ && cp -r .next/static .next/standalone/.next/\n\nTo start your minimal server.js file locally, run the following command:\n\nTerminal\nnode .next/standalone/server.js\n\nGood to know:\n\nIf your project needs to listen to a specific port or hostname, you can define PORT or HOSTNAME environment variables before running server.js. For example, run PORT=8080 HOSTNAME=0.0.0.0 node server.js to start the server on http://0.0.0.0:8080.\nCaveats\nWhile tracing in monorepo setups, the project directory is used for tracing by default. For next build packages/web-app, packages/web-app would be the tracing root and any files outside of that folder will not be included. To include files outside of this folder you can set outputFileTracingRoot in your next.config.js.\npackages/web-app/next.config.js\nconst path = require('path')\n \nmodule.exports = {\n  // this includes files from the monorepo base two directories up\n  outputFileTracingRoot: path.join(__dirname, '../../'),\n}\nThere are some cases in which Next.js might fail to include required files, or might incorrectly include unused files. In those cases, you can leverage outputFileTracingExcludes and outputFileTracingIncludes respectively in next.config.js. Each option accepts an object whose keys are route globs (matched with picomatch\n against the route path, e.g. /api/hello) and whose values are glob patterns resolved from the project root that specify files to include or exclude in the trace.\n\nGood to know: In a monorepo, project root refers to the Next.js project root (the folder containing next.config.js, e.g., packages/web-app), not necessarily the monorepo root.\n\nnext.config.js\nmodule.exports = {\n  outputFileTracingExcludes: {\n    '/api/hello': ['./un-necessary-folder/**/*'],\n  },\n  outputFileTracingIncludes: {\n    '/api/another': ['./necessary-folder/**/*'],\n    '/api/login/\\\\[\\\\[\\\\.\\\\.\\\\.slug\\\\]\\\\]': [\n      './node_modules/aws-crt/dist/bin/**/*',\n    ],\n  },\n}\n\nUsing a src/ directory does not change how you write these options:\n\nKeys still match the route path ('/api/hello', '/products/[id]', etc.).\nValues can reference paths under src/ since they are resolved relative to the project root.\nnext.config.js\nmodule.exports = {\n  outputFileTracingIncludes: {\n    '/products/*': ['src/lib/payments/**/*'],\n    '/*': ['src/config/runtime/**/*.json'],\n  },\n  outputFileTracingExcludes: {\n    '/api/*': ['src/temp/**/*', 'public/large-logs/**/*'],\n  },\n}\n\nYou can also target all routes using a global key like '/*':\n\nnext.config.js\nmodule.exports = {\n  outputFileTracingIncludes: {\n    '/*': ['src/i18n/locales/**/*.json'],\n  },\n}\n\nThese options are applied to server traces and do not affect routes that do not produce a server trace file:\n\nEdge Runtime routes are not affected.\nFully static pages are not affected.\n\nIn monorepos or when you need to include files outside the app folder, combine outputFileTracingRoot with includes:\n\nnext.config.js\nconst path = require('path')\n \nmodule.exports = {\n  // Trace from the monorepo root\n  outputFileTracingRoot: path.join(__dirname, '../../'),\n  outputFileTracingIncludes: {\n    '/route1': ['../shared/assets/**/*'],\n  },\n}\n\nGood to know:\n\nPrefer forward slashes (/) in patterns for cross-platform compatibility.\nKeep patterns as narrow as possible to avoid oversized traces (avoid **/* at the repo root).\n\nCommon include patterns for native/runtime assets:\n\nnext.config.js\nmodule.exports = {\n  outputFileTracingIncludes: {\n    '/*': ['node_modules/sharp/**/*', 'node_modules/aws-crt/dist/bin/**/*'],\n  },\n}\nPrevious\noptimizePackageImports\nNext\npageExtensions\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: pageExtensions | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/pageExtensions",
    "html": "Configuration\nnext.config.js\npageExtensions\nCopy page\npageExtensions\n\nBy default, Next.js accepts files with the following extensions: .tsx, .ts, .jsx, .js. This can be modified to allow other extensions like markdown (.md, .mdx).\n\nnext.config.js\nconst withMDX = require('@next/mdx')()\n \n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  pageExtensions: ['js', 'jsx', 'ts', 'tsx', 'md', 'mdx'],\n}\n \nmodule.exports = withMDX(nextConfig)\nPrevious\noutput\nNext\npoweredByHeader\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: poweredByHeader | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/poweredByHeader",
    "html": "Configuration\nnext.config.js\npoweredByHeader\nCopy page\npoweredByHeader\n\nBy default Next.js will add the x-powered-by header. To opt-out of it, open next.config.js and disable the poweredByHeader config:\n\nnext.config.js\nmodule.exports = {\n  poweredByHeader: false,\n}\nPrevious\npageExtensions\nNext\nproductionBrowserSourceMaps\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: productionBrowserSourceMaps | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/productionBrowserSourceMaps",
    "html": "Configuration\nnext.config.js\nproductionBrowserSourceMaps\nCopy page\nproductionBrowserSourceMaps\n\nSource Maps are enabled by default during development. During production builds, they are disabled to prevent you leaking your source on the client, unless you specifically opt-in with the configuration flag.\n\nNext.js provides a configuration flag you can use to enable browser source map generation during the production build:\n\nnext.config.js\nmodule.exports = {\n  productionBrowserSourceMaps: true,\n}\n\nWhen the productionBrowserSourceMaps option is enabled, the source maps will be output in the same directory as the JavaScript files. Next.js will automatically serve these files when requested.\n\nAdding source maps can increase next build time\nIncreases memory usage during next build\nPrevious\npoweredByHeader\nNext\nproxyClientMaxBodySize\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: proxyClientMaxBodySize | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/proxyClientMaxBodySize",
    "html": "Configuration\nnext.config.js\nproxyClientMaxBodySize\nCopy page\nproxyClientMaxBodySize\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nWhen proxy is used, Next.js automatically clones the request body and buffers it in memory to enable multiple reads - both in proxy and the underlying route handler. To prevent excessive memory usage, this configuration option sets a size limit on the buffered body.\n\nBy default, the maximum body size is 10MB. If a request body exceeds this limit, the body will only be buffered up to the limit, and a warning will be logged indicating which route exceeded the limit.\n\nOptions\nString format (recommended)\n\nSpecify the size using a human-readable string format:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    proxyClientMaxBodySize: '1mb',\n  },\n}\n \nexport default nextConfig\n\nSupported units: b, kb, mb, gb\n\nNumber format\n\nAlternatively, specify the size in bytes as a number:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    proxyClientMaxBodySize: 1048576, // 1MB in bytes\n  },\n}\n \nexport default nextConfig\nBehavior\n\nWhen a request body exceeds the configured limit:\n\nNext.js will buffer only the first N bytes (up to the limit)\nA warning will be logged to the console indicating the route that exceeded the limit\nThe request will continue processing normally, but only the partial body will be available\nThe request will not fail or return an error to the client\n\nIf your application needs to process the full request body, you should either:\n\nIncrease the proxyClientMaxBodySize limit\nHandle the partial body gracefully in your application logic\nExample\nproxy.ts\nimport { NextRequest, NextResponse } from 'next/server'\n \nexport async function proxy(request: NextRequest) {\n  // Next.js automatically buffers the body with the configured size limit\n  // You can read the body in proxy...\n  const body = await request.text()\n \n  // If the body exceeded the limit, only partial data will be available\n  console.log('Body size:', body.length)\n \n  return NextResponse.next()\n}\napp/api/upload/route.ts\nimport { NextRequest, NextResponse } from 'next/server'\n \nexport async function POST(request: NextRequest) {\n  // ...and the body is still available in your route handler\n  const body = await request.text()\n \n  console.log('Body in route handler:', body.length)\n \n  return NextResponse.json({ received: body.length })\n}\nGood to know\nThis setting only applies when proxy is used in your application\nThe default limit of 10MB is designed to balance memory usage and typical use cases\nThe limit applies per-request, not globally across all concurrent requests\nFor applications handling large file uploads, consider increasing the limit accordingly\nPrevious\nproductionBrowserSourceMaps\nNext\nreactCompiler\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: reactCompiler | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/reactCompiler",
    "html": "Configuration\nnext.config.js\nreactCompiler\nCopy page\nreactCompiler\n\nNext.js includes support for the React Compiler\n, a tool designed to improve performance by automatically optimizing component rendering. This reduces the need for manual memoization using useMemo and useCallback.\n\nNext.js includes a custom performance optimization written in SWC that makes the React Compiler more efficient. Instead of running the compiler on every file, Next.js analyzes your project and only applies the React Compiler to relevant files. This avoids unnecessary work and leads to faster builds compared to using the Babel plugin on its own.\n\nHow It Works\n\nThe React Compiler runs through a Babel plugin. To keep builds fast, Next.js uses a custom SWC optimization that only applies the React Compiler to relevant files—like those with JSX or React Hooks.\n\nThis avoids compiling everything and keeps the performance cost minimal. You may still see slightly slower builds compared to the default Rust-based compiler, but the impact is small and localized.\n\nTo use it, install the babel-plugin-react-compiler:\n\nTerminal\nnpm install -D babel-plugin-react-compiler\n\nThen, add reactCompiler option in next.config.js:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  reactCompiler: true,\n}\n \nexport default nextConfig\nAnnotations\n\nYou can configure the compiler to run in \"opt-in\" mode as follows:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  reactCompiler: {\n    compilationMode: 'annotation',\n  },\n}\n \nexport default nextConfig\n\nThen, you can annotate specific components or hooks with the \"use memo\" directive from React to opt-in:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Page() {\n  'use memo'\n  // ...\n}\n\nNote: You can also use the \"use no memo\" directive from React for the opposite effect, to opt-out a component or hook.\n\nPrevious\nproxyClientMaxBodySize\nNext\nreactMaxHeadersLength\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: reactMaxHeadersLength | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/reactMaxHeadersLength",
    "html": "Configuration\nnext.config.js\nreactMaxHeadersLength\nCopy page\nreactMaxHeadersLength\n\nDuring static rendering, React can emit headers that can be added to the response. These can be used to improve performance by allowing the browser to preload resources like fonts, scripts, and stylesheets. The default value is 6000, but you can override this value by configuring the reactMaxHeadersLength option in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  reactMaxHeadersLength: 1000,\n}\n\nGood to know: This option is only available in App Router.\n\nDepending on the type of proxy between the browser and the server, the headers can be truncated. For example, if you are using a reverse proxy that doesn't support long headers, you should set a lower value to ensure that the headers are not truncated.\n\nPrevious\nreactCompiler\nNext\nreactStrictMode\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: reactStrictMode | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/reactStrictMode",
    "html": "Configuration\nnext.config.js\nreactStrictMode\nCopy page\nreactStrictMode\n\nGood to know: Since Next.js 13.5.1, Strict Mode is true by default with app router, so the above configuration is only necessary for pages. You can still disable Strict Mode by setting reactStrictMode: false.\n\nSuggested: We strongly suggest you enable Strict Mode in your Next.js application to better prepare your application for the future of React.\n\nReact's Strict Mode\n is a development mode only feature for highlighting potential problems in an application. It helps to identify unsafe lifecycles, legacy API usage, and a number of other features.\n\nThe Next.js runtime is Strict Mode-compliant. To opt-in to Strict Mode, configure the following option in your next.config.js:\n\nnext.config.js\nmodule.exports = {\n  reactStrictMode: true,\n}\n\nIf you or your team are not ready to use Strict Mode in your entire application, that's OK! You can incrementally migrate on a page-by-page basis using <React.StrictMode>.\n\nPrevious\nreactMaxHeadersLength\nNext\nredirects\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: redirects | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/redirects",
    "html": "Configuration\nnext.config.js\nredirects\nCopy page\nredirects\n\nRedirects allow you to redirect an incoming request path to a different destination path.\n\nTo use redirects you can use the redirects key in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      {\n        source: '/about',\n        destination: '/',\n        permanent: true,\n      },\n    ]\n  },\n}\n\nredirects is an async function that expects an array to be returned holding objects with source, destination, and permanent properties:\n\nsource is the incoming request path pattern.\ndestination is the path you want to route to.\npermanent true or false - if true will use the 308 status code which instructs clients/search engines to cache the redirect forever, if false will use the 307 status code which is temporary and is not cached.\n\nWhy does Next.js use 307 and 308? Traditionally a 302 was used for a temporary redirect, and a 301 for a permanent redirect, but many browsers changed the request method of the redirect to GET, regardless of the original method. For example, if the browser made a request to POST /v1/users which returned status code 302 with location /v2/users, the subsequent request might be GET /v2/users instead of the expected POST /v2/users. Next.js uses the 307 temporary redirect, and 308 permanent redirect status codes to explicitly preserve the request method used.\n\nbasePath: false or undefined - if false the basePath won't be included when matching, can be used for external redirects only.\nlocale: false or undefined - whether the locale should not be included when matching.\nhas is an array of has objects with the type, key and value properties.\nmissing is an array of missing objects with the type, key and value properties.\n\nRedirects are checked before the filesystem which includes pages and /public files.\n\nWhen using the Pages Router, redirects are not applied to client-side routing (Link, router.push) unless Proxy is present and matches the path.\n\nWhen a redirect is applied, any query values provided in the request will be passed through to the redirect destination. For example, see the following redirect configuration:\n\n{\n  source: '/old-blog/:path*',\n  destination: '/blog/:path*',\n  permanent: false\n}\n\nGood to know: Remember to include the forward slash / before the colon : in path parameters of the source and destination paths, otherwise the path will be treated as a literal string and you run the risk of causing infinite redirects.\n\nWhen /old-blog/post-1?hello=world is requested, the client will be redirected to /blog/post-1?hello=world.\n\nPath Matching\n\nPath matches are allowed, for example /old-blog/:slug will match /old-blog/hello-world (no nested paths):\n\nnext.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      {\n        source: '/old-blog/:slug',\n        destination: '/news/:slug', // Matched parameters can be used in the destination\n        permanent: true,\n      },\n    ]\n  },\n}\nWildcard Path Matching\n\nTo match a wildcard path you can use * after a parameter, for example /blog/:slug* will match /blog/a/b/c/d/hello-world:\n\nnext.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      {\n        source: '/blog/:slug*',\n        destination: '/news/:slug*', // Matched parameters can be used in the destination\n        permanent: true,\n      },\n    ]\n  },\n}\nRegex Path Matching\n\nTo match a regex path you can wrap the regex in parentheses after a parameter, for example /post/:slug(\\\\d{1,}) will match /post/123 but not /post/abc:\n\nnext.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      {\n        source: '/post/:slug(\\\\d{1,})',\n        destination: '/news/:slug', // Matched parameters can be used in the destination\n        permanent: false,\n      },\n    ]\n  },\n}\n\nThe following characters (, ), {, }, :, *, +, ? are used for regex path matching, so when used in the source as non-special values they must be escaped by adding \\\\ before them:\n\nnext.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      {\n        // this will match `/english(default)/something` being requested\n        source: '/english\\\\(default\\\\)/:slug',\n        destination: '/en-us/:slug',\n        permanent: false,\n      },\n    ]\n  },\n}\nHeader, Cookie, and Query Matching\n\nTo only match a redirect when header, cookie, or query values also match the has field or don't match the missing field can be used. Both the source and all has items must match and all missing items must not match for the redirect to be applied.\n\nhas and missing items can have the following fields:\n\ntype: String - must be either header, cookie, host, or query.\nkey: String - the key from the selected type to match against.\nvalue: String or undefined - the value to check for, if undefined any value will match. A regex like string can be used to capture a specific part of the value, e.g. if the value first-(?<paramName>.*) is used for first-second then second will be usable in the destination with :paramName.\nnext.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      // if the header `x-redirect-me` is present,\n      // this redirect will be applied\n      {\n        source: '/:path((?!another-page$).*)',\n        has: [\n          {\n            type: 'header',\n            key: 'x-redirect-me',\n          },\n        ],\n        permanent: false,\n        destination: '/another-page',\n      },\n      // if the header `x-dont-redirect` is present,\n      // this redirect will NOT be applied\n      {\n        source: '/:path((?!another-page$).*)',\n        missing: [\n          {\n            type: 'header',\n            key: 'x-do-not-redirect',\n          },\n        ],\n        permanent: false,\n        destination: '/another-page',\n      },\n      // if the source, query, and cookie are matched,\n      // this redirect will be applied\n      {\n        source: '/specific/:path*',\n        has: [\n          {\n            type: 'query',\n            key: 'page',\n            // the page value will not be available in the\n            // destination since value is provided and doesn't\n            // use a named capture group e.g. (?<page>home)\n            value: 'home',\n          },\n          {\n            type: 'cookie',\n            key: 'authorized',\n            value: 'true',\n          },\n        ],\n        permanent: false,\n        destination: '/another/:path*',\n      },\n      // if the header `x-authorized` is present and\n      // contains a matching value, this redirect will be applied\n      {\n        source: '/',\n        has: [\n          {\n            type: 'header',\n            key: 'x-authorized',\n            value: '(?<authorized>yes|true)',\n          },\n        ],\n        permanent: false,\n        destination: '/home?authorized=:authorized',\n      },\n      // if the host is `example.com`,\n      // this redirect will be applied\n      {\n        source: '/:path((?!another-page$).*)',\n        has: [\n          {\n            type: 'host',\n            value: 'example.com',\n          },\n        ],\n        permanent: false,\n        destination: '/another-page',\n      },\n    ]\n  },\n}\nRedirects with basePath support\n\nWhen leveraging basePath support with redirects each source and destination is automatically prefixed with the basePath unless you add basePath: false to the redirect:\n\nnext.config.js\nmodule.exports = {\n  basePath: '/docs',\n \n  async redirects() {\n    return [\n      {\n        source: '/with-basePath', // automatically becomes /docs/with-basePath\n        destination: '/another', // automatically becomes /docs/another\n        permanent: false,\n      },\n      {\n        // does not add /docs since basePath: false is set\n        source: '/without-basePath',\n        destination: 'https://example.com',\n        basePath: false,\n        permanent: false,\n      },\n    ]\n  },\n}\nRedirects with i18n support\n\nWhen implementing redirects with internationalization in the App Router, you can include locales in next.config.js redirects, but only as hardcoded paths.\n\nFor dynamic or per-request locale handling, use dynamic route segments and proxy, which can redirect based on the user's preferred language.\n\nnext.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      {\n        // Manually handle locale prefixes for App Router\n        source: '/en/old-path',\n        destination: '/en/new-path',\n        permanent: false,\n      },\n      {\n        // Redirect for all locales using a parameter\n        source: '/:locale/old-path',\n        destination: '/:locale/new-path',\n        permanent: false,\n      },\n      {\n        // Redirect from one locale to another\n        source: '/de/old-path',\n        destination: '/en/new-path',\n        permanent: false,\n      },\n      {\n        // Catch-all redirect for multiple locales\n        source: '/:locale(en|fr|de)/:path*',\n        destination: '/:locale/new-section/:path*',\n        permanent: false,\n      },\n    ]\n  },\n}\n\nIn some rare cases, you might need to assign a custom status code for older HTTP Clients to properly redirect. In these cases, you can use the statusCode property instead of the permanent property, but not both. To ensure IE11 compatibility, a Refresh header is automatically added for the 308 status code.\n\nOther Redirects\nInside API Routes and Route Handlers, you can redirect based on the incoming request.\nInside getStaticProps and getServerSideProps, you can redirect specific pages at request-time.\nVersion History\nVersion\tChanges\nv13.3.0\tmissing added.\nv10.2.0\thas added.\nv9.5.0\tredirects added.\nPrevious\nreactStrictMode\nNext\nrewrites\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: sassOptions | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/sassOptions",
    "html": "Configuration\nnext.config.js\nsassOptions\nCopy page\nsassOptions\n\nsassOptions allow you to configure the Sass compiler.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst sassOptions = {\n  additionalData: `\n    $var: red;\n  `,\n}\n \nconst nextConfig: NextConfig = {\n  sassOptions: {\n    ...sassOptions,\n    implementation: 'sass-embedded',\n  },\n}\n \nexport default nextConfig\n\nGood to know:\n\nsassOptions are not typed outside of implementation because Next.js does not maintain the other possible properties.\nThe functions property for defining custom Sass functions is only supported with webpack. When using Turbopack, custom Sass functions are not available because Turbopack's Rust-based architecture cannot directly execute JavaScript functions passed through this option.\nPrevious\nrewrites\nNext\nserverActions\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: rewrites | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/rewrites",
    "html": "Configuration\nnext.config.js\nrewrites\nCopy page\nrewrites\n\nRewrites allow you to map an incoming request path to a different destination path.\n\nRewrites act as a URL proxy and mask the destination path, making it appear the user hasn't changed their location on the site. In contrast, redirects will reroute to a new page and show the URL changes.\n\nTo use rewrites you can use the rewrites key in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/about',\n        destination: '/',\n      },\n    ]\n  },\n}\n\nRewrites are applied to client-side routing. In the example above, navigating to <Link href=\"/about\"> will serve content from / while keeping the URL as /about.\n\nrewrites is an async function that expects to return either an array or an object of arrays (see below) holding objects with source and destination properties:\n\nsource: String - is the incoming request path pattern.\ndestination: String is the path you want to route to.\nbasePath: false or undefined - if false the basePath won't be included when matching, can be used for external rewrites only.\nlocale: false or undefined - whether the locale should not be included when matching.\nhas is an array of has objects with the type, key and value properties.\nmissing is an array of missing objects with the type, key and value properties.\n\nWhen the rewrites function returns an array, rewrites are applied after checking the filesystem (pages and /public files) and before dynamic routes. When the rewrites function returns an object of arrays with a specific shape, this behavior can be changed and more finely controlled, as of v10.1 of Next.js:\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return {\n      beforeFiles: [\n        // These rewrites are checked after headers/redirects\n        // and before all files including _next/public files which\n        // allows overriding page files\n        {\n          source: '/some-page',\n          destination: '/somewhere-else',\n          has: [{ type: 'query', key: 'overrideMe' }],\n        },\n      ],\n      afterFiles: [\n        // These rewrites are checked after pages/public files\n        // are checked but before dynamic routes\n        {\n          source: '/non-existent',\n          destination: '/somewhere-else',\n        },\n      ],\n      fallback: [\n        // These rewrites are checked after both pages/public files\n        // and dynamic routes are checked\n        {\n          source: '/:path*',\n          destination: `https://my-old-site.com/:path*`,\n        },\n      ],\n    }\n  },\n}\n\nGood to know: rewrites in beforeFiles do not check the filesystem/dynamic routes immediately after matching a source, they continue until all beforeFiles have been checked.\n\nThe order Next.js routes are checked is:\n\nheaders are checked/applied\nredirects are checked/applied\nproxy\nbeforeFiles rewrites are checked/applied\nstatic files from the public directory, _next/static files, and non-dynamic pages are checked/served\nafterFiles rewrites are checked/applied, if one of these rewrites is matched we check dynamic routes/static files after each match\nfallback rewrites are checked/applied, these are applied before rendering the 404 page and after dynamic routes/all static assets have been checked. If you use fallback: true/'blocking' in getStaticPaths, the fallback rewrites defined in your next.config.js will not be run.\nRewrite parameters\n\nWhen using parameters in a rewrite the parameters will be passed in the query by default when none of the parameters are used in the destination.\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/old-about/:path*',\n        destination: '/about', // The :path parameter isn't used here so will be automatically passed in the query\n      },\n    ]\n  },\n}\n\nIf a parameter is used in the destination none of the parameters will be automatically passed in the query.\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/docs/:path*',\n        destination: '/:path*', // The :path parameter is used here so will not be automatically passed in the query\n      },\n    ]\n  },\n}\n\nYou can still pass the parameters manually in the query if one is already used in the destination by specifying the query in the destination.\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/:first/:second',\n        destination: '/:first?second=:second',\n        // Since the :first parameter is used in the destination the :second parameter\n        // will not automatically be added in the query although we can manually add it\n        // as shown above\n      },\n    ]\n  },\n}\n\nGood to know: Static pages from Automatic Static Optimization or prerendering params from rewrites will be parsed on the client after hydration and provided in the query.\n\nPath Matching\n\nPath matches are allowed, for example /blog/:slug will match /blog/hello-world (no nested paths):\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/blog/:slug',\n        destination: '/news/:slug', // Matched parameters can be used in the destination\n      },\n    ]\n  },\n}\nWildcard Path Matching\n\nTo match a wildcard path you can use * after a parameter, for example /blog/:slug* will match /blog/a/b/c/d/hello-world:\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/blog/:slug*',\n        destination: '/news/:slug*', // Matched parameters can be used in the destination\n      },\n    ]\n  },\n}\nRegex Path Matching\n\nTo match a regex path you can wrap the regex in parenthesis after a parameter, for example /blog/:slug(\\\\d{1,}) will match /blog/123 but not /blog/abc:\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/old-blog/:post(\\\\d{1,})',\n        destination: '/blog/:post', // Matched parameters can be used in the destination\n      },\n    ]\n  },\n}\n\nThe following characters (, ), {, }, [, ], |, \\, ^, ., :, *, +, -, ?, $ are used for regex path matching, so when used in the source as non-special values they must be escaped by adding \\\\ before them:\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        // this will match `/english(default)/something` being requested\n        source: '/english\\\\(default\\\\)/:slug',\n        destination: '/en-us/:slug',\n      },\n    ]\n  },\n}\nHeader, Cookie, and Query Matching\n\nTo only match a rewrite when header, cookie, or query values also match the has field or don't match the missing field can be used. Both the source and all has items must match and all missing items must not match for the rewrite to be applied.\n\nhas and missing items can have the following fields:\n\ntype: String - must be either header, cookie, host, or query.\nkey: String - the key from the selected type to match against.\nvalue: String or undefined - the value to check for, if undefined any value will match. A regex like string can be used to capture a specific part of the value, e.g. if the value first-(?<paramName>.*) is used for first-second then second will be usable in the destination with :paramName.\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      // if the header `x-rewrite-me` is present,\n      // this rewrite will be applied\n      {\n        source: '/:path*',\n        has: [\n          {\n            type: 'header',\n            key: 'x-rewrite-me',\n          },\n        ],\n        destination: '/another-page',\n      },\n      // if the header `x-rewrite-me` is not present,\n      // this rewrite will be applied\n      {\n        source: '/:path*',\n        missing: [\n          {\n            type: 'header',\n            key: 'x-rewrite-me',\n          },\n        ],\n        destination: '/another-page',\n      },\n      // if the source, query, and cookie are matched,\n      // this rewrite will be applied\n      {\n        source: '/specific/:path*',\n        has: [\n          {\n            type: 'query',\n            key: 'page',\n            // the page value will not be available in the\n            // destination since value is provided and doesn't\n            // use a named capture group e.g. (?<page>home)\n            value: 'home',\n          },\n          {\n            type: 'cookie',\n            key: 'authorized',\n            value: 'true',\n          },\n        ],\n        destination: '/:path*/home',\n      },\n      // if the header `x-authorized` is present and\n      // contains a matching value, this rewrite will be applied\n      {\n        source: '/:path*',\n        has: [\n          {\n            type: 'header',\n            key: 'x-authorized',\n            value: '(?<authorized>yes|true)',\n          },\n        ],\n        destination: '/home?authorized=:authorized',\n      },\n      // if the host is `example.com`,\n      // this rewrite will be applied\n      {\n        source: '/:path*',\n        has: [\n          {\n            type: 'host',\n            value: 'example.com',\n          },\n        ],\n        destination: '/another-page',\n      },\n    ]\n  },\n}\nRewriting to an external URL\nExamples\n\nRewrites allow you to rewrite to an external URL. This is especially useful for incrementally adopting Next.js. The following is an example rewrite for redirecting the /blog route of your main app to an external site.\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return [\n      {\n        source: '/blog',\n        destination: 'https://example.com/blog',\n      },\n      {\n        source: '/blog/:slug',\n        destination: 'https://example.com/blog/:slug', // Matched parameters can be used in the destination\n      },\n    ]\n  },\n}\n\nIf you're using trailingSlash: true, you also need to insert a trailing slash in the source parameter. If the destination server is also expecting a trailing slash it should be included in the destination parameter as well.\n\nnext.config.js\nmodule.exports = {\n  trailingSlash: true,\n  async rewrites() {\n    return [\n      {\n        source: '/blog/',\n        destination: 'https://example.com/blog/',\n      },\n      {\n        source: '/blog/:path*/',\n        destination: 'https://example.com/blog/:path*/',\n      },\n    ]\n  },\n}\nIncremental adoption of Next.js\n\nYou can also have Next.js fall back to proxying to an existing website after checking all Next.js routes.\n\nThis way you don't have to change the rewrites configuration when migrating more pages to Next.js\n\nnext.config.js\nmodule.exports = {\n  async rewrites() {\n    return {\n      fallback: [\n        {\n          source: '/:path*',\n          destination: `https://custom-routes-proxying-endpoint.vercel.app/:path*`,\n        },\n      ],\n    }\n  },\n}\nRewrites with basePath support\n\nWhen leveraging basePath support with rewrites each source and destination is automatically prefixed with the basePath unless you add basePath: false to the rewrite:\n\nnext.config.js\nmodule.exports = {\n  basePath: '/docs',\n \n  async rewrites() {\n    return [\n      {\n        source: '/with-basePath', // automatically becomes /docs/with-basePath\n        destination: '/another', // automatically becomes /docs/another\n      },\n      {\n        // does not add /docs to /without-basePath since basePath: false is set\n        // Note: this can not be used for internal rewrites e.g. `destination: '/another'`\n        source: '/without-basePath',\n        destination: 'https://example.com',\n        basePath: false,\n      },\n    ]\n  },\n}\nVersion History\nVersion\tChanges\nv13.3.0\tmissing added.\nv10.2.0\thas added.\nv9.5.0\tHeaders added.\nPrevious\nredirects\nNext\nsassOptions\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: serverActions | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/serverActions",
    "html": "Configuration\nnext.config.js\nserverActions\nCopy page\nserverActions\n\nOptions for configuring Server Actions behavior in your Next.js application.\n\nallowedOrigins\n\nA list of extra safe origin domains from which Server Actions can be invoked. Next.js compares the origin of a Server Action request with the host domain, ensuring they match to prevent CSRF attacks. If not provided, only the same origin is allowed.\n\nnext.config.js\n/** @type {import('next').NextConfig} */\n \nmodule.exports = {\n  experimental: {\n    serverActions: {\n      allowedOrigins: ['my-proxy.com', '*.my-proxy.com'],\n    },\n  },\n}\nbodySizeLimit\n\nBy default, the maximum size of the request body sent to a Server Action is 1MB, to prevent the consumption of excessive server resources in parsing large amounts of data, as well as potential DDoS attacks.\n\nHowever, you can configure this limit using the serverActions.bodySizeLimit option. It can take the number of bytes or any string format supported by bytes, for example 1000, '500kb' or '3mb'.\n\nnext.config.js\n/** @type {import('next').NextConfig} */\n \nmodule.exports = {\n  experimental: {\n    serverActions: {\n      bodySizeLimit: '2mb',\n    },\n  },\n}\nEnabling Server Actions (v13)\n\nServer Actions became a stable feature in Next.js 14, and are enabled by default. However, if you are using an earlier version of Next.js, you can enable them by setting experimental.serverActions to true.\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst config = {\n  experimental: {\n    serverActions: true,\n  },\n}\n \nmodule.exports = config\nPrevious\nsassOptions\nNext\nserverComponentsHmrCache\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: serverComponentsHmrCache | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/serverComponentsHmrCache",
    "html": "Configuration\nnext.config.js\nserverComponentsHmrCache\nCopy page\nserverComponentsHmrCache\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe experimental serverComponentsHmrCache option allows you to cache fetch responses in Server Components across Hot Module Replacement (HMR) refreshes in local development. This results in faster responses and reduced costs for billed API calls.\n\nBy default, the HMR cache applies to all fetch requests, including those with the cache: 'no-store' option. This means uncached requests will not show fresh data between HMR refreshes. However, the cache will be cleared on navigation or full-page reloads.\n\nYou can disable the HMR cache by setting serverComponentsHmrCache to false in your next.config.js file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    serverComponentsHmrCache: false, // defaults to true\n  },\n}\n \nexport default nextConfig\n\nGood to know: For better observability, we recommend using the logging.fetches option which logs fetch cache hits and misses in the console during development.\n\nPrevious\nserverActions\nNext\nserverExternalPackages\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: staleTimes | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/staleTimes",
    "html": "Configuration\nnext.config.js\nstaleTimes\nCopy page\nstaleTimes\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nstaleTimes is an experimental feature that enables caching of page segments in the client-side router cache.\n\nYou can enable this experimental feature and provide custom revalidation times by setting the experimental staleTimes flag:\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  experimental: {\n    staleTimes: {\n      dynamic: 30,\n      static: 180,\n    },\n  },\n}\n \nmodule.exports = nextConfig\n\nThe static and dynamic properties correspond with the time period (in seconds) based on different types of link prefetching.\n\nThe dynamic property is used when the page is neither statically generated nor fully prefetched (e.g. with prefetch={true}).\nDefault: 0 seconds (not cached)\nThe static property is used for statically generated pages, or when the prefetch prop on Link is set to true, or when calling router.prefetch.\nDefault: 5 minutes\n\nGood to know:\n\nLoading boundaries are considered reusable for the static period defined in this configuration.\nThis doesn't affect partial rendering, meaning shared layouts won't automatically be refetched on every navigation, only the page segment that changes.\nThis doesn't change back/forward caching behavior to prevent layout shift and to prevent losing the browser scroll position.\n\nYou can learn more about the Client Router Cache here.\n\nVersion History\nVersion\tChanges\nv15.0.0\tThe dynamic staleTimes default changed from 30s to 0s.\nv14.2.0\tExperimental staleTimes introduced.\nPrevious\nserverExternalPackages\nNext\nstaticGeneration*\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: serverExternalPackages | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/serverExternalPackages",
    "html": "Configuration\nnext.config.js\nserverExternalPackages\nCopy page\nserverExternalPackages\n\nDependencies used inside Server Components and Route Handlers will automatically be bundled by Next.js.\n\nIf a dependency is using Node.js specific features, you can choose to opt-out specific dependencies from the Server Components bundling and use native Node.js require.\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  serverExternalPackages: ['@acme/ui'],\n}\n \nmodule.exports = nextConfig\n\nNext.js includes a short list of popular packages\n that currently are working on compatibility and automatically opt-ed out:\n\n@appsignal/nodejs\n@aws-sdk/client-s3\n@aws-sdk/s3-presigned-post\n@blockfrost/blockfrost-js\n@highlight-run/node\n@huggingface/transformers\n@jpg-store/lucid-cardano\n@libsql/client\n@mikro-orm/core\n@mikro-orm/knex\n@node-rs/argon2\n@node-rs/bcrypt\n@prisma/client\n@react-pdf/renderer\n@sentry/profiling-node\n@sparticuz/chromium\n@sparticuz/chromium-min\n@statsig/statsig-node-core\n@swc/core\n@xenova/transformers\nargon2\nautoprefixer\naws-crt\nbcrypt\nbetter-sqlite3\ncanvas\nchromadb-default-embed\nconfig\ncpu-features\ncypress\ndd-trace\neslint\nexpress\nfirebase-admin\nhtmlrewriter\nimport-in-the-middle\nisolated-vm\njest\njsdom\nkeyv\nlibsql\nmdx-bundler\nmongodb\nmongoose\nnewrelic\nnext-mdx-remote\nnext-seo\nnode-cron\nnode-pty\nnode-web-audio-api\nonnxruntime-node\noslo\npg\nplaywright\nplaywright-core\npostcss\nprettier\nprisma\npuppeteer-core\npuppeteer\nravendb\nrequire-in-the-middle\nrimraf\nsharp\nshiki\nsqlite3\nts-node\nts-morph\ntypescript\nvscode-oniguruma\nwebpack\nwebsocket\nzeromq\nVersion\tChanges\nv15.0.0\tMoved from experimental to stable. Renamed from serverComponentsExternalPackages to serverExternalPackages\nPrevious\nserverComponentsHmrCache\nNext\nstaleTimes\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: staticGeneration* | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/staticGeneration",
    "html": "Configuration\nnext.config.js\nstaticGeneration*\nCopy page\nstaticGeneration*\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nThe staticGeneration* options allow you to configure the Static Generation process for advanced use cases.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    staticGenerationRetryCount: 1,\n    staticGenerationMaxConcurrency: 8,\n    staticGenerationMinPagesPerWorker: 25,\n  },\n}\n \nexport default nextConfig\nConfig Options\n\nThe following options are available:\n\nstaticGenerationRetryCount: The number of times to retry a failed page generation before failing the build.\nstaticGenerationMaxConcurrency: The maximum number of pages to be processed per worker.\nstaticGenerationMinPagesPerWorker: The minimum number of pages to be processed before starting a new worker.\nPrevious\nstaleTimes\nNext\ntaint\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: taint | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/taint",
    "html": "Configuration\nnext.config.js\ntaint\nCopy page\ntaint\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\nUsage\n\nThe taint option enables support for experimental React APIs for tainting objects and values. This feature helps prevent sensitive data from being accidentally passed to the client. When enabled, you can use:\n\nexperimental_taintObjectReference\n taint objects references.\nexperimental_taintUniqueValue\n to taint unique values.\n\nGood to know: Activating this flag also enables the React experimental channel for app directory.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    taint: true,\n  },\n}\n \nexport default nextConfig\n\nWarning: Do not rely on the taint API as your only mechanism to prevent exposing sensitive data to the client. See our security recommendations.\n\nThe taint APIs allows you to be defensive, by declaratively and explicitly marking data that is not allowed to pass through the Server-Client boundary. When an object or value, is passed through the Server-Client boundary, React throws an error.\n\nThis is helpful for cases where:\n\nThe methods to read data are out of your control\nYou have to work with sensitive data shapes not defined by you\nSensitive data is accessed during Server Component rendering\n\nIt is recommended to model your data and APIs so that sensitive data is not returned to contexts where it is not needed.\n\nCaveats\nTainting can only keep track of objects by reference. Copying an object creates an untainted version, which loses all guarantees given by the API. You'll need to taint the copy.\nTainting cannot keep track of data derived from a tainted value. You also need to taint the derived value.\nValues are tainted for as long as their lifetime reference is within scope. See the experimental_taintUniqueValue parameters reference\n, for more information.\nExamples\nTainting an object reference\n\nIn this case, the getUserDetails function returns data about a given user. We taint the user object reference, so that it cannot cross a Server-Client boundary. For example, assuming UserCard is a Client Component.\n\nimport { experimental_taintObjectReference } from 'react'\n \nfunction getUserDetails(id: string): UserDetails {\n  const user = await db.queryUserById(id)\n \n  experimental_taintObjectReference(\n    'Do not use the entire user info object. Instead, select only the fields you need.',\n    user\n  )\n \n  return user\n}\n\nWe can still access individual fields from the tainted userDetails object.\n\nexport async function ContactPage({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n  const userDetails = await getUserDetails(id)\n \n  return (\n    <UserCard\n      firstName={userDetails.firstName}\n      lastName={userDetails.lastName}\n    />\n  )\n}\n\nNow, passing the entire object to the Client Component will throw an error.\n\nexport async function ContactPage({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const userDetails = await getUserDetails(id)\n \n  // Throws an error\n  return <UserCard user={userDetails} />\n}\nTainting a unique value\n\nIn this case, we can access the server configuration by awaiting calls to config.getConfigDetails. However, the system configuration contains the SERVICE_API_KEY that we don't want to expose to clients.\n\nWe can taint the config.SERVICE_API_KEY value.\n\nimport { experimental_taintUniqueValue } from 'react'\n \nfunction getSystemConfig(): SystemConfig {\n  const config = await config.getConfigDetails()\n \n  experimental_taintUniqueValue(\n    'Do not pass configuration tokens to the client',\n    config,\n    config.SERVICE_API_KEY\n  )\n \n  return config\n}\n\nWe can still access other properties of the systemConfig object.\n\nexport async function Dashboard() {\n  const systemConfig = await getSystemConfig()\n \n  return <ClientDashboard version={systemConfig.SERVICE_API_VERSION} />\n}\n\nHowever, passing SERVICE_API_KEY to ClientDashboard throws an error.\n\nexport async function Dashboard() {\n  const systemConfig = await getSystemConfig()\n  // Someone makes a mistake in a PR\n  const version = systemConfig.SERVICE_API_KEY\n \n  return <ClientDashboard version={version} />\n}\n\nNote that, even though, systemConfig.SERVICE_API_KEY is reassigned to a new variable. Passing it to a Client Component still throws an error.\n\nWhereas, a value derived from a tainted unique value, will be exposed to the client.\n\nexport async function Dashboard() {\n  const systemConfig = await getSystemConfig()\n  // Someone makes a mistake in a PR\n  const version = `version::${systemConfig.SERVICE_API_KEY}`\n \n  return <ClientDashboard version={version} />\n}\n\nA better approach is to remove SERVICE_API_KEY from the data returned by getSystemConfig.\n\nPrevious\nstaticGeneration*\nNext\ntrailingSlash\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: trailingSlash | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/trailingSlash",
    "html": "Configuration\nnext.config.js\ntrailingSlash\nCopy page\ntrailingSlash\n\nBy default Next.js will redirect URLs with trailing slashes to their counterpart without a trailing slash. For example /about/ will redirect to /about. You can configure this behavior to act the opposite way, where URLs without trailing slashes are redirected to their counterparts with trailing slashes.\n\nOpen next.config.js and add the trailingSlash config:\n\nnext.config.js\nmodule.exports = {\n  trailingSlash: true,\n}\n\nWith this option set, URLs like /about will redirect to /about/.\n\nWhen using trailingSlash: true, certain URLs are exceptions and will not have a trailing slash appended:\n\nStatic file URLs, such as files with extensions.\nAny paths under .well-known/.\n\nFor example, the following URLs will remain unchanged: /file.txt, images/photos/picture.png, and .well-known/subfolder/config.json.\n\nWhen used with output: \"export\" configuration, the /about page will output /about/index.html (instead of the default /about.html).\n\nVersion History\nVersion\tChanges\nv9.5.0\ttrailingSlash added.\nPrevious\ntaint\nNext\ntranspilePackages\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: transpilePackages | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/transpilePackages",
    "html": "Configuration\nnext.config.js\ntranspilePackages\nCopy page\ntranspilePackages\n\nNext.js can automatically transpile and bundle dependencies from local packages (like monorepos) or from external dependencies (node_modules). This replaces the next-transpile-modules package.\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  transpilePackages: ['package-name'],\n}\n \nmodule.exports = nextConfig\nVersion History\nVersion\tChanges\nv13.0.0\ttranspilePackages added.\nPrevious\ntrailingSlash\nNext\nturbopack\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: turbopack | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/turbopack",
    "html": "Configuration\nnext.config.js\nturbopack\nCopy page\nturbopack\n\nThe turbopack option lets you customize Turbopack to transform different files and change how modules are resolved.\n\nGood to know: The turbopack option was previously named experimental.turbo in Next.js versions 13.0.0 to 15.2.x. The experimental.turbo option will be removed in Next.js 16.\n\nIf you are using an older version of Next.js, run npx @next/codemod@latest next-experimental-turbo-to-turbopack . to automatically migrate your configuration.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  turbopack: {\n    // ...\n  },\n}\n \nexport default nextConfig\n\nGood to know:\n\nTurbopack for Next.js does not require loaders or loader configuration for built-in functionality. Turbopack has built-in support for CSS and compiling modern JavaScript, so there's no need for css-loader, postcss-loader, or babel-loader if you're using @babel/preset-env.\nReference\nOptions\n\nThe following options are available for the turbopack configuration:\n\nOption\tDescription\nroot\tSets the application root directory. Should be an absolute path.\nrules\tList of supported webpack loaders to apply when running with Turbopack.\nresolveAlias\tMap aliased imports to modules to load in their place.\nresolveExtensions\tList of extensions to resolve when importing files.\ndebugIds\tEnable generation of debug IDs\n in JavaScript bundles and source maps.\nSupported loaders\n\nThe following loaders have been tested to work with Turbopack's webpack loader implementation, but many other webpack loaders should work as well even if not listed here:\n\nbabel-loader\n (Configured automatically if a Babel configuration file is found)\n@svgr/webpack\nsvg-inline-loader\nyaml-loader\nstring-replace-loader\nraw-loader\nsass-loader\n (Configured automatically)\ngraphql-tag/loader\nMissing Webpack loader features\n\nTurbopack uses the loader-runner\n library to execute webpack loaders, which provides most of the standard loader API. However, some features are not supported:\n\nModule loading:\n\nimportModule\n - No support\nloadModule\n - No support\n\nFile system and output:\n\nfs\n - Partial support: only fs.readFile is currently implemented.\nemitFile\n - No support\n\nContext properties:\n\nversion\n - No support\nmode\n - No support\ntarget\n - No support\n\nUtilities:\n\nutils\n - No support\nresolve\n - No support (use getResolve\n instead)\n\nIf you have a loader that is critically dependent upon one of these features please file an issue.\n\nExamples\nRoot directory\n\nTurbopack uses the root directory to resolve modules. Files outside of the project root are not resolved.\n\nNext.js automatically detects the root directory of your project. It does so by looking for one of these files:\n\npnpm-lock.yaml\npackage-lock.json\nyarn.lock\nbun.lock\nbun.lockb\n\nIf you have a different project structure, for example if you don't use workspaces, you can manually set the root option:\n\nnext.config.js\nconst path = require('path')\nmodule.exports = {\n  turbopack: {\n    root: path.join(__dirname, '..'),\n  },\n}\nConfiguring webpack loaders\n\nIf you need loader support beyond what's built in, many webpack loaders already work with Turbopack. There are currently some limitations:\n\nOnly a core subset of the webpack loader API is implemented. Currently, there is enough coverage for some popular loaders, and we'll expand our API support in the future.\nOnly loaders that return JavaScript code are supported. Loaders that transform files like stylesheets or images are not currently supported.\nOptions passed to webpack loaders must be plain JavaScript primitives, objects, and arrays. For example, it's not possible to pass require() plugin modules as option values.\n\nTo configure loaders, add the names of the loaders you've installed and any options in next.config.js, mapping file extensions to a list of loaders. Rules are evaluated in order.\n\nHere is an example below using the @svgr/webpack\n loader, which enables importing .svg files and rendering them as React components.\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    rules: {\n      '*.svg': {\n        loaders: ['@svgr/webpack'],\n        as: '*.js',\n      },\n    },\n  },\n}\n\nGood to know: Globs used in the rules object match based on file name, unless the glob contains a / character, which will cause it to match based on the full project-relative file path. Windows file paths are normalized to use unix-style / path separators.\n\nTurbopack uses a modified version of the Rust globset library\n.\n\nFor loaders that require configuration options, you can use an object format instead of a string:\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    rules: {\n      '*.svg': {\n        loaders: [\n          {\n            loader: '@svgr/webpack',\n            options: {\n              icon: true,\n            },\n          },\n        ],\n        as: '*.js',\n      },\n    },\n  },\n}\n\nGood to know: Prior to Next.js version 13.4.4, turbopack.rules was named turbo.loaders and only accepted file extensions like .mdx instead of *.mdx.\n\nAdvanced webpack loader conditions\n\nYou can further restrict where a loader runs using the advanced condition syntax:\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    rules: {\n      // '*' will match all file paths, but we restrict where our\n      // rule runs with a condition.\n      '*': {\n        condition: {\n          all: [\n            // 'foreign' is a built-in condition.\n            { not: 'foreign' },\n            // 'path' can be a RegExp or a glob string. A RegExp matches\n            // anywhere in the full project-relative file path.\n            { path: /^img\\/[0-9]{3}\\// },\n            {\n              any: [\n                { path: '*.svg' },\n                // 'content' is always a RegExp, and can match\n                // anywhere in the file.\n                { content: /\\<svg\\W/ },\n              ],\n            },\n          ],\n        },\n        loaders: ['@svgr/webpack'],\n        as: '*.js',\n      },\n    },\n  },\n}\nSupported boolean operators are {all: [...]}, {any: [...]} and {not: ...}.\nSupported customizable operators are {path: string | RegExp} and {content: RegExp}. If path and content are specified in the same object, it acts as an implicit and.\n\nIn addition, a number of built-in conditions are supported:\n\nbrowser: Matches code that will execute on the client. Server code can be matched using {not: 'browser'}.\nforeign: Matches code in node_modules, as well as some Next.js internals. Usually you'll want to restrict loaders to {not: 'foreign'}. This can improve performance by reducing the number of files the loader is invoked on.\ndevelopment: Matches when using next dev.\nproduction: Matches when using next build.\nnode: Matches code that will run on the default Node.js runtime.\nedge-light: Matches code that will run on the Edge runtime.\n\nRules can be an object or an array of objects. An array is often useful for modeling disjoint conditions:\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    rules: {\n      '*.svg': [\n        {\n          condition: 'browser',\n          loaders: ['@svgr/webpack'],\n          as: '*.js',\n        },\n        {\n          condition: { not: 'browser' },\n          loaders: [require.resolve('./custom-svg-loader.js')],\n          as: '*.js',\n        },\n      ],\n    },\n  },\n}\n\nGood to know: All matching rules are executed in order.\n\nResolving aliases\n\nTurbopack can be configured to modify module resolution through aliases, similar to webpack's resolve.alias\n configuration.\n\nTo configure resolve aliases, map imported patterns to their new destination in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    resolveAlias: {\n      underscore: 'lodash',\n      mocha: { browser: 'mocha/browser-entry.js' },\n    },\n  },\n}\n\nThis aliases imports of the underscore package to the lodash package. In other words, import underscore from 'underscore' will load the lodash module instead of underscore.\n\nTurbopack also supports conditional aliasing through this field, similar to Node.js' conditional exports\n. At the moment only the browser condition is supported. In the case above, imports of the mocha module will be aliased to mocha/browser-entry.js when Turbopack targets browser environments.\n\nResolving custom extensions\n\nTurbopack can be configured to resolve modules with custom extensions, similar to webpack's resolve.extensions\n configuration.\n\nTo configure resolve extensions, use the resolveExtensions field in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    resolveExtensions: ['.mdx', '.tsx', '.ts', '.jsx', '.js', '.mjs', '.json'],\n  },\n}\n\nThis overwrites the original resolve extensions with the provided list. Make sure to include the default extensions.\n\nFor more information and guidance for how to migrate your app to Turbopack from webpack, see Turbopack's documentation on webpack compatibility\n.\n\nDebug IDs\n\nTurbopack can be configured to generate debug IDs\n in JavaScript bundles and source maps.\n\nTo configure debug IDs, use the debugIds field in next.config.js:\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    debugIds: true,\n  },\n}\n\nThe option automatically adds a polyfill for debug IDs to the JavaScript bundle to ensure compatibility. The debug IDs are available in the globalThis._debugIds global variable.\n\nVersion History\nVersion\tChanges\n16.0.0\tturbopack.debugIds was added.\n16.0.0\tturbopack.rules.*.condition was added.\n15.3.0\texperimental.turbo is changed to turbopack.\n13.0.0\texperimental.turbo introduced.\nPrevious\ntranspilePackages\nNext\nturbopackFileSystemCache\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: turbopackFileSystemCache | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/turbopackFileSystemCache",
    "html": "Configuration\nnext.config.js\nturbopackFileSystemCache\nCopy page\nTurbopack FileSystem Caching\nUsage\n\nTurbopack FileSystem Cache enables Turbopack to reduce work across next dev or next build commands. When enabled, Turbopack will save and restore data to the .next folder between builds, which can greatly speed up subsequent builds and dev sessions.\n\nGood to know: The FileSystem Cache feature is Beta and is still under development. Users adopting should expect some stability issues. We recommend first adopting it for development.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    // Enable filesystem caching for `next dev`\n    turbopackFileSystemCacheForDev: true,\n    // Enable filesystem caching for `next build`\n    turbopackFileSystemCacheForBuild: true,\n  },\n}\n \nexport default nextConfig\nVersion Changes\nVersion\tChanges\nv16.0.0\tBeta release with separate flags for build and dev\nv15.5.0\tPersistent caching released as experimental on canary releases\nPrevious\nturbopack\nNext\ntypedRoutes\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: typedRoutes | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/typedRoutes",
    "html": "Configuration\nnext.config.js\ntypedRoutes\nCopy page\ntypedRoutes\n\nNote: This option has been marked as stable, so you should use typedRoutes instead of experimental.typedRoutes.\n\nSupport for statically typed links. This feature requires using TypeScript in your project.\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  typedRoutes: true,\n}\n \nmodule.exports = nextConfig\nPrevious\nturbopackFileSystemCache\nNext\ntypescript\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: typescript | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/typescript",
    "html": "Configuration\nnext.config.js\ntypescript\nCopy page\ntypescript\n\nNext.js fails your production build (next build) when TypeScript errors are present in your project.\n\nIf you'd like Next.js to dangerously produce production code even when your application has errors, you can disable the built-in type checking step.\n\nIf disabled, be sure you are running type checks as part of your build or deploy process, otherwise this can be very dangerous.\n\nOpen next.config.js and enable the ignoreBuildErrors option in the typescript config:\n\nnext.config.js\nmodule.exports = {\n  typescript: {\n    // !! WARN !!\n    // Dangerously allow production builds to successfully complete even if\n    // your project has type errors.\n    // !! WARN !!\n    ignoreBuildErrors: true,\n  },\n}\nPrevious\ntypedRoutes\nNext\nurlImports\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: urlImports | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/urlImports",
    "html": "Configuration\nnext.config.js\nurlImports\nCopy page\nurlImports\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nURL imports are an experimental feature that allows you to import modules directly from external servers (instead of from the local disk).\n\nWarning: Only use domains that you trust to download and execute on your machine. Please exercise discretion, and caution until the feature is flagged as stable.\n\nTo opt-in, add the allowed URL prefixes inside next.config.js:\n\nnext.config.js\nmodule.exports = {\n  experimental: {\n    urlImports: ['https://example.com/assets/', 'https://cdn.skypack.dev'],\n  },\n}\n\nThen, you can import modules directly from URLs:\n\nimport { a, b, c } from 'https://example.com/assets/some/module.js'\n\nURL Imports can be used everywhere normal package imports can be used.\n\nSecurity Model\n\nThis feature is being designed with security as the top priority. To start, we added an experimental flag forcing you to explicitly allow the domains you accept URL imports from. We're working to take this further by limiting URL imports to execute in the browser sandbox using the Edge Runtime.\n\nLockfile\n\nWhen using URL imports, Next.js will create a next.lock directory containing a lockfile and fetched assets. This directory must be committed to Git, not ignored by .gitignore.\n\nWhen running next dev, Next.js will download and add all newly discovered URL Imports to your lockfile.\nWhen running next build, Next.js will use only the lockfile to build the application for production.\n\nTypically, no network requests are needed and any outdated lockfile will cause the build to fail. One exception is resources that respond with Cache-Control: no-cache. These resources will have a no-cache entry in the lockfile and will always be fetched from the network on each build.\n\nExamples\nSkypack\nimport confetti from 'https://cdn.skypack.dev/canvas-confetti'\nimport { useEffect } from 'react'\n \nexport default () => {\n  useEffect(() => {\n    confetti()\n  })\n  return <p>Hello</p>\n}\nStatic Image Imports\nimport Image from 'next/image'\nimport logo from 'https://example.com/assets/logo.png'\n \nexport default () => (\n  <div>\n    <Image src={logo} placeholder=\"blur\" />\n  </div>\n)\nURLs in CSS\n.className {\n  background: url('https://example.com/assets/hero.jpg');\n}\nAsset Imports\nconst logo = new URL('https://example.com/assets/file.txt', import.meta.url)\n \nconsole.log(logo.pathname)\n \n// prints \"/_next/static/media/file.a9727b5d.txt\"\nPrevious\ntypescript\nNext\nuseLightningcss\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: useLightningcss | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/useLightningcss",
    "html": "Configuration\nnext.config.js\nuseLightningcss\nCopy page\nuseLightningcss\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nExperimental support for using Lightning CSS\n with webpack. Lightning CSS is a fast CSS transformer and minifier, written in Rust.\n\nIf this option is not set, Next.js on webpack uses PostCSS\n with postcss-preset-env\n by default.\n\nTurbopack uses Lightning CSS by default since Next 14.2. This configuration option has no effect on Turbopack. Turbopack always uses Lightning CSS.\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    useLightningcss: false, // default, ignored on Turbopack\n  },\n}\n \nexport default nextConfig\nVersion History\nVersion\tChanges\n15.1.0\tSupport for useSwcCss was removed from Turbopack.\n14.2.0\tTurbopack's default CSS processor was changed from @swc/css to Lightning CSS. useLightningcss became ignored on Turbopack, and a legacy experimental.turbo.useSwcCss option was added.\nPrevious\nurlImports\nNext\nviewTransition\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: viewTransition | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/viewTransition",
    "html": "Configuration\nnext.config.js\nviewTransition\nCopy page\nviewTransition\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nviewTransition is an experimental flag that enables the new View Transitions API\n in React. This API allows you to leverage the native View Transitions browser API to create seamless transitions between UI states.\n\nTo enable this feature, you need to set the viewTransition property to true in your next.config.js file.\n\nnext.config.js\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  experimental: {\n    viewTransition: true,\n  },\n}\n \nmodule.exports = nextConfig\n\nImportant Notice: The <ViewTransition> Component is already available in React's Canary release channel. experimental.viewTransition is only required to enable deeper integration with Next.js features e.g. automatically adding Transition types\n for navigations. Next.js specific transition types are not implemented yet.\n\nUsage\n\nYou can import the <ViewTransition> Component\n from React in your application:\n\nimport { ViewTransition } from 'react'\nLive Demo\n\nCheck out our Next.js View Transition Demo\n to see this feature in action.\n\nAs this API evolves, we will update our documentation and share more examples. However, for now, we strongly advise against using this feature in production.\n\nPrevious\nuseLightningcss\nNext\nwebpack\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: webpack | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/webpack",
    "html": "Configuration\nnext.config.js\nwebpack\nCopy page\nCustom Webpack Config\n\nGood to know: changes to webpack config are not covered by semver so proceed at your own risk\n\nBefore continuing to add custom webpack configuration to your application make sure Next.js doesn't already support your use-case:\n\nCSS imports\nCSS modules\nSass/SCSS imports\nSass/SCSS modules\n\nSome commonly asked for features are available as plugins:\n\n@next/mdx\n@next/bundle-analyzer\n\nIn order to extend our usage of webpack, you can define a function that extends its config inside next.config.js, like so:\n\nnext.config.js\nmodule.exports = {\n  webpack: (\n    config,\n    { buildId, dev, isServer, defaultLoaders, nextRuntime, webpack }\n  ) => {\n    // Important: return the modified config\n    return config\n  },\n}\n\nThe webpack function is executed three times, twice for the server (nodejs / edge runtime) and once for the client. This allows you to distinguish between client and server configuration using the isServer property.\n\nThe second argument to the webpack function is an object with the following properties:\n\nbuildId: String - The build id, used as a unique identifier between builds.\ndev: Boolean - Indicates if the compilation will be done in development.\nisServer: Boolean - It's true for server-side compilation, and false for client-side compilation.\nnextRuntime: String | undefined - The target runtime for server-side compilation; either \"edge\" or \"nodejs\", it's undefined for client-side compilation.\ndefaultLoaders: Object - Default loaders used internally by Next.js:\nbabel: Object - Default babel-loader configuration.\n\nExample usage of defaultLoaders.babel:\n\n// Example config for adding a loader that depends on babel-loader\n// This source was taken from the @next/mdx plugin source:\n// https://github.com/vercel/next.js/tree/canary/packages/next-mdx\nmodule.exports = {\n  webpack: (config, options) => {\n    config.module.rules.push({\n      test: /\\.mdx/,\n      use: [\n        options.defaultLoaders.babel,\n        {\n          loader: '@mdx-js/loader',\n          options: pluginOptions.options,\n        },\n      ],\n    })\n \n    return config\n  },\n}\nnextRuntime\n\nNotice that isServer is true when nextRuntime is \"edge\" or \"nodejs\", nextRuntime \"edge\" is currently for proxy and Server Components in edge runtime only.\n\nPrevious\nviewTransition\nNext\nwebVitalsAttribution\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Configuration: TypeScript | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/typescript",
    "html": "API Reference\nConfiguration\nTypeScript\nCopy page\nTypeScript\n\nNext.js comes with built-in TypeScript, automatically installing the necessary packages and configuring the proper settings when you create a new project with create-next-app.\n\nTo add TypeScript to an existing project, rename a file to .ts / .tsx. Run next dev and next build to automatically install the necessary dependencies and add a tsconfig.json file with the recommended config options.\n\nGood to know: If you already have a jsconfig.json file, copy the paths compiler option from the old jsconfig.json into the new tsconfig.json file, and delete the old jsconfig.json file.\n\nIDE Plugin\n\nNext.js includes a custom TypeScript plugin and type checker, which VSCode and other code editors can use for advanced type-checking and auto-completion.\n\nYou can enable the plugin in VS Code by:\n\nOpening the command palette (Ctrl/⌘ + Shift + P)\nSearching for \"TypeScript: Select TypeScript Version\"\nSelecting \"Use Workspace Version\"\n\nNow, when editing files, the custom plugin will be enabled. When running next build, the custom type checker will be used.\n\nThe TypeScript plugin can help with:\n\nWarning if the invalid values for segment config options are passed.\nShowing available options and in-context documentation.\nEnsuring the 'use client' directive is used correctly.\nEnsuring client hooks (like useState) are only used in Client Components.\n\n🎥 Watch: Learn about the built-in TypeScript plugin → YouTube (3 minutes)\n\nEnd-to-End Type Safety\n\nThe Next.js App Router has enhanced type safety. This includes:\n\nNo serialization of data between fetching function and page: You can fetch directly in components, layouts, and pages on the server. This data does not need to be serialized (converted to a string) to be passed to the client side for consumption in React. Instead, since app uses Server Components by default, we can use values like Date, Map, Set, and more without any extra steps. Previously, you needed to manually type the boundary between server and client with Next.js-specific types.\nStreamlined data flow between components: With the removal of _app in favor of root layouts, it is now easier to visualize the data flow between components and pages. Previously, data flowing between individual pages and _app were difficult to type and could introduce confusing bugs. With colocated data fetching in the App Router, this is no longer an issue.\n\nData Fetching in Next.js now provides as close to end-to-end type safety as possible without being prescriptive about your database or content provider selection.\n\nWe're able to type the response data as you would expect with normal TypeScript. For example:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nasync function getData() {\n  const res = await fetch('https://api.example.com/...')\n  // The return value is *not* serialized\n  // You can return Date, Map, Set, etc.\n  return res.json()\n}\n \nexport default async function Page() {\n  const name = await getData()\n \n  return '...'\n}\n\nFor complete end-to-end type safety, this also requires your database or content provider to support TypeScript. This could be through using an ORM\n or type-safe query builder.\n\nRoute-Aware Type Helpers\n\nNext.js generates global helpers for App Router route types. These are available without imports and are generated during next dev, next build, or via next typegen:\n\nPageProps\nLayoutProps\nRouteContext\nExamples\nType Checking Next.js Configuration Files\n\nYou can use TypeScript and import types in your Next.js configuration by using next.config.ts.\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  /* config options here */\n}\n \nexport default nextConfig\n\nModule resolution in next.config.ts is currently limited to CommonJS. However, ECMAScript Modules (ESM) syntax is available when using Node.js native TypeScript resolver for Node.js v22.10.0 and higher.\n\nWhen using the next.config.js file, you can add some type checking in your IDE using JSDoc as below:\n\nnext.config.js\n// @ts-check\n \n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  /* config options here */\n}\n \nmodule.exports = nextConfig\nUsing Node.js Native TypeScript Resolver for next.config.ts\n\nNote: Available on Node.js v22.10.0+ and only when the feature is enabled. Next.js does not enable it.\n\nNext.js detects the Node.js native TypeScript resolver\n via process.features.typescript\n, added in v22.10.0. When present, next.config.ts can use native ESM, including top‑level await and dynamic import(). This mechanism inherits the capabilities and limitations of Node's resolver.\n\nIn Node.js versions v22.18.0+, process.features.typescript is enabled by default. For versions between v22.10.0 and 22.17.x, opt in with NODE_OPTIONS=--experimental-transform-types:\n\nTerminal\nNODE_OPTIONS=--experimental-transform-types next <command>\nFor CommonJS Projects (Default)\n\nAlthough next.config.ts supports native ESM syntax on CommonJS projects, Node.js will still assume next.config.ts is a CommonJS file by default, resulting in Node.js reparsing the file as ESM when module syntax is detected. Therefore, we recommend using the next.config.mts file for CommonJS projects to explicitly indicate it's an ESM module:\n\nnext.config.mts\nimport type { NextConfig } from 'next'\n \n// Top-level await and dynamic import are supported\nconst flags = await import('./flags.js').then((m) => m.default ?? m)\n \nconst nextConfig: NextConfig = {\n  /* config options here */\n  typedRoutes: Boolean(flags?.typedRoutes),\n}\n \nexport default nextConfig\nFor ESM Projects\n\nWhen \"type\" is set to \"module\" in package.json, your project uses ESM. Learn more about this setting in the Node.js docs\n. In this case, you can write next.config.ts directly with ESM syntax.\n\nGood to know: When using \"type\": \"module\" in your package.json, all .js and .ts files in your project are treated as ESM modules by default. You may need to rename files with CommonJS syntax to .cjs or .cts extensions if needed.\n\nStatically Typed Links\n\nNext.js can statically type links to prevent typos and other errors when using next/link, improving type safety when navigating between pages.\n\nWorks in both the Pages and App Router for the href prop in next/link. In the App Router, it also types next/navigation methods like push, replace, and prefetch. It does not type next/router methods in Pages Router.\n\nLiteral href strings are validated, while non-literal hrefs may require a cast with as Route.\n\nTo opt-into this feature, typedRoutes need to be enabled and the project needs to be using TypeScript.\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  typedRoutes: true,\n}\n \nexport default nextConfig\n\nNext.js will generate a link definition in .next/types that contains information about all existing routes in your application, which TypeScript can then use to provide feedback in your editor about invalid links.\n\nGood to know: If you set up your project without create-next-app, ensure the generated Next.js types are included by adding .next/types/**/*.ts to the include array in your tsconfig.json:\n\ntsconfig.json\n{\n  \"include\": [\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\"\n  ],\n  \"exclude\": [\"node_modules\"]\n}\n\nCurrently, support includes any string literal, including dynamic segments. For non-literal strings, you need to manually cast with as Route. The example below shows both next/link and next/navigation usage:\n\napp/example-client.tsx\n'use client'\n \nimport type { Route } from 'next'\nimport Link from 'next/link'\nimport { useRouter } from 'next/navigation'\n \nexport default function Example() {\n  const router = useRouter()\n  const slug = 'nextjs'\n \n  return (\n    <>\n      {/* Link: literal and dynamic */}\n      <Link href=\"/about\" />\n      <Link href={`/blog/${slug}`} />\n      <Link href={('/blog/' + slug) as Route} />\n      {/* TypeScript error if href is not a valid route */}\n      <Link href=\"/aboot\" />\n \n      {/* Router: literal and dynamic strings are validated */}\n      <button onClick={() => router.push('/about')}>Push About</button>\n      <button onClick={() => router.replace(`/blog/${slug}`)}>\n        Replace Blog\n      </button>\n      <button onClick={() => router.prefetch('/contact')}>\n        Prefetch Contact\n      </button>\n \n      {/* For non-literal strings, cast to Route */}\n      <button onClick={() => router.push(('/blog/' + slug) as Route)}>\n        Push Non-literal Blog\n      </button>\n    </>\n  )\n}\n\nThe same applies for redirecting routes defined by proxy:\n\nproxy.ts\nimport { NextRequest, NextResponse } from 'next/server'\n \nexport function proxy(request: NextRequest) {\n  if (request.nextUrl.pathname === '/proxy-redirect') {\n    return NextResponse.redirect(new URL('/', request.url))\n  }\n \n  return NextResponse.next()\n}\napp/some/page.tsx\nimport type { Route } from 'next'\n \nexport default function Page() {\n  return <Link href={'/proxy-redirect' as Route}>Link Text</Link>\n}\n\nTo accept href in a custom component wrapping next/link, use a generic:\n\nimport type { Route } from 'next'\nimport Link from 'next/link'\n \nfunction Card<T extends string>({ href }: { href: Route<T> | URL }) {\n  return (\n    <Link href={href}>\n      <div>My Card</div>\n    </Link>\n  )\n}\n\nYou can also type a simple data structure and iterate to render links:\n\ncomponents/nav-items.ts\nimport type { Route } from 'next'\n \ntype NavItem<T extends string = string> = {\n  href: T\n  label: string\n}\n \nexport const navItems: NavItem<Route>[] = [\n  { href: '/', label: 'Home' },\n  { href: '/about', label: 'About' },\n  { href: '/blog', label: 'Blog' },\n]\n\nThen, map over the items to render Links:\n\ncomponents/nav.tsx\nimport Link from 'next/link'\nimport { navItems } from './nav-items'\n \nexport function Nav() {\n  return (\n    <nav>\n      {navItems.map((item) => (\n        <Link key={item.href} href={item.href}>\n          {item.label}\n        </Link>\n      ))}\n    </nav>\n  )\n}\n\nHow does it work?\n\nWhen running next dev or next build, Next.js generates a hidden .d.ts file inside .next that contains information about all existing routes in your application (all valid routes as the href type of Link). This .d.ts file is included in tsconfig.json and the TypeScript compiler will check that .d.ts and provide feedback in your editor about invalid links.\n\nType IntelliSense for Environment Variables\n\nDuring development, Next.js generates a .d.ts file in .next/types that contains information about the loaded environment variables for your editor's IntelliSense. If the same environment variable key is defined in multiple files, it is deduplicated according to the Environment Variable Load Order.\n\nTo opt-into this feature, experimental.typedEnv needs to be enabled and the project needs to be using TypeScript.\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  experimental: {\n    typedEnv: true,\n  },\n}\n \nexport default nextConfig\n\nGood to know: Types are generated based on the environment variables loaded at development runtime, which excludes variables from .env.production* files by default. To include production-specific variables, run next dev with NODE_ENV=production.\n\nWith Async Server Components\n\nTo use an async Server Component with TypeScript, ensure you are using TypeScript 5.1.3 or higher and @types/react 18.2.8 or higher.\n\nIf you are using an older version of TypeScript, you may see a 'Promise<Element>' is not a valid JSX element type error. Updating to the latest version of TypeScript and @types/react should resolve this issue.\n\nIncremental type checking\n\nSince v10.2.1 Next.js supports incremental type checking\n when enabled in your tsconfig.json, this can help speed up type checking in larger applications.\n\nCustom tsconfig path\n\nIn some cases, you might want to use a different TypeScript configuration for builds or tooling. To do that, set typescript.tsconfigPath in next.config.ts to point Next.js to another tsconfig file.\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  typescript: {\n    tsconfigPath: 'tsconfig.build.json',\n  },\n}\n \nexport default nextConfig\n\nFor example, switch to a different config for production builds:\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst isProd = process.env.NODE_ENV === 'production'\n \nconst nextConfig: NextConfig = {\n  typescript: {\n    tsconfigPath: isProd ? 'tsconfig.build.json' : 'tsconfig.json',\n  },\n}\n \nexport default nextConfig\nWhy you might use a separate tsconfig for builds\n\nGood to know:\n\nIDEs typically read tsconfig.json for diagnostics and IntelliSense, so you can still see IDE warnings while production builds use the alternate config. Mirror critical options if you want parity in the editor.\nIn development, only tsconfig.json is watched for changes. If you edit a different file name via typescript.tsconfigPath, restart the dev server to apply changes.\nThe configured file is used in next dev, next build, and next typegen.\nDisabling TypeScript errors in production\n\nNext.js fails your production build (next build) when TypeScript errors are present in your project.\n\nIf you'd like Next.js to dangerously produce production code even when your application has errors, you can disable the built-in type checking step.\n\nIf disabled, be sure you are running type checks as part of your build or deploy process, otherwise this can be very dangerous.\n\nOpen next.config.ts and enable the ignoreBuildErrors option in the typescript config:\n\nnext.config.ts\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  typescript: {\n    // !! WARN !!\n    // Dangerously allow production builds to successfully complete even if\n    // your project has type errors.\n    // !! WARN !!\n    ignoreBuildErrors: true,\n  },\n}\n \nexport default nextConfig\n\nGood to know: You can run tsc --noEmit to check for TypeScript errors yourself before building. This is useful for CI/CD pipelines where you'd like to check for TypeScript errors before deploying.\n\nCustom type declarations\n\nWhen you need to declare custom types, you might be tempted to modify next-env.d.ts. However, this file is automatically generated, so any changes you make will be overwritten. Instead, you should create a new file, let's call it new-types.d.ts, and reference it in your tsconfig.json:\n\ntsconfig.json\n{\n  \"compilerOptions\": {\n    \"skipLibCheck\": true\n    //...truncated...\n  },\n  \"include\": [\n    \"new-types.d.ts\",\n    \"next-env.d.ts\",\n    \".next/types/**/*.ts\",\n    \"**/*.ts\",\n    \"**/*.tsx\"\n  ],\n  \"exclude\": [\"node_modules\"]\n}\nVersion Changes\nVersion\tChanges\nv15.0.0\tnext.config.ts support added for TypeScript projects.\nv13.2.0\tStatically typed links are available in beta.\nv12.0.0\tSWC is now used by default to compile TypeScript and TSX for faster builds.\nv10.2.1\tIncremental type checking\n support added when enabled in your tsconfig.json.\nPrevious\nwebVitalsAttribution\nNext\nESLint\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "next.config.js: webVitalsAttribution | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/next-config-js/webVitalsAttribution",
    "html": "Configuration\nnext.config.js\nwebVitalsAttribution\nCopy page\nwebVitalsAttribution\nThis feature is currently experimental and subject to change, it's not recommended for production. Try it out and share your feedback on GitHub.\n\nWhen debugging issues related to Web Vitals, it is often helpful if we can pinpoint the source of the problem. For example, in the case of Cumulative Layout Shift (CLS), we might want to know the first element that shifted when the single largest layout shift occurred. Or, in the case of Largest Contentful Paint (LCP), we might want to identify the element corresponding to the LCP for the page. If the LCP element is an image, knowing the URL of the image resource can help us locate the asset we need to optimize.\n\nPinpointing the biggest contributor to the Web Vitals score, aka attribution\n, allows us to obtain more in-depth information like entries for PerformanceEventTiming\n, PerformanceNavigationTiming\n and PerformanceResourceTiming\n.\n\nAttribution is disabled by default in Next.js but can be enabled per metric by specifying the following in next.config.js.\n\nnext.config.js\nmodule.exports = {\n  experimental: {\n    webVitalsAttribution: ['CLS', 'LCP'],\n  },\n}\n\nValid attribution values are all web-vitals metrics specified in the NextWebVitalsMetric\n type.\n\nPrevious\nwebpack\nNext\nTypeScript\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Configuration: ESLint | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/config/eslint",
    "html": "API Reference\nConfiguration\nESLint\nCopy page\nESLint Plugin\n\nNext.js provides an ESLint plugin, @next/eslint-plugin-next\n, already bundled within the base configuration that makes it possible to catch common issues and problems in a Next.js application.\n\nSetup ESLint\n\nGet linting working quickly with the ESLint CLI (flat config):\n\nInstall ESLint and the Next.js config:\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm add -D eslint eslint-config-next\n\nCreate eslint.config.mjs with the Next.js config:\n\neslint.config.mjs\nimport { defineConfig, globalIgnores } from 'eslint/config'\nimport nextVitals from 'eslint-config-next/core-web-vitals'\n \nconst eslintConfig = defineConfig([\n  ...nextVitals,\n  // Override default ignores of eslint-config-next.\n  globalIgnores([\n    // Default ignores of eslint-config-next:\n    '.next/**',\n    'out/**',\n    'build/**',\n    'next-env.d.ts',\n  ]),\n])\n \nexport default eslintConfig\n\nRun ESLint:\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm exec eslint .\nReference\n\nRecommended rule-sets from the following ESLint plugins are all used within eslint-config-next:\n\neslint-plugin-react\neslint-plugin-react-hooks\n@next/eslint-plugin-next\nRules\n\nThe full set of rules is as follows:\n\nEnabled in recommended config\tRule\tDescription\n\n\t@next/next/google-font-display\tEnforce font-display behavior with Google Fonts.\n\n\t@next/next/google-font-preconnect\tEnsure preconnect is used with Google Fonts.\n\n\t@next/next/inline-script-id\tEnforce id attribute on next/script components with inline content.\n\n\t@next/next/next-script-for-ga\tPrefer next/script component when using the inline script for Google Analytics.\n\n\t@next/next/no-assign-module-variable\tPrevent assignment to the module variable.\n\n\t@next/next/no-async-client-component\tPrevent Client Components from being async functions.\n\n\t@next/next/no-before-interactive-script-outside-document\tPrevent usage of next/script's beforeInteractive strategy outside of pages/_document.js.\n\n\t@next/next/no-css-tags\tPrevent manual stylesheet tags.\n\n\t@next/next/no-document-import-in-page\tPrevent importing next/document outside of pages/_document.js.\n\n\t@next/next/no-duplicate-head\tPrevent duplicate usage of <Head> in pages/_document.js.\n\n\t@next/next/no-head-element\tPrevent usage of <head> element.\n\n\t@next/next/no-head-import-in-document\tPrevent usage of next/head in pages/_document.js.\n\n\t@next/next/no-html-link-for-pages\tPrevent usage of <a> elements to navigate to internal Next.js pages.\n\n\t@next/next/no-img-element\tPrevent usage of <img> element due to slower LCP and higher bandwidth.\n\n\t@next/next/no-page-custom-font\tPrevent page-only custom fonts.\n\n\t@next/next/no-script-component-in-head\tPrevent usage of next/script in next/head component.\n\n\t@next/next/no-styled-jsx-in-document\tPrevent usage of styled-jsx in pages/_document.js.\n\n\t@next/next/no-sync-scripts\tPrevent synchronous scripts.\n\n\t@next/next/no-title-in-document-head\tPrevent usage of <title> with Head component from next/document.\n\n\t@next/next/no-typos\tPrevent common typos in Next.js's data fetching functions\n\n\t@next/next/no-unwanted-polyfillio\tPrevent duplicate polyfills from Polyfill.io.\n\nWe recommend using an appropriate integration\n to view warnings and errors directly in your code editor during development.\n\nnext lint removal\nExamples\nSpecifying a root directory within a monorepo\n\nIf you're using @next/eslint-plugin-next in a project where Next.js isn't installed in your root directory (such as a monorepo), you can tell @next/eslint-plugin-next where to find your Next.js application using the settings property in your eslint.config.mjs:\n\neslint.config.mjs\nimport { defineConfig } from 'eslint/config'\nimport eslintNextPlugin from '@next/eslint-plugin-next'\n \nconst eslintConfig = defineConfig([\n  {\n    plugins: {\n      next: eslintNextPlugin,\n    },\n    settings: {\n      next: {\n        rootDir: 'packages/my-app/',\n      },\n    },\n    files: [\n      // ...files\n    ],\n    ignores: [\n      // ...ignores\n    ],\n  },\n])\n \nexport default eslintConfig\n\nrootDir can be a path (relative or absolute), a glob (i.e. \"packages/*/\"), or an array of paths and/or globs.\n\nDisabling rules\n\nIf you would like to modify or disable any rules provided by the supported plugins (react, react-hooks, next), you can directly change them using the rules property in your eslint.config.mjs:\n\neslint.config.mjs\nimport { defineConfig, globalIgnores } from 'eslint/config'\nimport nextVitals from 'eslint-config-next/core-web-vitals'\n \nconst eslintConfig = defineConfig([\n  ...nextVitals,\n  {\n    rules: {\n      'react/no-unescaped-entities': 'off',\n      '@next/next/no-page-custom-font': 'off',\n    },\n  },\n  // Override default ignores of eslint-config-next.\n  globalIgnores([\n    // Default ignores of eslint-config-next:\n    '.next/**',\n    'out/**',\n    'build/**',\n    'next-env.d.ts',\n  ]),\n])\n \nexport default eslintConfig\nWith Core Web Vitals\n\nEnable the next/core-web-vitals rule set by extending it in your ESLint config.\n\neslint.config.mjs\nimport { defineConfig, globalIgnores } from 'eslint/config'\nimport nextVitals from 'eslint-config-next/core-web-vitals'\n \nconst eslintConfig = defineConfig([\n  ...nextVitals,\n  // Override default ignores of eslint-config-next.\n  globalIgnores([\n    // Default ignores of eslint-config-next:\n    '.next/**',\n    'out/**',\n    'build/**',\n    'next-env.d.ts',\n  ]),\n])\n \nexport default eslintConfig\n\nnext/core-web-vitals updates @next/eslint-plugin-next to error on a number of rules that are warnings by default if they affect Core Web Vitals\n.\n\nThe next/core-web-vitals entry point is automatically included for new applications built with Create Next App.\n\nWith TypeScript\n\nIn addition to the Next.js ESLint rules, create-next-app --typescript will also add TypeScript-specific lint rules with next/typescript to your config:\n\neslint.config.mjs\nimport { defineConfig, globalIgnores } from 'eslint/config'\nimport nextVitals from 'eslint-config-next/core-web-vitals'\nimport nextTs from 'eslint-config-next/typescript'\n \nconst eslintConfig = defineConfig([\n  ...nextVitals,\n  ...nextTs,\n  // Override default ignores of eslint-config-next.\n  globalIgnores([\n    // Default ignores of eslint-config-next:\n    '.next/**',\n    'out/**',\n    'build/**',\n    'next-env.d.ts',\n  ]),\n])\n \nexport default eslintConfig\n\nThose rules are based on plugin:@typescript-eslint/recommended\n. See typescript-eslint > Configs\n for more details.\n\nWith Prettier\n\nESLint also contains code formatting rules, which can conflict with your existing Prettier\n setup. We recommend including eslint-config-prettier\n in your ESLint config to make ESLint and Prettier work together.\n\nFirst, install the dependency:\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm add -D eslint-config-prettier\n\nThen, add prettier to your existing ESLint config:\n\neslint.config.mjs\nimport { defineConfig, globalIgnores } from 'eslint/config'\nimport nextVitals from 'eslint-config-next/core-web-vitals'\nimport prettier from 'eslint-config-prettier/flat'\n \nconst eslintConfig = defineConfig([\n  ...nextVitals,\n  prettier,\n  // Override default ignores of eslint-config-next.\n  globalIgnores([\n    // Default ignores of eslint-config-next:\n    '.next/**',\n    'out/**',\n    'build/**',\n    'next-env.d.ts',\n  ]),\n])\n \nexport default eslintConfig\nRunning lint on staged files\n\nIf you would like to use ESLint with lint-staged\n to run the linter on staged git files, add the following to the .lintstagedrc.js file in the root of your project:\n\n.lintstagedrc.js\nconst path = require('path')\n \nconst buildEslintCommand = (filenames) =>\n  `eslint --fix ${filenames\n    .map((f) => `\"${path.relative(process.cwd(), f)}\"`)\n    .join(' ')}`\n \nmodule.exports = {\n  '*.{js,jsx,ts,tsx}': [buildEslintCommand],\n}\nMigrating existing config\n\nIf you already have ESLint configured in your application, we recommend extending from this plugin directly instead of including eslint-config-next unless a few conditions are met.\n\nRecommended plugin ruleset\n\nIf the following conditions are true:\n\nYou have one or more of the following plugins already installed (either separately or through a different config such as airbnb or react-app):\nreact\nreact-hooks\njsx-a11y\nimport\nYou've defined specific parserOptions that are different from how Babel is configured within Next.js (this is not recommended unless you have customized your Babel configuration)\nYou have eslint-plugin-import installed with Node.js and/or TypeScript resolvers\n defined to handle imports\n\nThen we recommend either removing these settings if you prefer how these properties have been configured within eslint-config-next\n or extending directly from the Next.js ESLint plugin instead:\n\nmodule.exports = {\n  extends: [\n    //...\n    'plugin:@next/next/recommended',\n  ],\n}\n\nThe plugin can be installed normally in your project:\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm add -D @next/eslint-plugin-next\n\nThis eliminates the risk of collisions or errors that can occur due to importing the same plugin or parser across multiple configurations.\n\nAdditional configurations\n\nIf you already use a separate ESLint configuration and want to include eslint-config-next, ensure that it is extended last after other configurations. For example:\n\neslint.config.mjs\nimport { defineConfig, globalIgnores } from 'eslint/config'\nimport nextPlugin from '@next/eslint-plugin-next'\n \nconst eslintConfig = defineConfig([\n  nextPlugin.configs['core-web-vitals'],\n  // List of ignore patterns.\n  globalIgnores([]),\n])\n \nexport default eslintConfig\n\nThe next configuration already handles setting default values for the parser, plugins and settings properties. There is no need to manually re-declare any of these properties unless you need a different configuration for your use case.\n\nIf you include any other shareable configurations, you will need to make sure that these properties are not overwritten or modified. Otherwise, we recommend removing any configurations that share behavior with the next configuration or extending directly from the Next.js ESLint plugin as mentioned above.\n\nVersion\tChanges\nv16.0.0\tnext lint and the eslint next.config.js option were removed in favor of the ESLint CLI. A codemod is available to help you migrate.\nPrevious\nTypeScript\nNext\nCLI\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "API Reference: CLI | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/cli",
    "html": "App Router\nAPI Reference\nCLI\nCopy page\nCLI\n\nNext.js comes with two Command Line Interface (CLI) tools:\n\ncreate-next-app: Quickly create a new Next.js application using the default template or an example\n from a public GitHub repository.\nnext: Run the Next.js development server, build your application, and more.\ncreate-next-app\nCreate Next.js apps using one command with the create-next-app CLI.\nnext CLI\nLearn how to run and build your application with the Next.js CLI.\nPrevious\nESLint\nNext\ncreate-next-app\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "CLI: create-next-app | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/cli/create-next-app",
    "html": "API Reference\nCLI\ncreate-next-app\nCopy page\ncreate-next-app\n\nThe create-next-app CLI allow you to create a new Next.js application using the default template or an example\n from a public GitHub repository. It is the easiest way to get started with Next.js.\n\nBasic usage:\n\nTerminal\nnpx create-next-app@latest [project-name] [options]\nReference\n\nThe following options are available:\n\nOptions\tDescription\n-h or --help\tShow all available options\n-v or --version\tOutput the version number\n--no-*\tNegate default options. E.g. --no-ts\n--ts or --typescript\tInitialize as a TypeScript project (default)\n--js or --javascript\tInitialize as a JavaScript project\n--tailwind\tInitialize with Tailwind CSS config (default)\n--react-compiler\tInitialize with React Compiler enabled\n--eslint\tInitialize with ESLint config\n--biome\tInitialize with Biome config\n--no-linter\tSkip linter configuration\n--app\tInitialize as an App Router project\n--api\tInitialize a project with only route handlers\n--src-dir\tInitialize inside a src/ directory\n--turbopack\tForce enable Turbopack in generated package.json (enabled by default)\n--webpack\tForce enable Webpack in generated package.json\n--import-alias <alias-to-configure>\tSpecify import alias to use (default \"@/*\")\n--empty\tInitialize an empty project\n--use-npm\tExplicitly tell the CLI to bootstrap the application using npm\n--use-pnpm\tExplicitly tell the CLI to bootstrap the application using pnpm\n--use-yarn\tExplicitly tell the CLI to bootstrap the application using Yarn\n--use-bun\tExplicitly tell the CLI to bootstrap the application using Bun\n-e or --example [name] [github-url]\tAn example to bootstrap the app with\n--example-path <path-to-example>\tSpecify the path to the example separately\n--reset-preferences\tExplicitly tell the CLI to reset any stored preferences\n--skip-install\tExplicitly tell the CLI to skip installing packages\n--disable-git\tExplicitly tell the CLI to disable git initialization\n--yes\tUse previous preferences or defaults for all options\nExamples\nWith the default template\n\nTo create a new app using the default template, run the following command in your terminal:\n\nTerminal\nnpx create-next-app@latest\n\nOn installation, you'll see the following prompts:\n\nTerminal\nWhat is your project named? my-app\nWould you like to use the recommended Next.js defaults?\n    Yes, use recommended defaults - TypeScript, ESLint, Tailwind CSS, App Router, Turbopack\n    No, reuse previous settings\n    No, customize settings - Choose your own preferences\n\nIf you choose to customize settings, you'll see the following prompts:\n\nTerminal\nWould you like to use TypeScript? No / Yes\nWhich linter would you like to use? ESLint / Biome / None\nWould you like to use React Compiler? No / Yes\nWould you like to use Tailwind CSS? No / Yes\nWould you like your code inside a `src/` directory? No / Yes\nWould you like to use App Router? (recommended) No / Yes\nWould you like to use Turbopack? (recommended) No / Yes\nWould you like to customize the import alias (`@/*` by default)? No / Yes\nWhat import alias would you like configured? @/*\n\nAfter the prompts, create-next-app will create a folder with your project name and install the required dependencies.\n\nLinter Options\n\nESLint: The traditional and most popular JavaScript linter. Includes Next.js-specific rules from @next/eslint-plugin-next.\n\nBiome: A fast, modern linter and formatter that combines the functionality of ESLint and Prettier. Includes built-in Next.js and React domain support for optimal performance.\n\nNone: Skip linter configuration entirely. You can always add a linter later.\n\nOnce you've answered the prompts, a new project will be created with your chosen configuration.\n\nWith an official Next.js example\n\nTo create a new app using an official Next.js example, use the --example flag. For example:\n\nTerminal\nnpx create-next-app@latest --example [example-name] [your-project-name]\n\nYou can view a list of all available examples along with setup instructions in the Next.js repository\n.\n\nWith any public GitHub example\n\nTo create a new app using any public GitHub example, use the --example option with the GitHub repo's URL. For example:\n\nTerminal\nnpx create-next-app@latest --example \"https://github.com/.../\" [your-project-name]\nPrevious\nCLI\nNext\nnext CLI\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "CLI: next CLI | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/cli/next",
    "html": "API Reference\nCLI\nnext CLI\nCopy page\nnext CLI\n\nThe Next.js CLI allows you to develop, build, start your application, and more.\n\nBasic usage:\n\nTerminal\nnpx next [command] [options]\nReference\n\nThe following options are available:\n\nOptions\tDescription\n-h or --help\tShows all available options\n-v or --version\tOutputs the Next.js version number\nCommands\n\nThe following commands are available:\n\nCommand\tDescription\ndev\tStarts Next.js in development mode with Hot Module Reloading, error reporting, and more.\nbuild\tCreates an optimized production build of your application. Displaying information about each route.\nstart\tStarts Next.js in production mode. The application should be compiled with next build first.\ninfo\tPrints relevant details about the current system which can be used to report Next.js bugs.\ntelemetry\tAllows you to enable or disable Next.js' completely anonymous telemetry collection.\ntypegen\tGenerates TypeScript definitions for routes, pages, layouts, and route handlers without running a full build.\n\nGood to know: Running next without a command is an alias for next dev.\n\nnext dev options\n\nnext dev starts the application in development mode with Hot Module Reloading (HMR), error reporting, and more. The following options are available when running next dev:\n\nOption\tDescription\n-h, --help\tShow all available options.\n[directory]\tA directory in which to build the application. If not provided, current directory is used.\n--turbopack\tForce enable Turbopack (enabled by default). Also available as --turbo.\n--webpack\tUse Webpack instead of the default Turbopack bundler for development.\n-p or --port <port>\tSpecify a port number on which to start the application. Default: 3000, env: PORT\n-Hor --hostname <hostname>\tSpecify a hostname on which to start the application. Useful for making the application available for other devices on the network. Default: 0.0.0.0\n--experimental-https\tStarts the server with HTTPS and generates a self-signed certificate.\n--experimental-https-key <path>\tPath to a HTTPS key file.\n--experimental-https-cert <path>\tPath to a HTTPS certificate file.\n--experimental-https-ca <path>\tPath to a HTTPS certificate authority file.\n--experimental-upload-trace <traceUrl>\tReports a subset of the debugging trace to a remote HTTP URL.\nnext build options\n\nnext build creates an optimized production build of your application. The output displays information about each route. For example:\n\nTerminal\nRoute (app)\n┌ ○ /_not-found\n└ ƒ /products/[id]\n \n○  (Static)   prerendered as static content\nƒ  (Dynamic)  server-rendered on demand\n\nThe following options are available for the next build command:\n\nOption\tDescription\n-h, --help\tShow all available options.\n[directory]\tA directory on which to build the application. If not provided, the current directory will be used.\n--turbopack\tForce enable Turbopack (enabled by default). Also available as --turbo.\n--webpack\tBuild using Webpack.\n-d or --debug\tEnables a more verbose build output. With this flag enabled additional build output like rewrites, redirects, and headers will be shown.\n\t\n--profile\tEnables production profiling for React\n.\n--no-lint\tDisables linting. Note: linting will be removed from next build in Next 16. If you're using Next 15.5+ with a linter other than eslint, linting during build will not occur.\n--no-mangling\tDisables mangling\n. This may affect performance and should only be used for debugging purposes.\n--experimental-app-only\tBuilds only App Router routes.\n--experimental-build-mode [mode]\tUses an experimental build mode. (choices: \"compile\", \"generate\", default: \"default\")\n--debug-prerender\tDebug prerender errors in development.\n--debug-build-paths=<patterns>\tBuild only specific routes for debugging.\nnext start options\n\nnext start starts the application in production mode. The application should be compiled with next build first.\n\nThe following options are available for the next start command:\n\nOption\tDescription\n-h or --help\tShow all available options.\n[directory]\tA directory on which to start the application. If no directory is provided, the current directory will be used.\n-p or --port <port>\tSpecify a port number on which to start the application. (default: 3000, env: PORT)\n-H or --hostname <hostname>\tSpecify a hostname on which to start the application (default: 0.0.0.0).\n--keepAliveTimeout <keepAliveTimeout>\tSpecify the maximum amount of milliseconds to wait before closing the inactive connections.\nnext info options\n\nnext info prints relevant details about the current system which can be used to report Next.js bugs when opening a GitHub issue\n. This information includes Operating System platform/arch/version, Binaries (Node.js, npm, Yarn, pnpm), package versions (next, react, react-dom), and more.\n\nThe output should look like this:\n\nTerminal\nOperating System:\n  Platform: darwin\n  Arch: arm64\n  Version: Darwin Kernel Version 23.6.0\n  Available memory (MB): 65536\n  Available CPU cores: 10\nBinaries:\n  Node: 20.12.0\n  npm: 10.5.0\n  Yarn: 1.22.19\n  pnpm: 9.6.0\nRelevant Packages:\n  next: 15.0.0-canary.115 // Latest available version is detected (15.0.0-canary.115).\n  eslint-config-next: 14.2.5\n  react: 19.0.0-rc\n  react-dom: 19.0.0\n  typescript: 5.5.4\nNext.js Config:\n  output: N/A\n\nThe following options are available for the next info command:\n\nOption\tDescription\n-h or --help\tShow all available options\n--verbose\tCollects additional information for debugging.\nnext telemetry options\n\nNext.js collects completely anonymous telemetry data about general usage. Participation in this anonymous program is optional, and you can opt-out if you prefer not to share information.\n\nThe following options are available for the next telemetry command:\n\nOption\tDescription\n-h, --help\tShow all available options.\n--enable\tEnables Next.js' telemetry collection.\n--disable\tDisables Next.js' telemetry collection.\n\nLearn more about Telemetry.\n\nnext typegen Options\n\nnext typegen generates TypeScript definitions for your application's routes without performing a full build. This is useful for IDE autocomplete and CI type-checking of route usage.\n\nPreviously, route types were only generated during next dev or next build, which meant running tsc --noEmit directly wouldn't validate your route types. Now you can generate types independently and validate them externally:\n\nTerminal\n# Generate route types first, then validate with TypeScript\nnext typegen && tsc --noEmit\n \n# Or in CI workflows for type checking without building\nnext typegen && npm run type-check\n\nThe following options are available for the next typegen command:\n\nOption\tDescription\n-h, --help\tShow all available options.\n[directory]\tA directory on which to generate types. If not provided, the current directory will be used.\n\nOutput files are written to <distDir>/types (typically: .next/dev/types or .next/types, see isolatedDevBuild):\n\nTerminal\nnext typegen\n# or for a specific app\nnext typegen ./apps/web\n\nAdditionally, next typegen generates a next-env.d.ts file. We recommend adding next-env.d.ts to your .gitignore file.\n\nThe next-env.d.ts file is included into your tsconfig.json file, to make Next.js types available to your project.\n\nTo ensure next-env.d.ts is present before type-checking run next typegen. The commands next dev and next build also generate the next-env.d.ts file, but it is often undesirable to run these just to type-check, for example in CI/CD environments.\n\nGood to know: next typegen loads your Next.js config (next.config.js, next.config.mjs, or next.config.ts) using the production build phase. Ensure any required environment variables and dependencies are available so the config can load correctly.\n\nExamples\nDebugging prerender errors\n\nIf you encounter prerendering errors during next build, you can pass the --debug-prerender flag to get more detailed output:\n\nTerminal\nnext build --debug-prerender\n\nThis enables several experimental options to make debugging easier:\n\nDisables server code minification:\nexperimental.serverMinification = false\nexperimental.turbopackMinify = false\nGenerates source maps for server bundles:\nexperimental.serverSourceMaps = true\nEnables source map consumption in child processes used for prerendering:\nenablePrerenderSourceMaps = true\nContinues building even after the first prerender error, so you can see all issues at once:\nexperimental.prerenderEarlyExit = false\n\nThis helps surface more readable stack traces and code frames in the build output.\n\nWarning: --debug-prerender is for debugging in development only. Do not deploy builds generated with --debug-prerender to production, as it may impact performance.\n\nBuilding specific routes\n\nYou can build only specific routes in the App and Pages Routers using the --debug-build-paths option. This is useful for faster debugging when working with large applications. The --debug-build-paths option accepts comma-separated file paths and supports glob patterns:\n\nTerminal\n# Build a specific route\nnext build --debug-build-paths=\"app/page.tsx\"\n \n# Build more than one route\nnext build --debug-build-paths=\"app/page.tsx,pages/index.tsx\"\n \n# Use glob patterns\nnext build --debug-build-paths=\"app/**/page.tsx\"\nnext build --debug-build-paths=\"pages/*.tsx\"\nChanging the default port\n\nBy default, Next.js uses http://localhost:3000 during development and with next start. The default port can be changed with the -p option, like so:\n\nTerminal\nnext dev -p 4000\n\nOr using the PORT environment variable:\n\nTerminal\nPORT=4000 next dev\n\nGood to know: PORT cannot be set in .env as booting up the HTTP server happens before any other code is initialized.\n\nUsing HTTPS during development\n\nFor certain use cases like webhooks or authentication, you can use HTTPS\n to have a secure environment on localhost. Next.js can generate a self-signed certificate with next dev using the --experimental-https flag:\n\nTerminal\nnext dev --experimental-https\n\nWith the generated certificate, the Next.js development server will exist at https://localhost:3000. The default port 3000 is used unless a port is specified with -p, --port, or PORT.\n\nYou can also provide a custom certificate and key with --experimental-https-key and --experimental-https-cert. Optionally, you can provide a custom CA certificate with --experimental-https-ca as well.\n\nTerminal\nnext dev --experimental-https --experimental-https-key ./certificates/localhost-key.pem --experimental-https-cert ./certificates/localhost.pem\n\nnext dev --experimental-https is only intended for development and creates a locally trusted certificate with mkcert\n. In production, use properly issued certificates from trusted authorities.\n\nConfiguring a timeout for downstream proxies\n\nWhen deploying Next.js behind a downstream proxy (e.g. a load-balancer like AWS ELB/ALB), it's important to configure Next's underlying HTTP server with keep-alive timeouts\n that are larger than the downstream proxy's timeouts. Otherwise, once a keep-alive timeout is reached for a given TCP connection, Node.js will immediately terminate that connection without notifying the downstream proxy. This results in a proxy error whenever it attempts to reuse a connection that Node.js has already terminated.\n\nTo configure the timeout values for the production Next.js server, pass --keepAliveTimeout (in milliseconds) to next start, like so:\n\nTerminal\nnext start --keepAliveTimeout 70000\nPassing Node.js arguments\n\nYou can pass any node arguments\n to next commands. For example:\n\nTerminal\nNODE_OPTIONS='--throw-deprecation' next\nNODE_OPTIONS='-r esm' next\nNODE_OPTIONS='--inspect' next\nVersion\tChanges\nv16.0.0\tThe JS bundle size metrics have been removed from next build\nv15.5.0\tAdd the next typegen command\nv15.4.0\tAdd --debug-prerender option for next build to help debug prerender errors.\nPrevious\ncreate-next-app\nNext\nEdge Runtime\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "API Reference: Edge Runtime | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/edge",
    "html": "App Router\nAPI Reference\nEdge Runtime\nCopy page\nEdge Runtime\n\nNext.js has two server runtimes you can use in your application:\n\nThe Node.js Runtime (default), which has access to all Node.js APIs and is used for rendering your application.\nThe Edge Runtime which contains a more limited set of APIs, used in Proxy.\nCaveats\nThe Edge Runtime does not support all Node.js APIs. Some packages may not work as expected.\nThe Edge Runtime does not support Incremental Static Regeneration (ISR).\nBoth runtimes can support streaming depending on your deployment adapter.\nReference\n\nThe Edge Runtime supports the following APIs:\n\nNetwork APIs\nAPI\tDescription\nBlob\n\tRepresents a blob\nfetch\n\tFetches a resource\nFetchEvent\n\tRepresents a fetch event\nFile\n\tRepresents a file\nFormData\n\tRepresents form data\nHeaders\n\tRepresents HTTP headers\nRequest\n\tRepresents an HTTP request\nResponse\n\tRepresents an HTTP response\nURLSearchParams\n\tRepresents URL search parameters\nWebSocket\n\tRepresents a websocket connection\nEncoding APIs\nAPI\tDescription\natob\n\tDecodes a base-64 encoded string\nbtoa\n\tEncodes a string in base-64\nTextDecoder\n\tDecodes a Uint8Array into a string\nTextDecoderStream\n\tChainable decoder for streams\nTextEncoder\n\tEncodes a string into a Uint8Array\nTextEncoderStream\n\tChainable encoder for streams\nStream APIs\nAPI\tDescription\nReadableStream\n\tRepresents a readable stream\nReadableStreamBYOBReader\n\tRepresents a reader of a ReadableStream\nReadableStreamDefaultReader\n\tRepresents a reader of a ReadableStream\nTransformStream\n\tRepresents a transform stream\nWritableStream\n\tRepresents a writable stream\nWritableStreamDefaultWriter\n\tRepresents a writer of a WritableStream\nCrypto APIs\nAPI\tDescription\ncrypto\n\tProvides access to the cryptographic functionality of the platform\nCryptoKey\n\tRepresents a cryptographic key\nSubtleCrypto\n\tProvides access to common cryptographic primitives, like hashing, signing, encryption or decryption\nWeb Standard APIs\nAPI\tDescription\nAbortController\n\tAllows you to abort one or more DOM requests as and when desired\nArray\n\tRepresents an array of values\nArrayBuffer\n\tRepresents a generic, fixed-length raw binary data buffer\nAtomics\n\tProvides atomic operations as static methods\nBigInt\n\tRepresents a whole number with arbitrary precision\nBigInt64Array\n\tRepresents a typed array of 64-bit signed integers\nBigUint64Array\n\tRepresents a typed array of 64-bit unsigned integers\nBoolean\n\tRepresents a logical entity and can have two values: true and false\nclearInterval\n\tCancels a timed, repeating action which was previously established by a call to setInterval()\nclearTimeout\n\tCancels a timed, repeating action which was previously established by a call to setTimeout()\nconsole\n\tProvides access to the browser's debugging console\nDataView\n\tRepresents a generic view of an ArrayBuffer\nDate\n\tRepresents a single moment in time in a platform-independent format\ndecodeURI\n\tDecodes a Uniform Resource Identifier (URI) previously created by encodeURI or by a similar routine\ndecodeURIComponent\n\tDecodes a Uniform Resource Identifier (URI) component previously created by encodeURIComponent or by a similar routine\nDOMException\n\tRepresents an error that occurs in the DOM\nencodeURI\n\tEncodes a Uniform Resource Identifier (URI) by replacing each instance of certain characters by one, two, three, or four escape sequences representing the UTF-8 encoding of the character\nencodeURIComponent\n\tEncodes a Uniform Resource Identifier (URI) component by replacing each instance of certain characters by one, two, three, or four escape sequences representing the UTF-8 encoding of the character\nError\n\tRepresents an error when trying to execute a statement or accessing a property\nEvalError\n\tRepresents an error that occurs regarding the global function eval()\nFloat32Array\n\tRepresents a typed array of 32-bit floating point numbers\nFloat64Array\n\tRepresents a typed array of 64-bit floating point numbers\nFunction\n\tRepresents a function\nInfinity\n\tRepresents the mathematical Infinity value\nInt8Array\n\tRepresents a typed array of 8-bit signed integers\nInt16Array\n\tRepresents a typed array of 16-bit signed integers\nInt32Array\n\tRepresents a typed array of 32-bit signed integers\nIntl\n\tProvides access to internationalization and localization functionality\nisFinite\n\tDetermines whether a value is a finite number\nisNaN\n\tDetermines whether a value is NaN or not\nJSON\n\tProvides functionality to convert JavaScript values to and from the JSON format\nMap\n\tRepresents a collection of values, where each value may occur only once\nMath\n\tProvides access to mathematical functions and constants\nNumber\n\tRepresents a numeric value\nObject\n\tRepresents the object that is the base of all JavaScript objects\nparseFloat\n\tParses a string argument and returns a floating point number\nparseInt\n\tParses a string argument and returns an integer of the specified radix\nPromise\n\tRepresents the eventual completion (or failure) of an asynchronous operation, and its resulting value\nProxy\n\tRepresents an object that is used to define custom behavior for fundamental operations (e.g. property lookup, assignment, enumeration, function invocation, etc)\nqueueMicrotask\n\tQueues a microtask to be executed\nRangeError\n\tRepresents an error when a value is not in the set or range of allowed values\nReferenceError\n\tRepresents an error when a non-existent variable is referenced\nReflect\n\tProvides methods for interceptable JavaScript operations\nRegExp\n\tRepresents a regular expression, allowing you to match combinations of characters\nSet\n\tRepresents a collection of values, where each value may occur only once\nsetInterval\n\tRepeatedly calls a function, with a fixed time delay between each call\nsetTimeout\n\tCalls a function or evaluates an expression after a specified number of milliseconds\nSharedArrayBuffer\n\tRepresents a generic, fixed-length raw binary data buffer\nString\n\tRepresents a sequence of characters\nstructuredClone\n\tCreates a deep copy of a value\nSymbol\n\tRepresents a unique and immutable data type that is used as the key of an object property\nSyntaxError\n\tRepresents an error when trying to interpret syntactically invalid code\nTypeError\n\tRepresents an error when a value is not of the expected type\nUint8Array\n\tRepresents a typed array of 8-bit unsigned integers\nUint8ClampedArray\n\tRepresents a typed array of 8-bit unsigned integers clamped to 0-255\nUint32Array\n\tRepresents a typed array of 32-bit unsigned integers\nURIError\n\tRepresents an error when a global URI handling function was used in a wrong way\nURL\n\tRepresents an object providing static methods used for creating object URLs\nURLPattern\n\tRepresents a URL pattern\nURLSearchParams\n\tRepresents a collection of key/value pairs\nWeakMap\n\tRepresents a collection of key/value pairs in which the keys are weakly referenced\nWeakSet\n\tRepresents a collection of objects in which each object may occur only once\nWebAssembly\n\tProvides access to WebAssembly\nNext.js Specific Polyfills\nAsyncLocalStorage\nEnvironment Variables\n\nYou can use process.env to access Environment Variables for both next dev and next build.\n\nUnsupported APIs\n\nThe Edge Runtime has some restrictions including:\n\nNative Node.js APIs are not supported. For example, you can't read or write to the filesystem.\nnode_modules can be used, as long as they implement ES Modules and do not use native Node.js APIs.\nCalling require directly is not allowed. Use ES Modules instead.\n\nThe following JavaScript language features are disabled, and will not work:\n\nAPI\tDescription\neval\n\tEvaluates JavaScript code represented as a string\nnew Function(evalString)\n\tCreates a new function with the code provided as an argument\nWebAssembly.compile\n\tCompiles a WebAssembly module from a buffer source\nWebAssembly.instantiate\n\tCompiles and instantiates a WebAssembly module from a buffer source\n\nIn rare cases, your code could contain (or import) some dynamic code evaluation statements which can not be reached at runtime and which can not be removed by treeshaking. You can relax the check to allow specific files with your Proxy configuration:\n\nproxy.ts\nexport const config = {\n  unstable_allowDynamic: [\n    // allows a single file\n    '/lib/utilities.js',\n    // use a glob to allow anything in the function-bind 3rd party module\n    '**/node_modules/function-bind/**',\n  ],\n}\n\nunstable_allowDynamic is a glob\n, or an array of globs, ignoring dynamic code evaluation for specific files. The globs are relative to your application root folder.\n\nBe warned that if these statements are executed on the Edge, they will throw and cause a runtime error.\n\nPrevious\nnext CLI\nNext\nTurbopack\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "API Reference: Turbopack | Next.js",
    "url": "https://nextjs.org/docs/app/api-reference/turbopack",
    "html": "App Router\nAPI Reference\nTurbopack\nCopy page\nTurbopack\n\nTurbopack is an incremental bundler optimized for JavaScript and TypeScript, written in Rust, and built into Next.js. You can use Turbopack with both the Pages and App Router for a much faster local development experience.\n\nWhy Turbopack?\n\nWe built Turbopack to push the performance of Next.js, including:\n\nUnified Graph: Next.js supports multiple output environments (e.g., client and server). Managing multiple compilers and stitching bundles together can be tedious. Turbopack uses a single, unified graph for all environments.\nBundling vs Native ESM: Some tools skip bundling in development and rely on the browser's native ESM. This works well for small apps but can slow down large apps due to excessive network requests. Turbopack bundles in dev, but in an optimized way to keep large apps fast.\nIncremental Computation: Turbopack parallelizes work across cores and caches results down to the function level. Once a piece of work is done, Turbopack won’t repeat it.\nLazy Bundling: Turbopack only bundles what is actually requested by the dev server. This lazy approach can reduce initial compile times and memory usage.\nGetting started\n\nTurbopack is now the default bundler in Next.js. No configuration is needed to use Turbopack:\n\npackage.json\n{\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"next build\",\n    \"start\": \"next start\"\n  }\n}\nUsing Webpack instead\n\nIf you need to use Webpack instead of Turbopack, you can opt-in with the --webpack flag:\n\npackage.json\n{\n  \"scripts\": {\n    \"dev\": \"next dev --webpack\",\n    \"build\": \"next build --webpack\",\n    \"start\": \"next start\"\n  }\n}\nSupported features\n\nTurbopack in Next.js has zero-configuration for the common use cases. Below is a summary of what is supported out of the box, plus some references to how you can configure Turbopack further when needed.\n\nLanguage features\nFeature\tStatus\tNotes\nJavaScript & TypeScript\tSupported\tUses SWC under the hood. Type-checking is not done by Turbopack (run tsc --watch or rely on your IDE for type checks).\nECMAScript (ESNext)\tSupported\tTurbopack supports the latest ECMAScript features, matching SWC’s coverage.\nCommonJS\tSupported\trequire() syntax is handled out of the box.\nESM\tSupported\tStatic and dynamic import are fully supported.\nBabel\tSupported\tStarting in Next.js 16, Turbopack uses Babel automatically if it detects a configuration file\n. Unlike in webpack, SWC is always used for Next.js's internal transforms and downleveling to older ECMAScript revisions. Next.js with webpack disables SWC if a Babel configuration file is present. Files in node_modules are excluded, unless you manually configure babel-loader.\nFramework and React features\nFeature\tStatus\tNotes\nJSX / TSX\tSupported\tSWC handles JSX/TSX compilation.\nFast Refresh\tSupported\tNo configuration needed.\nReact Server Components (RSC)\tSupported\tFor the Next.js App Router. Turbopack ensures correct server/client bundling.\nRoot layout creation\tUnsupported\tAutomatic creation of a root layout in App Router is not supported. Turbopack will instruct you to create it manually.\nCSS and styling\nFeature\tStatus\tNotes\nGlobal CSS\tSupported\tImport .css files directly in your application.\nCSS Modules\tSupported\t.module.css files work natively (Lightning CSS).\nCSS Nesting\tSupported\tLightning CSS supports modern CSS nesting\n.\n@import syntax\tSupported\tCombine multiple CSS files.\nPostCSS\tSupported\tAutomatically processes postcss.config.js in a Node.js worker pool. Useful for Tailwind, Autoprefixer, etc.\nSass / SCSS\tSupported (Next.js)\tFor Next.js, Sass is supported out of the box. Custom Sass functions (sassOptions.functions) are not supported because Turbopack's Rust-based architecture cannot directly execute JavaScript functions, unlike webpack's Node.js environment. Use webpack if you need this feature. In the future, Turbopack standalone usage will likely require a loader config.\nLess\tPlanned via plugins\tNot yet supported by default. Will likely require a loader config once custom loaders are stable.\nLightning CSS\tIn Use\tHandles CSS transformations. Some low-usage CSS Modules features (like :local/:global as standalone pseudo-classes) are not yet supported. See below for more details.\nAssets\nFeature\tStatus\tNotes\nStatic Assets (images, fonts)\tSupported\tImporting import img from './img.png' works out of the box. In Next.js, returns an object for the <Image /> component.\nJSON Imports\tSupported\tNamed or default imports from .json are supported.\nModule resolution\nFeature\tStatus\tNotes\nPath Aliases\tSupported\tReads tsconfig.json's paths and baseUrl, matching Next.js behavior.\nManual Aliases\tSupported\tConfigure resolveAlias in next.config.js (similar to webpack.resolve.alias).\nCustom Extensions\tSupported\tConfigure resolveExtensions in next.config.js.\nAMD\tPartially Supported\tBasic transforms work; advanced AMD usage is limited.\nPerformance and Fast Refresh\nFeature\tStatus\tNotes\nFast Refresh\tSupported\tUpdates JavaScript, TypeScript, and CSS without a full refresh.\nIncremental Bundling\tSupported\tTurbopack lazily builds only what’s requested by the dev server, speeding up large apps.\nKnown gaps with webpack\n\nThere are a number of non-trivial behavior differences between webpack and Turbopack that are important to be aware of when migrating an application. Generally, these are less of a concern for new applications.\n\nCSS Module Ordering\n\nTurbopack will follow JS import order to order CSS modules which are not otherwise ordered. For example:\n\ncomponents/BlogPost.jsx\nimport utilStyles from './utils.module.css'\nimport buttonStyles from './button.module.css'\nexport default function BlogPost() {\n  return (\n    <div className={utilStyles.container}>\n      <button className={buttonStyles.primary}>Click me</button>\n    </div>\n  )\n}\n\nIn this example, Turbopack will ensure that utils.module.css will appear before button.module.css in the produced CSS chunk, following the import order\n\nWebpack generally does this as well, but there are cases where it will ignore JS inferred ordering, for example if it infers the JS file is side-effect-free.\n\nThis can lead to subtle rendering changes when adopting Turbopack, if applications have come to rely on an arbitrary ordering. Generally, the solution is easy, e.g. have button.module.css @import utils.module.css to force the ordering, or identify the conflicting rules and change them to not target the same properties.\n\nSass node_modules imports\n\nTurbopack supports importing node_modules Sass files out of the box. Webpack supports a legacy tilde ~ syntax for this, which is not supported by Turbopack.\n\nFrom:\n\nstyles/globals.scss\n@import '~bootstrap/dist/css/bootstrap.min.css';\n\nTo:\n\nstyles/globals.scss\n@import 'bootstrap/dist/css/bootstrap.min.css';\n\nIf you can't update the imports, you can add a turbopack.resolveAlias configuration to map the ~ syntax to the actual path:\n\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    resolveAlias: {\n      '~*': '*',\n    },\n  },\n}\nBundle Sizes\n\nFrom our testing on production applications, we observed that Turbopack generally produces bundles that are similar in size to Webpack. However, the comparison can be difficult since turbopack tends to produce fewer but larger chunks. Our advice is to focus on higher level metrics like Core Web Vitals\n or your own application level metrics to compare performance across the two bundlers. We are however aware of one gap that can occasionally cause a large regression.\n\nTurbopack does not yet have an equivalent to the Inner Graph Optimization\n in webpack which is enabled by default. This optimization is useful to tree shake large modules. For example:\n\nimport heavy from 'some-heavy-dependency.js'\n \nexport function usesHeavy() {\n  return heavy.run()\n}\n \nexport const CONSTANT_VALUE = 3\n\nIf an application only uses CONSTANT_VALUE Turbopack will detect this and delete the usesHeavy export but not the corresponding import. However, with the Inner Graph Optimization, webpack can delete the import too which can drop the dependency as well.\n\nWe are planning to offer an equivalent to the Inner Graph Optimization in Turbopack but it is still under development. If you are affected by this gap, consider manually splitting modules.\n\nBuild Caching\n\nWebpack supports disk build caching\n to improve build performance. Turbopack provides a similar opt-in feature, currently in beta. Starting with Next 16, you can enable Turbopack’s filesystem cache by setting the following experimental flags:\n\nexperimental.turbopackFileSystemCacheForDev\nexperimental.turbopackFileSystemCacheForBuild\n\nGood to know: For this reason, when comparing webpack and Turbopack performance, make sure to delete the .next folder between builds to see a fair comparison or enable the turbopack filesystem cache feature.\n\nWebpack plugins\n\nTurbopack does not support webpack plugins. This affects third-party tools that rely on webpack's plugin system for integration. We do support webpack loaders. If you depend on webpack plugins, you'll need to find Turbopack-compatible alternatives or continue using webpack until equivalent functionality is available.\n\nUnsupported and unplanned features\n\nSome features are not yet implemented or not planned:\n\nLegacy CSS Modules features\nStandalone :local and :global pseudo-classes (only the function variant :global(...) is supported).\nThe @value rule (superseded by CSS variables).\n:import and :export ICSS rules.\ncomposes in .module.css composing a .css file. In webpack this would treat the .css file as a CSS Module, with Turbopack the .css file will always be global. This means that if you want to use composes in a CSS Module, you need to change the .css file to a .module.css file.\n@import in CSS Modules importing .css as a CSS Module. In webpack this would treat the .css file as a CSS Module, with Turbopack the .css file will always be global. This means that if you want to use @import in a CSS Module, you need to change the .css file to a .module.css file.\nsassOptions.functions Custom Sass functions defined in sassOptions.functions are not supported. This feature allows defining JavaScript functions that can be called from Sass code during compilation. Turbopack's Rust-based architecture cannot directly execute JavaScript functions passed through sassOptions.functions, unlike webpack's Node.js-based sass-loader which runs entirely in JavaScript. If you're using custom Sass functions, you'll need to use webpack instead of Turbopack.\nwebpack() configuration in next.config.js Turbopack replaces webpack, so webpack() configs are not recognized. Use the turbopack config instead.\nYarn PnP Not planned for Turbopack support in Next.js.\nexperimental.urlImports Not planned for Turbopack.\nexperimental.esmExternals Not planned. Turbopack does not support the legacy esmExternals configuration in Next.js.\nSome Next.js Experimental Flags\nexperimental.nextScriptWorkers\nexperimental.sri.algorithm\nexperimental.fallbackNodePolyfills We plan to implement these in the future.\n\nFor a full, detailed breakdown of each feature flag and its status, see the Turbopack API Reference.\n\nConfiguration\n\nTurbopack can be configured via next.config.js (or next.config.ts) under the turbopack key. Configuration options include:\n\nrules Define additional webpack loaders for file transformations.\nresolveAlias Create manual aliases (like resolve.alias in webpack).\nresolveExtensions Change or extend file extensions for module resolution.\nnext.config.js\nmodule.exports = {\n  turbopack: {\n    // Example: adding an alias and custom file extension\n    resolveAlias: {\n      underscore: 'lodash',\n    },\n    resolveExtensions: ['.mdx', '.tsx', '.ts', '.jsx', '.js', '.json'],\n  },\n}\n\nFor more in-depth configuration examples, see the Turbopack config documentation.\n\nGenerating trace files for performance debugging\n\nIf you encounter performance or memory issues and want to help the Next.js team diagnose them, you can generate a trace file by appending NEXT_TURBOPACK_TRACING=1 to your dev command:\n\nNEXT_TURBOPACK_TRACING=1 next dev\n\nThis will produce a .next/dev/trace-turbopack file. Include that file when creating a GitHub issue on the Next.js repo\n to help us investigate.\n\nBy default the development server outputs to .next/dev. Read more about isolatedDevBuild.\n\nSummary\n\nTurbopack is a Rust-based, incremental bundler designed to make local development and builds fast—especially for large applications. It is integrated into Next.js, offering zero-config CSS, React, and TypeScript support.\n\nVersion Changes\nVersion\tChanges\nv16.0.0\tTurbopack becomes the default bundler for Next.js. Automatic support for Babel when a configuration file is found.\nv15.5.0\tTurbopack support for build beta\nv15.3.0\tExperimental support for build\nv15.0.0\tTurbopack for dev stable\nPrevious\nEdge Runtime\nNext\nPages Router\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Metadata and OG images | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/metadata-and-og-images",
    "html": "App Router\nGetting Started\nMetadata and OG images\nCopy page\nMetadata and OG images\n\nThe Metadata APIs can be used to define your application metadata for improved SEO and web shareability and include:\n\nThe static metadata object\nThe dynamic generateMetadata function\nSpecial file conventions that can be used to add static or dynamically generated favicons and OG images.\n\nWith all the options above, Next.js will automatically generate the relevant <head> tags for your page, which can be inspected in the browser's developer tools.\n\nThe metadata object and generateMetadata function exports are only supported in Server Components.\n\nDefault fields\n\nThere are two default meta tags that are always added even if a route doesn't define metadata:\n\nThe meta charset tag\n sets the character encoding for the website.\nThe meta viewport tag\n sets the viewport width and scale for the website to adjust for different devices.\n<meta charset=\"utf-8\" />\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\nThe other metadata fields can be defined with the Metadata object (for static metadata) or the generateMetadata function (for generated metadata).\n\nStatic metadata\n\nTo define static metadata, export a Metadata object from a static layout.js or page.js file. For example, to add a title and description to the blog route:\n\napp/blog/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: 'My Blog',\n  description: '...',\n}\n \nexport default function Layout() {}\n\nYou can view a full list of available options, in the generateMetadata documentation.\n\nGenerated metadata\n\nYou can use generateMetadata function to fetch metadata that depends on data. For example, to fetch the title and description for a specific blog post:\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata, ResolvingMetadata } from 'next'\n \ntype Props = {\n  params: Promise<{ slug: string }>\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}\n \nexport async function generateMetadata(\n  { params, searchParams }: Props,\n  parent: ResolvingMetadata\n): Promise<Metadata> {\n  const slug = (await params).slug\n \n  // fetch post information\n  const post = await fetch(`https://api.vercel.app/blog/${slug}`).then((res) =>\n    res.json()\n  )\n \n  return {\n    title: post.title,\n    description: post.description,\n  }\n}\n \nexport default function Page({ params, searchParams }: Props) {}\nStreaming metadata\n\nFor dynamically rendered pages, Next.js streams metadata separately, injecting it into the HTML once generateMetadata resolves, without blocking UI rendering.\n\nStreaming metadata improves perceived performance by allowing visual content to stream first.\n\nStreaming metadata is disabled for bots and crawlers that expect metadata to be in the <head> tag (e.g. Twitterbot, Slackbot, Bingbot). These are detected by using the User Agent header from the incoming request.\n\nYou can customize or disable streaming metadata completely, with the htmlLimitedBots option in your Next.js config file.\n\nStatically rendered pages don’t use streaming since metadata is resolved at build time.\n\nLearn more about streaming metadata.\n\nMemoizing data requests\n\nThere may be cases where you need to fetch the same data for metadata and the page itself. To avoid duplicate requests, you can use React's cache function\n to memoize the return value and only fetch the data once. For example, to fetch the blog post information for both the metadata and the page:\n\napp/lib/data.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cache } from 'react'\nimport { db } from '@/app/lib/db'\n \n// getPost will be used twice, but execute only once\nexport const getPost = cache(async (slug: string) => {\n  const res = await db.query.posts.findFirst({ where: eq(posts.slug, slug) })\n  return res\n})\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getPost } from '@/app/lib/data'\n \nexport async function generateMetadata({\n  params,\n}: {\n  params: { slug: string }\n}) {\n  const post = await getPost(params.slug)\n  return {\n    title: post.title,\n    description: post.description,\n  }\n}\n \nexport default async function Page({ params }: { params: { slug: string } }) {\n  const post = await getPost(params.slug)\n  return <div>{post.title}</div>\n}\nFile-based metadata\n\nThe following special files are available for metadata:\n\nfavicon.ico, apple-icon.jpg, and icon.jpg\nopengraph-image.jpg and twitter-image.jpg\nrobots.txt\nsitemap.xml\n\nYou can use these for static metadata, or you can programmatically generate these files with code.\n\nFavicons\n\nFavicons are small icons that represent your site in bookmarks and search results. To add a favicon to your application, create a favicon.ico and add to the root of the app folder.\n\nYou can also programmatically generate favicons using code. See the favicon docs for more information.\n\nStatic Open Graph images\n\nOpen Graph (OG) images are images that represent your site in social media. To add a static OG image to your application, create a opengraph-image.png file in the root of the app folder.\n\nYou can also add OG images for specific routes by creating a opengraph-image.png deeper down the folder structure. For example, to create an OG image specific to the /blog route, add a opengraph-image.jpg file inside the blog folder.\n\nThe more specific image will take precedence over any OG images above it in the folder structure.\n\nOther image formats such as jpeg, png, and gif are also supported. See the Open Graph Image docs for more information.\n\nGenerated Open Graph images\n\nThe ImageResponse constructor allows you to generate dynamic images using JSX and CSS. This is useful for OG images that depend on data.\n\nFor example, to generate a unique OG image for each blog post, add a opengraph-image.tsx file inside the blog folder, and import the ImageResponse constructor from next/og:\n\napp/blog/[slug]/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\nimport { getPost } from '@/app/lib/data'\n \n// Image metadata\nexport const size = {\n  width: 1200,\n  height: 630,\n}\n \nexport const contentType = 'image/png'\n \n// Image generation\nexport default async function Image({ params }: { params: { slug: string } }) {\n  const post = await getPost(params.slug)\n \n  return new ImageResponse(\n    (\n      // ImageResponse JSX element\n      <div\n        style={{\n          fontSize: 128,\n          background: 'white',\n          width: '100%',\n          height: '100%',\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n        }}\n      >\n        {post.title}\n      </div>\n    )\n  )\n}\n\nImageResponse supports common CSS properties including flexbox and absolute positioning, custom fonts, text wrapping, centering, and nested images. See the full list of supported CSS properties.\n\nGood to know:\n\nExamples are available in the Vercel OG Playground\n.\nImageResponse uses @vercel/og\n, satori\n, and resvg to convert HTML and CSS into PNG.\nOnly flexbox and a subset of CSS properties are supported. Advanced layouts (e.g. display: grid) will not work.\nAPI Reference\nLearn more about the Metadata APIs mentioned in this page.\ngenerateMetadata\nLearn how to add Metadata to your Next.js application for improved search engine optimization (SEO) and web shareability.\ngenerateViewport\nAPI Reference for the generateViewport function.\nImageResponse\nAPI Reference for the ImageResponse constructor.\nMetadata Files\nAPI documentation for the metadata file conventions.\nfavicon, icon, and apple-icon\nAPI Reference for the Favicon, Icon and Apple Icon file conventions.\nopengraph-image and twitter-image\nAPI Reference for the Open Graph Image and Twitter Image file conventions.\nrobots.txt\nAPI Reference for robots.txt file.\nsitemap.xml\nAPI Reference for the sitemap.xml file.\nhtmlLimitedBots\nSpecify a list of user agents that should receive blocking metadata.\nPrevious\nFont Optimization\nNext\nRoute Handlers\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Architecture: Accessibility | Next.js",
    "url": "https://nextjs.org/docs/architecture/accessibility",
    "html": "Next.js Docs\nArchitecture\nAccessibility\nCopy page\nAccessibility\n\nThe Next.js team is committed to making Next.js accessible to all developers (and their end-users). By adding accessibility features to Next.js by default, we aim to make the Web more inclusive for everyone.\n\nRoute Announcements\n\nWhen transitioning between pages rendered on the server (e.g. using the <a href> tag) screen readers and other assistive technology announce the page title when the page loads so that users understand that the page has changed.\n\nIn addition to traditional page navigations, Next.js also supports client-side transitions for improved performance (using next/link). To ensure that client-side transitions are also announced to assistive technology, Next.js includes a route announcer by default.\n\nThe Next.js route announcer looks for the page name to announce by first inspecting document.title, then the <h1> element, and finally the URL pathname. For the most accessible user experience, ensure that each page in your application has a unique and descriptive title.\n\nLinting\n\nNext.js provides an integrated ESLint experience out of the box, including custom rules for Next.js. By default, Next.js includes eslint-plugin-jsx-a11y to help catch accessibility issues early, including warning on:\n\naria-props\naria-proptypes\naria-unsupported-elements\nrole-has-required-aria-props\nrole-supports-aria-props\n\nFor example, this plugin helps ensure you add alt text to img tags, use correct aria-* attributes, use correct role attributes, and more.\n\nAccessibility Resources\nWebAIM WCAG checklist\nWCAG 2.2 Guidelines\nThe A11y Project\nCheck color contrast ratios\n between foreground and background elements\nUse prefers-reduced-motion\n when working with animations\nPrevious\nArchitecture\nNext\nFast Refresh\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Proxy | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/proxy",
    "html": "App Router\nGetting Started\nProxy\nCopy page\nProxy\nProxy\n\nProxy allows you to run code before a request is completed. Then, based on the incoming request, you can modify the response by rewriting, redirecting, modifying the request or response headers, or responding directly.\n\nUse cases\n\nSome common scenarios where Proxy is effective include:\n\nQuick redirects after reading parts of the incoming request\nRewriting to different pages based on A/B tests or experiments\nModifying headers for all pages or a subset of pages\n\nProxy is not a good fit for:\n\nSlow data fetching\nSession management\n\nUsing fetch with options.cache, options.next.revalidate, or options.next.tags, has no effect in Proxy.\n\nConvention\n\nCreate a proxy.ts (or .js) file in the project root, or inside src if applicable, so that it is located at the same level as pages or app.\n\nNote: While only one proxy.ts file is supported per project, you can still organize your proxy logic into modules. Break out proxy functionalities into separate .ts or .js files and import them into your main proxy.ts file. This allows for cleaner management of route-specific proxy, aggregated in the proxy.ts for centralized control. By enforcing a single proxy file, it simplifies configuration, prevents potential conflicts, and optimizes performance by avoiding multiple proxy layers.\n\nExample\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\n \n// This function can be marked `async` if using `await` inside\nexport function proxy(request: NextRequest) {\n  return NextResponse.redirect(new URL('/home', request.url))\n}\n \n// See \"Matching Paths\" below to learn more\nexport const config = {\n  matcher: '/about/:path*',\n}\n\nRead more about using proxy, or refer to the proxy API reference.\n\nAPI Reference\nLearn more about Proxy\nproxy.js\nAPI reference for the proxy.js file.\nBackend for Frontend\nLearn how to use Next.js as a backend framework\nPrevious\nRoute Handlers\nNext\nDeploying\n\nWas this helpful?\n\nsupported.\nSend"
  }
]
</file>

<file path="output/jobs/polar-sh.json">
[
  {
    "title": "Polar: Turn Your Software into a Business - Polar",
    "url": "https://polar.sh/docs/introduction",
    "html": "Bootup\nPolar: Turn Your Software into a Business\nCopy page\n\nThe next generation unicorns will be built by smaller teams. Polar makes that dream possible.\n\n​\nWhat is Polar?\nTurn your software into a business with Polar. Sell digital products, subscriptions, and more without the hassle of traditional payment systems.\nBeyond Payment Processing\nUnlike Stripe that only handles transactions, we provide complete billing infrastructure with tax compliance, product management, and automated access & delivery.\nMerchant of Record\nWe handle all international tax compliance, so you can sell globally without worrying about VAT, GST, or sales tax regulations.\n​\nProblems We Solve\n\nTax Compliance Nightmare\n\nComplex Billing Infrastructure\n\nManual Access & Delivery Overhead\n\nHigh Processing Costs\n\n​\nCore Features\n​\nFlexible Product Management\nOne-time Purchases\nSell digital products, courses, templates, or software licenses with instant delivery\nSubscriptions\nRecurring billing with automatic renewals and dunning management\nFlexible Pricing\nFixed price, pay-what-you-want, or free products with optional minimums\n​\nPowerful Checkout Experience\nCheckout Links\nNo-code solution for quick product sales. Create and share instantly.\nEmbedded Checkout\nIntegrate seamlessly into your website with customizable branding.\nCheckout API\nProgrammatically create dynamic checkout sessions for custom flows.\n​\nAutomated Benefits (Entitlements)\nSet it and forget it: Configure once, and customers get instant access to their benefits automatically. No manual work required.\nLicense Keys\nGenerate and deliver software licenses automatically with custom formats\nFile Downloads\nSecure delivery of digital assets up to 10GB with download tracking\nGitHub Access\nAuto-invite customers to private repositories and manage permissions\nDiscord Access\nAutomatic role assignment and server invites for community access\n​\nGlobal Merchant of Record\nWorldwide Tax Compliance - We handle VAT, GST, and sales tax in all jurisdictions\nEU VAT Handling - Proper B2B reverse charge and B2C tax collection\nAutomatic Tax Calculation - Real-time tax rates for every transaction\n​\nQuick Start Guide\n1\n\nCreate Your Account\n\nSign up for Polar using GitHub, Google, or email. Create an organization to manage your products and customers.\n2\n\nCreate Your First Product\n\nSet up a digital product in minutes:\nChoose between one-time purchase or subscription\nSet your pricing (fixed, pay-what-you-want, or free)\nConfigure automated benefits for instant delivery\nLearn more about Products →\n3\n\nChoose Your Integration\n\nPick the approach that fits your needs:\nNo-Code (Fastest)\nEmbedded\nFull API (Maximum Control)\nPerfect for getting started quickly:\nCreate Checkout Links from your dashboard\nShare via email, social media, or embed in websites\nStart accepting payments immediately\n4\n\nSet Up Webhooks\n\nStay synchronized with customer events:\nConfigure webhook endpoints in your dashboard\nReact to purchases, subscription changes, and customer events\nKeep your database in sync automatically\nRead the Webhooks guide →\n​\nIntegration Options\n​\nFramework Adapters (Recommended)\nNext.js\nReact-based full-stack framework with App Router support\nBetterAuth\nPayments and billing empowered by authentication & authorization\nLaravel\nPHP web application framework with Eloquent ORM integration\nDeno\nA modern runtime for TypeScript\n\nShow All 12 supported frameworks\n\n​\nNative SDKs\nJS/TS\nFor web and Node.js applications\nPython\nFor Django, Flask, FastAPI frameworks\nGo\nFor Go web services and applications\nPHP\nFor WordPress, Laravel, and PHP apps\n​\nWhy Choose Polar?\nIndividual Developers\nSmall Teams\nGrowing Businesses\nShip Faster\nFocus on your product, not billing infrastructure. Get to market weeks faster.\nGlobal Reach\nSell worldwide without worrying about tax compliance or regional restrictions.\nAutomated Delivery\nLicense keys and downloads handled automatically. No manual work required.\nLower Costs\n20% cheaper than competitors with transparent, pay-as-you-earn pricing.\n​\nTransparent Pricing\n4% + 40¢\nPer successful transaction\nSimple, transparent pricing with no surprises\n$0\nMonthly fees or setup costs\nPay only when you earn, no fixed costs\nAdditional fees may apply: Some transactions may incur additional fees (international cards, subscriptions). Payout fees are charged by payment providers. See our detailed fees page for complete information.\n​\nOpen Source & Community\nPolar is built in the open with full transparency and a growing community of contributors.\nOpen Source Codebase\nApache 2.0 license with 36+ contributors and growing\nPublic Development\nFeature requests, roadmap, and issues - all developed in public\nTransparent Pricing\nNo hidden fees or surprise charges. What you see is what you pay.\nCommunity Support\nJoin our Discord for help, feedback, and feature discussions\nWhile self-hosting is technically possible, we recommend using our hosted service to get the full Merchant of Record benefits including global tax compliance.\n​\nReady to Start?\nCreate Account\nFree signup, no credit card required\nGet started in under 2 minutes\nRead the Guides\nFramework-specific tutorials\nStep-by-step integration guides\nExplore the API\nComplete API documentation\nInteractive examples and SDKs\nJoin Our Community\nGet help from our team\nActive community and support\n\nWas this page helpful?\n\nYes\nNo\nMigrate to Polar\nGet set up on Polar in minutes from an existing store\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Products - Polar",
    "url": "https://polar.sh/docs/features/products",
    "html": "Features\nProducts\nCopy page\n\nCreate digital products on Polar in minutes\n\nEverything is a product\nSubscriptions or pay once products are both considered a product in Polar (API & data model). Just with different pricing & billing logic. So both are shown & managed under Products with the ability to filter based on pricing model.\n​\nCreate a product\n​\nName & Description\nStarting off with the basic.\nName The title of your product.\nDescription Markdown is supported here too.\n​\nPricing\nDetermine how you want to charge your customers for this product.\n1\n\nBilling cycle\n\nOne-time purchase Customer is charged once and gets access to the product forever.\nMonthly Customer is charged every month.\nYearly Customer is charged every year.\n2\n\nPricing type\n\nFixed price Set a fixed price for the product.\nPay what you want Let customers decide how much they want to pay.\nFree No charge for the product.\n3\n\nPrice\n\nFor fixed price products, set the amount you want to charge.\nFor pay what you want products, you can set a minimum amount and a default amount that will be preset on checkout.\nBilling cycle and pricing type cannot be changed after the product is created.\nWhat if I want both a monthly and yearly pricing?\nPolar has a unique approach to what the industry typically calls variants. Each product has a single pricing model, but you can create multiple products with different pricing models, and showcase them both at checkout.\n​\nTrial Period\nFor recurring products, you can set a trial period during which the customer won’t be charged. Toggle Enable trial period to enable it. Then, you’ll be able to set the duration of the trial period, given a number and a unit (days, weeks, months or years).\nYou can read more about how trials work here.\n​\nProduct Media\nYou can upload public product images to be displayed on product pages\nThey can be up to 10MB each\nYou can remove and re-arrange images\n​\nCheckout Fields\nYou can collect additional information from your customers at checkout. This can be useful for things like phone number, terms of service agreement or specific data you need to collect.\nFields are managed from your organization settings, and you can choose which fields to show on a per-product basis, and set if they are required or not. We support the following field types:\nText\nNumber\nDate\nCheckbox\nSelect\nIf you make a checkbox required, the customer will need to check it before confirming their purchase. Very handy for legal terms!\nThe data collected will be available in the order and subscription details.\n​\nAutomated Entitlements\nFinally, you can enable or create new entitlements (what we call Benefits) that you tie to the product.\nRead more in our product benefits guide on how they work and how to customize the built-in ones we offer:\nLicense Keys\nDiscord Server Role\nGitHub Repository Access\nFile Downloads\nCustom Benefit\n​\nVariants\nPolar has a unique approach regarding what the industry typically calls variants.\nWe believe having a single product with multiple pricing models and benefits adds unnecessary complexity to the user and to the API. Instead, we chose to treat everything as a product, giving you maximum flexibility about the pricing and benefits you want to offer.\nYou can showcase several products at checkout, allowing the customer to switch between them. Typically, you can offer a monthly and a yearly product, with specific pricing and benefits for each. Read more about how to do so using Checkout Links or the Checkout Session API.\n​\nUpdate a product\nYou can edit any product details, except the billing cycle and pricing type.\nFor fixed price products, you can change the price. Existing subscribers will remain on their current pricing.\nIf you add benefits, existing subscribers will get them automatically. If you remove benefits, existing subscribers will lose access to them.\n​\nArchive a product\nProducts on Polar can’t be deleted, but they can be archived. You can do so by clicking the Archive button on the bottom right of the product page.\nExisting customers will keep their access to the product, and subscriptions will continue to renew. However, the product will no longer be available for new purchases.\nIt’s possible to unarchive a product using the Products Update API.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nIntroduction\nUsage based billing using ingested events\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Trials - Polar",
    "url": "https://polar.sh/docs/features/trials",
    "html": "Features\nTrials\nCopy page\n\nOffer free trials on your subscriptions\n\nTrials are a great way to let potential customers experience your product before committing to a subscription. With Polar, you can easily set up free trials for your subscription products.\n​\nSetting up a trial\nYou can set up a trial period through the following means:\nWhen creating or editing a product.\nWhen creating or editing a checkout link.\nWhen creating a Checkout Session through the API.\nIf you set a trial period on the Checkout Link or Checkout Session, it will override the trial period set on the product.\nThe trial period consists of two parameters:\nA unit: day, week, month, or year.\nA duration: a number representing how many units the trial will last.\n​\nStarting a trial\nWhen a customer checks out a subscription product with a trial period, they will not be charged immediately. Instead, they will have access to the product for the duration of the trial period.\nWe’ll still collect their payment information at checkout, but they won’t be charged until the trial period ends. This means that if they decide to cancel before the trial ends, they won’t be charged at all.\nOnce the trial period ends, the customer will be automatically charged for the subscription, and their billing cycle will begin.\n​\nAdding, extending or canceling a trial\nFor existing subscriptions, youu can add, extend or cancel a customer’s trial period at any time through the dashboard, from the subscription details page. Click on Update Subscription, then click on the Trial tab.\nTo add or extend a trial, set a new trial end date in the future. If the subscription was active, its status will be changed to trialing, and the billing will be postponed until the end of the trial.\nTo cancel a trial, click on the End trial button. The subscription will become active immediately, and the customer will be charged immediately for a new billing cycle.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nSeat-Based Pricing\nSell team products with assignable seats and tiered pricing\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Seat-Based Pricing - Polar",
    "url": "https://polar.sh/docs/features/seat-based-pricing",
    "html": "Features\nSeat-Based Pricing\nCopy page\n\nSell team products with assignable seats and tiered pricing\n\nSeat-based pricing allows you to sell products where a billing manager purchases a specific number of seats and can assign them to team members. Each seat holder gets their own access to the product benefits, making it perfect for team subscriptions, perpetual licenses, and multi-user products.\nSeat-based pricing is ideal for:\nTeam subscriptions where one billing manager pays for multiple users\nPerpetual team licenses with one-time payment\nOrganizational licenses with per-seat pricing\nProducts with volume-based tiering (e.g., $10/seat for 1-4 seats, $9/seat for 5+)\n​\nFeature Flag\nSeat-based pricing is controlled by a feature flag at the organization level. You can enable this feature on the organization settings page.\n​\nHow it works\nWith seat-based pricing, a billing manager purchases a product (subscription or one-time) with a specific number of seats. They can then:\nAssign seats to team members via email or external customer ID\nManage seats by resending invitations or revoking access\nScale up by purchasing additional seats (or a new order for one-time products)\nTrack usage by viewing which seats are claimed, pending, or available\nTeam members receive an invitation email with a claim link. Once they claim their seat, benefits are automatically granted.\n​\nSubscriptions vs One-Time Purchases\nSeat-based pricing works for both recurring subscriptions and one-time purchases:\nFeature\tSubscriptions\tOne-Time Purchases\nPayment\tRecurring (monthly/yearly)\tSingle payment\nSeat Duration\tActive while subscribed\tPerpetual (never expire)\nAdding Seats\tModify subscription\tPurchase new order\nBilling\tRenews automatically\tNo renewals\nBenefits\tWhile subscription active\tForever after claim\nUse subscriptions for ongoing team access. Use one-time purchases for perpetual team licenses.\n​\nCreating a seat-based product\n1\n\nCreate a new product\n\nFrom your dashboard, navigate to Products and click Create Product.\n2\n\nConfigure basic settings\n\nSet your product name, description, and media as usual.\n3\n\nSelect seat-based pricing\n\nUnder Pricing, select:\nProduct type: Subscription or One-time\nBilling cycle (subscriptions only): Monthly or Yearly\nPricing type: Seat-based\n4\n\nConfigure seat tiers\n\nDefine your pricing tiers based on seat quantity:\nMin seats: Minimum number of seats required to purchase\nTiers: For each tier, set:\nMax seats: Upper limit for this tier (leave empty for unlimited)\nPrice per seat: Amount charged per seat in this tier (in cents)\nExample tiered pricing:\n1-4 seats: $10/seat per month\n5-9 seats: $9/seat per month\n10+ seats: $8/seat per month\n5\n\nAdd benefits\n\nConfigure the benefits that seat holders will receive. These are only granted when a seat is claimed, not when purchased.\nUnlike standard subscriptions, seat-based products do not grant benefits to the billing manager. Benefits are only granted to team members who claim their assigned seats.\n​\nPurchasing seats\nWhen a customer purchases a seat-based product, they specify how many seats they want during checkout. The total amount is calculated based on your tiered pricing.\nThe checkout experience clearly shows:\nNumber of seats being purchased\nPrice per seat based on volume\nTotal amount\nFor subscriptions: recurring billing cycle\nFor one-time: perpetual access indication\nOnce payment is completed, the billing manager can immediately start assigning seats to their team.\nFor one-time purchases, each order is independent. If customers want more seats later, they purchase a new order with its own seat pool. All purchased seats remain perpetual.\n​\nManaging seats\n​\nAssigning seats\nBilling managers can assign seats through:\nCustomer Portal: Accessible via the customer portal with billing manager permissions\nAPI: Programmatically assign seats using the Customer Seats API\nTo assign a seat, provide:\nSubscription ID (for subscriptions) or Order ID (for one-time purchases)\nEmail address (creates a new customer if needed)\nExternal customer ID (optional, for syncing with your system)\nCustomer ID (if customer already exists in Polar)\nMetadata (optional, up to 10 keys for custom data like role, department)\nAn invitation email is automatically sent to the recipient with a secure claim link (valid for 24 hours).\n​\nSeat statuses\nEach seat can have one of three statuses:\nPending: Seat assigned, invitation sent, awaiting claim\nClaimed: Seat claimed by team member, benefits granted\nRevoked: Seat revoked, benefits removed, can be reassigned\n​\nResending invitations\nFor pending seats, billing managers can resend the invitation email if it was lost or expired.\n​\nRevoking seats\nBilling managers can revoke a claimed seat at any time:\nBenefits are immediately removed from the seat holder\nThe seat becomes available for reassignment\nThe seat holder loses access to all product benefits\nThe revoked seat can be assigned to a different team member\nRevoking a seat does not issue a refund. The billing manager continues to pay for the total number of seats in their subscription.\n​\nClaiming seats\nWhen a team member receives a seat invitation:\nThey click the claim link in the email\nA claim page displays the product details and organization info\nThey click Claim Seat to accept\nBenefits are automatically granted\nThey receive a customer session token for immediate portal access\nThey can access their benefits through the customer portal\nClaim links are single-use and expire after 24 hours for security. If expired, the billing manager can resend the invitation.\n​\nScaling seats\n​\nAdding seats\nFor subscriptions:\nBilling managers can upgrade their subscription to add more seats:\nThe new seat count is applied immediately\nProrated charges are calculated for the current billing period\nFuture renewals bill at the new seat count\nNew seats can be assigned right away\nIf adding seats moves to a different pricing tier, the new per-seat rate applies to all seats, not just the additional ones.\nFor one-time purchases:\nBilling managers purchase a new order with additional seats:\nCreate a new checkout for the same product with desired seat quantity\nOnce paid, a new independent order is created\nEach order has its own seat pool\nAll seats remain perpetual across all orders\n​\nReducing seats\nFor subscriptions:\nTo reduce seats, the billing manager should:\nRevoke seats until the desired count is reached\nUpdate the subscription to reflect the lower seat count\nThe change takes effect at the next renewal\nYou cannot reduce subscription seats below the number of currently claimed seats. Revoke seats first before reducing the subscription seat count.\nFor one-time purchases:\nSeats cannot be reduced or refunded as they are perpetual. The billing manager can:\nRevoke unwanted seats to make them unassigned\nThe seats remain available for future assignment\nNo refund is issued for revoked seats\n​\nAPI Integration\nSeat-based pricing provides full API support for:\nCreating seat-based products with tiered pricing\nChecking out with seat quantities\nAssigning seats programmatically\nListing seats and their statuses\nRevoking seats\nSDK Version Requirement\nTo use seat-based pricing features, ensure you have the latest version of the Polar SDK installed:\nTypeScript/JavaScript: npm install @polar-sh/sdk@latest\nPython: pip install --upgrade polar-sdk\nOlder SDK versions may not include seat-based pricing support.\nSee the Customer Seats API Reference for complete documentation.\n​\nExample: Assign a seat (subscription)\nCopy\nAsk AI\nawait polar.customerSeats.assign({\n  subscription_id: \"sub_123\",\n  email: \"engineer@company.com\",\n  metadata: {\n    department: \"Engineering\",\n    role: \"Developer\"\n  }\n});\n\n​\nExample: Assign a seat (one-time purchase)\nCopy\nAsk AI\nawait polar.customerSeats.assign({\n  order_id: \"order_456\",\n  email: \"engineer@company.com\",\n  metadata: {\n    department: \"Engineering\",\n    role: \"Developer\"\n  }\n});\n\n​\nExample: List seats for subscription\nCopy\nAsk AI\nconst seats = await polar.customerSeats.list({\n  subscription_id: \"sub_123\"\n});\n\nconsole.log(`Available: ${seats.available_seats}/${seats.total_seats}`);\n\n​\nExample: List seats for order\nCopy\nAsk AI\nconst seats = await polar.customerSeats.list({\n  order_id: \"order_456\"\n});\n\nconsole.log(`Available: ${seats.available_seats}/${seats.total_seats}`);\n\n​\nWebhooks\nSeat-based pricing triggers webhooks for both subscriptions and orders:\nSubscription events:\nsubscription.created - When seat-based subscription is purchased\nsubscription.updated - When seat count changes\nsubscription.canceled - When subscription is cancelled\nOrder events:\norder.created - When seat-based one-time purchase is completed\norder.updated - When order is updated\nSeat and benefit events (both types):\nbenefit_grant.created - When a seat is claimed and benefits granted\nbenefit_grant.revoked - When a seat is revoked and benefits removed\nFor both subscriptions and one-time purchases, benefit_grant.created events are triggered per seat claim, not at purchase time.\n​\nBest Practices\n​\nUse tiered pricing strategically\nStructure your tiers to incentivize volume:\nLower per-seat prices as quantity increases\nCreate tiers at natural team sizes (5, 10, 25, etc.)\nConsider flat pricing for very large teams\n​\nLeverage metadata\nUse seat metadata to store:\nTeam member roles\nDepartments or cost centers\n​\nMonitor seat utilization\nTrack how many purchased seats are actually claimed to identify:\nOrganizations that may need more seats\nUnused capacity that could be reduced\nPatterns in team adoption\n​\nCommunicate clearly\nEnsure product pages clearly explain:\nThe billing manager will not get direct access\nSeats must be assigned to team members\nPricing structure and volume discounts\nSeat assignment and claiming process\n​\nLimitations\nSeats must be assigned individually (no bulk import via dashboard, use API instead)\nClaim links expire after 24 hours\nBilling manager does not receive product benefits\nMaximum of 1,000 seats per subscription\nMetadata limited to 10 keys and 1KB total size per seat\nUsage-based pricing with shared emails: If you sell to multiple businesses and different businesses assign seats to the same email address (e.g., “john@gmail.com”), and usage-based pricing is enabled, separate meters should be created for each business to properly segregate usage. This is a rare scenario since employees from different businesses typically don’t share the same email address.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCustom Fields\nLearn how to add custom input fields to your checkout with Polar\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Custom Fields - Polar",
    "url": "https://polar.sh/docs/features/custom-fields",
    "html": "Features\nCustom Fields\nCopy page\n\nLearn how to add custom input fields to your checkout with Polar\n\nBy default, the Checkout form will only ask basic information from the customer to fulfill the order: a name, an email address, billing information, etc. But you might need more! A few examples:\nA checkbox asking the customer to accept your terms\nAn opt-in newsletter consent\nA select menu to ask where they heard from you\n…\nWith Polar, you can easily add such fields to your checkout using Custom Fields.\n​\nCreate Custom Fields\nCustom Fields are managed at an organization’s level. To create them, go to Settings and Custom Fields. You’ll see the list of all the available fields on your organization.\nClick on New Custom Field to create a new one.\n​\nType\nThe type of the field is the most important thing to select. It determines what type of input will be displayed to the customer during checkout.\nThe type can’t be changed after the field is created.\nWe support five types of fields:\n​\nText\nThis will display a simple text field to input textual data. By default, it’ll render a simple input field but you can render a textarea by toggling the option under Form input options.\nUnder Validation constraints, you can add minimum and maximum length validation.\nUnderneath, the data will be stored as a string.\n​\nNumber\nThis will display a number input field. Under Validation constraints, you can add minimum and maximum validation.\nUnderneath, the data will be stored as a number.\n​\nDate\nThis will display a date input field. Under Validation constraints, you can add minimum and maximum validation.\nUnderneath, the data will be stored as a string using the ISO 8601 format.\n​\nCheckbox\nThis will display a checkbox field.\nUnderneath, the data will be stored as a boolean (true or false).\n​\nSelect\nThis will display a select field with a predefined set of options. Each option is a pair of Value and Label, the first one being the value that’ll be stored underneath and the latter the one that will be shown to the customer.\n​\nSlug and name\nThe slug determines the key that’ll be used to store the data inside objects related to the checkout, like Orders and Subscriptions. It must be unique across your organization. You can change it afterwards, we’ll automatically update the data to reflect the new slug.\nThe name is what we’ll be displayed to you to recognize the field across your dashboard. By default, it’ll also be the label of the field displayed to the customer, unless you customize it under Form input options.\n​\nForm input options\nThose options allow you to customize how the field is displayed to the customer. You can set:\nThe label, displayed above the field\nThe help text, displayed below the field\nThe placeholder, displayed inside the field when there is no value\nThe label and help text supports basic Markdown syntax, so you can add bold, italic or even links.\n​\nAdd Custom Field to Checkout\nCustom Fields are enabled on Checkout specifically on each product. While creating or updating a product, you can select the custom fields you want to include in the checkout for this product.\nNote that you can make the field Required.\nIf you make a checkbox field required, customers will have to check the box before submitting the checkout. Very useful for terms acceptance!\nThe fields are now added as part of the Checkout form for this product.\n​\nRead data\nOnce you have added Custom Fields to your organization, they’ll be automatically displayed as a column in your Sales page, both on Orders and Subscriptions. From there, you’ll be able to see the data input by the customer.\nThis data is also available from the Orders and Subscriptions API, under the custom_field_data property. Each value is referenced by the slug of the field.\nCopy\nAsk AI\n{\n  // ...\n  \"custom_field_value\": {\n    \"terms\": true,\n    \"source\": \"social_media\"\n  }\n}\n\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDiscounts\nCreate discounts on products and subscriptions\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Discounts - Polar",
    "url": "https://polar.sh/docs/features/discounts",
    "html": "Features\nDiscounts\nCopy page\n\nCreate discounts on products and subscriptions\n\nDiscounts are a way to reduce the price of a product or subscription. They can be applied to one-time purchasable products or subscriptions.\n​\nCreate a discount\nGo to the Products page and click on the Discounts tab.\n​\nName\nDisplayed to the customer when they apply the discount.\n​\nCode\nOptional code (case insensitive) that the customer can use to apply the discount. If left empty, the discount can only be applied through a Checkout Link or the API.\n​\nPercentage Discount\nThe percentage discount to apply to the product or subscription.\n​\nFixed Amount Discount\nThe discount deducts a fixed amount from the price of the product or subscription.\n​\nRecurring Discount\nThe percentage discount to apply to the product or subscription.\nOnce The discount is applied once.\nSeveral Months The discount is applied for a fixed number of months.\nForever The discount is applied indefinitely.\n​\nRestrictions\nProducts The discount can only be applied to specific products. By default the discount can be applied to all products, also ones created after the discount was created.\nStarts at The discount can only be applied after this date\nEnds at The discount can only be applied before this date\nMaximum redemptions The maximum number of times the discount can be applied.\n​\nApply a discount\nDiscounts can be applied to a Checkout Link or a Checkout Session.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nOrders & Subscriptions\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Orders & Subscriptions - Polar",
    "url": "https://polar.sh/docs/features/orders",
    "html": "Features\nOrders & Subscriptions\nCopy page\n​\nSales\nThe sales view shows you all sales in a paginated list.\n​\nOrder & Subscription Details\nEach sale has metadata attached to it. Common properties like\nAmount\nTax Amount\nInvoices\nCustomer\nBasic Customer Details\nPast Orders\n​\nCheckouts\nYou can also have an overview of all checkout sessions. You can filter them by customer email, status and product.\nA checkout can be in the following states:\nOpen: The checkout session is open and waiting for the customer to complete the payment.\nConfirmed: The customer clicked the Pay or Subscribe button and the payment is being processed.\nSucceeded: The payment was successful and the order was created.\nExpired: The checkout session expired and the customer can no longer complete it. A new checkout session must be created.\nIf you click on a Checkout, you can have more details on the payment attempts, in particular, why a payment has failed or has been declined.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nRefunds\nYou can easily refund orders on Polar - both in full or in parts.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Manage Refunds - Polar",
    "url": "https://polar.sh/docs/features/refunds",
    "html": "Features\nManage Refunds\nCopy page\n\nYou can easily refund orders on Polar - both in full or in parts.\n\nNo matter what refund policy you offer to customers, Polar makes it easy to offer both full and partial refunds to easily deliver the customer experience and refund policy you want.\nHowever, even in case you have a “no refund” policy, Polar reserves the right to issue refunds within 60 days of purchase - at our own discretion. We reserve this right in an effort to automatically and proactively reduce costly chargebacks.\nPolar can issue refunds on your behalf\nPolar reserves the right to issue refunds within 60 days of purchase, at its own discretion, in order to prevent chargebacks. So if you choose to have a “no refunds” policy, be aware that Polar could still issue refunds in an effort to proactively prevent chargebacks.\n​\nIssuing a refund\nGo to the order details page for the specific order you want to refund\nScroll down to the “Refund” section\nClick “Refund”\nAmount\nSpecify the amount to refund. By default it’s the full order amount, but you can reduce this to issue a partial refund instead.\nPayment fees are not refunded\nUnfortunately, credit card networks and PSPs charge us for the underlying transactions regardless of whether it’s later refunded (industry standard). Therefore, we cannot offer a refund on our fees since the costs remain constant.\nExample: An order of \n30\n𝑐\n𝑜\n𝑠\n𝑡\n𝑠\n \n30costs 1.6 in fees to Polar. You can still refund the customer \n30\n,\n𝑏\n𝑢\n𝑡\n𝑡\nℎ\n𝑒\n \n30,butthe 1.6 fee remains and is deducted on your balance from other purchases.\nReason\nSelect the reason for the refund - helpful for future reference.\nRevoke Benefits (One-time purchases)\nFor one-time purchases, you can revoke the customers access to product benefits, e.g file downloads, license keys or Discord/GitHub invites. By default this is selected since we default to a full refund, but can be disabled.\nRevoke Benefits (Subscriptions)\nYou cannot revoke access by refunding an order associated with a subscription. Instead the subscription is required to be canceled and Polar will then automatically revoke access once the subscription itself is revoked.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAnalytics\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Analytics - Polar",
    "url": "https://polar.sh/docs/features/analytics",
    "html": "Features\nAnalytics\nCopy page\n​\nSales Metrics\nPolar offers a professional metrics dashboard out of the box. So you can stay focused on increasing revenue vs. how to measure it.\nMissing any metrics? Let us know so we can add it.\n​\nFilters\nYou can easily slice and dice metrics with the filters below.\n​\nPeriod\nChange the time period in the X-axis to one of:\nYearly\nMonthly\nWeekly\nDaily\nHourly\n​\nTimeframe\nYou can choose a date range to view all metrics for.\n​\nProduct\nBy default metrics reflect the total across all products. However, you can specify individual products or subscription tiers to filter metrics by.\n​\nMetrics\n​\nRevenue\nHow much revenue you’ve earned before fees.\n​\nOrders\nHow many product sales and subscription payments have been made.\n​\nAverage Order Value (AOV)\nThe average earning per order, i.e revenue / orders.\n​\nOne-Time Products\nAmount of products sold.\n​\nOne-Time Products Revenue\nAmount of revenue earned from products.\n​\nNew Subscriptions\nAmount of new subscriptions.\n​\nNew Subscription Revenue\nAmount of revenue earned from new subscriptions.\n​\nRenewed Subscriptions\nAmount of renewed subscriptions.\n​\nRenewed Subscription Revenue\nAmount of revenue earned from renewed subscriptions.\n​\nActive Subscriptions\nAmount of active subscriptions (new + renewed)\n​\nMonthly Recurring Revenue (MRR)\nAmount of revenue earned from active subscriptions.\n​\nCheckouts\nNumber of created checkouts.\n​\nSucceeded Checkouts\nNumber of successful checkouts, i.e. checkouts that lead to a new order or subscription.\n​\nCheckouts Conversion Rate\nThe percentage of successful checkouts out of all created checkouts.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCustomer Management\nGet insights on your customers and sales\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Customer Management - Polar",
    "url": "https://polar.sh/docs/features/customer-management",
    "html": "Features\nCustomer Management\nCopy page\n\nGet insights on your customers and sales\n\n​\nManaging Customers\nPolar has a built in feature to view and manage your Customers.\nEveryone who has ever purchased something from you will be recorded as a Customer to your Organization. You’re able to see past orders and their ongoing subscriptions, as well as some additional metrics.\n​\nExternal ID\nQuite often, you’ll have our own users management system in your application, where your customer already have an ID. To ease reconciliation between Polar and your system, we have a dedicated external_id field on Customers. It’s unique across your organization and can’t be changed once set.\nWe have dedicated API endpoints that work with the external_id field, so you don’t even have to store the internal Polar ID in your system.\nGet Customer by External ID\nUpdate Customer by External ID\nDelete Customer by External ID\n​\nMetadata\nYou may set additional metadata on Customers. This can be very useful to store additional data about your customer you want to be available through our API and webhooks.\nIt can be set through the dashboard or through the API. It can also be pre-set when creating a Checkout Session by using the customer_metadata field. This way, after a successful checkout, the metadata will automatically be set on the newly created Customer.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCustomer Portal\nEnable customers to view & manage orders and subscriptions easily\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Customer Portal - Polar",
    "url": "https://polar.sh/docs/features/customer-portal",
    "html": "Features\nCustomer Portal\nCopy page\n\nEnable customers to view & manage orders and subscriptions easily\n\nThe Customer Portal is a destination where your customers can see their orders and ongoing subscriptions. It’s also where they’re able to get hands on receipts, benefits, and more.\n​\nRedirect to your Customer Portal\nThe customer portal is directly available from the URL https://polar.sh/your-org-slug/portal. Your customers will be able to authenticate there by entering the email they used to purchase or subscribe to your products.\nCustomer Portal Sign In\n​\nCreating an authenticated Customer Portal Link\nYou can provide a pre-authenticated Customer Portal Link to your customers. This is handy if you want to redirect them directly from your application.\nUsing the Polar API, all you need is to call the customerSessions endpoint. Here’s an example using our TypeScript SDK.\nCopy\nAsk AI\nimport { Polar } from \"@polar-sh/sdk\";\n\nconst polar = new Polar({\n  accessToken: process.env[\"POLAR_ACCESS_TOKEN\"] ?? \"\",\n});\n\nasync function run() {\n  const result = await polar.customerSessions.create({\n    customerId: \"<value>\",\n  });\n\n  redirect(result.customerPortalUrl)\n}\n\nrun();\n\nOr, if you use NextJS as your framework, we have a handy utility which shortens down your code significantly.\nCopy\nAsk AI\n// app/portal/route.ts\nimport { CustomerPortal } from \"@polar-sh/nextjs\";\n\nexport const GET = CustomerPortal({\n  accessToken: process.env.POLAR_ACCESS_TOKEN,\n  getCustomerId: async (req) => '<value>',\n  server: 'sandbox' // Use sandbox if you're testing Polar - pass 'production' otherwise\n});\n\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nPayout Accounts\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Introduction - Polar",
    "url": "https://polar.sh/docs/guides/introduction",
    "html": "Guides\nIntroduction\nCopy page\n\nA collection of how-tos with Polar in form of step-by-step guides and tutorials.\n\nThis section is your starting point for learning how to use Polar with various stacks, environments, etc. Here you will find step-by-step guides and tutorials to help you integrate Polar into your projects, set up your environment, and make the most of our platform.\n​\nGet Started\nBrowse the guides in the sidebar to find the right one based on your needs.\nIf you want to request a new guide, please create an issue on polarsource/polar.\n\nWas this page helpful?\n\nYes\nNo\nSeat-Based Pricing\nComplete guide to implementing team products with seat-based pricing\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "API Overview - Polar",
    "url": "https://polar.sh/docs/api-reference/introduction",
    "html": "General\nAPI Overview\nCopy page\n\nBase URLs, authentication, pagination, rate limits, and the difference between the Core API and the Customer Portal API\n\nProduction Base URL\nhttps://api.polar.sh/v1\nSandbox Base URL\nhttps://sandbox-api.polar.sh/v1\nAuth (Organization)\nUse an Organization Access Token (OAT) in the Authorization: Bearer header\nAuth (Customer Portal)\nUse a Customer Access Token created via /v1/customer-sessions/\n​\nBase URLs\nEnvironment\tBase URL\tPurpose\nProduction\thttps://api.polar.sh/v1\tReal customers & live payments\nSandbox\thttps://sandbox-api.polar.sh/v1\tSafe testing & integration work\nThe sandbox environment is fully isolated—data, users, tokens, and organizations created there do not affect production. Create separate tokens in each environment.\nRead more: Sandbox Environment\n​\nAuthentication\n​\nOrganization Access Tokens (OAT)\nUse an OAT to act on behalf of your organization (manage products, prices, checkouts, orders, subscriptions, benefits, etc.).\nCopy\nAsk AI\nAuthorization: Bearer polar_oat_xxxxxxxxxxxxxxxxx\n\nCreate OATs in your organization settings. See: Organization Access Tokens\nNever expose an OAT in client-side code, public repos, or logs. If leaked, it will be revoked automatically by our secret scanning integrations.\n​\nCustomer Access Tokens\nDo not use OATs in the browser. For customer-facing flows, generate a Customer Session server-side, then use the returned customer access token with the Customer Portal API to let a signed-in customer view their own orders, subscriptions, and benefits.\n​\nCore API vs Customer Portal API\nAspect\tCore API\tCustomer Portal API\nAudience\tYour server / backend\tOne of your customer\nAuth Type\tOrganization Access Token (OAT)\tCustomer Access Token\nScope\tFull org resources (products, orders, subscriptions, benefits, checkout)\tOnly the authenticated customer’s data\nTypical Use\tAdmin dashboards, internal tools, automation, provisioning\tBuilding a custom customer portal or gated app\nToken Creation\tVia dashboard (manual)\tVia /v1/customer-sessions/ (server-side)\nSensitive Operations\tYes (create/update products, issue refunds, etc.)\tNo (read/update only what the customer owns)\nThe Customer Portal API is a restricted surface designed for safe exposure in user-facing contexts (after exchanging a session). It cannot perform privileged org-level mutations like creating products or issuing refunds.\n​\nQuick Examples\ncurl (Production - Core API)\ncurl (Sandbox - Core API)\ncurl (Customer Portal API)\nCopy\nAsk AI\ncurl https://api.polar.sh/v1/products/ \\\n  -H \"Authorization: Bearer $POLAR_OAT\" \\\n  -H \"Accept: application/json\"\n\n​\nUsing SDKs\nAll official SDKs accept a server parameter for sandbox usage:\nTypeScript\nPython\nGo\nPHP\nCopy\nAsk AI\nimport { Polar } from \"@polar-sh/sdk\";\n\nconst polar = new Polar({\naccessToken: process.env.POLAR_ACCESS_TOKEN!,\nserver: \"sandbox\", // omit or use 'production' for live\n});\n\n\n​\nPagination\nList endpoints in the Polar API support pagination to help you efficiently retrieve large datasets. Use the page and limit query parameters to control pagination.\n​\nQuery Parameters\nParameter\tType\tDefault\tMax\tDescription\npage\tinteger\t1\t-\tPage number, starting from 1\nlimit\tinteger\t10\t100\tNumber of items to return per page (window size)\nThe page parameter works as a window offset. For example, page=2&limit=10 means the API will skip the first 10 elements and return the next 10.\n​\nResponse Format\nAll paginated responses include a pagination object with metadata about the current page and total results:\nField\tType\tDescription\ntotal_count\tinteger\tTotal number of items matching your query across all pages\nmax_page\tinteger\tTotal number of pages available, given the current limit value\n​\nExample\nLet’s say you want to fetch products with a limit of 100 items per page:\nRequest\nResponse\nCopy\nAsk AI\ncurl https://api.polar.sh/v1/products/?page=1&limit=100 \\\n  -H \"Authorization: Bearer $POLAR_OAT\" \\\n  -H \"Accept: application/json\"\n\nIn this example:\ntotal_count=250 indicates there are 250 total products\nlimit=100 means each page contains up to 100 products\nmax_page=3 means you need to make 3 requests to retrieve all products (pages 1, 2, and 3)\nTo retrieve all pages, increment the page parameter from 1 to max_page. Our SDKs provide built-in pagination helpers to automatically iterate through all pages.\n​\nRate Limits\nPolar API has rate limits to ensure fair usage and maintain performance. The limits are as follows:\n300 requests per minute per organization/customer or OAuth2 Client.\n3 requests per second for unauthenticated license key validation, activation, and deactivation endpoints.\nIf you exceed the rate limit, you will receive a 429 Too Many Requests response. The response will include a Retry-After header indicating how long you should wait before making another request.\nOrganizations requiring higher rate limits for production workloads may contact our support team to discuss elevated limits.\n\nWas this page helpful?\n\nYes\nNo\nCreate Checkout Session\nCreate a checkout session. **Scopes**: `checkouts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Checkout Links - Polar",
    "url": "https://polar.sh/docs/features/checkout/links",
    "html": "Checkout\nCheckout Links\nCopy page\n\nSell your digital products with ease by sharing a checkout link to select products\n\nCheckout links can be shared or linked on your website which automatically creates a checkout session for customers.\nLooking for a way to generate Checkout session programmatically? Checkout Links might not be the right tool for you. Instead, you should use the Checkout API.\n​\nCreate a Checkout Link\nCheckout Links can be managed from the Checkout Links tabs of the Products section. Click on New Link to create a new one.\n​\nLabel\nThis is an internal name for the Checkout Link. It’s only visible to you.\n​\nProducts\nYou can select one or several products. With several products, customers will be able to switch between them on the checkout page.\n​\nDiscount\nYou can disable discount codes, if you wish to prevent customers from using them.\nYou can also preset a discount: it’ll be automatically applied when the customer lands on the checkout page.\n​\nMetadata\nThis is an optional key-value object allowing you to store additional information which may be useful for you when handling the order. This metadata will be copied to the generated Checkout object and, if the checkout succeeds, to the resulting Order and/or Subscription.\n​\nUsing Checkout Links\nYou can share the Checkout Link URL on your webpage, social media, or directly to customers.\nCheckout Links will go against our API, and redirect to short-lived Checkout session. This means that the Checkout page the user will end up on, are temporary and expires after a while if no successful purchase is made.\nThis means that you need to make sure to always use this Checkout Link URL (as shown above). If you mistakenly copy the URL from a Checkout Session, the link will expire.\n​\nQuery parameters\nYou can pass optional query parameters to your Checkout Links.\n​\nPrepopulate fields\nYou can prefill the checkout fields with the following query parameters:\n​\ncustomer_email\nstring\nPrefill customer email at checkout\n​\ncustomer_name\nstring\nPrefill customer name at checkout\n​\ndiscount_code\nstring\nPrefill discount code\n​\namount\nstring\nPrefill amount in case of Pay What You Want pricing\n​\ncustom_field_data.{slug}\nstring\nPrefill checkout fields data, where {slug} is the slug of the custom field.\n​\nStore attribution and reference metadata\nThe following query parameters will automatically be set on Checkout metadata.\n​\nreference_id\nstring\nYour own reference ID for the checkout session.\n​\nutm_source\nstring\nUTM source of the checkout session.\n​\nutm_medium\nstring\nUTM medium of the checkout session.\n​\nutm_campaign\nstring\nUTM campaign of the checkout session.\n​\nutm_content\nstring\nUTM content of the checkout session.\n​\nutm_term\nstring\nUTM term of the checkout session.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nEmbedded Checkout\nEmbed our checkout directly on your site\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Embedded Checkout - Polar",
    "url": "https://polar.sh/docs/features/checkout/embed",
    "html": "Checkout\nEmbedded Checkout\nCopy page\n\nEmbed our checkout directly on your site\n\nYou can either copy and paste our code snippet to get up and running in a second or use our JavaScript library for more advanced integrations. Our embedded checkout allows you to provide a seamless purchasing experience without redirecting users away from your site.\n​\nCode Snippet\nThe code snippet can be used on any website or CMS that allows you to insert HTML.\nFirst, create a Checkout Link as described in the previous section. The code snippet can directly be copied from there by clicking on Copy Embed Code.\nThe snippet looks like this:\nCopy\nAsk AI\n<a\n  href=\"__CHECKOUT_LINK__\"\n  data-polar-checkout\n  data-polar-checkout-theme=\"light\"\n>\n  Purchase\n</a>\n<script\n  src=\"https://cdn.jsdelivr.net/npm/@polar-sh/checkout@0.1/dist/embed.global.js\"\n  defer\n  data-auto-init\n></script>\n\nThis will display a Purchase link which will open an inline checkout when clicked.\nYou can style the trigger element any way you want, as long as you keep the data-polar-checkout attribute.\n​\nImport Library\nIf you have a more advanced project in JavaScript, like a React app, adding the <script> tag may not be an option. In this case, you can install our dedicated library.\nnpm\npnpm\nyarn\nCopy\nAsk AI\nnpm install @polar-sh/checkout\n\nThen, you should import the PolarEmbedCheckout helper class and manually call PolarEmbedCheckout.init(). This will add the required handlers on elements having the data-polar-checkout attribute.\nHere is an example in React:\nCopy\nAsk AI\nimport { PolarEmbedCheckout } from '@polar-sh/checkout/embed'\nimport { useEffect } from 'react'\n\nconst PurchaseLink = () => {\n  useEffect(() => {\n    PolarEmbedCheckout.init()\n  }, [])\n\n  return (\n    <a\n      href=\"__CHECKOUT_LINK__\"\n      data-polar-checkout\n      data-polar-checkout-theme=\"light\"\n    >\n      Purchase\n    </a>\n  )\n}\n\nexport default PurchaseLink\n\nInstead of a Checkout Link, you can also use a Checkout Session URL created dynamically from the API.\nFor this to work, make sure to set the embed_origin parameter correctly when creating the Checkout Session. For example, if your checkout page is served on the URL https://example.com/checkout, you should set embed_origin to https://example.com.\n​\nAdvanced Integration\nFor users who need more control over the embedded checkout flow, the PolarEmbedCheckout class provides several advanced features.\n​\nProgrammatically creating an embed\nInstead of using declarative triggers with data-polar-checkout attributes, you can programmatically create and control checkout instances:\nCopy\nAsk AI\nimport { PolarEmbedCheckout } from \"@polar-sh/checkout/embed\";\n\n// Open checkout programmatically when needed\nconst openCheckout = async () => {\n  const checkoutLink = \"__CHECKOUT_LINK__\";\n  const theme = \"light\"; // or 'dark'\n\n  try {\n    // This creates the checkout iframe and returns a Promise\n    // that resolves when the checkout is fully loaded\n    const checkout = await PolarEmbedCheckout.create(checkoutLink, theme);\n\n    // Now you can interact with the checkout instance\n    return checkout;\n  } catch (error) {\n    console.error(\"Failed to open checkout\", error);\n  }\n};\n\n// Example: Trigger checkout when a button is clicked\ndocument.getElementById(\"buy-button\").addEventListener(\"click\", () => {\n  openCheckout();\n});\n\n​\nListening for checkout events\nYou can listen for checkout events to respond to user interactions:\nCopy\nAsk AI\nimport { PolarEmbedCheckout } from \"@polar-sh/checkout/embed\";\n\nconst openCheckoutWithEvents = async () => {\n  const checkout = await PolarEmbedCheckout.create(\"__CHECKOUT_LINK__\");\n\n  // Listen for when the checkout is loaded\n  checkout.addEventListener(\"loaded\", (event) => {\n    console.log(\"Checkout loaded\");\n    // Call event.preventDefault() if you want to prevent the standard behavior\n    // event.preventDefault()\n    // Note: This would prevent removing the loader if it's still visible\n  });\n\n  // Listen for when the checkout has been closed\n  checkout.addEventListener(\"close\", (event) => {\n    console.log(\"Checkout has been closed\");\n    // Call event.preventDefault() if you want to prevent the standard behavior\n    // event.preventDefault()\n  });\n\n  // Listen for when the checkout has been confirmed (payment processing)\n  checkout.addEventListener(\"confirmed\", (event) => {\n    console.log(\"Order confirmed, processing payment\");\n    // Call event.preventDefault() if you want to prevent the standard behavior\n    // event.preventDefault()\n    // Note: This would prevent setting the checkout as non-closable\n  });\n\n  // Listen for successful completion\n  checkout.addEventListener(\"success\", (event) => {\n    console.log(\"Purchase successful!\", event.detail);\n\n    // Call event.preventDefault() if you want to prevent the standard behavior\n    // event.preventDefault()\n    // Note: For success event, this prevents automatic redirection if redirect is true\n\n    // If redirect is false, you can show your own success message\n    if (!event.detail.redirect) {\n      showSuccessMessage();\n    }\n    // Otherwise, the user will be redirected to the success URL (unless prevented)\n  });\n\n  return checkout;\n};\n\n​\nReact Integration with event handling\nHere’s a more complete React example that handles checkout events:\nCopy\nAsk AI\nimport { PolarEmbedCheckout } from '@polar-sh/checkout/embed'\nimport { useState, useEffect } from 'react'\n\nconst CheckoutButton = () => {\n  const [checkoutInstance, setCheckoutInstance] = useState(null)\n\n  // Clean up checkout instance on unmount\n  useEffect(() => {\n    return () => {\n      if (checkoutInstance) {\n        checkoutInstance.close()\n      }\n    }\n  }, [checkoutInstance])\n\n  const handleCheckout = async () => {\n      try {\n        const checkout = await PolarEmbedCheckout.create(\n          '__CHECKOUT_LINK__',\n          'light'\n        )\n\n      setCheckoutInstance(checkout)\n\n      checkout.addEventListener('success', (event) => {\n        // Track successful purchase\n        analytics.track('Purchase Completed', {\n          productId: 'your-product-id',\n          // Add other analytics data\n        })\n\n        // Show success message or redirect\n        if (!event.detail.redirect) {\n          // Handle success in your app\n        }\n      })\n\n      checkout.addEventListener('close', (event) => {\n        // Clean up our reference when checkout is closed\n        setCheckoutInstance(null)\n      })\n    } catch (error) {\n      console.error('Failed to open checkout', error)\n    }\n  }\n\n  return (\n    <button onClick={handleCheckout}>\n      Complete Purchase\n    </button>\n  )\n}\n\nexport default CheckoutButton\n\n​\nProgrammatically closing checkout\nIn some cases, you might need to programmatically close the checkout - for instance, if you detect that a user needs to take an action elsewhere in your application first:\nCopy\nAsk AI\nimport { PolarEmbedCheckout } from \"@polar-sh/checkout/embed\";\n\n// Example: open checkout and store the instance\nlet activeCheckout = null;\n\nasync function openCheckout() {\n  const checkout = await PolarEmbedCheckout.create(\"__CHECKOUT_LINK__\");\n  activeCheckout = checkout;\n  return checkout;\n}\n\n// Later, close it programmatically when needed\nfunction closeCheckout() {\n  if (activeCheckout) {\n    activeCheckout.close();\n    // The 'close' event will fire automatically\n    // Don't set activeCheckout to null here, as we'll handle that in the event listener\n  }\n}\n\n// Add a listener to update our reference when checkout is closed\nfunction setupCheckout(checkout) {\n  checkout.addEventListener(\"close\", (event) => {\n    // Reset our reference when checkout is closed\n    activeCheckout = null;\n  });\n  return checkout;\n}\n\n// Example usage\ndocument.getElementById(\"open-checkout\").addEventListener(\"click\", async () => {\n  const checkout = await openCheckout();\n  setupCheckout(checkout);\n});\ndocument\n  .getElementById(\"close-checkout\")\n  .addEventListener(\"click\", closeCheckout);\n\n​\nEnabling Wallet Payment Methods (Apple Pay, Google Pay, etc.)\nWallet payment methods such as Apple Pay and Google Pay are supported in the checkout with the following conditions:\nApple Pay appears automatically in the checkout if:\nThe user is on an Apple device\nThe browser is Safari\nThe device is connected to an Apple account with Apple Pay configured\nGoogle Pay appears automatically in the checkout if:\nThe user is on Google Chrome\nThe browser is connected to a Google account with Google Pay configured\nNo additional action is required if you meet these conditions and are not using an embedded checkout.\n​\nEnabling Wallet Payments for Embedded Checkout\nBy default, wallet payment methods (Apple Pay, Google Pay, etc.) are not enabled when you embed our checkout form into your website. For security reasons, your website domain needs to be manually validated before enabling these payment methods in embedded mode.\nTo enable wallet payment methods on your embedded checkout, please email us with:\nYour organization slug\nThe domain you wish to allow for wallet payments\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCheckout API\nCreate checkout sessions programmatically for complete control\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Automate Customer License Key Management - Polar",
    "url": "https://polar.sh/docs/features/benefits/license-keys",
    "html": "Benefits\nAutomate Customer License Key Management\nCopy page\n\nSell license key access to your service, software or APIs with ease\n\nYou can easily sell software license keys with Polar without having to deal with sales tax or hosting an API to validate them in real-time. License keys with Polar come with a lot of powerful features built-in.\nBrandable prefixes, e.g POLAR_*****\nAutomatic expiration after N days, months or years\nLimited number of user activations, e.g devices\nCustom validation conditions\nUsage quotas per license key\nAutomatic revokation upon cancelled subscriptions\n​\nCreate License Key Benefit\nGo to Benefits in the sidebar\nClick + New Benefit to create a new benefit\nChoose License Keys as the Type\n​\nCustom Branding\nMake your license keys standout with brandable prefixes, e.g MYAPP_<AUTO_GENERATED_UUID4>\n​\nAutomatic Expiration\nWant license keys to expire automatically after a certain time period from when the customer bought them? No problem.\n​\nActivation Limits\nYou can require license keys to be activated before future validation. A great feature in case you want to limit license key usage to a certain number of devices, IPs or other conditions.\nEnable user to deactivate instances via Polar. Instead of building your own custom admin for customers to manage their activation instances - leave it to Polar instead.\n​\nUsage Limit\nOffering OpenAI tokens or anything else with a variable usage cost? You can set a custom usage quota per license key and increment usage upon validation.\n​\nCustomer Experience\nOnce customers buy your product or subscribes to your tier, they will automatically receive a unique license key. It’s easily accessible to them under their purchases page.\nCustomers can:\nView & copy their license key\nSee expiration date (if applicable)\nSee usage left (if applicable)\nDeactivate activations (if enabled)\n​\nIntegrate API\nIt’s super easy and straightforward to integrate Polar license keys into your application, library or API.\n​\nActivate License Keys (Optional)\nIn case you’ve setup license keys to have a maximum amount of activation instances, e.g user devices. You’ll then need to create an activation instance prior to validating license keys / activation.\nNo activation limit? You can skip this step.\nCopy\nAsk AI\ncurl -X POST https://api.polar.sh/v1/customer-portal/license-keys/activate\n-H \"Content-Type: application/json\"\n-d '{\n  \"key\": \"1C285B2D-6CE6-4BC7-B8BE-ADB6A7E304DA\",\n  \"organization_id\": \"fda84e25-7b55-4d67-916d-60ead04ff61f\",\n  \"label\": \"hello\",\n  \"conditions\": { \"major_version\": 1 },\n  \"meta\": { \"ip\": \"84.19.145.194\" }\n}'\n\n​\nkey\nstringrequired\nReplace with the users license key (from input in your app).\n​\norganization_id\nstringrequired\nReplace with your organization ID here found in your settings.\n​\nlabel\nstringrequired\nSet a label to associate with this specific activation.\n​\nconditions\nobject\nJSON object with custom conditions to validate against in the future, e.g IP, mac address, major version etc.\n​\nmeta\nobject\nJSON object with metadata to store for the users activation.\n​\nResponse (200 OK)\nCopy\nAsk AI\n{\n  \"id\": \"b6724bc8-7ad9-4ca0-b143-7c896fcbb6fe\",\n  \"license_key_id\": \"508176f7-065a-4b5d-b524-4e9c8a11ed63\",\n  \"label\": \"hello\",\n  \"meta\": {\n    \"ip\": \"84.19.145.194\"\n  },\n  \"created_at\": \"2024-09-02T13:48:13.251621Z\",\n  \"modified_at\": null,\n  \"license_key\": {\n    \"id\": \"508176f7-065a-4b5d-b524-4e9c8a11ed63\",\n    \"organization_id\": \"fda84e25-7b55-4d67-916d-60ead04ff61f\",\n    \"user_id\": \"d910050c-be66-4ca0-b4cc-34fde514f227\",\n    \"benefit_id\": \"32a8eda4-56cf-4a94-8228-792d324a519e\",\n    \"key\": \"1C285B2D-6CE6-4BC7-B8BE-ADB6A7E304DA\",\n    \"display_key\": \"****-E304DA\",\n    \"status\": \"granted\",\n    \"limit_activations\": 3,\n    \"usage\": 0,\n    \"limit_usage\": 100,\n    \"validations\": 0,\n    \"last_validated_at\": null,\n    \"expires_at\": \"2026-08-30T08:40:34.769148Z\"\n  }\n}\n\n​\nValidate License Keys\nFor each session of your premium app, library or API, we recommend you validate the users license key via the /v1/customer-portal/license-keys/validate endpoint.\nCopy\nAsk AI\ncurl -X POST https://api.polar.sh/v1/customer-portal/license-keys/validate\n-H \"Content-Type: application/json\"\n-d '{\n  \"key\": \"1C285B2D-6CE6-4BC7-B8BE-ADB6A7E304DA\",\n  \"organization_id\": \"fda84e25-7b55-4d67-916d-60ead04ff61f\",\n  \"activation_id\": \"b6724bc8-7ad9-4ca0-b143-7c896fcbb6fe\",\n  \"conditions\": { \"major_version\": 1 },\n  \"increment_usage\": 15\n}'\n\n​\nkey\nstringrequired\nReplace with the users license key (from input in your app).\n​\norganization_id\nstringrequired\nReplace with your organization ID here found in your settings.\n​\nactivation_id\nstring\nThe activation ID to validate - required in case activations limit is enabled and used (above).\n​\nconditions\nobject\nIn case of activation instances. Same exact JSON object as upon registration of the activation.\n​\nincrement_usage\ninteger\nIn case you want to increment usage upon validation.\n​\nResponse (200 OK)\nCopy\nAsk AI\n{\n  \"id\": \"508176f7-065a-4b5d-b524-4e9c8a11ed63\",\n  \"organization_id\": \"fda84e25-7b55-4d67-916d-60ead04ff61f\",\n  \"user_id\": \"d910050c-be66-4ca0-b4cc-34fde514f227\",\n  \"benefit_id\": \"32a8eda4-56cf-4a94-8228-792d324a519e\",\n  \"key\": \"1C285B2D-6CE6-4BC7-B8BE-ADB6A7E304DA\",\n  \"display_key\": \"****-E304DA\",\n  \"status\": \"granted\",\n  \"limit_activations\": 3,\n  \"usage\": 15,\n  \"limit_usage\": 100,\n  \"validations\": 5,\n  \"last_validated_at\": \"2024-09-02T13:57:00.977363Z\",\n  \"expires_at\": \"2026-08-30T08:40:34.769148Z\",\n  \"activation\": {\n    \"id\": \"b6724bc8-7ad9-4ca0-b143-7c896fcbb6fe\",\n    \"license_key_id\": \"508176f7-065a-4b5d-b524-4e9c8a11ed63\",\n    \"label\": \"hello\",\n    \"meta\": {\n      \"ip\": \"84.19.145.194\"\n    },\n    \"created_at\": \"2024-09-02T13:48:13.251621Z\",\n    \"modified_at\": null\n  }\n}\n\nValidate benefit_id in case of multiple license keys\nWe require organization_id to be provided to avoid cases of Polar license keys being used across Polar organizations erroneously. Otherwise, a valid license key for one organization could be used on another.However, you are required to validate and scope license keys more narrowly within your organization if necessary. Offering more than one type of license key? Be sure to validate their unique benefit_id in the responses.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nFile Downloads\nOffer digital file downloads with ease\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Automate Customer File Downloads - Polar",
    "url": "https://polar.sh/docs/features/benefits/file-downloads",
    "html": "Benefits\nAutomate Customer File Downloads\nCopy page\n\nOffer digital file downloads with ease\n\n​\nSell Digital Products\nYou can easily offer customers and subscribers access to downloadable files with Polar.\nUp to 10GB per file\nUpload any type of file - from ebooks to full-fledged applications\nSHA-256 checksum validation throughout for you and your customers (if desired)\nCustomers get a signed & personal downloadable URL\n​\nCreate Downloadable Benefit\nGo to Benefits in the Dashboard sidebar\nClick + Add Benefit to create a new benefit\nChoose File Downloads as the Type\nYou can now upload the files you want to offer as downloadables for customers.\nDrag & drop files to the dropzone (Feed me some bytes)\nOr click on that area to open a file browser\n​\nChange filename\nClick on the filename to change it inline.\n​\nChange order of files\nYou can drag and drop the files in the order you want.\n​\nReview SHA-256 checksum\nClick on the contextual menu dots and then Copy SHA-256 Checksum\n​\nDelete a file\nClick on the contextual menu dots and then Delete in the menu.\nActive subscribers & customers will lose access too!\nDeleting a file permanently deletes it from Polar and our S3 buckets except for the metadata. Disable the file instead if you don’t want it permanently deleted.\n​\nDisable & Enable Files\nYou can disable files at any point to prevent new customers getting access to it.\nExisting customers retain their access\nCustomers who purchased before the file was disabled will still have access to legacy files. Only new customers will be impacted.\nEnabling or adding files grants access retroactively\nIn case you add more files or re-enable existing ones, all current customers and subscribers with the benefit will be granted access.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDiscord Access\nSell Discord access & roles with ease\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Automate Private GitHub Repo(s) Access - Polar",
    "url": "https://polar.sh/docs/features/benefits/github-access",
    "html": "Benefits\nAutomate Private GitHub Repo(s) Access\nCopy page\n\nSell premium GitHub repository access with ease\n\n​\nSell GitHub Repository Access\nWith Polar you can seamlessly offer your customers and subscribers automated access to private GitHub repositories.\nFully automated collaborator invites\nUnlimited repositories (via multiple benefits) from your organization(s)\nUsers get access upon subscribing & removed on cancellation\nOr get lifetime access upon paying a one-time price (product)\n​\nUse cases\nSponsorware\nAccess to private GitHub discussions & issues for sponsors\nEarly access to new feature development before upstream push\nPremium educational materials & code\nSelf-hosting products\nCourses, starter kits, open core software & more…\n​\nCreate GitHub Repository Benefit\nGo to Benefits in the sidebar\nClick + New Benefit to create a new benefit\nChoose GitHub Repository Access as the Type\nYou first need to Connect your GitHub Account and install a dedicated Polar App for this benefit across the repositories you want to use it with.\nClick Connect your GitHub Account\nWhy do I need to connect GitHub again and install a separate app?\nThis feature requires permission to manage repository collaborators. GitHub Apps does not support progressive permission scope requests. So instead of requesting this sensitive permission from all users (unnecessarily) in our core GitHub Login this feature uses a standalone app instead.\nOnce you’ve authorized our dedicated GitHub App for this feature you’ll be redirected back to Polar and the benefit form - now connected and updated.\n​\nRepository\nSelect the desired repository you want to automate collaborator invites for.\nWhy can I only connect organization repositories vs. personal ones?\nGitHub does not support granular permissions for collaborators on personal repositories - granting them all write permissions instead. Since collaborators would then be able to push changes, releases and more, we do not support personal repositories by default.Want this still? Reach out to us and we can enable it.\n​\nRole\nSelect the role you want to grant collaborators.\nRead (Default & Highly recommended)\nTriage\nWrite\nMaintain\nAdmin\nRead access (read-only) is what 99.9% of cases should use and the others are highly discouraged unless you have special use cases & absolutely know the impact of these permissions. Checkout the GitHub documentation for reference.\nAnyone with read access to a repository can create a pull request (source).\nAdditional Costs for Paid GitHub Organizations\nGitHub treats collaborators as a seat and they will incurr charges accordingly to your billing unless you’re using a free GitHub organization plan. So make sure to confirm you’re on a free plan OR charge sufficiently to offset the costs you’ll need to pay to GitHub.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCredits\nCreate your own Credits benefit\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Automate Discord Invites & Roles - Polar",
    "url": "https://polar.sh/docs/features/benefits/discord-access",
    "html": "Benefits\nAutomate Discord Invites & Roles\nCopy page\n\nSell Discord access & roles with ease\n\nAutomating Discord server invites and roles for customers or subscribers is super easy and powerful with Polar.\nFully automated Discord server invitations\nYou can even setup multiple Discord servers, or…\nOffer different roles for different subscription tiers or products\n​\nCreate Discord Benefit\nClick on Connect your Discord server. You’ll be redirected to Discord where you can grant the Polar App for your desired server.\nNext, you’ll be prompted to approve the permissions our app requires to function. It needs all of them.\n​\nManage Roles\nAccess to your Discord roles. You’ll be able to select which ones to grant to your customers later.\n​\nKick Members\nAbility to kick members who have this benefit and connected Discord with Polar.\n​\nCreate Invite\nAbility to invite members who purchase a product or subscribes to a tier with this benefit.\nYou’re now redirected back to Polar and can finish setting up the Discord benefit on our end.\n​\nConnected Discord server\nThe Discord server you connected cannot be changed. However, you can create multiple benefits and connect more Discord servers if you want.\n​\nGranted role\nWhich Discord role do you want to grant as part of this benefit?\n​\nAdding Benefit to Product\nHead over to the product you want to associate this new Discord benefit with. You should be able to toggle the benefit in the bottom of the Edit Product form.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGitHub Access\nSell premium GitHub repository access with ease\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Integrate Polar with Next.js - Polar",
    "url": "https://polar.sh/docs/guides/nextjs",
    "html": "Framework Guides\nIntegrate Polar with Next.js\nCopy page\n\nIn this guide, we’ll show you how to integrate Polar with Next.js.\n\nFeel free to use our quick-start script to get started inside a new Next.js project:\nCopy\nAsk AI\n# Inside a new Next.js project\nnpx polar-init\n\nConsider following this guide while using the Polar Sandbox Environment. This will allow you to test your integration without affecting your production data.\nA complete code-example of this guide can be found on GitHub.\n​\nInstall the Polar JavaScript SDK\nTo get started, you need to install the Polar JavaScript SDK and the Polar Nextjs helper package. You can do this by running the following command:\nCopy\nAsk AI\npnpm install @polar-sh/sdk @polar-sh/nextjs\n\n​\nSetting up environment variables\n​\nPolar Access Token\nTo authenticate with Polar, you need to create an access token, and supply it to Next.js using a POLAR_ACCESS_TOKEN environment variable.\nYou can create an organization access token from your organization settings.\n​\nConfiguring a Polar API Client\nTo interact with the Polar API, you need to create a new instance of the Polar class. This class uses the provided access token to authenticate with the Polar API.\nCopy\nAsk AI\n// src/polar.ts\nimport { Polar } from \"@polar-sh/sdk\";\n\nexport const api = new Polar({\n  accessToken: process.env.POLAR_ACCESS_TOKEN!,\n  server: \"sandbox\", // Use this option if you're using the sandbox environment - else use 'production' or omit the parameter\n});\n\nRemember to replace sandbox with production when you’re ready to switch to the production environment.\n​\nGenerating Polar Checkout Sessions\nNext up, we need to create a checkout endpoint to handle the creation of checkout sessions.\nGo ahead and create a new GET route in Next.js.\nCopy\nAsk AI\n// src/app/checkout/route.ts\nimport { Checkout } from \"@polar-sh/nextjs\";\n\nexport const GET = Checkout({\n  accessToken: process.env.POLAR_ACCESS_TOKEN!,\n  successUrl: \"/confirmation?checkout_id={CHECKOUT_ID}\",\n  server: \"sandbox\", // Use this option if you're using the sandbox environment - else use 'production' or omit the parameter\n});\n\n​\nHandling Polar Webhooks\nPolar can send you events about various things happening in your organization. This is very useful for keeping your database in sync with Polar checkouts, orders, subscriptions, etc.\nConfiguring a webhook is simple. Head over to your organization’s settings page and click on the “Add Endpoint” button to create a new webhook.\n​\nTunneling webhook events to your local development environment\nIf you’re developing locally, you can use a tool like ngrok to tunnel webhook events to your local development environment. This will allow you to test your webhook handlers without deploying them to a live server.\nRun the following command to start an ngrok tunnel:\nCopy\nAsk AI\nngrok http 3000\n\n​\nAdd Webhook Endpoint\nPoint the Webhook to your-app.com/api/webhook/polar. This must be an absolute URL which Polar can reach. If you use ngrok, the URL will look something like this: https://<your-ngrok-id>.ngrok-free.app/api/webhook/polar.\nSelect which events you want to be notified about. You can read more about the available events in the Events section.\nGenerate a secret key to sign the requests. This will allow you to verify that the requests are truly coming from Polar.\nAdd the secret key to your environment variables.\nCopy\nAsk AI\n# .env\nPOLAR_ACCESS_TOKEN=\"polar_pat...\"\nPOLAR_WEBHOOK_SECRET=\"...\"\n\n​\nSetting up the Webhook handler\nCopy\nAsk AI\n// src/app/api/webhook/polar/route.ts\nimport { Webhooks } from \"@polar-sh/nextjs\";\n\nexport const POST = Webhooks({\n\twebhookSecret: process.env.POLAR_WEBHOOK_SECRET,\n\tonPayload: async (payload) => // Handle payload...\n});\n\nThe webhook event is now verified and you can proceed to handle the payload data.\n​\nHandling Webhook Events\nDepending on which events you’ve subscribed to, you’ll receive different payloads. This is where you can update your database, send notifications, etc.\nCopy\nAsk AI\n// src/app/api/webhook/polar/route.ts\nimport { Webhooks } from \"@polar-sh/nextjs\";\n\nexport const POST = Webhooks({\n  webhookSecret: process.env.POLAR_WEBHOOK_SECRET,\n  onPayload: async (payload) => ...,\n  onOrderCreated: async (order) => ...,\n  onCustomerStateChanged: async (customerState) => ...,\n  ...\n});\n\n​\nNotifying the client about the event\nIf you’re building a real-time application, you might want to notify the client about the event. On the confirmation-page, you can listen for the checkout.updated event and update the UI accordingly when it reaches the succeeded status.\n​\nConclusion\nIf you have issues or need support, feel free to join our Discord.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nLaravel\nIn this guide, we'll show you how to integrate Polar with Laravel.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Automated Benefits - Polar",
    "url": "https://polar.sh/docs/features/benefits/introduction",
    "html": "Benefits\nAutomated Benefits\nCopy page\nPolar offers built-in benefit (entitlements) automation for common upsells within the developer & designer ecosystem with more to come.\nCredits. A simple benefit that allows you to credit a customer’s Usage Meter balance.\nLicense Keys. Software license keys that you can customize the branding of.\nFile Downloads. Downloadable files of any kind up to 10GB each.\nGitHub Repository Access. Automatically invite subscribers to private GitHub repo(s).\nDiscord Invite. Automate invitations and granting of roles to subscribers and customers.\n​\nProduct & Subscription Benefits\nProduct and subscription benefits are standalone resources in Polar - connected to one or many products or subscription tiers.\nThis approach is a bit different from other platforms, but offers many advantages:\nEasy to enable the same benefit across multiple products & subscriptions\nYou can change a benefit in one place vs. many\nNo duplicate data or work (error prone)\nMore intuitive UI for you and your customers\nHow customers get access to benefits:\n✅ Active subscribers of tiers with the benefit enabled\n✅ Customers who bought a product with the benefit (lifetime access)\n❌ Subscribers with an expired subscription (cancelled)\n❌ Users who are not customers\n​\nCreating & Managing Benefits\nYou can manage benefits in two ways:\nDirectly within a product create/edit form\nOr via Benefits in your dashboard\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nLicense Keys\nSell license key access to your service, software or APIs with ease\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Checkout API - Polar",
    "url": "https://polar.sh/docs/features/checkout/session",
    "html": "Checkout\nCheckout API\nCopy page\n\nCreate checkout sessions programmatically for complete control\n\nIf you want to integrate more deeply the checkout process with your website or application, you can use our dedicated API.\nThe first step is to create a Checkout session. For this you’ll need at least your Product ID.\nYou can retrieve your Product ID from Products in your dashboard, click on “context-menu” button in front of your product and click on Copy Product ID.\nThe API will return you an object containing all the information about the session, including an URL where you should redirect your customer so they can complete their order.\n​\nMultiple products\nYou can create a checkout session with multiple products. This is useful if you want to allow your customers to choose between different products before they checkout.\n​\nExternal Customer ID\nQuite often, you’ll have your own users management system in your application, where your customer already have an ID. To ease reconciliation between Polar and your system, you can inform us about your customer ID when creating a checkout session through the external_customer_id field.\nAfter a successful checkout, we’ll create a Customer on Polar with the external ID you provided. It’ll be provided through the customer.external_id property in webhooks you may have configured.\n​\nSDK examples\nUsing our SDK, creating a checkout session is quite straightforward.\nTypeScript\nPython\nCopy\nAsk AI\nimport { Polar } from \"@polar-sh/sdk\";\n\nconst polar = new Polar({\n  accessToken: process.env[\"POLAR_ACCESS_TOKEN\"] ?? \"\",\n});\n\nasync function run() {\n  const checkout = await polar.checkouts.create({\n    products: [\"productId\"]\n  });\n\n  console.log(checkout.url)\n}\n\nrun();\n\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nTrials\nOffer free trials on your subscriptions\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Product - Polar",
    "url": "https://polar.sh/docs/api-reference/products/update#body-is-archived",
    "html": "Products\nUpdate Product\nCopy page\n\nUpdate a product.\n\nScopes: products:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nproducts\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe product ID.\n\nBody\napplication/json\n\nSchema to update a product.\n\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ntrial_interval\nenum<string> | null\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | null\n\nThe number of interval units for the trial period.\n\nRequired range: 1 <= x <= 1000\n​\nname\nstring | null\n\nThe name of the product.\n\nMinimum length: 3\n​\ndescription\nstring | null\n\nThe description of the product.\n\n​\nrecurring_interval\nenum<string> | null\n\nThe recurring interval of the product. If None, the product is a one-time purchase. Can only be set on legacy recurring products. Once set, it can't be changed.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\ninteger | null\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on. Once set, it can't be changed.**\n\nRequired range: 1 <= x <= 999\n​\nis_archived\nboolean | null\n\nWhether the product is archived. If true, the product won't be available for purchase anymore. Existing customers will still have access to their benefits, and subscriptions will continue normally.\n\n​\nprices\nPrices · array\n\nList of available prices for this product. If you want to keep existing prices, include them in the list as an ExistingProductPrice object.\n\nExistingProductPrice\nProductPriceFixedCreate\nProductPriceCustomCreate\nProductPriceFreeCreate\nProductPriceSeatBasedCreate\nProductPriceMeteredUnitCreate\n\nShow child attributes\n\n​\nmedias\nstring<uuid4>[] | null\n\nList of file IDs. Each one must be on the same organization as the product, of type product_media and correctly uploaded.\n\n​\nattached_custom_fields\nAttachedCustomFieldCreate · object[] | null\n\nList of custom fields to attach.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nProduct updated.\n\nA product.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nname\nstringrequired\n\nThe name of the product.\n\n​\ndescription\nstring | nullrequired\n\nThe description of the product.\n\n​\nrecurring_interval\nenum<string> | nullrequired\n\nThe recurring interval of the product. If None, the product is a one-time purchase.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\ninteger | nullrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on. None for one-time products.\n\n​\nis_recurring\nbooleanrequired\n\nWhether the product is a subscription.\n\n​\nis_archived\nbooleanrequired\n\nWhether the product is archived and no longer available.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the product.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of prices for this product.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nbenefits\nBenefits · arrayrequired\n\nList of benefits granted by the product.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nShow child attributes\n\n​\nmedias\nProductMediaFileRead · object[]required\n\nList of medias associated to the product.\n\nShow child attributes\n\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nList of custom fields attached to the product.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Product Benefits\nUpdate benefits granted by a product. **Scopes**: `products:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Introduction - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/introduction",
    "html": "Usage Based Billing\nIntroduction\nCopy page\n\nUsage based billing using ingested events\n\nUsage Based Billing is a new feature. We have a lot in store and welcome feedback!\n​\nOverview\nPolar has a powerful Usage Based Billing infrastructure that allows you to charge your customers based on the usage of your application.\nThis is done by ingesting events from your application, creating Meters to represent that usage, and then adding metered prices to Products to charge for it.\n​\nConcepts\n​\nEvents\nEvents are the core of Usage Based Billing. They represent some usage done by a customer in your application. Typical examples of events are:\nA customer consumed AI LLM tokens\nA customer streamed minutes of video\nA customer uploaded a file to your application\nEvents are sent to Polar using the Events Ingestion API and are stored in our database. An event consists of the following fields:\nA name, which is a string that can be used to identify the type of event. For example, ai_usage, video_streamed or file_uploaded.\nA customer_id or external_customer_id, which is Polar’s customer ID or your user’s ID. This is used to identify the customer that triggered the event.\nA metadata object, which is a JSON object that can contain any additional information about the event. This is useful for storing information that can be used to filter the events or compute the actual usage. For example, you can store the duration of the video streamed or the size of the file uploaded.\nHere is an example of an event:\nCopy\nAsk AI\n{\n  \"name\": \"ai_usage\",\n  \"external_customer_id\": \"cus_123\",\n  \"metadata\": {\n    \"model\": \"gpt-4.1-nano\",\n    \"requests\": 1,\n    \"total_tokens\": 77,\n    \"request_tokens\": 58,\n    \"response_tokens\": 19\n  }\n}\n\n​\nMeters\nMeters are there to filter and aggregate the events that are ingested. Said another way, this is how you define what usage you want to charge for, based on the events you send to Polar. For example:\nAI usage meter, which filters the events with the name ai_usage and sums the total_tokens field.\nVideo streaming meter, which filters the events with the name video_streamed and sums the duration field.\nFile upload meter, which filters the events with the name file_uploaded and sums the size field.\nYou can create and manage your meters from the dashboard. Polar is then able to compute the usage over time, both globally and per customer.\n​\nMetered Price\nA metered price is a price that is based on the usage of a meter, which is computed by filtering aggregating the events that are ingested. This is how you charge your customers for the usage of your application.\n​\nMeter Credits benefit\nYou can give credits to your customers on a specific meter. This is done by creating a Meter Credits Benefit, which is a special type of benefit that allows you to give credits to your customers on a specific meter.\nOn a recurring product, the customer will be credited the amount of units specified in the benefit at the beginning of every subscription cycle period — monthly or yearly.\n​\nQuickstart\nGet up and running in 5 minutes\n1\n\nCreate a Meter\n\nMeters consist of filters and an aggregation function. The filter is used to filter the events that should be included in the meter and the aggregation function is used to compute the usage.\n2\n\nAdd metered price to a Product\n\nTo enable usage based billing for a Product, you need to add a metered price to the Product. Metered prices are only applicable to Subscription Products.\n3\n\nIngest Events\n\nNow you’re ready to ingest events from your application. Sending events which match the meter’s filter will increment the meter’s usage for the customer.\n4\n\nCustomer Usage\n\nCustomers can view their estimated charges for each meter in the Customer Portal.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nEvent Ingestion\nIngest events from your application\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Checkout Session - Polar",
    "url": "https://polar.sh/docs/api-reference/checkouts/create-session",
    "html": "Checkout\nCreate Checkout Session\nCopy page\n\nCreate a checkout session.\n\nScopes: checkouts:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckouts\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n\nCreate a new checkout session from a list of products.\nCustomers will be able to switch between those products.\n\nMetadata set on the checkout will be copied\nto the resulting order and/or subscription.\n\n​\nproducts\nstring<uuid4>[]required\n\nList of product IDs available to select at that checkout. The first one will be selected by default.\n\nMinimum length: 1\n​\ntrial_interval\nenum<string> | null\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | null\n\nThe number of interval units for the trial period.\n\nRequired range: 1 <= x <= 1000\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\ndiscount_id\nstring<uuid4> | null\n\nID of the discount to apply to the checkout.\n\n​\nallow_discount_codes\nbooleandefault:true\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleandefault:false\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\namount\ninteger | null\n\nAmount in cents, before discounts and taxes. Only useful for custom prices, it'll be ignored for fixed and free prices.\n\nRequired range: 50 <= x <= 99999999\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing. Required for seat-based products.\n\nRequired range: 1 <= x <= 1000\n​\ncustomer_id\nstring<uuid4> | null\n\nID of an existing customer in the organization. The customer data will be pre-filled in the checkout form. The resulting order will be linked to this customer.\n\n​\nis_business_customer\nbooleandefault:false\n\nWhether the customer is a business or an individual. If true, the customer will be required to fill their full billing address and billing name.\n\n​\nexternal_customer_id\nstring | null\n\nID of the customer in your system. If a matching customer exists on Polar, the resulting order will be linked to this customer. Otherwise, a new customer will be created with this external ID set.\n\n​\ncustomer_name\nstring | null\n\nName of the customer.\n\n​\ncustomer_email\nstring<email> | null\n\nEmail address of the customer.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | null\n​\ncustomer_billing_name\nstring | null\n​\ncustomer_billing_address\nobject | null\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | null\n​\ncustomer_metadata\nobject\n\nKey-value object allowing you to store additional information that'll be copied to the created customer.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nsubscription_id\nstring<uuid4> | null\n\nID of a subscription to upgrade. It must be on a free pricing. If checkout is successful, metadata set on this checkout will be copied to the subscription, and existing keys will be overwritten.\n\n​\nsuccess_url\nstring<uri> | null\n\nURL where the customer will be redirected after a successful payment.You can add the checkout_id={CHECKOUT_ID} query parameter to retrieve the checkout session id.\n\nRequired string length: 1 - 2083\n​\nreturn_url\nstring<uri> | null\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\nRequired string length: 1 - 2083\n​\nembed_origin\nstring | null\n\nIf you plan to embed the checkout session, set this to the Origin of the embedding page. It'll allow the Polar iframe to communicate with the parent page.\n\nResponse\n201\napplication/json\n\nCheckout session created.\n\nCheckout session data retrieved using an access token.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nstatus\nenum<string>required\nStatus of the checkout session.\n\n    - Open: the checkout session was opened.\n    - Expired: the checkout session was expired and is no more accessible.\n    - Confirmed: the user on the checkout session clicked Pay. This is not indicative of the payment's success status.\n    - Failed: the checkout definitely failed for technical reasons and cannot be retried. In most cases, this state is never reached.\n    - Succeeded: the payment on the checkout was performed successfully.\nAvailable options: open, expired, confirmed, succeeded, failed \n​\nclient_secret\nstringrequired\n\nClient secret used to update and complete the checkout session from the client.\n\n​\nurl\nstringrequired\n\nURL where the customer can access the checkout session.\n\n​\nexpires_at\nstring<date-time>required\n\nExpiration date and time of the checkout session.\n\n​\nsuccess_url\nstringrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nreturn_url\nstring | nullrequired\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\n​\nembed_origin\nstring | nullrequired\n\nWhen checkout is embedded, represents the Origin of the page embedding the checkout. Used as a security measure to send messages only to the embedding page.\n\n​\namount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\n​\ntax_amount\ninteger | nullrequired\n\nSales tax amount in cents. If null, it means there is no enough information yet to calculate it.\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\n​\ncurrency\nstringrequired\n\nCurrency code of the checkout session.\n\n​\nactive_trial_interval\nenum<string> | nullrequired\n\nInterval unit of the trial period, if any. This value is either set from the checkout, if trial_interval is set, or from the selected product.\n\nAvailable options: day, week, month, year \n​\nactive_trial_interval_count\ninteger | nullrequired\n\nNumber of interval units of the trial period, if any. This value is either set from the checkout, if trial_interval_count is set, or from the selected product.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nEnd date and time of the trial period, if any.\n\n​\nproduct_id\nstring<uuid4>required\n\nID of the product to checkout.\n\n​\nproduct_price_id\nstring<uuid4>required\n\nID of the product price to checkout.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount applied to the checkout.\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\nis_discount_applicable\nbooleanrequired\n\nWhether the discount is applicable to the checkout. Typically, free and custom prices are not discountable.\n\n​\nis_free_product_price\nbooleanrequired\n\nWhether the product price is free, regardless of discounts.\n\n​\nis_payment_required\nbooleanrequired\n\nWhether the checkout requires payment, e.g. in case of free products or discounts that cover the total amount.\n\n​\nis_payment_setup_required\nbooleanrequired\n\nWhether the checkout requires setting up a payment method, regardless of the amount, e.g. subscriptions that have first free cycles.\n\n​\nis_payment_form_required\nbooleanrequired\n\nWhether the checkout requires a payment form, whether because of a payment or payment method setup.\n\n​\ncustomer_id\nstring<uuid4> | nullrequired\n​\nis_business_customer\nbooleanrequired\n\nWhether the customer is a business or an individual. If true, the customer will be required to fill their full billing address and billing name.\n\n​\ncustomer_name\nstring | nullrequired\n\nName of the customer.\n\n​\ncustomer_email\nstring | nullrequired\n\nEmail address of the customer.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | nullrequired\n​\ncustomer_billing_name\nstring | nullrequired\n​\ncustomer_billing_address\nobject | nullrequired\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | nullrequired\n​\npayment_processor_metadata\nobjectrequired\n\nShow child attributes\n\n​\nbilling_address_fields\nobjectrequired\n\nDetermine which billing address fields should be disabled, optional or required in the checkout form.\n\nShow child attributes\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_customer_id\nstring | nullrequired\n\nID of the customer in your system. If a matching customer exists on Polar, the resulting order will be linked to this customer. Otherwise, a new customer will be created with this external ID set.\n\n​\ncustomer_external_id\nstring | nullrequireddeprecated\n​\nproducts\nCheckoutProduct · object[]required\n\nList of products available to select.\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nProduct selected to checkout.\n\nShow child attributes\n\n​\nproduct_price\nobjectrequired\n\nPrice of the selected product.\nA recurring price for a product, i.e. a subscription.\n\nDeprecated: The recurring interval should be set on the product itself.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\n\nSchema for a fixed amount discount that is applied once or forever.\n\nCheckoutDiscountFixedOnceForeverDuration\nCheckoutDiscountFixedRepeatDuration\nCheckoutDiscountPercentageOnceForeverDuration\nCheckoutDiscountPercentageRepeatDuration\n\nShow child attributes\n\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nShow child attributes\n\n​\ncustomer_metadata\nobjectrequired\n\nShow child attributes\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\n​\nprice_per_seat\ninteger | null\n\nPrice per seat in cents for the current seat count, based on the applicable tier. Only relevant for seat-based pricing.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Checkout Session\nGet a checkout session by ID. **Scopes**: `checkouts:read` `checkouts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Assign Seat - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-seats/assign",
    "html": "Customer Seats\nAssign Seat\nCopy page\n\nScopes: customer_seats:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-seats\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nsubscription_id\nstring<uuid> | null\n\nSubscription ID. Required if checkout_id and order_id are not provided.\n\n​\ncheckout_id\nstring<uuid> | null\n\nCheckout ID. Used to look up subscription or order from the checkout page.\n\n​\norder_id\nstring<uuid> | null\n\nOrder ID for one-time purchases. Required if subscription_id and checkout_id are not provided.\n\n​\nemail\nstring<email> | null\n\nEmail of the customer to assign the seat to\n\n​\nexternal_customer_id\nstring | null\n\nExternal customer ID for the seat assignment\n\n​\ncustomer_id\nstring<uuid> | null\n\nCustomer ID for the seat assignment\n\n​\nmetadata\nobject | null\n\nAdditional metadata for the seat (max 10 keys, 1KB total)\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid>required\n\nThe seat ID\n\n​\nstatus\nenum<string>required\n\nStatus of the seat\n\nAvailable options: pending, claimed, revoked \n​\nsubscription_id\nstring<uuid> | null\n\nThe subscription ID (for recurring seats)\n\n​\norder_id\nstring<uuid> | null\n\nThe order ID (for one-time purchase seats)\n\n​\ncustomer_id\nstring<uuid> | null\n\nThe assigned customer ID\n\n​\ncustomer_email\nstring | null\n\nThe assigned customer email\n\n​\ninvitation_token_expires_at\nstring<date-time> | null\n\nWhen the invitation token expires\n\n​\nclaimed_at\nstring<date-time> | null\n\nWhen the seat was claimed\n\n​\nrevoked_at\nstring<date-time> | null\n\nWhen the seat was revoked\n\n​\nseat_metadata\nobject | null\n\nAdditional metadata for the seat\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Seats\n**Scopes**: `customer_seats:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Order - Polar",
    "url": "https://polar.sh/docs/api-reference/orders/get",
    "html": "Orders\nGet Order\nCopy page\n\nGet an order by ID.\n\nScopes: orders:read\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norders\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nstatus\nenum<string>required\nAvailable options: pending, paid, refunded, partially_refunded \n​\npaid\nbooleanrequired\n\nWhether the order has been paid for.\n\nExamples:\n\ntrue\n\n​\nsubtotal_amount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\nExamples:\n\n10000\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\nExamples:\n\n1000\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\nExamples:\n\n9000\n\n​\ntax_amount\nintegerrequired\n\nSales tax amount in cents.\n\nExamples:\n\n720\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\nExamples:\n\n9720\n\n​\napplied_balance_amount\nintegerrequired\n\nCustomer's balance amount applied to this invoice. Can increase the total amount paid, if the customer has a negative balance, or decrease it, if the customer has a positive balance.Amount in cents.\n\nExamples:\n\n0\n\n​\ndue_amount\nintegerrequired\n\nAmount in cents that is due for this order.\n\nExamples:\n\n0\n\n​\nrefunded_amount\nintegerrequired\n\nAmount refunded in cents.\n\nExamples:\n\n0\n\n​\nrefunded_tax_amount\nintegerrequired\n\nSales tax refunded in cents.\n\nExamples:\n\n0\n\n​\ncurrency\nstringrequired\nExamples:\n\n\"usd\"\n\n​\nbilling_reason\nenum<string>required\nAvailable options: purchase, subscription_create, subscription_cycle, subscription_update \n​\nbilling_name\nstring | nullrequired\n\nThe name of the customer that should appear on the invoice.\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ninvoice_number\nstringrequired\n\nThe invoice number associated with this order.\n\n​\nis_invoice_generated\nbooleanrequired\n\nWhether an invoice has been generated for this order.\n\n​\ncustomer_id\nstring<uuid4>required\n​\nproduct_id\nstring<uuid4> | nullrequired\n​\ndiscount_id\nstring<uuid4> | nullrequired\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nplatform_fee_amount\nintegerrequired\n\nPlatform fee amount in cents.\n\nExamples:\n\n500\n\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nuser_id\nstring<uuid4>requireddeprecated\n​\nproduct\nobject | nullrequired\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nsubscription\nobject | nullrequired\n\nShow child attributes\n\n​\nitems\nOrderItemSchema · object[]required\n\nLine items composing the order.\n\nShow child attributes\n\n​\ndescription\nstringrequired\n\nA summary description of the order.\n\nExamples:\n\n\"Pro Plan\"\n\n​\nseats\ninteger | null\n\nNumber of seats purchased (for seat-based one-time orders).\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Order\nUpdate an order. **Scopes**: `orders:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Subscription - Polar",
    "url": "https://polar.sh/docs/api-reference/subscriptions/get",
    "html": "Subscriptions\nGet Subscription\nCopy page\n\nGet a subscription by ID.\n\nScopes: subscriptions:read subscriptions:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nsubscriptions\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe subscription ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\namount\nintegerrequired\n\nThe amount of the subscription.\n\nExamples:\n\n10000\n\n​\ncurrency\nstringrequired\n\nThe currency of the subscription.\n\nExamples:\n\n\"usd\"\n\n​\nrecurring_interval\nenum<string>required\n\nThe interval at which the subscription recurs.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\nintegerrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\n​\nstatus\nenum<string>required\n\nThe status of the subscription.\n\nAvailable options: incomplete, incomplete_expired, trialing, active, past_due, canceled, unpaid \n​\ncurrent_period_start\nstring<date-time>required\n\nThe start timestamp of the current billing period.\n\n​\ncurrent_period_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the current billing period.\n\n​\ntrial_start\nstring<date-time> | nullrequired\n\nThe start timestamp of the trial period, if any.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the trial period, if any.\n\n​\ncancel_at_period_end\nbooleanrequired\n\nWhether the subscription will be canceled at the end of the current period.\n\n​\ncanceled_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription was canceled. The subscription might still be active if cancel_at_period_end is true.\n\n​\nstarted_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription started.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription will end.\n\n​\nended_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription ended.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the subscribed customer.\n\n​\nproduct_id\nstring<uuid4>required\n\nThe ID of the subscribed product.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nThe ID of the applied discount, if any.\n\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\ncustomer_cancellation_reason\nenum<string> | nullrequired\nAvailable options: customer_service, low_quality, missing_features, switched_service, too_complex, too_expensive, unused, other \n​\ncustomer_cancellation_comment\nstring | nullrequired\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nA product.\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of enabled prices for the subscription.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nmeters\nSubscriptionMeter · object[]required\n\nList of meters associated with the subscription.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats included in the subscription (for seat-based pricing).\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Subscriptions\nList subscriptions. **Scopes**: `subscriptions:read` `subscriptions:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Customer by External ID - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/get-external#response-external-id",
    "html": "Customers\nGet Customer by External ID\nCopy page\n\nGet a customer by external ID.\n\nScopes: customers:read customers:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\nexternal\n/\n{external_id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nexternal_id\nstringrequired\n\nThe customer external ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nA customer in an organization.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_id\nstring | nullrequired\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nemail\nstringrequired\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nemail_verified\nbooleanrequired\n\nWhether the customer email address is verified. The address is automatically verified when the customer accesses the customer portal using their email address.\n\nExamples:\n\ntrue\n\n​\nname\nstring | nullrequired\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the customer.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ndeleted_at\nstring<date-time> | nullrequired\n\nTimestamp for when the customer was soft deleted.\n\n​\navatar_url\nstringrequired\nExamples:\n\n\"https://www.gravatar.com/avatar/xxx?d=404\"\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Customer by External ID\nUpdate a customer by external ID. **Scopes**: `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Customer by External ID - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/update-external",
    "html": "Customers\nUpdate Customer by External ID\nCopy page\n\nUpdate a customer by external ID.\n\nScopes: customers:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\nexternal\n/\n{external_id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nexternal_id\nstringrequired\n\nThe customer external ID.\n\nBody\napplication/json\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nemail\nstring<email> | null\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nname\nstring | null\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | null\n\nShow child attributes\n\n​\ntax_id\nany[] | null\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\nResponse\n200\napplication/json\n\nCustomer updated.\n\nA customer in an organization.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_id\nstring | nullrequired\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nemail\nstringrequired\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nemail_verified\nbooleanrequired\n\nWhether the customer email address is verified. The address is automatically verified when the customer accesses the customer portal using their email address.\n\nExamples:\n\ntrue\n\n​\nname\nstring | nullrequired\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the customer.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ndeleted_at\nstring<date-time> | nullrequired\n\nTimestamp for when the customer was soft deleted.\n\n​\navatar_url\nstringrequired\nExamples:\n\n\"https://www.gravatar.com/avatar/xxx?d=404\"\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete Customer by External ID\nDelete a customer by external ID. Immediately cancels any active subscriptions and revokes any active benefits. **Scopes**: `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete Customer by External ID - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/delete-external",
    "html": "Customers\nDelete Customer by External ID\nCopy page\n\nDelete a customer by external ID.\n\nImmediately cancels any active subscriptions and revokes any active benefits.\n\nScopes: customers:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\nexternal\n/\n{external_id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nexternal_id\nstringrequired\n\nThe customer external ID.\n\nResponse\n204\n\nCustomer deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Subscription\nGet a subscription by ID. **Scopes**: `subscriptions:read` `subscriptions:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Customer - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/update#body-metadata",
    "html": "Customers\nUpdate Customer\nCopy page\n\nUpdate a customer.\n\nScopes: customers:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe customer ID.\n\nBody\napplication/json\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nHide child attributes\n\n​\nmetadata.{key}\nstring\ninteger\nnumber\nboolean\nRequired string length: 1 - 500\n​\nemail\nstring<email> | null\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nname\nstring | null\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | null\n\nShow child attributes\n\n​\ntax_id\nany[] | null\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\nexternal_id\nstring | null\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\nResponse\n200\napplication/json\n\nCustomer updated.\n\nA customer in an organization.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_id\nstring | nullrequired\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nemail\nstringrequired\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nemail_verified\nbooleanrequired\n\nWhether the customer email address is verified. The address is automatically verified when the customer accesses the customer portal using their email address.\n\nExamples:\n\ntrue\n\n​\nname\nstring | nullrequired\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the customer.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ndeleted_at\nstring<date-time> | nullrequired\n\nTimestamp for when the customer was soft deleted.\n\n​\navatar_url\nstringrequired\nExamples:\n\n\"https://www.gravatar.com/avatar/xxx?d=404\"\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete Customer\nDelete a customer. This action cannot be undone and will immediately: - Cancel any active subscriptions for the customer - Revoke all their benefits - Clear any `external_id` Use it only in the context of deleting a user within your own service. Otherwise, use more granular API endpoints to cancel a specific subscription or revoke certain benefits. Note: The customers information will nonetheless be retained for historic orders and subscriptions. **Scopes**: `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Setup a Payout Account - Polar",
    "url": "https://polar.sh/docs/features/finance/accounts",
    "html": "Finance & Payouts\nSetup a Payout Account\nCopy page\n​\nConnect Payout Account\nYou need to setup an account so that we can issue payouts.\nGo to the Finance page in your Polar dashboard\nClick Setup in the card shown above in your dashboard\nChoose account type & follow their setup instructions\nThis is only required the first time and you can do this proactively too in order - recommended to avoid any additional delays.\n​\nStripe Connect Express\nStripe is the default and recommended option since it enables instant transfers.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAccount Balance\nMonitor your Polar balance without hidden fees\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Implementing Seat-Based Pricing - Polar",
    "url": "https://polar.sh/docs/guides/seat-based-pricing",
    "html": "Guides\nImplementing Seat-Based Pricing\nCopy page\n\nComplete guide to implementing team products with seat-based pricing\n\nThis guide walks you through implementing seat-based pricing for team products, from creating the product to handling seat assignments and claims.\n​\nWhat you’ll build\nBy the end of this guide, you’ll have:\nA seat-based product with tiered pricing (subscription or one-time)\nCheckout flow for purchasing seats\nSeat assignment and management interface\nClaim flow for team members\nThis guide covers both subscription-based and one-time purchase seat-based products. The implementation is similar for both, with key differences in scaling and billing.\n​\nPrerequisites\nPolar organization with seat_based_pricing_enabled feature flag\nPolar SDK installed (npm install @polar-sh/sdk or pip install polar-sdk)\nImportant: Seat-based pricing requires the latest version of the SDK. Make sure to update to the latest version to access all seat-based pricing features.\nBasic understanding of Polar products and subscriptions\nSeat-based pricing is controlled by a feature flag. Contact support to enable it for your organization.\n​\nStep 1: Create a seat-based product\n1\n\nNavigate to Products\n\nIn the Polar dashboard, go to Products and click Create Product.\n2\n\nConfigure basic settings\n\nSet your product name, description, and media. For example:\nSubscription: Team Pro Plan - Professional features for your entire team\nOne-time: Enterprise License Pack - Perpetual team licenses\n3\n\nSelect seat-based pricing\n\nUnder Pricing:\nProduct type: Choose Subscription for recurring billing or One-time for perpetual licenses\nBilling cycle (subscriptions only): Monthly or Yearly\nPricing type: Seat-based\nMin seats: 1 (or your minimum team size)\n4\n\nConfigure pricing tiers\n\nDefine your volume-based pricing:\nTier\tMax Seats\tPrice per Seat\n1\t4\t$10/month\n2\t9\t$9/month\n3\tUnlimited\t$8/month\nExample: A team purchasing 6 seats pays 6 × \n9\n=\n9=54/month.\n5\n\nAdd benefits\n\nConfigure benefits that seat holders will receive:\nLicense Keys\nFile Downloads\nDiscord roles\nCustom benefits\nBenefits are granted when seats are claimed, not at purchase time.\nYou can also create seat-based products via API:\nSubscription example:\nCopy\nAsk AI\nconst subscriptionProduct = await polar.products.create({\n  name: \"Team Pro Plan\",\n  organization_id: \"org_123\",\n  is_recurring: true,\n  prices: [{\n    type: \"recurring\",\n    recurring_interval: \"month\",\n    amount_type: \"seat_based\",\n    price_currency: \"usd\",\n    seat_tiers: [\n      { min_seats: 1, max_seats: 4, price_per_seat: 1000 },   // $10/month\n      { min_seats: 5, max_seats: 9, price_per_seat: 900 },    // $9/month\n      { min_seats: 10, max_seats: null, price_per_seat: 800 } // $8/month\n    ]\n  }]\n});\n\nOne-time purchase example:\nCopy\nAsk AI\nconst oneTimeProduct = await polar.products.create({\n  name: \"Enterprise License Pack\",\n  organization_id: \"org_123\",\n  is_recurring: false,\n  prices: [{\n    type: \"one_time\",\n    amount_type: \"seat_based\",\n    price_currency: \"usd\",\n    seat_tiers: [\n      { min_seats: 1, max_seats: 10, price_per_seat: 5000 },   // $50 per seat\n      { min_seats: 11, max_seats: 50, price_per_seat: 4500 },  // $45 per seat\n      { min_seats: 51, max_seats: null, price_per_seat: 4000 } // $40 per seat\n    ]\n  }]\n});\n\n​\nStep 2: Implement checkout flow\nCreate a checkout session that allows customers to select seat quantity:\nCopy\nAsk AI\nconst checkout = await polar.checkouts.create({\n  product_price_id: \"price_123\",\n  seats: 5, // Customer selects quantity\n  success_url: \"https://yourapp.com/success\",\n  customer_email: \"billing@company.com\"\n});\n\n// Redirect to checkout.url\n\nThe checkout displays:\nPrice per seat based on quantity\nTotal amount\nClear indication this is for team access\nThe checkout automatically calculates pricing based on your tiers. A customer selecting 5 seats will see the \n9\n/\n𝑠\n𝑒\n𝑎\n𝑡\n𝑝\n𝑟\n𝑖\n𝑐\n𝑒\n,\n𝑡\n𝑜\n𝑡\n𝑎\n𝑙\n𝑖\n𝑛\n𝑔\n9/seatprice,totaling45.\n​\nStep 3: Handle post-purchase webhook\nListen for purchase webhooks to know when a customer buys seats:\nCopy\nAsk AI\n// Webhook handler\napp.post('/webhooks/polar', async (req, res) => {\n  const event = req.body;\n\n  // For subscriptions\n  if (event.type === 'subscription.created') {\n    const subscription = event.data;\n\n    if (subscription.product.has_seat_based_price) {\n      await notifyBillingManager(subscription.customer_id, {\n        message: `Your ${subscription.seats}-seat subscription is active!`,\n        manage_seats_url: `https://yourapp.com/seats/subscription/${subscription.id}`\n      });\n    }\n  }\n\n  // For one-time purchases\n  if (event.type === 'order.created') {\n    const order = event.data;\n\n    if (order.seats) {\n      await notifyBillingManager(order.customer_id, {\n        message: `Your ${order.seats} perpetual seat licenses have been purchased!`,\n        manage_seats_url: `https://yourapp.com/seats/order/${order.id}`\n      });\n    }\n  }\n\n  res.sendStatus(200);\n});\n\n​\nStep 4: Build seat management interface\nCreate an interface for billing managers to assign seats:\nCopy\nAsk AI\n// List available seats (works for both subscriptions and orders)\nasync function getSeatInfo(params: { subscription_id?: string; order_id?: string }) {\n  const { seats, available_seats, total_seats } =\n    await polar.customerSeats.list(params);\n\n  return {\n    seats,\n    available: available_seats,\n    total: total_seats,\n    canAssign: available_seats > 0\n  };\n}\n\n// Assign a seat (works for both subscriptions and orders)\nasync function assignSeat(\n  params: { subscription_id?: string; order_id?: string },\n  email: string,\n  metadata?: Record<string, any>\n) {\n  try {\n    const seat = await polar.customerSeats.assign({\n      ...params,\n      email: email,\n      metadata: metadata // e.g., { department: \"Engineering\" }\n    });\n\n    return {\n      success: true,\n      seat: seat,\n      message: `Invitation sent to ${email}`\n    };\n  } catch (error) {\n    if (error.status === 400) {\n      return {\n        success: false,\n        error: \"No seats available or customer already has a seat\"\n      };\n    }\n    throw error;\n  }\n}\n\n// Example usage:\n// For subscriptions: getSeatInfo({ subscription_id: \"sub_123\" })\n// For orders: getSeatInfo({ order_id: \"order_456\" })\n\nExample UI component (React):\nCopy\nAsk AI\nfunction SeatManagement({ subscriptionId }: { subscriptionId: string }) {\n  const [seatInfo, setSeatInfo] = useState(null);\n  const [email, setEmail] = useState(\"\");\n\n  useEffect(() => {\n    loadSeats();\n  }, [subscriptionId]);\n\n  async function loadSeats() {\n    const info = await getSeatInfo(subscriptionId);\n    setSeatInfo(info);\n  }\n\n  async function handleAssign() {\n    const result = await assignSeat(subscriptionId, email, {\n      role: \"Developer\"\n    });\n\n    if (result.success) {\n      setEmail(\"\");\n      loadSeats(); // Refresh list\n      toast.success(\"Invitation sent!\");\n    }\n  }\n\n  return (\n    <div>\n      <h2>Seat Management</h2>\n      <p>{seatInfo?.available} of {seatInfo?.total} seats available</p>\n\n      {/* Assign new seat */}\n      <div>\n        <input\n          type=\"email\"\n          value={email}\n          onChange={(e) => setEmail(e.target.value)}\n          placeholder=\"team-member@company.com\"\n        />\n        <button\n          onClick={handleAssign}\n          disabled={!seatInfo?.canAssign}\n        >\n          Assign Seat\n        </button>\n      </div>\n\n      {/* List existing seats */}\n      <table>\n        <thead>\n          <tr>\n            <th>Email</th>\n            <th>Status</th>\n            <th>Role</th>\n            <th>Actions</th>\n          </tr>\n        </thead>\n        <tbody>\n          {seatInfo?.seats.map(seat => (\n            <tr key={seat.id}>\n              <td>{seat.customer_email}</td>\n              <td>\n                <SeatStatusBadge status={seat.status} />\n              </td>\n              <td>{seat.seat_metadata?.role}</td>\n              <td>\n                {seat.status === 'pending' && (\n                  <button onClick={() => resendInvitation(seat.id)}>\n                    Resend\n                  </button>\n                )}\n                {seat.status === 'claimed' && (\n                  <button onClick={() => revokeSeat(seat.id)}>\n                    Revoke\n                  </button>\n                )}\n              </td>\n            </tr>\n          ))}\n        </tbody>\n      </table>\n    </div>\n  );\n}\n\n​\nStep 5: Implement seat claim flow\nWhen a team member receives an invitation email, they’ll click a link with the invitation token. Build a claim page:\nCopy\nAsk AI\n// Claim page route: /claim?token=abc123...\n\nasync function handleClaimPage(token: string) {\n  // Get claim information (no auth required)\n  const claimInfo = await polar.customerSeats.getClaimInfo({\n    invitation_token: token\n  });\n\n  if (!claimInfo.can_claim) {\n    return {\n      error: \"This invitation has expired or already been claimed\"\n    };\n  }\n\n  return {\n    product: claimInfo.product_name,\n    organization: claimInfo.organization_name,\n    email: claimInfo.customer_email\n  };\n}\n\nasync function claimSeat(token: string) {\n  const { seat, customer_session_token } =\n    await polar.customerSeats.claim({\n      invitation_token: token\n    });\n\n  // Store the customer session token\n  // This allows immediate portal access\n  localStorage.setItem('polar_session', customer_session_token);\n\n  return {\n    success: true,\n    seat: seat,\n    sessionToken: customer_session_token\n  };\n}\n\nExample claim page (React):\nCopy\nAsk AI\nfunction ClaimPage() {\n  const [token] = useSearchParams();\n  const [claimInfo, setClaimInfo] = useState(null);\n  const [claiming, setClaiming] = useState(false);\n\n  useEffect(() => {\n    loadClaimInfo();\n  }, [token]);\n\n  async function loadClaimInfo() {\n    const info = await handleClaimPage(token.get('token'));\n    setClaimInfo(info);\n  }\n\n  async function handleClaim() {\n    setClaiming(true);\n    try {\n      const result = await claimSeat(token.get('token'));\n\n      // Redirect to customer portal\n      window.location.href = `/portal?session=${result.sessionToken}`;\n    } catch (error) {\n      toast.error(\"Failed to claim seat\");\n      setClaiming(false);\n    }\n  }\n\n  if (claimInfo?.error) {\n    return <div>Error: {claimInfo.error}</div>;\n  }\n\n  return (\n    <div>\n      <h1>You've been invited!</h1>\n      <p>\n        Join {claimInfo?.organization}'s {claimInfo?.product} plan\n      </p>\n      <p>Email: {claimInfo?.email}</p>\n\n      <button onClick={handleClaim} disabled={claiming}>\n        {claiming ? \"Claiming...\" : \"Claim My Seat\"}\n      </button>\n    </div>\n  );\n}\n\n​\nStep 6: Handle benefit granting\nAfter a seat is claimed, benefits are granted automatically via background jobs. Listen for webhooks to track this:\nCopy\nAsk AI\napp.post('/webhooks/polar', async (req, res) => {\n  const event = req.body;\n\n  if (event.type === 'benefit_grant.created') {\n    const grant = event.data;\n\n    // A team member received their benefits\n    console.log(`Benefit ${grant.benefit_id} granted to ${grant.customer_id}`);\n\n    // Update your app (e.g., create license, grant access)\n    await grantAccess(grant.customer_id, grant.benefit);\n  }\n\n  if (event.type === 'benefit_grant.revoked') {\n    const grant = event.data;\n\n    // A seat was revoked\n    await revokeAccess(grant.customer_id, grant.benefit);\n  }\n\n  res.sendStatus(200);\n});\n\n​\nStep 7: Implement seat revocation\nAllow billing managers to revoke seats:\nCopy\nAsk AI\nasync function revokeSeat(seatId: string) {\n  const revokedSeat = await polar.customerSeats.revoke({\n    seat_id: seatId\n  });\n\n  // Benefits are automatically revoked via webhook\n  return {\n    success: true,\n    seat: revokedSeat,\n    message: \"Seat revoked successfully\"\n  };\n}\n\nRevoking a seat immediately removes access but does not issue a refund. The billing manager continues to pay for all purchased seats.\n​\nStep 8: Handle scaling\nFor subscriptions, allow billing managers to add or reduce seats:\nCopy\nAsk AI\nasync function addSeats(subscriptionId: string, newTotal: number) {\n  // Update subscription seat count\n  const subscription = await polar.subscriptions.update({\n    id: subscriptionId,\n    seats: newTotal\n  });\n\n  // New seats are immediately available for assignment\n  return subscription;\n}\n\nasync function reduceSeats(subscriptionId: string, newTotal: number) {\n  const { seats } = await polar.customerSeats.list({\n    subscription_id: subscriptionId\n  });\n\n  const claimedCount = seats.filter(s => s.status === 'claimed').length;\n\n  if (newTotal < claimedCount) {\n    throw new Error(\n      `Cannot reduce to ${newTotal} seats. ${claimedCount} seats are currently claimed. Revoke seats first.`\n    );\n  }\n\n  // Update will take effect at next renewal\n  const subscription = await polar.subscriptions.update({\n    id: subscriptionId,\n    seats: newTotal\n  });\n\n  return subscription;\n}\n\nFor one-time purchases, customers buy additional seats via new orders:\nCopy\nAsk AI\nasync function purchaseMoreSeats(productId: string, additionalSeats: number) {\n  // Create a new checkout for additional seats\n  const checkout = await polar.checkouts.create({\n    product_id: productId,\n    seats: additionalSeats,\n    success_url: \"https://yourapp.com/success\"\n  });\n\n  // Each order is independent with its own seat pool\n  return checkout;\n}\n\nFor one-time purchases, each order has its own independent seat pool. Customers can purchase additional seats anytime by creating a new order. All seats remain perpetual.\n​\nBest Practices\n​\n1. Validate seat availability\nAlways check available seats before showing the assignment form:\nCopy\nAsk AI\nif (available_seats === 0) {\n  return (\n    <div>\n      All seats are assigned.\n      <button onClick={upgradeSubscription}>\n        Add More Seats\n      </button>\n    </div>\n  );\n}\n\n​\n2. Use metadata effectively\nStore useful context in seat metadata:\nCopy\nAsk AI\nawait polar.customerSeats.assign({\n  subscription_id: subId,\n  email: \"dev@company.com\",\n  metadata: {\n    department: \"Engineering\",\n    role: \"Senior Developer\",\n    cost_center: \"R&D\",\n    manager: \"jane@company.com\"\n  }\n});\n\n​\n3. Handle expired tokens gracefully\nCopy\nAsk AI\ntry {\n  await claimSeat(token);\n} catch (error) {\n  if (error.status === 400) {\n    // Show resend option\n    return \"This invitation has expired. Contact your admin to resend.\";\n  }\n}\n\n​\n4. Track utilization\nMonitor seat usage to identify upsell opportunities:\nCopy\nAsk AI\nconst { seats, available_seats, total_seats } = await getSeatInfo(subId);\nconst utilization = ((total_seats - available_seats) / total_seats) * 100;\n\nif (utilization > 80) {\n  // Suggest adding more seats\n  showUpgradePrompt();\n}\n\n​\n5. Clear communication\nMake it clear to billing managers that:\nThey won’t receive direct access to benefits\nSeats must be assigned to team members\nRevocation doesn’t refund costs\nFor subscriptions: Reducing seats requires revoking claims first\nFor one-time purchases: Seats are perpetual and non-refundable\n​\nCommon Patterns\n​\nBulk seat assignment\nCopy\nAsk AI\nasync function assignMultipleSeats(\n  subscriptionId: string,\n  emails: string[]\n) {\n  const results = await Promise.allSettled(\n    emails.map(email =>\n      polar.customerSeats.assign({\n        subscription_id: subscriptionId,\n        email: email\n      })\n    )\n  );\n\n  const succeeded = results.filter(r => r.status === 'fulfilled');\n  const failed = results.filter(r => r.status === 'rejected');\n\n  return {\n    succeeded: succeeded.length,\n    failed: failed.length,\n    errors: failed.map(f => f.reason)\n  };\n}\n\n​\nSyncing with your user system\nCopy\nAsk AI\n// When a user joins your system\nasync function onUserSignup(email: string, organizationId: string) {\n  // Check if they have a pending seat\n  const subscriptions = await getOrganizationSubscriptions(organizationId);\n\n  for (const sub of subscriptions) {\n    const { seats } = await polar.customerSeats.list({\n      subscription_id: sub.id\n    });\n\n    const pendingSeat = seats.find(s =>\n      s.status === 'pending' && s.customer_email === email\n    );\n\n    if (pendingSeat) {\n      // Auto-claim on signup\n      const claimLink = `/claim?token=${pendingSeat.invitation_token}`;\n      return { shouldClaim: true, claimLink };\n    }\n  }\n}\n\n​\nCustom portal integration\nCopy\nAsk AI\n// Display team subscriptions in your app\nasync function getTeamSubscriptions(customerId: string) {\n  const subs = await polar.customerPortal.seats.listSubscriptions({\n    customer_id: customerId\n  });\n\n  return subs.map(sub => ({\n    product: sub.product.name,\n    status: sub.status,\n    role: sub.seat_metadata?.role,\n    expires: sub.current_period_end\n  }));\n}\n\n​\nTroubleshooting\n​\nSeats not appearing\nEnsure the feature flag is enabled:\nCopy\nAsk AI\nseat_based_pricing_enabled: true\n\n​\nBenefits not granted after claim\nCheck webhook logs for benefit_grant.created events. Benefits are granted asynchronously via background jobs.\n​\nCannot reduce seats\nMake sure to revoke seats before reducing the subscription seat count. You cannot reduce below the currently claimed count.\n​\nClaim link expired\nInvitation tokens expire after 24 hours. Have the billing manager resend the invitation:\nCopy\nAsk AI\nawait polar.customerSeats.resend({ seat_id: seatId });\n\n​\nNext Steps\nReview the Seat-Based Pricing Feature Documentation\nExplore the Customer Seats API Reference\nSet up webhook handlers for real-time updates\nLearn about Customer Portal customization\n​\nNeed Help?\nJoin our Discord community or contact support for assistance with seat-based pricing implementation.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate product variants\nLearn how create product variants in Polar and how customers can easily switch between them in the customer portal.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "How to create product variants - Polar",
    "url": "https://polar.sh/docs/guides/create-variants",
    "html": "Guides\nHow to create product variants\nCopy page\n\nLearn how create product variants in Polar and how customers can easily switch between them in the customer portal.\n\n​\nCreating product variants (3 subscription products)\n1\n\nGo to Products Catalogue\n\nIn the Polar dashboard sidebar, navigate to Products > Catalogue for your organization. You can also go directly to:\nhttps://polar.sh/dashboard/${org_slug}/products\n2\n\nCreate a product\n\nClick on New Product and fill the product information. Here, we are creating a monthly subscription product Basic version with cost $20.\nYour product catalogue should now show this product as follows:\n3\n\nSimilarly, create two more products\n\nClick on New Product and create two more subscription products one by one.\nMid version: Fill the product information. We create a monthly subscription product named Mid version with cost $30.\nAdvanced version: We create a monthly subscription product named Advanced version with cost $40.\nProduct Catalogue: You should be able to see all your products on Product Catalogue.\n​\nCreating checkout links with variants\n1\n\nNavigate to Checkout Links in the dashboard\n\nIn the Polar dashboard sidebar, navigate to Products > Checkout Links. You can also go directly to:\nhttps://polar.sh/dashboard/${org_slug}/products/checkout-links\n2\n\nCreate a Checkout Link\n\nClick on New Link and select all your products which you want to offer as variants.\nAt this step, you may add a label, success URL and metadata. You may also configure whether discount codes are allowed and whether billing address is required from customers. Click on Create Link after adding your configurations.\n3\n\nAccessing the checkout link\n\nYou should be able to see your label name in Checkout Links. In our case, 3 products is the default label name assigned by the system.\nClick on your label to see the checkout link.\nYou can copy this link and share to your customers for them to purchase a variant.\n​\nPurchasing from variants\n1\n\nPurchasing a product\n\nOn opening the checkout link, the customer will need to select the variant they want to purchase and fill their email address and card details.\n2\n\nAccess email for upgrade/downgrade link\n\nOnce the customer has purchased the subscription, they will receive an email containing the link to access their purchase.\n​\nDowngrading to another product variant\n1\n\nOpen Customer Portal and click on Change Plan\n\nOn opening the link from the email received, the customer needs to click on Change Plan.\n2\n\nSelect the desired plan\n\nThen, they can select the plan they want to downgrade to and click on Change Plan.\n3\n\nDowngraded successfully\n\nNow, the product is changed to Basic version instead of Mid version on the portal.\n​\nUpgrading to another product variant\n1\n\nOpen Customer Portal and click on Change Plan\n\nOn opening the link from the email received, the customer needs to click on Change Plan.\n2\n\nSelect the desired plan\n\nThen, they need to select the variant they want to upgrade to, Advanced version and click on Change Plan.\n3\n\nUpgraded successfully\n\nNow, the product is changed to Advanced version on the portal.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDisable subscription changes in customer portal\nLearn how to disable the option for customers to upgrade or downgrade subscription plans from the customer portal.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "How to disable subscription upgrades/downgrades in customer portal - Polar",
    "url": "https://polar.sh/docs/guides/disable-subscription-changes-in-customer-portal",
    "html": "Guides\nHow to disable subscription upgrades/downgrades in customer portal\nCopy page\n\nLearn how to disable the option for customers to upgrade or downgrade subscription plans from the customer portal.\n\n1\n\nGo to Organization Settings\n\nIn the Polar dashboard sidebar, click on Settings. You can also go directly to:\nhttps://polar.sh/dashboard/${org_slug}/settings\nScroll down to Subscriptions section.\n2\n\nToggle Allow price changes\n\nToggle OFF Allow price changes to prevent customers from upgrading or downgrading their subscriptions from the customer portal.\n3\n\nSave the changes\n\nClick Save in the Subscriptions section to save the changed settings.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAllow multiple subscriptions per customer\nLearn how to allow multiple subscriptions per customer in Polar.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "How to allow multiple subscriptions per customer - Polar",
    "url": "https://polar.sh/docs/guides/allow-multiple-subscriptions-per-customer",
    "html": "Guides\nHow to allow multiple subscriptions per customer\nCopy page\n\nLearn how to allow multiple subscriptions per customer in Polar.\n\n1\n\nGo to Organization Settings\n\nIn the Polar dashboard sidebar, click on Settings. You can also go directly to:\nhttps://polar.sh/dashboard/${org_slug}/settings\nScroll down to Subscriptions section.\n2\n\nToggle Allow multiple subscriptions\n\nToggle ON Allow multiple subscriptions to allow multiple subscriptions per customer.\n3\n\nSave the changes\n\nClick Save in the Subscriptions section to save the changed settings.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nPerform subscription downgrades\nLearn how to downgrade a subscription as a merchant or a customer.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "How to perform subscription downgrades - Polar",
    "url": "https://polar.sh/docs/guides/subscription-downgrades",
    "html": "Guides\nHow to perform subscription downgrades\nCopy page\n\nLearn how to downgrade a subscription as a merchant or a customer.\n\n​\nDowngrading a subscription as a merchant\n1\n\nGo to Sales > Subscriptions\n\nIn the Polar dashboard sidebar, navigate to Sales > Subscriptions for your organization. You can also go directly to:\nhttps://polar.sh/dashboard/${org_slug}/sales/subscriptions\n2\n\nSelect the subscription to be downgraded\n\nClick on the subscription you want to downgrade. The subscription details page opens up as shown below. Click on Update Subscription.\n3\n\nChoose the plan and the proration behavior\n\nSelect the New product (plan to downgrade to) and the Proration behavior from the dropdown menu.\nRegardless of the option, the subscription is downgraded immediately, only the invoicing happens according to the selected Proration behaior.\nThere are two types of proration:\nNext invoice: The customer is charged (or credited) in the upcoming invoice for the difference.\nInvoice immediately: The customer is charged (or credited) right away for the difference.\nThen, click on Update Subscription.\n4\n\nSuccessful downgrade!\n\nThe subscription is successfully downgraded to Basic version.\nNote that merchants can disable customer-level upgrades or downgrades in the portal by toggling OFF Allow price change setting.\n​\nDowngrading a subscription as a customer\n1\n\nOpen email and click the purchase link\n\nOpen the email you received after purchasing the subscription. Click the Access my Purchase link to go to the Customer Portal, where you can downgrade your subscription.\n2\n\nBrowse Overview > Subscriptions in Customer Portal\n\nIn the Overview tab of Customer Portal, scroll to Subscriptions and click on Change Plan.\n3\n\nSelect the desired plan\n\nSelect the plan you want to downgrade to and click on Change Plan.\n4\n\nSuccessful downgrade!\n\nThe subscription is successfully downgraded to Basic version.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nPerform subscription upgrades\nLearn how to upgrade a subscription as a merchant or a customer.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "How to perform subscription upgrades - Polar",
    "url": "https://polar.sh/docs/guides/subscription-upgrades",
    "html": "Guides\nHow to perform subscription upgrades\nCopy page\n\nLearn how to upgrade a subscription as a merchant or a customer.\n\n​\nUpgrading a subscription as a merchant\n1\n\nGo to Sales > Subscriptions\n\nIn the Polar dashboard sidebar, navigate to Sales > Subscriptions for your organization. You can also go directly to:\nhttps://polar.sh/dashboard/${org_slug}/sales/subscriptions\n2\n\nSelect the subscription to be upgraded\n\nClick on the subscription you want to upgrade. The subscription details page opens up as shown below. Click on Update Subscription.\n3\n\nChoose the plan and the proration behavior\n\nSelect the New product (plan to upgrade to) and the Proration behavior from the dropdown menu.\nRegardless of the option, the subscription is upgraded immediately, only the invoicing happens according to the selected Proration behaior.\nThere are two types of proration:\nNext invoice: The customer is charged (or credited) in the upcoming invoice for the difference.\nInvoice immediately: The customer is charged (or credited) right away for the difference.\nThen, click on Update Subscription.\n4\n\nSuccessful upgrade!\n\nThe subscription is successfully upgraded to Advanced version.\nNote that merchants can disable customer-level upgrades or downgrades in the portal by toggling OFF Allow price change setting.\n​\nUpgrading subscription as a customer\n1\n\nOpen email and click the purchase link\n\nOpen the email you received after purchasing the subscription. Click the Access my Purchase link to go to the Customer Portal, where you can upgrade your subscription.\n2\n\nBrowse Overview > Subscriptions in Customer Portal\n\nIn the Overview tab of Customer Portal, scroll to Subscriptions and click on Change Plan.\n3\n\nSelect the desired plan\n\nSelect the plan you want to upgrade to and click on Change Plan.\n4\n\nSuccessful upgrade!\n\nThe subscription is successfully upgraded to Advanced version.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nPerform subscription downgrades\nLearn how to downgrade a subscription as a merchant or a customer.\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Customer - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/get-customer",
    "html": "Customer Portal API\nGet Customer\nCopy page\n\nGet authenticated customer.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\ncustomers\n/\nme\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nResponse\n200 - application/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nemail\nstringrequired\n​\nemail_verified\nbooleanrequired\n​\nname\nstring | nullrequired\n​\nbilling_name\nstring | nullrequired\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\noauth_accounts\nobjectrequired\n\nShow child attributes\n\n​\ndefault_payment_method_id\nstring<uuid4> | null\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Organization\nGet a customer portal's organization by slug.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Organization - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/get-organization",
    "html": "Customer Portal API\nGet Organization\nCopy page\n\nGet a customer portal’s organization by slug.\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\norganizations\n/\n{slug}\nTry it\nPath Parameters\n​\nslug\nstringrequired\n\nThe organization slug.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nSchema of an organization and related data for customer portal.\n\n​\norganization\nobjectrequired\n\nShow child attributes\n\n​\nproducts\nCustomerProduct · object[]required\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Customer Session\nCreate a customer session. **Scopes**: `customer_sessions:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Customer Session - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/sessions/create",
    "html": "Sessions\nCreate Customer Session\nCopy page\n\nCreate a customer session.\n\nScopes: customer_sessions:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-sessions\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\nCustomerSessionCustomerIDCreate\nCustomerSessionCustomerExternalIDCreate\n\nSchema for creating a customer session using a customer ID.\n\n​\ncustomer_id\nstring<uuid4>required\n\nID of the customer to create a session for.\n\n​\nreturn_url\nstring<uri> | null\n\nWhen set, a back button will be shown in the customer portal to return to this URL.\n\nRequired string length: 1 - 2083\nExamples:\n\n\"https://example.com/account\"\n\nResponse\n201\napplication/json\n\nCustomer session created.\n\nA customer session that can be used to authenticate as a customer.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ntoken\nstringrequired\n​\nexpires_at\nstring<date-time>required\n​\nreturn_url\nstring | nullrequired\n​\ncustomer_portal_url\nstringrequired\n​\ncustomer_id\nstring<uuid4>required\n​\ncustomer\nobjectrequired\n\nA customer in an organization.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Subscription\nGet a subscription for the authenticated customer. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Validate License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/license-keys/validate",
    "html": "License Keys\nValidate License Key\nCopy page\n\nValidate a license key.\n\nThis endpoint doesn’t require authentication and can be safely used on a public client, like a desktop application or a mobile app. If you plan to validate a license key on a server, use the /v1/license-keys/validate endpoint instead.\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nlicense-keys\n/\nvalidate\nTry it\nBody\napplication/json\n​\nkey\nstringrequired\n​\norganization_id\nstring<uuid4>required\n​\nactivation_id\nstring<uuid4> | null\n​\nbenefit_id\nstring<uuid4> | null\n\nThe benefit ID.\n\n​\ncustomer_id\nstring<uuid4> | null\n​\nincrement_usage\ninteger | null\n​\nconditions\nobject\n\nKey-value object allowing you to set conditions that must match when validating the license key.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\ncustomer_id\nstring<uuid4>required\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nbenefit_id\nstring<uuid4>required\n\nThe benefit ID.\n\n​\nkey\nstringrequired\n​\ndisplay_key\nstringrequired\n​\nstatus\nenum<string>required\nAvailable options: granted, revoked, disabled \n​\nlimit_activations\ninteger | nullrequired\n​\nusage\nintegerrequired\n​\nlimit_usage\ninteger | nullrequired\n​\nvalidations\nintegerrequired\n​\nlast_validated_at\nstring<date-time> | nullrequired\n​\nexpires_at\nstring<date-time> | nullrequired\n​\nactivation\nobject | null\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nActivate License Key\nActivate a license key instance. > This endpoint doesn't require authentication and can be safely used on a public > client, like a desktop application or a mobile app. > If you plan to validate a license key on a server, use the `/v1/license-keys/activate` > endpoint instead.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Activate License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/license-keys/activate",
    "html": "License Keys\nActivate License Key\nCopy page\n\nActivate a license key instance.\n\nThis endpoint doesn’t require authentication and can be safely used on a public client, like a desktop application or a mobile app. If you plan to validate a license key on a server, use the /v1/license-keys/activate endpoint instead.\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nlicense-keys\n/\nactivate\nTry it\nYou only need to use this endpoint if you have device activations enabled on the license key benefit. You then use this endpoint to reserve an allocation for a specific device. Storing the unique activation ID from the response on the device and using it as extra validation in the /validate endpoint.\nNot using activations? Just use the /validate endpoint directly instead.\nBody\napplication/json\n​\nkey\nstringrequired\n​\norganization_id\nstring<uuid4>required\n​\nlabel\nstringrequired\n​\nconditions\nobject\n\nKey-value object allowing you to set conditions that must match when validating the license key.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nmeta\nobject\n\nKey-value object allowing you to store additional information about the activation\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n​\nlicense_key_id\nstring<uuid4>required\n​\nlabel\nstringrequired\n​\nmeta\nobjectrequired\n\nShow child attributes\n\n​\ncreated_at\nstring<date-time>required\n​\nmodified_at\nstring<date-time> | nullrequired\n​\nlicense_key\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDeactivate License Key\nDeactivate a license key instance. > This endpoint doesn't require authentication and can be safely used on a public > client, like a desktop application or a mobile app. > If you plan to validate a license key on a server, use the `/v1/license-keys/deactivate` > endpoint instead.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Deactivate License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/license-keys/deactivate",
    "html": "License Keys\nDeactivate License Key\nCopy page\n\nDeactivate a license key instance.\n\nThis endpoint doesn’t require authentication and can be safely used on a public client, like a desktop application or a mobile app. If you plan to validate a license key on a server, use the /v1/license-keys/deactivate endpoint instead.\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nlicense-keys\n/\ndeactivate\nTry it\nBody\napplication/json\n​\nkey\nstringrequired\n​\norganization_id\nstring<uuid4>required\n​\nactivation_id\nstring<uuid4>required\nResponse\n204\n\nLicense key activation deactivated.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet License Key\nGet a license key. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Custom Benefit - Polar",
    "url": "https://polar.sh/docs/features/benefits/custom",
    "html": "Benefits\nCustom Benefit\nCopy page\n\nCreate your own Custom benefit\n\nYou can add a simple, custom benefit, which allows you to attach a note to paying customers.\n​\nCustom Notes\nSecret message only customers can see, e.g Cal.com link, private email for support etc.\nFor custom integrations you can also distinguish benefits granted to customers to offer even more bespoke user benefits.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCheckout Links\nSell your digital products with ease by sharing a checkout link to select products\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Checkout Session - Polar",
    "url": "https://polar.sh/docs/api-reference/checkouts/get-session#response-metadata",
    "html": "Checkout\nGet Checkout Session\nCopy page\n\nGet a checkout session by ID.\n\nScopes: checkouts:read checkouts:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckouts\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe checkout session ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nCheckout session data retrieved using an access token.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nstatus\nenum<string>required\nStatus of the checkout session.\n\n    - Open: the checkout session was opened.\n    - Expired: the checkout session was expired and is no more accessible.\n    - Confirmed: the user on the checkout session clicked Pay. This is not indicative of the payment's success status.\n    - Failed: the checkout definitely failed for technical reasons and cannot be retried. In most cases, this state is never reached.\n    - Succeeded: the payment on the checkout was performed successfully.\nAvailable options: open, expired, confirmed, succeeded, failed \n​\nclient_secret\nstringrequired\n\nClient secret used to update and complete the checkout session from the client.\n\n​\nurl\nstringrequired\n\nURL where the customer can access the checkout session.\n\n​\nexpires_at\nstring<date-time>required\n\nExpiration date and time of the checkout session.\n\n​\nsuccess_url\nstringrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nreturn_url\nstring | nullrequired\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\n​\nembed_origin\nstring | nullrequired\n\nWhen checkout is embedded, represents the Origin of the page embedding the checkout. Used as a security measure to send messages only to the embedding page.\n\n​\namount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\n​\ntax_amount\ninteger | nullrequired\n\nSales tax amount in cents. If null, it means there is no enough information yet to calculate it.\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\n​\ncurrency\nstringrequired\n\nCurrency code of the checkout session.\n\n​\nactive_trial_interval\nenum<string> | nullrequired\n\nInterval unit of the trial period, if any. This value is either set from the checkout, if trial_interval is set, or from the selected product.\n\nAvailable options: day, week, month, year \n​\nactive_trial_interval_count\ninteger | nullrequired\n\nNumber of interval units of the trial period, if any. This value is either set from the checkout, if trial_interval_count is set, or from the selected product.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nEnd date and time of the trial period, if any.\n\n​\nproduct_id\nstring<uuid4>required\n\nID of the product to checkout.\n\n​\nproduct_price_id\nstring<uuid4>required\n\nID of the product price to checkout.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount applied to the checkout.\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\nis_discount_applicable\nbooleanrequired\n\nWhether the discount is applicable to the checkout. Typically, free and custom prices are not discountable.\n\n​\nis_free_product_price\nbooleanrequired\n\nWhether the product price is free, regardless of discounts.\n\n​\nis_payment_required\nbooleanrequired\n\nWhether the checkout requires payment, e.g. in case of free products or discounts that cover the total amount.\n\n​\nis_payment_setup_required\nbooleanrequired\n\nWhether the checkout requires setting up a payment method, regardless of the amount, e.g. subscriptions that have first free cycles.\n\n​\nis_payment_form_required\nbooleanrequired\n\nWhether the checkout requires a payment form, whether because of a payment or payment method setup.\n\n​\ncustomer_id\nstring<uuid4> | nullrequired\n​\nis_business_customer\nbooleanrequired\n\nWhether the customer is a business or an individual. If true, the customer will be required to fill their full billing address and billing name.\n\n​\ncustomer_name\nstring | nullrequired\n\nName of the customer.\n\n​\ncustomer_email\nstring | nullrequired\n\nEmail address of the customer.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | nullrequired\n​\ncustomer_billing_name\nstring | nullrequired\n​\ncustomer_billing_address\nobject | nullrequired\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | nullrequired\n​\npayment_processor_metadata\nobjectrequired\n\nShow child attributes\n\n​\nbilling_address_fields\nobjectrequired\n\nDetermine which billing address fields should be disabled, optional or required in the checkout form.\n\nShow child attributes\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nmetadata\nobjectrequired\n\nHide child attributes\n\n​\nmetadata.{key}\nstring\ninteger\nnumber\nboolean\n​\nexternal_customer_id\nstring | nullrequired\n\nID of the customer in your system. If a matching customer exists on Polar, the resulting order will be linked to this customer. Otherwise, a new customer will be created with this external ID set.\n\n​\ncustomer_external_id\nstring | nullrequireddeprecated\n​\nproducts\nCheckoutProduct · object[]required\n\nList of products available to select.\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nProduct selected to checkout.\n\nShow child attributes\n\n​\nproduct_price\nobjectrequired\n\nPrice of the selected product.\nA recurring price for a product, i.e. a subscription.\n\nDeprecated: The recurring interval should be set on the product itself.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\n\nSchema for a fixed amount discount that is applied once or forever.\n\nCheckoutDiscountFixedOnceForeverDuration\nCheckoutDiscountFixedRepeatDuration\nCheckoutDiscountPercentageOnceForeverDuration\nCheckoutDiscountPercentageRepeatDuration\n\nShow child attributes\n\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nShow child attributes\n\n​\ncustomer_metadata\nobjectrequired\n\nShow child attributes\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\n​\nprice_per_seat\ninteger | null\n\nPrice per seat in cents for the current seat count, based on the applicable tier. Only relevant for seat-based pricing.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Checkout Sessions\nList checkout sessions. **Scopes**: `checkouts:read` `checkouts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Credits Benefit - Polar",
    "url": "https://polar.sh/docs/features/benefits/credits",
    "html": "Benefits\nCredits Benefit\nCopy page\n\nCreate your own Credits benefit\n\nThe Credits benefit allows you to credit a customer’s Usage Meter balance.\n​\nCrediting Usage Meter Balance\nThe Credits benefit will credit a customer’s Usage Meter balance at different points in time depending on the type of product purchased.\n​\nSubscription Products\nThe customer will be credited the amount of units specified in the benefit at the beginning of every subscription cycle period — monthly or yearly.\n​\nOne-Time Products\nThe customer will be credited the amount of units specified in the benefit once at the time of purchase.\n​\nRollover unused credits\nYou can choose to rollover unused credits to the next billing cycle. This means that if a customer doesn’t use all of their credits in a given billing cycle, the remaining credits will be added to their balance for the next billing cycle. To enable this feature, check the “Rollover unused credits” checkbox when creating or editing the Credits benefit.\nIf you change the rollover setting for a benefit, it will only apply to new credits issued after the change. Existing credits will not be affected.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCustom\nCreate your own Custom benefit\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Integrate Polar with Laravel - Polar",
    "url": "https://polar.sh/docs/guides/laravel",
    "html": "Framework Guides\nIntegrate Polar with Laravel\nCopy page\n\nIn this guide, we’ll show you how to integrate Polar with Laravel.\n\nConsider following this guide while using the Polar Sandbox Environment. This will allow you to test your integration without affecting your production data.\n​\nPolar Laravel Example App\nWe’ve created a simple example Laravel application that you can use as a reference.\nView Code on GitHub\n​\nSetting up environment variables\n​\nPolar API Key\nTo authenticate with Polar, you need to create an access token, and supply it to Laravel using a POLAR_API_KEY environment variable.\nYou can create an organization access token from your organization settings.\n​\nFetching Polar Products for display\n​\nCreating the Products Controller\nGo ahead and add the following entry in your routes/web.php file:\nCopy\nAsk AI\n// routes/web.php\nRoute::get('/products', [ProductsController::class, 'handle']);\n\nNext up, create the ProductsController class in the app/Http/Controllers directory:\nCopy\nAsk AI\n// app/Http/Controllers/ProductsController.php\n<?php\n\nnamespace App\\Http\\Controllers;\n\nuse Illuminate\\Http\\Request;\nuse Illuminate\\Support\\Facades\\Http;\nuse Illuminate\\Support\\Facades\\Log;\n\nclass ProductsController extends Controller\n{\n    public function handle(Request $request)\n    {\n        // Change from sandbox-api.polar.sh -> api.polar.sh when ready to go live\n        // And don't forget to update the .env file with the correct POLAR_ORGANIZATION_ID and POLAR_WEBHOOK_SECRET\n        $data = Http::get('https://sandbox-api.polar.sh/v1/products', [\n            'is_archived' => false,\n        ]);\n\n        $products = $data->json();\n\n        return view('products', ['products' => $products['items']]);\n    }\n}\n\n​\nDisplaying Products\nFinally, create the products view in the resources/views directory:\nCopy\nAsk AI\n// resources/views/products.blade.php\n@foreach ($products as $product)\n    <div>\n        <h3>{{ $product['name'] }}</h3>\n        <a href=\"/checkout?priceId={{ $product['prices'][0]['id'] }}\">Buy</a>\n    </div>\n@endforeach\n\nNotice that we create a link to /checkout with a query parameter priceId. This is the ID of the price that the user will be charged for when they click the “Buy” button. We will configure this route in the next section.\nThat’s it for the products page. You can now display the products to your users, and they will be able to buy them. Let’s now create the checkout endpoint.\n​\nGenerating Polar Checkout Sessions\nThis endpoint will be responsible for creating a new checkout session, redirecting the user to the Polar Checkout page & redirect back to a configured confirmation page.\nGo ahead and create a new entry in your routes/web.php file:\nCopy\nAsk AI\n// routes/web.php\nRoute::get('/checkout', [CheckoutController::class, 'handle']);\n\nNext, create the CheckoutController class in the app/Http/Controllers directory:\nCopy\nAsk AI\n// app/Http/Controllers/CheckoutController.php\n<?php\n\nnamespace App\\Http\\Controllers;\n\nuse Illuminate\\Http\\Request;\nuse Illuminate\\Support\\Facades\\Http;\nuse Illuminate\\Support\\Facades\\Log;\n\nclass CheckoutController extends Controller\n{\n    public function handle(Request $request)\n    {\n        $productPriceId = $request->query('priceId', '');\n        // Polar will replace {CHECKOUT_ID} with the actual checkout ID upon a confirmed checkout\n        $confirmationUrl = $request->getSchemeAndHttpHost() . '/confirmation?checkout_id={CHECKOUT_ID}';\n\n        // Change from sandbox-api.polar.sh -> api.polar.sh when ready to go live\n        // And don't forget to update the .env file with the correct POLAR_ORGANIZATION_ID and POLAR_WEBHOOK_SECRET\n        $result = Http::withHeaders([\n            'Authorization' => 'Bearer ' . env('POLAR_API_KEY'),\n            'Content-Type' => 'application/json',\n        ])->post('https://sandbox-api.polar.sh/v1/checkouts/custom/', [\n            'product_price_id' => $productPriceId,\n            'success_url' => $confirmationUrl,\n            'payment_processor' => 'stripe',\n        ]);\n\n        $data = $result->json();\n\n        $checkoutUrl = $data['url'];\n\n        return redirect($checkoutUrl);\n    }\n}\n\nWe can now easily create a checkout session & redirect there by creating a link to /checkout?priceId={priceId}. Just like we did when displaying the products above.\nUpon Checkout success, the user will be redirected to the confirmation page.\n​\nCreating the Confirmation Page\nCreate a new entry in your routes/web.php file:\nCopy\nAsk AI\n// routes/web.php\nRoute::get('/confirmation', [ConfirmationController::class, 'handle']);\n\nNext, create the ConfirmationController class in the app/Http/Controllers directory:\nCopy\nAsk AI\n// app/Http/Controllers/ConfirmationController.php\n<?php\n\nnamespace App\\Http\\Controllers;\n\nuse Illuminate\\Http\\Request;\nuse Illuminate\\Support\\Facades\\Http;\nuse Illuminate\\Support\\Facades\\Log;\n\nclass ConfirmationController extends Controller\n{\n    public function handle(Request $request)\n    {\n        // Change from sandbox-api.polar.sh -> api.polar.sh when ready to go live\n        // And don't forget to update the .env file with the correct POLAR_ORGANIZATION_ID and POLAR_WEBHOOK_SECRET\n        $data = Http::withHeaders([\n            'Authorization' => 'Bearer ' . env('POLAR_API_KEY'),\n            'Content-Type' => 'application/json',\n        ])->get('https://sandbox-api.polar.sh/v1/checkouts/custom/' . $request->query('checkout_id'));\n\n        $checkout = $data->json();\n\n        Log::info(json_encode($checkout, JSON_PRETTY_PRINT));\n\n        return view('confirmation', ['checkout' => $checkout]);\n    }\n}\n\nThe checkout is not considered “successful” yet however. It’s initially marked as confirmed until you’ve received a webhook event checkout.updated with a status set to succeeded. We’ll cover this in the next section.\n​\nHandling Polar Webhooks\nPolar can send you events about various things happening in your organization. This is very useful for keeping your database in sync with Polar checkouts, orders, subscriptions, etc.\nConfiguring a webhook is simple. Head over to your organization’s settings page and click on the “Add Endpoint” button to create a new webhook.\n​\nTunneling webhook events to your local development environment\nIf you’re developing locally, you can use a tool like ngrok to tunnel webhook events to your local development environment. This will allow you to test your webhook handlers without deploying them to a live server.\nRun the following command to start an ngrok tunnel:\nCopy\nAsk AI\nngrok http 3000\n\n​\nAdd Webhook Endpoint\nPoint the Webhook to your-app.com/api/webhook/polar. This must be an absolute URL which Polar can reach. If you use ngrok, the URL will look something like this: https://<your-ngrok-id>.ngrok-free.app/api/webhook/polar.\nSelect which events you want to be notified about. You can read more about the available events in the Events section.\nGenerate a secret key to sign the requests. This will allow you to verify that the requests are truly coming from Polar.\nAdd the secret key to your environment variables.\nCopy\nAsk AI\n# .env\nPOLAR_API_KEY=\"polar_oat...\"\nPOLAR_WEBHOOK_SECRET=\"...\"\n\n​\nSetting up the Webhook handler\nFirst, we need to install the standard-webhooks package to properly decode the incoming webhook payloads.\nCopy\nAsk AI\ncomposer require standard-webhooks/standard-webhooks:dev-main\n\nGo and add a routes/api.php file and add the following entry:\nCopy\nAsk AI\n// routes/api.php\nRoute::webhooks('/webhook/polar');\n\nMake sure that it is included in the Bootstrap file.\nCopy\nAsk AI\n// bootstrap/app.php\n<?php\n\nuse Illuminate\\Foundation\\Application;\nuse Illuminate\\Foundation\\Configuration\\Exceptions;\nuse Illuminate\\Foundation\\Configuration\\Middleware;\n\nreturn Application::configure(basePath: dirname(__DIR__))\n    ->withRouting(\n        web: __DIR__.'/../routes/web.php',\n        api: __DIR__.'/../routes/api.php',\n        commands: __DIR__.'/../routes/console.php',\n        health: '/up',\n    )\n    ->withMiddleware(function (Middleware $middleware) {\n        //\n    })\n    ->withExceptions(function (Exceptions $exceptions) {\n        //\n    })->create();\n\nWe will use Spatie’s Webhook Client to handle the webhook events. It will automatically verify the signature of the requests, and dispatch the payload to a job queue for processing.\nCopy\nAsk AI\ncomposer require spatie/laravel-webhook-client\n\nLet’s publish the config:\nCopy\nAsk AI\nphp artisan vendor:publish --provider=\"Spatie\\WebhookClient\\WebhookClientServiceProvider\" --tag=\"webhook-client-config\"\n\nThis will create a new file called webhook-client.php in the config folder.\nWe need to adjust it to properly verify the signature of the requests.\nCopy\nAsk AI\n// config/webhook-client.php\n<?php\nreturn [\n    'configs' => [\n        [\n            /*\n             * This package supports multiple webhook receiving endpoints. If you only have\n             * one endpoint receiving webhooks, you can use 'default'.\n             */\n            'name' => 'default',\n\n            /*\n             * We expect that every webhook call will be signed using a secret. This secret\n             * is used to verify that the payload has not been tampered with.\n             */\n            'signing_secret' => env('POLAR_WEBHOOK_SECRET'),\n\n            /*\n             * The name of the header containing the signature.\n             */\n            'signature_header_name' => 'webhook-signature',\n\n            /*\n             *  This class will verify that the content of the signature header is valid.\n             *\n             * It should implement \\Spatie\\WebhookClient\\SignatureValidator\\SignatureValidator\n             */\n            // 'signature_validator' => \\Spatie\\WebhookClient\\SignatureValidator\\DefaultSignatureValidator::class,\n            'signature_validator' => App\\Handler\\PolarSignature::class,\n\n            /*\n             * This class determines if the webhook call should be stored and processed.\n             */\n            'webhook_profile' => \\Spatie\\WebhookClient\\WebhookProfile\\ProcessEverythingWebhookProfile::class,\n\n            /*\n             * This class determines the response on a valid webhook call.\n             */\n            'webhook_response' => \\Spatie\\WebhookClient\\WebhookResponse\\DefaultRespondsTo::class,\n\n            /*\n             * The classname of the model to be used to store webhook calls. The class should\n             * be equal or extend Spatie\\WebhookClient\\Models\\WebhookCall.\n             */\n            'webhook_model' => \\Spatie\\WebhookClient\\Models\\WebhookCall::class,\n\n            /*\n             * In this array, you can pass the headers that should be stored on\n             * the webhook call model when a webhook comes in.\n             *\n             * To store all headers, set this value to `*`.\n             */\n            'store_headers' => [],\n\n            /*\n             * The class name of the job that will process the webhook request.\n             *\n             * This should be set to a class that extends \\Spatie\\WebhookClient\\Jobs\\ProcessWebhookJob.\n             */\n            'process_webhook_job' => App\\Handler\\ProcessWebhook::class,\n        ],\n    ],\n\n    /*\n     * The integer amount of days after which models should be deleted.\n     *\n     * 7 deletes all records after 1 week. Set to null if no models should be deleted.\n     */\n    'delete_after_days' => 30,\n];\n\n​\nPreparing the database\nBy default, all webhook calls get saved into the database. So, we need to publish the migration that will hold the records. So run:\nCopy\nAsk AI\nphp artisan vendor:publish --provider=\"Spatie\\WebhookClient\\WebhookClientServiceProvider\" --tag=\"webhook-client-migrations\"\n\nThis will create a new migration file in the “database/migration” folder.\nThen run php artisan migrate to run the migration.\n​\nSetting up the queue system\nBefore we set up our job handler — let’s set up our queue system\nGo to your “.env” file and set the QUEUE_CONNECTION=database — you can decide to use other connections like redis.\nLet’s create our jobs table by running php artisan queue:table and then run the migration using php artisan migrate.\n​\nCreate the Handlers\nThe next thing we do is to create a folder named Handler inside the app folder. Then inside this app/Handler, create two files which are\nPolarSignature.php\nProcessWebhook.php\nInside app/Handler/PolarSignature.php, what we want to do is to validate that the request came from Polar. Add the code to that file.\nCopy\nAsk AI\n// app/Handler/PolarSignature.php\n<?php\n\nnamespace App\\Handler;\n\nuse Illuminate\\Http\\Request;\nuse Spatie\\WebhookClient\\Exceptions\\WebhookFailed;\nuse Spatie\\WebhookClient\\WebhookConfig;\nuse Spatie\\WebhookClient\\SignatureValidator\\SignatureValidator;\n\nclass PolarSignature implements SignatureValidator\n{\n    public function isValid(Request $request, WebhookConfig $config): bool\n    {\n        $signingSecret = base64_encode($config->signingSecret);\n        $wh = new \\StandardWebhooks\\Webhook($signingSecret);\n\n        return boolval( $wh->verify($request->getContent(), array(\n            \"webhook-id\" => $request->header(\"webhook-id\"),\n            \"webhook-signature\" => $request->header(\"webhook-signature\"),\n            \"webhook-timestamp\" => $request->header(\"webhook-timestamp\"),\n        )));\n    }\n}\n\nGreat. So the other file app/Handler/ProcessWebhook.php extends the ProcessWebhookJob class which holds the WebhookCall variables containing each job’s detail.\nCopy\nAsk AI\n// app/Handler/ProcessWebhook.php\n<?php\n\nnamespace App\\Handler;\n\nuse Illuminate\\Support\\Facades\\Log;\nuse Spatie\\WebhookClient\\Jobs\\ProcessWebhookJob;\n\nclass ProcessWebhook extends ProcessWebhookJob\n{\n    public function handle()\n    {\n        $decoded = json_decode($this->webhookCall, true);\n        $data = $decoded['payload'];\n\n        switch ($data['type']) {\n            case \"checkout.created\":\n                // Handle the checkout created event\n                break;\n            case \"checkout.updated\":\n                // Handle the checkout updated event\n                break;\n            case \"subscription.created\":\n                // Handle the subscription created event\n                break;\n            case \"subscription.updated\":\n                // Handle the subscription updated event\n                break;\n            case \"subscription.active\":\n                // Handle the subscription active event\n                break;\n            case \"subscription.revoked\":\n                // Handle the subscription revoked event\n                break;\n            case \"subscription.canceled\":\n                // Handle the subscription canceled event\n                break;\n            default:\n                // Handle unknown event\n                Log::info($data['type']);\n                break;\n        }\n\n        //Acknowledge you received the response\n        http_response_code(200);\n    }\n}\n\nOur application is ready to receive webhook requests.\nDon’t forget to run php artisan queue:listen to process the jobs.\n​\nTips\nIf you’re keeping track of active and inactive subscriptions in your database, make sure to handle the subscription.active and subscription.revoked events accordingly.\nThe cancellation of a subscription is handled by the subscription.canceled event. The user has probably canceled their subscription before the end of the billing period. Do not revoke any kind of access immediately, but rather wait until the end of the billing period or when you receive the subscription.revoked event.\n​\nNotifying the client about the event\nIf you’re building a real-time application, you might want to notify the client about the event. On the confirmation-page, you can listen for the checkout.updated event and update the UI accordingly when it reaches the succeeded status.\n​\nPolar Laravel Example App\nWe’ve created a simple example Laravel application that you can use as a reference\nView Code on GitHub\nIf you have issues or need support, feel free to join our Discord.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nSetup an endpoint\nGet notifications asynchronously when events occur instead of having to poll for updates\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Billing - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/billing",
    "html": "Usage Based Billing\nBilling\nCopy page\n\nHow billing works with Usage Based\n\n​\nMetered Pricing\nMetered Pricing is a pricing model where you charge your customers based on the usage of your application.\nThere are a few different pricing models unique to Usage Based Billing:\nUnit Pricing\nVolume Pricing (coming soon)\n​\nUnit Pricing\nUnit pricing is a simple pricing model where you charge a fixed amount for each unit of usage.\nFor example:\nProduct Meter\tPrice per unit\nprompt-tokens\t$0.10\ncompletion-tokens\t$0.18\nThis means that every unit of prompt-tokens consumed by a customer will be charged at $0.10 and every unit of completion-tokens will be charged at $0.18.\nIt’s a linear pricing model, where the price per unit is fixed.\n​\nVolume Pricing (coming soon)\nVolume pricing is a pricing model where you charge a fixed amount for a certain volume of usage. Volume pricing is not yet available, but will be coming soon.\n​\nInvoicing Customers for Usage\nOur Usage Based Billing infrastructure is built to work with Subscription products out of the box.\n​\nAdd a metered price to your product\nTo charge your customers for usage, you need to add a metered price to your product. You’ll need the select the Meter and the amount per unit.\nOptionally, you can set a cap. The customer will be charged the cap amount if they exceed it, regardless of the usage.\n​\nMonthly Invoicing\nIf a customer has a subscription with a monthly billing period, usage is aggregated monthly and invoiced at the end of the month with the rest of the subscription.\n​\nYearly Invoicing\nIf a customer has a subscription with a yearly billing period, usage is aggregated yearly and invoiced at the end of the year with the rest of the subscription.\n​\nUsage Charges and Subscription Cancellation\nWhen a subscription is canceled, it generally remains active until the end of the current billing period (known as the grace period). During this grace period, all accumulated usage-based charges continue to be tracked. A final invoice will be issued at the end of that period to cover the consumed usage, even if the subscription will not be renewed. This ensures no pending usage charges are lost.\nIf a discount is applied on the subscription, it’ll be applied on the whole invoice, including metered usage.\n​\nCustomer Portal\nCustomers can view their estimated charges for each meter in the Customer Portal.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nIntroduction\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Product - Polar",
    "url": "https://polar.sh/docs/api-reference/products/get",
    "html": "Products\nGet Product\nCopy page\n\nGet a product by ID.\n\nScopes: products:read products:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nproducts\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe product ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nA product.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nname\nstringrequired\n\nThe name of the product.\n\n​\ndescription\nstring | nullrequired\n\nThe description of the product.\n\n​\nrecurring_interval\nenum<string> | nullrequired\n\nThe recurring interval of the product. If None, the product is a one-time purchase.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\ninteger | nullrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on. None for one-time products.\n\n​\nis_recurring\nbooleanrequired\n\nWhether the product is a subscription.\n\n​\nis_archived\nbooleanrequired\n\nWhether the product is archived and no longer available.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the product.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of prices for this product.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nbenefits\nBenefits · arrayrequired\n\nList of benefits granted by the product.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nShow child attributes\n\n​\nmedias\nProductMediaFileRead · object[]required\n\nList of medias associated to the product.\n\nShow child attributes\n\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nList of custom fields attached to the product.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Products\nList products. **Scopes**: `products:read` `products:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Products - Polar",
    "url": "https://polar.sh/docs/api-reference/products/list",
    "html": "Products\nList Products\nCopy page\n\nList products.\n\nScopes: products:read products:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nproducts\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\nid\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nquery\nstring | null\n\nFilter by product name.\n\n​\nis_archived\nboolean | null\n\nFilter on archived products.\n\n​\nis_recurring\nboolean | null\n\nFilter on recurring products. If true, only subscriptions tiers are returned. If false, only one-time purchase products are returned.\n\n​\nbenefit_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter products granting specific benefit.\nThe benefit ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nProduct · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Product\nCreate a product. **Scopes**: `products:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Product - Polar",
    "url": "https://polar.sh/docs/api-reference/products/create",
    "html": "Products\nCreate Product\nCopy page\n\nCreate a product.\n\nScopes: products:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nproducts\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\nProductCreateRecurring\nProductCreateOneTime\n​\nname\nstringrequired\n\nThe name of the product.\n\nMinimum length: 3\n​\nprices\nProductPriceCreateList · arrayrequired\n\nList of available prices for this product. It should contain at most one static price (fixed, custom or free), and any number of metered prices. Metered prices are not supported on one-time purchase products.\n\nMinimum length: 1\nProductPriceFixedCreate\nProductPriceCustomCreate\nProductPriceFreeCreate\nProductPriceSeatBasedCreate\nProductPriceMeteredUnitCreate\n\nShow child attributes\n\n​\nrecurring_interval\nenum<string>required\n\nThe recurring interval of the product. Note that the day and week values are for internal Polar staff use only.\n\nAvailable options: day, week, month, year \n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ndescription\nstring | null\n\nThe description of the product.\n\n​\nmedias\nstring<uuid4>[] | null\n\nList of file IDs. Each one must be on the same organization as the product, of type product_media and correctly uploaded.\n\n​\nattached_custom_fields\nAttachedCustomFieldCreate · object[]\n\nList of custom fields to attach.\n\nShow child attributes\n\n​\norganization_id\nstring<uuid4> | null\n\nThe ID of the organization owning the product. Required unless you use an organization token.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ntrial_interval\nenum<string> | null\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | null\n\nThe number of interval units for the trial period.\n\nRequired range: 1 <= x <= 1000\n​\nrecurring_interval_count\nintegerdefault:1\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\nRequired range: 1 <= x <= 999\nResponse\n201\napplication/json\n\nProduct created.\n\nA product.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nname\nstringrequired\n\nThe name of the product.\n\n​\ndescription\nstring | nullrequired\n\nThe description of the product.\n\n​\nrecurring_interval\nenum<string> | nullrequired\n\nThe recurring interval of the product. If None, the product is a one-time purchase.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\ninteger | nullrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on. None for one-time products.\n\n​\nis_recurring\nbooleanrequired\n\nWhether the product is a subscription.\n\n​\nis_archived\nbooleanrequired\n\nWhether the product is archived and no longer available.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the product.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of prices for this product.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nbenefits\nBenefits · arrayrequired\n\nList of benefits granted by the product.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nShow child attributes\n\n​\nmedias\nProductMediaFileRead · object[]required\n\nList of medias associated to the product.\n\nShow child attributes\n\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nList of custom fields attached to the product.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Product\nUpdate a product. **Scopes**: `products:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Event Ingestion - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/event-ingestion",
    "html": "Usage Based Billing\nEvent Ingestion\nCopy page\n\nIngest events from your application\n\nEvents are the core of Usage Based Billing. They represent some usage done by a customer in your application. Typical examples of events are:\nA customer consumed AI LLM tokens\nA customer streamed minutes of video\nA customer uploaded a file to your application\nEvents are sent to Polar using the Events Ingestion API and are stored in our database. An event consists of the following fields:\nA name, which is a string that can be used to identify the type of event. For example, ai_usage, video_streamed or file_uploaded.\nA customer_id or external_customer_id, which is Polar’s customer ID or your user’s ID. This is used to identify the customer that triggered the event.\nA metadata object, which is a JSON object that can contain any additional information about the event. This is useful for storing information that can be used to filter the events or compute the actual usage. For example, you can store the duration of the video streamed or the size of the file uploaded.\nHere is an example of an event:\nCopy\nAsk AI\n{\n  \"name\": \"ai_usage\",\n  \"external_customer_id\": \"cus_123\",\n  \"metadata\": {\n    \"model\": \"gpt-4.1-nano\",\n    \"requests\": 1,\n    \"total_tokens\": 77,\n    \"request_tokens\": 58,\n    \"response_tokens\": 19\n  }\n}\n\n​\nIngest events using the Polar SDK\nTo ingest events, you can use the Polar SDKs.\n​\nTypeScript Example\nCopy\nAsk AI\nimport { Polar } from \"@polar-sh/sdk\";\n\nconst polar = new Polar({\n  accessToken: process.env[\"POLAR_ACCESS_TOKEN\"] ?? \"\",\n});\n\nawait polar.events.ingest({\n  events: [\n    {\n      name: \"<value>\",\n      externalCustomerId: \"<id>\",\n      metadata: {\n        key: \"value\",\n      },\n    },\n  ],\n});\n\nYou are always responsible for checking the balance of your customers’ Usage Meter. As events always are ingested, we will never prohibit any customer’s action based on their Usage Meter balance.\n​\nIngestion Strategies\nTo make it easier to ingest events, we have created a set of ingestion strategies for common event sources.\nLearn more about our Ingestion Strategies.\n​\nGood to know\n​\nEvents are immutable\nOnce an event is ingested, it cannot be changed, nor can it be deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nStrategy Introduction\nIngestion strategies for Usage Based Billing\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Product Benefits - Polar",
    "url": "https://polar.sh/docs/api-reference/products/update-benefits",
    "html": "Products\nUpdate Product Benefits\nCopy page\n\nUpdate benefits granted by a product.\n\nScopes: products:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nproducts\n/\n{id}\n/\nbenefits\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe product ID.\n\nBody\napplication/json\n\nSchema to update the benefits granted by a product.\n\n​\nbenefits\nstring<uuid4>[]required\n\nList of benefit IDs. Each one must be on the same organization as the product.\n\nThe benefit ID.\n\nResponse\n200\napplication/json\n\nProduct benefits updated.\n\nA product.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nname\nstringrequired\n\nThe name of the product.\n\n​\ndescription\nstring | nullrequired\n\nThe description of the product.\n\n​\nrecurring_interval\nenum<string> | nullrequired\n\nThe recurring interval of the product. If None, the product is a one-time purchase.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\ninteger | nullrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on. None for one-time products.\n\n​\nis_recurring\nbooleanrequired\n\nWhether the product is a subscription.\n\n​\nis_archived\nbooleanrequired\n\nWhether the product is archived and no longer available.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the product.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of prices for this product.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nbenefits\nBenefits · arrayrequired\n\nList of benefits granted by the product.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nShow child attributes\n\n​\nmedias\nProductMediaFileRead · object[]required\n\nList of medias associated to the product.\n\nShow child attributes\n\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nList of custom fields attached to the product.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nIngest Events\nIngest batch of events. **Scopes**: `events:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Meters - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/meters",
    "html": "Usage Based Billing\nMeters\nCopy page\n\nCreating and managing meters for Usage Based Billing\n\nMeters are there to filter and aggregate the events that are ingested. Said another way, this is how you define what usage you want to charge for, based on the events you send to Polar. For example:\nAI usage meter, which filters the events with the name ai_usage and sums the total_tokens field.\nVideo streaming meter, which filters the events with the name video_streamed and sums the duration field.\nFile upload meter, which filters the events with the name file_uploaded and sums the size field.\nYou can create and manage your meters from the dashboard. Polar is then able to compute the usage over time, both globally and per customer.\n​\nCreating a Meter\nTo create a meter, navigate to the Meters page in the sidebar and click the “Create Meter” button.\n​\nFilters\nA filter is a set of clauses that are combined using conjunctions. They’re used to filter events that you’ve ingested into Polar.\n​\nClauses\nA clause is a condition that an event must meet to be included in the meter.\n​\nProperty\nProperties are the properties of the event that you want to filter on.\nIf you want to match on a metadata field, you can use the metadata key directly. No need to include a metadata. prefix.\n​\nOperator\nOperators are the operators that you want to use to filter the events.\nEquals\nNot equals\nGreater Than\nGreater Than or Equals\nLess Than\nLess Than or Equals\nContains\nDoes Not Contain\n​\nValue\nValues are automatically parsed in the filter builder. They’re parsed in the following order:\nNumber — Tries to parse the value as number\nBoolean — Checks if value is “true” or “false”\nString — Treats value as string as fallback\n​\nConjunctions\nA conjunction is a logical operator that combines two or more clauses.\nand — All clauses must be true for the event to be included.\nor — At least one clause must be true for the event to be included.\n​\nAggregation\nThe aggregation is the function that is used to aggregate the events that match the filter.\nFor example, if you want to count the number of events that match the filter, you can use the Count aggregation. If you want to sum the value of a metadata field, you can use the Sum aggregation.\nCount — Counts the number of events that match the filter.\nSum — Sums the value of a property.\nAverage — Computes the average value of a property.\nMinimum — Computes the minimum value of a property.\nMaximum — Computes the maximum value of a property.\nUnique — Counts the number of unique values of a property.\n\nExample\n\nIf you want to use a metadata property in the aggregation, you can use the metadata property directly. No need to include a metadata. prefix.\n​\nExample\nThe following Meter Filter & Aggregation will match events that have the name openai-usage and sum units over metadata property completionTokens.\nYou can Preview the events matched by the meter while creating it.\n​\nGood to know\nA few things to keep in mind when creating and managing meters:\n​\nRenaming a Meter\nUntil https://github.com/polarsource/polar/issues/6490 is fixed, please contact support to rename the meter for you.\n​\nUpdating a Meter\nYou may update a meter’s filters or aggregation function as long as the meter doesn’t have any processed events or does not have any customer purchase associated with it.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCredits\nCrediting customers for Usage Based Billing\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Credits - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/credits",
    "html": "Usage Based Billing\nCredits\nCopy page\n\nCrediting customers for Usage Based Billing\n\nCredits is the way to pre-pay for usage in Polar. It allows you to give your customers the ability to pre-pay for usage instead of risk getting a hefty bill at the end of the month.\n​\nHow Credits Work\nWhen you ingest events into a Usage Meter, customers will be charged for the usage based on the product’s pricing model.\nHowever, sometimes you may want to give your customers the ability to pre-pay for usage instead of risk getting a hefty bill at the end of the month.\nWhen you issue Credits to a customer, we first deduct the Credits from their Usage Meter balance. If the Usage Meter balance reaches 0, the customer will be charged for the overage.\n​\nCredits-only spending\nTo avoid any overage charges, don’t create any Metered price on your product. This way, billing won’t be triggered at all for the meter\n​\nIssuing Credits with the Credits Benefit\nThe Credits benefit will credit a customer’s Usage Meter balance at different points in time depending on the type of product the benefit is attached to.\n​\nSubscription Products\nThe customer will be credited the amount of units specified in the benefit at the beginning of every subscription cycle period — monthly or yearly.\n​\nOne-Time Products\nThe customer will be credited the amount of units specified in the benefit once at the time of purchase.\n​\nTracking customer’s balance\nIn your application, you’ll likely need to track the customer’s balance for a given meter. The easiest way to do this is to use the Customer State, which will give you the overview of the customer, including the balance for each of their active meters.\nYou can also specifically query the meters balance using the Customer Meters API.\nPolar doesn’t block usage if the customer exceeds their balance. You’re responsible for implementing the logic you need to prevent usage if they exceed it.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nBilling\nHow billing works with Usage Based\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Ingest Events - Polar",
    "url": "https://polar.sh/docs/api-reference/events/ingest",
    "html": "Events\nIngest Events\nCopy page\n\nIngest batch of events.\n\nScopes: events:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nevents\n/\ningest\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nevents\nEvents · arrayrequired\n\nList of events to ingest.\n\nEventCreateCustomer\nEventCreateExternalCustomer\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ninserted\nintegerrequired\n\nNumber of events inserted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Event\nGet an event by ID. **Scopes**: `events:read` `events:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Checkout Sessions - Polar",
    "url": "https://polar.sh/docs/api-reference/checkouts/list-sessions",
    "html": "Checkout\nList Checkout Sessions\nCopy page\n\nList checkout sessions.\n\nScopes: checkouts:read checkouts:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckouts\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproduct_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\n​\nstatus\nenum<string> | null\nenum<string>[] | null\n\nFilter by checkout session status.\n\nAvailable options: open, expired, confirmed, succeeded, failed \n​\nquery\nstring | null\n\nFilter by customer email.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nCheckout · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Checkout Session\nUpdate a checkout session. **Scopes**: `checkouts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Checkout Session - Polar",
    "url": "https://polar.sh/docs/api-reference/checkouts/update-session",
    "html": "Checkout\nUpdate Checkout Session\nCopy page\n\nUpdate a checkout session.\n\nScopes: checkouts:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckouts\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe checkout session ID.\n\nBody\napplication/json\n\nUpdate an existing checkout session using an access token.\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nproduct_id\nstring<uuid4> | null\n\nID of the product to checkout. Must be present in the checkout's product list.\n\n​\nproduct_price_id\nstring<uuid4> | nulldeprecated\n\nID of the product price to checkout. Must correspond to a price present in the checkout's product list.\n\n​\namount\ninteger | null\n\nAmount in cents, before discounts and taxes. Only useful for custom prices, it'll be ignored for fixed and free prices.\n\nRequired range: 50 <= x <= 99999999\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\nRequired range: 1 <= x <= 1000\n​\nis_business_customer\nboolean | null\n​\ncustomer_name\nstring | null\n\nName of the customer.\n\n​\ncustomer_email\nstring<email> | null\n\nEmail address of the customer.\n\n​\ncustomer_billing_name\nstring | null\n​\ncustomer_billing_address\nobject | null\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | null\n​\ntrial_interval\nenum<string> | null\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | null\n\nThe number of interval units for the trial period.\n\nRequired range: 1 <= x <= 1000\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ndiscount_id\nstring<uuid4> | null\n\nID of the discount to apply to the checkout.\n\n​\nallow_discount_codes\nboolean | null\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nboolean | null\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | null\n​\ncustomer_metadata\nobject | null\n\nKey-value object allowing you to store additional information that'll be copied to the created customer.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nsuccess_url\nstring<uri> | null\n\nURL where the customer will be redirected after a successful payment.You can add the checkout_id={CHECKOUT_ID} query parameter to retrieve the checkout session id.\n\nRequired string length: 1 - 2083\n​\nreturn_url\nstring<uri> | null\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\nRequired string length: 1 - 2083\n​\nembed_origin\nstring | null\n\nIf you plan to embed the checkout session, set this to the Origin of the embedding page. It'll allow the Polar iframe to communicate with the parent page.\n\nResponse\n200\napplication/json\n\nCheckout session updated.\n\nCheckout session data retrieved using an access token.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nstatus\nenum<string>required\nStatus of the checkout session.\n\n    - Open: the checkout session was opened.\n    - Expired: the checkout session was expired and is no more accessible.\n    - Confirmed: the user on the checkout session clicked Pay. This is not indicative of the payment's success status.\n    - Failed: the checkout definitely failed for technical reasons and cannot be retried. In most cases, this state is never reached.\n    - Succeeded: the payment on the checkout was performed successfully.\nAvailable options: open, expired, confirmed, succeeded, failed \n​\nclient_secret\nstringrequired\n\nClient secret used to update and complete the checkout session from the client.\n\n​\nurl\nstringrequired\n\nURL where the customer can access the checkout session.\n\n​\nexpires_at\nstring<date-time>required\n\nExpiration date and time of the checkout session.\n\n​\nsuccess_url\nstringrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nreturn_url\nstring | nullrequired\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\n​\nembed_origin\nstring | nullrequired\n\nWhen checkout is embedded, represents the Origin of the page embedding the checkout. Used as a security measure to send messages only to the embedding page.\n\n​\namount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\n​\ntax_amount\ninteger | nullrequired\n\nSales tax amount in cents. If null, it means there is no enough information yet to calculate it.\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\n​\ncurrency\nstringrequired\n\nCurrency code of the checkout session.\n\n​\nactive_trial_interval\nenum<string> | nullrequired\n\nInterval unit of the trial period, if any. This value is either set from the checkout, if trial_interval is set, or from the selected product.\n\nAvailable options: day, week, month, year \n​\nactive_trial_interval_count\ninteger | nullrequired\n\nNumber of interval units of the trial period, if any. This value is either set from the checkout, if trial_interval_count is set, or from the selected product.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nEnd date and time of the trial period, if any.\n\n​\nproduct_id\nstring<uuid4>required\n\nID of the product to checkout.\n\n​\nproduct_price_id\nstring<uuid4>required\n\nID of the product price to checkout.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount applied to the checkout.\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\nis_discount_applicable\nbooleanrequired\n\nWhether the discount is applicable to the checkout. Typically, free and custom prices are not discountable.\n\n​\nis_free_product_price\nbooleanrequired\n\nWhether the product price is free, regardless of discounts.\n\n​\nis_payment_required\nbooleanrequired\n\nWhether the checkout requires payment, e.g. in case of free products or discounts that cover the total amount.\n\n​\nis_payment_setup_required\nbooleanrequired\n\nWhether the checkout requires setting up a payment method, regardless of the amount, e.g. subscriptions that have first free cycles.\n\n​\nis_payment_form_required\nbooleanrequired\n\nWhether the checkout requires a payment form, whether because of a payment or payment method setup.\n\n​\ncustomer_id\nstring<uuid4> | nullrequired\n​\nis_business_customer\nbooleanrequired\n\nWhether the customer is a business or an individual. If true, the customer will be required to fill their full billing address and billing name.\n\n​\ncustomer_name\nstring | nullrequired\n\nName of the customer.\n\n​\ncustomer_email\nstring | nullrequired\n\nEmail address of the customer.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | nullrequired\n​\ncustomer_billing_name\nstring | nullrequired\n​\ncustomer_billing_address\nobject | nullrequired\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | nullrequired\n​\npayment_processor_metadata\nobjectrequired\n\nShow child attributes\n\n​\nbilling_address_fields\nobjectrequired\n\nDetermine which billing address fields should be disabled, optional or required in the checkout form.\n\nShow child attributes\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_customer_id\nstring | nullrequired\n\nID of the customer in your system. If a matching customer exists on Polar, the resulting order will be linked to this customer. Otherwise, a new customer will be created with this external ID set.\n\n​\ncustomer_external_id\nstring | nullrequireddeprecated\n​\nproducts\nCheckoutProduct · object[]required\n\nList of products available to select.\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nProduct selected to checkout.\n\nShow child attributes\n\n​\nproduct_price\nobjectrequired\n\nPrice of the selected product.\nA recurring price for a product, i.e. a subscription.\n\nDeprecated: The recurring interval should be set on the product itself.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\n\nSchema for a fixed amount discount that is applied once or forever.\n\nCheckoutDiscountFixedOnceForeverDuration\nCheckoutDiscountFixedRepeatDuration\nCheckoutDiscountPercentageOnceForeverDuration\nCheckoutDiscountPercentageRepeatDuration\n\nShow child attributes\n\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nShow child attributes\n\n​\ncustomer_metadata\nobjectrequired\n\nShow child attributes\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\n​\nprice_per_seat\ninteger | null\n\nPrice per seat in cents for the current seat count, based on the applicable tier. Only relevant for seat-based pricing.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Checkout Session from Client\nGet a checkout session by client secret.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Checkout Session from Client - Polar",
    "url": "https://polar.sh/docs/api-reference/checkouts/get-session-from-client",
    "html": "Checkout\nGet Checkout Session from Client\nCopy page\n\nGet a checkout session by client secret.\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckouts\n/\nclient\n/\n{client_secret}\nTry it\nPath Parameters\n​\nclient_secret\nstringrequired\n\nThe checkout session client secret.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nCheckout session data retrieved using the client secret.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nstatus\nenum<string>required\nStatus of the checkout session.\n\n    - Open: the checkout session was opened.\n    - Expired: the checkout session was expired and is no more accessible.\n    - Confirmed: the user on the checkout session clicked Pay. This is not indicative of the payment's success status.\n    - Failed: the checkout definitely failed for technical reasons and cannot be retried. In most cases, this state is never reached.\n    - Succeeded: the payment on the checkout was performed successfully.\nAvailable options: open, expired, confirmed, succeeded, failed \n​\nclient_secret\nstringrequired\n\nClient secret used to update and complete the checkout session from the client.\n\n​\nurl\nstringrequired\n\nURL where the customer can access the checkout session.\n\n​\nexpires_at\nstring<date-time>required\n\nExpiration date and time of the checkout session.\n\n​\nsuccess_url\nstringrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nreturn_url\nstring | nullrequired\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\n​\nembed_origin\nstring | nullrequired\n\nWhen checkout is embedded, represents the Origin of the page embedding the checkout. Used as a security measure to send messages only to the embedding page.\n\n​\namount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\n​\ntax_amount\ninteger | nullrequired\n\nSales tax amount in cents. If null, it means there is no enough information yet to calculate it.\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\n​\ncurrency\nstringrequired\n\nCurrency code of the checkout session.\n\n​\nactive_trial_interval\nenum<string> | nullrequired\n\nInterval unit of the trial period, if any. This value is either set from the checkout, if trial_interval is set, or from the selected product.\n\nAvailable options: day, week, month, year \n​\nactive_trial_interval_count\ninteger | nullrequired\n\nNumber of interval units of the trial period, if any. This value is either set from the checkout, if trial_interval_count is set, or from the selected product.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nEnd date and time of the trial period, if any.\n\n​\nproduct_id\nstring<uuid4>required\n\nID of the product to checkout.\n\n​\nproduct_price_id\nstring<uuid4>required\n\nID of the product price to checkout.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount applied to the checkout.\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\nis_discount_applicable\nbooleanrequired\n\nWhether the discount is applicable to the checkout. Typically, free and custom prices are not discountable.\n\n​\nis_free_product_price\nbooleanrequired\n\nWhether the product price is free, regardless of discounts.\n\n​\nis_payment_required\nbooleanrequired\n\nWhether the checkout requires payment, e.g. in case of free products or discounts that cover the total amount.\n\n​\nis_payment_setup_required\nbooleanrequired\n\nWhether the checkout requires setting up a payment method, regardless of the amount, e.g. subscriptions that have first free cycles.\n\n​\nis_payment_form_required\nbooleanrequired\n\nWhether the checkout requires a payment form, whether because of a payment or payment method setup.\n\n​\ncustomer_id\nstring<uuid4> | nullrequired\n​\nis_business_customer\nbooleanrequired\n\nWhether the customer is a business or an individual. If true, the customer will be required to fill their full billing address and billing name.\n\n​\ncustomer_name\nstring | nullrequired\n\nName of the customer.\n\n​\ncustomer_email\nstring | nullrequired\n\nEmail address of the customer.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | nullrequired\n​\ncustomer_billing_name\nstring | nullrequired\n​\ncustomer_billing_address\nobject | nullrequired\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | nullrequired\n​\npayment_processor_metadata\nobjectrequired\n\nShow child attributes\n\n​\nbilling_address_fields\nobjectrequired\n\nDetermine which billing address fields should be disabled, optional or required in the checkout form.\n\nShow child attributes\n\n​\nproducts\nCheckoutProduct · object[]required\n\nList of products available to select.\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nProduct selected to checkout.\n\nShow child attributes\n\n​\nproduct_price\nobjectrequired\n\nPrice of the selected product.\nA recurring price for a product, i.e. a subscription.\n\nDeprecated: The recurring interval should be set on the product itself.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\n\nSchema for a fixed amount discount that is applied once or forever.\n\nCheckoutDiscountFixedOnceForeverDuration\nCheckoutDiscountFixedRepeatDuration\nCheckoutDiscountPercentageOnceForeverDuration\nCheckoutDiscountPercentageRepeatDuration\n\nShow child attributes\n\n​\norganization\nobjectrequired\n\nShow child attributes\n\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nShow child attributes\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\n​\nprice_per_seat\ninteger | null\n\nPrice per seat in cents for the current seat count, based on the applicable tier. Only relevant for seat-based pricing.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Checkout Session from Client\nUpdate a checkout session by client secret.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Checkout Session from Client - Polar",
    "url": "https://polar.sh/docs/api-reference/checkouts/update-session-from-client",
    "html": "Checkout\nUpdate Checkout Session from Client\nCopy page\n\nUpdate a checkout session by client secret.\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckouts\n/\nclient\n/\n{client_secret}\nTry it\nPath Parameters\n​\nclient_secret\nstringrequired\n\nThe checkout session client secret.\n\nBody\napplication/json\n\nUpdate an existing checkout session using the client secret.\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nproduct_id\nstring<uuid4> | null\n\nID of the product to checkout. Must be present in the checkout's product list.\n\n​\nproduct_price_id\nstring<uuid4> | nulldeprecated\n\nID of the product price to checkout. Must correspond to a price present in the checkout's product list.\n\n​\namount\ninteger | null\n\nAmount in cents, before discounts and taxes. Only useful for custom prices, it'll be ignored for fixed and free prices.\n\nRequired range: 50 <= x <= 99999999\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\nRequired range: 1 <= x <= 1000\n​\nis_business_customer\nboolean | null\n​\ncustomer_name\nstring | null\n\nName of the customer.\n\n​\ncustomer_email\nstring<email> | null\n\nEmail address of the customer.\n\n​\ncustomer_billing_name\nstring | null\n​\ncustomer_billing_address\nobject | null\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | null\n​\ndiscount_code\nstring | null\n\nDiscount code to apply to the checkout.\n\nResponse\n200\napplication/json\n\nCheckout session updated.\n\nCheckout session data retrieved using the client secret.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nstatus\nenum<string>required\nStatus of the checkout session.\n\n    - Open: the checkout session was opened.\n    - Expired: the checkout session was expired and is no more accessible.\n    - Confirmed: the user on the checkout session clicked Pay. This is not indicative of the payment's success status.\n    - Failed: the checkout definitely failed for technical reasons and cannot be retried. In most cases, this state is never reached.\n    - Succeeded: the payment on the checkout was performed successfully.\nAvailable options: open, expired, confirmed, succeeded, failed \n​\nclient_secret\nstringrequired\n\nClient secret used to update and complete the checkout session from the client.\n\n​\nurl\nstringrequired\n\nURL where the customer can access the checkout session.\n\n​\nexpires_at\nstring<date-time>required\n\nExpiration date and time of the checkout session.\n\n​\nsuccess_url\nstringrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nreturn_url\nstring | nullrequired\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\n​\nembed_origin\nstring | nullrequired\n\nWhen checkout is embedded, represents the Origin of the page embedding the checkout. Used as a security measure to send messages only to the embedding page.\n\n​\namount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\n​\ntax_amount\ninteger | nullrequired\n\nSales tax amount in cents. If null, it means there is no enough information yet to calculate it.\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\n​\ncurrency\nstringrequired\n\nCurrency code of the checkout session.\n\n​\nactive_trial_interval\nenum<string> | nullrequired\n\nInterval unit of the trial period, if any. This value is either set from the checkout, if trial_interval is set, or from the selected product.\n\nAvailable options: day, week, month, year \n​\nactive_trial_interval_count\ninteger | nullrequired\n\nNumber of interval units of the trial period, if any. This value is either set from the checkout, if trial_interval_count is set, or from the selected product.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nEnd date and time of the trial period, if any.\n\n​\nproduct_id\nstring<uuid4>required\n\nID of the product to checkout.\n\n​\nproduct_price_id\nstring<uuid4>required\n\nID of the product price to checkout.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount applied to the checkout.\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\nis_discount_applicable\nbooleanrequired\n\nWhether the discount is applicable to the checkout. Typically, free and custom prices are not discountable.\n\n​\nis_free_product_price\nbooleanrequired\n\nWhether the product price is free, regardless of discounts.\n\n​\nis_payment_required\nbooleanrequired\n\nWhether the checkout requires payment, e.g. in case of free products or discounts that cover the total amount.\n\n​\nis_payment_setup_required\nbooleanrequired\n\nWhether the checkout requires setting up a payment method, regardless of the amount, e.g. subscriptions that have first free cycles.\n\n​\nis_payment_form_required\nbooleanrequired\n\nWhether the checkout requires a payment form, whether because of a payment or payment method setup.\n\n​\ncustomer_id\nstring<uuid4> | nullrequired\n​\nis_business_customer\nbooleanrequired\n\nWhether the customer is a business or an individual. If true, the customer will be required to fill their full billing address and billing name.\n\n​\ncustomer_name\nstring | nullrequired\n\nName of the customer.\n\n​\ncustomer_email\nstring | nullrequired\n\nEmail address of the customer.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | nullrequired\n​\ncustomer_billing_name\nstring | nullrequired\n​\ncustomer_billing_address\nobject | nullrequired\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | nullrequired\n​\npayment_processor_metadata\nobjectrequired\n\nShow child attributes\n\n​\nbilling_address_fields\nobjectrequired\n\nDetermine which billing address fields should be disabled, optional or required in the checkout form.\n\nShow child attributes\n\n​\nproducts\nCheckoutProduct · object[]required\n\nList of products available to select.\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nProduct selected to checkout.\n\nShow child attributes\n\n​\nproduct_price\nobjectrequired\n\nPrice of the selected product.\nA recurring price for a product, i.e. a subscription.\n\nDeprecated: The recurring interval should be set on the product itself.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\n\nSchema for a fixed amount discount that is applied once or forever.\n\nCheckoutDiscountFixedOnceForeverDuration\nCheckoutDiscountFixedRepeatDuration\nCheckoutDiscountPercentageOnceForeverDuration\nCheckoutDiscountPercentageRepeatDuration\n\nShow child attributes\n\n​\norganization\nobjectrequired\n\nShow child attributes\n\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nShow child attributes\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\n​\nprice_per_seat\ninteger | null\n\nPrice per seat in cents for the current seat count, based on the applicable tier. Only relevant for seat-based pricing.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nConfirm Checkout Session from Client\nConfirm a checkout session by client secret. Orders and subscriptions will be processed.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Confirm Checkout Session from Client - Polar",
    "url": "https://polar.sh/docs/api-reference/checkouts/confirm-session-from-client",
    "html": "Checkout\nConfirm Checkout Session from Client\nCopy page\n\nConfirm a checkout session by client secret.\n\nOrders and subscriptions will be processed.\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckouts\n/\nclient\n/\n{client_secret}\n/\nconfirm\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nclient_secret\nstringrequired\n\nThe checkout session client secret.\n\nBody\napplication/json\n\nConfirm a checkout session using a Stripe confirmation token.\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nproduct_id\nstring<uuid4> | null\n\nID of the product to checkout. Must be present in the checkout's product list.\n\n​\nproduct_price_id\nstring<uuid4> | nulldeprecated\n\nID of the product price to checkout. Must correspond to a price present in the checkout's product list.\n\n​\namount\ninteger | null\n\nAmount in cents, before discounts and taxes. Only useful for custom prices, it'll be ignored for fixed and free prices.\n\nRequired range: 50 <= x <= 99999999\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\nRequired range: 1 <= x <= 1000\n​\nis_business_customer\nboolean | null\n​\ncustomer_name\nstring | null\n\nName of the customer.\n\n​\ncustomer_email\nstring<email> | null\n\nEmail address of the customer.\n\n​\ncustomer_billing_name\nstring | null\n​\ncustomer_billing_address\nobject | null\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | null\n​\ndiscount_code\nstring | null\n\nDiscount code to apply to the checkout.\n\n​\nconfirmation_token_id\nstring | null\n\nID of the Stripe confirmation token. Required for fixed prices and custom prices.\n\nResponse\n200\napplication/json\n\nCheckout session confirmed.\n\nCheckout session data retrieved using the client secret after confirmation.\n\nIt contains a customer session token to retrieve order information\nright after the checkout.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nstatus\nstringrequired\nAllowed value: \"confirmed\"\n​\nclient_secret\nstringrequired\n\nClient secret used to update and complete the checkout session from the client.\n\n​\nurl\nstringrequired\n\nURL where the customer can access the checkout session.\n\n​\nexpires_at\nstring<date-time>required\n\nExpiration date and time of the checkout session.\n\n​\nsuccess_url\nstringrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nreturn_url\nstring | nullrequired\n\nWhen set, a back button will be shown in the checkout to return to this URL.\n\n​\nembed_origin\nstring | nullrequired\n\nWhen checkout is embedded, represents the Origin of the page embedding the checkout. Used as a security measure to send messages only to the embedding page.\n\n​\namount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\n​\ntax_amount\ninteger | nullrequired\n\nSales tax amount in cents. If null, it means there is no enough information yet to calculate it.\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\n​\ncurrency\nstringrequired\n\nCurrency code of the checkout session.\n\n​\nactive_trial_interval\nenum<string> | nullrequired\n\nInterval unit of the trial period, if any. This value is either set from the checkout, if trial_interval is set, or from the selected product.\n\nAvailable options: day, week, month, year \n​\nactive_trial_interval_count\ninteger | nullrequired\n\nNumber of interval units of the trial period, if any. This value is either set from the checkout, if trial_interval_count is set, or from the selected product.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nEnd date and time of the trial period, if any.\n\n​\nproduct_id\nstring<uuid4>required\n\nID of the product to checkout.\n\n​\nproduct_price_id\nstring<uuid4>required\n\nID of the product price to checkout.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount applied to the checkout.\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting. If you preset the billing address, this setting will be automatically set to true.\n\n​\nis_discount_applicable\nbooleanrequired\n\nWhether the discount is applicable to the checkout. Typically, free and custom prices are not discountable.\n\n​\nis_free_product_price\nbooleanrequired\n\nWhether the product price is free, regardless of discounts.\n\n​\nis_payment_required\nbooleanrequired\n\nWhether the checkout requires payment, e.g. in case of free products or discounts that cover the total amount.\n\n​\nis_payment_setup_required\nbooleanrequired\n\nWhether the checkout requires setting up a payment method, regardless of the amount, e.g. subscriptions that have first free cycles.\n\n​\nis_payment_form_required\nbooleanrequired\n\nWhether the checkout requires a payment form, whether because of a payment or payment method setup.\n\n​\ncustomer_id\nstring<uuid4> | nullrequired\n​\nis_business_customer\nbooleanrequired\n\nWhether the customer is a business or an individual. If true, the customer will be required to fill their full billing address and billing name.\n\n​\ncustomer_name\nstring | nullrequired\n\nName of the customer.\n\n​\ncustomer_email\nstring | nullrequired\n\nEmail address of the customer.\n\n​\ncustomer_ip_address\nstring<ipvanyaddress> | nullrequired\n​\ncustomer_billing_name\nstring | nullrequired\n​\ncustomer_billing_address\nobject | nullrequired\n\nBilling address of the customer.\n\nShow child attributes\n\n​\ncustomer_tax_id\nstring | nullrequired\n​\npayment_processor_metadata\nobjectrequired\n\nShow child attributes\n\n​\nbilling_address_fields\nobjectrequired\n\nDetermine which billing address fields should be disabled, optional or required in the checkout form.\n\nShow child attributes\n\n​\nproducts\nCheckoutProduct · object[]required\n\nList of products available to select.\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nProduct selected to checkout.\n\nShow child attributes\n\n​\nproduct_price\nobjectrequired\n\nPrice of the selected product.\nA recurring price for a product, i.e. a subscription.\n\nDeprecated: The recurring interval should be set on the product itself.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\n\nSchema for a fixed amount discount that is applied once or forever.\n\nCheckoutDiscountFixedOnceForeverDuration\nCheckoutDiscountFixedRepeatDuration\nCheckoutDiscountPercentageOnceForeverDuration\nCheckoutDiscountPercentageRepeatDuration\n\nShow child attributes\n\n​\norganization\nobjectrequired\n\nShow child attributes\n\n​\nattached_custom_fields\nAttachedCustomField · object[]required\n\nShow child attributes\n\n​\ncustomer_session_token\nstringrequired\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats for seat-based pricing.\n\n​\nprice_per_seat\ninteger | null\n\nPrice per seat in cents for the current seat count, based on the applicable tier. Only relevant for seat-based pricing.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Checkout Link\nCreate a checkout link. **Scopes**: `checkout_links:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Seats - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-seats/list",
    "html": "Customer Seats\nList Seats\nCopy page\n\nScopes: customer_seats:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-seats\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\nsubscription_id\nstring | null\n​\norder_id\nstring | null\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nseats\nCustomerSeat · object[]required\n\nList of seats\n\nShow child attributes\n\n​\navailable_seats\nintegerrequired\n\nNumber of available seats\n\n​\ntotal_seats\nintegerrequired\n\nTotal number of seats for the subscription\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nRevoke Seat\n**Scopes**: `customer_seats:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Revoke Seat - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-seats/revoke",
    "html": "Customer Seats\nRevoke Seat\nCopy page\n\nScopes: customer_seats:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-seats\n/\n{seat_id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nseat_id\nstringrequired\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid>required\n\nThe seat ID\n\n​\nstatus\nenum<string>required\n\nStatus of the seat\n\nAvailable options: pending, claimed, revoked \n​\nsubscription_id\nstring<uuid> | null\n\nThe subscription ID (for recurring seats)\n\n​\norder_id\nstring<uuid> | null\n\nThe order ID (for one-time purchase seats)\n\n​\ncustomer_id\nstring<uuid> | null\n\nThe assigned customer ID\n\n​\ncustomer_email\nstring | null\n\nThe assigned customer email\n\n​\ninvitation_token_expires_at\nstring<date-time> | null\n\nWhen the invitation token expires\n\n​\nclaimed_at\nstring<date-time> | null\n\nWhen the seat was claimed\n\n​\nrevoked_at\nstring<date-time> | null\n\nWhen the seat was revoked\n\n​\nseat_metadata\nobject | null\n\nAdditional metadata for the seat\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nResend Invitation\n**Scopes**: `customer_seats:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Resend Invitation - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-seats/resend",
    "html": "Customer Seats\nResend Invitation\nCopy page\n\nScopes: customer_seats:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-seats\n/\n{seat_id}\n/\nresend\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nseat_id\nstringrequired\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid>required\n\nThe seat ID\n\n​\nstatus\nenum<string>required\n\nStatus of the seat\n\nAvailable options: pending, claimed, revoked \n​\nsubscription_id\nstring<uuid> | null\n\nThe subscription ID (for recurring seats)\n\n​\norder_id\nstring<uuid> | null\n\nThe order ID (for one-time purchase seats)\n\n​\ncustomer_id\nstring<uuid> | null\n\nThe assigned customer ID\n\n​\ncustomer_email\nstring | null\n\nThe assigned customer email\n\n​\ninvitation_token_expires_at\nstring<date-time> | null\n\nWhen the invitation token expires\n\n​\nclaimed_at\nstring<date-time> | null\n\nWhen the seat was claimed\n\n​\nrevoked_at\nstring<date-time> | null\n\nWhen the seat was revoked\n\n​\nseat_metadata\nobject | null\n\nAdditional metadata for the seat\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Claim Info\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Claim Info - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-seats/get-claim-info",
    "html": "Customer Seats\nGet Claim Info\nCopy page\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-seats\n/\nclaim\n/\n{invitation_token}\nTry it\nPath Parameters\n​\ninvitation_token\nstringrequired\nResponse\n200\napplication/json\n\nSuccessful Response\n\nRead-only information about a seat claim invitation.\nSafe for email scanners - no side effects when fetched.\n\n​\nproduct_name\nstringrequired\n\nName of the product\n\n​\nproduct_id\nstring<uuid>required\n\nID of the product\n\n​\norganization_name\nstringrequired\n\nName of the organization\n\n​\norganization_slug\nstringrequired\n\nSlug of the organization\n\n​\ncustomer_email\nstringrequired\n\nEmail of the customer assigned to this seat\n\n​\ncan_claim\nbooleanrequired\n\nWhether the seat can be claimed\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nClaim Seat\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Claim Seat - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-seats/claim",
    "html": "Customer Seats\nClaim Seat\nCopy page\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-seats\n/\nclaim\nTry it\nBody\napplication/json\n​\ninvitation_token\nstringrequired\n\nInvitation token to claim the seat\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nResponse after successfully claiming a seat.\n\n​\nseat\nobjectrequired\n\nThe claimed seat\n\nShow child attributes\n\n​\ncustomer_session_token\nstringrequired\n\nSession token for immediate customer portal access\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate File\nCreate a file. **Scopes**: `files:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Deactivate License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/license-keys/deactivate",
    "html": "License Keys\nDeactivate License Key\nCopy page\n\nDeactivate a license key instance.\n\nScopes: license_keys:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nlicense-keys\n/\ndeactivate\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nkey\nstringrequired\n​\norganization_id\nstring<uuid4>required\n​\nactivation_id\nstring<uuid4>required\nResponse\n204\n\nLicense key activation deactivated.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAssign Seat\n**Scopes**: `customer_seats:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Order - Polar",
    "url": "https://polar.sh/docs/api-reference/orders/patch",
    "html": "Orders\nUpdate Order\nCopy page\n\nUpdate an order.\n\nScopes: orders:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norders\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nBody\napplication/json\n\nSchema to update an order.\n\n​\nbilling_name\nstring | nullrequired\n\nThe name of the customer that should appear on the invoice. Can't be updated after the invoice is generated.\n\n​\nbilling_address\nobject | nullrequired\n\nThe address of the customer that should appear on the invoice. Can't be updated after the invoice is generated.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nstatus\nenum<string>required\nAvailable options: pending, paid, refunded, partially_refunded \n​\npaid\nbooleanrequired\n\nWhether the order has been paid for.\n\nExamples:\n\ntrue\n\n​\nsubtotal_amount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\nExamples:\n\n10000\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\nExamples:\n\n1000\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\nExamples:\n\n9000\n\n​\ntax_amount\nintegerrequired\n\nSales tax amount in cents.\n\nExamples:\n\n720\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\nExamples:\n\n9720\n\n​\napplied_balance_amount\nintegerrequired\n\nCustomer's balance amount applied to this invoice. Can increase the total amount paid, if the customer has a negative balance, or decrease it, if the customer has a positive balance.Amount in cents.\n\nExamples:\n\n0\n\n​\ndue_amount\nintegerrequired\n\nAmount in cents that is due for this order.\n\nExamples:\n\n0\n\n​\nrefunded_amount\nintegerrequired\n\nAmount refunded in cents.\n\nExamples:\n\n0\n\n​\nrefunded_tax_amount\nintegerrequired\n\nSales tax refunded in cents.\n\nExamples:\n\n0\n\n​\ncurrency\nstringrequired\nExamples:\n\n\"usd\"\n\n​\nbilling_reason\nenum<string>required\nAvailable options: purchase, subscription_create, subscription_cycle, subscription_update \n​\nbilling_name\nstring | nullrequired\n\nThe name of the customer that should appear on the invoice.\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ninvoice_number\nstringrequired\n\nThe invoice number associated with this order.\n\n​\nis_invoice_generated\nbooleanrequired\n\nWhether an invoice has been generated for this order.\n\n​\ncustomer_id\nstring<uuid4>required\n​\nproduct_id\nstring<uuid4> | nullrequired\n​\ndiscount_id\nstring<uuid4> | nullrequired\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nplatform_fee_amount\nintegerrequired\n\nPlatform fee amount in cents.\n\nExamples:\n\n500\n\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nuser_id\nstring<uuid4>requireddeprecated\n​\nproduct\nobject | nullrequired\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nsubscription\nobject | nullrequired\n\nShow child attributes\n\n​\nitems\nOrderItemSchema · object[]required\n\nLine items composing the order.\n\nShow child attributes\n\n​\ndescription\nstringrequired\n\nA summary description of the order.\n\nExamples:\n\n\"Pro Plan\"\n\n​\nseats\ninteger | null\n\nNumber of seats purchased (for seat-based one-time orders).\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Orders\nList orders. **Scopes**: `orders:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Orders - Polar",
    "url": "https://polar.sh/docs/api-reference/orders/list",
    "html": "Orders\nList Orders\nCopy page\n\nList orders.\n\nScopes: orders:read\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norders\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproduct_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\nproduct_billing_type\nenum<string> | null\nenum<string>[] | null\n\nFilter by product billing type. recurring will filter data corresponding to subscriptions creations or renewals. one_time will filter data corresponding to one-time purchases.\n\nAvailable options: one_time, recurring \n​\ndiscount_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by discount ID.\n\n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\n​\ncheckout_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by checkout ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nOrder · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGenerate Order Invoice\nTrigger generation of an order's invoice. **Scopes**: `orders:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Subscriptions - Polar",
    "url": "https://polar.sh/docs/api-reference/subscriptions/list",
    "html": "Subscriptions\nList Subscriptions\nCopy page\n\nList subscriptions.\n\nScopes: subscriptions:read subscriptions:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nsubscriptions\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproduct_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\n​\nexternal_customer_id\nstring | null\nstring[] | null\n\nFilter by customer external ID.\nThe customer external ID.\n\n​\ndiscount_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by discount ID.\nThe product ID.\n\n​\nactive\nboolean | null\n\nFilter by active or inactive subscription.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nSubscription · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Subscription\nUpdate a subscription. **Scopes**: `subscriptions:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Generate Order Invoice - Polar",
    "url": "https://polar.sh/docs/api-reference/orders/post-invoice",
    "html": "Orders\nGenerate Order Invoice\nCopy page\n\nTrigger generation of an order’s invoice.\n\nScopes: orders:read\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norders\n/\n{id}\n/\ninvoice\nTry it\nOnce the invoice is generated, it’s permanent and cannot be modified.\nMake sure the billing details (name and address) are correct before generating the invoice. You can update them before generating the invoice by calling the PATCH /v1/orders/{id} endpoint.\nAfter successfully calling this endpoint, you get a 202 response, meaning the generation of the invoice has been scheduled. It usually only takes a few seconds before you can retrieve the invoice using the GET /v1/orders/{id} /invoice endpoint.\nIf you want a reliable notification when the invoice is ready, you can listen to the order.updated webhook and check the is_invoice_generated field.\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nResponse\n202\napplication/json\n\nSuccessful Response\n\nThe response is of type any.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Order Invoice\nGet an order's invoice data. **Scopes**: `orders:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Order Invoice - Polar",
    "url": "https://polar.sh/docs/api-reference/orders/get-invoice",
    "html": "Orders\nGet Order Invoice\nCopy page\n\nGet an order’s invoice data.\n\nScopes: orders:read\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norders\n/\n{id}\n/\ninvoice\nTry it\nThe invoice must be generated first before it can be retrieved. You should call the POST /v1/orders/{id}/invoice endpoint to generate the invoice.\nIf the invoice is not generated, you will receive a 404 error.\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nOrder's invoice data.\n\n​\nurl\nstringrequired\n\nThe URL to the invoice.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Discount\nGet a discount by ID. **Scopes**: `discounts:read` `discounts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Subscription - Polar",
    "url": "https://polar.sh/docs/api-reference/subscriptions/update",
    "html": "Subscriptions\nUpdate Subscription\nCopy page\n\nUpdate a subscription.\n\nScopes: subscriptions:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nsubscriptions\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe subscription ID.\n\nBody\napplication/json\nSubscriptionUpdateProduct\nSubscriptionUpdateDiscount\nSubscriptionUpdateTrial\nSubscriptionCancel\nSubscriptionRevoke\n​\nproduct_id\nstring<uuid4>required\n\nUpdate subscription to another product.\n\n​\nproration_behavior\nenum<string> | null\n\nDetermine how to handle the proration billing. If not provided, will use the default organization setting.\n\nAvailable options: invoice, prorate \nResponse\n200\napplication/json\n\nSubscription updated.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\namount\nintegerrequired\n\nThe amount of the subscription.\n\nExamples:\n\n10000\n\n​\ncurrency\nstringrequired\n\nThe currency of the subscription.\n\nExamples:\n\n\"usd\"\n\n​\nrecurring_interval\nenum<string>required\n\nThe interval at which the subscription recurs.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\nintegerrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\n​\nstatus\nenum<string>required\n\nThe status of the subscription.\n\nAvailable options: incomplete, incomplete_expired, trialing, active, past_due, canceled, unpaid \n​\ncurrent_period_start\nstring<date-time>required\n\nThe start timestamp of the current billing period.\n\n​\ncurrent_period_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the current billing period.\n\n​\ntrial_start\nstring<date-time> | nullrequired\n\nThe start timestamp of the trial period, if any.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the trial period, if any.\n\n​\ncancel_at_period_end\nbooleanrequired\n\nWhether the subscription will be canceled at the end of the current period.\n\n​\ncanceled_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription was canceled. The subscription might still be active if cancel_at_period_end is true.\n\n​\nstarted_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription started.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription will end.\n\n​\nended_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription ended.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the subscribed customer.\n\n​\nproduct_id\nstring<uuid4>required\n\nThe ID of the subscribed product.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nThe ID of the applied discount, if any.\n\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\ncustomer_cancellation_reason\nenum<string> | nullrequired\nAvailable options: customer_service, low_quality, missing_features, switched_service, too_complex, too_expensive, unused, other \n​\ncustomer_cancellation_comment\nstring | nullrequired\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nA product.\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of enabled prices for the subscription.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nmeters\nSubscriptionMeter · object[]required\n\nList of meters associated with the subscription.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats included in the subscription (for seat-based pricing).\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nRevoke Subscription\nRevoke a subscription, i.e cancel immediately. **Scopes**: `subscriptions:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Customer State - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/state",
    "html": "Customers\nGet Customer State\nCopy page\n\nGet a customer state by ID.\n\nThe customer state includes information about the customer’s active subscriptions and benefits.\n\nIt’s the ideal endpoint to use when you need to get a full overview of a customer’s status.\n\nScopes: customers:read customers:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\n{id}\n/\nstate\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe customer ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nA customer along with additional state information:\n\nActive subscriptions\nGranted benefits\nActive meters\n​\nid\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_id\nstring | nullrequired\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nemail\nstringrequired\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nemail_verified\nbooleanrequired\n\nWhether the customer email address is verified. The address is automatically verified when the customer accesses the customer portal using their email address.\n\nExamples:\n\ntrue\n\n​\nname\nstring | nullrequired\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the customer.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ndeleted_at\nstring<date-time> | nullrequired\n\nTimestamp for when the customer was soft deleted.\n\n​\nactive_subscriptions\nCustomerStateSubscription · object[]required\n\nThe customer's active subscriptions.\n\nShow child attributes\n\n​\ngranted_benefits\nCustomerStateBenefitGrant · object[]required\n\nThe customer's active benefit grants.\n\nShow child attributes\n\n​\nactive_meters\nCustomerStateMeter · object[]required\n\nThe customer's active meters.\n\nShow child attributes\n\n​\navatar_url\nstringrequired\nExamples:\n\n\"https://www.gravatar.com/avatar/xxx?d=404\"\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Customer State by External ID\nGet a customer state by external ID. The customer state includes information about the customer's active subscriptions and benefits. It's the ideal endpoint to use when you need to get a full overview of a customer's status. **Scopes**: `customers:read` `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Revoke Subscription - Polar",
    "url": "https://polar.sh/docs/api-reference/subscriptions/revoke",
    "html": "Subscriptions\nRevoke Subscription\nCopy page\n\nRevoke a subscription, i.e cancel immediately.\n\nScopes: subscriptions:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nsubscriptions\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe subscription ID.\n\nResponse\n200\napplication/json\n\nSubscription revoked.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\namount\nintegerrequired\n\nThe amount of the subscription.\n\nExamples:\n\n10000\n\n​\ncurrency\nstringrequired\n\nThe currency of the subscription.\n\nExamples:\n\n\"usd\"\n\n​\nrecurring_interval\nenum<string>required\n\nThe interval at which the subscription recurs.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\nintegerrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\n​\nstatus\nenum<string>required\n\nThe status of the subscription.\n\nAvailable options: incomplete, incomplete_expired, trialing, active, past_due, canceled, unpaid \n​\ncurrent_period_start\nstring<date-time>required\n\nThe start timestamp of the current billing period.\n\n​\ncurrent_period_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the current billing period.\n\n​\ntrial_start\nstring<date-time> | nullrequired\n\nThe start timestamp of the trial period, if any.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the trial period, if any.\n\n​\ncancel_at_period_end\nbooleanrequired\n\nWhether the subscription will be canceled at the end of the current period.\n\n​\ncanceled_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription was canceled. The subscription might still be active if cancel_at_period_end is true.\n\n​\nstarted_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription started.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription will end.\n\n​\nended_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription ended.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the subscribed customer.\n\n​\nproduct_id\nstring<uuid4>required\n\nThe ID of the subscribed product.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nThe ID of the applied discount, if any.\n\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\ncustomer_cancellation_reason\nenum<string> | nullrequired\nAvailable options: customer_service, low_quality, missing_features, switched_service, too_complex, too_expensive, unused, other \n​\ncustomer_cancellation_comment\nstring | nullrequired\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nproduct\nobjectrequired\n\nA product.\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of enabled prices for the subscription.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nmeters\nSubscriptionMeter · object[]required\n\nList of meters associated with the subscription.\n\nShow child attributes\n\n​\nseats\ninteger | null\n\nNumber of seats included in the subscription (for seat-based pricing).\n\n​\ncustom_field_data\nobject\n\nKey-value object storing custom field values.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Order\nGet an order by ID. **Scopes**: `orders:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Customers - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/list",
    "html": "Customers\nList Customers\nCopy page\n\nList customers.\n\nScopes: customers:read customers:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nemail\nstring | null\n\nFilter by exact email.\n\n​\nquery\nstring | null\n\nFilter by name, email, or external ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nCustomer · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Customer\nCreate a customer. **Scopes**: `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Customer State by External ID - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/state-external",
    "html": "Customers\nGet Customer State by External ID\nCopy page\n\nGet a customer state by external ID.\n\nThe customer state includes information about the customer’s active subscriptions and benefits.\n\nIt’s the ideal endpoint to use when you need to get a full overview of a customer’s status.\n\nScopes: customers:read customers:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\nexternal\n/\n{external_id}\n/\nstate\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nexternal_id\nstringrequired\n\nThe customer external ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nA customer along with additional state information:\n\nActive subscriptions\nGranted benefits\nActive meters\n​\nid\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_id\nstring | nullrequired\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nemail\nstringrequired\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nemail_verified\nbooleanrequired\n\nWhether the customer email address is verified. The address is automatically verified when the customer accesses the customer portal using their email address.\n\nExamples:\n\ntrue\n\n​\nname\nstring | nullrequired\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the customer.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ndeleted_at\nstring<date-time> | nullrequired\n\nTimestamp for when the customer was soft deleted.\n\n​\nactive_subscriptions\nCustomerStateSubscription · object[]required\n\nThe customer's active subscriptions.\n\nShow child attributes\n\n​\ngranted_benefits\nCustomerStateBenefitGrant · object[]required\n\nThe customer's active benefit grants.\n\nShow child attributes\n\n​\nactive_meters\nCustomerStateMeter · object[]required\n\nThe customer's active meters.\n\nShow child attributes\n\n​\navatar_url\nstringrequired\nExamples:\n\n\"https://www.gravatar.com/avatar/xxx?d=404\"\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Customers\nList customers. **Scopes**: `customers:read` `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Customer - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/get",
    "html": "Customers\nGet Customer\nCopy page\n\nGet a customer by ID.\n\nScopes: customers:read customers:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe customer ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nA customer in an organization.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_id\nstring | nullrequired\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nemail\nstringrequired\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nemail_verified\nbooleanrequired\n\nWhether the customer email address is verified. The address is automatically verified when the customer accesses the customer portal using their email address.\n\nExamples:\n\ntrue\n\n​\nname\nstring | nullrequired\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the customer.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ndeleted_at\nstring<date-time> | nullrequired\n\nTimestamp for when the customer was soft deleted.\n\n​\navatar_url\nstringrequired\nExamples:\n\n\"https://www.gravatar.com/avatar/xxx?d=404\"\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Customer\nUpdate a customer. **Scopes**: `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Customer - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/create",
    "html": "Customers\nCreate Customer\nCopy page\n\nCreate a customer.\n\nScopes: customers:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nemail\nstring<email>required\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nexternal_id\nstring | null\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nname\nstring | null\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | null\n\nShow child attributes\n\n​\ntax_id\nany[] | null\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4> | null\n\nThe ID of the organization owning the customer. Required unless you use an organization token.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nResponse\n201\napplication/json\n\nCustomer created.\n\nA customer in an organization.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nexternal_id\nstring | nullrequired\n\nThe ID of the customer in your system. This must be unique within the organization. Once set, it can't be updated.\n\nExamples:\n\n\"usr_1337\"\n\n​\nemail\nstringrequired\n\nThe email address of the customer. This must be unique within the organization.\n\nExamples:\n\n\"customer@example.com\"\n\n​\nemail_verified\nbooleanrequired\n\nWhether the customer email address is verified. The address is automatically verified when the customer accesses the customer portal using their email address.\n\nExamples:\n\ntrue\n\n​\nname\nstring | nullrequired\n\nThe name of the customer.\n\nExamples:\n\n\"John Doe\"\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ntax_id\nany[] | nullrequired\nRequired array length: 2 elements\nExamples:\n[\"911144442\", \"us_ein\"]\n[\"FR61954506077\", \"eu_vat\"]\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the customer.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ndeleted_at\nstring<date-time> | nullrequired\n\nTimestamp for when the customer was soft deleted.\n\n​\navatar_url\nstringrequired\nExamples:\n\n\"https://www.gravatar.com/avatar/xxx?d=404\"\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Customer\nGet a customer by ID. **Scopes**: `customers:read` `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Account Balance & Transparent Fees - Polar",
    "url": "https://polar.sh/docs/features/finance/balance",
    "html": "Finance & Payouts\nAccount Balance & Transparent Fees\nCopy page\n\nMonitor your Polar balance without hidden fees\n\nYou can see your available balance for payout at any time under your Finance page.\n​\nPolar Balance\nYour balance is all the earnings minus:\nAny VAT we’ve captured for remittance, i.e balance is excluding VAT\nOur revenue share (4% + 40¢)\nAll historic transactions are available in chronological order along with their associated fees that have been deducted.\nNote: Upon payout (withdrawal), Stripe incurs additional fees that will be deducted before the final payout of the balance.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nPayouts\nEasily withdraw money from your Polar account at any time\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete Customer - Polar",
    "url": "https://polar.sh/docs/api-reference/customers/delete",
    "html": "Customers\nDelete Customer\nCopy page\n\nDelete a customer.\n\nThis action cannot be undone and will immediately:\n\nCancel any active subscriptions for the customer\nRevoke all their benefits\nClear any external_id\n\nUse it only in the context of deleting a user within your own service. Otherwise, use more granular API endpoints to cancel a specific subscription or revoke certain benefits.\n\nNote: The customers information will nonetheless be retained for historic orders and subscriptions.\n\nScopes: customers:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomers\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe customer ID.\n\nResponse\n204\n\nCustomer deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Customer by External ID\nGet a customer by external ID. **Scopes**: `customers:read` `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Payouts - Polar",
    "url": "https://polar.sh/docs/features/finance/payouts",
    "html": "Finance & Payouts\nPayouts\nCopy page\n\nEasily withdraw money from your Polar account at any time\n\nYou can issue a withdrawal, i.e payout, at any time once there is at least $10 on your balance. We will then transfer the balance minus Stripe payout fees (see below) to your Stripe account & issue a payout on their side.\n​\nManual Withdrawal\nWe require this to be done manually since:\nUsers have requested control for easier accounting vs. frequent & small payouts\nGiving users control of Stripe payout fees\n​\nStripe Payout Fees\n$2 per month of active payout(s)\n0.25% + $0.25 per payout\nCross border fees (currency conversion): 0.25% (EU) - 1% in other countries.\nGiven the fixed costs, we want to default to manual payouts so you can control when you want to incur them and do it once vs. per each individual transaction in order to reduce the overall fees.\n​\nReverse invoices\nSince we’re the Merchant of Record, your customers get an invoice from Polar. Thus, for your accounting, you need to issue an invoice to Polar for the amount we paid out to you. To ease this process, we can automatically generate a reverse invoice for you, detailing the sells we made on your behalf, minus our fees.\nYou can generate them from the Payouts page under Finance in your Polar dashboard. Click on the ellipsis next to the payout you want to generate a reverse invoice for, and select Download invoice.\nA modal will open, allowing you to:\nSet your billing name and address.\nAdd information shown below your billing address.\nAdd notes shown at the bottom of the invoice.\nCustomize the invoice number. By default, we generate one like POLAR-0001, but you can change it to your own format and sequence.\nOnce the reverse invoice is generated, it cannot be changed. Make sure to double-check the information before generating it.\n​\nSample Reverse Invoice\n​\nFrequently Asked Questions\n\nHow long do payouts take?\n\nCan I use my personal bank account to receive payouts?\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nRaycast\nThe fastest way to access Polar from your keyboard\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Metrics Limits - Polar",
    "url": "https://polar.sh/docs/api-reference/metrics/get-limits",
    "html": "Metrics\nGet Metrics Limits\nCopy page\n\nGet the interval limits for the metrics endpoint.\n\nScopes: metrics:read\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nmetrics\n/\nlimits\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nResponse\n200 - application/json\n\nSuccessful Response\n\nDate limits to get metrics.\n\n​\nmin_date\nstring<date>required\n\nMinimum date to get metrics.\n\n​\nintervals\nobjectrequired\n\nLimits for each interval.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Customer\nGet authenticated customer. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Subscription - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/subscriptions/get",
    "html": "Subscriptions\nGet Subscription\nCopy page\n\nGet a subscription for the authenticated customer.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nsubscriptions\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe subscription ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\namount\nintegerrequired\n\nThe amount of the subscription.\n\nExamples:\n\n10000\n\n​\ncurrency\nstringrequired\n\nThe currency of the subscription.\n\nExamples:\n\n\"usd\"\n\n​\nrecurring_interval\nenum<string>required\n\nThe interval at which the subscription recurs.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\nintegerrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\n​\nstatus\nenum<string>required\n\nThe status of the subscription.\n\nAvailable options: incomplete, incomplete_expired, trialing, active, past_due, canceled, unpaid \n​\ncurrent_period_start\nstring<date-time>required\n\nThe start timestamp of the current billing period.\n\n​\ncurrent_period_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the current billing period.\n\n​\ntrial_start\nstring<date-time> | nullrequired\n\nThe start timestamp of the trial period, if any.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the trial period, if any.\n\n​\ncancel_at_period_end\nbooleanrequired\n\nWhether the subscription will be canceled at the end of the current period.\n\n​\ncanceled_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription was canceled. The subscription might still be active if cancel_at_period_end is true.\n\n​\nstarted_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription started.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription will end.\n\n​\nended_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription ended.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the subscribed customer.\n\n​\nproduct_id\nstring<uuid4>required\n\nThe ID of the subscribed product.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nThe ID of the applied discount, if any.\n\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\ncustomer_cancellation_reason\nenum<string> | nullrequired\nAvailable options: customer_service, low_quality, missing_features, switched_service, too_complex, too_expensive, unused, other \n​\ncustomer_cancellation_comment\nstring | nullrequired\n​\nproduct\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of enabled prices for the subscription.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nmeters\nCustomerSubscriptionMeter · object[]required\n\nList of meters associated with the subscription.\n\nShow child attributes\n\n​\nis_polar_managed\nbooleanrequired\n\nWhether the subscription is managed by Polar.\n\n​\nseats\ninteger | null\n\nNumber of seats included in the subscription (for seat-based pricing).\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Subscriptions\nList subscriptions of the authenticated customer. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/license-keys/get",
    "html": "License Keys\nGet License Key\nCopy page\n\nGet a license key.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nlicense-keys\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\ncustomer_id\nstring<uuid4>required\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nbenefit_id\nstring<uuid4>required\n\nThe benefit ID.\n\n​\nkey\nstringrequired\n​\ndisplay_key\nstringrequired\n​\nstatus\nenum<string>required\nAvailable options: granted, revoked, disabled \n​\nlimit_activations\ninteger | nullrequired\n​\nusage\nintegerrequired\n​\nlimit_usage\ninteger | nullrequired\n​\nvalidations\nintegerrequired\n​\nlast_validated_at\nstring<date-time> | nullrequired\n​\nexpires_at\nstring<date-time> | nullrequired\n​\nactivations\nLicenseKeyActivationBase · object[]required\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList License Keys\n**Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List License Keys - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/license-keys/list",
    "html": "License Keys\nList License Keys\nCopy page\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nlicense-keys\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nbenefit_id\nstring<uuid4> | null\n\nFilter by a specific benefit\nThe benefit ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nLicenseKeyRead · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Order Invoice - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/orders/get-invoice",
    "html": "Orders\nGet Order Invoice\nCopy page\n\nGet an order’s invoice data.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\norders\n/\n{id}\n/\ninvoice\nTry it\nThe invoice must be generated first before it can be retrieved. You should call the POST /v1/customer-portal/orders/{id}/invoice endpoint to generate the invoice.\nIf the invoice is not generated, you will receive a 404 error.\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nOrder's invoice data.\n\n​\nurl\nstringrequired\n\nThe URL to the invoice.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nValidate License Key\nValidate a license key. > This endpoint doesn't require authentication and can be safely used on a public > client, like a desktop application or a mobile app. > If you plan to validate a license key on a server, use the `/v1/license-keys/validate` > endpoint instead.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Refunds - Polar",
    "url": "https://polar.sh/docs/api-reference/refunds/list",
    "html": "Refunds\nList Refunds\nCopy page\n\nList products.\n\nScopes: refunds:read refunds:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nrefunds\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\nid\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by refund ID.\nThe refund ID.\n\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\norder_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by order ID.\nThe order ID.\n\n​\nsubscription_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by subscription ID.\nThe subscription ID.\n\n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\n​\nsucceeded\nboolean | null\n\nFilter by succeeded.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nRefund · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Product\nGet a product by ID. **Scopes**: `products:read` `products:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Strategy Introduction - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/ingestion-strategies/ingestion-strategy",
    "html": "Ingestion Strategies\nStrategy Introduction\nCopy page\n\nIngestion strategies for Usage Based Billing\n\nPolar offers an ingestion framework to work with Polar’s event ingestion API.\nWant to report events regarding Large Language Model usage, S3 file uploads or something else? Our Ingestion strategies are customized to make it as seamless as possible to fire ingestion events for complex needs.\nLLM Strategy\nS3 Strategy\nStream Strategy\nDelta Time Strategy\n​\nHelp us improve\nWe’re always looking for ways to improve our ingestion strategies. Feel free to contribute — Polar Ingestion SDK.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nLLM Strategy\nIngestion strategy for LLM Usage\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Strategy Introduction - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/ingestion-strategies/ingestion-strategy",
    "html": "Ingestion Strategies\nStrategy Introduction\nCopy page\n\nIngestion strategies for Usage Based Billing\n\nPolar offers an ingestion framework to work with Polar’s event ingestion API.\nWant to report events regarding Large Language Model usage, S3 file uploads or something else? Our Ingestion strategies are customized to make it as seamless as possible to fire ingestion events for complex needs.\nLLM Strategy\nS3 Strategy\nStream Strategy\nDelta Time Strategy\n​\nHelp us improve\nWe’re always looking for ways to improve our ingestion strategies. Feel free to contribute — Polar Ingestion SDK.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nLLM Strategy\nIngestion strategy for LLM Usage\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delta Time Strategy - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/ingestion-strategies/delta-time-strategy",
    "html": "Ingestion Strategies\nDelta Time Strategy\nCopy page\n\nIngest delta time of arbitrary execution\n\n​\nJavascript SDK\nIngest delta time of arbitrary execution. Bring your own now-resolver.\nCopy\nAsk AI\npnpm add @polar-sh/ingestion\n\nCopy\nAsk AI\nimport { Ingestion } from \"@polar-sh/ingestion\";\nimport { DeltaTimeStrategy } from \"@polar-sh/ingestion/strategies/DeltaTime\";\n\nconst nowResolver = () => performance.now();\n// const nowResolver = () => Number(hrtime.bigint())\n// const nowResolver = () => Date.now()\n\n// Setup the Delta Time Ingestion Strategy\nconst deltaTimeIngestion = Ingestion({\n  accessToken: process.env.POLAR_ACCESS_TOKEN,\n})\n  .strategy(new DeltaTimeStrategy(nowResolver))\n  .ingest(\"execution-time\");\n\nexport async function GET(request: Request) {\n  try {\n    // Get the wrapped start clock function\n    // Pass Customer Id to properly annotate the ingestion events with a specific customer\n    const start = deltaTimeIngestion.client({\n      customerId: request.headers.get(\"X-Polar-Customer-Id\") ?? \"\",\n    });\n\n    const stop = start();\n\n    await sleep(1000);\n\n    // { deltaTime: xxx } is automatically ingested to Polar\n    const delta = stop();\n\n    return Response.json({ delta });\n  } catch (error) {\n    return Response.json({ error: error.message });\n  }\n}\n\n​\nIngestion Payload\nCopy\nAsk AI\n{\n  \"customerId\": \"123\",\n  \"name\": \"execution-time\",\n  \"metadata\": {\n    \"deltaTime\": 1000\n  }\n}\n\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nMeters\nCreating and managing meters for Usage Based Billing\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Customer Meters - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-meters/list",
    "html": "Customer Meters\nList Customer Meters\nCopy page\n\nList customer meters.\n\nScopes: customer_meters:read\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-meters\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\n​\nexternal_customer_id\nstring | null\nstring[] | null\n\nFilter by external customer ID.\n\n​\nmeter_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by meter ID.\nThe meter ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nCustomerMeter · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet License Key\nGet a license key. **Scopes**: `license_keys:read` `license_keys:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Event - Polar",
    "url": "https://polar.sh/docs/api-reference/events/get",
    "html": "Events\nGet Event\nCopy page\n\nGet an event by ID.\n\nScopes: events:read events:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nevents\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe event ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nMeterCreditEvent\nMeterResetEvent\nBenefitGrantedEvent\nBenefitCycledEvent\nBenefitUpdatedEvent\nBenefitRevokedEvent\nSubscriptionCycledEvent\nSubscriptionRevokedEvent\nSubscriptionProductUpdatedEvent\nUserEvent\n\nAn event created by Polar when credits are added to a customer meter.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ntimestamp\nstring<date-time>required\n\nThe timestamp of the event.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the event.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ncustomer_id\nstring<uuid4> | nullrequired\n\nID of the customer in your Polar organization associated with the event.\n\n​\ncustomer\nobject | nullrequired\n\nThe customer associated with the event.\nA customer in an organization.\n\nShow child attributes\n\n​\nexternal_customer_id\nstring | nullrequired\n\nID of the customer in your system associated with the event.\n\n​\nsource\nstringrequired\n\nThe source of the event. system events are created by Polar. user events are the one you create through our ingestion API.\n\nAllowed value: \"system\"\n​\nname\nstringrequired\n\nThe name of the event.\n\nAllowed value: \"meter.credited\"\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Events\nList events. **Scopes**: `events:read` `events:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Events - Polar",
    "url": "https://polar.sh/docs/api-reference/events/list",
    "html": "Events\nList Events\nCopy page\n\nList events.\n\nScopes: events:read events:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nevents\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\nfilter\nstring | null\n\nFilter events following filter clauses. JSON string following the same schema a meter filter clause.\n\n​\nstart_timestamp\nstring<date-time> | null\n\nFilter events after this timestamp.\n\n​\nend_timestamp\nstring<date-time> | null\n\nFilter events before this timestamp.\n\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\n​\nexternal_customer_id\nstring | null\nstring[] | null\n\nFilter by external customer ID.\n\n​\nmeter_id\nstring<uuid4> | null\n\nFilter by a meter filter clause.\nThe meter ID.\n\n​\nname\nstring | null\nstring[] | null\n\nFilter by event name.\n\n​\nsource\nenum<string> | null\nenum<string>[] | null\n\nFilter by event source.\n\nAvailable options: system, user \n​\nquery\nstring | null\n\nQuery to filter events.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nItems · arrayrequired\nMeterCreditEvent\nMeterResetEvent\nBenefitGrantedEvent\nBenefitCycledEvent\nBenefitUpdatedEvent\nBenefitRevokedEvent\nSubscriptionCycledEvent\nSubscriptionRevokedEvent\nSubscriptionProductUpdatedEvent\nUserEvent\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Meter\nCreate a meter. **Scopes**: `meters:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Checkout Link - Polar",
    "url": "https://polar.sh/docs/api-reference/checkout-links/create",
    "html": "Checkout Links\nCreate Checkout Link\nCopy page\n\nCreate a checkout link.\n\nScopes: checkout_links:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckout-links\n/\nTry it\nLooking to create a single use checkout session? Checkout Links are probably not what you’re looking for.\nCheckout Links are shareable links that generate checkout sessions when opened. They are very handy to start a purchase from your website or social media.\nHowever, if you want to start a checkout for one of your user inside your product, you should use the Checkout Sessions API.\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\nCheckoutLinkCreateProductPrice\nCheckoutLinkCreateProduct\nCheckoutLinkCreateProducts\n\nSchema to create a new checkout link from a a single product price.\n\nDeprecated: Use CheckoutLinkCreateProducts instead.\n\n​\npayment_processor\nstringrequired\n\nPayment processor to use. Currently only Stripe is supported.\n\nAllowed value: \"stripe\"\n​\nproduct_price_id\nstring<uuid4>required\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ntrial_interval\nenum<string> | null\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | null\n\nThe number of interval units for the trial period.\n\nRequired range: 1 <= x <= 1000\n​\nlabel\nstring | null\n\nOptional label to distinguish links internally\n\n​\nallow_discount_codes\nbooleandefault:true\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleandefault:false\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting.\n\n​\ndiscount_id\nstring<uuid4> | null\n\nID of the discount to apply to the checkout. If the discount is not applicable anymore when opening the checkout link, it'll be ignored.\n\n​\nsuccess_url\nstring<uri> | null\n\nURL where the customer will be redirected after a successful payment.You can add the checkout_id={CHECKOUT_ID} query parameter to retrieve the checkout session id.\n\nRequired string length: 1 - 2083\nResponse\n201\napplication/json\n\nCheckout link created.\n\nCheckout link data.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nclient_secret\nstringrequired\n\nClient secret used to access the checkout link.\n\n​\nsuccess_url\nstring | nullrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nlabel\nstring | nullrequired\n\nOptional label to distinguish links internally\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount to apply to the checkout. If the discount is not applicable anymore when opening the checkout link, it'll be ignored.\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproducts\nCheckoutLinkProduct · object[]required\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nurl\nstringrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Checkout Link\nGet a checkout link by ID. **Scopes**: `checkout_links:read` `checkout_links:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create File - Polar",
    "url": "https://polar.sh/docs/api-reference/files/create",
    "html": "Files\nCreate File\nCopy page\n\nCreate a file.\n\nScopes: files:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nfiles\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\nDownloadableFileCreate\nProductMediaFileCreate\nOrganizationAvatarFileCreate\n\nSchema to create a file to be associated with the downloadables benefit.\n\n​\nname\nstringrequired\n​\nmime_type\nstringrequired\n​\nsize\nintegerrequired\n​\nupload\nobjectrequired\n\nShow child attributes\n\n​\nservice\nstringrequired\nAllowed value: \"downloadable\"\n​\norganization_id\nstring<uuid4> | null\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nchecksum_sha256_base64\nstring | null\n​\nversion\nstring | null\nResponse\n201\napplication/json\n\nFile created.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\nname\nstringrequired\n​\npath\nstringrequired\n​\nmime_type\nstringrequired\n​\nsize\nintegerrequired\n​\nstorage_version\nstring | nullrequired\n​\nchecksum_etag\nstring | nullrequired\n​\nchecksum_sha256_base64\nstring | nullrequired\n​\nchecksum_sha256_hex\nstring | nullrequired\n​\nlast_modified_at\nstring<date-time> | nullrequired\n​\nupload\nobjectrequired\n\nShow child attributes\n\n​\nversion\nstring | nullrequired\n​\nservice\nenum<string>required\nAvailable options: downloadable, product_media, organization_avatar \n​\nsize_readable\nstringrequired\n​\nis_uploaded\nbooleandefault:false\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Files\nList files. **Scopes**: `files:read` `files:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/license-keys/get",
    "html": "License Keys\nGet License Key\nCopy page\n\nGet a license key.\n\nScopes: license_keys:read license_keys:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nlicense-keys\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\ncustomer_id\nstring<uuid4>required\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nbenefit_id\nstring<uuid4>required\n\nThe benefit ID.\n\n​\nkey\nstringrequired\n​\ndisplay_key\nstringrequired\n​\nstatus\nenum<string>required\nAvailable options: granted, revoked, disabled \n​\nlimit_activations\ninteger | nullrequired\n​\nusage\nintegerrequired\n​\nlimit_usage\ninteger | nullrequired\n​\nvalidations\nintegerrequired\n​\nlast_validated_at\nstring<date-time> | nullrequired\n​\nexpires_at\nstring<date-time> | nullrequired\n​\nactivations\nLicenseKeyActivationBase · object[]required\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList License Keys\nGet license keys connected to the given organization & filters. **Scopes**: `license_keys:read` `license_keys:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List License Keys - Polar",
    "url": "https://polar.sh/docs/api-reference/license-keys/list",
    "html": "License Keys\nList License Keys\nCopy page\n\nGet license keys connected to the given organization & filters.\n\nScopes: license_keys:read license_keys:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nlicense-keys\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nbenefit_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by benefit ID.\nThe benefit ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nLicenseKeyRead · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate License Key\nUpdate a license key. **Scopes**: `license_keys:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/license-keys/update",
    "html": "License Keys\nUpdate License Key\nCopy page\n\nUpdate a license key.\n\nScopes: license_keys:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nlicense-keys\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\nBody\napplication/json\n​\nstatus\nenum<string> | null\nAvailable options: granted, revoked, disabled \n​\nusage\nintegerdefault:0\n​\nlimit_activations\ninteger | null\nRequired range: 0 < x <= 1000\n​\nlimit_usage\ninteger | null\nRequired range: x > 0\n​\nexpires_at\nstring<date-time> | null\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\ncustomer_id\nstring<uuid4>required\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nbenefit_id\nstring<uuid4>required\n\nThe benefit ID.\n\n​\nkey\nstringrequired\n​\ndisplay_key\nstringrequired\n​\nstatus\nenum<string>required\nAvailable options: granted, revoked, disabled \n​\nlimit_activations\ninteger | nullrequired\n​\nusage\nintegerrequired\n​\nlimit_usage\ninteger | nullrequired\n​\nvalidations\nintegerrequired\n​\nlast_validated_at\nstring<date-time> | nullrequired\n​\nexpires_at\nstring<date-time> | nullrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Activation\nGet a license key activation. **Scopes**: `license_keys:read` `license_keys:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Activation - Polar",
    "url": "https://polar.sh/docs/api-reference/license-keys/get-activation",
    "html": "License Keys\nGet Activation\nCopy page\n\nGet a license key activation.\n\nScopes: license_keys:read license_keys:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nlicense-keys\n/\n{id}\n/\nactivations\n/\n{activation_id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n​\nactivation_id\nstring<uuid4>required\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n​\nlicense_key_id\nstring<uuid4>required\n​\nlabel\nstringrequired\n​\nmeta\nobjectrequired\n\nShow child attributes\n\n​\ncreated_at\nstring<date-time>required\n​\nmodified_at\nstring<date-time> | nullrequired\n​\nlicense_key\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nValidate License Key\nValidate a license key. **Scopes**: `license_keys:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Activate License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/license-keys/activate",
    "html": "License Keys\nActivate License Key\nCopy page\n\nActivate a license key instance.\n\nScopes: license_keys:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nlicense-keys\n/\nactivate\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nkey\nstringrequired\n​\norganization_id\nstring<uuid4>required\n​\nlabel\nstringrequired\n​\nconditions\nobject\n\nKey-value object allowing you to set conditions that must match when validating the license key.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nmeta\nobject\n\nKey-value object allowing you to store additional information about the activation\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n​\nlicense_key_id\nstring<uuid4>required\n​\nlabel\nstringrequired\n​\nmeta\nobjectrequired\n\nShow child attributes\n\n​\ncreated_at\nstring<date-time>required\n​\nmodified_at\nstring<date-time> | nullrequired\n​\nlicense_key\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDeactivate License Key\nDeactivate a license key instance. **Scopes**: `license_keys:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Validate License Key - Polar",
    "url": "https://polar.sh/docs/api-reference/license-keys/validate",
    "html": "License Keys\nValidate License Key\nCopy page\n\nValidate a license key.\n\nScopes: license_keys:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nlicense-keys\n/\nvalidate\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nkey\nstringrequired\n​\norganization_id\nstring<uuid4>required\n​\nactivation_id\nstring<uuid4> | null\n​\nbenefit_id\nstring<uuid4> | null\n\nThe benefit ID.\n\n​\ncustomer_id\nstring<uuid4> | null\n​\nincrement_usage\ninteger | null\n​\nconditions\nobject\n\nKey-value object allowing you to set conditions that must match when validating the license key.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\ncustomer_id\nstring<uuid4>required\n​\ncustomer\nobjectrequired\n\nShow child attributes\n\n​\nbenefit_id\nstring<uuid4>required\n\nThe benefit ID.\n\n​\nkey\nstringrequired\n​\ndisplay_key\nstringrequired\n​\nstatus\nenum<string>required\nAvailable options: granted, revoked, disabled \n​\nlimit_activations\ninteger | nullrequired\n​\nusage\nintegerrequired\n​\nlimit_usage\ninteger | nullrequired\n​\nvalidations\nintegerrequired\n​\nlast_validated_at\nstring<date-time> | nullrequired\n​\nexpires_at\nstring<date-time> | nullrequired\n​\nactivation\nobject | null\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nActivate License Key\nActivate a license key instance. **Scopes**: `license_keys:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "order.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/order.updated",
    "html": "Orders\norder.updated\nCopy page\n\nSent when an order is updated.\n\nAn order is updated when:\n\nIts status changes, e.g. from pending to paid.\nIt's refunded, partially or fully.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"order.updated\"\nExamples:\n\n\"order.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\norder.refunded\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Discount - Polar",
    "url": "https://polar.sh/docs/api-reference/discounts/get",
    "html": "Discounts\nGet Discount\nCopy page\n\nGet a discount by ID.\n\nScopes: discounts:read discounts:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ndiscounts\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe discount ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nDiscountFixedOnceForeverDuration\nDiscountFixedRepeatDuration\nDiscountPercentageOnceForeverDuration\nDiscountPercentageRepeatDuration\n\nSchema for a fixed amount discount that is applied once or forever.\n\n​\nduration\nenum<string>required\nAvailable options: once, forever, repeating \n​\ntype\nenum<string>required\nAvailable options: fixed, percentage \n​\namount\nintegerrequired\nExamples:\n\n1000\n\n​\ncurrency\nstringrequired\nExamples:\n\n\"usd\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nname\nstringrequired\n\nName of the discount. Will be displayed to the customer when the discount is applied.\n\n​\ncode\nstring | nullrequired\n\nCode customers can use to apply the discount during checkout.\n\n​\nstarts_at\nstring<date-time> | nullrequired\n\nTimestamp after which the discount is redeemable.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nTimestamp after which the discount is no longer redeemable.\n\n​\nmax_redemptions\ninteger | nullrequired\n\nMaximum number of times the discount can be redeemed.\n\n​\nredemptions_count\nintegerrequired\n\nNumber of times the discount has been redeemed.\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproducts\nDiscountProduct · object[]required\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Discounts\nList discounts. **Scopes**: `discounts:read` `discounts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Polar for Raycast - Polar",
    "url": "https://polar.sh/docs/features/integrations/raycast",
    "html": "Integrations\nPolar for Raycast\nCopy page\n\nThe fastest way to access Polar from your keyboard\n\n​\nInstall Extension\nHead over to Polar on the Raycast Store, and install it from there.\n​\nView Orders\nEasily view orders across organizations.\n​\nView Subscriptions\nView all active subscriptions across your organizations.\n​\nView Customers\nKeep track of all your customers.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nFramer\nThe fastest way to sell digital products on your Framer site\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete Custom Field - Polar",
    "url": "https://polar.sh/docs/api-reference/custom-fields/delete",
    "html": "Custom Checkout Fields\nDelete Custom Field\nCopy page\n\nDelete a custom field.\n\nScopes: custom_fields:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustom-fields\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe custom field ID.\n\nResponse\n204\n\nCustom field deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Customer State\nGet a customer state by ID. The customer state includes information about the customer's active subscriptions and benefits. It's the ideal endpoint to use when you need to get a full overview of a customer's status. **Scopes**: `customers:read` `customers:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Metrics - Polar",
    "url": "https://polar.sh/docs/api-reference/metrics/get",
    "html": "Metrics\nGet Metrics\nCopy page\n\nGet metrics about your orders and subscriptions.\n\nCurrency values are output in cents.\n\nScopes: metrics:read\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nmetrics\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\nstart_date\nstring<date>required\n\nStart date.\n\n​\nend_date\nstring<date>required\n\nEnd date.\n\n​\ntimezone\nstringdefault:UTC\n\nTimezone to use for the timestamps. Default is UTC.\n\nMinimum length: 1\n​\ninterval\nenum<string>required\n\nInterval between two timestamps.\n\nAvailable options: year, month, week, day, hour \n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproduct_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\nbilling_type\nenum<string> | null\nenum<string>[] | null\n\nFilter by billing type. recurring will filter data corresponding to subscriptions creations or renewals. one_time will filter data corresponding to one-time purchases.\n\nAvailable options: one_time, recurring \n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nMetrics response schema.\n\n​\nperiods\nMetricPeriod · object[]required\n\nList of data for each timestamp.\n\nShow child attributes\n\n​\ntotals\nobjectrequired\n\nTotals for the whole selected period.\n\nShow child attributes\n\n​\nmetrics\nobjectrequired\n\nInformation about the returned metrics.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Metrics Limits\nGet the interval limits for the metrics endpoint. **Scopes**: `metrics:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Subscriptions - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/subscriptions/list",
    "html": "Subscriptions\nList Subscriptions\nCopy page\n\nList subscriptions of the authenticated customer.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nsubscriptions\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproduct_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\nactive\nboolean | null\n\nFilter by active or cancelled subscription.\n\n​\nquery\nstring | null\n\nSearch by product or organization name.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nCustomerSubscription · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Subscription\nUpdate a subscription of the authenticated customer. **Scopes**: `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Subscription - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/subscriptions/update",
    "html": "Subscriptions\nUpdate Subscription\nCopy page\n\nUpdate a subscription of the authenticated customer.\n\nScopes: customer_portal:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nsubscriptions\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe subscription ID.\n\nBody\napplication/json\nCustomerSubscriptionUpdateProduct\nCustomerSubscriptionCancel\n​\nproduct_id\nstring<uuid4>required\n\nUpdate subscription to another product.\n\nResponse\n200\napplication/json\n\nCustomer subscription updated.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\namount\nintegerrequired\n\nThe amount of the subscription.\n\nExamples:\n\n10000\n\n​\ncurrency\nstringrequired\n\nThe currency of the subscription.\n\nExamples:\n\n\"usd\"\n\n​\nrecurring_interval\nenum<string>required\n\nThe interval at which the subscription recurs.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\nintegerrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\n​\nstatus\nenum<string>required\n\nThe status of the subscription.\n\nAvailable options: incomplete, incomplete_expired, trialing, active, past_due, canceled, unpaid \n​\ncurrent_period_start\nstring<date-time>required\n\nThe start timestamp of the current billing period.\n\n​\ncurrent_period_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the current billing period.\n\n​\ntrial_start\nstring<date-time> | nullrequired\n\nThe start timestamp of the trial period, if any.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the trial period, if any.\n\n​\ncancel_at_period_end\nbooleanrequired\n\nWhether the subscription will be canceled at the end of the current period.\n\n​\ncanceled_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription was canceled. The subscription might still be active if cancel_at_period_end is true.\n\n​\nstarted_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription started.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription will end.\n\n​\nended_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription ended.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the subscribed customer.\n\n​\nproduct_id\nstring<uuid4>required\n\nThe ID of the subscribed product.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nThe ID of the applied discount, if any.\n\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\ncustomer_cancellation_reason\nenum<string> | nullrequired\nAvailable options: customer_service, low_quality, missing_features, switched_service, too_complex, too_expensive, unused, other \n​\ncustomer_cancellation_comment\nstring | nullrequired\n​\nproduct\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of enabled prices for the subscription.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nmeters\nCustomerSubscriptionMeter · object[]required\n\nList of meters associated with the subscription.\n\nShow child attributes\n\n​\nis_polar_managed\nbooleanrequired\n\nWhether the subscription is managed by Polar.\n\n​\nseats\ninteger | null\n\nNumber of seats included in the subscription (for seat-based pricing).\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCancel Subscription\nCancel a subscription of the authenticated customer. **Scopes**: `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Cancel Subscription - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/subscriptions/cancel",
    "html": "Subscriptions\nCancel Subscription\nCopy page\n\nCancel a subscription of the authenticated customer.\n\nScopes: customer_portal:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nsubscriptions\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe subscription ID.\n\nResponse\n200\napplication/json\n\nCustomer subscription is canceled.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\namount\nintegerrequired\n\nThe amount of the subscription.\n\nExamples:\n\n10000\n\n​\ncurrency\nstringrequired\n\nThe currency of the subscription.\n\nExamples:\n\n\"usd\"\n\n​\nrecurring_interval\nenum<string>required\n\nThe interval at which the subscription recurs.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\nintegerrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\n​\nstatus\nenum<string>required\n\nThe status of the subscription.\n\nAvailable options: incomplete, incomplete_expired, trialing, active, past_due, canceled, unpaid \n​\ncurrent_period_start\nstring<date-time>required\n\nThe start timestamp of the current billing period.\n\n​\ncurrent_period_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the current billing period.\n\n​\ntrial_start\nstring<date-time> | nullrequired\n\nThe start timestamp of the trial period, if any.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the trial period, if any.\n\n​\ncancel_at_period_end\nbooleanrequired\n\nWhether the subscription will be canceled at the end of the current period.\n\n​\ncanceled_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription was canceled. The subscription might still be active if cancel_at_period_end is true.\n\n​\nstarted_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription started.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription will end.\n\n​\nended_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription ended.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the subscribed customer.\n\n​\nproduct_id\nstring<uuid4>required\n\nThe ID of the subscribed product.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nThe ID of the applied discount, if any.\n\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\ncustomer_cancellation_reason\nenum<string> | nullrequired\nAvailable options: customer_service, low_quality, missing_features, switched_service, too_complex, too_expensive, unused, other \n​\ncustomer_cancellation_comment\nstring | nullrequired\n​\nproduct\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of enabled prices for the subscription.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nmeters\nCustomerSubscriptionMeter · object[]required\n\nList of meters associated with the subscription.\n\nShow child attributes\n\n​\nis_polar_managed\nbooleanrequired\n\nWhether the subscription is managed by Polar.\n\n​\nseats\ninteger | null\n\nNumber of seats included in the subscription (for seat-based pricing).\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Order\nGet an order by ID for the authenticated customer. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/downloadables/get",
    "html": "File Downloads\nGet\nCopy page\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Downloadables\n**Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Order - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/orders/get",
    "html": "Orders\nGet Order\nCopy page\n\nGet an order by ID for the authenticated customer.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\norders\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nstatus\nenum<string>required\nAvailable options: pending, paid, refunded, partially_refunded \n​\npaid\nbooleanrequired\n\nWhether the order has been paid for.\n\nExamples:\n\ntrue\n\n​\nsubtotal_amount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\nExamples:\n\n10000\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\nExamples:\n\n1000\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\nExamples:\n\n9000\n\n​\ntax_amount\nintegerrequired\n\nSales tax amount in cents.\n\nExamples:\n\n720\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\nExamples:\n\n9720\n\n​\napplied_balance_amount\nintegerrequired\n\nCustomer's balance amount applied to this invoice. Can increase the total amount paid, if the customer has a negative balance, or decrease it, if the customer has a positive balance.Amount in cents.\n\nExamples:\n\n0\n\n​\ndue_amount\nintegerrequired\n\nAmount in cents that is due for this order.\n\nExamples:\n\n0\n\n​\nrefunded_amount\nintegerrequired\n\nAmount refunded in cents.\n\nExamples:\n\n0\n\n​\nrefunded_tax_amount\nintegerrequired\n\nSales tax refunded in cents.\n\nExamples:\n\n0\n\n​\ncurrency\nstringrequired\nExamples:\n\n\"usd\"\n\n​\nbilling_reason\nenum<string>required\nAvailable options: purchase, subscription_create, subscription_cycle, subscription_update \n​\nbilling_name\nstring | nullrequired\n\nThe name of the customer that should appear on the invoice.\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ninvoice_number\nstringrequired\n\nThe invoice number associated with this order.\n\n​\nis_invoice_generated\nbooleanrequired\n\nWhether an invoice has been generated for this order.\n\n​\ncustomer_id\nstring<uuid4>required\n​\nproduct_id\nstring<uuid4> | nullrequired\n​\ndiscount_id\nstring<uuid4> | nullrequired\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\nuser_id\nstring<uuid4>requireddeprecated\n​\nproduct\nobject | nullrequired\n\nShow child attributes\n\n​\nsubscription\nobject | nullrequired\n\nShow child attributes\n\n​\nitems\nOrderItemSchema · object[]required\n\nLine items composing the order.\n\nShow child attributes\n\n​\ndescription\nstringrequired\n\nA summary description of the order.\n\nExamples:\n\n\"Pro Plan\"\n\n​\nseats\ninteger | null\n\nNumber of seats purchased (for seat-based one-time orders).\n\n​\nnext_payment_attempt_at\nstring<date-time> | null\n\nWhen the next payment retry is scheduled\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Order\nUpdate an order for the authenticated customer. **Scopes**: `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Order - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/orders/patch",
    "html": "Orders\nUpdate Order\nCopy page\n\nUpdate an order for the authenticated customer.\n\nScopes: customer_portal:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\norders\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nBody\napplication/json\n\nSchema to update an order.\n\n​\nbilling_name\nstring | nullrequired\n\nThe name of the customer that should appear on the invoice. Can't be updated after the invoice is generated.\n\n​\nbilling_address\nobject | nullrequired\n\nThe address of the customer that should appear on the invoice. Can't be updated after the invoice is generated.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nstatus\nenum<string>required\nAvailable options: pending, paid, refunded, partially_refunded \n​\npaid\nbooleanrequired\n\nWhether the order has been paid for.\n\nExamples:\n\ntrue\n\n​\nsubtotal_amount\nintegerrequired\n\nAmount in cents, before discounts and taxes.\n\nExamples:\n\n10000\n\n​\ndiscount_amount\nintegerrequired\n\nDiscount amount in cents.\n\nExamples:\n\n1000\n\n​\nnet_amount\nintegerrequired\n\nAmount in cents, after discounts but before taxes.\n\nExamples:\n\n9000\n\n​\ntax_amount\nintegerrequired\n\nSales tax amount in cents.\n\nExamples:\n\n720\n\n​\ntotal_amount\nintegerrequired\n\nAmount in cents, after discounts and taxes.\n\nExamples:\n\n9720\n\n​\napplied_balance_amount\nintegerrequired\n\nCustomer's balance amount applied to this invoice. Can increase the total amount paid, if the customer has a negative balance, or decrease it, if the customer has a positive balance.Amount in cents.\n\nExamples:\n\n0\n\n​\ndue_amount\nintegerrequired\n\nAmount in cents that is due for this order.\n\nExamples:\n\n0\n\n​\nrefunded_amount\nintegerrequired\n\nAmount refunded in cents.\n\nExamples:\n\n0\n\n​\nrefunded_tax_amount\nintegerrequired\n\nSales tax refunded in cents.\n\nExamples:\n\n0\n\n​\ncurrency\nstringrequired\nExamples:\n\n\"usd\"\n\n​\nbilling_reason\nenum<string>required\nAvailable options: purchase, subscription_create, subscription_cycle, subscription_update \n​\nbilling_name\nstring | nullrequired\n\nThe name of the customer that should appear on the invoice.\n\n​\nbilling_address\nobject | nullrequired\n\nShow child attributes\n\n​\ninvoice_number\nstringrequired\n\nThe invoice number associated with this order.\n\n​\nis_invoice_generated\nbooleanrequired\n\nWhether an invoice has been generated for this order.\n\n​\ncustomer_id\nstring<uuid4>required\n​\nproduct_id\nstring<uuid4> | nullrequired\n​\ndiscount_id\nstring<uuid4> | nullrequired\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\nuser_id\nstring<uuid4>requireddeprecated\n​\nproduct\nobject | nullrequired\n\nShow child attributes\n\n​\nsubscription\nobject | nullrequired\n\nShow child attributes\n\n​\nitems\nOrderItemSchema · object[]required\n\nLine items composing the order.\n\nShow child attributes\n\n​\ndescription\nstringrequired\n\nA summary description of the order.\n\nExamples:\n\n\"Pro Plan\"\n\n​\nseats\ninteger | null\n\nNumber of seats purchased (for seat-based one-time orders).\n\n​\nnext_payment_attempt_at\nstring<date-time> | null\n\nWhen the next payment retry is scheduled\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Orders\nList orders of the authenticated customer. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Orders - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/orders/list",
    "html": "Orders\nList Orders\nCopy page\n\nList orders of the authenticated customer.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\norders\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproduct_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\nproduct_billing_type\nenum<string> | null\nenum<string>[] | null\n\nFilter by product billing type. recurring will filter data corresponding to subscriptions creations or renewals. one_time will filter data corresponding to one-time purchases.\n\nAvailable options: one_time, recurring \n​\nsubscription_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by subscription ID.\nThe subscription ID.\n\n​\nquery\nstring | null\n\nSearch by product or organization name.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nCustomerOrder · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGenerate Order Invoice\nTrigger generation of an order's invoice. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Generate Order Invoice - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/orders/post-invoice",
    "html": "Orders\nGenerate Order Invoice\nCopy page\n\nTrigger generation of an order’s invoice.\n\nScopes: customer_portal:read customer_portal:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\norders\n/\n{id}\n/\ninvoice\nTry it\nOnce the invoice is generated, it’s permanent and cannot be modified.\nMake sure the billing details (name and address) are correct before generating the invoice. You can update them before generating the invoice by calling the PATCH /v1/customer-portal/orders/{id} endpoint.\nAfter successfully calling this endpoint, you get a 202 response, meaning the generation of the invoice has been scheduled. It usually only takes a few seconds before you can retrieve the invoice using the GET /v1/customer-portal/orders/{id}/invoice endpoint.\nIf you want a reliable notification when the invoice is ready, you can listen to the order.updated webhook and check the is_invoice_generated field.\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe order ID.\n\nResponse\n202\napplication/json\n\nSuccessful Response\n\nThe response is of type any.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Order Invoice\nGet an order's invoice data. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Refund - Polar",
    "url": "https://polar.sh/docs/api-reference/refunds/create",
    "html": "Refunds\nCreate Refund\nCopy page\n\nCreate a refund.\n\nScopes: refunds:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nrefunds\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\norder_id\nstring<uuid4>required\n​\nreason\nenum<string>required\nAvailable options: duplicate, fraudulent, customer_request, service_disruption, satisfaction_guarantee, other \n​\namount\nintegerrequired\n\nAmount to refund in cents. Minimum is 1.\n\nRequired range: x > 0\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ncomment\nstring | null\n\nAn internal comment about the refund.\n\n​\nrevoke_benefits\nbooleandefault:false\n\nShould this refund trigger the associated customer benefits to be revoked?\n\nNote:\nOnly allowed in case the order is a one-time purchase.\nSubscriptions automatically revoke customer benefits once the\nsubscription itself is revoked, i.e fully canceled.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nstatus\nenum<string>required\nAvailable options: pending, succeeded, failed, canceled \n​\nreason\nenum<string>required\nAvailable options: duplicate, fraudulent, customer_request, service_disruption, satisfaction_guarantee, other \n​\namount\nintegerrequired\n​\ntax_amount\nintegerrequired\n​\ncurrency\nstringrequired\n​\norganization_id\nstring<uuid4>required\n​\norder_id\nstring<uuid4>required\n​\nsubscription_id\nstring<uuid4> | nullrequired\n​\ncustomer_id\nstring<uuid4>required\n​\nrevoke_benefits\nbooleanrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Refunds\nList products. **Scopes**: `refunds:read` `refunds:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "LLM Strategy - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/ingestion-strategies/llm-strategy",
    "html": "Ingestion Strategies\nLLM Strategy\nCopy page\n\nIngestion strategy for LLM Usage\n\n​\nJavascript SDK\n​\nLLM Strategy\nWrap any LLM model from the @ai-sdk/* library, to automatically fire prompt- & completion tokens used by every model call.\nCopy\nAsk AI\npnpm add @polar-sh/ingestion ai @ai-sdk/openai\n\nCopy\nAsk AI\nimport { Ingestion } from \"@polar-sh/ingestion\";\nimport { LLMStrategy } from \"@polar-sh/ingestion/strategies/LLM\";\nimport { generateText } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\n\n// Setup the LLM Ingestion Strategy\nconst llmIngestion = Ingestion({ accessToken: process.env.POLAR_ACCESS_TOKEN })\n  .strategy(new LLMStrategy(openai(\"gpt-4o\")))\n  .ingest(\"openai-usage\");\n\nexport async function POST(req: Request) {\n  const { prompt }: { prompt: string } = await req.json();\n\n  // Get the wrapped LLM model with ingestion capabilities\n  // Pass Customer Id to properly annotate the ingestion events with a specific customer\n  const model = llmIngestion.client({\n    customerId: request.headers.get(\"X-Polar-Customer-Id\") ?? \"\",\n  });\n\n  const { text } = await generateText({\n    model,\n    system: \"You are a helpful assistant.\",\n    prompt,\n  });\n\n  return Response.json({ text });\n}\n\n​\nIngestion Payload\nCopy\nAsk AI\n{\n  \"customerId\": \"123\",\n  \"name\": \"openai-usage\",\n  \"metadata\": {\n    \"promptTokens\": 100,\n    \"completionTokens\": 200\n  }\n}\n\n​\nPython SDK\nOur Python SDK includes an ingestion helper and strategies for common use cases. It’s installed as part of the Polar SDK.\npip\nuv\nCopy\nAsk AI\npip install polar-sdk\n\n​\nIngestion helper\nThe ingestion helper is a simple wrapper around the Polar events ingestion API. It takes care of batching and sending events to Polar in the background, without blocking your main thread.\nCopy\nAsk AI\nimport os\nfrom polar_sdk.ingestion import Ingestion\n\ningestion = Ingestion(os.getenv(\"POLAR_ACCESS_TOKEN\"))\n\ningestion.ingest({\n    \"name\": \"my-event\",\n    \"external_customer_id\": \"CUSTOMER_ID\",\n    \"metadata\": {\n        \"usage\": 13.37,\n    }\n})\n\n​\nPydanticAI Strategy\nPydanticAI is an AI agent framework for Python. A common use-case with AI applications is to track the usage of LLMs, like the number of input and output tokens, and bill the customer accordingly.\nWith our PydanticAI strategy, you can easily track the usage of LLMs and send the data to Polar for billing.\nCopy\nAsk AI\nimport os\nfrom polar_sdk.ingestion import Ingestion\nfrom polar_sdk.ingestion.strategies import PydanticAIStrategy\nfrom pydantic import BaseModel\nfrom pydantic_ai import Agent\n\n\ningestion = Ingestion(os.getenv(\"POLAR_ACCESS_TOKEN\"))\nstrategy = ingestion.strategy(PydanticAIStrategy, \"ai_usage\")\n\n\nclass MyModel(BaseModel):\n    city: str\n    country: str\n\n\nagent = Agent(\"gpt-4.1-nano\", output_type=MyModel)\n\nif __name__ == '__main__':\n    result = agent.run_sync(\"The windy city in the US of A.\")\n    print(result.output)\n    strategy.ingest(\"CUSTOMER_ID\", result)\n\nThis example is inspired from the Pydantic Model example of PydanticAI documentation.\n​\nIngestion Payload\nCopy\nAsk AI\n{\n  \"name\": \"ai_usage\",\n  \"external_customer_id\": \"CUSTOMER_ID\",\n  \"metadata\": {\n    \"requests\": 1,\n    \"total_tokens\": 78,\n    \"request_tokens\": 58,\n    \"response_tokens\": 20\n  }\n}\n\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nS3 Strategy\nIngestion strategy for S3 Operations\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "S3 Strategy - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/ingestion-strategies/s3-strategy",
    "html": "Ingestion Strategies\nS3 Strategy\nCopy page\n\nIngestion strategy for S3 Operations\n\n​\nJavascript SDK\nWrap the official AWS S3 Client with our S3 Ingestion Strategy to automatically ingest bytes uploaded.\nCopy\nAsk AI\npnpm add @polar-sh/ingestion @aws-sdk/client-s3\n\nCopy\nAsk AI\nimport { Ingestion } from \"@polar-sh/ingestion\";\nimport { S3Strategy } from \"@polar-sh/ingestion/strategies/S3\";\nimport { PutObjectCommand, S3Client } from \"@aws-sdk/client-s3\";\n\nconst s3Client = new S3Client({\n  region: process.env.AWS_REGION,\n  endpoint: process.env.AWS_ENDPOINT_URL,\n  credentials: {\n    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,\n    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,\n  },\n});\n\n// Setup the S3 Ingestion Strategy\nconst s3Ingestion = Ingestion({ accessToken: process.env.POLAR_ACCESS_TOKEN })\n  .strategy(new S3Strategy(s3Client))\n  .ingest(\"s3-uploads\");\n\nexport async function POST(request: Request) {\n  try {\n    // Get the wrapped S3 Client\n    // Pass Customer Id to properly annotate the ingestion events with a specific customer\n    const s3 = s3Ingestion.client({\n      customerId: request.headers.get(\"X-Polar-Customer-Id\") ?? \"\",\n    });\n\n    await s3.send(\n      new PutObjectCommand({\n        Bucket: process.env.AWS_BUCKET_NAME,\n        Key: \"a-random-key\",\n        Body: JSON.stringify({\n          name: \"John Doe\",\n          age: 30,\n        }),\n        ContentType: \"application/json\",\n      })\n    );\n\n    return Response.json({});\n  } catch (error) {\n    return Response.json({ error: error.message });\n  }\n}\n\n​\nIngestion Payload\nCopy\nAsk AI\n{\n  \"customerId\": \"123\",\n  \"name\": \"s3-uploads\",\n  \"metadata\": {\n    \"bytes\": 100,\n    \"bucket\": \"my-bucket\",\n    \"key\": \"my-key\",\n    \"contentType\": \"application/text\"\n  }\n}\n\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nStream Strategy\nIngestion strategy for Readable & Writable Streams\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Stream Strategy - Polar",
    "url": "https://polar.sh/docs/features/usage-based-billing/ingestion-strategies/stream-strategy",
    "html": "Ingestion Strategies\nStream Strategy\nCopy page\n\nIngestion strategy for Readable & Writable Streams\n\n​\nJavascript SDK\nWrap any Readable or Writable stream of choice to automatically ingest the bytes consumed.\nCopy\nAsk AI\npnpm add @polar-sh/ingestion\n\nCopy\nAsk AI\nimport { Ingestion } from '@polar-sh/ingestion';\nimport { StreamStrategy } from '@polar-sh/ingestion/strategies/Stream';\n\nconst myReadstream = createReadStream(...);\n\n// Setup the Stream Ingestion Strategy\nconst streamIngestion = Ingestion({ accessToken: process.env.POLAR_ACCESS_TOKEN })\n  .strategy(new StreamStrategy(myReadstream))\n  .ingest(\"my-stream\");\n\nexport async function GET(request: Request) {\n  try {\n\n    // Get the wrapped stream\n    // Pass Customer Id to properly annotate the ingestion events with a specific customer\n    const stream = streamIngestion.client({\n      customerId: request.headers.get(\"X-Polar-Customer-Id\") ?? \"\"\n    });\n\n    // Consume stream...\n    stream.on('data', () => ...)\n\n    return Response.json({});\n  } catch (error) {\n    return Response.json({ error: error.message });\n  }\n}\n\n​\nIngestion Payload\nCopy\nAsk AI\n{\n  \"customerId\": \"123\",\n  \"name\": \"my-stream\",\n  \"metadata\": {\n    \"bytes\": 100\n  }\n}\n\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelta Time Strategy\nIngest delta time of arbitrary execution\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Customer Meter - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-meters/get",
    "html": "Customer Meters\nGet Customer Meter\nCopy page\n\nGet a customer meter by ID.\n\nScopes: customer_meters:read\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-meters\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe customer meter ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nAn active customer meter, with current consumed and credited units.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the customer.\n\nExamples:\n\n\"992fae2a-2a17-4b7a-8d9e-e287cf90131b\"\n\n​\nmeter_id\nstring<uuid4>required\n\nThe ID of the meter.\n\nExamples:\n\n\"d498a884-e2cd-4d3e-8002-f536468a8b22\"\n\n​\nconsumed_units\nnumberrequired\n\nThe number of consumed units.\n\nExamples:\n\n25\n\n​\ncredited_units\nintegerrequired\n\nThe number of credited units.\n\nExamples:\n\n100\n\n​\nbalance\nnumberrequired\n\nThe balance of the meter, i.e. the difference between credited and consumed units.\n\nExamples:\n\n75\n\n​\ncustomer\nobjectrequired\n\nThe customer associated with this meter.\n\nShow child attributes\n\n​\nmeter\nobjectrequired\n\nThe meter associated with this customer.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Customer Meters\nList customer meters. **Scopes**: `customer_meters:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Meter - Polar",
    "url": "https://polar.sh/docs/api-reference/meters/create",
    "html": "Meters\nCreate Meter\nCopy page\n\nCreate a meter.\n\nScopes: meters:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nmeters\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nname\nstringrequired\n\nThe name of the meter. Will be shown on customer's invoices and usage.\n\nMinimum length: 3\n​\nfilter\nobjectrequired\n\nThe filter to apply on events that'll be used to calculate the meter.\n\nShow child attributes\n\n​\naggregation\nobjectrequired\n\nThe aggregation to apply on the filtered events to calculate the meter.\n\nCountAggregation\nPropertyAggregation\nUniqueAggregation\n\nShow child attributes\n\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\norganization_id\nstring<uuid4> | null\n\nThe ID of the organization owning the meter. Required unless you use an organization token.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nResponse\n201\napplication/json\n\nMeter created.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nname\nstringrequired\n\nThe name of the meter. Will be shown on customer's invoices and usage.\n\n​\nfilter\nobjectrequired\n\nThe filter to apply on events that'll be used to calculate the meter.\n\nShow child attributes\n\n​\naggregation\nobjectrequired\n\nThe aggregation to apply on the filtered events to calculate the meter.\n\nCountAggregation\nPropertyAggregation\nUniqueAggregation\n\nShow child attributes\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the meter.\n\n​\narchived_at\nstring<date-time> | null\n\nWhether the meter is archived and the time it was archived.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Meter\nGet a meter by ID. **Scopes**: `meters:read` `meters:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Checkout Link - Polar",
    "url": "https://polar.sh/docs/api-reference/checkout-links/get",
    "html": "Checkout Links\nGet Checkout Link\nCopy page\n\nGet a checkout link by ID.\n\nScopes: checkout_links:read checkout_links:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckout-links\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe checkout link ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nCheckout link data.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nclient_secret\nstringrequired\n\nClient secret used to access the checkout link.\n\n​\nsuccess_url\nstring | nullrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nlabel\nstring | nullrequired\n\nOptional label to distinguish links internally\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount to apply to the checkout. If the discount is not applicable anymore when opening the checkout link, it'll be ignored.\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproducts\nCheckoutLinkProduct · object[]required\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nurl\nstringrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Checkout Links\nList checkout links. **Scopes**: `checkout_links:read` `checkout_links:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Checkout Links - Polar",
    "url": "https://polar.sh/docs/api-reference/checkout-links/list",
    "html": "Checkout Links\nList Checkout Links\nCopy page\n\nList checkout links.\n\nScopes: checkout_links:read checkout_links:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckout-links\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproduct_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by product ID.\nThe product ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nCheckoutLink · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Checkout Link\nUpdate a checkout link. **Scopes**: `checkout_links:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete Checkout Link - Polar",
    "url": "https://polar.sh/docs/api-reference/checkout-links/delete",
    "html": "Checkout Links\nDelete Checkout Link\nCopy page\n\nDelete a checkout link.\n\nScopes: checkout_links:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckout-links\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe checkout link ID.\n\nResponse\n204\n\nCheckout link deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Custom Field\nCreate a custom field. **Scopes**: `custom_fields:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Checkout Link - Polar",
    "url": "https://polar.sh/docs/api-reference/checkout-links/update",
    "html": "Checkout Links\nUpdate Checkout Link\nCopy page\n\nUpdate a checkout link.\n\nScopes: checkout_links:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncheckout-links\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe checkout link ID.\n\nBody\napplication/json\n\nSchema to update an existing checkout link.\n\n​\ntrial_interval\nenum<string> | null\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | null\n\nThe number of interval units for the trial period.\n\nRequired range: 1 <= x <= 1000\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nproducts\nstring<uuid4>[] | null\n\nList of products that will be available to select at checkout.\n\nMinimum length: 1\n​\nlabel\nstring | null\n​\nallow_discount_codes\nboolean | null\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nboolean | null\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting.\n\n​\ndiscount_id\nstring<uuid4> | null\n\nID of the discount to apply to the checkout. If the discount is not applicable anymore when opening the checkout link, it'll be ignored.\n\n​\nsuccess_url\nstring<uri> | null\n\nURL where the customer will be redirected after a successful payment.You can add the checkout_id={CHECKOUT_ID} query parameter to retrieve the checkout session id.\n\nRequired string length: 1 - 2083\nResponse\n200\napplication/json\n\nCheckout link updated.\n\nCheckout link data.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntrial_interval\nenum<string> | nullrequired\n\nThe interval unit for the trial period.\n\nAvailable options: day, week, month, year \n​\ntrial_interval_count\ninteger | nullrequired\n\nThe number of interval units for the trial period.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\npayment_processor\nenum<string>required\n\nPayment processor used.\n\nAvailable options: stripe \n​\nclient_secret\nstringrequired\n\nClient secret used to access the checkout link.\n\n​\nsuccess_url\nstring | nullrequired\n\nURL where the customer will be redirected after a successful payment.\n\n​\nlabel\nstring | nullrequired\n\nOptional label to distinguish links internally\n\n​\nallow_discount_codes\nbooleanrequired\n\nWhether to allow the customer to apply discount codes. If you apply a discount through discount_id, it'll still be applied, but the customer won't be able to change it.\n\n​\nrequire_billing_address\nbooleanrequired\n\nWhether to require the customer to fill their full billing address, instead of just the country. Customers in the US will always be required to fill their full address, regardless of this setting.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nID of the discount to apply to the checkout. If the discount is not applicable anymore when opening the checkout link, it'll be ignored.\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproducts\nCheckoutLinkProduct · object[]required\n\nShow child attributes\n\n​\ndiscount\nobject | nullrequired\nDiscountFixedOnceForeverDurationBase\nDiscountFixedRepeatDurationBase\nDiscountPercentageOnceForeverDurationBase\nDiscountPercentageRepeatDurationBase\n\nShow child attributes\n\n​\nurl\nstringrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete Checkout Link\nDelete a checkout link. **Scopes**: `checkout_links:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Files - Polar",
    "url": "https://polar.sh/docs/api-reference/files/list",
    "html": "Files\nList Files\nCopy page\n\nList files.\n\nScopes: files:read files:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nfiles\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nids\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by file ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nItems · arrayrequired\nDownloadableFileRead\nProductMediaFileRead\nOrganizationAvatarFileRead\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate File\nUpdate a file. **Scopes**: `files:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update File - Polar",
    "url": "https://polar.sh/docs/api-reference/files/update",
    "html": "Files\nUpdate File\nCopy page\n\nUpdate a file.\n\nScopes: files:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nfiles\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe file ID.\n\nBody\napplication/json\n​\nname\nstring | null\n​\nversion\nstring | null\nResponse\n200\napplication/json\n\nFile updated.\n\nDownloadableFileRead\nProductMediaFileRead\nOrganizationAvatarFileRead\n\nFile to be associated with the downloadables benefit.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\nname\nstringrequired\n​\npath\nstringrequired\n​\nmime_type\nstringrequired\n​\nsize\nintegerrequired\n​\nstorage_version\nstring | nullrequired\n​\nchecksum_etag\nstring | nullrequired\n​\nchecksum_sha256_base64\nstring | nullrequired\n​\nchecksum_sha256_hex\nstring | nullrequired\n​\nlast_modified_at\nstring<date-time> | nullrequired\n​\nversion\nstring | nullrequired\n​\nservice\nstringrequired\nAllowed value: \"downloadable\"\n​\nis_uploaded\nbooleanrequired\n​\ncreated_at\nstring<date-time>required\n​\nsize_readable\nstringrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete File\nDelete a file. **Scopes**: `files:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete File - Polar",
    "url": "https://polar.sh/docs/api-reference/files/delete",
    "html": "Files\nDelete File\nCopy page\n\nDelete a file.\n\nScopes: files:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nfiles\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\nResponse\n204\n\nFile deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nComplete File Upload\nComplete a file upload. **Scopes**: `files:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Complete File Upload - Polar",
    "url": "https://polar.sh/docs/api-reference/files/complete-upload",
    "html": "Files\nComplete File Upload\nCopy page\n\nComplete a file upload.\n\nScopes: files:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nfiles\n/\n{id}\n/\nuploaded\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe file ID.\n\nBody\napplication/json\n​\nid\nstringrequired\n​\npath\nstringrequired\n​\nparts\nS3FileUploadCompletedPart · object[]required\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nFile upload completed.\n\nDownloadableFileRead\nProductMediaFileRead\nOrganizationAvatarFileRead\n\nFile to be associated with the downloadables benefit.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\norganization_id\nstring<uuid4>required\n​\nname\nstringrequired\n​\npath\nstringrequired\n​\nmime_type\nstringrequired\n​\nsize\nintegerrequired\n​\nstorage_version\nstring | nullrequired\n​\nchecksum_etag\nstring | nullrequired\n​\nchecksum_sha256_base64\nstring | nullrequired\n​\nchecksum_sha256_hex\nstring | nullrequired\n​\nlast_modified_at\nstring<date-time> | nullrequired\n​\nversion\nstring | nullrequired\n​\nservice\nstringrequired\nAllowed value: \"downloadable\"\n​\nis_uploaded\nbooleanrequired\n​\ncreated_at\nstring<date-time>required\n​\nsize_readable\nstringrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Organization\nGet an organization by ID. **Scopes**: `organizations:read` `organizations:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "order.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/order.created",
    "html": "Orders\norder.created\nCopy page\n\nSent when a new order is created.\n\nA new order is created when:\n\nA customer purchases a one-time product. In this case, billing_reason is set to purchase.\nA customer starts a subscription. In this case, billing_reason is set to subscription_create.\nA subscription is renewed. In this case, billing_reason is set to subscription_cycle.\nA subscription is upgraded or downgraded with an immediate proration invoice. In this case, billing_reason is set to subscription_update.\n\n<Warning>The order might not be paid yet, so the status field might be pending.</Warning>\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"order.created\"\nExamples:\n\n\"order.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\norder.paid\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "order.paid - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/order.paid",
    "html": "Orders\norder.paid\nCopy page\n\nSent when an order is paid.\n\nWhen you receive this event, the order is fully processed and payment has been received.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"order.paid\"\nExamples:\n\n\"order.paid\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\norder.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "order.refunded - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/order.refunded",
    "html": "Orders\norder.refunded\nCopy page\n\nSent when an order is fully or partially refunded.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"order.refunded\"\nExamples:\n\n\"order.refunded\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncustomer_seat.assigned\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Discounts - Polar",
    "url": "https://polar.sh/docs/api-reference/discounts/list",
    "html": "Discounts\nList Discounts\nCopy page\n\nList discounts.\n\nScopes: discounts:read discounts:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ndiscounts\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nquery\nstring | null\n\nFilter by name.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nItems · arrayrequired\nDiscountFixedOnceForeverDuration\nDiscountFixedRepeatDuration\nDiscountPercentageOnceForeverDuration\nDiscountPercentageRepeatDuration\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Discount\nCreate a discount. **Scopes**: `discounts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Discount - Polar",
    "url": "https://polar.sh/docs/api-reference/discounts/create",
    "html": "Discounts\nCreate Discount\nCopy page\n\nCreate a discount.\n\nScopes: discounts:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ndiscounts\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\nDiscountFixedOnceForeverDurationCreate\nDiscountFixedRepeatDurationCreate\nDiscountPercentageOnceForeverDurationCreate\nDiscountPercentageRepeatDurationCreate\n\nSchema to create a fixed amount discount that is applied once or forever.\n\n​\nduration\nenum<string>required\nAvailable options: once, forever, repeating \n​\ntype\nenum<string>required\n\nType of the discount.\n\nAvailable options: fixed, percentage \n​\namount\nintegerrequired\n\nFixed amount to discount from the invoice total.\n\nRequired range: 0 <= x <= 999999999999\n​\nname\nstringrequired\n\nName of the discount. Will be displayed to the customer when the discount is applied.\n\nMinimum length: 1\n​\ncurrency\nstringdefault:usd\n\nThe currency. Currently, only usd is supported.\n\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ncode\nstring | null\n\nCode customers can use to apply the discount during checkout. Must be between 3 and 256 characters long and contain only alphanumeric characters.If not provided, the discount can only be applied via the API.\n\n​\nstarts_at\nstring<date-time> | null\n\nOptional timestamp after which the discount is redeemable.\n\n​\nends_at\nstring<date-time> | null\n\nOptional timestamp after which the discount is no longer redeemable.\n\n​\nmax_redemptions\ninteger | null\n\nOptional maximum number of times the discount can be redeemed.\n\nRequired range: x >= 1\n​\nproducts\nstring<uuid4>[] | null\n\nList of product IDs the discount can be applied to.\n\n​\norganization_id\nstring<uuid4> | null\n\nThe ID of the organization owning the discount. Required unless you use an organization token.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nResponse\n201\napplication/json\n\nDiscount created.\n\nDiscountFixedOnceForeverDuration\nDiscountFixedRepeatDuration\nDiscountPercentageOnceForeverDuration\nDiscountPercentageRepeatDuration\n\nSchema for a fixed amount discount that is applied once or forever.\n\n​\nduration\nenum<string>required\nAvailable options: once, forever, repeating \n​\ntype\nenum<string>required\nAvailable options: fixed, percentage \n​\namount\nintegerrequired\nExamples:\n\n1000\n\n​\ncurrency\nstringrequired\nExamples:\n\n\"usd\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nname\nstringrequired\n\nName of the discount. Will be displayed to the customer when the discount is applied.\n\n​\ncode\nstring | nullrequired\n\nCode customers can use to apply the discount during checkout.\n\n​\nstarts_at\nstring<date-time> | nullrequired\n\nTimestamp after which the discount is redeemable.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nTimestamp after which the discount is no longer redeemable.\n\n​\nmax_redemptions\ninteger | nullrequired\n\nMaximum number of times the discount can be redeemed.\n\n​\nredemptions_count\nintegerrequired\n\nNumber of times the discount has been redeemed.\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproducts\nDiscountProduct · object[]required\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Discount\nUpdate a discount. **Scopes**: `discounts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Discount - Polar",
    "url": "https://polar.sh/docs/api-reference/discounts/update",
    "html": "Discounts\nUpdate Discount\nCopy page\n\nUpdate a discount.\n\nScopes: discounts:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ndiscounts\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe discount ID.\n\nBody\napplication/json\n\nSchema to update a discount.\n\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nname\nstring | null\n\nName of the discount. Will be displayed to the customer when the discount is applied.\n\nMinimum length: 1\n​\ncode\nstring | null\n\nCode customers can use to apply the discount during checkout. Must be between 3 and 256 characters long and contain only alphanumeric characters.If not provided, the discount can only be applied via the API.\n\n​\nstarts_at\nstring<date-time> | null\n\nOptional timestamp after which the discount is redeemable.\n\n​\nends_at\nstring<date-time> | null\n\nOptional timestamp after which the discount is no longer redeemable.\n\n​\nmax_redemptions\ninteger | null\n\nOptional maximum number of times the discount can be redeemed.\n\nRequired range: x >= 1\n​\nduration\nenum<string> | null\nAvailable options: once, forever, repeating \n​\nduration_in_months\ninteger | null\n\nNumber of months the discount should be applied.\n\nFor this to work on yearly pricing, you should multiply this by 12.\nFor example, to apply the discount for 2 years, set this to 24.\n\nRequired range: 1 <= x <= 999\n​\ntype\nenum<string> | null\nAvailable options: fixed, percentage \n​\namount\ninteger | null\n\nFixed amount to discount from the invoice total.\n\nRequired range: 0 <= x <= 999999999999\n​\ncurrency\nstring | null\n\nThe currency. Currently, only usd is supported.\n\n​\nbasis_points\ninteger | null\n\nDiscount percentage in basis points.\n\nA basis point is 1/100th of a percent.\nFor example, to create a 25.5% discount, set this to 2550.\n\nRequired range: 1 <= x <= 10000\n​\nproducts\nstring<uuid4>[] | null\n\nList of product IDs the discount can be applied to.\n\nResponse\n200\napplication/json\n\nDiscount updated.\n\nDiscountFixedOnceForeverDuration\nDiscountFixedRepeatDuration\nDiscountPercentageOnceForeverDuration\nDiscountPercentageRepeatDuration\n\nSchema for a fixed amount discount that is applied once or forever.\n\n​\nduration\nenum<string>required\nAvailable options: once, forever, repeating \n​\ntype\nenum<string>required\nAvailable options: fixed, percentage \n​\namount\nintegerrequired\nExamples:\n\n1000\n\n​\ncurrency\nstringrequired\nExamples:\n\n\"usd\"\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nname\nstringrequired\n\nName of the discount. Will be displayed to the customer when the discount is applied.\n\n​\ncode\nstring | nullrequired\n\nCode customers can use to apply the discount during checkout.\n\n​\nstarts_at\nstring<date-time> | nullrequired\n\nTimestamp after which the discount is redeemable.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nTimestamp after which the discount is no longer redeemable.\n\n​\nmax_redemptions\ninteger | nullrequired\n\nMaximum number of times the discount can be redeemed.\n\n​\nredemptions_count\nintegerrequired\n\nNumber of times the discount has been redeemed.\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproducts\nDiscountProduct · object[]required\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete Discount\nDelete a discount. **Scopes**: `discounts:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete Discount - Polar",
    "url": "https://polar.sh/docs/api-reference/discounts/delete",
    "html": "Discounts\nDelete Discount\nCopy page\n\nDelete a discount.\n\nScopes: discounts:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ndiscounts\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe discount ID.\n\nResponse\n204\n\nDiscount deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Refund\nCreate a refund. **Scopes**: `refunds:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Polar for Framer - Polar",
    "url": "https://polar.sh/docs/features/integrations/framer",
    "html": "Integrations\nPolar for Framer\nCopy page\n\nThe fastest way to sell digital products on your Framer site\n\nIntroducing the official Polar plugin for Framer. Allowing you to sell products on your site without having to build a custom checkout flow.\n​\nGetting Started\nGet your hands on the Polar plugin in the Framer Marketplace\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nZapier\nConnect Polar to hundreds of other apps with Zapier\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Polar for Zapier - Polar",
    "url": "https://polar.sh/docs/features/integrations/zapier",
    "html": "Integrations\nPolar for Zapier\nCopy page\n\nConnect Polar to hundreds of other apps with Zapier\n\nZapier lets you connect Polar to 2,000+ other web services. Automated connections called Zaps, set up in minutes with no coding, can automate your day-to-day tasks and build workflows between apps that otherwise wouldn’t be possible.\nEach Zap has one app as the Trigger, where your information comes from and which causes one or more Actions in other apps, where your data gets sent automatically.\nWe’ve focused on triggers (webhooks) for now, so you can react to events in Polar and trigger actions in other apps.\nNeed to perform actions in Polar? Tell us about your use case here and we’ll consider adding more actions in the future.\n​\nGetting Started with Zapier\nSign up for a free Zapier account, from there you can jump right in. To help you hit the ground running, you’ll find popular pre-made Zaps below.\n​\nHow do I connect Polar to Zapier?\nLog in to your Zapier account or create a new account. Navigate to “My Apps” from the top menu bar. Now click on “Connect a new account…” and search for “Polar” Use your credentials to connect your Polar account to Zapier. Once that’s done you can start creating an automation! Use a pre-made Zap or create your own with the Zap Editor. Creating a Zap requires no coding knowledge and you’ll be walked step-by-step through the setup. Need inspiration? See everything that’s possible with Polar and Zapier.\nIf you have any additional questions, you can open a ticket with Zapier Support from https://zapier.com/app/get-help\n​\nPopular use cases\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nParityDeals (PPP)\nOffer products with different price across the globe\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Purchase Power Parity with ParityDeals - Polar",
    "url": "https://polar.sh/docs/features/integrations/paritydeals",
    "html": "Integrations\nPurchase Power Parity with ParityDeals\nCopy page\n\nOffer products with different price across the globe\n\nWant to offer different prices in different countries? ParityDeals offers automatic pricing optimizations depending on customers geolocation and a seamless integration with Polar.\n​\nSimple Integration, Powerful Deals\nYou can easily and securely (OAuth 2.0) connect Polar to ParityDeals\nSelect products on Polar to offer deals for\nConfigure deals by country or holidays\nParityDeals automatically creates and manages discounts on Polar\nShowing them to customers based on time and geolocation (unless VPN is detected)\nOffering great & local deals internationally with ease\n​\nSetup Guide\n​\nSignup to ParityDeals\nGo to app.paritydeals.com and sign up.\n​\nConnect Polar on ParityDeals\nIn your ParityDeals dashboard, click Create Deals > Create Deals with Polar.\n​\nGrant ParityDeals Access (OAuth 2.0)\nNo need to create API access keys and share them externally. Just connect securely and grant the necessary permissions using Polar OAuth 2.0.\n​\nChoose Products\nNow, let’s select the Polar products you want to offer deals for.\n​\nConfigure Deals\nLet’s configure our deal settings.\nEnter your website URL (requires your own site vs. Polar storefront)\nEnter a targeted URL path, e.g /pricing to only show deals on that page\nNow we can configure the deals for different countries. ParityDeals offers great defaults, but you can of course change them.\n​\nConfigure Banner\nYou can then customize the ParityDeals banner to suit your site and design.\n​\nEmbed Banner\nFinally, we’re all setup over at ParityDeals. Just copy the script to their banner and embed it on your site. You’re now done 👏🏼\n​\nQuestions & Help\nCheckout the ParityDeals documentation for more guides and information.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAffonso Affiliates\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Affonso Affiliates with Polar - Polar",
    "url": "https://polar.sh/docs/features/integrations/affonso",
    "html": "Integrations\nAffonso Affiliates with Polar\nCopy page\nThis guide explains how to integrate Affonso’s affiliate marketing software with your Polar account to track and manage affiliate-driven sales for your SaaS business.\n​\nWhat is Affonso?\nAffonso is an affiliate marketing software that enables SaaS businesses to launch, manage, and scale their own affiliate programs. With Affonso, you can:\nSet up flexible commission structures\nManage multiple affiliate programs from one dashboard\nProvide your affiliates with real-time tracking and marketing resources\nAutomate affiliate payments and commission calculations\n​\nIntegration Steps\n​\n1. Create a Polar Access Token for Affonso\nFirst, you’ll need to create an API token in Polar that Affonso can use to communicate with your account:\nLogin to your Polar Dashboard\nNavigate to Settings in the main menu\nScroll down to the Developers section on the Settings page\nClick the New token button\nGive your token a name (e.g., “Affonso Integration”)\nSet token expiration to No expiration Important: If you set an expiration date, you’ll need to manually update the token in Affonso when it expires. Tracking will stop working if the token expires.\nEnable all the following scopes:\ndiscounts:read\ndiscounts:write\nevents:read\nsubscriptions:read\ncustomers:read\ncustomers:write\norders:read\nrefunds:read\nwebhooks:read\nwebhooks:write\nClick Create token and copy the generated token\nProvide this token to Affonso by entering it in their integration settings\n​\n2. Set Up Webhooks in Polar\nAfter connecting your Polar account with Affonso, you’ll receive a webhook URL and secret from Affonso. Add these to your Polar account:\nGo to Settings → Developers → Webhooks in your Polar Dashboard\nClick the “Add Endpoint” button\nIn the URL field, paste the webhook URL provided by Affonso\nFor Format, select RAW from the dropdown\nIn the Secret field, paste the webhook secret provided by Affonso\nUnder Events, enable all of the following:\norder.created\norder.refunded\nsubscription.canceled\nClick Save to complete the webhook setup\n​\n3. Add the Affonso Tracking Script to Your Website\nAdd Affonso’s tracking script to the <head> tag of your website:\nCopy\nAsk AI\n<!-- Place in <head> tag -->\n<script\n  async\n  defer\n  src=\"https://affonso.io/js/pixel.min.js\"\n  data-affonso=\"YOUR_AFFONSO_PROGRAM_ID\"\n  data-cookie_duration=\"YOUR_COOKIE_DURATION\">\n</script>\n\nReplace YOUR_AFFONSO_PROGRAM_ID with the unique program ID provided by Affonso.\nThis script should be placed on all pages of your website, including:\nYour main marketing website\nYour application domain\nAny subdomains where users might land or make purchases\n​\n4. Track User Signups (Optional)\nFor better conversion insights, you can track when users sign up through an affiliate link:\nCopy\nAsk AI\n// After successful registration\nwindow.Affonso.signup(userEmail);\n\n​\n5. Pass Referral Data to Polar Checkout\nTo ensure proper commission attribution, pass the referral data when creating checkout sessions:\nCopy\nAsk AI\n// Get the referral ID from the Affonso global variable\nconst referralId = window.affonso_referral;\n\n// Create checkout session with Polar\nconst checkout = await polar.checkouts.create({\n  products: [\"your_product_id\"],\n  success_url: \"https://your-site.com/success\",\n  metadata: {\n    affonso_referral: referralId, // Include referral ID from Affonso\n  }\n});\n\n// Redirect to checkout\nwindow.location.href = checkout.url;\n\n​\nHow It Works\nWhen a user visits your site through an affiliate link, Affonso’s script stores a unique identifier in a cookie\nIf you’ve implemented signup tracking, Affonso records when the user creates an account\nWhen the user makes a purchase, the referral ID is passed to Polar as metadata\nPolar’s webhook notifies Affonso about the purchase\nAffonso attributes the sale to the correct affiliate and calculates the commission\n​\nBenefits of the Integration\nAutomated Tracking: No manual work required to track affiliate-driven sales\nReal-Time Analytics: Both you and your affiliates get immediate insights into performance\nSeamless User Experience: The integration works behind the scenes without affecting your checkout flow\nFlexible Commission Structures: Set up complex commission rules based on product, subscription duration, etc.\n​\nGetting Help\nMore details about the integration: Polar Affiliate Program\nIf you need assistance with your Affonso integration, contact Affonso’s support team:\nEmail: hello@affonso.io\nLive chat: Available directly in the Affonso dashboard\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nFernand\nLearn how to sync customer and payment data from Polar to Fernand.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Polar Integration in Fernand - Polar",
    "url": "https://polar.sh/docs/features/integrations/fernand",
    "html": "Integrations\nPolar Integration in Fernand\nCopy page\n\nLearn how to sync customer and payment data from Polar to Fernand.\n\n​\nWhat is Fernand?\nFernand is a modern customer support tool designed for SaaS — it’s fast, calm, and built to reduce the anxiety of answering support requests.\n​\nHow it works\nAfter connecting your Polar account to Fernand, you’ll be able to see customer payment information and product access details directly within each customer conversation.\nThis enables you to:\nInstantly verify if someone is an active customer\nPrioritize conversations from high-tier plans\nView product purchases and payment history in context\n​\nHow to connect Fernand with Polar\nOpen Integrations in your Fernand organization settings.\nClick on Connect Polar.\nYou’ll be redirected to Polar to authorize the connection.\nOnce approved, Fernand will begin syncing customer data automatically.\nThat’s it! You’ll now see Polar customer info directly in Fernand’s conversation list and sidebar.\n​\nHow to automate your inbox with Polar data\nOnce Polar is connected, you can create automation rules in Fernand based on Polar data.\nLet’s walk through a basic example: auto-replying to all customers on your Pro plan.\n​\nCreate a new rule\n1\n\nCreate a new rule\n\nGo to Rules in Fernand.\nClick Add rule and give it a descriptive name.\n2\n\nSelect a trigger\n\nThis ensures the rule runs on each new customer message.\n3\n\nSelect a condition\n\nNow add a condition based on Polar data. For example:\nContact is a customer...\nContact has paid plan...\nYou can target specific plans (e.g. Pro, Business) or specific products to personalize support or automate prioritization.\n4\n\nSelect an action\n\nNow define what happens when the rule matches. For example:\nSend an auto reply (with variables)\nAssign the conversation to a specific agent\nTag the conversation with priority or paid\nTrigger a webhook for external automation\n​\nDisconnecting the integration\nIf you ever want to disconnect Polar from your Fernand workspace:\n1\n\nGo to the Integrations page.\n\n2\n\nClick Disconnect next to Polar.\n\nDeleting your organization on Fernand will also remove the Polar integration automatically.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAuthentication\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Custom Field - Polar",
    "url": "https://polar.sh/docs/api-reference/custom-fields/create",
    "html": "Custom Checkout Fields\nCreate Custom Field\nCopy page\n\nCreate a custom field.\n\nScopes: custom_fields:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustom-fields\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\nCustomFieldCreateText\nCustomFieldCreateNumber\nCustomFieldCreateDate\nCustomFieldCreateCheckbox\nCustomFieldCreateSelect\n\nSchema to create a custom field of type text.\n\n​\ntype\nstringrequired\nAllowed value: \"text\"\n​\nslug\nstringrequired\n\nIdentifier of the custom field. It'll be used as key when storing the value. Must be unique across the organization.It can only contain ASCII letters, numbers and hyphens.\n\nMinimum length: 1\n​\nname\nstringrequired\n\nName of the custom field.\n\nMinimum length: 1\n​\nproperties\nobjectrequired\n\nShow child attributes\n\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\norganization_id\nstring<uuid4> | null\n\nThe ID of the organization owning the custom field. Required unless you use an organization token.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nResponse\n201\napplication/json\n\nCustom field created.\n\nCustomFieldText\nCustomFieldNumber\nCustomFieldDate\nCustomFieldCheckbox\nCustomFieldSelect\n\nSchema for a custom field of type text.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ntype\nstringrequired\nAllowed value: \"text\"\n​\nslug\nstringrequired\n\nIdentifier of the custom field. It'll be used as key when storing the value.\n\n​\nname\nstringrequired\n\nName of the custom field.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the custom field.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproperties\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Custom Field\nGet a custom field by ID. **Scopes**: `custom_fields:read` `custom_fields:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Custom Field - Polar",
    "url": "https://polar.sh/docs/api-reference/custom-fields/get",
    "html": "Custom Checkout Fields\nGet Custom Field\nCopy page\n\nGet a custom field by ID.\n\nScopes: custom_fields:read custom_fields:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustom-fields\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe custom field ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nCustomFieldText\nCustomFieldNumber\nCustomFieldDate\nCustomFieldCheckbox\nCustomFieldSelect\n\nSchema for a custom field of type text.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ntype\nstringrequired\nAllowed value: \"text\"\n​\nslug\nstringrequired\n\nIdentifier of the custom field. It'll be used as key when storing the value.\n\n​\nname\nstringrequired\n\nName of the custom field.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the custom field.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproperties\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Custom Fields\nList custom fields. **Scopes**: `custom_fields:read` `custom_fields:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Custom Fields - Polar",
    "url": "https://polar.sh/docs/api-reference/custom-fields/list",
    "html": "Custom Checkout Fields\nList Custom Fields\nCopy page\n\nList custom fields.\n\nScopes: custom_fields:read custom_fields:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustom-fields\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nquery\nstring | null\n\nFilter by custom field name or slug.\n\n​\ntype\nenum<string> | null\nenum<string>[] | null\n\nFilter by custom field type.\n\nAvailable options: text, number, date, checkbox, select \n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nItems · arrayrequired\nCustomFieldText\nCustomFieldNumber\nCustomFieldDate\nCustomFieldCheckbox\nCustomFieldSelect\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Custom Field\nUpdate a custom field. **Scopes**: `custom_fields:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Custom Field - Polar",
    "url": "https://polar.sh/docs/api-reference/custom-fields/update",
    "html": "Custom Checkout Fields\nUpdate Custom Field\nCopy page\n\nUpdate a custom field.\n\nScopes: custom_fields:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustom-fields\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe custom field ID.\n\nBody\napplication/json\nCustomFieldUpdateText\nCustomFieldUpdateNumber\nCustomFieldUpdateDate\nCustomFieldUpdateCheckbox\nCustomFieldUpdateSelect\n\nSchema to update a custom field of type text.\n\n​\ntype\nstringrequired\nAllowed value: \"text\"\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nname\nstring | null\n\nName of the custom field.\n\nMinimum length: 1\n​\nslug\nstring | null\n\nIdentifier of the custom field. It'll be used as key when storing the value. Must be unique across the organization.It can only contain ASCII letters, numbers and hyphens.\n\nMinimum length: 1\n​\nproperties\nobject | null\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nCustom field updated.\n\nCustomFieldText\nCustomFieldNumber\nCustomFieldDate\nCustomFieldCheckbox\nCustomFieldSelect\n\nSchema for a custom field of type text.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ntype\nstringrequired\nAllowed value: \"text\"\n​\nslug\nstringrequired\n\nIdentifier of the custom field. It'll be used as key when storing the value.\n\n​\nname\nstringrequired\n\nName of the custom field.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the custom field.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nproperties\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete Custom Field\nDelete a custom field. **Scopes**: `custom_fields:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Organization - Polar",
    "url": "https://polar.sh/docs/api-reference/organizations/update",
    "html": "Organizations\nUpdate Organization\nCopy page\n\nUpdate an organization.\n\nScopes: organizations:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norganizations\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nBody\napplication/json\n​\nname\nstring | null\nMinimum length: 3\n​\navatar_url\nstring<uri> | null\nRequired string length: 1 - 2083\n​\nemail\nstring<email> | null\n\nPublic support email.\n\n​\nwebsite\nstring<uri> | null\n\nOfficial website of the organization.\n\nRequired string length: 1 - 2083\n​\nsocials\nOrganizationSocialLink · object[] | null\n\nLinks to social profiles.\n\nShow child attributes\n\n​\ndetails\nobject | null\n\nAdditional, private, business details Polar needs about active organizations for compliance (KYC).\n\nShow child attributes\n\n​\nfeature_settings\nobject | null\n\nShow child attributes\n\n​\nsubscription_settings\nobject | null\n\nShow child attributes\n\n​\nnotification_settings\nobject | null\n\nShow child attributes\n\n​\ncustomer_email_settings\nobject | null\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nOrganization updated.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nname\nstringrequired\n\nOrganization name shown in checkout, customer portal, emails etc.\n\n​\nslug\nstringrequired\n\nUnique organization slug in checkout, customer portal and credit card statements.\n\n​\navatar_url\nstring | nullrequired\n\nAvatar URL shown in checkout, customer portal, emails etc.\n\n​\nemail\nstring | nullrequired\n\nPublic support email.\n\n​\nwebsite\nstring | nullrequired\n\nOfficial website of the organization.\n\n​\nsocials\nOrganizationSocialLink · object[]required\n\nLinks to social profiles.\n\nShow child attributes\n\n​\nstatus\nenum<string>required\n\nCurrent organization status\n\nAvailable options: created, onboarding_started, under_review, denied, active \n​\ndetails_submitted_at\nstring<date-time> | nullrequired\n\nWhen the business details were submitted.\n\n​\nfeature_settings\nobject | nullrequired\n\nOrganization feature settings\n\nShow child attributes\n\n​\nsubscription_settings\nobjectrequired\n\nSettings related to subscriptions management\n\nShow child attributes\n\n​\nnotification_settings\nobjectrequired\n\nSettings related to notifications\n\nShow child attributes\n\n​\ncustomer_email_settings\nobjectrequired\n\nSettings related to customer emails\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Metrics\nGet metrics about your orders and subscriptions. Currency values are output in cents. **Scopes**: `metrics:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Downloadables - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/downloadables/list",
    "html": "File Downloads\nList Downloadables\nCopy page\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\ndownloadables\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nbenefit_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by benefit ID.\nThe benefit ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nDownloadableRead · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Seats\n**Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete Benefit - Polar",
    "url": "https://polar.sh/docs/api-reference/benefits/delete",
    "html": "Benefits\nDelete Benefit\nCopy page\n\nDelete a benefit.\n\n[!WARNING] Every grants associated with the benefit will be revoked. Users will lose access to the benefit.\n\nScopes: benefits:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nbenefits\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe benefit ID.\n\nResponse\n204\n\nBenefit deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Customer Meter\nGet a customer meter by ID. **Scopes**: `customer_meters:read`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Meter - Polar",
    "url": "https://polar.sh/docs/api-reference/meters/get",
    "html": "Meters\nGet Meter\nCopy page\n\nGet a meter by ID.\n\nScopes: meters:read meters:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nmeters\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe meter ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nname\nstringrequired\n\nThe name of the meter. Will be shown on customer's invoices and usage.\n\n​\nfilter\nobjectrequired\n\nThe filter to apply on events that'll be used to calculate the meter.\n\nShow child attributes\n\n​\naggregation\nobjectrequired\n\nThe aggregation to apply on the filtered events to calculate the meter.\n\nCountAggregation\nPropertyAggregation\nUniqueAggregation\n\nShow child attributes\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the meter.\n\n​\narchived_at\nstring<date-time> | null\n\nWhether the meter is archived and the time it was archived.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Meters\nList meters. **Scopes**: `meters:read` `meters:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Meters - Polar",
    "url": "https://polar.sh/docs/api-reference/meters/list",
    "html": "Meters\nList Meters\nCopy page\n\nList meters.\n\nScopes: meters:read meters:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nmeters\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nquery\nstring | null\n\nFilter by name.\n\n​\nis_archived\nboolean | null\n\nFilter on archived meters.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nMeter · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Meter\nUpdate a meter. **Scopes**: `meters:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Meter - Polar",
    "url": "https://polar.sh/docs/api-reference/meters/update",
    "html": "Meters\nUpdate Meter\nCopy page\n\nUpdate a meter.\n\nScopes: meters:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nmeters\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe meter ID.\n\nBody\napplication/json\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\nname\nstring | null\n\nThe name of the meter. Will be shown on customer's invoices and usage.\n\nMinimum length: 3\n​\nfilter\nobject | null\n\nThe filter to apply on events that'll be used to calculate the meter.\n\nShow child attributes\n\n​\naggregation\nobject | null\n\nThe aggregation to apply on the filtered events to calculate the meter.\n\nCountAggregation\nPropertyAggregation\nUniqueAggregation\n\nShow child attributes\n\n​\nis_archived\nboolean | null\n\nWhether the meter is archived. Archived meters are no longer used for billing.\n\nResponse\n200\napplication/json\n\nMeter updated.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nname\nstringrequired\n\nThe name of the meter. Will be shown on customer's invoices and usage.\n\n​\nfilter\nobjectrequired\n\nThe filter to apply on events that'll be used to calculate the meter.\n\nShow child attributes\n\n​\naggregation\nobjectrequired\n\nThe aggregation to apply on the filtered events to calculate the meter.\n\nCountAggregation\nPropertyAggregation\nUniqueAggregation\n\nShow child attributes\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the meter.\n\n​\narchived_at\nstring<date-time> | null\n\nWhether the meter is archived and the time it was archived.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Meter Quantities\nGet quantities of a meter over a time period. **Scopes**: `meters:read` `meters:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Meter Quantities - Polar",
    "url": "https://polar.sh/docs/api-reference/meters/get-quantities",
    "html": "Meters\nGet Meter Quantities\nCopy page\n\nGet quantities of a meter over a time period.\n\nScopes: meters:read meters:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nmeters\n/\n{id}\n/\nquantities\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe meter ID.\n\nQuery Parameters\n​\nstart_timestamp\nstring<date-time>required\n\nStart timestamp.\n\n​\nend_timestamp\nstring<date-time>required\n\nEnd timestamp.\n\n​\ninterval\nenum<string>required\n\nInterval between two timestamps.\n\nAvailable options: year, month, week, day, hour \n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer ID.\nThe customer ID.\n\n​\nexternal_customer_id\nstring | null\nstring[] | null\n\nFilter by external customer ID.\n\n​\ncustomer_aggregation_function\nenum<string> | null\n\nIf set, will first compute the quantities per customer before aggregating them using the given function. If not set, the quantities will be aggregated across all events.\n\nAvailable options: count, sum, max, min, avg, unique \n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nquantities\nMeterQuantity · object[]required\n\nShow child attributes\n\n​\ntotal\nnumberrequired\n\nThe total quantity for the period.\n\nExamples:\n\n100\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Benefit\nCreate a benefit. **Scopes**: `benefits:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Organization - Polar",
    "url": "https://polar.sh/docs/api-reference/organizations/get",
    "html": "Organizations\nGet Organization\nCopy page\n\nGet an organization by ID.\n\nScopes: organizations:read organizations:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norganizations\n/\n{id}\nTry it\nHello there. Just testing a custom intro.\nProperty\tDescription\nName\tFull name of user\nAge\tReported age\nJoined\tWhether the user joined the community\nContinuing here.\n​\n2024-10-12\nv0.1.1\nSome update to the endpoint here\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nname\nstringrequired\n\nOrganization name shown in checkout, customer portal, emails etc.\n\n​\nslug\nstringrequired\n\nUnique organization slug in checkout, customer portal and credit card statements.\n\n​\navatar_url\nstring | nullrequired\n\nAvatar URL shown in checkout, customer portal, emails etc.\n\n​\nemail\nstring | nullrequired\n\nPublic support email.\n\n​\nwebsite\nstring | nullrequired\n\nOfficial website of the organization.\n\n​\nsocials\nOrganizationSocialLink · object[]required\n\nLinks to social profiles.\n\nShow child attributes\n\n​\nstatus\nenum<string>required\n\nCurrent organization status\n\nAvailable options: created, onboarding_started, under_review, denied, active \n​\ndetails_submitted_at\nstring<date-time> | nullrequired\n\nWhen the business details were submitted.\n\n​\nfeature_settings\nobject | nullrequired\n\nOrganization feature settings\n\nShow child attributes\n\n​\nsubscription_settings\nobjectrequired\n\nSettings related to subscriptions management\n\nShow child attributes\n\n​\nnotification_settings\nobjectrequired\n\nSettings related to notifications\n\nShow child attributes\n\n​\ncustomer_email_settings\nobjectrequired\n\nSettings related to customer emails\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Organizations\nList organizations. **Scopes**: `organizations:read` `organizations:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "customer_seat.assigned - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/customer_seat.assigned",
    "html": "Customer Seats\ncustomer_seat.assigned\nCopy page\n\nSent when a new customer seat is assigned.\n\nThis event is triggered when a seat is assigned to a customer by the organization.\nThe customer will receive an invitation email to claim the seat.\n\n​\ntype\nstringrequired\nAllowed value: \"customer_seat.assigned\"\nExamples:\n\n\"customer_seat.assigned\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncustomer_seat.claimed\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "subscription.revoked - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/subscription.revoked",
    "html": "Subscriptions\nsubscription.revoked\nCopy page\n\nSent when a subscription is revoked, the user loses access immediately.\nHappens when the subscription is canceled, or payment is past due.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"subscription.revoked\"\nExamples:\n\n\"subscription.revoked\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\norder.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Organization - Polar",
    "url": "https://polar.sh/docs/api-reference/organizations/create",
    "html": "Organizations\nCreate Organization\nCopy page\n\nCreate an organization.\n\nScopes: organizations:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norganizations\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n​\nname\nstringrequired\nMinimum length: 3\n​\nslug\nstringrequired\nMinimum length: 3\n​\navatar_url\nstring<uri> | null\nRequired string length: 1 - 2083\n​\nemail\nstring<email> | null\n\nPublic support email.\n\n​\nwebsite\nstring<uri> | null\n\nOfficial website of the organization.\n\nRequired string length: 1 - 2083\n​\nsocials\nOrganizationSocialLink · object[] | null\n\nLink to social profiles.\n\nShow child attributes\n\n​\ndetails\nobject | null\n\nAdditional, private, business details Polar needs about active organizations for compliance (KYC).\n\nShow child attributes\n\n​\nfeature_settings\nobject | null\n\nShow child attributes\n\n​\nsubscription_settings\nobject | null\n\nShow child attributes\n\n​\nnotification_settings\nobject | null\n\nShow child attributes\n\n​\ncustomer_email_settings\nobject | null\n\nShow child attributes\n\nResponse\n201\napplication/json\n\nOrganization created.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\nname\nstringrequired\n\nOrganization name shown in checkout, customer portal, emails etc.\n\n​\nslug\nstringrequired\n\nUnique organization slug in checkout, customer portal and credit card statements.\n\n​\navatar_url\nstring | nullrequired\n\nAvatar URL shown in checkout, customer portal, emails etc.\n\n​\nemail\nstring | nullrequired\n\nPublic support email.\n\n​\nwebsite\nstring | nullrequired\n\nOfficial website of the organization.\n\n​\nsocials\nOrganizationSocialLink · object[]required\n\nLinks to social profiles.\n\nShow child attributes\n\n​\nstatus\nenum<string>required\n\nCurrent organization status\n\nAvailable options: created, onboarding_started, under_review, denied, active \n​\ndetails_submitted_at\nstring<date-time> | nullrequired\n\nWhen the business details were submitted.\n\n​\nfeature_settings\nobject | nullrequired\n\nOrganization feature settings\n\nShow child attributes\n\n​\nsubscription_settings\nobjectrequired\n\nSettings related to subscriptions management\n\nShow child attributes\n\n​\nnotification_settings\nobjectrequired\n\nSettings related to notifications\n\nShow child attributes\n\n​\ncustomer_email_settings\nobjectrequired\n\nSettings related to customer emails\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Organization\nUpdate an organization. **Scopes**: `organizations:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Organizations - Polar",
    "url": "https://polar.sh/docs/api-reference/organizations/list",
    "html": "Organizations\nList Organizations\nCopy page\n\nList organizations.\n\nScopes: organizations:read organizations:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\norganizations\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\nslug\nstring | null\n\nFilter by slug.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nOrganization · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Organization\nCreate an organization. **Scopes**: `organizations:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Seats - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/seats/list",
    "html": "Seats\nList Seats\nCopy page\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nseats\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nQuery Parameters\n​\nsubscription_id\nstring | null\n\nSubscription ID\n\n​\norder_id\nstring | null\n\nOrder ID\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nseats\nCustomerSeat · object[]required\n\nList of seats\n\nShow child attributes\n\n​\navailable_seats\nintegerrequired\n\nNumber of available seats\n\n​\ntotal_seats\nintegerrequired\n\nTotal number of seats for the subscription\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAssign Seat\n**Scopes**: `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Benefit - Polar",
    "url": "https://polar.sh/docs/api-reference/benefits/create",
    "html": "Benefits\nCreate Benefit\nCopy page\n\nCreate a benefit.\n\nScopes: benefits:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nbenefits\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\nBenefitCustomCreate\nBenefitDiscordCreate\nBenefitGitHubRepositoryCreate\nBenefitDownloadablesCreate\nBenefitLicenseKeysCreate\nBenefitMeterCreditCreate\n\nSchema to create a benefit of type custom.\n\n​\ntype\nstringrequired\nAllowed value: \"custom\"\n​\ndescription\nstringrequired\n\nThe description of the benefit. Will be displayed on products having this benefit.\n\nRequired string length: 3 - 42\n​\nproperties\nobjectrequired\n\nProperties for creating a benefit of type custom.\n\nShow child attributes\n\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\norganization_id\nstring<uuid4> | null\n\nThe ID of the organization owning the benefit. Required unless you use an organization token.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nResponse\n201\napplication/json\n\nBenefit created.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nA benefit of type custom.\n\nUse it to grant any kind of benefit that doesn't fit in the other types.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the benefit.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntype\nstringrequired\nAllowed value: \"custom\"\n​\ndescription\nstringrequired\n\nThe description of the benefit.\n\n​\nselectable\nbooleanrequired\n\nWhether the benefit is selectable when creating a product.\n\n​\ndeletable\nbooleanrequired\n\nWhether the benefit is deletable.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the benefit.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nproperties\nobjectrequired\n\nProperties for a benefit of type custom.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Benefit\nGet a benefit by ID. **Scopes**: `benefits:read` `benefits:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Benefit - Polar",
    "url": "https://polar.sh/docs/api-reference/benefits/get",
    "html": "Benefits\nGet Benefit\nCopy page\n\nGet a benefit by ID.\n\nScopes: benefits:read benefits:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nbenefits\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe benefit ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nA benefit of type custom.\n\nUse it to grant any kind of benefit that doesn't fit in the other types.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the benefit.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntype\nstringrequired\nAllowed value: \"custom\"\n​\ndescription\nstringrequired\n\nThe description of the benefit.\n\n​\nselectable\nbooleanrequired\n\nWhether the benefit is selectable when creating a product.\n\n​\ndeletable\nbooleanrequired\n\nWhether the benefit is deletable.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the benefit.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nproperties\nobjectrequired\n\nProperties for a benefit of type custom.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Benefits\nList benefits. **Scopes**: `benefits:read` `benefits:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Benefits - Polar",
    "url": "https://polar.sh/docs/api-reference/benefits/list",
    "html": "Benefits\nList Benefits\nCopy page\n\nList benefits.\n\nScopes: benefits:read benefits:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nbenefits\n/\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\ntype\nenum<string> | null\nenum<string>[] | null\n\nFilter by benefit type.\n\nAvailable options: custom, discord, github_repository, downloadables, license_keys, meter_credit \n​\nquery\nstring | null\n\nFilter by description.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\n​\nsorting\nenum<string>[] | null\n\nSorting criterion. Several criteria can be used simultaneously and will be applied in order. Add a minus sign - before the criteria name to sort by descending order.\n\nShow child attributes\n\n​\nmetadata\nobject | null\n\nFilter by metadata key-value pairs. It uses the deepObject style, e.g. ?metadata[key]=value.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nItems · arrayrequired\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Benefit Grants\nList the individual grants for a benefit. It's especially useful to check if a user has been granted a benefit. **Scopes**: `benefits:read` `benefits:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Benefit - Polar",
    "url": "https://polar.sh/docs/api-reference/benefits/update",
    "html": "Benefits\nUpdate Benefit\nCopy page\n\nUpdate a benefit.\n\nScopes: benefits:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nbenefits\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe benefit ID.\n\nBody\napplication/json\nBenefitCustomUpdate\nBenefitDiscordUpdate\nBenefitGitHubRepositoryUpdate\nBenefitDownloadablesUpdate\nBenefitLicenseKeysUpdate\nBenefitMeterCreditUpdate\n​\ntype\nstringrequired\nAllowed value: \"custom\"\n​\nmetadata\nobject\n\nKey-value object allowing you to store additional information.\n\nThe key must be a string with a maximum length of 40 characters.\nThe value must be either:\n\nA string with a maximum length of 500 characters\nAn integer\nA floating-point number\nA boolean\n\nYou can store up to 50 key-value pairs.\n\nShow child attributes\n\n​\ndescription\nstring | null\n\nThe description of the benefit. Will be displayed on products having this benefit.\n\nRequired string length: 3 - 42\n​\nproperties\nobject | null\n\nProperties for a benefit of type custom.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nBenefit updated.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nA benefit of type custom.\n\nUse it to grant any kind of benefit that doesn't fit in the other types.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the benefit.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\ntype\nstringrequired\nAllowed value: \"custom\"\n​\ndescription\nstringrequired\n\nThe description of the benefit.\n\n​\nselectable\nbooleanrequired\n\nWhether the benefit is selectable when creating a product.\n\n​\ndeletable\nbooleanrequired\n\nWhether the benefit is deletable.\n\n​\norganization_id\nstring<uuid4>required\n\nThe ID of the organization owning the benefit.\n\n​\nmetadata\nobjectrequired\n\nShow child attributes\n\n​\nproperties\nobjectrequired\n\nProperties for a benefit of type custom.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete Benefit\nDelete a benefit. > [!WARNING] > Every grants associated with the benefit will be revoked. > Users will lose access to the benefit. **Scopes**: `benefits:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Benefit Grants - Polar",
    "url": "https://polar.sh/docs/api-reference/benefits/list-grants",
    "html": "Benefits\nList Benefit Grants\nCopy page\n\nList the individual grants for a benefit.\n\nIt’s especially useful to check if a user has been granted a benefit.\n\nScopes: benefits:read benefits:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nbenefits\n/\n{id}\n/\ngrants\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe benefit ID.\n\nQuery Parameters\n​\nis_granted\nboolean | null\n\nFilter by granted status. If true, only granted benefits will be returned. If false, only revoked benefits will be returned.\n\n​\ncustomer_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by customer.\nThe customer ID.\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nBenefitGrant · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Benefit\nUpdate a benefit. **Scopes**: `benefits:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "customer_seat.claimed - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/customer_seat.claimed",
    "html": "Customer Seats\ncustomer_seat.claimed\nCopy page\n\nSent when a customer seat is claimed.\n\nThis event is triggered when a customer accepts the seat invitation and claims their access.\n\n​\ntype\nstringrequired\nAllowed value: \"customer_seat.claimed\"\nExamples:\n\n\"customer_seat.claimed\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncustomer_seat.revoked\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "customer_seat.revoked - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/customer_seat.revoked",
    "html": "Customer Seats\ncustomer_seat.revoked\nCopy page\n\nSent when a customer seat is revoked.\n\nThis event is triggered when access to a seat is revoked, either manually by the organization or automatically when a subscription is canceled.\n\n​\ntype\nstringrequired\nAllowed value: \"customer_seat.revoked\"\nExamples:\n\n\"customer_seat.revoked\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nrefund.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "subscription.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/subscription.created",
    "html": "Subscriptions\nsubscription.created\nCopy page\n\nSent when a new subscription is created.\n\nWhen this event occurs, the subscription status might not be active yet, as we can still have to wait for the first payment to be processed.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"subscription.created\"\nExamples:\n\n\"subscription.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nsubscription.active\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "subscription.active - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/subscription.active",
    "html": "Subscriptions\nsubscription.active\nCopy page\n\nSent when a subscription becomes active,\nwhether because it's a new paid subscription or because payment was recovered.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"subscription.active\"\nExamples:\n\n\"subscription.active\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nsubscription.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "subscription.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/subscription.updated",
    "html": "Subscriptions\nsubscription.updated\nCopy page\n\nSent when a subscription is updated. This event fires for all changes to the subscription, including renewals.\n\nIf you want more specific events, you can listen to subscription.active, subscription.canceled, and subscription.revoked.\n\nTo listen specifically for renewals, you can listen to order.created events and check the billing_reason field.\n\nDiscord & Slack support: On cancellation and revocation. Renewals are skipped.\n\n​\ntype\nstringrequired\nAllowed value: \"subscription.updated\"\nExamples:\n\n\"subscription.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nsubscription.canceled\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "subscription.canceled - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/subscription.canceled",
    "html": "Subscriptions\nsubscription.canceled\nCopy page\n\nSent when a subscription is canceled.\nCustomers might still have access until the end of the current period.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"subscription.canceled\"\nExamples:\n\n\"subscription.canceled\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nsubscription.uncanceled\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "subscription.uncanceled - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/subscription.uncanceled",
    "html": "Subscriptions\nsubscription.uncanceled\nCopy page\n\nSent when a subscription is uncanceled.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"subscription.uncanceled\"\nExamples:\n\n\"subscription.uncanceled\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nsubscription.revoked\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Assign Seat - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/seats/assign",
    "html": "Seats\nAssign Seat\nCopy page\n\nScopes: customer_portal:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nseats\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nBody\napplication/json\n​\nsubscription_id\nstring<uuid> | null\n\nSubscription ID. Required if checkout_id and order_id are not provided.\n\n​\ncheckout_id\nstring<uuid> | null\n\nCheckout ID. Used to look up subscription or order from the checkout page.\n\n​\norder_id\nstring<uuid> | null\n\nOrder ID for one-time purchases. Required if subscription_id and checkout_id are not provided.\n\n​\nemail\nstring<email> | null\n\nEmail of the customer to assign the seat to\n\n​\nexternal_customer_id\nstring | null\n\nExternal customer ID for the seat assignment\n\n​\ncustomer_id\nstring<uuid> | null\n\nCustomer ID for the seat assignment\n\n​\nmetadata\nobject | null\n\nAdditional metadata for the seat (max 10 keys, 1KB total)\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid>required\n\nThe seat ID\n\n​\nstatus\nenum<string>required\n\nStatus of the seat\n\nAvailable options: pending, claimed, revoked \n​\nsubscription_id\nstring<uuid> | null\n\nThe subscription ID (for recurring seats)\n\n​\norder_id\nstring<uuid> | null\n\nThe order ID (for one-time purchase seats)\n\n​\ncustomer_id\nstring<uuid> | null\n\nThe assigned customer ID\n\n​\ncustomer_email\nstring | null\n\nThe assigned customer email\n\n​\ninvitation_token_expires_at\nstring<date-time> | null\n\nWhen the invitation token expires\n\n​\nclaimed_at\nstring<date-time> | null\n\nWhen the seat was claimed\n\n​\nrevoked_at\nstring<date-time> | null\n\nWhen the seat was revoked\n\n​\nseat_metadata\nobject | null\n\nAdditional metadata for the seat\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nRevoke Seat\n**Scopes**: `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Revoke Seat - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/seats/revoke",
    "html": "Seats\nRevoke Seat\nCopy page\n\nScopes: customer_portal:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nseats\n/\n{seat_id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nseat_id\nstring<uuid>required\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid>required\n\nThe seat ID\n\n​\nstatus\nenum<string>required\n\nStatus of the seat\n\nAvailable options: pending, claimed, revoked \n​\nsubscription_id\nstring<uuid> | null\n\nThe subscription ID (for recurring seats)\n\n​\norder_id\nstring<uuid> | null\n\nThe order ID (for one-time purchase seats)\n\n​\ncustomer_id\nstring<uuid> | null\n\nThe assigned customer ID\n\n​\ncustomer_email\nstring | null\n\nThe assigned customer email\n\n​\ninvitation_token_expires_at\nstring<date-time> | null\n\nWhen the invitation token expires\n\n​\nclaimed_at\nstring<date-time> | null\n\nWhen the seat was claimed\n\n​\nrevoked_at\nstring<date-time> | null\n\nWhen the seat was revoked\n\n​\nseat_metadata\nobject | null\n\nAdditional metadata for the seat\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nResend Invitation\n**Scopes**: `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Resend Invitation - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/seats/resend",
    "html": "Seats\nResend Invitation\nCopy page\n\nScopes: customer_portal:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nseats\n/\n{seat_id}\n/\nresend\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nPath Parameters\n​\nseat_id\nstring<uuid>required\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid>required\n\nThe seat ID\n\n​\nstatus\nenum<string>required\n\nStatus of the seat\n\nAvailable options: pending, claimed, revoked \n​\nsubscription_id\nstring<uuid> | null\n\nThe subscription ID (for recurring seats)\n\n​\norder_id\nstring<uuid> | null\n\nThe order ID (for one-time purchase seats)\n\n​\ncustomer_id\nstring<uuid> | null\n\nThe assigned customer ID\n\n​\ncustomer_email\nstring | null\n\nThe assigned customer email\n\n​\ninvitation_token_expires_at\nstring<date-time> | null\n\nWhen the invitation token expires\n\n​\nclaimed_at\nstring<date-time> | null\n\nWhen the seat was claimed\n\n​\nrevoked_at\nstring<date-time> | null\n\nWhen the seat was revoked\n\n​\nseat_metadata\nobject | null\n\nAdditional metadata for the seat\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Claimed Subscriptions\nList all subscriptions where the authenticated customer has claimed a seat. **Scopes**: `customer_portal:read` `customer_portal:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "refund.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/refund.created",
    "html": "Refunds\nrefund.created\nCopy page\n\nSent when a refund is created regardless of status.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"refund.created\"\nExamples:\n\n\"refund.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nrefund.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Claimed Subscriptions - Polar",
    "url": "https://polar.sh/docs/api-reference/customer-portal/seats/list-subscriptions",
    "html": "Seats\nList Claimed Subscriptions\nCopy page\n\nList all subscriptions where the authenticated customer has claimed a seat.\n\nScopes: customer_portal:read customer_portal:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\ncustomer-portal\n/\nseats\n/\nsubscriptions\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nCustomer session tokens are specific tokens that are used to authenticate customers on your organization. You can create those sessions programmatically using the Create Customer Session endpoint.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\namount\nintegerrequired\n\nThe amount of the subscription.\n\nExamples:\n\n10000\n\n​\ncurrency\nstringrequired\n\nThe currency of the subscription.\n\nExamples:\n\n\"usd\"\n\n​\nrecurring_interval\nenum<string>required\n\nThe interval at which the subscription recurs.\n\nAvailable options: day, week, month, year \n​\nrecurring_interval_count\nintegerrequired\n\nNumber of interval units of the subscription. If this is set to 1 the charge will happen every interval (e.g. every month), if set to 2 it will be every other month, and so on.\n\n​\nstatus\nenum<string>required\n\nThe status of the subscription.\n\nAvailable options: incomplete, incomplete_expired, trialing, active, past_due, canceled, unpaid \n​\ncurrent_period_start\nstring<date-time>required\n\nThe start timestamp of the current billing period.\n\n​\ncurrent_period_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the current billing period.\n\n​\ntrial_start\nstring<date-time> | nullrequired\n\nThe start timestamp of the trial period, if any.\n\n​\ntrial_end\nstring<date-time> | nullrequired\n\nThe end timestamp of the trial period, if any.\n\n​\ncancel_at_period_end\nbooleanrequired\n\nWhether the subscription will be canceled at the end of the current period.\n\n​\ncanceled_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription was canceled. The subscription might still be active if cancel_at_period_end is true.\n\n​\nstarted_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription started.\n\n​\nends_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription will end.\n\n​\nended_at\nstring<date-time> | nullrequired\n\nThe timestamp when the subscription ended.\n\n​\ncustomer_id\nstring<uuid4>required\n\nThe ID of the subscribed customer.\n\n​\nproduct_id\nstring<uuid4>required\n\nThe ID of the subscribed product.\n\n​\ndiscount_id\nstring<uuid4> | nullrequired\n\nThe ID of the applied discount, if any.\n\n​\ncheckout_id\nstring<uuid4> | nullrequired\n​\ncustomer_cancellation_reason\nenum<string> | nullrequired\nAvailable options: customer_service, low_quality, missing_features, switched_service, too_complex, too_expensive, unused, other \n​\ncustomer_cancellation_comment\nstring | nullrequired\n​\nproduct\nobjectrequired\n\nShow child attributes\n\n​\nprices\nPrices · arrayrequired\n\nList of enabled prices for the subscription.\n\nLegacyRecurringProductPriceFixed\nLegacyRecurringProductPriceCustom\nLegacyRecurringProductPriceFree\nProductPriceFixed\nProductPriceCustom\nProductPriceFree\nProductPriceSeatBased\nProductPriceMeteredUnit\n\nShow child attributes\n\n​\nmeters\nCustomerSubscriptionMeter · object[]required\n\nList of meters associated with the subscription.\n\nShow child attributes\n\n​\nis_polar_managed\nbooleanrequired\n\nWhether the subscription is managed by Polar.\n\n​\nseats\ninteger | null\n\nNumber of seats included in the subscription (for seat-based pricing).\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncustomer.state_changed\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "checkout.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/checkout.updated",
    "html": "Checkout\ncheckout.updated\nCopy page\n\nSent when a checkout is updated.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"checkout.updated\"\nExamples:\n\n\"checkout.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nCheckout session data retrieved using an access token.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nsubscription.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "refund.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/refund.updated",
    "html": "Refunds\nrefund.updated\nCopy page\n\nSent when a refund is updated.\n\nDiscord & Slack support: Full\n\n​\ntype\nstringrequired\nAllowed value: \"refund.updated\"\nExamples:\n\n\"refund.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nbenefit_grant.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "customer.state_changed - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/customer.state_changed",
    "html": "Customer Events\ncustomer.state_changed\nCopy page\n\nSent when a customer state has changed.\n\nIt's triggered when:\n\nCustomer is created, updated or deleted.\nA subscription is created or updated.\nA benefit is granted or revoked.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"customer.state_changed\"\nExamples:\n\n\"customer.state_changed\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA customer along with additional state information:\n\nActive subscriptions\nGranted benefits\nActive meters\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncustomer.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "checkout.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/checkout.created",
    "html": "Checkout\ncheckout.created\nCopy page\n\nSent when a new checkout is created.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"checkout.created\"\nExamples:\n\n\"checkout.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nCheckout session data retrieved using an access token.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncheckout.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "benefit_grant.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/benefit_grant.created",
    "html": "Benefit Grants\nbenefit_grant.created\nCopy page\n\nSent when a new benefit grant is created.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"benefit_grant.created\"\nExamples:\n\n\"benefit_grant.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\nBenefitGrantDiscordWebhook\nBenefitGrantCustomWebhook\nBenefitGrantGitHubRepositoryWebhook\nBenefitGrantDownloadablesWebhook\nBenefitGrantLicenseKeysWebhook\nBenefitGrantMeterCreditWebhook\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nbenefit_grant.cycled\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "customer.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/customer.created",
    "html": "Customer Events\ncustomer.created\nCopy page\n\nSent when a new customer is created.\n\nA customer can be created:\n\nAfter a successful checkout.\nProgrammatically via the API.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"customer.created\"\nExamples:\n\n\"customer.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA customer in an organization.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncustomer.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "customer.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/customer.updated",
    "html": "Customer Events\ncustomer.updated\nCopy page\n\nSent when a customer is updated.\n\nThis event is fired when the customer details are updated.\n\nIf you want to be notified when a customer subscription or benefit state changes, you should listen to the customer_state_changed event.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"customer.updated\"\nExamples:\n\n\"customer.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA customer in an organization.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncustomer.deleted\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "customer.deleted - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/customer.deleted",
    "html": "Customer Events\ncustomer.deleted\nCopy page\n\nSent when a customer is deleted.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"customer.deleted\"\nExamples:\n\n\"customer.deleted\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA customer in an organization.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\ncheckout.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "benefit_grant.cycled - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/benefit_grant.cycled",
    "html": "Benefit Grants\nbenefit_grant.cycled\nCopy page\n\nSent when a benefit grant is cycled,\nmeaning the related subscription has been renewed for another period.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"benefit_grant.cycled\"\nExamples:\n\n\"benefit_grant.cycled\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\nBenefitGrantDiscordWebhook\nBenefitGrantCustomWebhook\nBenefitGrantGitHubRepositoryWebhook\nBenefitGrantDownloadablesWebhook\nBenefitGrantLicenseKeysWebhook\nBenefitGrantMeterCreditWebhook\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nbenefit_grant.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "benefit_grant.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/benefit_grant.updated",
    "html": "Benefit Grants\nbenefit_grant.updated\nCopy page\n\nSent when a benefit grant is updated.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"benefit_grant.updated\"\nExamples:\n\n\"benefit_grant.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\nBenefitGrantDiscordWebhook\nBenefitGrantCustomWebhook\nBenefitGrantGitHubRepositoryWebhook\nBenefitGrantDownloadablesWebhook\nBenefitGrantLicenseKeysWebhook\nBenefitGrantMeterCreditWebhook\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nbenefit_grant.revoked\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "benefit_grant.revoked - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/benefit_grant.revoked",
    "html": "Benefit Grants\nbenefit_grant.revoked\nCopy page\n\nSent when a benefit grant is revoked.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"benefit_grant.revoked\"\nExamples:\n\n\"benefit_grant.revoked\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\nBenefitGrantDiscordWebhook\nBenefitGrantCustomWebhook\nBenefitGrantGitHubRepositoryWebhook\nBenefitGrantDownloadablesWebhook\nBenefitGrantLicenseKeysWebhook\nBenefitGrantMeterCreditWebhook\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nbenefit.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "benefit.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/benefit.created",
    "html": "Benefits\nbenefit.created\nCopy page\n\nSent when a new benefit is created.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"benefit.created\"\nExamples:\n\n\"benefit.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA benefit of type custom.\n\nUse it to grant any kind of benefit that doesn't fit in the other types.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nbenefit.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "benefit.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/benefit.updated",
    "html": "Benefits\nbenefit.updated\nCopy page\n\nSent when a benefit is updated.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"benefit.updated\"\nExamples:\n\n\"benefit.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA benefit of type custom.\n\nUse it to grant any kind of benefit that doesn't fit in the other types.\n\nBenefitCustom\nBenefitDiscord\nBenefitGitHubRepository\nBenefitDownloadables\nBenefitLicenseKeys\nBenefitMeterCredit\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nproduct.created\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "product.created - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/product.created",
    "html": "Products\nproduct.created\nCopy page\n\nSent when a new product is created.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"product.created\"\nExamples:\n\n\"product.created\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA product.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nproduct.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "product.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/product.updated",
    "html": "Products\nproduct.updated\nCopy page\n\nSent when a product is updated.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"product.updated\"\nExamples:\n\n\"product.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nA product.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\norganization.updated\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "organization.updated - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/organization.updated",
    "html": "Organization\norganization.updated\nCopy page\n\nSent when a organization is updated.\n\nDiscord & Slack support: Basic\n\n​\ntype\nstringrequired\nAllowed value: \"organization.updated\"\nExamples:\n\n\"organization.updated\"\n\n​\ntimestamp\nstring<date-time>required\n​\ndata\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nAuthorize\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Authorize - Polar",
    "url": "https://polar.sh/docs/api-reference/oauth2/connect/authorize",
    "html": "OpenID Connect\nAuthorize\nCopy page\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\noauth2\n/\nauthorize\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nResponse\n200 - application/json\n\nSuccessful Response\n\nAuthorizeResponseUser\nAuthorizeResponseOrganization\n​\nclient\nobjectrequired\n\nShow child attributes\n\n​\nsub_type\nstringrequired\nAllowed value: \"user\"\n​\nsub\nobject | nullrequired\n\nShow child attributes\n\n​\nscopes\nenum<string>[]required\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nRequest Token\nRequest an access token using a valid grant.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Request Token - Polar",
    "url": "https://polar.sh/docs/api-reference/oauth2/connect/request-token",
    "html": "OpenID Connect\nRequest Token\nCopy page\n\nRequest an access token using a valid grant.\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\noauth2\n/\ntoken\nTry it\nBody\napplication/x-www-form-urlencoded\nAuthorizationCodeTokenRequest\nRefreshTokenRequest\nWebTokenRequest\n​\ngrant_type\nstringrequired\nAllowed value: \"authorization_code\"\n​\nclient_id\nstringrequired\n​\nclient_secret\nstringrequired\n​\ncode\nstringrequired\n​\nredirect_uri\nstring<uri>required\nRequired string length: 1 - 2083\nResponse\n200 - application/json\n\nSuccessful Response\n\n​\naccess_token\nstringrequired\n​\ntoken_type\nstringrequired\nAllowed value: \"Bearer\"\n​\nexpires_in\nintegerrequired\n​\nrefresh_token\nstring | nullrequired\n​\nscope\nstringrequired\n​\nid_token\nstringrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nIntrospect Token\nGet information about an access token.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Introspect Token - Polar",
    "url": "https://polar.sh/docs/api-reference/oauth2/connect/introspect-token",
    "html": "OpenID Connect\nIntrospect Token\nCopy page\n\nGet information about an access token.\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\noauth2\n/\nintrospect\nTry it\nBody\napplication/x-www-form-urlencoded\n​\ntoken\nstringrequired\n​\nclient_id\nstringrequired\n​\nclient_secret\nstringrequired\n​\ntoken_type_hint\nenum<string> | null\nAvailable options: access_token, refresh_token \nResponse\n200 - application/json\n\nSuccessful Response\n\n​\nactive\nbooleanrequired\n​\nclient_id\nstringrequired\n​\ntoken_type\nenum<string>required\nAvailable options: access_token, refresh_token \n​\nscope\nstringrequired\n​\nsub_type\nenum<string>required\nAvailable options: user, organization \n​\nsub\nstringrequired\n​\naud\nstringrequired\n​\niss\nstringrequired\n​\nexp\nintegerrequired\n​\niat\nintegerrequired\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nRevoke Token\nRevoke an access token or a refresh token.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get User Info - Polar",
    "url": "https://polar.sh/docs/api-reference/oauth2/connect/get-user-info",
    "html": "OpenID Connect\nGet User Info\nCopy page\n\nGet information about the authenticated user.\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\noauth2\n/\nuserinfo\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nResponse\n200 - application/json\n\nSuccessful Response\n\nUserInfoUser\nUserInfoOrganization\n​\nsub\nstringrequired\n​\nname\nstring | null\n​\nemail\nstring | null\n​\nemail_verified\nboolean | null\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nCreate Webhook Endpoint\nCreate a webhook endpoint. **Scopes**: `webhooks:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Revoke Token - Polar",
    "url": "https://polar.sh/docs/api-reference/oauth2/connect/revoke-token",
    "html": "OpenID Connect\nRevoke Token\nCopy page\n\nRevoke an access token or a refresh token.\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\noauth2\n/\nrevoke\nTry it\nBody\napplication/x-www-form-urlencoded\n​\ntoken\nstringrequired\n​\nclient_id\nstringrequired\n​\nclient_secret\nstringrequired\n​\ntoken_type_hint\nenum<string> | null\nAvailable options: access_token, refresh_token \nResponse\n200 - application/json\n\nSuccessful Response\n\nThe response is of type object.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet User Info\nGet information about the authenticated user.\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Create Webhook Endpoint - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/endpoints/create",
    "html": "Webhooks\nCreate Webhook Endpoint\nCopy page\n\nCreate a webhook endpoint.\n\nScopes: webhooks:write\n\nPOST\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nwebhooks\n/\nendpoints\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nBody\napplication/json\n\nSchema to create a webhook endpoint.\n\n​\nurl\nstring<uri>required\n\nThe URL where the webhook events will be sent.\n\nRequired string length: 1 - 2083\nExamples:\n\n\"https://webhook.site/cb791d80-f26e-4f8c-be88-6e56054192b0\"\n\n​\nformat\nenum<string>required\n\nThe format of the webhook payload.\n\nAvailable options: raw, discord, slack \n​\nevents\nenum<string>[]required\n\nThe events that will trigger the webhook.\n\nShow child attributes\n\n​\nsecret\nstring | nulldeprecated\n\nThe secret used to sign the webhook events.\n\nMinimum length: 32\nExamples:\n\n\"polar_whs_ovyN6cPrTv56AApvzCaJno08SSmGJmgbWilb33N2JuK\"\n\n​\norganization_id\nstring<uuid4> | null\n\nThe organization ID associated with the webhook endpoint. Required unless you use an organization token.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\nResponse\n201\napplication/json\n\nWebhook endpoint created.\n\nA webhook endpoint.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nurl\nstring<uri>required\n\nThe URL where the webhook events will be sent.\n\nRequired string length: 1 - 2083\nExamples:\n\n\"https://webhook.site/cb791d80-f26e-4f8c-be88-6e56054192b0\"\n\n​\nformat\nenum<string>required\n\nThe format of the webhook payload.\n\nAvailable options: raw, discord, slack \n​\nsecret\nstringrequired\n\nThe secret used to sign the webhook events.\n\nExamples:\n\n\"polar_whs_ovyN6cPrTv56AApvzCaJno08SSmGJmgbWilb33N2JuK\"\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID associated with the webhook endpoint.\n\n​\nevents\nenum<string>[]required\n\nThe events that will trigger the webhook.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nGet Webhook Endpoint\nGet a webhook endpoint by ID. **Scopes**: `webhooks:read` `webhooks:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Get Webhook Endpoint - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/endpoints/get",
    "html": "Webhooks\nGet Webhook Endpoint\nCopy page\n\nGet a webhook endpoint by ID.\n\nScopes: webhooks:read webhooks:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nwebhooks\n/\nendpoints\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe webhook endpoint ID.\n\nResponse\n200\napplication/json\n\nSuccessful Response\n\nA webhook endpoint.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nurl\nstring<uri>required\n\nThe URL where the webhook events will be sent.\n\nRequired string length: 1 - 2083\nExamples:\n\n\"https://webhook.site/cb791d80-f26e-4f8c-be88-6e56054192b0\"\n\n​\nformat\nenum<string>required\n\nThe format of the webhook payload.\n\nAvailable options: raw, discord, slack \n​\nsecret\nstringrequired\n\nThe secret used to sign the webhook events.\n\nExamples:\n\n\"polar_whs_ovyN6cPrTv56AApvzCaJno08SSmGJmgbWilb33N2JuK\"\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID associated with the webhook endpoint.\n\n​\nevents\nenum<string>[]required\n\nThe events that will trigger the webhook.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nList Webhook Endpoints\nList webhook endpoints. **Scopes**: `webhooks:read` `webhooks:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "List Webhook Endpoints - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/endpoints/list",
    "html": "Webhooks\nList Webhook Endpoints\nCopy page\n\nList webhook endpoints.\n\nScopes: webhooks:read webhooks:write\n\nGET\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nwebhooks\n/\nendpoints\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nQuery Parameters\n​\norganization_id\nstring<uuid4> | null\nstring<uuid4>[] | null\n\nFilter by organization ID.\nThe organization ID.\n\nExamples:\n\n\"1dbfc517-0bbf-4301-9ba8-555ca42b9737\"\n\n​\npage\nintegerdefault:1\n\nPage number, defaults to 1.\n\nRequired range: x > 0\n​\nlimit\nintegerdefault:10\n\nSize of a page, defaults to 10. Maximum is 100.\n\nRequired range: x > 0\nResponse\n200\napplication/json\n\nSuccessful Response\n\n​\nitems\nWebhookEndpoint · object[]required\n\nShow child attributes\n\n​\npagination\nobjectrequired\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Webhook Endpoint\nUpdate a webhook endpoint. **Scopes**: `webhooks:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Delete Webhook Endpoint - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/endpoints/delete",
    "html": "Webhooks\nDelete Webhook Endpoint\nCopy page\n\nDelete a webhook endpoint.\n\nScopes: webhooks:write\n\nDELETE\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nwebhooks\n/\nendpoints\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe webhook endpoint ID.\n\nResponse\n204\n\nWebhook endpoint deleted.\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nUpdate Webhook Endpoint\nUpdate a webhook endpoint. **Scopes**: `webhooks:write`\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  },
  {
    "title": "Update Webhook Endpoint - Polar",
    "url": "https://polar.sh/docs/api-reference/webhooks/endpoints/update",
    "html": "Webhooks\nUpdate Webhook Endpoint\nCopy page\n\nUpdate a webhook endpoint.\n\nScopes: webhooks:write\n\nPATCH\nhttps://api.polar.sh\nhttps://sandbox-api.polar.sh\n/\nv1\n/\nwebhooks\n/\nendpoints\n/\n{id}\nTry it\nAuthorizations\n​\nAuthorization\nstringheaderrequired\n\nYou can generate an Organization Access Token from your organization's settings.\n\nPath Parameters\n​\nid\nstring<uuid4>required\n\nThe webhook endpoint ID.\n\nBody\napplication/json\n\nSchema to update a webhook endpoint.\n\n​\nurl\nstring<uri> | null\n\nThe URL where the webhook events will be sent.\n\nRequired string length: 1 - 2083\nExamples:\n\n\"https://webhook.site/cb791d80-f26e-4f8c-be88-6e56054192b0\"\n\n​\nsecret\nstring | nulldeprecated\n\nThe secret used to sign the webhook events.\n\nMinimum length: 32\nExamples:\n\n\"polar_whs_ovyN6cPrTv56AApvzCaJno08SSmGJmgbWilb33N2JuK\"\n\n​\nformat\nenum<string> | null\n\nThe format of the webhook payload.\n\nAvailable options: raw, discord, slack \n​\nevents\nenum<string>[] | null\n\nThe events that will trigger the webhook.\n\nShow child attributes\n\nResponse\n200\napplication/json\n\nWebhook endpoint updated.\n\nA webhook endpoint.\n\n​\ncreated_at\nstring<date-time>required\n\nCreation timestamp of the object.\n\n​\nmodified_at\nstring<date-time> | nullrequired\n\nLast modification timestamp of the object.\n\n​\nid\nstring<uuid4>required\n\nThe ID of the object.\n\n​\nurl\nstring<uri>required\n\nThe URL where the webhook events will be sent.\n\nRequired string length: 1 - 2083\nExamples:\n\n\"https://webhook.site/cb791d80-f26e-4f8c-be88-6e56054192b0\"\n\n​\nformat\nenum<string>required\n\nThe format of the webhook payload.\n\nAvailable options: raw, discord, slack \n​\nsecret\nstringrequired\n\nThe secret used to sign the webhook events.\n\nExamples:\n\n\"polar_whs_ovyN6cPrTv56AApvzCaJno08SSmGJmgbWilb33N2JuK\"\n\n​\norganization_id\nstring<uuid4>required\n\nThe organization ID associated with the webhook endpoint.\n\n​\nevents\nenum<string>[]required\n\nThe events that will trigger the webhook.\n\nShow child attributes\n\nWas this page helpful?\n\nYes\nNo\nPrevious\nDelete Webhook Endpoint\nDelete a webhook endpoint. **Scopes**: `webhooks:write`\nNext\n⌘I\nx\ngithub\ndiscord\nPowered by Mintlify"
  }
]
</file>

<file path="output/jobs/react-19.json">
[
  {
    "title": "React Reference Overview – React",
    "url": "https://react.dev/reference/react",
    "html": "API REFERENCE\nReact Reference Overview\n\nThis section provides detailed reference documentation for working with React. For an introduction to React, please visit the Learn section.\n\nThe React reference documentation is broken down into functional subsections:\n\nReact \n\nProgrammatic React features:\n\nHooks - Use different React features from your components.\nComponents - Built-in components that you can use in your JSX.\nAPIs - APIs that are useful for defining components.\nDirectives - Provide instructions to bundlers compatible with React Server Components.\nReact DOM \n\nReact-dom contains features that are only supported for web applications (which run in the browser DOM environment). This section is broken into the following:\n\nHooks - Hooks for web applications which run in the browser DOM environment.\nComponents - React supports all of the browser built-in HTML and SVG components.\nAPIs - The react-dom package contains methods supported only in web applications.\nClient APIs - The react-dom/client APIs let you render React components on the client (in the browser).\nServer APIs - The react-dom/server APIs let you render React components to HTML on the server.\nReact Compiler \n\nThe React Compiler is a build-time optimization tool that automatically memoizes your React components and values:\n\nConfiguration - Configuration options for React Compiler.\nDirectives - Function-level directives to control compilation.\nCompiling Libraries - Guide for shipping pre-compiled library code.\nESLint Plugin React Hooks \n\nThe ESLint plugin for React Hooks helps enforce the Rules of React:\n\nLints - Detailed documentation for each lint with examples.\nRules of React \n\nReact has idioms — or rules — for how to express patterns in a way that is easy to understand and yields high-quality applications:\n\nComponents and Hooks must be pure – Purity makes your code easier to understand, debug, and allows React to automatically optimize your components and hooks correctly.\nReact calls Components and Hooks – React is responsible for rendering components and hooks when necessary to optimize the user experience.\nRules of Hooks – Hooks are defined using JavaScript functions, but they represent a special type of reusable UI logic with restrictions on where they can be called.\nLegacy APIs \nLegacy APIs - Exported from the react package, but not recommended for use in newly written code.\nNEXT\nHooks"
  },
  {
    "title": "Built-in React Hooks – React",
    "url": "https://react.dev/reference/react/hooks",
    "html": "API REFERENCE\nBuilt-in React Hooks\n\nHooks let you use different React features from your components. You can either use the built-in Hooks or combine them to build your own. This page lists all built-in Hooks in React.\n\nState Hooks \n\nState lets a component “remember” information like user input. For example, a form component can use state to store the input value, while an image gallery component can use state to store the selected image index.\n\nTo add state to a component, use one of these Hooks:\n\nuseState declares a state variable that you can update directly.\nuseReducer declares a state variable with the update logic inside a reducer function.\nfunction ImageGallery() {\n\n  const [index, setIndex] = useState(0);\n\n  // ...\nContext Hooks \n\nContext lets a component receive information from distant parents without passing it as props. For example, your app’s top-level component can pass the current UI theme to all components below, no matter how deep.\n\nuseContext reads and subscribes to a context.\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\nRef Hooks \n\nRefs let a component hold some information that isn’t used for rendering, like a DOM node or a timeout ID. Unlike with state, updating a ref does not re-render your component. Refs are an “escape hatch” from the React paradigm. They are useful when you need to work with non-React systems, such as the built-in browser APIs.\n\nuseRef declares a ref. You can hold any value in it, but most often it’s used to hold a DOM node.\nuseImperativeHandle lets you customize the ref exposed by your component. This is rarely used.\nfunction Form() {\n\n  const inputRef = useRef(null);\n\n  // ...\nEffect Hooks \n\nEffects let a component connect to and synchronize with external systems. This includes dealing with network, browser DOM, animations, widgets written using a different UI library, and other non-React code.\n\nuseEffect connects a component to an external system.\nfunction ChatRoom({ roomId }) {\n\n  useEffect(() => {\n\n    const connection = createConnection(roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]);\n\n  // ...\n\nEffects are an “escape hatch” from the React paradigm. Don’t use Effects to orchestrate the data flow of your application. If you’re not interacting with an external system, you might not need an Effect.\n\nThere are two rarely used variations of useEffect with differences in timing:\n\nuseLayoutEffect fires before the browser repaints the screen. You can measure layout here.\nuseInsertionEffect fires before React makes changes to the DOM. Libraries can insert dynamic CSS here.\nPerformance Hooks \n\nA common way to optimize re-rendering performance is to skip unnecessary work. For example, you can tell React to reuse a cached calculation or to skip a re-render if the data has not changed since the previous render.\n\nTo skip calculations and unnecessary re-rendering, use one of these Hooks:\n\nuseMemo lets you cache the result of an expensive calculation.\nuseCallback lets you cache a function definition before passing it down to an optimized component.\nfunction TodoList({ todos, tab, theme }) {\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  // ...\n\n}\n\nSometimes, you can’t skip re-rendering because the screen actually needs to update. In that case, you can improve performance by separating blocking updates that must be synchronous (like typing into an input) from non-blocking updates which don’t need to block the user interface (like updating a chart).\n\nTo prioritize rendering, use one of these Hooks:\n\nuseTransition lets you mark a state transition as non-blocking and allow other updates to interrupt it.\nuseDeferredValue lets you defer updating a non-critical part of the UI and let other parts update first.\nOther Hooks \n\nThese Hooks are mostly useful to library authors and aren’t commonly used in the application code.\n\nuseDebugValue lets you customize the label React DevTools displays for your custom Hook.\nuseId lets a component associate a unique ID with itself. Typically used with accessibility APIs.\nuseSyncExternalStore lets a component subscribe to an external store.\nuseActionState allows you to manage state of actions.\nYour own Hooks \n\nYou can also define your own custom Hooks as JavaScript functions.\n\nPREVIOUS\nOverview\nNEXT\nuseActionState"
  },
  {
    "title": "useActionState – React",
    "url": "https://react.dev/reference/react/useActionState",
    "html": "API REFERENCE\nHOOKS\nuseActionState\n\nuseActionState is a Hook that allows you to update state based on the result of a form action.\n\nconst [state, formAction, isPending] = useActionState(fn, initialState, permalink?);\nNote\n\nIn earlier React Canary versions, this API was part of React DOM and called useFormState.\n\nReference\nuseActionState(action, initialState, permalink?)\nUsage\nUsing information returned by a form action\nTroubleshooting\nMy action can no longer read the submitted form data\nReference \nuseActionState(action, initialState, permalink?) \n\nCall useActionState at the top level of your component to create component state that is updated when a form action is invoked. You pass useActionState an existing form action function as well as an initial state, and it returns a new action that you use in your form, along with the latest form state and whether the Action is still pending. The latest form state is also passed to the function that you provided.\n\nimport { useActionState } from \"react\";\n\n\n\nasync function increment(previousState, formData) {\n\n  return previousState + 1;\n\n}\n\n\n\nfunction StatefulForm({}) {\n\n  const [state, formAction] = useActionState(increment, 0);\n\n  return (\n\n    <form>\n\n      {state}\n\n      <button formAction={formAction}>Increment</button>\n\n    </form>\n\n  )\n\n}\n\nThe form state is the value returned by the action when the form was last submitted. If the form has not yet been submitted, it is the initial state that you pass.\n\nIf used with a Server Function, useActionState allows the server’s response from submitting the form to be shown even before hydration has completed.\n\nSee more examples below.\n\nParameters \nfn: The function to be called when the form is submitted or button pressed. When the function is called, it will receive the previous state of the form (initially the initialState that you pass, subsequently its previous return value) as its initial argument, followed by the arguments that a form action normally receives.\ninitialState: The value you want the state to be initially. It can be any serializable value. This argument is ignored after the action is first invoked.\noptional permalink: A string containing the unique page URL that this form modifies. For use on pages with dynamic content (eg: feeds) in conjunction with progressive enhancement: if fn is a server function and the form is submitted before the JavaScript bundle loads, the browser will navigate to the specified permalink URL, rather than the current page’s URL. Ensure that the same form component is rendered on the destination page (including the same action fn and permalink) so that React knows how to pass the state through. Once the form has been hydrated, this parameter has no effect.\nReturns \n\nuseActionState returns an array with the following values:\n\nThe current state. During the first render, it will match the initialState you have passed. After the action is invoked, it will match the value returned by the action.\nA new action that you can pass as the action prop to your form component or formAction prop to any button component within the form. The action can also be called manually within startTransition.\nThe isPending flag that tells you whether there is a pending Transition.\nCaveats \nWhen used with a framework that supports React Server Components, useActionState lets you make forms interactive before JavaScript has executed on the client. When used without Server Components, it is equivalent to component local state.\nThe function passed to useActionState receives an extra argument, the previous or initial state, as its first argument. This makes its signature different than if it were used directly as a form action without using useActionState.\nUsage \nUsing information returned by a form action \n\nCall useActionState at the top level of your component to access the return value of an action from the last time a form was submitted.\n\nimport { useActionState } from 'react';\n\nimport { action } from './actions.js';\n\n\n\nfunction MyComponent() {\n\n  const [state, formAction] = useActionState(action, null);\n\n  // ...\n\n  return (\n\n    <form action={formAction}>\n\n      {/* ... */}\n\n    </form>\n\n  );\n\n}\n\nuseActionState returns an array with the following items:\n\nThe current state of the form, which is initially set to the initial state you provided, and after the form is submitted is set to the return value of the action you provided.\nA new action that you pass to <form> as its action prop or call manually within startTransition.\nA pending state that you can utilise while your action is processing.\n\nWhen the form is submitted, the action function that you provided will be called. Its return value will become the new current state of the form.\n\nThe action that you provide will also receive a new first argument, namely the current state of the form. The first time the form is submitted, this will be the initial state you provided, while with subsequent submissions, it will be the return value from the last time the action was called. The rest of the arguments are the same as if useActionState had not been used.\n\nfunction action(currentState, formData) {\n\n  // ...\n\n  return 'next state';\n\n}\nDisplay information after submitting a form\n1. Display form errors\n2. Display structured information after submitting a form\nExample 1 of 2: Display form errors \n\nTo display messages such as an error message or toast that’s returned by a Server Function, wrap the action in a call to useActionState.\n\nApp.js\nactions.js\nReload\nClear\nFork\nimport { useActionState, useState } from \"react\";\nimport { addToCart } from \"./actions.js\";\n\nfunction AddToCartForm({itemID, itemTitle}) {\n  const [message, formAction, isPending] = useActionState(addToCart, null);\n  return (\n    <form action={formAction}>\n      <h2>{itemTitle}</h2>\n      <input type=\"hidden\" name=\"itemID\" value={itemID} />\n      <button type=\"submit\">Add to Cart</button>\n      {isPending ? \"Loading...\" : message}\n    </form>\n  );\n}\n\nexport default function App() {\n  return (\n    <>\n      <AddToCartForm itemID=\"1\" itemTitle=\"JavaScript: The Definitive Guide\" />\n      <AddToCartForm itemID=\"2\" itemTitle=\"JavaScript: The Good Parts\" />\n    </>\n  )\n}\n\n\nShow more\nNext Example\nTroubleshooting \nMy action can no longer read the submitted form data \n\nWhen you wrap an action with useActionState, it gets an extra argument as its first argument. The submitted form data is therefore its second argument instead of its first as it would usually be. The new first argument that gets added is the current state of the form.\n\nfunction action(currentState, formData) {\n\n  // ...\n\n}\nPREVIOUS\nHooks\nNEXT\nuseCallback"
  },
  {
    "title": "useCallback – React",
    "url": "https://react.dev/reference/react/useCallback",
    "html": "API REFERENCE\nHOOKS\nuseCallback\n\nuseCallback is a React Hook that lets you cache a function definition between re-renders.\n\nconst cachedFn = useCallback(fn, dependencies)\nNote\n\nReact Compiler automatically memoizes values and functions, reducing the need for manual useCallback calls. You can use the compiler to handle memoization automatically.\n\nReference\nuseCallback(fn, dependencies)\nUsage\nSkipping re-rendering of components\nUpdating state from a memoized callback\nPreventing an Effect from firing too often\nOptimizing a custom Hook\nTroubleshooting\nEvery time my component renders, useCallback returns a different function\nI need to call useCallback for each list item in a loop, but it’s not allowed\nReference \nuseCallback(fn, dependencies) \n\nCall useCallback at the top level of your component to cache a function definition between re-renders:\n\nimport { useCallback } from 'react';\n\n\n\nexport default function ProductPage({ productId, referrer, theme }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]);\n\nSee more examples below.\n\nParameters \n\nfn: The function value that you want to cache. It can take any arguments and return any values. React will return (not call!) your function back to you during the initial render. On next renders, React will give you the same function again if the dependencies have not changed since the last render. Otherwise, it will give you the function that you have passed during the current render, and store it in case it can be reused later. React will not call your function. The function is returned to you so you can decide when and whether to call it.\n\ndependencies: The list of all reactive values referenced inside of the fn code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison algorithm.\n\nReturns \n\nOn the initial render, useCallback returns the fn function you have passed.\n\nDuring subsequent renders, it will either return an already stored fn function from the last render (if the dependencies haven’t changed), or return the fn function you have passed during this render.\n\nCaveats \nuseCallback is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nReact will not throw away the cached function unless there is a specific reason to do that. For example, in development, React throws away the cache when you edit the file of your component. Both in development and in production, React will throw away the cache if your component suspends during the initial mount. In the future, React may add more features that take advantage of throwing away the cache—for example, if React adds built-in support for virtualized lists in the future, it would make sense to throw away the cache for items that scroll out of the virtualized table viewport. This should match your expectations if you rely on useCallback as a performance optimization. Otherwise, a state variable or a ref may be more appropriate.\nUsage \nSkipping re-rendering of components \n\nWhen you optimize rendering performance, you will sometimes need to cache the functions that you pass to child components. Let’s first look at the syntax for how to do this, and then see in which cases it’s useful.\n\nTo cache a function between re-renders of your component, wrap its definition into the useCallback Hook:\n\nimport { useCallback } from 'react';\n\n\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]);\n\n  // ...\n\nYou need to pass two things to useCallback:\n\nA function definition that you want to cache between re-renders.\nA list of dependencies including every value within your component that’s used inside your function.\n\nOn the initial render, the returned function you’ll get from useCallback will be the function you passed.\n\nOn the following renders, React will compare the dependencies with the dependencies you passed during the previous render. If none of the dependencies have changed (compared with Object.is), useCallback will return the same function as before. Otherwise, useCallback will return the function you passed on this render.\n\nIn other words, useCallback caches a function between re-renders until its dependencies change.\n\nLet’s walk through an example to see when this is useful.\n\nSay you’re passing a handleSubmit function down from the ProductPage to the ShippingForm component:\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  // ...\n\n  return (\n\n    <div className={theme}>\n\n      <ShippingForm onSubmit={handleSubmit} />\n\n    </div>\n\n  );\n\nYou’ve noticed that toggling the theme prop freezes the app for a moment, but if you remove <ShippingForm /> from your JSX, it feels fast. This tells you that it’s worth trying to optimize the ShippingForm component.\n\nBy default, when a component re-renders, React re-renders all of its children recursively. This is why, when ProductPage re-renders with a different theme, the ShippingForm component also re-renders. This is fine for components that don’t require much calculation to re-render. But if you verified a re-render is slow, you can tell ShippingForm to skip re-rendering when its props are the same as on last render by wrapping it in memo:\n\nimport { memo } from 'react';\n\n\n\nconst ShippingForm = memo(function ShippingForm({ onSubmit }) {\n\n  // ...\n\n});\n\nWith this change, ShippingForm will skip re-rendering if all of its props are the same as on the last render. This is when caching a function becomes important! Let’s say you defined handleSubmit without useCallback:\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  // Every time the theme changes, this will be a different function...\n\n  function handleSubmit(orderDetails) {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }\n\n\n\n  return (\n\n    <div className={theme}>\n\n      {/* ... so ShippingForm's props will never be the same, and it will re-render every time */}\n\n      <ShippingForm onSubmit={handleSubmit} />\n\n    </div>\n\n  );\n\n}\n\nIn JavaScript, a function () {} or () => {} always creates a different function, similar to how the {} object literal always creates a new object. Normally, this wouldn’t be a problem, but it means that ShippingForm props will never be the same, and your memo optimization won’t work. This is where useCallback comes in handy:\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  // Tell React to cache your function between re-renders...\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]); // ...so as long as these dependencies don't change...\n\n\n\n  return (\n\n    <div className={theme}>\n\n      {/* ...ShippingForm will receive the same props and can skip re-rendering */}\n\n      <ShippingForm onSubmit={handleSubmit} />\n\n    </div>\n\n  );\n\n}\n\nBy wrapping handleSubmit in useCallback, you ensure that it’s the same function between the re-renders (until dependencies change). You don’t have to wrap a function in useCallback unless you do it for some specific reason. In this example, the reason is that you pass it to a component wrapped in memo, and this lets it skip re-rendering. There are other reasons you might need useCallback which are described further on this page.\n\nNote\n\nYou should only rely on useCallback as a performance optimization. If your code doesn’t work without it, find the underlying problem and fix it first. Then you may add useCallback back.\n\nDEEP DIVE\nHow is useCallback related to useMemo? \nShow Details\nDEEP DIVE\nShould you add useCallback everywhere? \nShow Details\nThe difference between useCallback and declaring a function directly\n1. Skipping re-rendering with useCallback and memo\n2. Always re-rendering a component\nExample 1 of 2: Skipping re-rendering with useCallback and memo \n\nIn this example, the ShippingForm component is artificially slowed down so that you can see what happens when a React component you’re rendering is genuinely slow. Try incrementing the counter and toggling the theme.\n\nIncrementing the counter feels slow because it forces the slowed down ShippingForm to re-render. That’s expected because the counter has changed, and so you need to reflect the user’s new choice on the screen.\n\nNext, try toggling the theme. Thanks to useCallback together with memo, it’s fast despite the artificial slowdown! ShippingForm skipped re-rendering because the handleSubmit function has not changed. The handleSubmit function has not changed because both productId and referrer (your useCallback dependencies) haven’t changed since last render.\n\nApp.js\nProductPage.js\nShippingForm.js\nReload\nClear\nFork\nimport { useCallback } from 'react';\nimport ShippingForm from './ShippingForm.js';\n\nexport default function ProductPage({ productId, referrer, theme }) {\n  const handleSubmit = useCallback((orderDetails) => {\n    post('/product/' + productId + '/buy', {\n      referrer,\n      orderDetails,\n    });\n  }, [productId, referrer]);\n\n  return (\n    <div className={theme}>\n      <ShippingForm onSubmit={handleSubmit} />\n    </div>\n  );\n}\n\nfunction post(url, data) {\n  // Imagine this sends a request...\n  console.log('POST /' + url);\n  console.log(data);\n}\n\n\nShow more\nNext Example\nUpdating state from a memoized callback \n\nSometimes, you might need to update state based on previous state from a memoized callback.\n\nThis handleAddTodo function specifies todos as a dependency because it computes the next todos from it:\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState([]);\n\n\n\n  const handleAddTodo = useCallback((text) => {\n\n    const newTodo = { id: nextId++, text };\n\n    setTodos([...todos, newTodo]);\n\n  }, [todos]);\n\n  // ...\n\nYou’ll usually want memoized functions to have as few dependencies as possible. When you read some state only to calculate the next state, you can remove that dependency by passing an updater function instead:\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState([]);\n\n\n\n  const handleAddTodo = useCallback((text) => {\n\n    const newTodo = { id: nextId++, text };\n\n    setTodos(todos => [...todos, newTodo]);\n\n  }, []); // ✅ No need for the todos dependency\n\n  // ...\n\nHere, instead of making todos a dependency and reading it inside, you pass an instruction about how to update the state (todos => [...todos, newTodo]) to React. Read more about updater functions.\n\nPreventing an Effect from firing too often \n\nSometimes, you might want to call a function from inside an Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  function createOptions() {\n\n    return {\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    };\n\n  }\n\n\n\n  useEffect(() => {\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    // ...\n\nThis creates a problem. Every reactive value must be declared as a dependency of your Effect. However, if you declare createOptions as a dependency, it will cause your Effect to constantly reconnect to the chat room:\n\n  useEffect(() => {\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [createOptions]); // 🔴 Problem: This dependency changes on every render\n\n  // ...\n\nTo solve this, you can wrap the function you need to call from an Effect into useCallback:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const createOptions = useCallback(() => {\n\n    return {\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    };\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n\n\n  useEffect(() => {\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [createOptions]); // ✅ Only changes when createOptions changes\n\n  // ...\n\nThis ensures that the createOptions function is the same between re-renders if the roomId is the same. However, it’s even better to remove the need for a function dependency. Move your function inside the Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  useEffect(() => {\n\n    function createOptions() { // ✅ No need for useCallback or function dependencies!\n\n      return {\n\n        serverUrl: 'https://localhost:1234',\n\n        roomId: roomId\n\n      };\n\n    }\n\n\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n  // ...\n\nNow your code is simpler and doesn’t need useCallback. Learn more about removing Effect dependencies.\n\nOptimizing a custom Hook \n\nIf you’re writing a custom Hook, it’s recommended to wrap any functions that it returns into useCallback:\n\nfunction useRouter() {\n\n  const { dispatch } = useContext(RouterStateContext);\n\n\n\n  const navigate = useCallback((url) => {\n\n    dispatch({ type: 'navigate', url });\n\n  }, [dispatch]);\n\n\n\n  const goBack = useCallback(() => {\n\n    dispatch({ type: 'back' });\n\n  }, [dispatch]);\n\n\n\n  return {\n\n    navigate,\n\n    goBack,\n\n  };\n\n}\n\nThis ensures that the consumers of your Hook can optimize their own code when needed.\n\nTroubleshooting \nEvery time my component renders, useCallback returns a different function \n\nMake sure you’ve specified the dependency array as a second argument!\n\nIf you forget the dependency array, useCallback will return a new function every time:\n\nfunction ProductPage({ productId, referrer }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }); // 🔴 Returns a new function every time: no dependency array\n\n  // ...\n\nThis is the corrected version passing the dependency array as a second argument:\n\nfunction ProductPage({ productId, referrer }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]); // ✅ Does not return a new function unnecessarily\n\n  // ...\n\nIf this doesn’t help, then the problem is that at least one of your dependencies is different from the previous render. You can debug this problem by manually logging your dependencies to the console:\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    // ..\n\n  }, [productId, referrer]);\n\n\n\n  console.log([productId, referrer]);\n\nYou can then right-click on the arrays from different re-renders in the console and select “Store as a global variable” for both of them. Assuming the first one got saved as temp1 and the second one got saved as temp2, you can then use the browser console to check whether each dependency in both arrays is the same:\n\nObject.is(temp1[0], temp2[0]); // Is the first dependency the same between the arrays?\n\nObject.is(temp1[1], temp2[1]); // Is the second dependency the same between the arrays?\n\nObject.is(temp1[2], temp2[2]); // ... and so on for every dependency ...\n\nWhen you find which dependency is breaking memoization, either find a way to remove it, or memoize it as well.\n\nI need to call useCallback for each list item in a loop, but it’s not allowed \n\nSuppose the Chart component is wrapped in memo. You want to skip re-rendering every Chart in the list when the ReportList component re-renders. However, you can’t call useCallback in a loop:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item => {\n\n        // 🔴 You can't call useCallback in a loop like this:\n\n        const handleClick = useCallback(() => {\n\n          sendReport(item)\n\n        }, [item]);\n\n\n\n        return (\n\n          <figure key={item.id}>\n\n            <Chart onClick={handleClick} />\n\n          </figure>\n\n        );\n\n      })}\n\n    </article>\n\n  );\n\n}\n\nInstead, extract a component for an individual item, and put useCallback there:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item =>\n\n        <Report key={item.id} item={item} />\n\n      )}\n\n    </article>\n\n  );\n\n}\n\n\n\nfunction Report({ item }) {\n\n  // ✅ Call useCallback at the top level:\n\n  const handleClick = useCallback(() => {\n\n    sendReport(item)\n\n  }, [item]);\n\n\n\n  return (\n\n    <figure>\n\n      <Chart onClick={handleClick} />\n\n    </figure>\n\n  );\n\n}\n\nAlternatively, you could remove useCallback in the last snippet and instead wrap Report itself in memo. If the item prop does not change, Report will skip re-rendering, so Chart will skip re-rendering too:\n\nfunction ReportList({ items }) {\n\n  // ...\n\n}\n\n\n\nconst Report = memo(function Report({ item }) {\n\n  function handleClick() {\n\n    sendReport(item);\n\n  }\n\n\n\n  return (\n\n    <figure>\n\n      <Chart onClick={handleClick} />\n\n    </figure>\n\n  );\n\n});\nPREVIOUS\nuseActionState\nNEXT\nuseContext"
  },
  {
    "title": "useContext – React",
    "url": "https://react.dev/reference/react/useContext",
    "html": "API REFERENCE\nHOOKS\nuseContext\n\nuseContext is a React Hook that lets you read and subscribe to context from your component.\n\nconst value = useContext(SomeContext)\nReference\nuseContext(SomeContext)\nUsage\nPassing data deeply into the tree\nUpdating data passed via context\nSpecifying a fallback default value\nOverriding context for a part of the tree\nOptimizing re-renders when passing objects and functions\nTroubleshooting\nMy component doesn’t see the value from my provider\nI am always getting undefined from my context although the default value is different\nReference \nuseContext(SomeContext) \n\nCall useContext at the top level of your component to read and subscribe to context.\n\nimport { useContext } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\nSee more examples below.\n\nParameters \nSomeContext: The context that you’ve previously created with createContext. The context itself does not hold the information, it only represents the kind of information you can provide or read from components.\nReturns \n\nuseContext returns the context value for the calling component. It is determined as the value passed to the closest SomeContext above the calling component in the tree. If there is no such provider, then the returned value will be the defaultValue you have passed to createContext for that context. The returned value is always up-to-date. React automatically re-renders components that read some context if it changes.\n\nCaveats \nuseContext() call in a component is not affected by providers returned from the same component. The corresponding <Context> needs to be above the component doing the useContext() call.\nReact automatically re-renders all the children that use a particular context starting from the provider that receives a different value. The previous and the next values are compared with the Object.is comparison. Skipping re-renders with memo does not prevent the children receiving fresh context values.\nIf your build system produces duplicates modules in the output (which can happen with symlinks), this can break context. Passing something via context only works if SomeContext that you use to provide context and SomeContext that you use to read it are exactly the same object, as determined by a === comparison.\nUsage \nPassing data deeply into the tree \n\nCall useContext at the top level of your component to read and subscribe to context.\n\nimport { useContext } from 'react';\n\n\n\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\nuseContext returns the context value for the context you passed. To determine the context value, React searches the component tree and finds the closest context provider above for that particular context.\n\nTo pass context to a Button, wrap it or one of its parent components into the corresponding context provider:\n\nfunction MyPage() {\n\n  return (\n\n    <ThemeContext value=\"dark\">\n\n      <Form />\n\n    </ThemeContext>\n\n  );\n\n}\n\n\n\nfunction Form() {\n\n  // ... renders buttons inside ...\n\n}\n\nIt doesn’t matter how many layers of components there are between the provider and the Button. When a Button anywhere inside of Form calls useContext(ThemeContext), it will receive \"dark\" as the value.\n\nPitfall\n\nuseContext() always looks for the closest provider above the component that calls it. It searches upwards and does not consider providers in the component from which you’re calling useContext().\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nUpdating data passed via context \n\nOften, you’ll want the context to change over time. To update context, combine it with state. Declare a state variable in the parent component, and pass the current state down as the context value to the provider.\n\nfunction MyPage() {\n\n  const [theme, setTheme] = useState('dark');\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <Form />\n\n      <Button onClick={() => {\n\n        setTheme('light');\n\n      }}>\n\n        Switch to light theme\n\n      </Button>\n\n    </ThemeContext>\n\n  );\n\n}\n\nNow any Button inside of the provider will receive the current theme value. If you call setTheme to update the theme value that you pass to the provider, all Button components will re-render with the new 'light' value.\n\nExamples of updating context\n1. Updating a value via context\n2. Updating an object via context\n3. Multiple contexts\n4. Extracting providers to a component\n5. Scaling up with context and a reducer\nExample 1 of 5: Updating a value via context \n\nIn this example, the MyApp component holds a state variable which is then passed to the ThemeContext provider. Checking the “Dark mode” checkbox updates the state. Changing the provided value re-renders all the components using that context.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext, useState } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  const [theme, setTheme] = useState('light');\n  return (\n    <ThemeContext value={theme}>\n      <Form />\n      <label>\n        <input\n          type=\"checkbox\"\n          checked={theme === 'dark'}\n          onChange={(e) => {\n            setTheme(e.target.checked ? 'dark' : 'light')\n          }}\n        />\n        Use dark mode\n      </label>\n    </ThemeContext>\n  )\n}\n\nfunction Form({ children }) {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\n\nNote that value=\"dark\" passes the \"dark\" string, but value={theme} passes the value of the JavaScript theme variable with JSX curly braces. Curly braces also let you pass context values that aren’t strings.\n\nNext Example\nSpecifying a fallback default value \n\nIf React can’t find any providers of that particular context in the parent tree, the context value returned by useContext() will be equal to the default value that you specified when you created that context:\n\nconst ThemeContext = createContext(null);\n\nThe default value never changes. If you want to update context, use it with state as described above.\n\nOften, instead of null, there is some more meaningful value you can use as a default, for example:\n\nconst ThemeContext = createContext('light');\n\nThis way, if you accidentally render some component without a corresponding provider, it won’t break. This also helps your components work well in a test environment without setting up a lot of providers in the tests.\n\nIn the example below, the “Toggle theme” button is always light because it’s outside any theme context provider and the default context theme value is 'light'. Try editing the default theme to be 'dark'.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext, useState } from 'react';\n\nconst ThemeContext = createContext('light');\n\nexport default function MyApp() {\n  const [theme, setTheme] = useState('light');\n  return (\n    <>\n      <ThemeContext value={theme}>\n        <Form />\n      </ThemeContext>\n      <Button onClick={() => {\n        setTheme(theme === 'dark' ? 'light' : 'dark');\n      }}>\n        Toggle theme\n      </Button>\n    </>\n  )\n}\n\nfunction Form({ children }) {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children, onClick }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className} onClick={onClick}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nOverriding context for a part of the tree \n\nYou can override the context for a part of the tree by wrapping that part in a provider with a different value.\n\n<ThemeContext value=\"dark\">\n\n  ...\n\n  <ThemeContext value=\"light\">\n\n    <Footer />\n\n  </ThemeContext>\n\n  ...\n\n</ThemeContext>\n\nYou can nest and override providers as many times as you need.\n\nExamples of overriding context\n1. Overriding a theme\n2. Automatically nested headings\nExample 1 of 2: Overriding a theme \n\nHere, the button inside the Footer receives a different context value (\"light\") than the buttons outside (\"dark\").\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n      <ThemeContext value=\"light\">\n        <Footer />\n      </ThemeContext>\n    </Panel>\n  );\n}\n\nfunction Footer() {\n  return (\n    <footer>\n      <Button>Settings</Button>\n    </footer>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      {title && <h1>{title}</h1>}\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nNext Example\nOptimizing re-renders when passing objects and functions \n\nYou can pass any values via context, including objects and functions.\n\nfunction MyApp() {\n\n  const [currentUser, setCurrentUser] = useState(null);\n\n\n\n  function login(response) {\n\n    storeCredentials(response.credentials);\n\n    setCurrentUser(response.user);\n\n  }\n\n\n\n  return (\n\n    <AuthContext value={{ currentUser, login }}>\n\n      <Page />\n\n    </AuthContext>\n\n  );\n\n}\n\nHere, the context value is a JavaScript object with two properties, one of which is a function. Whenever MyApp re-renders (for example, on a route update), this will be a different object pointing at a different function, so React will also have to re-render all components deep in the tree that call useContext(AuthContext).\n\nIn smaller apps, this is not a problem. However, there is no need to re-render them if the underlying data, like currentUser, has not changed. To help React take advantage of that fact, you may wrap the login function with useCallback and wrap the object creation into useMemo. This is a performance optimization:\n\nimport { useCallback, useMemo } from 'react';\n\n\n\nfunction MyApp() {\n\n  const [currentUser, setCurrentUser] = useState(null);\n\n\n\n  const login = useCallback((response) => {\n\n    storeCredentials(response.credentials);\n\n    setCurrentUser(response.user);\n\n  }, []);\n\n\n\n  const contextValue = useMemo(() => ({\n\n    currentUser,\n\n    login\n\n  }), [currentUser, login]);\n\n\n\n  return (\n\n    <AuthContext value={contextValue}>\n\n      <Page />\n\n    </AuthContext>\n\n  );\n\n}\n\nAs a result of this change, even if MyApp needs to re-render, the components calling useContext(AuthContext) won’t need to re-render unless currentUser has changed.\n\nRead more about useMemo and useCallback.\n\nTroubleshooting \nMy component doesn’t see the value from my provider \n\nThere are a few common ways that this can happen:\n\nYou’re rendering <SomeContext> in the same component (or below) as where you’re calling useContext(). Move <SomeContext> above and outside the component calling useContext().\nYou may have forgotten to wrap your component with <SomeContext>, or you might have put it in a different part of the tree than you thought. Check whether the hierarchy is right using React DevTools.\nYou might be running into some build issue with your tooling that causes SomeContext as seen from the providing component and SomeContext as seen by the reading component to be two different objects. This can happen if you use symlinks, for example. You can verify this by assigning them to globals like window.SomeContext1 and window.SomeContext2 and then checking whether window.SomeContext1 === window.SomeContext2 in the console. If they’re not the same, fix that issue on the build tool level.\nI am always getting undefined from my context although the default value is different \n\nYou might have a provider without a value in the tree:\n\n// 🚩 Doesn't work: no value prop\n\n<ThemeContext>\n\n   <Button />\n\n</ThemeContext>\n\nIf you forget to specify value, it’s like passing value={undefined}.\n\nYou may have also mistakingly used a different prop name by mistake:\n\n// 🚩 Doesn't work: prop should be called \"value\"\n\n<ThemeContext theme={theme}>\n\n   <Button />\n\n</ThemeContext>\n\nIn both of these cases you should see a warning from React in the console. To fix them, call the prop value:\n\n// ✅ Passing the value prop\n\n<ThemeContext value={theme}>\n\n   <Button />\n\n</ThemeContext>\n\nNote that the default value from your createContext(defaultValue) call is only used if there is no matching provider above at all. If there is a <SomeContext value={undefined}> component somewhere in the parent tree, the component calling useContext(SomeContext) will receive undefined as the context value.\n\nPREVIOUS\nuseCallback\nNEXT\nuseDebugValue"
  },
  {
    "title": "useDebugValue – React",
    "url": "https://react.dev/reference/react/useDebugValue",
    "html": "API REFERENCE\nHOOKS\nuseDebugValue\n\nuseDebugValue is a React Hook that lets you add a label to a custom Hook in React DevTools.\n\nuseDebugValue(value, format?)\nReference\nuseDebugValue(value, format?)\nUsage\nAdding a label to a custom Hook\nDeferring formatting of a debug value\nReference \nuseDebugValue(value, format?) \n\nCall useDebugValue at the top level of your custom Hook to display a readable debug value:\n\nimport { useDebugValue } from 'react';\n\n\n\nfunction useOnlineStatus() {\n\n  // ...\n\n  useDebugValue(isOnline ? 'Online' : 'Offline');\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \nvalue: The value you want to display in React DevTools. It can have any type.\noptional format: A formatting function. When the component is inspected, React DevTools will call the formatting function with the value as the argument, and then display the returned formatted value (which may have any type). If you don’t specify the formatting function, the original value itself will be displayed.\nReturns \n\nuseDebugValue does not return anything.\n\nUsage \nAdding a label to a custom Hook \n\nCall useDebugValue at the top level of your custom Hook to display a readable debug value for React DevTools.\n\nimport { useDebugValue } from 'react';\n\n\n\nfunction useOnlineStatus() {\n\n  // ...\n\n  useDebugValue(isOnline ? 'Online' : 'Offline');\n\n  // ...\n\n}\n\nThis gives components calling useOnlineStatus a label like OnlineStatus: \"Online\" when you inspect them:\n\nWithout the useDebugValue call, only the underlying data (in this example, true) would be displayed.\n\nApp.js\nuseOnlineStatus.js\nReload\nClear\nFork\nimport { useSyncExternalStore, useDebugValue } from 'react';\n\nexport function useOnlineStatus() {\n  const isOnline = useSyncExternalStore(subscribe, () => navigator.onLine, () => true);\n  useDebugValue(isOnline ? 'Online' : 'Offline');\n  return isOnline;\n}\n\nfunction subscribe(callback) {\n  window.addEventListener('online', callback);\n  window.addEventListener('offline', callback);\n  return () => {\n    window.removeEventListener('online', callback);\n    window.removeEventListener('offline', callback);\n  };\n}\n\n\nShow more\nNote\n\nDon’t add debug values to every custom Hook. It’s most valuable for custom Hooks that are part of shared libraries and that have a complex internal data structure that’s difficult to inspect.\n\nDeferring formatting of a debug value \n\nYou can also pass a formatting function as the second argument to useDebugValue:\n\nuseDebugValue(date, date => date.toDateString());\n\nYour formatting function will receive the debug value as a parameter and should return a formatted display value. When your component is inspected, React DevTools will call this function and display its result.\n\nThis lets you avoid running potentially expensive formatting logic unless the component is actually inspected. For example, if date is a Date value, this avoids calling toDateString() on it for every render.\n\nPREVIOUS\nuseContext\nNEXT\nuseDeferredValue"
  },
  {
    "title": "useDeferredValue – React",
    "url": "https://react.dev/reference/react/useDeferredValue",
    "html": "API REFERENCE\nHOOKS\nuseDeferredValue\n\nuseDeferredValue is a React Hook that lets you defer updating a part of the UI.\n\nconst deferredValue = useDeferredValue(value)\nReference\nuseDeferredValue(value, initialValue?)\nUsage\nShowing stale content while fresh content is loading\nIndicating that the content is stale\nDeferring re-rendering for a part of the UI\nReference \nuseDeferredValue(value, initialValue?) \n\nCall useDeferredValue at the top level of your component to get a deferred version of that value.\n\nimport { useState, useDeferredValue } from 'react';\n\n\n\nfunction SearchPage() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \nvalue: The value you want to defer. It can have any type.\noptional initialValue: A value to use during the initial render of a component. If this option is omitted, useDeferredValue will not defer during the initial render, because there’s no previous version of value that it can render instead.\nReturns \ncurrentValue: During the initial render, the returned deferred value will be the initialValue, or the same as the value you provided. During updates, React will first attempt a re-render with the old value (so it will return the old value), and then try another re-render in the background with the new value (so it will return the updated value).\nCaveats \n\nWhen an update is inside a Transition, useDeferredValue always returns the new value and does not spawn a deferred render, since the update is already deferred.\n\nThe values you pass to useDeferredValue should either be primitive values (like strings and numbers) or objects created outside of rendering. If you create a new object during rendering and immediately pass it to useDeferredValue, it will be different on every render, causing unnecessary background re-renders.\n\nWhen useDeferredValue receives a different value (compared with Object.is), in addition to the current render (when it still uses the previous value), it schedules a re-render in the background with the new value. The background re-render is interruptible: if there’s another update to the value, React will restart the background re-render from scratch. For example, if the user is typing into an input faster than a chart receiving its deferred value can re-render, the chart will only re-render after the user stops typing.\n\nuseDeferredValue is integrated with <Suspense>. If the background update caused by a new value suspends the UI, the user will not see the fallback. They will see the old deferred value until the data loads.\n\nuseDeferredValue does not by itself prevent extra network requests.\n\nThere is no fixed delay caused by useDeferredValue itself. As soon as React finishes the original re-render, React will immediately start working on the background re-render with the new deferred value. Any updates caused by events (like typing) will interrupt the background re-render and get prioritized over it.\n\nThe background re-render caused by useDeferredValue does not fire Effects until it’s committed to the screen. If the background re-render suspends, its Effects will run after the data loads and the UI updates.\n\nUsage \nShowing stale content while fresh content is loading \n\nCall useDeferredValue at the top level of your component to defer updating some part of your UI.\n\nimport { useState, useDeferredValue } from 'react';\n\n\n\nfunction SearchPage() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  // ...\n\n}\n\nDuring the initial render, the deferred value will be the same as the value you provided.\n\nDuring updates, the deferred value will “lag behind” the latest value. In particular, React will first re-render without updating the deferred value, and then try to re-render with the newly received value in the background.\n\nLet’s walk through an example to see when this is useful.\n\nNote\n\nThis example assumes you use a Suspense-enabled data source:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a Promise with use\n\nLearn more about Suspense and its limitations.\n\nIn this example, the SearchResults component suspends while fetching the search results. Try typing \"a\", waiting for the results, and then editing it to \"ab\". The results for \"a\" get replaced by the loading fallback.\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <SearchResults query={query} />\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nA common alternative UI pattern is to defer updating the list of results and to keep showing the previous results until the new results are ready. Call useDeferredValue to pass a deferred version of the query down:\n\nexport default function App() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  return (\n\n    <>\n\n      <label>\n\n        Search albums:\n\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n\n      </label>\n\n      <Suspense fallback={<h2>Loading...</h2>}>\n\n        <SearchResults query={deferredQuery} />\n\n      </Suspense>\n\n    </>\n\n  );\n\n}\n\nThe query will update immediately, so the input will display the new value. However, the deferredQuery will keep its previous value until the data has loaded, so SearchResults will show the stale results for a bit.\n\nEnter \"a\" in the example below, wait for the results to load, and then edit the input to \"ab\". Notice how instead of the Suspense fallback, you now see the stale result list until the new results have loaded:\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState, useDeferredValue } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  const deferredQuery = useDeferredValue(query);\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <SearchResults query={deferredQuery} />\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\nDEEP DIVE\nHow does deferring a value work under the hood? \nShow Details\nIndicating that the content is stale \n\nIn the example above, there is no indication that the result list for the latest query is still loading. This can be confusing to the user if the new results take a while to load. To make it more obvious to the user that the result list does not match the latest query, you can add a visual indication when the stale result list is displayed:\n\n<div style={{\n\n  opacity: query !== deferredQuery ? 0.5 : 1,\n\n}}>\n\n  <SearchResults query={deferredQuery} />\n\n</div>\n\nWith this change, as soon as you start typing, the stale result list gets slightly dimmed until the new result list loads. You can also add a CSS transition to delay dimming so that it feels gradual, like in the example below:\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState, useDeferredValue } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  const deferredQuery = useDeferredValue(query);\n  const isStale = query !== deferredQuery;\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <div style={{\n          opacity: isStale ? 0.5 : 1,\n          transition: isStale ? 'opacity 0.2s 0.2s linear' : 'opacity 0s 0s linear'\n        }}>\n          <SearchResults query={deferredQuery} />\n        </div>\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\nDeferring re-rendering for a part of the UI \n\nYou can also apply useDeferredValue as a performance optimization. It is useful when a part of your UI is slow to re-render, there’s no easy way to optimize it, and you want to prevent it from blocking the rest of the UI.\n\nImagine you have a text field and a component (like a chart or a long list) that re-renders on every keystroke:\n\nfunction App() {\n\n  const [text, setText] = useState('');\n\n  return (\n\n    <>\n\n      <input value={text} onChange={e => setText(e.target.value)} />\n\n      <SlowList text={text} />\n\n    </>\n\n  );\n\n}\n\nFirst, optimize SlowList to skip re-rendering when its props are the same. To do this, wrap it in memo:\n\nconst SlowList = memo(function SlowList({ text }) {\n\n  // ...\n\n});\n\nHowever, this only helps if the SlowList props are the same as during the previous render. The problem you’re facing now is that it’s slow when they’re different, and when you actually need to show different visual output.\n\nConcretely, the main performance problem is that whenever you type into the input, the SlowList receives new props, and re-rendering its entire tree makes the typing feel janky. In this case, useDeferredValue lets you prioritize updating the input (which must be fast) over updating the result list (which is allowed to be slower):\n\nfunction App() {\n\n  const [text, setText] = useState('');\n\n  const deferredText = useDeferredValue(text);\n\n  return (\n\n    <>\n\n      <input value={text} onChange={e => setText(e.target.value)} />\n\n      <SlowList text={deferredText} />\n\n    </>\n\n  );\n\n}\n\nThis does not make re-rendering of the SlowList faster. However, it tells React that re-rendering the list can be deprioritized so that it doesn’t block the keystrokes. The list will “lag behind” the input and then “catch up”. Like before, React will attempt to update the list as soon as possible, but will not block the user from typing.\n\nThe difference between useDeferredValue and unoptimized re-rendering\n1. Deferred re-rendering of the list\n2. Unoptimized re-rendering of the list\nExample 1 of 2: Deferred re-rendering of the list \n\nIn this example, each item in the SlowList component is artificially slowed down so that you can see how useDeferredValue lets you keep the input responsive. Type into the input and notice that typing feels snappy while the list “lags behind” it.\n\nApp.js\nSlowList.js\nReload\nClear\nFork\nimport { useState, useDeferredValue } from 'react';\nimport SlowList from './SlowList.js';\n\nexport default function App() {\n  const [text, setText] = useState('');\n  const deferredText = useDeferredValue(text);\n  return (\n    <>\n      <input value={text} onChange={e => setText(e.target.value)} />\n      <SlowList text={deferredText} />\n    </>\n  );\n}\n\n\nNext Example\nPitfall\n\nThis optimization requires SlowList to be wrapped in memo. This is because whenever the text changes, React needs to be able to re-render the parent component quickly. During that re-render, deferredText still has its previous value, so SlowList is able to skip re-rendering (its props have not changed). Without memo, it would have to re-render anyway, defeating the point of the optimization.\n\nDEEP DIVE\nHow is deferring a value different from debouncing and throttling? \nShow Details\nPREVIOUS\nuseDebugValue\nNEXT\nuseEffect"
  },
  {
    "title": "useEffect – React",
    "url": "https://react.dev/reference/react/useEffect",
    "html": "API REFERENCE\nHOOKS\nuseEffect\n\nuseEffect is a React Hook that lets you synchronize a component with an external system.\n\nuseEffect(setup, dependencies?)\nReference\nuseEffect(setup, dependencies?)\nUsage\nConnecting to an external system\nWrapping Effects in custom Hooks\nControlling a non-React widget\nFetching data with Effects\nSpecifying reactive dependencies\nUpdating state based on previous state from an Effect\nRemoving unnecessary object dependencies\nRemoving unnecessary function dependencies\nReading the latest props and state from an Effect\nDisplaying different content on the server and the client\nTroubleshooting\nMy Effect runs twice when the component mounts\nMy Effect runs after every re-render\nMy Effect keeps re-running in an infinite cycle\nMy cleanup logic runs even though my component didn’t unmount\nMy Effect does something visual, and I see a flicker before it runs\nReference \nuseEffect(setup, dependencies?) \n\nCall useEffect at the top level of your component to declare an Effect:\n\nimport { useState, useEffect } from 'react';\n\nimport { createConnection } from './chat.js';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => {\n\n      connection.disconnect();\n\n    };\n\n  }, [serverUrl, roomId]);\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \n\nsetup: The function with your Effect’s logic. Your setup function may also optionally return a cleanup function. When your component is added to the DOM, React will run your setup function. After every re-render with changed dependencies, React will first run the cleanup function (if you provided it) with the old values, and then run your setup function with the new values. After your component is removed from the DOM, React will run your cleanup function.\n\noptional dependencies: The list of all reactive values referenced inside of the setup code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison. If you omit this argument, your Effect will re-run after every re-render of the component. See the difference between passing an array of dependencies, an empty array, and no dependencies at all.\n\nReturns \n\nuseEffect returns undefined.\n\nCaveats \n\nuseEffect is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\n\nIf you’re not trying to synchronize with some external system, you probably don’t need an Effect.\n\nWhen Strict Mode is on, React will run one extra development-only setup+cleanup cycle before the first real setup. This is a stress-test that ensures that your cleanup logic “mirrors” your setup logic and that it stops or undoes whatever the setup is doing. If this causes a problem, implement the cleanup function.\n\nIf some of your dependencies are objects or functions defined inside the component, there is a risk that they will cause the Effect to re-run more often than needed. To fix this, remove unnecessary object and function dependencies. You can also extract state updates and non-reactive logic outside of your Effect.\n\nIf your Effect wasn’t caused by an interaction (like a click), React will generally let the browser paint the updated screen first before running your Effect. If your Effect is doing something visual (for example, positioning a tooltip), and the delay is noticeable (for example, it flickers), replace useEffect with useLayoutEffect.\n\nIf your Effect is caused by an interaction (like a click), React may run your Effect before the browser paints the updated screen. This ensures that the result of the Effect can be observed by the event system. Usually, this works as expected. However, if you must defer the work until after paint, such as an alert(), you can use setTimeout. See reactwg/react-18/128 for more information.\n\nEven if your Effect was caused by an interaction (like a click), React may allow the browser to repaint the screen before processing the state updates inside your Effect. Usually, this works as expected. However, if you must block the browser from repainting the screen, you need to replace useEffect with useLayoutEffect.\n\nEffects only run on the client. They don’t run during server rendering.\n\nUsage \nConnecting to an external system \n\nSome components need to stay connected to the network, some browser API, or a third-party library, while they are displayed on the page. These systems aren’t controlled by React, so they are called external.\n\nTo connect your component to some external system, call useEffect at the top level of your component:\n\nimport { useState, useEffect } from 'react';\n\nimport { createConnection } from './chat.js';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useEffect(() => {\n\n  \tconst connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n  \treturn () => {\n\n      connection.disconnect();\n\n  \t};\n\n  }, [serverUrl, roomId]);\n\n  // ...\n\n}\n\nYou need to pass two arguments to useEffect:\n\nA setup function with setup code that connects to that system.\nIt should return a cleanup function with cleanup code that disconnects from that system.\nA list of dependencies including every value from your component used inside of those functions.\n\nReact calls your setup and cleanup functions whenever it’s necessary, which may happen multiple times:\n\nYour setup code runs when your component is added to the page (mounts).\nAfter every re-render of your component where the dependencies have changed:\nFirst, your cleanup code runs with the old props and state.\nThen, your setup code runs with the new props and state.\nYour cleanup code runs one final time after your component is removed from the page (unmounts).\n\nLet’s illustrate this sequence for the example above.\n\nWhen the ChatRoom component above gets added to the page, it will connect to the chat room with the initial serverUrl and roomId. If either serverUrl or roomId change as a result of a re-render (say, if the user picks a different chat room in a dropdown), your Effect will disconnect from the previous room, and connect to the next one. When the ChatRoom component is removed from the page, your Effect will disconnect one last time.\n\nTo help you find bugs, in development React runs setup and cleanup one extra time before the setup. This is a stress-test that verifies your Effect’s logic is implemented correctly. If this causes visible issues, your cleanup function is missing some logic. The cleanup function should stop or undo whatever the setup function was doing. The rule of thumb is that the user shouldn’t be able to distinguish between the setup being called once (as in production) and a setup → cleanup → setup sequence (as in development). See common solutions.\n\nTry to write every Effect as an independent process and think about a single setup/cleanup cycle at a time. It shouldn’t matter whether your component is mounting, updating, or unmounting. When your cleanup logic correctly “mirrors” the setup logic, your Effect is resilient to running setup and cleanup as often as needed.\n\nNote\n\nAn Effect lets you keep your component synchronized with some external system (like a chat service). Here, external system means any piece of code that’s not controlled by React, such as:\n\nA timer managed with setInterval() and clearInterval().\nAn event subscription using window.addEventListener() and window.removeEventListener().\nA third-party animation library with an API like animation.start() and animation.reset().\n\nIf you’re not connecting to any external system, you probably don’t need an Effect.\n\nExamples of connecting to an external system\n1. Connecting to a chat server\n2. Listening to a global browser event\n3. Triggering an animation\n4. Controlling a modal dialog\n5. Tracking element visibility\nExample 1 of 5: Connecting to a chat server \n\nIn this example, the ChatRoom component uses an Effect to stay connected to an external system defined in chat.js. Press “Open chat” to make the ChatRoom component appear. This sandbox runs in development mode, so there is an extra connect-and-disconnect cycle, as explained here. Try changing the roomId and serverUrl using the dropdown and the input, and see how the Effect re-connects to the chat. Press “Close chat” to see the Effect disconnect one last time.\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nfunction ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  useEffect(() => {\n    const connection = createConnection(serverUrl, roomId);\n    connection.connect();\n    return () => {\n      connection.disconnect();\n    };\n  }, [roomId, serverUrl]);\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  const [show, setShow] = useState(false);\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <button onClick={() => setShow(!show)}>\n        {show ? 'Close chat' : 'Open chat'}\n      </button>\n      {show && <hr />}\n      {show && <ChatRoom roomId={roomId} />}\n    </>\n  );\n}\n\n\nShow more\nNext Example\nWrapping Effects in custom Hooks \n\nEffects are an “escape hatch”: you use them when you need to “step outside React” and when there is no better built-in solution for your use case. If you find yourself often needing to manually write Effects, it’s usually a sign that you need to extract some custom Hooks for common behaviors your components rely on.\n\nFor example, this useChatRoom custom Hook “hides” the logic of your Effect behind a more declarative API:\n\nfunction useChatRoom({ serverUrl, roomId }) {\n\n  useEffect(() => {\n\n    const options = {\n\n      serverUrl: serverUrl,\n\n      roomId: roomId\n\n    };\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId, serverUrl]);\n\n}\n\nThen you can use it from any component like this:\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useChatRoom({\n\n    roomId: roomId,\n\n    serverUrl: serverUrl\n\n  });\n\n  // ...\n\nThere are also many excellent custom Hooks for every purpose available in the React ecosystem.\n\nLearn more about wrapping Effects in custom Hooks.\n\nExamples of wrapping Effects in custom Hooks\n1. Custom useChatRoom Hook\n2. Custom useWindowListener Hook\n3. Custom useIntersectionObserver Hook\nExample 1 of 3: Custom useChatRoom Hook \n\nThis example is identical to one of the earlier examples, but the logic is extracted to a custom Hook.\n\nApp.js\nuseChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport { useChatRoom } from './useChatRoom.js';\n\nfunction ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  useChatRoom({\n    roomId: roomId,\n    serverUrl: serverUrl\n  });\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  const [show, setShow] = useState(false);\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <button onClick={() => setShow(!show)}>\n        {show ? 'Close chat' : 'Open chat'}\n      </button>\n      {show && <hr />}\n      {show && <ChatRoom roomId={roomId} />}\n    </>\n  );\n}\n\n\nShow more\nNext Example\nControlling a non-React widget \n\nSometimes, you want to keep an external system synchronized to some prop or state of your component.\n\nFor example, if you have a third-party map widget or a video player component written without React, you can use an Effect to call methods on it that make its state match the current state of your React component. This Effect creates an instance of a MapWidget class defined in map-widget.js. When you change the zoomLevel prop of the Map component, the Effect calls the setZoom() on the class instance to keep it synchronized:\n\nApp.js\nMap.js\nmap-widget.js\nReload\nClear\nFork\nimport { useRef, useEffect } from 'react';\nimport { MapWidget } from './map-widget.js';\n\nexport default function Map({ zoomLevel }) {\n  const containerRef = useRef(null);\n  const mapRef = useRef(null);\n\n  useEffect(() => {\n    if (mapRef.current === null) {\n      mapRef.current = new MapWidget(containerRef.current);\n    }\n\n    const map = mapRef.current;\n    map.setZoom(zoomLevel);\n  }, [zoomLevel]);\n\n  return (\n    <div\n      style={{ width: 200, height: 200 }}\n      ref={containerRef}\n    />\n  );\n}\n\n\nShow more\n\nIn this example, a cleanup function is not needed because the MapWidget class manages only the DOM node that was passed to it. After the Map React component is removed from the tree, both the DOM node and the MapWidget class instance will be automatically garbage-collected by the browser JavaScript engine.\n\nFetching data with Effects \n\nYou can use an Effect to fetch data for your component. Note that if you use a framework, using your framework’s data fetching mechanism will be a lot more efficient than writing Effects manually.\n\nIf you want to fetch data from an Effect manually, your code might look like this:\n\nimport { useState, useEffect } from 'react';\n\nimport { fetchBio } from './api.js';\n\n\n\nexport default function Page() {\n\n  const [person, setPerson] = useState('Alice');\n\n  const [bio, setBio] = useState(null);\n\n\n\n  useEffect(() => {\n\n    let ignore = false;\n\n    setBio(null);\n\n    fetchBio(person).then(result => {\n\n      if (!ignore) {\n\n        setBio(result);\n\n      }\n\n    });\n\n    return () => {\n\n      ignore = true;\n\n    };\n\n  }, [person]);\n\n\n\n  // ...\n\nNote the ignore variable which is initialized to false, and is set to true during cleanup. This ensures your code doesn’t suffer from “race conditions”: network responses may arrive in a different order than you sent them.\n\nApp.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { fetchBio } from './api.js';\n\nexport default function Page() {\n  const [person, setPerson] = useState('Alice');\n  const [bio, setBio] = useState(null);\n  useEffect(() => {\n    let ignore = false;\n    setBio(null);\n    fetchBio(person).then(result => {\n      if (!ignore) {\n        setBio(result);\n      }\n    });\n    return () => {\n      ignore = true;\n    }\n  }, [person]);\n\n  return (\n    <>\n      <select value={person} onChange={e => {\n        setPerson(e.target.value);\n      }}>\n        <option value=\"Alice\">Alice</option>\n        <option value=\"Bob\">Bob</option>\n        <option value=\"Taylor\">Taylor</option>\n      </select>\n      <hr />\n      <p><i>{bio ?? 'Loading...'}</i></p>\n    </>\n  );\n}\n\n\nShow more\n\nYou can also rewrite using the async / await syntax, but you still need to provide a cleanup function:\n\nApp.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { fetchBio } from './api.js';\n\nexport default function Page() {\n  const [person, setPerson] = useState('Alice');\n  const [bio, setBio] = useState(null);\n  useEffect(() => {\n    async function startFetching() {\n      setBio(null);\n      const result = await fetchBio(person);\n      if (!ignore) {\n        setBio(result);\n      }\n    }\n\n    let ignore = false;\n    startFetching();\n    return () => {\n      ignore = true;\n    }\n  }, [person]);\n\n  return (\n    <>\n      <select value={person} onChange={e => {\n        setPerson(e.target.value);\n      }}>\n        <option value=\"Alice\">Alice</option>\n        <option value=\"Bob\">Bob</option>\n        <option value=\"Taylor\">Taylor</option>\n      </select>\n      <hr />\n      <p><i>{bio ?? 'Loading...'}</i></p>\n    </>\n  );\n}\n\n\nShow more\n\nWriting data fetching directly in Effects gets repetitive and makes it difficult to add optimizations like caching and server rendering later. It’s easier to use a custom Hook—either your own or maintained by the community.\n\nDEEP DIVE\nWhat are good alternatives to data fetching in Effects? \nShow Details\nSpecifying reactive dependencies \n\nNotice that you can’t “choose” the dependencies of your Effect. Every reactive value used by your Effect’s code must be declared as a dependency. Your Effect’s dependency list is determined by the surrounding code:\n\nfunction ChatRoom({ roomId }) { // This is a reactive value\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234'); // This is a reactive value too\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId); // This Effect reads these reactive values\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [serverUrl, roomId]); // ✅ So you must specify them as dependencies of your Effect\n\n  // ...\n\n}\n\nIf either serverUrl or roomId change, your Effect will reconnect to the chat using the new values.\n\nReactive values include props and all variables and functions declared directly inside of your component. Since roomId and serverUrl are reactive values, you can’t remove them from the dependencies. If you try to omit them and your linter is correctly configured for React, the linter will flag this as a mistake you need to fix:\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  \n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, []); // 🔴 React Hook useEffect has missing dependencies: 'roomId' and 'serverUrl'\n\n  // ...\n\n}\n\nTo remove a dependency, you need to “prove” to the linter that it doesn’t need to be a dependency. For example, you can move serverUrl out of your component to prove that it’s not reactive and won’t change on re-renders:\n\nconst serverUrl = 'https://localhost:1234'; // Not a reactive value anymore\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nNow that serverUrl is not a reactive value (and can’t change on a re-render), it doesn’t need to be a dependency. If your Effect’s code doesn’t use any reactive values, its dependency list should be empty ([]):\n\nconst serverUrl = 'https://localhost:1234'; // Not a reactive value anymore\n\nconst roomId = 'music'; // Not a reactive value anymore\n\n\n\nfunction ChatRoom() {\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, []); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nAn Effect with empty dependencies doesn’t re-run when any of your component’s props or state change.\n\nPitfall\n\nIf you have an existing codebase, you might have some Effects that suppress the linter like this:\n\nuseEffect(() => {\n\n  // ...\n\n  // 🔴 Avoid suppressing the linter like this:\n\n  // eslint-ignore-next-line react-hooks/exhaustive-deps\n\n}, []);\n\nWhen dependencies don’t match the code, there is a high risk of introducing bugs. By suppressing the linter, you “lie” to React about the values your Effect depends on. Instead, prove they’re unnecessary.\n\nExamples of passing reactive dependencies\n1. Passing a dependency array\n2. Passing an empty dependency array\n3. Passing no dependency array at all\nExample 1 of 3: Passing a dependency array \n\nIf you specify the dependencies, your Effect runs after the initial render and after re-renders with changed dependencies.\n\nuseEffect(() => {\n\n  // ...\n\n}, [a, b]); // Runs again if a or b are different\n\nIn the below example, serverUrl and roomId are reactive values, so they both must be specified as dependencies. As a result, selecting a different room in the dropdown or editing the server URL input causes the chat to re-connect. However, since message isn’t used in the Effect (and so it isn’t a dependency), editing the message doesn’t re-connect to the chat.\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nfunction ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n  const [message, setMessage] = useState('');\n\n  useEffect(() => {\n    const connection = createConnection(serverUrl, roomId);\n    connection.connect();\n    return () => {\n      connection.disconnect();\n    };\n  }, [serverUrl, roomId]);\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n      <label>\n        Your message:{' '}\n        <input value={message} onChange={e => setMessage(e.target.value)} />\n      </label>\n    </>\n  );\n}\n\nexport default function App() {\n  const [show, setShow] = useState(false);\n  const [roomId, setRoomId] = useState('general');\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n        <button onClick={() => setShow(!show)}>\n          {show ? 'Close chat' : 'Open chat'}\n        </button>\n      </label>\n      {show && <hr />}\n      {show && <ChatRoom roomId={roomId}/>}\n    </>\n  );\n}\n\n\nShow more\nNext Example\nUpdating state based on previous state from an Effect \n\nWhen you want to update state based on previous state from an Effect, you might run into a problem:\n\nfunction Counter() {\n\n  const [count, setCount] = useState(0);\n\n\n\n  useEffect(() => {\n\n    const intervalId = setInterval(() => {\n\n      setCount(count + 1); // You want to increment the counter every second...\n\n    }, 1000)\n\n    return () => clearInterval(intervalId);\n\n  }, [count]); // 🚩 ... but specifying `count` as a dependency always resets the interval.\n\n  // ...\n\n}\n\nSince count is a reactive value, it must be specified in the list of dependencies. However, that causes the Effect to cleanup and setup again every time the count changes. This is not ideal.\n\nTo fix this, pass the c => c + 1 state updater to setCount:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\n\nexport default function Counter() {\n  const [count, setCount] = useState(0);\n\n  useEffect(() => {\n    const intervalId = setInterval(() => {\n      setCount(c => c + 1); // ✅ Pass a state updater\n    }, 1000);\n    return () => clearInterval(intervalId);\n  }, []); // ✅ Now count is not a dependency\n\n  return <h1>{count}</h1>;\n}\n\n\n\nNow that you’re passing c => c + 1 instead of count + 1, your Effect no longer needs to depend on count. As a result of this fix, it won’t need to cleanup and setup the interval again every time the count changes.\n\nRemoving unnecessary object dependencies \n\nIf your Effect depends on an object or a function created during rendering, it might run too often. For example, this Effect re-connects after every render because the options object is different for every render:\n\nconst serverUrl = 'https://localhost:1234';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const options = { // 🚩 This object is created from scratch on every re-render\n\n    serverUrl: serverUrl,\n\n    roomId: roomId\n\n  };\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(options); // It's used inside the Effect\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [options]); // 🚩 As a result, these dependencies are always different on a re-render\n\n  // ...\n\nAvoid using an object created during rendering as a dependency. Instead, create the object inside the Effect:\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nconst serverUrl = 'https://localhost:1234';\n\nfunction ChatRoom({ roomId }) {\n  const [message, setMessage] = useState('');\n\n  useEffect(() => {\n    const options = {\n      serverUrl: serverUrl,\n      roomId: roomId\n    };\n    const connection = createConnection(options);\n    connection.connect();\n    return () => connection.disconnect();\n  }, [roomId]);\n\n  return (\n    <>\n      <h1>Welcome to the {roomId} room!</h1>\n      <input value={message} onChange={e => setMessage(e.target.value)} />\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <hr />\n      <ChatRoom roomId={roomId} />\n    </>\n  );\n}\n\n\nShow more\n\nNow that you create the options object inside the Effect, the Effect itself only depends on the roomId string.\n\nWith this fix, typing into the input doesn’t reconnect the chat. Unlike an object which gets re-created, a string like roomId doesn’t change unless you set it to another value. Read more about removing dependencies.\n\nRemoving unnecessary function dependencies \n\nIf your Effect depends on an object or a function created during rendering, it might run too often. For example, this Effect re-connects after every render because the createOptions function is different for every render:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  function createOptions() { // 🚩 This function is created from scratch on every re-render\n\n    return {\n\n      serverUrl: serverUrl,\n\n      roomId: roomId\n\n    };\n\n  }\n\n\n\n  useEffect(() => {\n\n    const options = createOptions(); // It's used inside the Effect\n\n    const connection = createConnection();\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [createOptions]); // 🚩 As a result, these dependencies are always different on a re-render\n\n  // ...\n\nBy itself, creating a function from scratch on every re-render is not a problem. You don’t need to optimize that. However, if you use it as a dependency of your Effect, it will cause your Effect to re-run after every re-render.\n\nAvoid using a function created during rendering as a dependency. Instead, declare it inside the Effect:\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nconst serverUrl = 'https://localhost:1234';\n\nfunction ChatRoom({ roomId }) {\n  const [message, setMessage] = useState('');\n\n  useEffect(() => {\n    function createOptions() {\n      return {\n        serverUrl: serverUrl,\n        roomId: roomId\n      };\n    }\n\n    const options = createOptions();\n    const connection = createConnection(options);\n    connection.connect();\n    return () => connection.disconnect();\n  }, [roomId]);\n\n  return (\n    <>\n      <h1>Welcome to the {roomId} room!</h1>\n      <input value={message} onChange={e => setMessage(e.target.value)} />\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <hr />\n      <ChatRoom roomId={roomId} />\n    </>\n  );\n}\n\n\nShow more\n\nNow that you define the createOptions function inside the Effect, the Effect itself only depends on the roomId string. With this fix, typing into the input doesn’t reconnect the chat. Unlike a function which gets re-created, a string like roomId doesn’t change unless you set it to another value. Read more about removing dependencies.\n\nReading the latest props and state from an Effect \n\nBy default, when you read a reactive value from an Effect, you have to add it as a dependency. This ensures that your Effect “reacts” to every change of that value. For most dependencies, that’s the behavior you want.\n\nHowever, sometimes you’ll want to read the latest props and state from an Effect without “reacting” to them. For example, imagine you want to log the number of the items in the shopping cart for every page visit:\n\nfunction Page({ url, shoppingCart }) {\n\n  useEffect(() => {\n\n    logVisit(url, shoppingCart.length);\n\n  }, [url, shoppingCart]); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nWhat if you want to log a new page visit after every url change, but not if only the shoppingCart changes? You can’t exclude shoppingCart from dependencies without breaking the reactivity rules. However, you can express that you don’t want a piece of code to “react” to changes even though it is called from inside an Effect. Declare an Effect Event with the useEffectEvent Hook, and move the code reading shoppingCart inside of it:\n\nfunction Page({ url, shoppingCart }) {\n\n  const onVisit = useEffectEvent(visitedUrl => {\n\n    logVisit(visitedUrl, shoppingCart.length)\n\n  });\n\n\n\n  useEffect(() => {\n\n    onVisit(url);\n\n  }, [url]); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nEffect Events are not reactive and must always be omitted from dependencies of your Effect. This is what lets you put non-reactive code (where you can read the latest value of some props and state) inside of them. By reading shoppingCart inside of onVisit, you ensure that shoppingCart won’t re-run your Effect.\n\nRead more about how Effect Events let you separate reactive and non-reactive code.\n\nDisplaying different content on the server and the client \n\nIf your app uses server rendering (either directly or via a framework), your component will render in two different environments. On the server, it will render to produce the initial HTML. On the client, React will run the rendering code again so that it can attach your event handlers to that HTML. This is why, for hydration to work, your initial render output must be identical on the client and the server.\n\nIn rare cases, you might need to display different content on the client. For example, if your app reads some data from localStorage, it can’t possibly do that on the server. Here is how you could implement this:\n\nfunction MyComponent() {\n\n  const [didMount, setDidMount] = useState(false);\n\n\n\n  useEffect(() => {\n\n    setDidMount(true);\n\n  }, []);\n\n\n\n  if (didMount) {\n\n    // ... return client-only JSX ...\n\n  }  else {\n\n    // ... return initial JSX ...\n\n  }\n\n}\n\nWhile the app is loading, the user will see the initial render output. Then, when it’s loaded and hydrated, your Effect will run and set didMount to true, triggering a re-render. This will switch to the client-only render output. Effects don’t run on the server, so this is why didMount was false during the initial server render.\n\nUse this pattern sparingly. Keep in mind that users with a slow connection will see the initial content for quite a bit of time—potentially, many seconds—so you don’t want to make jarring changes to your component’s appearance. In many cases, you can avoid the need for this by conditionally showing different things with CSS.\n\nTroubleshooting \nMy Effect runs twice when the component mounts \n\nWhen Strict Mode is on, in development, React runs setup and cleanup one extra time before the actual setup.\n\nThis is a stress-test that verifies your Effect’s logic is implemented correctly. If this causes visible issues, your cleanup function is missing some logic. The cleanup function should stop or undo whatever the setup function was doing. The rule of thumb is that the user shouldn’t be able to distinguish between the setup being called once (as in production) and a setup → cleanup → setup sequence (as in development).\n\nRead more about how this helps find bugs and how to fix your logic.\n\nMy Effect runs after every re-render \n\nFirst, check that you haven’t forgotten to specify the dependency array:\n\nuseEffect(() => {\n\n  // ...\n\n}); // 🚩 No dependency array: re-runs after every render!\n\nIf you’ve specified the dependency array but your Effect still re-runs in a loop, it’s because one of your dependencies is different on every re-render.\n\nYou can debug this problem by manually logging your dependencies to the console:\n\n  useEffect(() => {\n\n    // ..\n\n  }, [serverUrl, roomId]);\n\n\n\n  console.log([serverUrl, roomId]);\n\nYou can then right-click on the arrays from different re-renders in the console and select “Store as a global variable” for both of them. Assuming the first one got saved as temp1 and the second one got saved as temp2, you can then use the browser console to check whether each dependency in both arrays is the same:\n\nObject.is(temp1[0], temp2[0]); // Is the first dependency the same between the arrays?\n\nObject.is(temp1[1], temp2[1]); // Is the second dependency the same between the arrays?\n\nObject.is(temp1[2], temp2[2]); // ... and so on for every dependency ...\n\nWhen you find the dependency that is different on every re-render, you can usually fix it in one of these ways:\n\nUpdating state based on previous state from an Effect\nRemoving unnecessary object dependencies\nRemoving unnecessary function dependencies\nReading the latest props and state from an Effect\n\nAs a last resort (if these methods didn’t help), wrap its creation with useMemo or useCallback (for functions).\n\nMy Effect keeps re-running in an infinite cycle \n\nIf your Effect runs in an infinite cycle, these two things must be true:\n\nYour Effect is updating some state.\nThat state leads to a re-render, which causes the Effect’s dependencies to change.\n\nBefore you start fixing the problem, ask yourself whether your Effect is connecting to some external system (like DOM, network, a third-party widget, and so on). Why does your Effect need to set state? Does it synchronize with that external system? Or are you trying to manage your application’s data flow with it?\n\nIf there is no external system, consider whether removing the Effect altogether would simplify your logic.\n\nIf you’re genuinely synchronizing with some external system, think about why and under what conditions your Effect should update the state. Has something changed that affects your component’s visual output? If you need to keep track of some data that isn’t used by rendering, a ref (which doesn’t trigger re-renders) might be more appropriate. Verify your Effect doesn’t update the state (and trigger re-renders) more than needed.\n\nFinally, if your Effect is updating the state at the right time, but there is still a loop, it’s because that state update leads to one of the Effect’s dependencies changing. Read how to debug dependency changes.\n\nMy cleanup logic runs even though my component didn’t unmount \n\nThe cleanup function runs not only during unmount, but before every re-render with changed dependencies. Additionally, in development, React runs setup+cleanup one extra time immediately after component mounts.\n\nIf you have cleanup code without corresponding setup code, it’s usually a code smell:\n\nuseEffect(() => {\n\n  // 🔴 Avoid: Cleanup logic without corresponding setup logic\n\n  return () => {\n\n    doSomething();\n\n  };\n\n}, []);\n\nYour cleanup logic should be “symmetrical” to the setup logic, and should stop or undo whatever setup did:\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => {\n\n      connection.disconnect();\n\n    };\n\n  }, [serverUrl, roomId]);\n\nLearn how the Effect lifecycle is different from the component’s lifecycle.\n\nMy Effect does something visual, and I see a flicker before it runs \n\nIf your Effect must block the browser from painting the screen, replace useEffect with useLayoutEffect. Note that this shouldn’t be needed for the vast majority of Effects. You’ll only need this if it’s crucial to run your Effect before the browser paint: for example, to measure and position a tooltip before the user sees it.\n\nPREVIOUS\nuseDeferredValue\nNEXT\nuseEffectEvent"
  },
  {
    "title": "useEffectEvent – React",
    "url": "https://react.dev/reference/react/useEffectEvent",
    "html": "API REFERENCE\nHOOKS\nuseEffectEvent\n\nuseEffectEvent is a React Hook that lets you extract non-reactive logic from your Effects into a reusable function called an Effect Event.\n\nconst onSomething = useEffectEvent(callback)\nReference\nuseEffectEvent(callback)\nUsage\nReading the latest props and state\nReference \nuseEffectEvent(callback) \n\nCall useEffectEvent at the top level of your component to declare an Effect Event. Effect Events are functions you can call inside Effects, such as useEffect:\n\nimport { useEffectEvent, useEffect } from 'react';\n\n\n\nfunction ChatRoom({ roomId, theme }) {\n\n  const onConnected = useEffectEvent(() => {\n\n    showNotification('Connected!', theme);\n\n  });\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.on('connected', () => {\n\n      onConnected();\n\n    });\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]);\n\n\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \ncallback: A function containing the logic for your Effect Event. When you define an Effect Event with useEffectEvent, the callback always accesses the latest values from props and state when it is invoked. This helps avoid issues with stale closures.\nReturns \n\nReturns an Effect Event function. You can call this function inside useEffect, useLayoutEffect, or useInsertionEffect.\n\nCaveats \nOnly call inside Effects: Effect Events should only be called within Effects. Define them just before the Effect that uses them. Do not pass them to other components or hooks. The eslint-plugin-react-hooks linter (version 6.1.1 or higher) will enforce this restriction to prevent calling Effect Events in the wrong context.\nNot a dependency shortcut: Do not use useEffectEvent to avoid specifying dependencies in your Effect’s dependency array. This can hide bugs and make your code harder to understand. Prefer explicit dependencies or use refs to compare previous values if needed.\nUse for non-reactive logic: Only use useEffectEvent to extract logic that does not depend on changing values.\nUsage \nReading the latest props and state \n\nTypically, when you access a reactive value inside an Effect, you must include it in the dependency array. This makes sure your Effect runs again whenever that value changes, which is usually the desired behavior.\n\nBut in some cases, you may want to read the most recent props or state inside an Effect without causing the Effect to re-run when those values change.\n\nTo read the latest props or state in your Effect, without making those values reactive, include them in an Effect Event.\n\nimport { useEffect, useContext, useEffectEvent } from 'react';\n\n\n\nfunction Page({ url }) {\n\n  const { items } = useContext(ShoppingCartContext);\n\n  const numberOfItems = items.length;\n\n\n\n  const onNavigate = useEffectEvent((visitedUrl) => {\n\n    logVisit(visitedUrl, numberOfItems);\n\n  });\n\n\n\n  useEffect(() => {\n\n    onNavigate(url);\n\n  }, [url]);\n\n\n\n  // ...\n\n}\n\nIn this example, the Effect should re-run after a render when url changes (to log the new page visit), but it should not re-run when numberOfItems changes. By wrapping the logging logic in an Effect Event, numberOfItems becomes non-reactive. It’s always read from the latest value without triggering the Effect.\n\nYou can pass reactive values like url as arguments to the Effect Event to keep them reactive while accessing the latest non-reactive values inside the event.\n\nPREVIOUS\nuseEffect\nNEXT\nuseId"
  },
  {
    "title": "useId – React",
    "url": "https://react.dev/reference/react/useId",
    "html": "API REFERENCE\nHOOKS\nuseId\n\nuseId is a React Hook for generating unique IDs that can be passed to accessibility attributes.\n\nconst id = useId()\nReference\nuseId()\nUsage\nGenerating unique IDs for accessibility attributes\nGenerating IDs for several related elements\nSpecifying a shared prefix for all generated IDs\nUsing the same ID prefix on the client and the server\nReference \nuseId() \n\nCall useId at the top level of your component to generate a unique ID:\n\nimport { useId } from 'react';\n\n\n\nfunction PasswordField() {\n\n  const passwordHintId = useId();\n\n  // ...\n\nSee more examples below.\n\nParameters \n\nuseId does not take any parameters.\n\nReturns \n\nuseId returns a unique ID string associated with this particular useId call in this particular component.\n\nCaveats \n\nuseId is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\n\nuseId should not be used to generate keys in a list. Keys should be generated from your data.\n\nuseId currently cannot be used in async Server Components.\n\nUsage \nPitfall\n\nDo not call useId to generate keys in a list. Keys should be generated from your data.\n\nGenerating unique IDs for accessibility attributes \n\nCall useId at the top level of your component to generate a unique ID:\n\nimport { useId } from 'react';\n\n\n\nfunction PasswordField() {\n\n  const passwordHintId = useId();\n\n  // ...\n\nYou can then pass the generated ID to different attributes:\n\n<>\n\n  <input type=\"password\" aria-describedby={passwordHintId} />\n\n  <p id={passwordHintId}>\n\n</>\n\nLet’s walk through an example to see when this is useful.\n\nHTML accessibility attributes like aria-describedby let you specify that two tags are related to each other. For example, you can specify that an element (like an input) is described by another element (like a paragraph).\n\nIn regular HTML, you would write it like this:\n\n<label>\n\n  Password:\n\n  <input\n\n    type=\"password\"\n\n    aria-describedby=\"password-hint\"\n\n  />\n\n</label>\n\n<p id=\"password-hint\">\n\n  The password should contain at least 18 characters\n\n</p>\n\nHowever, hardcoding IDs like this is not a good practice in React. A component may be rendered more than once on the page—but IDs have to be unique! Instead of hardcoding an ID, generate a unique ID with useId:\n\nimport { useId } from 'react';\n\n\n\nfunction PasswordField() {\n\n  const passwordHintId = useId();\n\n  return (\n\n    <>\n\n      <label>\n\n        Password:\n\n        <input\n\n          type=\"password\"\n\n          aria-describedby={passwordHintId}\n\n        />\n\n      </label>\n\n      <p id={passwordHintId}>\n\n        The password should contain at least 18 characters\n\n      </p>\n\n    </>\n\n  );\n\n}\n\nNow, even if PasswordField appears multiple times on the screen, the generated IDs won’t clash.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useId } from 'react';\n\nfunction PasswordField() {\n  const passwordHintId = useId();\n  return (\n    <>\n      <label>\n        Password:\n        <input\n          type=\"password\"\n          aria-describedby={passwordHintId}\n        />\n      </label>\n      <p id={passwordHintId}>\n        The password should contain at least 18 characters\n      </p>\n    </>\n  );\n}\n\nexport default function App() {\n  return (\n    <>\n      <h2>Choose password</h2>\n      <PasswordField />\n      <h2>Confirm password</h2>\n      <PasswordField />\n    </>\n  );\n}\n\n\nShow more\n\nWatch this video to see the difference in the user experience with assistive technologies.\n\nPitfall\n\nWith server rendering, useId requires an identical component tree on the server and the client. If the trees you render on the server and the client don’t match exactly, the generated IDs won’t match.\n\nDEEP DIVE\nWhy is useId better than an incrementing counter? \nShow Details\nGenerating IDs for several related elements \n\nIf you need to give IDs to multiple related elements, you can call useId to generate a shared prefix for them:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useId } from 'react';\n\nexport default function Form() {\n  const id = useId();\n  return (\n    <form>\n      <label htmlFor={id + '-firstName'}>First Name:</label>\n      <input id={id + '-firstName'} type=\"text\" />\n      <hr />\n      <label htmlFor={id + '-lastName'}>Last Name:</label>\n      <input id={id + '-lastName'} type=\"text\" />\n    </form>\n  );\n}\n\n\n\nThis lets you avoid calling useId for every single element that needs a unique ID.\n\nSpecifying a shared prefix for all generated IDs \n\nIf you render multiple independent React applications on a single page, pass identifierPrefix as an option to your createRoot or hydrateRoot calls. This ensures that the IDs generated by the two different apps never clash because every identifier generated with useId will start with the distinct prefix you’ve specified.\n\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport App from './App.js';\nimport './styles.css';\n\nconst root1 = createRoot(document.getElementById('root1'), {\n  identifierPrefix: 'my-first-app-'\n});\nroot1.render(<App />);\n\nconst root2 = createRoot(document.getElementById('root2'), {\n  identifierPrefix: 'my-second-app-'\n});\nroot2.render(<App />);\n\n\nUsing the same ID prefix on the client and the server \n\nIf you render multiple independent React apps on the same page, and some of these apps are server-rendered, make sure that the identifierPrefix you pass to the hydrateRoot call on the client side is the same as the identifierPrefix you pass to the server APIs such as renderToPipeableStream.\n\n// Server\n\nimport { renderToPipeableStream } from 'react-dom/server';\n\n\n\nconst { pipe } = renderToPipeableStream(\n\n  <App />,\n\n  { identifierPrefix: 'react-app1' }\n\n);\n// Client\n\nimport { hydrateRoot } from 'react-dom/client';\n\n\n\nconst domNode = document.getElementById('root');\n\nconst root = hydrateRoot(\n\n  domNode,\n\n  reactNode,\n\n  { identifierPrefix: 'react-app1' }\n\n);\n\nYou do not need to pass identifierPrefix if you only have one React app on the page.\n\nPREVIOUS\nuseEffectEvent\nNEXT\nuseImperativeHandle"
  },
  {
    "title": "useImperativeHandle – React",
    "url": "https://react.dev/reference/react/useImperativeHandle",
    "html": "API REFERENCE\nHOOKS\nuseImperativeHandle\n\nuseImperativeHandle is a React Hook that lets you customize the handle exposed as a ref.\n\nuseImperativeHandle(ref, createHandle, dependencies?)\nReference\nuseImperativeHandle(ref, createHandle, dependencies?)\nUsage\nExposing a custom ref handle to the parent component\nExposing your own imperative methods\nReference \nuseImperativeHandle(ref, createHandle, dependencies?) \n\nCall useImperativeHandle at the top level of your component to customize the ref handle it exposes:\n\nimport { useImperativeHandle } from 'react';\n\n\n\nfunction MyInput({ ref }) {\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      // ... your methods ...\n\n    };\n\n  }, []);\n\n  // ...\n\nSee more examples below.\n\nParameters \n\nref: The ref you received as a prop to the MyInput component.\n\ncreateHandle: A function that takes no arguments and returns the ref handle you want to expose. That ref handle can have any type. Usually, you will return an object with the methods you want to expose.\n\noptional dependencies: The list of all reactive values referenced inside of the createHandle code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison. If a re-render resulted in a change to some dependency, or if you omitted this argument, your createHandle function will re-execute, and the newly created handle will be assigned to the ref.\n\nNote\n\nStarting with React 19, ref is available as a prop. In React 18 and earlier, it was necessary to get the ref from forwardRef.\n\nReturns \n\nuseImperativeHandle returns undefined.\n\nUsage \nExposing a custom ref handle to the parent component \n\nTo expose a DOM node to the parent element, pass in the ref prop to the node.\n\nfunction MyInput({ ref }) {\n\n  return <input ref={ref} />;\n\n};\n\nWith the code above, a ref to MyInput will receive the <input> DOM node. However, you can expose a custom value instead. To customize the exposed handle, call useImperativeHandle at the top level of your component:\n\nimport { useImperativeHandle } from 'react';\n\n\n\nfunction MyInput({ ref }) {\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      // ... your methods ...\n\n    };\n\n  }, []);\n\n\n\n  return <input />;\n\n};\n\nNote that in the code above, the ref is no longer passed to the <input>.\n\nFor example, suppose you don’t want to expose the entire <input> DOM node, but you want to expose two of its methods: focus and scrollIntoView. To do this, keep the real browser DOM in a separate ref. Then use useImperativeHandle to expose a handle with only the methods that you want the parent component to call:\n\nimport { useRef, useImperativeHandle } from 'react';\n\n\n\nfunction MyInput({ ref }) {\n\n  const inputRef = useRef(null);\n\n\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      focus() {\n\n        inputRef.current.focus();\n\n      },\n\n      scrollIntoView() {\n\n        inputRef.current.scrollIntoView();\n\n      },\n\n    };\n\n  }, []);\n\n\n\n  return <input ref={inputRef} />;\n\n};\n\nNow, if the parent component gets a ref to MyInput, it will be able to call the focus and scrollIntoView methods on it. However, it will not have full access to the underlying <input> DOM node.\n\nApp.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport MyInput from './MyInput.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n    // This won't work because the DOM node isn't exposed:\n    // ref.current.style.opacity = 0.5;\n  }\n\n  return (\n    <form>\n      <MyInput placeholder=\"Enter your name\" ref={ref} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\nExposing your own imperative methods \n\nThe methods you expose via an imperative handle don’t have to match the DOM methods exactly. For example, this Post component exposes a scrollAndFocusAddComment method via an imperative handle. This lets the parent Page scroll the list of comments and focus the input field when you click the button:\n\nApp.js\nPost.js\nCommentList.js\nAddComment.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport Post from './Post.js';\n\nexport default function Page() {\n  const postRef = useRef(null);\n\n  function handleClick() {\n    postRef.current.scrollAndFocusAddComment();\n  }\n\n  return (\n    <>\n      <button onClick={handleClick}>\n        Write a comment\n      </button>\n      <Post ref={postRef} />\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\nDo not overuse refs. You should only use refs for imperative behaviors that you can’t express as props: for example, scrolling to a node, focusing a node, triggering an animation, selecting text, and so on.\n\nIf you can express something as a prop, you should not use a ref. For example, instead of exposing an imperative handle like { open, close } from a Modal component, it is better to take isOpen as a prop like <Modal isOpen={isOpen} />. Effects can help you expose imperative behaviors via props.\n\nPREVIOUS\nuseId\nNEXT\nuseInsertionEffect"
  },
  {
    "title": "useInsertionEffect – React",
    "url": "https://react.dev/reference/react/useInsertionEffect",
    "html": "API REFERENCE\nHOOKS\nuseInsertionEffect\nPitfall\n\nuseInsertionEffect is for CSS-in-JS library authors. Unless you are working on a CSS-in-JS library and need a place to inject the styles, you probably want useEffect or useLayoutEffect instead.\n\nuseInsertionEffect allows inserting elements into the DOM before any layout Effects fire.\n\nuseInsertionEffect(setup, dependencies?)\nReference\nuseInsertionEffect(setup, dependencies?)\nUsage\nInjecting dynamic styles from CSS-in-JS libraries\nReference \nuseInsertionEffect(setup, dependencies?) \n\nCall useInsertionEffect to insert styles before any Effects fire that may need to read layout:\n\nimport { useInsertionEffect } from 'react';\n\n\n\n// Inside your CSS-in-JS library\n\nfunction useCSS(rule) {\n\n  useInsertionEffect(() => {\n\n    // ... inject <style> tags here ...\n\n  });\n\n  return rule;\n\n}\n\nSee more examples below.\n\nParameters \n\nsetup: The function with your Effect’s logic. Your setup function may also optionally return a cleanup function. When your component is added to the DOM, but before any layout Effects fire, React will run your setup function. After every re-render with changed dependencies, React will first run the cleanup function (if you provided it) with the old values, and then run your setup function with the new values. When your component is removed from the DOM, React will run your cleanup function.\n\noptional dependencies: The list of all reactive values referenced inside of the setup code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison algorithm. If you don’t specify the dependencies at all, your Effect will re-run after every re-render of the component.\n\nReturns \n\nuseInsertionEffect returns undefined.\n\nCaveats \nEffects only run on the client. They don’t run during server rendering.\nYou can’t update state from inside useInsertionEffect.\nBy the time useInsertionEffect runs, refs are not attached yet.\nuseInsertionEffect may run either before or after the DOM has been updated. You shouldn’t rely on the DOM being updated at any particular time.\nUnlike other types of Effects, which fire cleanup for every Effect and then setup for every Effect, useInsertionEffect will fire both cleanup and setup one component at a time. This results in an “interleaving” of the cleanup and setup functions.\nUsage \nInjecting dynamic styles from CSS-in-JS libraries \n\nTraditionally, you would style React components using plain CSS.\n\n// In your JS file:\n\n<button className=\"success\" />\n\n\n\n// In your CSS file:\n\n.success { color: green; }\n\nSome teams prefer to author styles directly in JavaScript code instead of writing CSS files. This usually requires using a CSS-in-JS library or a tool. There are three common approaches to CSS-in-JS:\n\nStatic extraction to CSS files with a compiler\nInline styles, e.g. <div style={{ opacity: 1 }}>\nRuntime injection of <style> tags\n\nIf you use CSS-in-JS, we recommend a combination of the first two approaches (CSS files for static styles, inline styles for dynamic styles). We don’t recommend runtime <style> tag injection for two reasons:\n\nRuntime injection forces the browser to recalculate the styles a lot more often.\nRuntime injection can be very slow if it happens at the wrong time in the React lifecycle.\n\nThe first problem is not solvable, but useInsertionEffect helps you solve the second problem.\n\nCall useInsertionEffect to insert the styles before any layout Effects fire:\n\n// Inside your CSS-in-JS library\n\nlet isInserted = new Set();\n\nfunction useCSS(rule) {\n\n  useInsertionEffect(() => {\n\n    // As explained earlier, we don't recommend runtime injection of <style> tags.\n\n    // But if you have to do it, then it's important to do in useInsertionEffect.\n\n    if (!isInserted.has(rule)) {\n\n      isInserted.add(rule);\n\n      document.head.appendChild(getStyleForRule(rule));\n\n    }\n\n  });\n\n  return rule;\n\n}\n\n\n\nfunction Button() {\n\n  const className = useCSS('...');\n\n  return <div className={className} />;\n\n}\n\nSimilarly to useEffect, useInsertionEffect does not run on the server. If you need to collect which CSS rules have been used on the server, you can do it during rendering:\n\nlet collectedRulesSet = new Set();\n\n\n\nfunction useCSS(rule) {\n\n  if (typeof window === 'undefined') {\n\n    collectedRulesSet.add(rule);\n\n  }\n\n  useInsertionEffect(() => {\n\n    // ...\n\n  });\n\n  return rule;\n\n}\n\nRead more about upgrading CSS-in-JS libraries with runtime injection to useInsertionEffect.\n\nDEEP DIVE\nHow is this better than injecting styles during rendering or useLayoutEffect? \nShow Details\nPREVIOUS\nuseImperativeHandle\nNEXT\nuseLayoutEffect"
  },
  {
    "title": "useLayoutEffect – React",
    "url": "https://react.dev/reference/react/useLayoutEffect",
    "html": "API REFERENCE\nHOOKS\nuseLayoutEffect\nPitfall\n\nuseLayoutEffect can hurt performance. Prefer useEffect when possible.\n\nuseLayoutEffect is a version of useEffect that fires before the browser repaints the screen.\n\nuseLayoutEffect(setup, dependencies?)\nReference\nuseLayoutEffect(setup, dependencies?)\nUsage\nMeasuring layout before the browser repaints the screen\nTroubleshooting\nI’m getting an error: “useLayoutEffect does nothing on the server”\nReference \nuseLayoutEffect(setup, dependencies?) \n\nCall useLayoutEffect to perform the layout measurements before the browser repaints the screen:\n\nimport { useState, useRef, useLayoutEffect } from 'react';\n\n\n\nfunction Tooltip() {\n\n  const ref = useRef(null);\n\n  const [tooltipHeight, setTooltipHeight] = useState(0);\n\n\n\n  useLayoutEffect(() => {\n\n    const { height } = ref.current.getBoundingClientRect();\n\n    setTooltipHeight(height);\n\n  }, []);\n\n  // ...\n\nSee more examples below.\n\nParameters \n\nsetup: The function with your Effect’s logic. Your setup function may also optionally return a cleanup function. Before your component is added to the DOM, React will run your setup function. After every re-render with changed dependencies, React will first run the cleanup function (if you provided it) with the old values, and then run your setup function with the new values. Before your component is removed from the DOM, React will run your cleanup function.\n\noptional dependencies: The list of all reactive values referenced inside of the setup code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison. If you omit this argument, your Effect will re-run after every re-render of the component.\n\nReturns \n\nuseLayoutEffect returns undefined.\n\nCaveats \n\nuseLayoutEffect is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a component and move the Effect there.\n\nWhen Strict Mode is on, React will run one extra development-only setup+cleanup cycle before the first real setup. This is a stress-test that ensures that your cleanup logic “mirrors” your setup logic and that it stops or undoes whatever the setup is doing. If this causes a problem, implement the cleanup function.\n\nIf some of your dependencies are objects or functions defined inside the component, there is a risk that they will cause the Effect to re-run more often than needed. To fix this, remove unnecessary object and function dependencies. You can also extract state updates and non-reactive logic outside of your Effect.\n\nEffects only run on the client. They don’t run during server rendering.\n\nThe code inside useLayoutEffect and all state updates scheduled from it block the browser from repainting the screen. When used excessively, this makes your app slow. When possible, prefer useEffect.\n\nIf you trigger a state update inside useLayoutEffect, React will execute all remaining Effects immediately including useEffect.\n\nUsage \nMeasuring layout before the browser repaints the screen \n\nMost components don’t need to know their position and size on the screen to decide what to render. They only return some JSX. Then the browser calculates their layout (position and size) and repaints the screen.\n\nSometimes, that’s not enough. Imagine a tooltip that appears next to some element on hover. If there’s enough space, the tooltip should appear above the element, but if it doesn’t fit, it should appear below. In order to render the tooltip at the right final position, you need to know its height (i.e. whether it fits at the top).\n\nTo do this, you need to render in two passes:\n\nRender the tooltip anywhere (even with a wrong position).\nMeasure its height and decide where to place the tooltip.\nRender the tooltip again in the correct place.\n\nAll of this needs to happen before the browser repaints the screen. You don’t want the user to see the tooltip moving. Call useLayoutEffect to perform the layout measurements before the browser repaints the screen:\n\nfunction Tooltip() {\n\n  const ref = useRef(null);\n\n  const [tooltipHeight, setTooltipHeight] = useState(0); // You don't know real height yet\n\n\n\n  useLayoutEffect(() => {\n\n    const { height } = ref.current.getBoundingClientRect();\n\n    setTooltipHeight(height); // Re-render now that you know the real height\n\n  }, []);\n\n\n\n  // ...use tooltipHeight in the rendering logic below...\n\n}\n\nHere’s how this works step by step:\n\nTooltip renders with the initial tooltipHeight = 0 (so the tooltip may be wrongly positioned).\nReact places it in the DOM and runs the code in useLayoutEffect.\nYour useLayoutEffect measures the height of the tooltip content and triggers an immediate re-render.\nTooltip renders again with the real tooltipHeight (so the tooltip is correctly positioned).\nReact updates it in the DOM, and the browser finally displays the tooltip.\n\nHover over the buttons below and see how the tooltip adjusts its position depending on whether it fits:\n\nApp.js\nButtonWithTooltip.js\nTooltip.js\nTooltipContainer.js\nReload\nClear\nFork\nimport { useRef, useLayoutEffect, useState } from 'react';\nimport { createPortal } from 'react-dom';\nimport TooltipContainer from './TooltipContainer.js';\n\nexport default function Tooltip({ children, targetRect }) {\n  const ref = useRef(null);\n  const [tooltipHeight, setTooltipHeight] = useState(0);\n\n  useLayoutEffect(() => {\n    const { height } = ref.current.getBoundingClientRect();\n    setTooltipHeight(height);\n    console.log('Measured tooltip height: ' + height);\n  }, []);\n\n  let tooltipX = 0;\n  let tooltipY = 0;\n  if (targetRect !== null) {\n    tooltipX = targetRect.left;\n    tooltipY = targetRect.top - tooltipHeight;\n    if (tooltipY < 0) {\n      // It doesn't fit above, so place below.\n      tooltipY = targetRect.bottom;\n    }\n  }\n\n  return createPortal(\n    <TooltipContainer x={tooltipX} y={tooltipY} contentRef={ref}>\n      {children}\n    </TooltipContainer>,\n    document.body\n  );\n}\n\n\nShow more\n\nNotice that even though the Tooltip component has to render in two passes (first, with tooltipHeight initialized to 0 and then with the real measured height), you only see the final result. This is why you need useLayoutEffect instead of useEffect for this example. Let’s look at the difference in detail below.\n\nuseLayoutEffect vs useEffect\n1. useLayoutEffect blocks the browser from repainting\n2. useEffect does not block the browser\nExample 1 of 2: useLayoutEffect blocks the browser from repainting \n\nReact guarantees that the code inside useLayoutEffect and any state updates scheduled inside it will be processed before the browser repaints the screen. This lets you render the tooltip, measure it, and re-render the tooltip again without the user noticing the first extra render. In other words, useLayoutEffect blocks the browser from painting.\n\nApp.js\nButtonWithTooltip.js\nTooltip.js\nTooltipContainer.js\nReload\nClear\nFork\nimport { useRef, useLayoutEffect, useState } from 'react';\nimport { createPortal } from 'react-dom';\nimport TooltipContainer from './TooltipContainer.js';\n\nexport default function Tooltip({ children, targetRect }) {\n  const ref = useRef(null);\n  const [tooltipHeight, setTooltipHeight] = useState(0);\n\n  useLayoutEffect(() => {\n    const { height } = ref.current.getBoundingClientRect();\n    setTooltipHeight(height);\n  }, []);\n\n  let tooltipX = 0;\n  let tooltipY = 0;\n  if (targetRect !== null) {\n    tooltipX = targetRect.left;\n    tooltipY = targetRect.top - tooltipHeight;\n    if (tooltipY < 0) {\n      // It doesn't fit above, so place below.\n      tooltipY = targetRect.bottom;\n    }\n  }\n\n  return createPortal(\n    <TooltipContainer x={tooltipX} y={tooltipY} contentRef={ref}>\n      {children}\n    </TooltipContainer>,\n    document.body\n  );\n}\n\n\nShow more\nNext Example\nNote\n\nRendering in two passes and blocking the browser hurts performance. Try to avoid this when you can.\n\nTroubleshooting \nI’m getting an error: “useLayoutEffect does nothing on the server” \n\nThe purpose of useLayoutEffect is to let your component use layout information for rendering:\n\nRender the initial content.\nMeasure the layout before the browser repaints the screen.\nRender the final content using the layout information you’ve read.\n\nWhen you or your framework uses server rendering, your React app renders to HTML on the server for the initial render. This lets you show the initial HTML before the JavaScript code loads.\n\nThe problem is that on the server, there is no layout information.\n\nIn the earlier example, the useLayoutEffect call in the Tooltip component lets it position itself correctly (either above or below content) depending on the content height. If you tried to render Tooltip as a part of the initial server HTML, this would be impossible to determine. On the server, there is no layout yet! So, even if you rendered it on the server, its position would “jump” on the client after the JavaScript loads and runs.\n\nUsually, components that rely on layout information don’t need to render on the server anyway. For example, it probably doesn’t make sense to show a Tooltip during the initial render. It is triggered by a client interaction.\n\nHowever, if you’re running into this problem, you have a few different options:\n\nReplace useLayoutEffect with useEffect. This tells React that it’s okay to display the initial render result without blocking the paint (because the original HTML will become visible before your Effect runs).\n\nAlternatively, mark your component as client-only. This tells React to replace its content up to the closest <Suspense> boundary with a loading fallback (for example, a spinner or a glimmer) during server rendering.\n\nAlternatively, you can render a component with useLayoutEffect only after hydration. Keep a boolean isMounted state that’s initialized to false, and set it to true inside a useEffect call. Your rendering logic can then be like return isMounted ? <RealContent /> : <FallbackContent />. On the server and during the hydration, the user will see FallbackContent which should not call useLayoutEffect. Then React will replace it with RealContent which runs on the client only and can include useLayoutEffect calls.\n\nIf you synchronize your component with an external data store and rely on useLayoutEffect for different reasons than measuring layout, consider useSyncExternalStore instead which supports server rendering.\n\nPREVIOUS\nuseInsertionEffect\nNEXT\nuseMemo"
  },
  {
    "title": "useMemo – React",
    "url": "https://react.dev/reference/react/useMemo",
    "html": "API REFERENCE\nHOOKS\nuseMemo\n\nuseMemo is a React Hook that lets you cache the result of a calculation between re-renders.\n\nconst cachedValue = useMemo(calculateValue, dependencies)\nNote\n\nReact Compiler automatically memoizes values and functions, reducing the need for manual useMemo calls. You can use the compiler to handle memoization automatically.\n\nReference\nuseMemo(calculateValue, dependencies)\nUsage\nSkipping expensive recalculations\nSkipping re-rendering of components\nPreventing an Effect from firing too often\nMemoizing a dependency of another Hook\nMemoizing a function\nTroubleshooting\nMy calculation runs twice on every re-render\nMy useMemo call is supposed to return an object, but returns undefined\nEvery time my component renders, the calculation in useMemo re-runs\nI need to call useMemo for each list item in a loop, but it’s not allowed\nReference \nuseMemo(calculateValue, dependencies) \n\nCall useMemo at the top level of your component to cache a calculation between re-renders:\n\nimport { useMemo } from 'react';\n\n\n\nfunction TodoList({ todos, tab }) {\n\n  const visibleTodos = useMemo(\n\n    () => filterTodos(todos, tab),\n\n    [todos, tab]\n\n  );\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \n\ncalculateValue: The function calculating the value that you want to cache. It should be pure, should take no arguments, and should return a value of any type. React will call your function during the initial render. On next renders, React will return the same value again if the dependencies have not changed since the last render. Otherwise, it will call calculateValue, return its result, and store it so it can be reused later.\n\ndependencies: The list of all reactive values referenced inside of the calculateValue code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison.\n\nReturns \n\nOn the initial render, useMemo returns the result of calling calculateValue with no arguments.\n\nDuring next renders, it will either return an already stored value from the last render (if the dependencies haven’t changed), or call calculateValue again, and return the result that calculateValue has returned.\n\nCaveats \nuseMemo is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nIn Strict Mode, React will call your calculation function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your calculation function is pure (as it should be), this should not affect your logic. The result from one of the calls will be ignored.\nReact will not throw away the cached value unless there is a specific reason to do that. For example, in development, React throws away the cache when you edit the file of your component. Both in development and in production, React will throw away the cache if your component suspends during the initial mount. In the future, React may add more features that take advantage of throwing away the cache—for example, if React adds built-in support for virtualized lists in the future, it would make sense to throw away the cache for items that scroll out of the virtualized table viewport. This should be fine if you rely on useMemo solely as a performance optimization. Otherwise, a state variable or a ref may be more appropriate.\nNote\n\nCaching return values like this is also known as memoization, which is why this Hook is called useMemo.\n\nUsage \nSkipping expensive recalculations \n\nTo cache a calculation between re-renders, wrap it in a useMemo call at the top level of your component:\n\nimport { useMemo } from 'react';\n\n\n\nfunction TodoList({ todos, tab, theme }) {\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  // ...\n\n}\n\nYou need to pass two things to useMemo:\n\nA calculation function that takes no arguments, like () =>, and returns what you wanted to calculate.\nA list of dependencies including every value within your component that’s used inside your calculation.\n\nOn the initial render, the value you’ll get from useMemo will be the result of calling your calculation.\n\nOn every subsequent render, React will compare the dependencies with the dependencies you passed during the last render. If none of the dependencies have changed (compared with Object.is), useMemo will return the value you already calculated before. Otherwise, React will re-run your calculation and return the new value.\n\nIn other words, useMemo caches a calculation result between re-renders until its dependencies change.\n\nLet’s walk through an example to see when this is useful.\n\nBy default, React will re-run the entire body of your component every time that it re-renders. For example, if this TodoList updates its state or receives new props from its parent, the filterTodos function will re-run:\n\nfunction TodoList({ todos, tab, theme }) {\n\n  const visibleTodos = filterTodos(todos, tab);\n\n  // ...\n\n}\n\nUsually, this isn’t a problem because most calculations are very fast. However, if you’re filtering or transforming a large array, or doing some expensive computation, you might want to skip doing it again if data hasn’t changed. If both todos and tab are the same as they were during the last render, wrapping the calculation in useMemo like earlier lets you reuse visibleTodos you’ve already calculated before.\n\nThis type of caching is called memoization.\n\nNote\n\nYou should only rely on useMemo as a performance optimization. If your code doesn’t work without it, find the underlying problem and fix it first. Then you may add useMemo to improve performance.\n\nDEEP DIVE\nHow to tell if a calculation is expensive? \nShow Details\nDEEP DIVE\nShould you add useMemo everywhere? \nShow Details\nThe difference between useMemo and calculating a value directly\n1. Skipping recalculation with useMemo\n2. Always recalculating a value\nExample 1 of 2: Skipping recalculation with useMemo \n\nIn this example, the filterTodos implementation is artificially slowed down so that you can see what happens when some JavaScript function you’re calling during rendering is genuinely slow. Try switching the tabs and toggling the theme.\n\nSwitching the tabs feels slow because it forces the slowed down filterTodos to re-execute. That’s expected because the tab has changed, and so the entire calculation needs to re-run. (If you’re curious why it runs twice, it’s explained here.)\n\nToggle the theme. Thanks to useMemo, it’s fast despite the artificial slowdown! The slow filterTodos call was skipped because both todos and tab (which you pass as dependencies to useMemo) haven’t changed since the last render.\n\nApp.js\nTodoList.js\nutils.js\nReload\nClear\nFork\nimport { useMemo } from 'react';\nimport { filterTodos } from './utils.js'\n\nexport default function TodoList({ todos, theme, tab }) {\n  const visibleTodos = useMemo(\n    () => filterTodos(todos, tab),\n    [todos, tab]\n  );\n  return (\n    <div className={theme}>\n      <p><b>Note: <code>filterTodos</code> is artificially slowed down!</b></p>\n      <ul>\n        {visibleTodos.map(todo => (\n          <li key={todo.id}>\n            {todo.completed ?\n              <s>{todo.text}</s> :\n              todo.text\n            }\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\n\nShow more\nNext Example\nSkipping re-rendering of components \n\nIn some cases, useMemo can also help you optimize performance of re-rendering child components. To illustrate this, let’s say this TodoList component passes the visibleTodos as a prop to the child List component:\n\nexport default function TodoList({ todos, tab, theme }) {\n\n  // ...\n\n  return (\n\n    <div className={theme}>\n\n      <List items={visibleTodos} />\n\n    </div>\n\n  );\n\n}\n\nYou’ve noticed that toggling the theme prop freezes the app for a moment, but if you remove <List /> from your JSX, it feels fast. This tells you that it’s worth trying to optimize the List component.\n\nBy default, when a component re-renders, React re-renders all of its children recursively. This is why, when TodoList re-renders with a different theme, the List component also re-renders. This is fine for components that don’t require much calculation to re-render. But if you’ve verified that a re-render is slow, you can tell List to skip re-rendering when its props are the same as on last render by wrapping it in memo:\n\nimport { memo } from 'react';\n\n\n\nconst List = memo(function List({ items }) {\n\n  // ...\n\n});\n\nWith this change, List will skip re-rendering if all of its props are the same as on the last render. This is where caching the calculation becomes important! Imagine that you calculated visibleTodos without useMemo:\n\nexport default function TodoList({ todos, tab, theme }) {\n\n  // Every time the theme changes, this will be a different array...\n\n  const visibleTodos = filterTodos(todos, tab);\n\n  return (\n\n    <div className={theme}>\n\n      {/* ... so List's props will never be the same, and it will re-render every time */}\n\n      <List items={visibleTodos} />\n\n    </div>\n\n  );\n\n}\n\nIn the above example, the filterTodos function always creates a different array, similar to how the {} object literal always creates a new object. Normally, this wouldn’t be a problem, but it means that List props will never be the same, and your memo optimization won’t work. This is where useMemo comes in handy:\n\nexport default function TodoList({ todos, tab, theme }) {\n\n  // Tell React to cache your calculation between re-renders...\n\n  const visibleTodos = useMemo(\n\n    () => filterTodos(todos, tab),\n\n    [todos, tab] // ...so as long as these dependencies don't change...\n\n  );\n\n  return (\n\n    <div className={theme}>\n\n      {/* ...List will receive the same props and can skip re-rendering */}\n\n      <List items={visibleTodos} />\n\n    </div>\n\n  );\n\n}\n\nBy wrapping the visibleTodos calculation in useMemo, you ensure that it has the same value between the re-renders (until dependencies change). You don’t have to wrap a calculation in useMemo unless you do it for some specific reason. In this example, the reason is that you pass it to a component wrapped in memo, and this lets it skip re-rendering. There are a few other reasons to add useMemo which are described further on this page.\n\nDEEP DIVE\nMemoizing individual JSX nodes \nShow Details\nThe difference between skipping re-renders and always re-rendering\n1. Skipping re-rendering with useMemo and memo\n2. Always re-rendering a component\nExample 1 of 2: Skipping re-rendering with useMemo and memo \n\nIn this example, the List component is artificially slowed down so that you can see what happens when a React component you’re rendering is genuinely slow. Try switching the tabs and toggling the theme.\n\nSwitching the tabs feels slow because it forces the slowed down List to re-render. That’s expected because the tab has changed, and so you need to reflect the user’s new choice on the screen.\n\nNext, try toggling the theme. Thanks to useMemo together with memo, it’s fast despite the artificial slowdown! The List skipped re-rendering because the visibleTodos array has not changed since the last render. The visibleTodos array has not changed because both todos and tab (which you pass as dependencies to useMemo) haven’t changed since the last render.\n\nApp.js\nTodoList.js\nList.js\nutils.js\nReload\nClear\nFork\nimport { useMemo } from 'react';\nimport List from './List.js';\nimport { filterTodos } from './utils.js'\n\nexport default function TodoList({ todos, theme, tab }) {\n  const visibleTodos = useMemo(\n    () => filterTodos(todos, tab),\n    [todos, tab]\n  );\n  return (\n    <div className={theme}>\n      <p><b>Note: <code>List</code> is artificially slowed down!</b></p>\n      <List items={visibleTodos} />\n    </div>\n  );\n}\n\n\nShow more\nNext Example\nPreventing an Effect from firing too often \n\nSometimes, you might want to use a value inside an Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const options = {\n\n    serverUrl: 'https://localhost:1234',\n\n    roomId: roomId\n\n  }\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    // ...\n\nThis creates a problem. Every reactive value must be declared as a dependency of your Effect. However, if you declare options as a dependency, it will cause your Effect to constantly reconnect to the chat room:\n\n  useEffect(() => {\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [options]); // 🔴 Problem: This dependency changes on every render\n\n  // ...\n\nTo solve this, you can wrap the object you need to call from an Effect in useMemo:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const options = useMemo(() => {\n\n    return {\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    };\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [options]); // ✅ Only changes when options changes\n\n  // ...\n\nThis ensures that the options object is the same between re-renders if useMemo returns the cached object.\n\nHowever, since useMemo is performance optimization, not a semantic guarantee, React may throw away the cached value if there is a specific reason to do that. This will also cause the effect to re-fire, so it’s even better to remove the need for a function dependency by moving your object inside the Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  useEffect(() => {\n\n    const options = { // ✅ No need for useMemo or object dependencies!\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    }\n\n\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n  // ...\n\nNow your code is simpler and doesn’t need useMemo. Learn more about removing Effect dependencies.\n\nMemoizing a dependency of another Hook \n\nSuppose you have a calculation that depends on an object created directly in the component body:\n\nfunction Dropdown({ allItems, text }) {\n\n  const searchOptions = { matchMode: 'whole-word', text };\n\n\n\n  const visibleItems = useMemo(() => {\n\n    return searchItems(allItems, searchOptions);\n\n  }, [allItems, searchOptions]); // 🚩 Caution: Dependency on an object created in the component body\n\n  // ...\n\nDepending on an object like this defeats the point of memoization. When a component re-renders, all of the code directly inside the component body runs again. The lines of code creating the searchOptions object will also run on every re-render. Since searchOptions is a dependency of your useMemo call, and it’s different every time, React knows the dependencies are different, and recalculate searchItems every time.\n\nTo fix this, you could memoize the searchOptions object itself before passing it as a dependency:\n\nfunction Dropdown({ allItems, text }) {\n\n  const searchOptions = useMemo(() => {\n\n    return { matchMode: 'whole-word', text };\n\n  }, [text]); // ✅ Only changes when text changes\n\n\n\n  const visibleItems = useMemo(() => {\n\n    return searchItems(allItems, searchOptions);\n\n  }, [allItems, searchOptions]); // ✅ Only changes when allItems or searchOptions changes\n\n  // ...\n\nIn the example above, if the text did not change, the searchOptions object also won’t change. However, an even better fix is to move the searchOptions object declaration inside of the useMemo calculation function:\n\nfunction Dropdown({ allItems, text }) {\n\n  const visibleItems = useMemo(() => {\n\n    const searchOptions = { matchMode: 'whole-word', text };\n\n    return searchItems(allItems, searchOptions);\n\n  }, [allItems, text]); // ✅ Only changes when allItems or text changes\n\n  // ...\n\nNow your calculation depends on text directly (which is a string and can’t “accidentally” become different).\n\nMemoizing a function \n\nSuppose the Form component is wrapped in memo. You want to pass a function to it as a prop:\n\nexport default function ProductPage({ productId, referrer }) {\n\n  function handleSubmit(orderDetails) {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails\n\n    });\n\n  }\n\n\n\n  return <Form onSubmit={handleSubmit} />;\n\n}\n\nJust as {} creates a different object, function declarations like function() {} and expressions like () => {} produce a different function on every re-render. By itself, creating a new function is not a problem. This is not something to avoid! However, if the Form component is memoized, presumably you want to skip re-rendering it when no props have changed. A prop that is always different would defeat the point of memoization.\n\nTo memoize a function with useMemo, your calculation function would have to return another function:\n\nexport default function Page({ productId, referrer }) {\n\n  const handleSubmit = useMemo(() => {\n\n    return (orderDetails) => {\n\n      post('/product/' + productId + '/buy', {\n\n        referrer,\n\n        orderDetails\n\n      });\n\n    };\n\n  }, [productId, referrer]);\n\n\n\n  return <Form onSubmit={handleSubmit} />;\n\n}\n\nThis looks clunky! Memoizing functions is common enough that React has a built-in Hook specifically for that. Wrap your functions into useCallback instead of useMemo to avoid having to write an extra nested function:\n\nexport default function Page({ productId, referrer }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails\n\n    });\n\n  }, [productId, referrer]);\n\n\n\n  return <Form onSubmit={handleSubmit} />;\n\n}\n\nThe two examples above are completely equivalent. The only benefit to useCallback is that it lets you avoid writing an extra nested function inside. It doesn’t do anything else. Read more about useCallback.\n\nTroubleshooting \nMy calculation runs twice on every re-render \n\nIn Strict Mode, React will call some of your functions twice instead of once:\n\nfunction TodoList({ todos, tab }) {\n\n  // This component function will run twice for every render.\n\n\n\n  const visibleTodos = useMemo(() => {\n\n    // This calculation will run twice if any of the dependencies change.\n\n    return filterTodos(todos, tab);\n\n  }, [todos, tab]);\n\n\n\n  // ...\n\nThis is expected and shouldn’t break your code.\n\nThis development-only behavior helps you keep components pure. React uses the result of one of the calls, and ignores the result of the other call. As long as your component and calculation functions are pure, this shouldn’t affect your logic. However, if they are accidentally impure, this helps you notice and fix the mistake.\n\nFor example, this impure calculation function mutates an array you received as a prop:\n\n  const visibleTodos = useMemo(() => {\n\n    // 🚩 Mistake: mutating a prop\n\n    todos.push({ id: 'last', text: 'Go for a walk!' });\n\n    const filtered = filterTodos(todos, tab);\n\n    return filtered;\n\n  }, [todos, tab]);\n\nReact calls your function twice, so you’d notice the todo is added twice. Your calculation shouldn’t change any existing objects, but it’s okay to change any new objects you created during the calculation. For example, if the filterTodos function always returns a different array, you can mutate that array instead:\n\n  const visibleTodos = useMemo(() => {\n\n    const filtered = filterTodos(todos, tab);\n\n    // ✅ Correct: mutating an object you created during the calculation\n\n    filtered.push({ id: 'last', text: 'Go for a walk!' });\n\n    return filtered;\n\n  }, [todos, tab]);\n\nRead keeping components pure to learn more about purity.\n\nAlso, check out the guides on updating objects and updating arrays without mutation.\n\nMy useMemo call is supposed to return an object, but returns undefined \n\nThis code doesn’t work:\n\n  // 🔴 You can't return an object from an arrow function with () => {\n\n  const searchOptions = useMemo(() => {\n\n    matchMode: 'whole-word',\n\n    text: text\n\n  }, [text]);\n\nIn JavaScript, () => { starts the arrow function body, so the { brace is not a part of your object. This is why it doesn’t return an object, and leads to mistakes. You could fix it by adding parentheses like ({ and }):\n\n  // This works, but is easy for someone to break again\n\n  const searchOptions = useMemo(() => ({\n\n    matchMode: 'whole-word',\n\n    text: text\n\n  }), [text]);\n\nHowever, this is still confusing and too easy for someone to break by removing the parentheses.\n\nTo avoid this mistake, write a return statement explicitly:\n\n  // ✅ This works and is explicit\n\n  const searchOptions = useMemo(() => {\n\n    return {\n\n      matchMode: 'whole-word',\n\n      text: text\n\n    };\n\n  }, [text]);\nEvery time my component renders, the calculation in useMemo re-runs \n\nMake sure you’ve specified the dependency array as a second argument!\n\nIf you forget the dependency array, useMemo will re-run the calculation every time:\n\nfunction TodoList({ todos, tab }) {\n\n  // 🔴 Recalculates every time: no dependency array\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab));\n\n  // ...\n\nThis is the corrected version passing the dependency array as a second argument:\n\nfunction TodoList({ todos, tab }) {\n\n  // ✅ Does not recalculate unnecessarily\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  // ...\n\nIf this doesn’t help, then the problem is that at least one of your dependencies is different from the previous render. You can debug this problem by manually logging your dependencies to the console:\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  console.log([todos, tab]);\n\nYou can then right-click on the arrays from different re-renders in the console and select “Store as a global variable” for both of them. Assuming the first one got saved as temp1 and the second one got saved as temp2, you can then use the browser console to check whether each dependency in both arrays is the same:\n\nObject.is(temp1[0], temp2[0]); // Is the first dependency the same between the arrays?\n\nObject.is(temp1[1], temp2[1]); // Is the second dependency the same between the arrays?\n\nObject.is(temp1[2], temp2[2]); // ... and so on for every dependency ...\n\nWhen you find which dependency breaks memoization, either find a way to remove it, or memoize it as well.\n\nI need to call useMemo for each list item in a loop, but it’s not allowed \n\nSuppose the Chart component is wrapped in memo. You want to skip re-rendering every Chart in the list when the ReportList component re-renders. However, you can’t call useMemo in a loop:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item => {\n\n        // 🔴 You can't call useMemo in a loop like this:\n\n        const data = useMemo(() => calculateReport(item), [item]);\n\n        return (\n\n          <figure key={item.id}>\n\n            <Chart data={data} />\n\n          </figure>\n\n        );\n\n      })}\n\n    </article>\n\n  );\n\n}\n\nInstead, extract a component for each item and memoize data for individual items:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item =>\n\n        <Report key={item.id} item={item} />\n\n      )}\n\n    </article>\n\n  );\n\n}\n\n\n\nfunction Report({ item }) {\n\n  // ✅ Call useMemo at the top level:\n\n  const data = useMemo(() => calculateReport(item), [item]);\n\n  return (\n\n    <figure>\n\n      <Chart data={data} />\n\n    </figure>\n\n  );\n\n}\n\nAlternatively, you could remove useMemo and instead wrap Report itself in memo. If the item prop does not change, Report will skip re-rendering, so Chart will skip re-rendering too:\n\nfunction ReportList({ items }) {\n\n  // ...\n\n}\n\n\n\nconst Report = memo(function Report({ item }) {\n\n  const data = calculateReport(item);\n\n  return (\n\n    <figure>\n\n      <Chart data={data} />\n\n    </figure>\n\n  );\n\n});\nPREVIOUS\nuseLayoutEffect\nNEXT\nuseOptimistic"
  },
  {
    "title": "useOptimistic – React",
    "url": "https://react.dev/reference/react/useOptimistic",
    "html": "API REFERENCE\nHOOKS\nuseOptimistic\n\nuseOptimistic is a React Hook that lets you optimistically update the UI.\n\n  const [optimisticState, addOptimistic] = useOptimistic(state, updateFn);\nReference\nuseOptimistic(state, updateFn)\nUsage\nOptimistically updating forms\nReference \nuseOptimistic(state, updateFn) \n\nuseOptimistic is a React Hook that lets you show a different state while an async action is underway. It accepts some state as an argument and returns a copy of that state that can be different during the duration of an async action such as a network request. You provide a function that takes the current state and the input to the action, and returns the optimistic state to be used while the action is pending.\n\nThis state is called the “optimistic” state because it is usually used to immediately present the user with the result of performing an action, even though the action actually takes time to complete.\n\nimport { useOptimistic } from 'react';\n\n\n\nfunction AppContainer() {\n\n  const [optimisticState, addOptimistic] = useOptimistic(\n\n    state,\n\n    // updateFn\n\n    (currentState, optimisticValue) => {\n\n      // merge and return new state\n\n      // with optimistic value\n\n    }\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \nstate: the value to be returned initially and whenever no action is pending.\nupdateFn(currentState, optimisticValue): a function that takes the current state and the optimistic value passed to addOptimistic and returns the resulting optimistic state. It must be a pure function. updateFn takes in two parameters. The currentState and the optimisticValue. The return value will be the merged value of the currentState and optimisticValue.\nReturns \noptimisticState: The resulting optimistic state. It is equal to state unless an action is pending, in which case it is equal to the value returned by updateFn.\naddOptimistic: addOptimistic is the dispatching function to call when you have an optimistic update. It takes one argument, optimisticValue, of any type and will call the updateFn with state and optimisticValue.\nUsage \nOptimistically updating forms \n\nThe useOptimistic Hook provides a way to optimistically update the user interface before a background operation, like a network request, completes. In the context of forms, this technique helps to make apps feel more responsive. When a user submits a form, instead of waiting for the server’s response to reflect the changes, the interface is immediately updated with the expected outcome.\n\nFor example, when a user types a message into the form and hits the “Send” button, the useOptimistic Hook allows the message to immediately appear in the list with a “Sending…” label, even before the message is actually sent to a server. This “optimistic” approach gives the impression of speed and responsiveness. The form then attempts to truly send the message in the background. Once the server confirms the message has been received, the “Sending…” label is removed.\n\nApp.js\nactions.js\nReload\nClear\nFork\nimport { useOptimistic, useState, useRef, startTransition } from \"react\";\nimport { deliverMessage } from \"./actions.js\";\n\nfunction Thread({ messages, sendMessageAction }) {\n  const formRef = useRef();\n  function formAction(formData) {\n    addOptimisticMessage(formData.get(\"message\"));\n    formRef.current.reset();\n    startTransition(async () => {\n      await sendMessageAction(formData);\n    });\n  }\n  const [optimisticMessages, addOptimisticMessage] = useOptimistic(\n    messages,\n    (state, newMessage) => [\n      {\n        text: newMessage,\n        sending: true\n      },\n      ...state,\n    ]\n  );\n\n  return (\n    <>\n      <form action={formAction} ref={formRef}>\n        <input type=\"text\" name=\"message\" placeholder=\"Hello!\" />\n        <button type=\"submit\">Send</button>\n      </form>\n      {optimisticMessages.map((message, index) => (\n        <div key={index}>\n          {message.text}\n          {!!message.sending && <small> (Sending...)</small>}\n        </div>\n      ))}\n      \n    </>\n  );\n}\n\nexport default function App() {\n  const [messages, setMessages] = useState([\n    { text: \"Hello there!\", sending: false, key: 1 }\n  ]);\n  async function sendMessageAction(formData) {\n    const sentMessage = await deliverMessage(formData.get(\"message\"));\n    startTransition(() => {\n      setMessages((messages) => [{ text: sentMessage }, ...messages]);\n    })\n  }\n  return <Thread messages={messages} sendMessageAction={sendMessageAction} />;\n}\n\n\nShow more\nPREVIOUS\nuseMemo\nNEXT\nuseReducer"
  },
  {
    "title": "useReducer – React",
    "url": "https://react.dev/reference/react/useReducer",
    "html": "API REFERENCE\nHOOKS\nuseReducer\n\nuseReducer is a React Hook that lets you add a reducer to your component.\n\nconst [state, dispatch] = useReducer(reducer, initialArg, init?)\nReference\nuseReducer(reducer, initialArg, init?)\ndispatch function\nUsage\nAdding a reducer to a component\nWriting the reducer function\nAvoiding recreating the initial state\nTroubleshooting\nI’ve dispatched an action, but logging gives me the old state value\nI’ve dispatched an action, but the screen doesn’t update\nA part of my reducer state becomes undefined after dispatching\nMy entire reducer state becomes undefined after dispatching\nI’m getting an error: “Too many re-renders”\nMy reducer or initializer function runs twice\nReference \nuseReducer(reducer, initialArg, init?) \n\nCall useReducer at the top level of your component to manage its state with a reducer.\n\nimport { useReducer } from 'react';\n\n\n\nfunction reducer(state, action) {\n\n  // ...\n\n}\n\n\n\nfunction MyComponent() {\n\n  const [state, dispatch] = useReducer(reducer, { age: 42 });\n\n  // ...\n\nSee more examples below.\n\nParameters \nreducer: The reducer function that specifies how the state gets updated. It must be pure, should take the state and action as arguments, and should return the next state. State and action can be of any types.\ninitialArg: The value from which the initial state is calculated. It can be a value of any type. How the initial state is calculated from it depends on the next init argument.\noptional init: The initializer function that should return the initial state. If it’s not specified, the initial state is set to initialArg. Otherwise, the initial state is set to the result of calling init(initialArg).\nReturns \n\nuseReducer returns an array with exactly two values:\n\nThe current state. During the first render, it’s set to init(initialArg) or initialArg (if there’s no init).\nThe dispatch function that lets you update the state to a different value and trigger a re-render.\nCaveats \nuseReducer is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nThe dispatch function has a stable identity, so you will often see it omitted from Effect dependencies, but including it will not cause the Effect to fire. If the linter lets you omit a dependency without errors, it is safe to do. Learn more about removing Effect dependencies.\nIn Strict Mode, React will call your reducer and initializer twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your reducer and initializer are pure (as they should be), this should not affect your logic. The result from one of the calls is ignored.\ndispatch function \n\nThe dispatch function returned by useReducer lets you update the state to a different value and trigger a re-render. You need to pass the action as the only argument to the dispatch function:\n\nconst [state, dispatch] = useReducer(reducer, { age: 42 });\n\n\n\nfunction handleClick() {\n\n  dispatch({ type: 'incremented_age' });\n\n  // ...\n\nReact will set the next state to the result of calling the reducer function you’ve provided with the current state and the action you’ve passed to dispatch.\n\nParameters \naction: The action performed by the user. It can be a value of any type. By convention, an action is usually an object with a type property identifying it and, optionally, other properties with additional information.\nReturns \n\ndispatch functions do not have a return value.\n\nCaveats \n\nThe dispatch function only updates the state variable for the next render. If you read the state variable after calling the dispatch function, you will still get the old value that was on the screen before your call.\n\nIf the new value you provide is identical to the current state, as determined by an Object.is comparison, React will skip re-rendering the component and its children. This is an optimization. React may still need to call your component before ignoring the result, but it shouldn’t affect your code.\n\nReact batches state updates. It updates the screen after all the event handlers have run and have called their set functions. This prevents multiple re-renders during a single event. In the rare case that you need to force React to update the screen earlier, for example to access the DOM, you can use flushSync.\n\nUsage \nAdding a reducer to a component \n\nCall useReducer at the top level of your component to manage state with a reducer.\n\nimport { useReducer } from 'react';\n\n\n\nfunction reducer(state, action) {\n\n  // ...\n\n}\n\n\n\nfunction MyComponent() {\n\n  const [state, dispatch] = useReducer(reducer, { age: 42 });\n\n  // ...\n\nuseReducer returns an array with exactly two items:\n\nThe current state of this state variable, initially set to the initial state you provided.\nThe dispatch function that lets you change it in response to interaction.\n\nTo update what’s on the screen, call dispatch with an object representing what the user did, called an action:\n\nfunction handleClick() {\n\n  dispatch({ type: 'incremented_age' });\n\n}\n\nReact will pass the current state and the action to your reducer function. Your reducer will calculate and return the next state. React will store that next state, render your component with it, and update the UI.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useReducer } from 'react';\n\nfunction reducer(state, action) {\n  if (action.type === 'incremented_age') {\n    return {\n      age: state.age + 1\n    };\n  }\n  throw Error('Unknown action.');\n}\n\nexport default function Counter() {\n  const [state, dispatch] = useReducer(reducer, { age: 42 });\n\n  return (\n    <>\n      <button onClick={() => {\n        dispatch({ type: 'incremented_age' })\n      }}>\n        Increment age\n      </button>\n      <p>Hello! You are {state.age}.</p>\n    </>\n  );\n}\n\n\nShow more\n\nuseReducer is very similar to useState, but it lets you move the state update logic from event handlers into a single function outside of your component. Read more about choosing between useState and useReducer.\n\nWriting the reducer function \n\nA reducer function is declared like this:\n\nfunction reducer(state, action) {\n\n  // ...\n\n}\n\nThen you need to fill in the code that will calculate and return the next state. By convention, it is common to write it as a switch statement. For each case in the switch, calculate and return some next state.\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      return {\n\n        name: state.name,\n\n        age: state.age + 1\n\n      };\n\n    }\n\n    case 'changed_name': {\n\n      return {\n\n        name: action.nextName,\n\n        age: state.age\n\n      };\n\n    }\n\n  }\n\n  throw Error('Unknown action: ' + action.type);\n\n}\n\nActions can have any shape. By convention, it’s common to pass objects with a type property identifying the action. It should include the minimal necessary information that the reducer needs to compute the next state.\n\nfunction Form() {\n\n  const [state, dispatch] = useReducer(reducer, { name: 'Taylor', age: 42 });\n\n  \n\n  function handleButtonClick() {\n\n    dispatch({ type: 'incremented_age' });\n\n  }\n\n\n\n  function handleInputChange(e) {\n\n    dispatch({\n\n      type: 'changed_name',\n\n      nextName: e.target.value\n\n    });\n\n  }\n\n  // ...\n\nThe action type names are local to your component. Each action describes a single interaction, even if that leads to multiple changes in data. The shape of the state is arbitrary, but usually it’ll be an object or an array.\n\nRead extracting state logic into a reducer to learn more.\n\nPitfall\n\nState is read-only. Don’t modify any objects or arrays in state:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // 🚩 Don't mutate an object in state like this:\n\n      state.age = state.age + 1;\n\n      return state;\n\n    }\n\nInstead, always return new objects from your reducer:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // ✅ Instead, return a new object\n\n      return {\n\n        ...state,\n\n        age: state.age + 1\n\n      };\n\n    }\n\nRead updating objects in state and updating arrays in state to learn more.\n\nBasic useReducer examples\n1. Form (object)\n2. Todo list (array)\n3. Writing concise update logic with Immer\nExample 1 of 3: Form (object) \n\nIn this example, the reducer manages a state object with two fields: name and age.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useReducer } from 'react';\n\nfunction reducer(state, action) {\n  switch (action.type) {\n    case 'incremented_age': {\n      return {\n        name: state.name,\n        age: state.age + 1\n      };\n    }\n    case 'changed_name': {\n      return {\n        name: action.nextName,\n        age: state.age\n      };\n    }\n  }\n  throw Error('Unknown action: ' + action.type);\n}\n\nconst initialState = { name: 'Taylor', age: 42 };\n\nexport default function Form() {\n  const [state, dispatch] = useReducer(reducer, initialState);\n\n  function handleButtonClick() {\n    dispatch({ type: 'incremented_age' });\n  }\n\n  function handleInputChange(e) {\n    dispatch({\n      type: 'changed_name',\n      nextName: e.target.value\n    }); \n  }\n\n  return (\n    <>\n      <input\n        value={state.name}\n        onChange={handleInputChange}\n      />\n      <button onClick={handleButtonClick}>\n        Increment age\n      </button>\n      <p>Hello, {state.name}. You are {state.age}.</p>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nAvoiding recreating the initial state \n\nReact saves the initial state once and ignores it on the next renders.\n\nfunction createInitialState(username) {\n\n  // ...\n\n}\n\n\n\nfunction TodoList({ username }) {\n\n  const [state, dispatch] = useReducer(reducer, createInitialState(username));\n\n  // ...\n\nAlthough the result of createInitialState(username) is only used for the initial render, you’re still calling this function on every render. This can be wasteful if it’s creating large arrays or performing expensive calculations.\n\nTo solve this, you may pass it as an initializer function to useReducer as the third argument instead:\n\nfunction createInitialState(username) {\n\n  // ...\n\n}\n\n\n\nfunction TodoList({ username }) {\n\n  const [state, dispatch] = useReducer(reducer, username, createInitialState);\n\n  // ...\n\nNotice that you’re passing createInitialState, which is the function itself, and not createInitialState(), which is the result of calling it. This way, the initial state does not get re-created after initialization.\n\nIn the above example, createInitialState takes a username argument. If your initializer doesn’t need any information to compute the initial state, you may pass null as the second argument to useReducer.\n\nThe difference between passing an initializer and passing the initial state directly\n1. Passing the initializer function\n2. Passing the initial state directly\nExample 1 of 2: Passing the initializer function \n\nThis example passes the initializer function, so the createInitialState function only runs during initialization. It does not run when component re-renders, such as when you type into the input.\n\nTodoList.js\nReload\nClear\nFork\nimport { useReducer } from 'react';\n\nfunction createInitialState(username) {\n  const initialTodos = [];\n  for (let i = 0; i < 50; i++) {\n    initialTodos.push({\n      id: i,\n      text: username + \"'s task #\" + (i + 1)\n    });\n  }\n  return {\n    draft: '',\n    todos: initialTodos,\n  };\n}\n\nfunction reducer(state, action) {\n  switch (action.type) {\n    case 'changed_draft': {\n      return {\n        draft: action.nextDraft,\n        todos: state.todos,\n      };\n    };\n    case 'added_todo': {\n      return {\n        draft: '',\n        todos: [{\n          id: state.todos.length,\n          text: state.draft\n        }, ...state.todos]\n      }\n    }\n  }\n  throw Error('Unknown action: ' + action.type);\n}\n\nexport default function TodoList({ username }) {\n  const [state, dispatch] = useReducer(\n    reducer,\n    username,\n    createInitialState\n  );\n  return (\n    <>\n      <input\n        value={state.draft}\n        onChange={e => {\n          dispatch({\n            type: 'changed_draft',\n            nextDraft: e.target.value\n          })\n        }}\n      />\n      <button onClick={() => {\n        dispatch({ type: 'added_todo' });\n      }}>Add</button>\n      <ul>\n        {state.todos.map(item => (\n          <li key={item.id}>\n            {item.text}\n          </li>\n        ))}\n      </ul>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nTroubleshooting \nI’ve dispatched an action, but logging gives me the old state value \n\nCalling the dispatch function does not change state in the running code:\n\nfunction handleClick() {\n\n  console.log(state.age);  // 42\n\n\n\n  dispatch({ type: 'incremented_age' }); // Request a re-render with 43\n\n  console.log(state.age);  // Still 42!\n\n\n\n  setTimeout(() => {\n\n    console.log(state.age); // Also 42!\n\n  }, 5000);\n\n}\n\nThis is because states behaves like a snapshot. Updating state requests another render with the new state value, but does not affect the state JavaScript variable in your already-running event handler.\n\nIf you need to guess the next state value, you can calculate it manually by calling the reducer yourself:\n\nconst action = { type: 'incremented_age' };\n\ndispatch(action);\n\n\n\nconst nextState = reducer(state, action);\n\nconsole.log(state);     // { age: 42 }\n\nconsole.log(nextState); // { age: 43 }\nI’ve dispatched an action, but the screen doesn’t update \n\nReact will ignore your update if the next state is equal to the previous state, as determined by an Object.is comparison. This usually happens when you change an object or an array in state directly:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // 🚩 Wrong: mutating existing object\n\n      state.age++;\n\n      return state;\n\n    }\n\n    case 'changed_name': {\n\n      // 🚩 Wrong: mutating existing object\n\n      state.name = action.nextName;\n\n      return state;\n\n    }\n\n    // ...\n\n  }\n\n}\n\nYou mutated an existing state object and returned it, so React ignored the update. To fix this, you need to ensure that you’re always updating objects in state and updating arrays in state instead of mutating them:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // ✅ Correct: creating a new object\n\n      return {\n\n        ...state,\n\n        age: state.age + 1\n\n      };\n\n    }\n\n    case 'changed_name': {\n\n      // ✅ Correct: creating a new object\n\n      return {\n\n        ...state,\n\n        name: action.nextName\n\n      };\n\n    }\n\n    // ...\n\n  }\n\n}\nA part of my reducer state becomes undefined after dispatching \n\nMake sure that every case branch copies all of the existing fields when returning the new state:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      return {\n\n        ...state, // Don't forget this!\n\n        age: state.age + 1\n\n      };\n\n    }\n\n    // ...\n\nWithout ...state above, the returned next state would only contain the age field and nothing else.\n\nMy entire reducer state becomes undefined after dispatching \n\nIf your state unexpectedly becomes undefined, you’re likely forgetting to return state in one of the cases, or your action type doesn’t match any of the case statements. To find why, throw an error outside the switch:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // ...\n\n    }\n\n    case 'edited_name': {\n\n      // ...\n\n    }\n\n  }\n\n  throw Error('Unknown action: ' + action.type);\n\n}\n\nYou can also use a static type checker like TypeScript to catch such mistakes.\n\nI’m getting an error: “Too many re-renders” \n\nYou might get an error that says: Too many re-renders. React limits the number of renders to prevent an infinite loop. Typically, this means that you’re unconditionally dispatching an action during render, so your component enters a loop: render, dispatch (which causes a render), render, dispatch (which causes a render), and so on. Very often, this is caused by a mistake in specifying an event handler:\n\n// 🚩 Wrong: calls the handler during render\n\nreturn <button onClick={handleClick()}>Click me</button>\n\n\n\n// ✅ Correct: passes down the event handler\n\nreturn <button onClick={handleClick}>Click me</button>\n\n\n\n// ✅ Correct: passes down an inline function\n\nreturn <button onClick={(e) => handleClick(e)}>Click me</button>\n\nIf you can’t find the cause of this error, click on the arrow next to the error in the console and look through the JavaScript stack to find the specific dispatch function call responsible for the error.\n\nMy reducer or initializer function runs twice \n\nIn Strict Mode, React will call your reducer and initializer functions twice. This shouldn’t break your code.\n\nThis development-only behavior helps you keep components pure. React uses the result of one of the calls, and ignores the result of the other call. As long as your component, initializer, and reducer functions are pure, this shouldn’t affect your logic. However, if they are accidentally impure, this helps you notice the mistakes.\n\nFor example, this impure reducer function mutates an array in state:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'added_todo': {\n\n      // 🚩 Mistake: mutating state\n\n      state.todos.push({ id: nextId++, text: action.text });\n\n      return state;\n\n    }\n\n    // ...\n\n  }\n\n}\n\nBecause React calls your reducer function twice, you’ll see the todo was added twice, so you’ll know that there is a mistake. In this example, you can fix the mistake by replacing the array instead of mutating it:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'added_todo': {\n\n      // ✅ Correct: replacing with new state\n\n      return {\n\n        ...state,\n\n        todos: [\n\n          ...state.todos,\n\n          { id: nextId++, text: action.text }\n\n        ]\n\n      };\n\n    }\n\n    // ...\n\n  }\n\n}\n\nNow that this reducer function is pure, calling it an extra time doesn’t make a difference in behavior. This is why React calling it twice helps you find mistakes. Only component, initializer, and reducer functions need to be pure. Event handlers don’t need to be pure, so React will never call your event handlers twice.\n\nRead keeping components pure to learn more.\n\nPREVIOUS\nuseOptimistic\nNEXT\nuseRef"
  },
  {
    "title": "useRef – React",
    "url": "https://react.dev/reference/react/useRef",
    "html": "API REFERENCE\nHOOKS\nuseRef\n\nuseRef is a React Hook that lets you reference a value that’s not needed for rendering.\n\nconst ref = useRef(initialValue)\nReference\nuseRef(initialValue)\nUsage\nReferencing a value with a ref\nManipulating the DOM with a ref\nAvoiding recreating the ref contents\nTroubleshooting\nI can’t get a ref to a custom component\nReference \nuseRef(initialValue) \n\nCall useRef at the top level of your component to declare a ref.\n\nimport { useRef } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const intervalRef = useRef(0);\n\n  const inputRef = useRef(null);\n\n  // ...\n\nSee more examples below.\n\nParameters \ninitialValue: The value you want the ref object’s current property to be initially. It can be a value of any type. This argument is ignored after the initial render.\nReturns \n\nuseRef returns an object with a single property:\n\ncurrent: Initially, it’s set to the initialValue you have passed. You can later set it to something else. If you pass the ref object to React as a ref attribute to a JSX node, React will set its current property.\n\nOn the next renders, useRef will return the same object.\n\nCaveats \nYou can mutate the ref.current property. Unlike state, it is mutable. However, if it holds an object that is used for rendering (for example, a piece of your state), then you shouldn’t mutate that object.\nWhen you change the ref.current property, React does not re-render your component. React is not aware of when you change it because a ref is a plain JavaScript object.\nDo not write or read ref.current during rendering, except for initialization. This makes your component’s behavior unpredictable.\nIn Strict Mode, React will call your component function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. Each ref object will be created twice, but one of the versions will be discarded. If your component function is pure (as it should be), this should not affect the behavior.\nUsage \nReferencing a value with a ref \n\nCall useRef at the top level of your component to declare one or more refs.\n\nimport { useRef } from 'react';\n\n\n\nfunction Stopwatch() {\n\n  const intervalRef = useRef(0);\n\n  // ...\n\nuseRef returns a ref object with a single current property initially set to the initial value you provided.\n\nOn the next renders, useRef will return the same object. You can change its current property to store information and read it later. This might remind you of state, but there is an important difference.\n\nChanging a ref does not trigger a re-render. This means refs are perfect for storing information that doesn’t affect the visual output of your component. For example, if you need to store an interval ID and retrieve it later, you can put it in a ref. To update the value inside the ref, you need to manually change its current property:\n\nfunction handleStartClick() {\n\n  const intervalId = setInterval(() => {\n\n    // ...\n\n  }, 1000);\n\n  intervalRef.current = intervalId;\n\n}\n\nLater, you can read that interval ID from the ref so that you can call clear that interval:\n\nfunction handleStopClick() {\n\n  const intervalId = intervalRef.current;\n\n  clearInterval(intervalId);\n\n}\n\nBy using a ref, you ensure that:\n\nYou can store information between re-renders (unlike regular variables, which reset on every render).\nChanging it does not trigger a re-render (unlike state variables, which trigger a re-render).\nThe information is local to each copy of your component (unlike the variables outside, which are shared).\n\nChanging a ref does not trigger a re-render, so refs are not appropriate for storing information you want to display on the screen. Use state for that instead. Read more about choosing between useRef and useState.\n\nExamples of referencing a value with useRef\n1. Click counter\n2. A stopwatch\nExample 1 of 2: Click counter \n\nThis component uses a ref to keep track of how many times the button was clicked. Note that it’s okay to use a ref instead of state here because the click count is only read and written in an event handler.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useRef } from 'react';\n\nexport default function Counter() {\n  let ref = useRef(0);\n\n  function handleClick() {\n    ref.current = ref.current + 1;\n    alert('You clicked ' + ref.current + ' times!');\n  }\n\n  return (\n    <button onClick={handleClick}>\n      Click me!\n    </button>\n  );\n}\n\n\nShow more\n\nIf you show {ref.current} in the JSX, the number won’t update on click. This is because setting ref.current does not trigger a re-render. Information that’s used for rendering should be state instead.\n\nNext Example\nPitfall\n\nDo not write or read ref.current during rendering.\n\nReact expects that the body of your component behaves like a pure function:\n\nIf the inputs (props, state, and context) are the same, it should return exactly the same JSX.\nCalling it in a different order or with different arguments should not affect the results of other calls.\n\nReading or writing a ref during rendering breaks these expectations.\n\nfunction MyComponent() {\n\n  // ...\n\n  // 🚩 Don't write a ref during rendering\n\n  myRef.current = 123;\n\n  // ...\n\n  // 🚩 Don't read a ref during rendering\n\n  return <h1>{myOtherRef.current}</h1>;\n\n}\n\nYou can read or write refs from event handlers or effects instead.\n\nfunction MyComponent() {\n\n  // ...\n\n  useEffect(() => {\n\n    // ✅ You can read or write refs in effects\n\n    myRef.current = 123;\n\n  });\n\n  // ...\n\n  function handleClick() {\n\n    // ✅ You can read or write refs in event handlers\n\n    doSomething(myOtherRef.current);\n\n  }\n\n  // ...\n\n}\n\nIf you have to read or write something during rendering, use state instead.\n\nWhen you break these rules, your component might still work, but most of the newer features we’re adding to React will rely on these expectations. Read more about keeping your components pure.\n\nManipulating the DOM with a ref \n\nIt’s particularly common to use a ref to manipulate the DOM. React has built-in support for this.\n\nFirst, declare a ref object with an initial value of null:\n\nimport { useRef } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const inputRef = useRef(null);\n\n  // ...\n\nThen pass your ref object as the ref attribute to the JSX of the DOM node you want to manipulate:\n\n  // ...\n\n  return <input ref={inputRef} />;\n\nAfter React creates the DOM node and puts it on the screen, React will set the current property of your ref object to that DOM node. Now you can access the <input>’s DOM node and call methods like focus():\n\n  function handleClick() {\n\n    inputRef.current.focus();\n\n  }\n\nReact will set the current property back to null when the node is removed from the screen.\n\nRead more about manipulating the DOM with refs.\n\nExamples of manipulating the DOM with useRef\n1. Focusing a text input\n2. Scrolling an image into view\n3. Playing and pausing a video\n4. Exposing a ref to your own component\nExample 1 of 4: Focusing a text input \n\nIn this example, clicking the button will focus the input:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useRef } from 'react';\n\nexport default function Form() {\n  const inputRef = useRef(null);\n\n  function handleClick() {\n    inputRef.current.focus();\n  }\n\n  return (\n    <>\n      <input ref={inputRef} />\n      <button onClick={handleClick}>\n        Focus the input\n      </button>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nAvoiding recreating the ref contents \n\nReact saves the initial ref value once and ignores it on the next renders.\n\nfunction Video() {\n\n  const playerRef = useRef(new VideoPlayer());\n\n  // ...\n\nAlthough the result of new VideoPlayer() is only used for the initial render, you’re still calling this function on every render. This can be wasteful if it’s creating expensive objects.\n\nTo solve it, you may initialize the ref like this instead:\n\nfunction Video() {\n\n  const playerRef = useRef(null);\n\n  if (playerRef.current === null) {\n\n    playerRef.current = new VideoPlayer();\n\n  }\n\n  // ...\n\nNormally, writing or reading ref.current during render is not allowed. However, it’s fine in this case because the result is always the same, and the condition only executes during initialization so it’s fully predictable.\n\nDEEP DIVE\nHow to avoid null checks when initializing useRef later \nShow Details\nTroubleshooting \nI can’t get a ref to a custom component \n\nIf you try to pass a ref to your own component like this:\n\nconst inputRef = useRef(null);\n\n\n\nreturn <MyInput ref={inputRef} />;\n\nYou might get an error in the console:\n\nConsole\nTypeError: Cannot read properties of null\n\nBy default, your own components don’t expose refs to the DOM nodes inside them.\n\nTo fix this, find the component that you want to get a ref to:\n\nexport default function MyInput({ value, onChange }) {\n\n  return (\n\n    <input\n\n      value={value}\n\n      onChange={onChange}\n\n    />\n\n  );\n\n}\n\nAnd then add ref to the list of props your component accepts and pass ref as a prop to the relevant child built-in component like this:\n\nfunction MyInput({ value, onChange, ref }) {\n\n  return (\n\n    <input\n\n      value={value}\n\n      onChange={onChange}\n\n      ref={ref}\n\n    />\n\n  );\n\n};\n\n\n\nexport default MyInput;\n\nThen the parent component can get a ref to it.\n\nRead more about accessing another component’s DOM nodes.\n\nPREVIOUS\nuseReducer\nNEXT\nuseState"
  },
  {
    "title": "useState – React",
    "url": "https://react.dev/reference/react/useState",
    "html": "API REFERENCE\nHOOKS\nuseState\n\nuseState is a React Hook that lets you add a state variable to your component.\n\nconst [state, setState] = useState(initialState)\nReference\nuseState(initialState)\nset functions, like setSomething(nextState)\nUsage\nAdding state to a component\nUpdating state based on the previous state\nUpdating objects and arrays in state\nAvoiding recreating the initial state\nResetting state with a key\nStoring information from previous renders\nTroubleshooting\nI’ve updated the state, but logging gives me the old value\nI’ve updated the state, but the screen doesn’t update\nI’m getting an error: “Too many re-renders”\nMy initializer or updater function runs twice\nI’m trying to set state to a function, but it gets called instead\nReference \nuseState(initialState) \n\nCall useState at the top level of your component to declare a state variable.\n\nimport { useState } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const [age, setAge] = useState(28);\n\n  const [name, setName] = useState('Taylor');\n\n  const [todos, setTodos] = useState(() => createTodos());\n\n  // ...\n\nThe convention is to name state variables like [something, setSomething] using array destructuring.\n\nSee more examples below.\n\nParameters \ninitialState: The value you want the state to be initially. It can be a value of any type, but there is a special behavior for functions. This argument is ignored after the initial render.\nIf you pass a function as initialState, it will be treated as an initializer function. It should be pure, should take no arguments, and should return a value of any type. React will call your initializer function when initializing the component, and store its return value as the initial state. See an example below.\nReturns \n\nuseState returns an array with exactly two values:\n\nThe current state. During the first render, it will match the initialState you have passed.\nThe set function that lets you update the state to a different value and trigger a re-render.\nCaveats \nuseState is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nIn Strict Mode, React will call your initializer function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your initializer function is pure (as it should be), this should not affect the behavior. The result from one of the calls will be ignored.\nset functions, like setSomething(nextState) \n\nThe set function returned by useState lets you update the state to a different value and trigger a re-render. You can pass the next state directly, or a function that calculates it from the previous state:\n\nconst [name, setName] = useState('Edward');\n\n\n\nfunction handleClick() {\n\n  setName('Taylor');\n\n  setAge(a => a + 1);\n\n  // ...\nParameters \nnextState: The value that you want the state to be. It can be a value of any type, but there is a special behavior for functions.\nIf you pass a function as nextState, it will be treated as an updater function. It must be pure, should take the pending state as its only argument, and should return the next state. React will put your updater function in a queue and re-render your component. During the next render, React will calculate the next state by applying all of the queued updaters to the previous state. See an example below.\nReturns \n\nset functions do not have a return value.\n\nCaveats \n\nThe set function only updates the state variable for the next render. If you read the state variable after calling the set function, you will still get the old value that was on the screen before your call.\n\nIf the new value you provide is identical to the current state, as determined by an Object.is comparison, React will skip re-rendering the component and its children. This is an optimization. Although in some cases React may still need to call your component before skipping the children, it shouldn’t affect your code.\n\nReact batches state updates. It updates the screen after all the event handlers have run and have called their set functions. This prevents multiple re-renders during a single event. In the rare case that you need to force React to update the screen earlier, for example to access the DOM, you can use flushSync.\n\nThe set function has a stable identity, so you will often see it omitted from Effect dependencies, but including it will not cause the Effect to fire. If the linter lets you omit a dependency without errors, it is safe to do. Learn more about removing Effect dependencies.\n\nCalling the set function during rendering is only allowed from within the currently rendering component. React will discard its output and immediately attempt to render it again with the new state. This pattern is rarely needed, but you can use it to store information from the previous renders. See an example below.\n\nIn Strict Mode, React will call your updater function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your updater function is pure (as it should be), this should not affect the behavior. The result from one of the calls will be ignored.\n\nUsage \nAdding state to a component \n\nCall useState at the top level of your component to declare one or more state variables.\n\nimport { useState } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const [age, setAge] = useState(42);\n\n  const [name, setName] = useState('Taylor');\n\n  // ...\n\nThe convention is to name state variables like [something, setSomething] using array destructuring.\n\nuseState returns an array with exactly two items:\n\nThe current state of this state variable, initially set to the initial state you provided.\nThe set function that lets you change it to any other value in response to interaction.\n\nTo update what’s on the screen, call the set function with some next state:\n\nfunction handleClick() {\n\n  setName('Robin');\n\n}\n\nReact will store the next state, render your component again with the new values, and update the UI.\n\nPitfall\n\nCalling the set function does not change the current state in the already executing code:\n\nfunction handleClick() {\n\n  setName('Robin');\n\n  console.log(name); // Still \"Taylor\"!\n\n}\n\nIt only affects what useState will return starting from the next render.\n\nBasic useState examples\n1. Counter (number)\n2. Text field (string)\n3. Checkbox (boolean)\n4. Form (two variables)\nExample 1 of 4: Counter (number) \n\nIn this example, the count state variable holds a number. Clicking the button increments it.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [count, setCount] = useState(0);\n\n  function handleClick() {\n    setCount(count + 1);\n  }\n\n  return (\n    <button onClick={handleClick}>\n      You pressed me {count} times\n    </button>\n  );\n}\n\n\nNext Example\nUpdating state based on the previous state \n\nSuppose the age is 42. This handler calls setAge(age + 1) three times:\n\nfunction handleClick() {\n\n  setAge(age + 1); // setAge(42 + 1)\n\n  setAge(age + 1); // setAge(42 + 1)\n\n  setAge(age + 1); // setAge(42 + 1)\n\n}\n\nHowever, after one click, age will only be 43 rather than 45! This is because calling the set function does not update the age state variable in the already running code. So each setAge(age + 1) call becomes setAge(43).\n\nTo solve this problem, you may pass an updater function to setAge instead of the next state:\n\nfunction handleClick() {\n\n  setAge(a => a + 1); // setAge(42 => 43)\n\n  setAge(a => a + 1); // setAge(43 => 44)\n\n  setAge(a => a + 1); // setAge(44 => 45)\n\n}\n\nHere, a => a + 1 is your updater function. It takes the pending state and calculates the next state from it.\n\nReact puts your updater functions in a queue. Then, during the next render, it will call them in the same order:\n\na => a + 1 will receive 42 as the pending state and return 43 as the next state.\na => a + 1 will receive 43 as the pending state and return 44 as the next state.\na => a + 1 will receive 44 as the pending state and return 45 as the next state.\n\nThere are no other queued updates, so React will store 45 as the current state in the end.\n\nBy convention, it’s common to name the pending state argument for the first letter of the state variable name, like a for age. However, you may also call it like prevAge or something else that you find clearer.\n\nReact may call your updaters twice in development to verify that they are pure.\n\nDEEP DIVE\nIs using an updater always preferred? \nShow Details\nThe difference between passing an updater and passing the next state directly\n1. Passing the updater function\n2. Passing the next state directly\nExample 1 of 2: Passing the updater function \n\nThis example passes the updater function, so the “+3” button works.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [age, setAge] = useState(42);\n\n  function increment() {\n    setAge(a => a + 1);\n  }\n\n  return (\n    <>\n      <h1>Your age: {age}</h1>\n      <button onClick={() => {\n        increment();\n        increment();\n        increment();\n      }}>+3</button>\n      <button onClick={() => {\n        increment();\n      }}>+1</button>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nUpdating objects and arrays in state \n\nYou can put objects and arrays into state. In React, state is considered read-only, so you should replace it rather than mutate your existing objects. For example, if you have a form object in state, don’t mutate it:\n\n// 🚩 Don't mutate an object in state like this:\n\nform.firstName = 'Taylor';\n\nInstead, replace the whole object by creating a new one:\n\n// ✅ Replace state with a new object\n\nsetForm({\n\n  ...form,\n\n  firstName: 'Taylor'\n\n});\n\nRead updating objects in state and updating arrays in state to learn more.\n\nExamples of objects and arrays in state\n1. Form (object)\n2. Form (nested object)\n3. List (array)\n4. Writing concise update logic with Immer\nExample 1 of 4: Form (object) \n\nIn this example, the form state variable holds an object. Each input has a change handler that calls setForm with the next state of the entire form. The { ...form } spread syntax ensures that the state object is replaced rather than mutated.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Form() {\n  const [form, setForm] = useState({\n    firstName: 'Barbara',\n    lastName: 'Hepworth',\n    email: 'bhepworth@sculpture.com',\n  });\n\n  return (\n    <>\n      <label>\n        First name:\n        <input\n          value={form.firstName}\n          onChange={e => {\n            setForm({\n              ...form,\n              firstName: e.target.value\n            });\n          }}\n        />\n      </label>\n      <label>\n        Last name:\n        <input\n          value={form.lastName}\n          onChange={e => {\n            setForm({\n              ...form,\n              lastName: e.target.value\n            });\n          }}\n        />\n      </label>\n      <label>\n        Email:\n        <input\n          value={form.email}\n          onChange={e => {\n            setForm({\n              ...form,\n              email: e.target.value\n            });\n          }}\n        />\n      </label>\n      <p>\n        {form.firstName}{' '}\n        {form.lastName}{' '}\n        ({form.email})\n      </p>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nAvoiding recreating the initial state \n\nReact saves the initial state once and ignores it on the next renders.\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState(createInitialTodos());\n\n  // ...\n\nAlthough the result of createInitialTodos() is only used for the initial render, you’re still calling this function on every render. This can be wasteful if it’s creating large arrays or performing expensive calculations.\n\nTo solve this, you may pass it as an initializer function to useState instead:\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState(createInitialTodos);\n\n  // ...\n\nNotice that you’re passing createInitialTodos, which is the function itself, and not createInitialTodos(), which is the result of calling it. If you pass a function to useState, React will only call it during initialization.\n\nReact may call your initializers twice in development to verify that they are pure.\n\nThe difference between passing an initializer and passing the initial state directly\n1. Passing the initializer function\n2. Passing the initial state directly\nExample 1 of 2: Passing the initializer function \n\nThis example passes the initializer function, so the createInitialTodos function only runs during initialization. It does not run when component re-renders, such as when you type into the input.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nfunction createInitialTodos() {\n  const initialTodos = [];\n  for (let i = 0; i < 50; i++) {\n    initialTodos.push({\n      id: i,\n      text: 'Item ' + (i + 1)\n    });\n  }\n  return initialTodos;\n}\n\nexport default function TodoList() {\n  const [todos, setTodos] = useState(createInitialTodos);\n  const [text, setText] = useState('');\n\n  return (\n    <>\n      <input\n        value={text}\n        onChange={e => setText(e.target.value)}\n      />\n      <button onClick={() => {\n        setText('');\n        setTodos([{\n          id: todos.length,\n          text: text\n        }, ...todos]);\n      }}>Add</button>\n      <ul>\n        {todos.map(item => (\n          <li key={item.id}>\n            {item.text}\n          </li>\n        ))}\n      </ul>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nResetting state with a key \n\nYou’ll often encounter the key attribute when rendering lists. However, it also serves another purpose.\n\nYou can reset a component’s state by passing a different key to a component. In this example, the Reset button changes the version state variable, which we pass as a key to the Form. When the key changes, React re-creates the Form component (and all of its children) from scratch, so its state gets reset.\n\nRead preserving and resetting state to learn more.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function App() {\n  const [version, setVersion] = useState(0);\n\n  function handleReset() {\n    setVersion(version + 1);\n  }\n\n  return (\n    <>\n      <button onClick={handleReset}>Reset</button>\n      <Form key={version} />\n    </>\n  );\n}\n\nfunction Form() {\n  const [name, setName] = useState('Taylor');\n\n  return (\n    <>\n      <input\n        value={name}\n        onChange={e => setName(e.target.value)}\n      />\n      <p>Hello, {name}.</p>\n    </>\n  );\n}\n\n\nShow more\nStoring information from previous renders \n\nUsually, you will update state in event handlers. However, in rare cases you might want to adjust state in response to rendering — for example, you might want to change a state variable when a prop changes.\n\nIn most cases, you don’t need this:\n\nIf the value you need can be computed entirely from the current props or other state, remove that redundant state altogether. If you’re worried about recomputing too often, the useMemo Hook can help.\nIf you want to reset the entire component tree’s state, pass a different key to your component.\nIf you can, update all the relevant state in the event handlers.\n\nIn the rare case that none of these apply, there is a pattern you can use to update state based on the values that have been rendered so far, by calling a set function while your component is rendering.\n\nHere’s an example. This CountLabel component displays the count prop passed to it:\n\nexport default function CountLabel({ count }) {\n\n  return <h1>{count}</h1>\n\n}\n\nSay you want to show whether the counter has increased or decreased since the last change. The count prop doesn’t tell you this — you need to keep track of its previous value. Add the prevCount state variable to track it. Add another state variable called trend to hold whether the count has increased or decreased. Compare prevCount with count, and if they’re not equal, update both prevCount and trend. Now you can show both the current count prop and how it has changed since the last render.\n\nApp.js\nCountLabel.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function CountLabel({ count }) {\n  const [prevCount, setPrevCount] = useState(count);\n  const [trend, setTrend] = useState(null);\n  if (prevCount !== count) {\n    setPrevCount(count);\n    setTrend(count > prevCount ? 'increasing' : 'decreasing');\n  }\n  return (\n    <>\n      <h1>{count}</h1>\n      {trend && <p>The count is {trend}</p>}\n    </>\n  );\n}\n\n\nShow more\n\nNote that if you call a set function while rendering, it must be inside a condition like prevCount !== count, and there must be a call like setPrevCount(count) inside of the condition. Otherwise, your component would re-render in a loop until it crashes. Also, you can only update the state of the currently rendering component like this. Calling the set function of another component during rendering is an error. Finally, your set call should still update state without mutation — this doesn’t mean you can break other rules of pure functions.\n\nThis pattern can be hard to understand and is usually best avoided. However, it’s better than updating state in an effect. When you call the set function during render, React will re-render that component immediately after your component exits with a return statement, and before rendering the children. This way, children don’t need to render twice. The rest of your component function will still execute (and the result will be thrown away). If your condition is below all the Hook calls, you may add an early return; to restart rendering earlier.\n\nTroubleshooting \nI’ve updated the state, but logging gives me the old value \n\nCalling the set function does not change state in the running code:\n\nfunction handleClick() {\n\n  console.log(count);  // 0\n\n\n\n  setCount(count + 1); // Request a re-render with 1\n\n  console.log(count);  // Still 0!\n\n\n\n  setTimeout(() => {\n\n    console.log(count); // Also 0!\n\n  }, 5000);\n\n}\n\nThis is because states behaves like a snapshot. Updating state requests another render with the new state value, but does not affect the count JavaScript variable in your already-running event handler.\n\nIf you need to use the next state, you can save it in a variable before passing it to the set function:\n\nconst nextCount = count + 1;\n\nsetCount(nextCount);\n\n\n\nconsole.log(count);     // 0\n\nconsole.log(nextCount); // 1\nI’ve updated the state, but the screen doesn’t update \n\nReact will ignore your update if the next state is equal to the previous state, as determined by an Object.is comparison. This usually happens when you change an object or an array in state directly:\n\nobj.x = 10;  // 🚩 Wrong: mutating existing object\n\nsetObj(obj); // 🚩 Doesn't do anything\n\nYou mutated an existing obj object and passed it back to setObj, so React ignored the update. To fix this, you need to ensure that you’re always replacing objects and arrays in state instead of mutating them:\n\n// ✅ Correct: creating a new object\n\nsetObj({\n\n  ...obj,\n\n  x: 10\n\n});\nI’m getting an error: “Too many re-renders” \n\nYou might get an error that says: Too many re-renders. React limits the number of renders to prevent an infinite loop. Typically, this means that you’re unconditionally setting state during render, so your component enters a loop: render, set state (which causes a render), render, set state (which causes a render), and so on. Very often, this is caused by a mistake in specifying an event handler:\n\n// 🚩 Wrong: calls the handler during render\n\nreturn <button onClick={handleClick()}>Click me</button>\n\n\n\n// ✅ Correct: passes down the event handler\n\nreturn <button onClick={handleClick}>Click me</button>\n\n\n\n// ✅ Correct: passes down an inline function\n\nreturn <button onClick={(e) => handleClick(e)}>Click me</button>\n\nIf you can’t find the cause of this error, click on the arrow next to the error in the console and look through the JavaScript stack to find the specific set function call responsible for the error.\n\nMy initializer or updater function runs twice \n\nIn Strict Mode, React will call some of your functions twice instead of once:\n\nfunction TodoList() {\n\n  // This component function will run twice for every render.\n\n\n\n  const [todos, setTodos] = useState(() => {\n\n    // This initializer function will run twice during initialization.\n\n    return createTodos();\n\n  });\n\n\n\n  function handleClick() {\n\n    setTodos(prevTodos => {\n\n      // This updater function will run twice for every click.\n\n      return [...prevTodos, createTodo()];\n\n    });\n\n  }\n\n  // ...\n\nThis is expected and shouldn’t break your code.\n\nThis development-only behavior helps you keep components pure. React uses the result of one of the calls, and ignores the result of the other call. As long as your component, initializer, and updater functions are pure, this shouldn’t affect your logic. However, if they are accidentally impure, this helps you notice the mistakes.\n\nFor example, this impure updater function mutates an array in state:\n\nsetTodos(prevTodos => {\n\n  // 🚩 Mistake: mutating state\n\n  prevTodos.push(createTodo());\n\n});\n\nBecause React calls your updater function twice, you’ll see the todo was added twice, so you’ll know that there is a mistake. In this example, you can fix the mistake by replacing the array instead of mutating it:\n\nsetTodos(prevTodos => {\n\n  // ✅ Correct: replacing with new state\n\n  return [...prevTodos, createTodo()];\n\n});\n\nNow that this updater function is pure, calling it an extra time doesn’t make a difference in behavior. This is why React calling it twice helps you find mistakes. Only component, initializer, and updater functions need to be pure. Event handlers don’t need to be pure, so React will never call your event handlers twice.\n\nRead keeping components pure to learn more.\n\nI’m trying to set state to a function, but it gets called instead \n\nYou can’t put a function into state like this:\n\nconst [fn, setFn] = useState(someFunction);\n\n\n\nfunction handleClick() {\n\n  setFn(someOtherFunction);\n\n}\n\nBecause you’re passing a function, React assumes that someFunction is an initializer function, and that someOtherFunction is an updater function, so it tries to call them and store the result. To actually store a function, you have to put () => before them in both cases. Then React will store the functions you pass.\n\nconst [fn, setFn] = useState(() => someFunction);\n\n\n\nfunction handleClick() {\n\n  setFn(() => someOtherFunction);\n\n}\nPREVIOUS\nuseRef\nNEXT\nuseSyncExternalStore"
  },
  {
    "title": "useSyncExternalStore – React",
    "url": "https://react.dev/reference/react/useSyncExternalStore",
    "html": "API REFERENCE\nHOOKS\nuseSyncExternalStore\n\nuseSyncExternalStore is a React Hook that lets you subscribe to an external store.\n\nconst snapshot = useSyncExternalStore(subscribe, getSnapshot, getServerSnapshot?)\nReference\nuseSyncExternalStore(subscribe, getSnapshot, getServerSnapshot?)\nUsage\nSubscribing to an external store\nSubscribing to a browser API\nExtracting the logic to a custom Hook\nAdding support for server rendering\nTroubleshooting\nI’m getting an error: “The result of getSnapshot should be cached”\nMy subscribe function gets called after every re-render\nReference \nuseSyncExternalStore(subscribe, getSnapshot, getServerSnapshot?) \n\nCall useSyncExternalStore at the top level of your component to read a value from an external data store.\n\nimport { useSyncExternalStore } from 'react';\n\nimport { todosStore } from './todoStore.js';\n\n\n\nfunction TodosApp() {\n\n  const todos = useSyncExternalStore(todosStore.subscribe, todosStore.getSnapshot);\n\n  // ...\n\n}\n\nIt returns the snapshot of the data in the store. You need to pass two functions as arguments:\n\nThe subscribe function should subscribe to the store and return a function that unsubscribes.\nThe getSnapshot function should read a snapshot of the data from the store.\n\nSee more examples below.\n\nParameters \n\nsubscribe: A function that takes a single callback argument and subscribes it to the store. When the store changes, it should invoke the provided callback, which will cause React to re-call getSnapshot and (if needed) re-render the component. The subscribe function should return a function that cleans up the subscription.\n\ngetSnapshot: A function that returns a snapshot of the data in the store that’s needed by the component. While the store has not changed, repeated calls to getSnapshot must return the same value. If the store changes and the returned value is different (as compared by Object.is), React re-renders the component.\n\noptional getServerSnapshot: A function that returns the initial snapshot of the data in the store. It will be used only during server rendering and during hydration of server-rendered content on the client. The server snapshot must be the same between the client and the server, and is usually serialized and passed from the server to the client. If you omit this argument, rendering the component on the server will throw an error.\n\nReturns \n\nThe current snapshot of the store which you can use in your rendering logic.\n\nCaveats \n\nThe store snapshot returned by getSnapshot must be immutable. If the underlying store has mutable data, return a new immutable snapshot if the data has changed. Otherwise, return a cached last snapshot.\n\nIf a different subscribe function is passed during a re-render, React will re-subscribe to the store using the newly passed subscribe function. You can prevent this by declaring subscribe outside the component.\n\nIf the store is mutated during a non-blocking Transition update, React will fall back to performing that update as blocking. Specifically, for every Transition update, React will call getSnapshot a second time just before applying changes to the DOM. If it returns a different value than when it was called originally, React will restart the update from scratch, this time applying it as a blocking update, to ensure that every component on screen is reflecting the same version of the store.\n\nIt’s not recommended to suspend a render based on a store value returned by useSyncExternalStore. The reason is that mutations to the external store cannot be marked as non-blocking Transition updates, so they will trigger the nearest Suspense fallback, replacing already-rendered content on screen with a loading spinner, which typically makes a poor UX.\n\nFor example, the following are discouraged:\n\nconst LazyProductDetailPage = lazy(() => import('./ProductDetailPage.js'));\n\n\n\nfunction ShoppingApp() {\n\n  const selectedProductId = useSyncExternalStore(...);\n\n\n\n  // ❌ Calling `use` with a Promise dependent on `selectedProductId`\n\n  const data = use(fetchItem(selectedProductId))\n\n\n\n  // ❌ Conditionally rendering a lazy component based on `selectedProductId`\n\n  return selectedProductId != null ? <LazyProductDetailPage /> : <FeaturedProducts />;\n\n}\nUsage \nSubscribing to an external store \n\nMost of your React components will only read data from their props, state, and context. However, sometimes a component needs to read some data from some store outside of React that changes over time. This includes:\n\nThird-party state management libraries that hold state outside of React.\nBrowser APIs that expose a mutable value and events to subscribe to its changes.\n\nCall useSyncExternalStore at the top level of your component to read a value from an external data store.\n\nimport { useSyncExternalStore } from 'react';\n\nimport { todosStore } from './todoStore.js';\n\n\n\nfunction TodosApp() {\n\n  const todos = useSyncExternalStore(todosStore.subscribe, todosStore.getSnapshot);\n\n  // ...\n\n}\n\nIt returns the snapshot of the data in the store. You need to pass two functions as arguments:\n\nThe subscribe function should subscribe to the store and return a function that unsubscribes.\nThe getSnapshot function should read a snapshot of the data from the store.\n\nReact will use these functions to keep your component subscribed to the store and re-render it on changes.\n\nFor example, in the sandbox below, todosStore is implemented as an external store that stores data outside of React. The TodosApp component connects to that external store with the useSyncExternalStore Hook.\n\nApp.js\ntodoStore.js\nReload\nClear\nFork\nimport { useSyncExternalStore } from 'react';\nimport { todosStore } from './todoStore.js';\n\nexport default function TodosApp() {\n  const todos = useSyncExternalStore(todosStore.subscribe, todosStore.getSnapshot);\n  return (\n    <>\n      <button onClick={() => todosStore.addTodo()}>Add todo</button>\n      <hr />\n      <ul>\n        {todos.map(todo => (\n          <li key={todo.id}>{todo.text}</li>\n        ))}\n      </ul>\n    </>\n  );\n}\n\n\nShow more\nNote\n\nWhen possible, we recommend using built-in React state with useState and useReducer instead. The useSyncExternalStore API is mostly useful if you need to integrate with existing non-React code.\n\nSubscribing to a browser API \n\nAnother reason to add useSyncExternalStore is when you want to subscribe to some value exposed by the browser that changes over time. For example, suppose that you want your component to display whether the network connection is active. The browser exposes this information via a property called navigator.onLine.\n\nThis value can change without React’s knowledge, so you should read it with useSyncExternalStore.\n\nimport { useSyncExternalStore } from 'react';\n\n\n\nfunction ChatIndicator() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n  // ...\n\n}\n\nTo implement the getSnapshot function, read the current value from the browser API:\n\nfunction getSnapshot() {\n\n  return navigator.onLine;\n\n}\n\nNext, you need to implement the subscribe function. For example, when navigator.onLine changes, the browser fires the online and offline events on the window object. You need to subscribe the callback argument to the corresponding events, and then return a function that cleans up the subscriptions:\n\nfunction subscribe(callback) {\n\n  window.addEventListener('online', callback);\n\n  window.addEventListener('offline', callback);\n\n  return () => {\n\n    window.removeEventListener('online', callback);\n\n    window.removeEventListener('offline', callback);\n\n  };\n\n}\n\nNow React knows how to read the value from the external navigator.onLine API and how to subscribe to its changes. Disconnect your device from the network and notice that the component re-renders in response:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useSyncExternalStore } from 'react';\n\nexport default function ChatIndicator() {\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n  return <h1>{isOnline ? '✅ Online' : '❌ Disconnected'}</h1>;\n}\n\nfunction getSnapshot() {\n  return navigator.onLine;\n}\n\nfunction subscribe(callback) {\n  window.addEventListener('online', callback);\n  window.addEventListener('offline', callback);\n  return () => {\n    window.removeEventListener('online', callback);\n    window.removeEventListener('offline', callback);\n  };\n}\n\n\nShow more\nExtracting the logic to a custom Hook \n\nUsually you won’t write useSyncExternalStore directly in your components. Instead, you’ll typically call it from your own custom Hook. This lets you use the same external store from different components.\n\nFor example, this custom useOnlineStatus Hook tracks whether the network is online:\n\nimport { useSyncExternalStore } from 'react';\n\n\n\nexport function useOnlineStatus() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n  return isOnline;\n\n}\n\n\n\nfunction getSnapshot() {\n\n  // ...\n\n}\n\n\n\nfunction subscribe(callback) {\n\n  // ...\n\n}\n\nNow different components can call useOnlineStatus without repeating the underlying implementation:\n\nApp.js\nuseOnlineStatus.js\nReload\nClear\nFork\nimport { useOnlineStatus } from './useOnlineStatus.js';\n\nfunction StatusBar() {\n  const isOnline = useOnlineStatus();\n  return <h1>{isOnline ? '✅ Online' : '❌ Disconnected'}</h1>;\n}\n\nfunction SaveButton() {\n  const isOnline = useOnlineStatus();\n\n  function handleSaveClick() {\n    console.log('✅ Progress saved');\n  }\n\n  return (\n    <button disabled={!isOnline} onClick={handleSaveClick}>\n      {isOnline ? 'Save progress' : 'Reconnecting...'}\n    </button>\n  );\n}\n\nexport default function App() {\n  return (\n    <>\n      <SaveButton />\n      <StatusBar />\n    </>\n  );\n}\n\n\nShow more\nAdding support for server rendering \n\nIf your React app uses server rendering, your React components will also run outside the browser environment to generate the initial HTML. This creates a few challenges when connecting to an external store:\n\nIf you’re connecting to a browser-only API, it won’t work because it does not exist on the server.\nIf you’re connecting to a third-party data store, you’ll need its data to match between the server and client.\n\nTo solve these issues, pass a getServerSnapshot function as the third argument to useSyncExternalStore:\n\nimport { useSyncExternalStore } from 'react';\n\n\n\nexport function useOnlineStatus() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot, getServerSnapshot);\n\n  return isOnline;\n\n}\n\n\n\nfunction getSnapshot() {\n\n  return navigator.onLine;\n\n}\n\n\n\nfunction getServerSnapshot() {\n\n  return true; // Always show \"Online\" for server-generated HTML\n\n}\n\n\n\nfunction subscribe(callback) {\n\n  // ...\n\n}\n\nThe getServerSnapshot function is similar to getSnapshot, but it runs only in two situations:\n\nIt runs on the server when generating the HTML.\nIt runs on the client during hydration, i.e. when React takes the server HTML and makes it interactive.\n\nThis lets you provide the initial snapshot value which will be used before the app becomes interactive. If there is no meaningful initial value for the server rendering, omit this argument to force rendering on the client.\n\nNote\n\nMake sure that getServerSnapshot returns the same exact data on the initial client render as it returned on the server. For example, if getServerSnapshot returned some prepopulated store content on the server, you need to transfer this content to the client. One way to do this is to emit a <script> tag during server rendering that sets a global like window.MY_STORE_DATA, and read from that global on the client in getServerSnapshot. Your external store should provide instructions on how to do that.\n\nTroubleshooting \nI’m getting an error: “The result of getSnapshot should be cached” \n\nThis error means your getSnapshot function returns a new object every time it’s called, for example:\n\nfunction getSnapshot() {\n\n  // 🔴 Do not return always different objects from getSnapshot\n\n  return {\n\n    todos: myStore.todos\n\n  };\n\n}\n\nReact will re-render the component if getSnapshot return value is different from the last time. This is why, if you always return a different value, you will enter an infinite loop and get this error.\n\nYour getSnapshot object should only return a different object if something has actually changed. If your store contains immutable data, you can return that data directly:\n\nfunction getSnapshot() {\n\n  // ✅ You can return immutable data\n\n  return myStore.todos;\n\n}\n\nIf your store data is mutable, your getSnapshot function should return an immutable snapshot of it. This means it does need to create new objects, but it shouldn’t do this for every single call. Instead, it should store the last calculated snapshot, and return the same snapshot as the last time if the data in the store has not changed. How you determine whether mutable data has changed depends on your mutable store.\n\nMy subscribe function gets called after every re-render \n\nThis subscribe function is defined inside a component so it is different on every re-render:\n\nfunction ChatIndicator() {\n\n  // 🚩 Always a different function, so React will resubscribe on every re-render\n\n  function subscribe() {\n\n    // ...\n\n  }\n\n  \n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n\n\n  // ...\n\n}\n\nReact will resubscribe to your store if you pass a different subscribe function between re-renders. If this causes performance issues and you’d like to avoid resubscribing, move the subscribe function outside:\n\n// ✅ Always the same function, so React won't need to resubscribe\n\nfunction subscribe() {\n\n  // ...\n\n}\n\n\n\nfunction ChatIndicator() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n  // ...\n\n}\n\nAlternatively, wrap subscribe into useCallback to only resubscribe when some argument changes:\n\nfunction ChatIndicator({ userId }) {\n\n  // ✅ Same function as long as userId doesn't change\n\n  const subscribe = useCallback(() => {\n\n    // ...\n\n  }, [userId]);\n\n  \n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n\n\n  // ...\n\n}\nPREVIOUS\nuseState\nNEXT\nuseTransition"
  },
  {
    "title": "useTransition – React",
    "url": "https://react.dev/reference/react/useTransition",
    "html": "API REFERENCE\nHOOKS\nuseTransition\n\nuseTransition is a React Hook that lets you render a part of the UI in the background.\n\nconst [isPending, startTransition] = useTransition()\nReference\nuseTransition()\nstartTransition(action)\nUsage\nPerform non-blocking updates with Actions\nExposing action prop from components\nDisplaying a pending visual state\nPreventing unwanted loading indicators\nBuilding a Suspense-enabled router\nDisplaying an error to users with an error boundary\nTroubleshooting\nUpdating an input in a Transition doesn’t work\nReact doesn’t treat my state update as a Transition\nReact doesn’t treat my state update after await as a Transition\nI want to call useTransition from outside a component\nThe function I pass to startTransition executes immediately\nMy state updates in Transitions are out of order\nReference \nuseTransition() \n\nCall useTransition at the top level of your component to mark some state updates as Transitions.\n\nimport { useTransition } from 'react';\n\n\n\nfunction TabContainer() {\n\n  const [isPending, startTransition] = useTransition();\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \n\nuseTransition does not take any parameters.\n\nReturns \n\nuseTransition returns an array with exactly two items:\n\nThe isPending flag that tells you whether there is a pending Transition.\nThe startTransition function that lets you mark updates as a Transition.\nstartTransition(action) \n\nThe startTransition function returned by useTransition lets you mark an update as a Transition.\n\nfunction TabContainer() {\n\n  const [isPending, startTransition] = useTransition();\n\n  const [tab, setTab] = useState('about');\n\n\n\n  function selectTab(nextTab) {\n\n    startTransition(() => {\n\n      setTab(nextTab);\n\n    });\n\n  }\n\n  // ...\n\n}\nNote\nFunctions called in startTransition are called “Actions”. \n\nThe function passed to startTransition is called an “Action”. By convention, any callback called inside startTransition (such as a callback prop) should be named action or include the “Action” suffix:\n\nfunction SubmitButton({ submitAction }) {\n\n  const [isPending, startTransition] = useTransition();\n\n\n\n  return (\n\n    <button\n\n      disabled={isPending}\n\n      onClick={() => {\n\n        startTransition(async () => {\n\n          await submitAction();\n\n        });\n\n      }}\n\n    >\n\n      Submit\n\n    </button>\n\n  );\n\n}\nParameters \naction: A function that updates some state by calling one or more set functions. React calls action immediately with no parameters and marks all state updates scheduled synchronously during the action function call as Transitions. Any async calls that are awaited in the action will be included in the Transition, but currently require wrapping any set functions after the await in an additional startTransition (see Troubleshooting). State updates marked as Transitions will be non-blocking and will not display unwanted loading indicators.\nReturns \n\nstartTransition does not return anything.\n\nCaveats \n\nuseTransition is a Hook, so it can only be called inside components or custom Hooks. If you need to start a Transition somewhere else (for example, from a data library), call the standalone startTransition instead.\n\nYou can wrap an update into a Transition only if you have access to the set function of that state. If you want to start a Transition in response to some prop or a custom Hook value, try useDeferredValue instead.\n\nThe function you pass to startTransition is called immediately, marking all state updates that happen while it executes as Transitions. If you try to perform state updates in a setTimeout, for example, they won’t be marked as Transitions.\n\nYou must wrap any state updates after any async requests in another startTransition to mark them as Transitions. This is a known limitation that we will fix in the future (see Troubleshooting).\n\nThe startTransition function has a stable identity, so you will often see it omitted from Effect dependencies, but including it will not cause the Effect to fire. If the linter lets you omit a dependency without errors, it is safe to do. Learn more about removing Effect dependencies.\n\nA state update marked as a Transition will be interrupted by other state updates. For example, if you update a chart component inside a Transition, but then start typing into an input while the chart is in the middle of a re-render, React will restart the rendering work on the chart component after handling the input update.\n\nTransition updates can’t be used to control text inputs.\n\nIf there are multiple ongoing Transitions, React currently batches them together. This is a limitation that may be removed in a future release.\n\nUsage \nPerform non-blocking updates with Actions \n\nCall useTransition at the top of your component to create Actions, and access the pending state:\n\nimport {useState, useTransition} from 'react';\n\n\n\nfunction CheckoutForm() {\n\n  const [isPending, startTransition] = useTransition();\n\n  // ...\n\n}\n\nuseTransition returns an array with exactly two items:\n\nThe isPending flag that tells you whether there is a pending Transition.\nThe startTransition function that lets you create an Action.\n\nTo start a Transition, pass a function to startTransition like this:\n\nimport {useState, useTransition} from 'react';\n\nimport {updateQuantity} from './api';\n\n\n\nfunction CheckoutForm() {\n\n  const [isPending, startTransition] = useTransition();\n\n  const [quantity, setQuantity] = useState(1);\n\n\n\n  function onSubmit(newQuantity) {\n\n    startTransition(async function () {\n\n      const savedQuantity = await updateQuantity(newQuantity);\n\n      startTransition(() => {\n\n        setQuantity(savedQuantity);\n\n      });\n\n    });\n\n  }\n\n  // ...\n\n}\n\nThe function passed to startTransition is called the “Action”. You can update state and (optionally) perform side effects within an Action, and the work will be done in the background without blocking user interactions on the page. A Transition can include multiple Actions, and while a Transition is in progress, your UI stays responsive. For example, if the user clicks a tab but then changes their mind and clicks another tab, the second click will be immediately handled without waiting for the first update to finish.\n\nTo give the user feedback about in-progress Transitions, the isPending state switches to true at the first call to startTransition, and stays true until all Actions complete and the final state is shown to the user. Transitions ensure side effects in Actions to complete in order to prevent unwanted loading indicators, and you can provide immediate feedback while the Transition is in progress with useOptimistic.\n\nThe difference between Actions and regular event handling\n1. Updating the quantity in an Action\n2. Updating the quantity without an Action\nExample 1 of 2: Updating the quantity in an Action \n\nIn this example, the updateQuantity function simulates a request to the server to update the item’s quantity in the cart. This function is artificially slowed down so that it takes at least a second to complete the request.\n\nUpdate the quantity multiple times quickly. Notice that the pending “Total” state is shown while any requests are in progress, and the “Total” updates only after the final request is complete. Because the update is in an Action, the “quantity” can continue to be updated while the request is in progress.\n\nApp.js\nItem.js\nTotal.js\napi.js\nReload\nClear\nFork\nimport { useState, useTransition } from \"react\";\nimport { updateQuantity } from \"./api\";\nimport Item from \"./Item\";\nimport Total from \"./Total\";\n\nexport default function App({}) {\n  const [quantity, setQuantity] = useState(1);\n  const [isPending, startTransition] = useTransition();\n\n  const updateQuantityAction = async newQuantity => {\n    // To access the pending state of a transition,\n    // call startTransition again.\n    startTransition(async () => {\n      const savedQuantity = await updateQuantity(newQuantity);\n      startTransition(() => {\n        setQuantity(savedQuantity);\n      });\n    });\n  };\n\n  return (\n    <div>\n      <h1>Checkout</h1>\n      <Item action={updateQuantityAction}/>\n      <hr />\n      <Total quantity={quantity} isPending={isPending} />\n    </div>\n  );\n}\n\n\nShow more\n\nThis is a basic example to demonstrate how Actions work, but this example does not handle requests completing out of order. When updating the quantity multiple times, it’s possible for the previous requests to finish after later requests causing the quantity to update out of order. This is a known limitation that we will fix in the future (see Troubleshooting below).\n\nFor common use cases, React provides built-in abstractions such as:\n\nuseActionState\n<form> actions\nServer Functions\n\nThese solutions handle request ordering for you. When using Transitions to build your own custom hooks or libraries that manage async state transitions, you have greater control over the request ordering, but you must handle it yourself.\n\nNext Example\nExposing action prop from components \n\nYou can expose an action prop from a component to allow a parent to call an Action.\n\nFor example, this TabButton component wraps its onClick logic in an action prop:\n\nexport default function TabButton({ action, children, isActive }) {\n\n  const [isPending, startTransition] = useTransition();\n\n  if (isActive) {\n\n    return <b>{children}</b>\n\n  }\n\n  return (\n\n    <button onClick={() => {\n\n      startTransition(async () => {\n\n        // await the action that's passed in.\n\n        // This allows it to be either sync or async.\n\n        await action();\n\n      });\n\n    }}>\n\n      {children}\n\n    </button>\n\n  );\n\n}\n\nBecause the parent component updates its state inside the action, that state update gets marked as a Transition. This means you can click on “Posts” and then immediately click “Contact” and it does not block user interactions:\n\nApp.js\nTabButton.js\nAboutTab.js\nPostsTab.js\nContactTab.js\nReload\nClear\nFork\nimport { useTransition } from 'react';\n\nexport default function TabButton({ action, children, isActive }) {\n  const [isPending, startTransition] = useTransition();\n  if (isActive) {\n    return <b>{children}</b>\n  }\n  if (isPending) {\n    return <b className=\"pending\">{children}</b>;\n  }\n  return (\n    <button onClick={async () => {\n      startTransition(async () => {\n        // await the action that's passed in.\n        // This allows it to be either sync or async.\n        await action();\n      });\n    }}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nNote\n\nWhen exposing an action prop from a component, you should await it inside the transition.\n\nThis allows the action callback to be either synchronous or asynchronous without requiring an additional startTransition to wrap the await in the action.\n\nDisplaying a pending visual state \n\nYou can use the isPending boolean value returned by useTransition to indicate to the user that a Transition is in progress. For example, the tab button can have a special “pending” visual state:\n\nfunction TabButton({ action, children, isActive }) {\n\n  const [isPending, startTransition] = useTransition();\n\n  // ...\n\n  if (isPending) {\n\n    return <b className=\"pending\">{children}</b>;\n\n  }\n\n  // ...\n\nNotice how clicking “Posts” now feels more responsive because the tab button itself updates right away:\n\nApp.js\nTabButton.js\nAboutTab.js\nPostsTab.js\nContactTab.js\nReload\nClear\nFork\nimport { useTransition } from 'react';\n\nexport default function TabButton({ action, children, isActive }) {\n  const [isPending, startTransition] = useTransition();\n  if (isActive) {\n    return <b>{children}</b>\n  }\n  if (isPending) {\n    return <b className=\"pending\">{children}</b>;\n  }\n  return (\n    <button onClick={() => {\n      startTransition(async () => {\n        await action();\n      });\n    }}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nPreventing unwanted loading indicators \n\nIn this example, the PostsTab component fetches some data using use. When you click the “Posts” tab, the PostsTab component suspends, causing the closest loading fallback to appear:\n\nApp.js\nTabButton.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport AboutTab from './AboutTab.js';\nimport PostsTab from './PostsTab.js';\nimport ContactTab from './ContactTab.js';\n\nexport default function TabContainer() {\n  const [tab, setTab] = useState('about');\n  return (\n    <Suspense fallback={<h1>🌀 Loading...</h1>}>\n      <TabButton\n        isActive={tab === 'about'}\n        action={() => setTab('about')}\n      >\n        About\n      </TabButton>\n      <TabButton\n        isActive={tab === 'posts'}\n        action={() => setTab('posts')}\n      >\n        Posts\n      </TabButton>\n      <TabButton\n        isActive={tab === 'contact'}\n        action={() => setTab('contact')}\n      >\n        Contact\n      </TabButton>\n      <hr />\n      {tab === 'about' && <AboutTab />}\n      {tab === 'posts' && <PostsTab />}\n      {tab === 'contact' && <ContactTab />}\n    </Suspense>\n  );\n}\n\n\nShow more\n\nHiding the entire tab container to show a loading indicator leads to a jarring user experience. If you add useTransition to TabButton, you can instead display the pending state in the tab button instead.\n\nNotice that clicking “Posts” no longer replaces the entire tab container with a spinner:\n\nApp.js\nTabButton.js\nReload\nClear\nFork\nimport { useTransition } from 'react';\n\nexport default function TabButton({ action, children, isActive }) {\n  const [isPending, startTransition] = useTransition();\n  if (isActive) {\n    return <b>{children}</b>\n  }\n  if (isPending) {\n    return <b className=\"pending\">{children}</b>;\n  }\n  return (\n    <button onClick={() => {\n      startTransition(async () => {\n        await action();\n      });\n    }}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\n\nRead more about using Transitions with Suspense.\n\nNote\n\nTransitions only “wait” long enough to avoid hiding already revealed content (like the tab container). If the Posts tab had a nested <Suspense> boundary, the Transition would not “wait” for it.\n\nBuilding a Suspense-enabled router \n\nIf you’re building a React framework or a router, we recommend marking page navigations as Transitions.\n\nfunction Router() {\n\n  const [page, setPage] = useState('/');\n\n  const [isPending, startTransition] = useTransition();\n\n\n\n  function navigate(url) {\n\n    startTransition(() => {\n\n      setPage(url);\n\n    });\n\n  }\n\n  // ...\n\nThis is recommended for three reasons:\n\nTransitions are interruptible, which lets the user click away without waiting for the re-render to complete.\nTransitions prevent unwanted loading indicators, which lets the user avoid jarring jumps on navigation.\nTransitions wait for all pending actions which lets the user wait for side effects to complete before the new page is shown.\n\nHere is a simplified router example using Transitions for navigations.\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, useState, useTransition } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n  const [isPending, startTransition] = useTransition();\n\n  function navigate(url) {\n    startTransition(() => {\n      setPage(url);\n    });\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout isPending={isPending}>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\nNote\n\nSuspense-enabled routers are expected to wrap the navigation updates into Transitions by default.\n\nDisplaying an error to users with an error boundary \n\nIf a function passed to startTransition throws an error, you can display an error to your user with an error boundary. To use an error boundary, wrap the component where you are calling the useTransition in an error boundary. Once the function passed to startTransition errors, the fallback for the error boundary will be displayed.\n\nAddCommentContainer.js\nReload\nClear\nFork\nimport { useTransition } from \"react\";\nimport { ErrorBoundary } from \"react-error-boundary\";\n\nexport function AddCommentContainer() {\n  return (\n    <ErrorBoundary fallback={<p>⚠️Something went wrong</p>}>\n      <AddCommentButton />\n    </ErrorBoundary>\n  );\n}\n\nfunction addComment(comment) {\n  // For demonstration purposes to show Error Boundary\n  if (comment == null) {\n    throw new Error(\"Example Error: An error thrown to trigger error boundary\");\n  }\n}\n\nfunction AddCommentButton() {\n  const [pending, startTransition] = useTransition();\n\n  return (\n    <button\n      disabled={pending}\n      onClick={() => {\n        startTransition(() => {\n          // Intentionally not passing a comment\n          // so error gets thrown\n          addComment();\n        });\n      }}\n    >\n      Add comment\n    </button>\n  );\n}\n\n\nShow more\nTroubleshooting \nUpdating an input in a Transition doesn’t work \n\nYou can’t use a Transition for a state variable that controls an input:\n\nconst [text, setText] = useState('');\n\n// ...\n\nfunction handleChange(e) {\n\n  // ❌ Can't use Transitions for controlled input state\n\n  startTransition(() => {\n\n    setText(e.target.value);\n\n  });\n\n}\n\n// ...\n\nreturn <input value={text} onChange={handleChange} />;\n\nThis is because Transitions are non-blocking, but updating an input in response to the change event should happen synchronously. If you want to run a Transition in response to typing, you have two options:\n\nYou can declare two separate state variables: one for the input state (which always updates synchronously), and one that you will update in a Transition. This lets you control the input using the synchronous state, and pass the Transition state variable (which will “lag behind” the input) to the rest of your rendering logic.\nAlternatively, you can have one state variable, and add useDeferredValue which will “lag behind” the real value. It will trigger non-blocking re-renders to “catch up” with the new value automatically.\nReact doesn’t treat my state update as a Transition \n\nWhen you wrap a state update in a Transition, make sure that it happens during the startTransition call:\n\nstartTransition(() => {\n\n  // ✅ Setting state *during* startTransition call\n\n  setPage('/about');\n\n});\n\nThe function you pass to startTransition must be synchronous. You can’t mark an update as a Transition like this:\n\nstartTransition(() => {\n\n  // ❌ Setting state *after* startTransition call\n\n  setTimeout(() => {\n\n    setPage('/about');\n\n  }, 1000);\n\n});\n\nInstead, you could do this:\n\nsetTimeout(() => {\n\n  startTransition(() => {\n\n    // ✅ Setting state *during* startTransition call\n\n    setPage('/about');\n\n  });\n\n}, 1000);\nReact doesn’t treat my state update after await as a Transition \n\nWhen you use await inside a startTransition function, the state updates that happen after the await are not marked as Transitions. You must wrap state updates after each await in a startTransition call:\n\nstartTransition(async () => {\n\n  await someAsyncFunction();\n\n  // ❌ Not using startTransition after await\n\n  setPage('/about');\n\n});\n\nHowever, this works instead:\n\nstartTransition(async () => {\n\n  await someAsyncFunction();\n\n  // ✅ Using startTransition *after* await\n\n  startTransition(() => {\n\n    setPage('/about');\n\n  });\n\n});\n\nThis is a JavaScript limitation due to React losing the scope of the async context. In the future, when AsyncContext is available, this limitation will be removed.\n\nI want to call useTransition from outside a component \n\nYou can’t call useTransition outside a component because it’s a Hook. In this case, use the standalone startTransition method instead. It works the same way, but it doesn’t provide the isPending indicator.\n\nThe function I pass to startTransition executes immediately \n\nIf you run this code, it will print 1, 2, 3:\n\nconsole.log(1);\n\nstartTransition(() => {\n\n  console.log(2);\n\n  setPage('/about');\n\n});\n\nconsole.log(3);\n\nIt is expected to print 1, 2, 3. The function you pass to startTransition does not get delayed. Unlike with the browser setTimeout, it does not run the callback later. React executes your function immediately, but any state updates scheduled while it is running are marked as Transitions. You can imagine that it works like this:\n\n// A simplified version of how React works\n\n\n\nlet isInsideTransition = false;\n\n\n\nfunction startTransition(scope) {\n\n  isInsideTransition = true;\n\n  scope();\n\n  isInsideTransition = false;\n\n}\n\n\n\nfunction setState() {\n\n  if (isInsideTransition) {\n\n    // ... schedule a Transition state update ...\n\n  } else {\n\n    // ... schedule an urgent state update ...\n\n  }\n\n}\nMy state updates in Transitions are out of order \n\nIf you await inside startTransition, you might see the updates happen out of order.\n\nIn this example, the updateQuantity function simulates a request to the server to update the item’s quantity in the cart. This function artificially returns every other request after the previous to simulate race conditions for network requests.\n\nTry updating the quantity once, then update it quickly multiple times. You might see the incorrect total:\n\nApp.js\nItem.js\nTotal.js\napi.js\nReload\nClear\nFork\nimport { useState, useTransition } from \"react\";\nimport { updateQuantity } from \"./api\";\nimport Item from \"./Item\";\nimport Total from \"./Total\";\n\nexport default function App({}) {\n  const [quantity, setQuantity] = useState(1);\n  const [isPending, startTransition] = useTransition();\n  // Store the actual quantity in separate state to show the mismatch.\n  const [clientQuantity, setClientQuantity] = useState(1);\n\n  const updateQuantityAction = newQuantity => {\n    setClientQuantity(newQuantity);\n\n    // Access the pending state of the transition,\n    // by wrapping in startTransition again.\n    startTransition(async () => {\n      const savedQuantity = await updateQuantity(newQuantity);\n      startTransition(() => {\n        setQuantity(savedQuantity);\n      });\n    });\n  };\n\n  return (\n    <div>\n      <h1>Checkout</h1>\n      <Item action={updateQuantityAction}/>\n      <hr />\n      <Total clientQuantity={clientQuantity} savedQuantity={quantity} isPending={isPending} />\n    </div>\n  );\n}\n\n\nShow more\n\nWhen clicking multiple times, it’s possible for previous requests to finish after later requests. When this happens, React currently has no way to know the intended order. This is because the updates are scheduled asynchronously, and React loses context of the order across the async boundary.\n\nThis is expected, because Actions within a Transition do not guarantee execution order. For common use cases, React provides higher-level abstractions like useActionState and <form> actions that handle ordering for you. For advanced use cases, you’ll need to implement your own queuing and abort logic to handle this.\n\nExample of useActionState handling execution order:\n\nApp.js\nItem.js\nTotal.js\napi.js\nReload\nClear\nFork\nimport { useState, useActionState } from \"react\";\nimport { updateQuantity } from \"./api\";\nimport Item from \"./Item\";\nimport Total from \"./Total\";\n\nexport default function App({}) {\n  // Store the actual quantity in separate state to show the mismatch.\n  const [clientQuantity, setClientQuantity] = useState(1);\n  const [quantity, updateQuantityAction, isPending] = useActionState(\n    async (prevState, payload) => {\n      setClientQuantity(payload);\n      const savedQuantity = await updateQuantity(payload);\n      return savedQuantity; // Return the new quantity to update the state\n    },\n    1 // Initial quantity\n  );\n\n  return (\n    <div>\n      <h1>Checkout</h1>\n      <Item action={updateQuantityAction}/>\n      <hr />\n      <Total clientQuantity={clientQuantity} savedQuantity={quantity} isPending={isPending} />\n    </div>\n  );\n}\n\n\nShow more\nPREVIOUS\nuseSyncExternalStore\nNEXT\nComponents"
  },
  {
    "title": "Built-in React Components – React",
    "url": "https://react.dev/reference/react/components",
    "html": "API REFERENCE\nBuilt-in React Components\n\nReact exposes a few built-in components that you can use in your JSX.\n\nBuilt-in components \n<Fragment>, alternatively written as <>...</>, lets you group multiple JSX nodes together.\n<Profiler> lets you measure rendering performance of a React tree programmatically.\n<Suspense> lets you display a fallback while the child components are loading.\n<StrictMode> enables extra development-only checks that help you find bugs early.\n<Activity> lets you hide and restore the UI and internal state of its children.\nYour own components \n\nYou can also define your own components as JavaScript functions.\n\nPREVIOUS\nuseTransition\nNEXT\n<Fragment> (<>)"
  },
  {
    "title": "<Fragment> (<>...</>) – React",
    "url": "https://react.dev/reference/react/Fragment",
    "html": "API REFERENCE\nCOMPONENTS\n<Fragment> (<>...</>)\n\n<Fragment>, often used via <>...</> syntax, lets you group elements without a wrapper node.\n\nCanary\nFragments can also accept refs, which enable interacting with underlying DOM nodes without adding wrapper elements. See reference and usage below.\n<>\n\n  <OneChild />\n\n  <AnotherChild />\n\n</>\nReference\n<Fragment>\nCanary only FragmentInstance\nUsage\nReturning multiple elements\nAssigning multiple elements to a variable\nGrouping elements with text\nRendering a list of Fragments\nCanary only Using Fragment refs for DOM interaction\nCanary only Tracking visibility with Fragment refs\nCanary only Focus management with Fragment refs\nReference \n<Fragment> \n\nWrap elements in <Fragment> to group them together in situations where you need a single element. Grouping elements in Fragment has no effect on the resulting DOM; it is the same as if the elements were not grouped. The empty JSX tag <></> is shorthand for <Fragment></Fragment> in most cases.\n\nProps \noptional key: Fragments declared with the explicit <Fragment> syntax may have keys.\nCanary only optional ref: A ref object (e.g. from useRef) or callback function. React provides a FragmentInstance as the ref value that implements methods for interacting with the DOM nodes wrapped by the Fragment.\nCanary only FragmentInstance \n\nWhen you pass a ref to a fragment, React provides a FragmentInstance object with methods for interacting with the DOM nodes wrapped by the fragment:\n\nEvent handling methods:\n\naddEventListener(type, listener, options?): Adds an event listener to all first-level DOM children of the Fragment.\nremoveEventListener(type, listener, options?): Removes an event listener from all first-level DOM children of the Fragment.\ndispatchEvent(event): Dispatches an event to a virtual child of the Fragment to call any added listeners and can bubble to the DOM parent.\n\nLayout methods:\n\ncompareDocumentPosition(otherNode): Compares the document position of the Fragment with another node.\nIf the Fragment has children, the native compareDocumentPosition value is returned.\nEmpty Fragments will attempt to compare positioning within the React tree and include Node.DOCUMENT_POSITION_IMPLEMENTATION_SPECIFIC.\nElements that have a different relationship in the React tree and DOM tree due to portaling or other insertions are Node.DOCUMENT_POSITION_IMPLEMENTATION_SPECIFIC.\ngetClientRects(): Returns a flat array of DOMRect objects representing the bounding rectangles of all children.\ngetRootNode(): Returns the root node containing the Fragment’s parent DOM node.\n\nFocus management methods:\n\nfocus(options?): Focuses the first focusable DOM node in the Fragment. Focus is attempted on nested children depth-first.\nfocusLast(options?): Focuses the last focusable DOM node in the Fragment. Focus is attempted on nested children depth-first.\nblur(): Removes focus if document.activeElement is within the Fragment.\n\nObserver methods:\n\nobserveUsing(observer): Starts observing the Fragment’s DOM children with an IntersectionObserver or ResizeObserver.\nunobserveUsing(observer): Stops observing the Fragment’s DOM children with the specified observer.\nCaveats \n\nIf you want to pass key to a Fragment, you can’t use the <>...</> syntax. You have to explicitly import Fragment from 'react' and render <Fragment key={yourKey}>...</Fragment>.\n\nReact does not reset state when you go from rendering <><Child /></> to [<Child />] or back, or when you go from rendering <><Child /></> to <Child /> and back. This only works a single level deep: for example, going from <><><Child /></></> to <Child /> resets the state. See the precise semantics here.\n\nCanary only If you want to pass ref to a Fragment, you can’t use the <>...</> syntax. You have to explicitly import Fragment from 'react' and render <Fragment ref={yourRef}>...</Fragment>.\n\nUsage \nReturning multiple elements \n\nUse Fragment, or the equivalent <>...</> syntax, to group multiple elements together. You can use it to put multiple elements in any place where a single element can go. For example, a component can only return one element, but by using a Fragment you can group multiple elements together and then return them as a group:\n\nfunction Post() {\n\n  return (\n\n    <>\n\n      <PostTitle />\n\n      <PostBody />\n\n    </>\n\n  );\n\n}\n\nFragments are useful because grouping elements with a Fragment has no effect on layout or styles, unlike if you wrapped the elements in another container like a DOM element. If you inspect this example with the browser tools, you’ll see that all <h1> and <article> DOM nodes appear as siblings without wrappers around them:\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function Blog() {\n  return (\n    <>\n      <Post title=\"An update\" body=\"It's been a while since I posted...\" />\n      <Post title=\"My new blog\" body=\"I am starting a new blog!\" />\n    </>\n  )\n}\n\nfunction Post({ title, body }) {\n  return (\n    <>\n      <PostTitle title={title} />\n      <PostBody body={body} />\n    </>\n  );\n}\n\nfunction PostTitle({ title }) {\n  return <h1>{title}</h1>\n}\n\nfunction PostBody({ body }) {\n  return (\n    <article>\n      <p>{body}</p>\n    </article>\n  );\n}\n\n\nShow more\nDEEP DIVE\nHow to write a Fragment without the special syntax? \nShow Details\nAssigning multiple elements to a variable \n\nLike any other element, you can assign Fragment elements to variables, pass them as props, and so on:\n\nfunction CloseDialog() {\n\n  const buttons = (\n\n    <>\n\n      <OKButton />\n\n      <CancelButton />\n\n    </>\n\n  );\n\n  return (\n\n    <AlertDialog buttons={buttons}>\n\n      Are you sure you want to leave this page?\n\n    </AlertDialog>\n\n  );\n\n}\nGrouping elements with text \n\nYou can use Fragment to group text together with components:\n\nfunction DateRangePicker({ start, end }) {\n\n  return (\n\n    <>\n\n      From\n\n      <DatePicker date={start} />\n\n      to\n\n      <DatePicker date={end} />\n\n    </>\n\n  );\n\n}\nRendering a list of Fragments \n\nHere’s a situation where you need to write Fragment explicitly instead of using the <></> syntax. When you render multiple elements in a loop, you need to assign a key to each element. If the elements within the loop are Fragments, you need to use the normal JSX element syntax in order to provide the key attribute:\n\nfunction Blog() {\n\n  return posts.map(post =>\n\n    <Fragment key={post.id}>\n\n      <PostTitle title={post.title} />\n\n      <PostBody body={post.body} />\n\n    </Fragment>\n\n  );\n\n}\n\nYou can inspect the DOM to verify that there are no wrapper elements around the Fragment children:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Fragment } from 'react';\n\nconst posts = [\n  { id: 1, title: 'An update', body: \"It's been a while since I posted...\" },\n  { id: 2, title: 'My new blog', body: 'I am starting a new blog!' }\n];\n\nexport default function Blog() {\n  return posts.map(post =>\n    <Fragment key={post.id}>\n      <PostTitle title={post.title} />\n      <PostBody body={post.body} />\n    </Fragment>\n  );\n}\n\nfunction PostTitle({ title }) {\n  return <h1>{title}</h1>\n}\n\nfunction PostBody({ body }) {\n  return (\n    <article>\n      <p>{body}</p>\n    </article>\n  );\n}\n\n\nShow more\nCanary only Using Fragment refs for DOM interaction \n\nFragment refs allow you to interact with the DOM nodes wrapped by a Fragment without adding extra wrapper elements. This is useful for event handling, visibility tracking, focus management, and replacing deprecated patterns like ReactDOM.findDOMNode().\n\nimport { Fragment } from 'react';\n\n\n\nfunction ClickableFragment({ children, onClick }) {\n\n  return (\n\n    <Fragment ref={fragmentInstance => {\n\n      fragmentInstance.addEventListener('click', handleClick);\n\n      return () => fragmentInstance.removeEventListener('click', handleClick);\n\n    }}>\n\n      {children}\n\n    </Fragment>\n\n  );\n\n}\nCanary only Tracking visibility with Fragment refs \n\nFragment refs are useful for visibility tracking and intersection observation. This enables you to monitor when content becomes visible without requiring the child Components to expose refs:\n\nimport { Fragment, useRef, useLayoutEffect } from 'react';\n\n\n\nfunction VisibilityObserverFragment({ threshold = 0.5, onVisibilityChange, children }) {\n\n  const fragmentRef = useRef(null);\n\n\n\n  useLayoutEffect(() => {\n\n    const observer = new IntersectionObserver(\n\n      (entries) => {\n\n        onVisibilityChange(entries.some(entry => entry.isIntersecting))\n\n      },\n\n      { threshold }\n\n    );\n\n    \n\n    fragmentRef.current.observeUsing(observer);\n\n    return () => fragmentRef.current.unobserveUsing(observer);\n\n  }, [threshold, onVisibilityChange]);\n\n\n\n  return (\n\n    <Fragment ref={fragmentRef}>\n\n      {children}\n\n    </Fragment>\n\n  );\n\n}\n\n\n\nfunction MyComponent() {\n\n  const handleVisibilityChange = (isVisible) => {\n\n    console.log('Component is', isVisible ? 'visible' : 'hidden');\n\n  };\n\n\n\n  return (\n\n    <VisibilityObserverFragment onVisibilityChange={handleVisibilityChange}>\n\n      <SomeThirdPartyComponent />\n\n      <AnotherComponent />\n\n    </VisibilityObserverFragment>\n\n  );\n\n}\n\nThis pattern is an alternative to Effect-based visibility logging, which is an anti-pattern in most cases. Relying on Effects alone does not guarantee that the rendered Component is observable by the user.\n\nCanary only Focus management with Fragment refs \n\nFragment refs provide focus management methods that work across all DOM nodes within the Fragment:\n\nimport { Fragment, useRef } from 'react';\n\n\n\nfunction FocusFragment({ children }) {\n\n  return (\n\n    <Fragment ref={(fragmentInstance) => fragmentInstance?.focus()}>\n\n      {children}\n\n    </Fragment>\n\n  );\n\n}\n\nThe focus() method focuses the first focusable element within the Fragment, while focusLast() focuses the last focusable element.\n\nPREVIOUS\nComponents\nNEXT\n<Profiler>"
  },
  {
    "title": "<Profiler> – React",
    "url": "https://react.dev/reference/react/Profiler",
    "html": "API REFERENCE\nCOMPONENTS\n<Profiler>\n\n<Profiler> lets you measure rendering performance of a React tree programmatically.\n\n<Profiler id=\"App\" onRender={onRender}>\n\n  <App />\n\n</Profiler>\nReference\n<Profiler>\nonRender callback\nUsage\nMeasuring rendering performance programmatically\nMeasuring different parts of the application\nReference \n<Profiler> \n\nWrap a component tree in a <Profiler> to measure its rendering performance.\n\n<Profiler id=\"App\" onRender={onRender}>\n\n  <App />\n\n</Profiler>\nProps \nid: A string identifying the part of the UI you are measuring.\nonRender: An onRender callback that React calls every time components within the profiled tree update. It receives information about what was rendered and how much time it took.\nCaveats \nProfiling adds some additional overhead, so it is disabled in the production build by default. To opt into production profiling, you need to enable a special production build with profiling enabled.\nonRender callback \n\nReact will call your onRender callback with information about what was rendered.\n\nfunction onRender(id, phase, actualDuration, baseDuration, startTime, commitTime) {\n\n  // Aggregate or log render timings...\n\n}\nParameters \nid: The string id prop of the <Profiler> tree that has just committed. This lets you identify which part of the tree was committed if you are using multiple profilers.\nphase: \"mount\", \"update\" or \"nested-update\". This lets you know whether the tree has just been mounted for the first time or re-rendered due to a change in props, state, or Hooks.\nactualDuration: The number of milliseconds spent rendering the <Profiler> and its descendants for the current update. This indicates how well the subtree makes use of memoization (e.g. memo and useMemo). Ideally this value should decrease significantly after the initial mount as many of the descendants will only need to re-render if their specific props change.\nbaseDuration: The number of milliseconds estimating how much time it would take to re-render the entire <Profiler> subtree without any optimizations. It is calculated by summing up the most recent render durations of each component in the tree. This value estimates a worst-case cost of rendering (e.g. the initial mount or a tree with no memoization). Compare actualDuration against it to see if memoization is working.\nstartTime: A numeric timestamp for when React began rendering the current update.\ncommitTime: A numeric timestamp for when React committed the current update. This value is shared between all profilers in a commit, enabling them to be grouped if desirable.\nUsage \nMeasuring rendering performance programmatically \n\nWrap the <Profiler> component around a React tree to measure its rendering performance.\n\n<App>\n\n  <Profiler id=\"Sidebar\" onRender={onRender}>\n\n    <Sidebar />\n\n  </Profiler>\n\n  <PageContent />\n\n</App>\n\nIt requires two props: an id (string) and an onRender callback (function) which React calls any time a component within the tree “commits” an update.\n\nPitfall\n\nProfiling adds some additional overhead, so it is disabled in the production build by default. To opt into production profiling, you need to enable a special production build with profiling enabled.\n\nNote\n\n<Profiler> lets you gather measurements programmatically. If you’re looking for an interactive profiler, try the Profiler tab in React Developer Tools. It exposes similar functionality as a browser extension.\n\nComponents wrapped in <Profiler> will also be marked in the Component tracks of React Performance tracks even in profiling builds.\nIn development builds, all components are marked in the Components track regardless of whether they’re wrapped in <Profiler>.\n\nMeasuring different parts of the application \n\nYou can use multiple <Profiler> components to measure different parts of your application:\n\n<App>\n\n  <Profiler id=\"Sidebar\" onRender={onRender}>\n\n    <Sidebar />\n\n  </Profiler>\n\n  <Profiler id=\"Content\" onRender={onRender}>\n\n    <Content />\n\n  </Profiler>\n\n</App>\n\nYou can also nest <Profiler> components:\n\n<App>\n\n  <Profiler id=\"Sidebar\" onRender={onRender}>\n\n    <Sidebar />\n\n  </Profiler>\n\n  <Profiler id=\"Content\" onRender={onRender}>\n\n    <Content>\n\n      <Profiler id=\"Editor\" onRender={onRender}>\n\n        <Editor />\n\n      </Profiler>\n\n      <Preview />\n\n    </Content>\n\n  </Profiler>\n\n</App>\n\nAlthough <Profiler> is a lightweight component, it should be used only when necessary. Each use adds some CPU and memory overhead to an application.\n\nPREVIOUS\n<Fragment> (<>)\nNEXT\n<StrictMode>"
  },
  {
    "title": "<StrictMode> – React",
    "url": "https://react.dev/reference/react/StrictMode",
    "html": "API REFERENCE\nCOMPONENTS\n<StrictMode>\n\n<StrictMode> lets you find common bugs in your components early during development.\n\n<StrictMode>\n\n  <App />\n\n</StrictMode>\nReference\n<StrictMode>\nUsage\nEnabling Strict Mode for entire app\nEnabling Strict Mode for a part of the app\nFixing bugs found by double rendering in development\nFixing bugs found by re-running Effects in development\nFixing bugs found by re-running ref callbacks in development\nFixing deprecation warnings enabled by Strict Mode\nReference \n<StrictMode> \n\nUse StrictMode to enable additional development behaviors and warnings for the component tree inside:\n\nimport { StrictMode } from 'react';\n\nimport { createRoot } from 'react-dom/client';\n\n\n\nconst root = createRoot(document.getElementById('root'));\n\nroot.render(\n\n  <StrictMode>\n\n    <App />\n\n  </StrictMode>\n\n);\n\nSee more examples below.\n\nStrict Mode enables the following development-only behaviors:\n\nYour components will re-render an extra time to find bugs caused by impure rendering.\nYour components will re-run Effects an extra time to find bugs caused by missing Effect cleanup.\nYour components will re-run refs callbacks an extra time to find bugs caused by missing ref cleanup.\nYour components will be checked for usage of deprecated APIs.\nProps \n\nStrictMode accepts no props.\n\nCaveats \nThere is no way to opt out of Strict Mode inside a tree wrapped in <StrictMode>. This gives you confidence that all components inside <StrictMode> are checked. If two teams working on a product disagree whether they find the checks valuable, they need to either reach consensus or move <StrictMode> down in the tree.\nUsage \nEnabling Strict Mode for entire app \n\nStrict Mode enables extra development-only checks for the entire component tree inside the <StrictMode> component. These checks help you find common bugs in your components early in the development process.\n\nTo enable Strict Mode for your entire app, wrap your root component with <StrictMode> when you render it:\n\nimport { StrictMode } from 'react';\n\nimport { createRoot } from 'react-dom/client';\n\n\n\nconst root = createRoot(document.getElementById('root'));\n\nroot.render(\n\n  <StrictMode>\n\n    <App />\n\n  </StrictMode>\n\n);\n\nWe recommend wrapping your entire app in Strict Mode, especially for newly created apps. If you use a framework that calls createRoot for you, check its documentation for how to enable Strict Mode.\n\nAlthough the Strict Mode checks only run in development, they help you find bugs that already exist in your code but can be tricky to reliably reproduce in production. Strict Mode lets you fix bugs before your users report them.\n\nNote\n\nStrict Mode enables the following checks in development:\n\nYour components will re-render an extra time to find bugs caused by impure rendering.\nYour components will re-run Effects an extra time to find bugs caused by missing Effect cleanup.\nYour components will re-run ref callbacks an extra time to find bugs caused by missing ref cleanup.\nYour components will be checked for usage of deprecated APIs.\n\nAll of these checks are development-only and do not impact the production build.\n\nEnabling Strict Mode for a part of the app \n\nYou can also enable Strict Mode for any part of your application:\n\nimport { StrictMode } from 'react';\n\n\n\nfunction App() {\n\n  return (\n\n    <>\n\n      <Header />\n\n      <StrictMode>\n\n        <main>\n\n          <Sidebar />\n\n          <Content />\n\n        </main>\n\n      </StrictMode>\n\n      <Footer />\n\n    </>\n\n  );\n\n}\n\nIn this example, Strict Mode checks will not run against the Header and Footer components. However, they will run on Sidebar and Content, as well as all of the components inside them, no matter how deep.\n\nNote\n\nWhen StrictMode is enabled for a part of the app, React will only enable behaviors that are possible in production. For example, if <StrictMode> is not enabled at the root of the app, it will not re-run Effects an extra time on initial mount, since this would cause child effects to double fire without the parent effects, which cannot happen in production.\n\nFixing bugs found by double rendering in development \n\nReact assumes that every component you write is a pure function. This means that React components you write must always return the same JSX given the same inputs (props, state, and context).\n\nComponents breaking this rule behave unpredictably and cause bugs. To help you find accidentally impure code, Strict Mode calls some of your functions (only the ones that should be pure) twice in development. This includes:\n\nYour component function body (only top-level logic, so this doesn’t include code inside event handlers)\nFunctions that you pass to useState, set functions, useMemo, or useReducer\nSome class component methods like constructor, render, shouldComponentUpdate (see the whole list)\n\nIf a function is pure, running it twice does not change its behavior because a pure function produces the same result every time. However, if a function is impure (for example, it mutates the data it receives), running it twice tends to be noticeable (that’s what makes it impure!) This helps you spot and fix the bug early.\n\nHere is an example to illustrate how double rendering in Strict Mode helps you find bugs early.\n\nThis StoryTray component takes an array of stories and adds one last “Create Story” item at the end:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nexport default function StoryTray({ stories }) {\n  const items = stories;\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul>\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\n\nThere is a mistake in the code above. However, it is easy to miss because the initial output appears correct.\n\nThis mistake will become more noticeable if the StoryTray component re-renders multiple times. For example, let’s make the StoryTray re-render with a different background color whenever you hover over it:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function StoryTray({ stories }) {\n  const [isHover, setIsHover] = useState(false);\n  const items = stories;\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul\n      onPointerEnter={() => setIsHover(true)}\n      onPointerLeave={() => setIsHover(false)}\n      style={{\n        backgroundColor: isHover ? '#ddd' : '#fff'\n      }}\n    >\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\nShow more\n\nNotice how every time you hover over the StoryTray component, “Create Story” gets added to the list again. The intention of the code was to add it once at the end. But StoryTray directly modifies the stories array from the props. Every time StoryTray renders, it adds “Create Story” again at the end of the same array. In other words, StoryTray is not a pure function—running it multiple times produces different results.\n\nTo fix this problem, you can make a copy of the array, and modify that copy instead of the original one:\n\nexport default function StoryTray({ stories }) {\n\n  const items = stories.slice(); // Clone the array\n\n  // ✅ Good: Pushing into a new array\n\n  items.push({ id: 'create', label: 'Create Story' });\n\nThis would make the StoryTray function pure. Each time it is called, it would only modify a new copy of the array, and would not affect any external objects or variables. This solves the bug, but you had to make the component re-render more often before it became obvious that something is wrong with its behavior.\n\nIn the original example, the bug wasn’t obvious. Now let’s wrap the original (buggy) code in <StrictMode>:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nexport default function StoryTray({ stories }) {\n  const items = stories;\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul>\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\n\nStrict Mode always calls your rendering function twice, so you can see the mistake right away (“Create Story” appears twice). This lets you notice such mistakes early in the process. When you fix your component to render in Strict Mode, you also fix many possible future production bugs like the hover functionality from before:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function StoryTray({ stories }) {\n  const [isHover, setIsHover] = useState(false);\n  const items = stories.slice(); // Clone the array\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul\n      onPointerEnter={() => setIsHover(true)}\n      onPointerLeave={() => setIsHover(false)}\n      style={{\n        backgroundColor: isHover ? '#ddd' : '#fff'\n      }}\n    >\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\nShow more\n\nWithout Strict Mode, it was easy to miss the bug until you added more re-renders. Strict Mode made the same bug appear right away. Strict Mode helps you find bugs before you push them to your team and to your users.\n\nRead more about keeping components pure.\n\nNote\n\nIf you have React DevTools installed, any console.log calls during the second render call will appear slightly dimmed. React DevTools also offers a setting (off by default) to suppress them completely.\n\nFixing bugs found by re-running Effects in development \n\nStrict Mode can also help find bugs in Effects.\n\nEvery Effect has some setup code and may have some cleanup code. Normally, React calls setup when the component mounts (is added to the screen) and calls cleanup when the component unmounts (is removed from the screen). React then calls cleanup and setup again if its dependencies changed since the last render.\n\nWhen Strict Mode is on, React will also run one extra setup+cleanup cycle in development for every Effect. This may feel surprising, but it helps reveal subtle bugs that are hard to catch manually.\n\nHere is an example to illustrate how re-running Effects in Strict Mode helps you find bugs early.\n\nConsider this example that connects a component to a chat:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(<App />);\n\n\n\nThere is an issue with this code, but it might not be immediately clear.\n\nTo make the issue more obvious, let’s implement a feature. In the example below, roomId is not hardcoded. Instead, the user can select the roomId that they want to connect to from a dropdown. Click “Open chat” and then select different chat rooms one by one. Keep track of the number of active connections in the console:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(<App />);\n\n\n\nYou’ll notice that the number of open connections always keeps growing. In a real app, this would cause performance and network problems. The issue is that your Effect is missing a cleanup function:\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]);\n\nNow that your Effect “cleans up” after itself and destroys the outdated connections, the leak is solved. However, notice that the problem did not become visible until you’ve added more features (the select box).\n\nIn the original example, the bug wasn’t obvious. Now let’s wrap the original (buggy) code in <StrictMode>:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { StrictMode } from 'react';\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(\n  <StrictMode>\n    <App />\n  </StrictMode>\n);\n\n\n\nWith Strict Mode, you immediately see that there is a problem (the number of active connections jumps to 2). Strict Mode runs an extra setup+cleanup cycle for every Effect. This Effect has no cleanup logic, so it creates an extra connection but doesn’t destroy it. This is a hint that you’re missing a cleanup function.\n\nStrict Mode lets you notice such mistakes early in the process. When you fix your Effect by adding a cleanup function in Strict Mode, you also fix many possible future production bugs like the select box from before:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { StrictMode } from 'react';\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(\n  <StrictMode>\n    <App />\n  </StrictMode>\n);\n\n\n\nNotice how the active connection count in the console doesn’t keep growing anymore.\n\nWithout Strict Mode, it was easy to miss that your Effect needed cleanup. By running setup → cleanup → setup instead of setup for your Effect in development, Strict Mode made the missing cleanup logic more noticeable.\n\nRead more about implementing Effect cleanup.\n\nFixing bugs found by re-running ref callbacks in development \n\nStrict Mode can also help find bugs in callbacks refs.\n\nEvery callback ref has some setup code and may have some cleanup code. Normally, React calls setup when the element is created (is added to the DOM) and calls cleanup when the element is removed (is removed from the DOM).\n\nWhen Strict Mode is on, React will also run one extra setup+cleanup cycle in development for every callback ref. This may feel surprising, but it helps reveal subtle bugs that are hard to catch manually.\n\nConsider this example, which allows you to select an animal and then scroll to one of them. Notice when you switch from “Cats” to “Dogs”, the console logs show that the number of animals in the list keeps growing, and the “Scroll to” buttons stop working:\n\nindex.js\nApp.js\nReload\nClear\nFork\nimport { useRef, useState } from \"react\";\n\nexport default function CatFriends() {\n  const itemsRef = useRef([]);\n  const [catList, setCatList] = useState(setupCatList);\n  const [cat, setCat] = useState('neo');\n\n  function scrollToCat(index) {\n    const list = itemsRef.current;\n    const {node} = list[index];\n    node.scrollIntoView({\n      behavior: \"smooth\",\n      block: \"nearest\",\n      inline: \"center\",\n    });\n  }\n\n  const cats = catList.filter(c => c.type === cat)\n\n  return (\n    <>\n      <nav>\n        <button onClick={() => setCat('neo')}>Neo</button>\n        <button onClick={() => setCat('millie')}>Millie</button>\n      </nav>\n      <hr />\n      <nav>\n        <span>Scroll to:</span>{cats.map((cat, index) => (\n          <button key={cat.src} onClick={() => scrollToCat(index)}>\n            {index}\n          </button>\n        ))}\n      </nav>\n      <div>\n        <ul>\n          {cats.map((cat) => (\n            <li\n              key={cat.src}\n              ref={(node) => {\n                const list = itemsRef.current;\n                const item = {cat: cat, node};\n                list.push(item);\n                console.log(`✅ Adding cat to the map. Total cats: ${list.length}`);\n                if (list.length > 10) {\n                  console.log('❌ Too many cats in the list!');\n                }\n                return () => {\n                  // 🚩 No cleanup, this is a bug!\n                }\n              }}\n            >\n              <img src={cat.src} />\n            </li>\n          ))}\n        </ul>\n      </div>\n    </>\n  );\n}\n\nfunction setupCatList() {\n  const catList = [];\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'neo', src: \"https://placecats.com/neo/320/240?\" + i});\n  }\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'millie', src: \"https://placecats.com/millie/320/240?\" + i});\n  }\n\n  return catList;\n}\n\n\nShow more\n\nThis is a production bug! Since the ref callback doesn’t remove animals from the list in the cleanup, the list of animals keeps growing. This is a memory leak that can cause performance problems in a real app, and breaks the behavior of the app.\n\nThe issue is the ref callback doesn’t cleanup after itself:\n\n<li\n\n  ref={node => {\n\n    const list = itemsRef.current;\n\n    const item = {animal, node};\n\n    list.push(item);\n\n    return () => {\n\n      // 🚩 No cleanup, this is a bug!\n\n    }\n\n  }}\n\n</li>\n\nNow let’s wrap the original (buggy) code in <StrictMode>:\n\nindex.js\nApp.js\nReload\nClear\nFork\nimport { useRef, useState } from \"react\";\n\nexport default function CatFriends() {\n  const itemsRef = useRef([]);\n  const [catList, setCatList] = useState(setupCatList);\n  const [cat, setCat] = useState('neo');\n\n  function scrollToCat(index) {\n    const list = itemsRef.current;\n    const {node} = list[index];\n    node.scrollIntoView({\n      behavior: \"smooth\",\n      block: \"nearest\",\n      inline: \"center\",\n    });\n  }\n\n  const cats = catList.filter(c => c.type === cat)\n\n  return (\n    <>\n      <nav>\n        <button onClick={() => setCat('neo')}>Neo</button>\n        <button onClick={() => setCat('millie')}>Millie</button>\n      </nav>\n      <hr />\n      <nav>\n        <span>Scroll to:</span>{cats.map((cat, index) => (\n          <button key={cat.src} onClick={() => scrollToCat(index)}>\n            {index}\n          </button>\n        ))}\n      </nav>\n      <div>\n        <ul>\n          {cats.map((cat) => (\n            <li\n              key={cat.src}\n              ref={(node) => {\n                const list = itemsRef.current;\n                const item = {cat: cat, node};\n                list.push(item);\n                console.log(`✅ Adding cat to the map. Total cats: ${list.length}`);\n                if (list.length > 10) {\n                  console.log('❌ Too many cats in the list!');\n                }\n                return () => {\n                  // 🚩 No cleanup, this is a bug!\n                }\n              }}\n            >\n              <img src={cat.src} />\n            </li>\n          ))}\n        </ul>\n      </div>\n    </>\n  );\n}\n\nfunction setupCatList() {\n  const catList = [];\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'neo', src: \"https://placecats.com/neo/320/240?\" + i});\n  }\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'millie', src: \"https://placecats.com/millie/320/240?\" + i});\n  }\n\n  return catList;\n}\n\n\nShow more\n\nWith Strict Mode, you immediately see that there is a problem. Strict Mode runs an extra setup+cleanup cycle for every callback ref. This callback ref has no cleanup logic, so it adds refs but doesn’t remove them. This is a hint that you’re missing a cleanup function.\n\nStrict Mode lets you eagerly find mistakes in callback refs. When you fix your callback by adding a cleanup function in Strict Mode, you also fix many possible future production bugs like the “Scroll to” bug from before:\n\nindex.js\nApp.js\nReload\nClear\nFork\nimport { useRef, useState } from \"react\";\n\nexport default function CatFriends() {\n  const itemsRef = useRef([]);\n  const [catList, setCatList] = useState(setupCatList);\n  const [cat, setCat] = useState('neo');\n\n  function scrollToCat(index) {\n    const list = itemsRef.current;\n    const {node} = list[index];\n    node.scrollIntoView({\n      behavior: \"smooth\",\n      block: \"nearest\",\n      inline: \"center\",\n    });\n  }\n\n  const cats = catList.filter(c => c.type === cat)\n\n  return (\n    <>\n      <nav>\n        <button onClick={() => setCat('neo')}>Neo</button>\n        <button onClick={() => setCat('millie')}>Millie</button>\n      </nav>\n      <hr />\n      <nav>\n        <span>Scroll to:</span>{cats.map((cat, index) => (\n          <button key={cat.src} onClick={() => scrollToCat(index)}>\n            {index}\n          </button>\n        ))}\n      </nav>\n      <div>\n        <ul>\n          {cats.map((cat) => (\n            <li\n              key={cat.src}\n              ref={(node) => {\n                const list = itemsRef.current;\n                const item = {cat: cat, node};\n                list.push(item);\n                console.log(`✅ Adding cat to the map. Total cats: ${list.length}`);\n                if (list.length > 10) {\n                  console.log('❌ Too many cats in the list!');\n                }\n                return () => {\n                  list.splice(list.indexOf(item), 1);\n                  console.log(`❌ Removing cat from the map. Total cats: ${itemsRef.current.length}`);\n                }\n              }}\n            >\n              <img src={cat.src} />\n            </li>\n          ))}\n        </ul>\n      </div>\n    </>\n  );\n}\n\nfunction setupCatList() {\n  const catList = [];\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'neo', src: \"https://placecats.com/neo/320/240?\" + i});\n  }\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'millie', src: \"https://placecats.com/millie/320/240?\" + i});\n  }\n\n  return catList;\n}\n\n\nShow more\n\nNow on inital mount in StrictMode, the ref callbacks are all setup, cleaned up, and setup again:\n\n...\n\n✅ Adding animal to the map. Total animals: 10\n\n...\n\n❌ Removing animal from the map. Total animals: 0\n\n...\n\n✅ Adding animal to the map. Total animals: 10\n\nThis is expected. Strict Mode confirms that the ref callbacks are cleaned up correctly, so the size never grows above the expected amount. After the fix, there are no memory leaks, and all the features work as expected.\n\nWithout Strict Mode, it was easy to miss the bug until you clicked around to app to notice broken features. Strict Mode made the bugs appear right away, before you push them to production.\n\nFixing deprecation warnings enabled by Strict Mode \n\nReact warns if some component anywhere inside a <StrictMode> tree uses one of these deprecated APIs:\n\nUNSAFE_ class lifecycle methods like UNSAFE_componentWillMount. See alternatives.\n\nThese APIs are primarily used in older class components so they rarely appear in modern apps.\n\nPREVIOUS\n<Profiler>\nNEXT\n<Suspense>"
  },
  {
    "title": "<Suspense> – React",
    "url": "https://react.dev/reference/react/Suspense",
    "html": "API REFERENCE\nCOMPONENTS\n<Suspense>\n\n<Suspense> lets you display a fallback until its children have finished loading.\n\n<Suspense fallback={<Loading />}>\n\n  <SomeComponent />\n\n</Suspense>\nReference\n<Suspense>\nUsage\nDisplaying a fallback while content is loading\nRevealing content together at once\nRevealing nested content as it loads\nShowing stale content while fresh content is loading\nPreventing already revealed content from hiding\nIndicating that a Transition is happening\nResetting Suspense boundaries on navigation\nProviding a fallback for server errors and client-only content\nTroubleshooting\nHow do I prevent the UI from being replaced by a fallback during an update?\nReference \n<Suspense> \nProps \nchildren: The actual UI you intend to render. If children suspends while rendering, the Suspense boundary will switch to rendering fallback.\nfallback: An alternate UI to render in place of the actual UI if it has not finished loading. Any valid React node is accepted, though in practice, a fallback is a lightweight placeholder view, such as a loading spinner or skeleton. Suspense will automatically switch to fallback when children suspends, and back to children when the data is ready. If fallback suspends while rendering, it will activate the closest parent Suspense boundary.\nCaveats \nReact does not preserve any state for renders that got suspended before they were able to mount for the first time. When the component has loaded, React will retry rendering the suspended tree from scratch.\nIf Suspense was displaying content for the tree, but then it suspended again, the fallback will be shown again unless the update causing it was caused by startTransition or useDeferredValue.\nIf React needs to hide the already visible content because it suspended again, it will clean up layout Effects in the content tree. When the content is ready to be shown again, React will fire the layout Effects again. This ensures that Effects measuring the DOM layout don’t try to do this while the content is hidden.\nReact includes under-the-hood optimizations like Streaming Server Rendering and Selective Hydration that are integrated with Suspense. Read an architectural overview and watch a technical talk to learn more.\nUsage \nDisplaying a fallback while content is loading \n\nYou can wrap any part of your application with a Suspense boundary:\n\n<Suspense fallback={<Loading />}>\n\n  <Albums />\n\n</Suspense>\n\nReact will display your loading fallback until all the code and data needed by the children has been loaded.\n\nIn the example below, the Albums component suspends while fetching the list of albums. Until it’s ready to render, React switches the closest Suspense boundary above to show the fallback—your Loading component. Then, when the data loads, React hides the Loading fallback and renders the Albums component with data.\n\nArtistPage.js\nAlbums.js\nReload\nClear\nFork\nimport { Suspense } from 'react';\nimport Albums from './Albums.js';\n\nexport default function ArtistPage({ artist }) {\n  return (\n    <>\n      <h1>{artist.name}</h1>\n      <Suspense fallback={<Loading />}>\n        <Albums artistId={artist.id} />\n      </Suspense>\n    </>\n  );\n}\n\nfunction Loading() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\nNote\n\nOnly Suspense-enabled data sources will activate the Suspense component. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a cached Promise with use\n\nSuspense does not detect when data is fetched inside an Effect or event handler.\n\nThe exact way you would load data in the Albums component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nRevealing content together at once \n\nBy default, the whole tree inside Suspense is treated as a single unit. For example, even if only one of these components suspends waiting for some data, all of them together will be replaced by the loading indicator:\n\n<Suspense fallback={<Loading />}>\n\n  <Biography />\n\n  <Panel>\n\n    <Albums />\n\n  </Panel>\n\n</Suspense>\n\nThen, after all of them are ready to be displayed, they will all appear together at once.\n\nIn the example below, both Biography and Albums fetch some data. However, because they are grouped under a single Suspense boundary, these components always “pop in” together at the same time.\n\nArtistPage.js\nPanel.js\nBiography.js\nAlbums.js\nReload\nClear\nFork\nimport { Suspense } from 'react';\nimport Albums from './Albums.js';\nimport Biography from './Biography.js';\nimport Panel from './Panel.js';\n\nexport default function ArtistPage({ artist }) {\n  return (\n    <>\n      <h1>{artist.name}</h1>\n      <Suspense fallback={<Loading />}>\n        <Biography artistId={artist.id} />\n        <Panel>\n          <Albums artistId={artist.id} />\n        </Panel>\n      </Suspense>\n    </>\n  );\n}\n\nfunction Loading() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\n\nComponents that load data don’t have to be direct children of the Suspense boundary. For example, you can move Biography and Albums into a new Details component. This doesn’t change the behavior. Biography and Albums share the same closest parent Suspense boundary, so their reveal is coordinated together.\n\n<Suspense fallback={<Loading />}>\n\n  <Details artistId={artist.id} />\n\n</Suspense>\n\n\n\nfunction Details({ artistId }) {\n\n  return (\n\n    <>\n\n      <Biography artistId={artistId} />\n\n      <Panel>\n\n        <Albums artistId={artistId} />\n\n      </Panel>\n\n    </>\n\n  );\n\n}\nRevealing nested content as it loads \n\nWhen a component suspends, the closest parent Suspense component shows the fallback. This lets you nest multiple Suspense components to create a loading sequence. Each Suspense boundary’s fallback will be filled in as the next level of content becomes available. For example, you can give the album list its own fallback:\n\n<Suspense fallback={<BigSpinner />}>\n\n  <Biography />\n\n  <Suspense fallback={<AlbumsGlimmer />}>\n\n    <Panel>\n\n      <Albums />\n\n    </Panel>\n\n  </Suspense>\n\n</Suspense>\n\nWith this change, displaying the Biography doesn’t need to “wait” for the Albums to load.\n\nThe sequence will be:\n\nIf Biography hasn’t loaded yet, BigSpinner is shown in place of the entire content area.\nOnce Biography finishes loading, BigSpinner is replaced by the content.\nIf Albums hasn’t loaded yet, AlbumsGlimmer is shown in place of Albums and its parent Panel.\nFinally, once Albums finishes loading, it replaces AlbumsGlimmer.\nArtistPage.js\nPanel.js\nBiography.js\nAlbums.js\nReload\nClear\nFork\nimport { Suspense } from 'react';\nimport Albums from './Albums.js';\nimport Biography from './Biography.js';\nimport Panel from './Panel.js';\n\nexport default function ArtistPage({ artist }) {\n  return (\n    <>\n      <h1>{artist.name}</h1>\n      <Suspense fallback={<BigSpinner />}>\n        <Biography artistId={artist.id} />\n        <Suspense fallback={<AlbumsGlimmer />}>\n          <Panel>\n            <Albums artistId={artist.id} />\n          </Panel>\n        </Suspense>\n      </Suspense>\n    </>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\nfunction AlbumsGlimmer() {\n  return (\n    <div className=\"glimmer-panel\">\n      <div className=\"glimmer-line\" />\n      <div className=\"glimmer-line\" />\n      <div className=\"glimmer-line\" />\n    </div>\n  );\n}\n\n\nShow more\n\nSuspense boundaries let you coordinate which parts of your UI should always “pop in” together at the same time, and which parts should progressively reveal more content in a sequence of loading states. You can add, move, or delete Suspense boundaries in any place in the tree without affecting the rest of your app’s behavior.\n\nDon’t put a Suspense boundary around every component. Suspense boundaries should not be more granular than the loading sequence that you want the user to experience. If you work with a designer, ask them where the loading states should be placed—it’s likely that they’ve already included them in their design wireframes.\n\nShowing stale content while fresh content is loading \n\nIn this example, the SearchResults component suspends while fetching the search results. Type \"a\", wait for the results, and then edit it to \"ab\". The results for \"a\" will get replaced by the loading fallback.\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <SearchResults query={query} />\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nA common alternative UI pattern is to defer updating the list and to keep showing the previous results until the new results are ready. The useDeferredValue Hook lets you pass a deferred version of the query down:\n\nexport default function App() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  return (\n\n    <>\n\n      <label>\n\n        Search albums:\n\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n\n      </label>\n\n      <Suspense fallback={<h2>Loading...</h2>}>\n\n        <SearchResults query={deferredQuery} />\n\n      </Suspense>\n\n    </>\n\n  );\n\n}\n\nThe query will update immediately, so the input will display the new value. However, the deferredQuery will keep its previous value until the data has loaded, so SearchResults will show the stale results for a bit.\n\nTo make it more obvious to the user, you can add a visual indication when the stale result list is displayed:\n\n<div style={{\n\n  opacity: query !== deferredQuery ? 0.5 : 1 \n\n}}>\n\n  <SearchResults query={deferredQuery} />\n\n</div>\n\nEnter \"a\" in the example below, wait for the results to load, and then edit the input to \"ab\". Notice how instead of the Suspense fallback, you now see the dimmed stale result list until the new results have loaded:\n\nApp.js\nReload\nClear\nFork\nimport { Suspense, useState, useDeferredValue } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  const deferredQuery = useDeferredValue(query);\n  const isStale = query !== deferredQuery;\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <div style={{ opacity: isStale ? 0.5 : 1 }}>\n          <SearchResults query={deferredQuery} />\n        </div>\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\nNote\n\nBoth deferred values and Transitions let you avoid showing Suspense fallback in favor of inline indicators. Transitions mark the whole update as non-urgent so they are typically used by frameworks and router libraries for navigation. Deferred values, on the other hand, are mostly useful in application code where you want to mark a part of UI as non-urgent and let it “lag behind” the rest of the UI.\n\nPreventing already revealed content from hiding \n\nWhen a component suspends, the closest parent Suspense boundary switches to showing the fallback. This can lead to a jarring user experience if it was already displaying some content. Try pressing this button:\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n\n  function navigate(url) {\n    setPage(url);\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\n\nWhen you pressed the button, the Router component rendered ArtistPage instead of IndexPage. A component inside ArtistPage suspended, so the closest Suspense boundary started showing the fallback. The closest Suspense boundary was near the root, so the whole site layout got replaced by BigSpinner.\n\nTo prevent this, you can mark the navigation state update as a Transition with startTransition:\n\nfunction Router() {\n\n  const [page, setPage] = useState('/');\n\n\n\n  function navigate(url) {\n\n    startTransition(() => {\n\n      setPage(url);      \n\n    });\n\n  }\n\n  // ...\n\nThis tells React that the state transition is not urgent, and it’s better to keep showing the previous page instead of hiding any already revealed content. Now clicking the button “waits” for the Biography to load:\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, startTransition, useState } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n\n  function navigate(url) {\n    startTransition(() => {\n      setPage(url);\n    });\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\n\nA Transition doesn’t wait for all content to load. It only waits long enough to avoid hiding already revealed content. For example, the website Layout was already revealed, so it would be bad to hide it behind a loading spinner. However, the nested Suspense boundary around Albums is new, so the Transition doesn’t wait for it.\n\nNote\n\nSuspense-enabled routers are expected to wrap the navigation updates into Transitions by default.\n\nIndicating that a Transition is happening \n\nIn the above example, once you click the button, there is no visual indication that a navigation is in progress. To add an indicator, you can replace startTransition with useTransition which gives you a boolean isPending value. In the example below, it’s used to change the website header styling while a Transition is happening:\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, useState, useTransition } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n  const [isPending, startTransition] = useTransition();\n\n  function navigate(url) {\n    startTransition(() => {\n      setPage(url);\n    });\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout isPending={isPending}>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\nResetting Suspense boundaries on navigation \n\nDuring a Transition, React will avoid hiding already revealed content. However, if you navigate to a route with different parameters, you might want to tell React it is different content. You can express this with a key:\n\n<ProfilePage key={queryParams.id} />\n\nImagine you’re navigating within a user’s profile page, and something suspends. If that update is wrapped in a Transition, it will not trigger the fallback for already visible content. That’s the expected behavior.\n\nHowever, now imagine you’re navigating between two different user profiles. In that case, it makes sense to show the fallback. For example, one user’s timeline is different content from another user’s timeline. By specifying a key, you ensure that React treats different users’ profiles as different components, and resets the Suspense boundaries during navigation. Suspense-integrated routers should do this automatically.\n\nProviding a fallback for server errors and client-only content \n\nIf you use one of the streaming server rendering APIs (or a framework that relies on them), React will also use your <Suspense> boundaries to handle errors on the server. If a component throws an error on the server, React will not abort the server render. Instead, it will find the closest <Suspense> component above it and include its fallback (such as a spinner) into the generated server HTML. The user will see a spinner at first.\n\nOn the client, React will attempt to render the same component again. If it errors on the client too, React will throw the error and display the closest Error Boundary. However, if it does not error on the client, React will not display the error to the user since the content was eventually displayed successfully.\n\nYou can use this to opt out some components from rendering on the server. To do this, throw an error in the server environment and then wrap them in a <Suspense> boundary to replace their HTML with fallbacks:\n\n<Suspense fallback={<Loading />}>\n\n  <Chat />\n\n</Suspense>\n\n\n\nfunction Chat() {\n\n  if (typeof window === 'undefined') {\n\n    throw Error('Chat should only render on the client.');\n\n  }\n\n  // ...\n\n}\n\nThe server HTML will include the loading indicator. It will be replaced by the Chat component on the client.\n\nTroubleshooting \nHow do I prevent the UI from being replaced by a fallback during an update? \n\nReplacing visible UI with a fallback creates a jarring user experience. This can happen when an update causes a component to suspend, and the nearest Suspense boundary is already showing content to the user.\n\nTo prevent this from happening, mark the update as non-urgent using startTransition. During a Transition, React will wait until enough data has loaded to prevent an unwanted fallback from appearing:\n\nfunction handleNextPageClick() {\n\n  // If this update suspends, don't hide the already displayed content\n\n  startTransition(() => {\n\n    setCurrentPage(currentPage + 1);\n\n  });\n\n}\n\nThis will avoid hiding existing content. However, any newly rendered Suspense boundaries will still immediately display fallbacks to avoid blocking the UI and let the user see the content as it becomes available.\n\nReact will only prevent unwanted fallbacks during non-urgent updates. It will not delay a render if it’s the result of an urgent update. You must opt in with an API like startTransition or useDeferredValue.\n\nIf your router is integrated with Suspense, it should wrap its updates into startTransition automatically.\n\nPREVIOUS\n<StrictMode>\nNEXT\n<Activity>"
  },
  {
    "title": "<Activity> – React",
    "url": "https://react.dev/reference/react/Activity",
    "html": "API REFERENCE\nCOMPONENTS\n<Activity>\n\n<Activity> lets you hide and restore the UI and internal state of its children.\n\n<Activity mode={visibility}>\n\n  <Sidebar />\n\n</Activity>\nReference\n<Activity>\nUsage\nRestoring the state of hidden components\nRestoring the DOM of hidden components\nPre-rendering content that’s likely to become visible\nSpeeding up interactions during page load\nTroubleshooting\nMy hidden components have unwanted side effects\nMy hidden components have Effects that aren’t running\nReference \n<Activity> \n\nYou can use Activity to hide part of your application:\n\n<Activity mode={isShowingSidebar ? \"visible\" : \"hidden\"}>\n\n  <Sidebar />\n\n</Activity>\n\nWhen an Activity boundary is hidden, React will visually hide its children using the display: \"none\" CSS property. It will also destroy their Effects, cleaning up any active subscriptions.\n\nWhile hidden, children still re-render in response to new props, albeit at a lower priority than the rest of the content.\n\nWhen the boundary becomes visible again, React will reveal the children with their previous state restored, and re-create their Effects.\n\nIn this way, Activity can be thought of as a mechanism for rendering “background activity”. Rather than completely discarding content that’s likely to become visible again, you can use Activity to maintain and restore that content’s UI and internal state, while ensuring that your hidden content has no unwanted side effects.\n\nSee more examples below.\n\nProps \nchildren: The UI you intend to show and hide.\nmode: A string value of either 'visible' or 'hidden'. If omitted, defaults to 'visible'.\nCaveats \nIf an Activity is rendered inside of a ViewTransition, and it becomes visible as a result of an update caused by startTransition, it will activate the ViewTransition’s enter animation. If it becomes hidden, it will activate its exit animation.\nAn Activity that just renders text will not render anything rather than rendering hidden text, because there’s no corresponding DOM element to apply visibility changes to. For example, <Activity mode=\"hidden\"><ComponentThatJustReturnsText /></Activity> will not produce any output in the DOM for const ComponentThatJustReturnsText = () => \"Hello, World!\".\nUsage \nRestoring the state of hidden components \n\nIn React, when you want to conditionally show or hide a component, you typically mount or unmount it based on that condition:\n\n{isShowingSidebar && (\n\n  <Sidebar />\n\n)}\n\nBut unmounting a component destroys its internal state, which is not always what you want.\n\nWhen you hide a component using an Activity boundary instead, React will “save” its state for later:\n\n<Activity mode={isShowingSidebar ? \"visible\" : \"hidden\"}>\n\n  <Sidebar />\n\n</Activity>\n\nThis makes it possible to hide and then later restore components in the state they were previously in.\n\nThe following example has a sidebar with an expandable section. You can press “Overview” to reveal the three subitems below it. The main app area also has a button that hides and shows the sidebar.\n\nTry expanding the Overview section, and then toggling the sidebar closed then open:\n\nApp.js\nSidebar.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport Sidebar from './Sidebar.js';\n\nexport default function App() {\n  const [isShowingSidebar, setIsShowingSidebar] = useState(true);\n\n  return (\n    <>\n      {isShowingSidebar && (\n        <Sidebar />\n      )}\n\n      <main>\n        <button onClick={() => setIsShowingSidebar(!isShowingSidebar)}>\n          Toggle sidebar\n        </button>\n        <h1>Main content</h1>\n      </main>\n    </>\n  );\n}\n\n\nShow more\n\nThe Overview section always starts out collapsed. Because we unmount the sidebar when isShowingSidebar flips to false, all its internal state is lost.\n\nThis is a perfect use case for Activity. We can preserve the internal state of our sidebar, even when visually hiding it.\n\nLet’s replace the conditional rendering of our sidebar with an Activity boundary:\n\n// Before\n\n{isShowingSidebar && (\n\n  <Sidebar />\n\n)}\n\n\n\n// After\n\n<Activity mode={isShowingSidebar ? 'visible' : 'hidden'}>\n\n  <Sidebar />\n\n</Activity>\n\nand check out the new behavior:\n\nApp.js\nSidebar.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\n\nimport Sidebar from './Sidebar.js';\n\nexport default function App() {\n  const [isShowingSidebar, setIsShowingSidebar] = useState(true);\n\n  return (\n    <>\n      <Activity mode={isShowingSidebar ? 'visible' : 'hidden'}>\n        <Sidebar />\n      </Activity>\n\n      <main>\n        <button onClick={() => setIsShowingSidebar(!isShowingSidebar)}>\n          Toggle sidebar\n        </button>\n        <h1>Main content</h1>\n      </main>\n    </>\n  );\n}\n\n\nShow more\n\nOur sidebar’s internal state is now restored, without any changes to its implementation.\n\nRestoring the DOM of hidden components \n\nSince Activity boundaries hide their children using display: none, their children’s DOM is also preserved when hidden. This makes them great for maintaining ephemeral state in parts of the UI that the user is likely to interact with again.\n\nIn this example, the Contact tab has a <textarea> where the user can enter a message. If you enter some text, change to the Home tab, then change back to the Contact tab, the draft message is lost:\n\nApp.js\nTabButton.js\nHome.js\nContact.js\nReload\nClear\nFork\nexport default function Contact() {\n  return (\n    <div>\n      <p>Send me a message!</p>\n\n      <textarea />\n\n      <p>You can find me online here:</p>\n      <ul>\n        <li>admin@mysite.com</li>\n        <li>+123456789</li>\n      </ul>\n    </div>\n  );\n}\n\n\n\nThis is because we’re fully unmounting Contact in App. When the Contact tab unmounts, the <textarea> element’s internal DOM state is lost.\n\nIf we switch to using an Activity boundary to show and hide the active tab, we can preserve the state of each tab’s DOM. Try entering text and switching tabs again, and you’ll see the draft message is no longer reset:\n\nApp.js\nTabButton.js\nHome.js\nContact.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Contact from './Contact.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('contact');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'contact'}\n        onClick={() => setActiveTab('contact')}\n      >\n        Contact\n      </TabButton>\n\n      <hr />\n\n      <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n        <Home />\n      </Activity>\n      <Activity mode={activeTab === 'contact' ? 'visible' : 'hidden'}>\n        <Contact />\n      </Activity>\n    </>\n  );\n}\n\n\nShow more\n\nAgain, the Activity boundary let us preserve the Contact tab’s internal state without changing its implementation.\n\nPre-rendering content that’s likely to become visible \n\nSo far, we’ve seen how Activity can hide some content that the user has interacted with, without discarding that content’s ephemeral state.\n\nBut Activity boundaries can also be used to prepare content that the user has yet to see for the first time:\n\n<Activity mode=\"hidden\">\n\n  <SlowComponent />\n\n</Activity>\n\nWhen an Activity boundary is hidden during its initial render, its children won’t be visible on the page — but they will still be rendered, albeit at a lower priority than the visible content, and without mounting their Effects.\n\nThis pre-rendering allows the children to load any code or data they need ahead of time, so that later, when the Activity boundary becomes visible, the children can appear faster with reduced loading times.\n\nLet’s look at an example.\n\nIn this demo, the Posts tab loads some data. If you press it, you’ll see a Suspense fallback displayed while the data is being fetched:\n\nApp.js\nHome.js\nPosts.js\nReload\nClear\nFork\nimport { useState, Suspense } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Posts from './Posts.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('home');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'posts'}\n        onClick={() => setActiveTab('posts')}\n      >\n        Posts\n      </TabButton>\n\n      <hr />\n\n      <Suspense fallback={<h1>🌀 Loading...</h1>}>\n        {activeTab === 'home' && <Home />}\n        {activeTab === 'posts' && <Posts />}\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nThis is because App doesn’t mount Posts until its tab is active.\n\nIf we update App to use an Activity boundary to show and hide the active tab, Posts will be pre-rendered when the app first loads, allowing it to fetch its data before it becomes visible.\n\nTry clicking the Posts tab now:\n\nApp.js\nHome.js\nPosts.js\nReload\nClear\nFork\nimport { Activity, useState, Suspense } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Posts from './Posts.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('home');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'posts'}\n        onClick={() => setActiveTab('posts')}\n      >\n        Posts\n      </TabButton>\n\n      <hr />\n\n      <Suspense fallback={<h1>🌀 Loading...</h1>}>\n        <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n          <Home />\n        </Activity>\n        <Activity mode={activeTab === 'posts' ? 'visible' : 'hidden'}>\n          <Posts />\n        </Activity>\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nPosts was able to prepare itself for a faster render, thanks to the hidden Activity boundary.\n\nPre-rendering components with hidden Activity boundaries is a powerful way to reduce loading times for parts of the UI that the user is likely to interact with next.\n\nNote\n\nOnly Suspense-enabled data sources will be fetched during pre-rendering. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a cached Promise with use\n\nActivity does not detect data that is fetched inside an Effect.\n\nThe exact way you would load data in the Posts component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nSpeeding up interactions during page load \n\nReact includes an under-the-hood performance optimization called Selective Hydration. It works by hydrating your app’s initial HTML in chunks, enabling some components to become interactive even if other components on the page haven’t loaded their code or data yet.\n\nSuspense boundaries participate in Selective Hydration, because they naturally divide your component tree into units that are independent from one another:\n\nfunction Page() {\n\n  return (\n\n    <>\n\n      <MessageComposer />\n\n\n\n      <Suspense fallback=\"Loading chats...\">\n\n        <Chats />\n\n      </Suspense>\n\n    </>\n\n  )\n\n}\n\nHere, MessageComposer can be fully hydrated during the initial render of the page, even before Chats is mounted and starts to fetch its data.\n\nSo by breaking up your component tree into discrete units, Suspense allows React to hydrate your app’s server-rendered HTML in chunks, enabling parts of your app to become interactive as fast as possible.\n\nBut what about pages that don’t use Suspense?\n\nTake this tabs example:\n\nfunction Page() {\n\n  const [activeTab, setActiveTab] = useState('home');\n\n\n\n  return (\n\n    <>\n\n      <TabButton onClick={() => setActiveTab('home')}>\n\n        Home\n\n      </TabButton>\n\n      <TabButton onClick={() => setActiveTab('video')}>\n\n        Video\n\n      </TabButton>\n\n\n\n      {activeTab === 'home' && (\n\n        <Home />\n\n      )}\n\n      {activeTab === 'video' && (\n\n        <Video />\n\n      )}\n\n    </>\n\n  )\n\n}\n\nHere, React must hydrate the entire page all at once. If Home or Video are slower to render, they could make the tab buttons feel unresponsive during hydration.\n\nAdding Suspense around the active tab would solve this:\n\nfunction Page() {\n\n  const [activeTab, setActiveTab] = useState('home');\n\n\n\n  return (\n\n    <>\n\n      <TabButton onClick={() => setActiveTab('home')}>\n\n        Home\n\n      </TabButton>\n\n      <TabButton onClick={() => setActiveTab('video')}>\n\n        Video\n\n      </TabButton>\n\n\n\n      <Suspense fallback={<Placeholder />}>\n\n        {activeTab === 'home' && (\n\n          <Home />\n\n        )}\n\n        {activeTab === 'video' && (\n\n          <Video />\n\n        )}\n\n      </Suspense>\n\n    </>\n\n  )\n\n}\n\n…but it would also change the UI, since the Placeholder fallback would be displayed on the initial render.\n\nInstead, we can use Activity. Since Activity boundaries show and hide their children, they already naturally divide the component tree into independent units. And just like Suspense, this feature allows them to participate in Selective Hydration.\n\nLet’s update our example to use Activity boundaries around the active tab:\n\nfunction Page() {\n\n  const [activeTab, setActiveTab] = useState('home');\n\n\n\n  return (\n\n    <>\n\n      <TabButton onClick={() => setActiveTab('home')}>\n\n        Home\n\n      </TabButton>\n\n      <TabButton onClick={() => setActiveTab('video')}>\n\n        Video\n\n      </TabButton>\n\n\n\n      <Activity mode={activeTab === \"home\" ? \"visible\" : \"hidden\"}>\n\n        <Home />\n\n      </Activity>\n\n      <Activity mode={activeTab === \"video\" ? \"visible\" : \"hidden\"}>\n\n        <Video />\n\n      </Activity>\n\n    </>\n\n  )\n\n}\n\nNow our initial server-rendered HTML looks the same as it did in the original version, but thanks to Activity, React can hydrate the tab buttons first, before it even mounts Home or Video.\n\nThus, in addition to hiding and showing content, Activity boundaries help improve your app’s performance during hydration by letting React know which parts of your page can become interactive in isolation.\n\nAnd even if your page doesn’t ever hide part of its content, you can still add always-visible Activity boundaries to improve hydration performance:\n\nfunction Page() {\n\n  return (\n\n    <>\n\n      <Post />\n\n\n\n      <Activity>\n\n        <Comments />\n\n      </Activity>\n\n    </>\n\n  );\n\n}\nTroubleshooting \nMy hidden components have unwanted side effects \n\nAn Activity boundary hides its content by setting display: none on its children and cleaning up any of their Effects. So, most well-behaved React components that properly clean up their side effects will already be robust to being hidden by Activity.\n\nBut there are some situations where a hidden component behaves differently than an unmounted one. Most notably, since a hidden component’s DOM is not destroyed, any side effects from that DOM will persist, even after the component is hidden.\n\nAs an example, consider a <video> tag. Typically it doesn’t require any cleanup, because even if you’re playing a video, unmounting the tag stops the video and audio from playing in the browser. Try playing the video and then pressing Home in this demo:\n\nApp.js\nHome.js\nVideo.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Video from './Video.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('video');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'video'}\n        onClick={() => setActiveTab('video')}\n      >\n        Video\n      </TabButton>\n\n      <hr />\n\n      {activeTab === 'home' && <Home />}\n      {activeTab === 'video' && <Video />}\n    </>\n  );\n}\n\n\nShow more\n\nThe video stops playing as expected.\n\nNow, let’s say we wanted to preserve the timecode where the user last watched, so that when they tab back to the video, it doesn’t start over from the beginning again.\n\nThis is a great use case for Activity!\n\nLet’s update App to hide the inactive tab with a hidden Activity boundary instead of unmounting it, and see how the demo behaves this time:\n\nApp.js\nHome.js\nVideo.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Video from './Video.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('video');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'video'}\n        onClick={() => setActiveTab('video')}\n      >\n        Video\n      </TabButton>\n\n      <hr />\n\n      <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n        <Home />\n      </Activity>\n      <Activity mode={activeTab === 'video' ? 'visible' : 'hidden'}>\n        <Video />\n      </Activity>\n    </>\n  );\n}\n\n\nShow more\n\nWhoops! The video and audio continue to play even after it’s been hidden, because the tab’s <video> element is still in the DOM.\n\nTo fix this, we can add an Effect with a cleanup function that pauses the video:\n\nexport default function VideoTab() {\n\n  const ref = useRef();\n\n\n\n  useLayoutEffect(() => {\n\n    const videoRef = ref.current;\n\n\n\n    return () => {\n\n      videoRef.pause()\n\n    }\n\n  }, []);\n\n\n\n  return (\n\n    <video\n\n      ref={ref}\n\n      controls\n\n      playsInline\n\n      src=\"...\"\n\n    />\n\n\n\n  );\n\n}\n\nWe call useLayoutEffect instead of useEffect because conceptually the clean-up code is tied to the component’s UI being visually hidden. If we used a regular effect, the code could be delayed by (say) a re-suspending Suspense boundary or a View Transition.\n\nLet’s see the new behavior. Try playing the video, switching to the Home tab, then back to the Video tab:\n\nApp.js\nHome.js\nVideo.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Video from './Video.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('video');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'video'}\n        onClick={() => setActiveTab('video')}\n      >\n        Video\n      </TabButton>\n\n      <hr />\n\n      <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n        <Home />\n      </Activity>\n      <Activity mode={activeTab === 'video' ? 'visible' : 'hidden'}>\n        <Video />\n      </Activity>\n    </>\n  );\n}\n\n\nShow more\n\nIt works great! Our cleanup function ensures that the video stops playing if it’s ever hidden by an Activity boundary, and even better, because the <video> tag is never destroyed, the timecode is preserved, and the video itself doesn’t need to be initialized or downloaded again when the user switches back to keep watching it.\n\nThis is a great example of using Activity to preserve ephemeral DOM state for parts of the UI that become hidden, but the user is likely to interact with again soon.\n\nOur example illustrates that for certain tags like <video>, unmounting and hiding have different behavior. If a component renders DOM that has a side effect, and you want to prevent that side effect when an Activity boundary hides it, add an Effect with a return function to clean it up.\n\nThe most common cases of this will be from the following tags:\n\n<video>\n<audio>\n<iframe>\n\nTypically, though, most of your React components should already be robust to being hidden by an Activity boundary. And conceptually, you should think of “hidden” Activities as being unmounted.\n\nTo eagerly discover other Effects that don’t have proper cleanup, which is important not only for Activity boundaries but for many other behaviors in React, we recommend using <StrictMode>.\n\nMy hidden components have Effects that aren’t running \n\nWhen an <Activity> is “hidden”, all its children’s Effects are cleaned up. Conceptually, the children are unmounted, but React saves their state for later. This is a feature of Activity because it means subscriptions won’t be active for hidden parts of the UI, reducing the amount of work needed for hidden content.\n\nIf you’re relying on an Effect mounting to clean up a component’s side effects, refactor the Effect to do the work in the returned cleanup function instead.\n\nTo eagerly find problematic Effects, we recommend adding <StrictMode> which will eagerly perform Activity unmounts and mounts to catch any unexpected side-effects.\n\nPREVIOUS\n<Suspense>\nNEXT\n<ViewTransition>"
  },
  {
    "title": "<ViewTransition> – React",
    "url": "https://react.dev/reference/react/ViewTransition",
    "html": "API REFERENCE\nCOMPONENTS\n<ViewTransition>\nCanary\n\nThe <ViewTransition /> API is currently only available in React’s Canary and Experimental channels.\n\nLearn more about React’s release channels here.\n\n<ViewTransition> lets you animate elements that update inside a Transition.\n\nimport {ViewTransition} from 'react';\n\n\n\n<ViewTransition>\n\n  <div>...</div>\n\n</ViewTransition>\nReference\n<ViewTransition>\nView Transition Class\nStyling View Transitions\nUsage\nAnimating an element on enter/exit\nAnimating a shared element\nAnimating reorder of items in a list\nAnimating from Suspense content\nOpting-out of an animation\nCustomizing animations\nCustomizing animations with types\nBuilding View Transition enabled routers\nTroubleshooting\nMy <ViewTransition> is not activating\nI’m getting an error “There are two <ViewTransition name=%s> components with the same name mounted at the same time.”\nReference \n<ViewTransition> \n\nWrap elements in <ViewTransition> to animate them when they update inside a Transition. React uses the following heuristics to determine if a View Transition activates for an animation:\n\nenter: If a ViewTransition itself gets inserted in this Transition, then this will activate.\nexit: If a ViewTransition itself gets deleted in this Transition, then this will activate.\nupdate: If a ViewTransition has any DOM mutations inside it that React is doing (such as a prop changing) or if the ViewTransition boundary itself changes size or position due to an immediate sibling. If there are nested ViewTransition then the mutation applies to them and not the parent.\nshare: If a named ViewTransition is inside a deleted subtree and another named ViewTransition with the same name is part of an inserted subtree in the same Transition, they form a Shared Element Transition, and it animates from the deleted one to the inserted one.\n\nBy default, <ViewTransition> animates with a smooth cross-fade (the browser default view transition). You can customize the animation by providing a View Transition Class to the <ViewTransition> component. You can  customize animations for each kind of trigger (see Styling View Transitions).\n\nDEEP DIVE\nHow does <ViewTransition> work? \nShow Details\nProps \n\nBy default, <ViewTransition> animates with a smooth cross-fade. You can customize the animation, or specify a shared element transition, with these props:\n\noptional enter: A string or object. The View Transition Class to apply when enter is activated.\noptional exit: A string or object. The View Transition Class to apply when exit is activated.\noptional update: A string or object. The View Transition Class to apply when an update is activated.\noptional share: A string or object. The View Transition Class to apply when a shared element is activated.\noptional default: A string or object. The View Transition Class used when no other matching activation prop is found.\noptional name: A string or object. The name of the View Transition used for shared element transitions. If not provided, React will use a unique name for each View Transition to prevent unexpected animations.\nCallback \n\nThese callbacks allow you to adjust the animation imperatively using the animate APIs:\n\noptional onEnter: A function. React calls onEnter after an “enter” animation.\noptional onExit: A function. React calls onExit after an “exit” animation.\noptional onShare: A function. React calls onShare after a “share” animation.\noptional onUpdate: A function. React calls onUpdate after an “update” animation.\n\nEach callback receives as arguments:\n\nelement: The DOM element that was animated.\ntypes: The Transition Types included in the animation.\nView Transition Class \n\nThe View Transition Class is the CSS class name(s) applied by React during the transition when the ViewTransition activates. It can be a string or an object.\n\nstring: the class added on the child elements when activated. If 'none' is provided, no class will be added.\nobject: the class added on the child elements will be the key matching View Transition type added with addTransitionType. The object can also specify a default to use if no matching type is found.\n\nThe value 'none' can be used to prevent a View Transition from activating for a specific trigger.\n\nStyling View Transitions \nNote\n\nIn many early examples of View Transitions around the web, you’ll have seen using a view-transition-name and then style it using ::view-transition-...(my-name) selectors. We don’t recommend that for styling. Instead, we normally recommend using a View Transition Class instead.\n\nTo customize the animation for a <ViewTransition> you can provide a View Transition Class to one of the activation props. The View Transition Class is a CSS class name that React applies to the child elements when the ViewTransition activates.\n\nFor example, to customize an “enter” animation, provide a class name to the enter prop:\n\n<ViewTransition enter=\"slide-in\">\n\nWhen the <ViewTransition> activates an “enter” animation, React will add the class name slide-in. Then you can refer to this class using view transition pseudo selectors to build reusable animations:\n\n::view-transition-group(.slide-in) {\n\n  \n\n}\n\n::view-transition-old(.slide-in) {\n\n\n\n}\n\n::view-transition-new(.slide-in) {\n\n\n\n}\n\nIn the future, CSS libraries may add built-in animations using View Transition Classes to make this easier to use.\n\nCaveats \nBy default, setState updates immediately and does not activate <ViewTransition>, only updates wrapped in a Transition. You can also use <Suspense> to opt-in to a Transition to reveal content.\n<ViewTransition> creates an image that can be moved around, scaled and cross-faded. Unlike Layout Animations you may have seen in React Native or Motion, this means that not every individual Element inside of it animates its position. This can lead to better performance and a more continuous feeling, smooth animation compared to animating every individual piece. However, it can also lose continuity in things that should be moving by themselves. So you might have to add more <ViewTransition> boundaries manually as a result.\nMany users may prefer not having animations on the page. React doesn’t automatically disable animations for this case. We recommend that using the @media (prefers-reduced-motion) media query to disable animations or tone them down based on user preference. In the future, CSS libraries may have this built-in to their presets.\nCurrently, <ViewTransition> only works in the DOM. We’re working on adding support for React Native and other platforms.\nUsage \nAnimating an element on enter/exit \n\nEnter/Exit Transitions trigger when a <ViewTransition> is added or removed by a component in a transition:\n\nfunction Child() {\n\n  return (\n\n    <ViewTransition>\n\n      <div>Hi</div>\n\n    </ViewTransition>\n\n  );\n\n}\n\n\n\nfunction Parent() {\n\n  const [show, setShow] = useState();\n\n  if (show) {\n\n    return <Child />;\n\n  }\n\n  return null;\n\n}\n\nWhen setShow is called, show switches to true and the Child component is rendered. When setShow is called inside startTransition, and Child renders a ViewTransition before any other DOM nodes, an enter animation is triggered.\n\nWhen show switches back to false, an exit animation is triggered.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from 'react';\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition>\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\n<ViewTransition> only activates if it is placed before any DOM node. If Child instead looked like this, no animation would trigger:\n\nfunction Component() {\n\n  return <ViewTransition>Hi</ViewTransition>;\n\n}\nAnimating a shared element \n\nNormally, we don’t recommend assigning a name to a <ViewTransition> and instead let React assign it an automatic name. The reason you might want to assign a name is to animate between completely different components when one tree unmounts and another tree mounts at the same time. To preserve continuity.\n\n<ViewTransition name={UNIQUE_NAME}>\n\n  <Child />\n\n</ViewTransition>\n\nWhen one tree unmounts and another mounts, if there’s a pair where the same name exists in the unmounting tree and the mounting tree, they trigger the “share” animation on both. It animates from the unmounting side to the mounting side.\n\nUnlike an exit/enter animation this can be deeply inside the deleted/mounted tree. If a <ViewTransition> would also be eligible for exit/enter, then the “share” animation takes precedence.\n\nIf Transition first unmounts one side and then leads to a <Suspense> fallback being shown before eventually the new name being mounted, then no shared element transition happens.\n\nApp.js\nVideo.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from \"react\";\nimport {Video, Thumbnail, FullscreenVideo} from \"./Video\";\nimport videos from \"./data\";\n\nexport default function Component() {\n  const [fullscreen, setFullscreen] = useState(false);\n  if (fullscreen) {\n    return <FullscreenVideo\n      video={videos[0]}\n      onExit={() => startTransition(() => setFullscreen(false))}\n    />\n  }\n  return <Video\n    video={videos[0]}\n    onClick={() => startTransition(() => setFullscreen(true))}\n  />\n}\n\n\nShow more\nNote\n\nIf either the mounted or unmounted side of a pair is outside the viewport, then no pair is formed. This ensures that it doesn’t fly in or out of the viewport when something is scrolled. Instead it’s treated as a regular enter/exit by itself.\n\nThis does not happen if the same Component instance changes position, which triggers an “update”. Those animate regardless if one position is outside the viewport.\n\nThere’s currently a quirk where if a deeply nested unmounted <ViewTransition> is inside the viewport but the mounted side is not within the viewport, then the unmounted side animates as its own “exit” animation even if it’s deeply nested instead of as part of the parent animation.\n\nPitfall\n\nIt’s important that there’s only one thing with the same name mounted at a time in the entire app. Therefore it’s important to use unique namespaces for the name to avoid conflicts. To ensure you can do this you might want to add a constant in a separate module that you import.\n\nexport const MY_NAME = \"my-globally-unique-name\";\n\nimport {MY_NAME} from './shared-name';\n\n...\n\n<ViewTransition name={MY_NAME}>\nAnimating reorder of items in a list \nitems.map(item => <Component key={item.id} item={item} />)\n\nWhen reordering a list, without updating the content, the “update” animation triggers on each <ViewTransition> in the list if they’re outside a DOM node. Similar to enter/exit animations.\n\nThis means that this will trigger the animation on this <ViewTransition>:\n\nfunction Component() {\n\n  return <ViewTransition><div>...</div></ViewTransition>;\n\n}\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from \"react\";\nimport {Video} from \"./Video\";\nimport videos from \"./data\";\n\nexport default function Component() {\n  const [orderedVideos, setOrderedVideos] = useState(videos);\n  const reorder = () => {\n    startTransition(() => {\n      setOrderedVideos((prev) => {\n        return [...prev.sort(() => Math.random() - 0.5)];\n      });\n    });\n  };\n  return (\n    <>\n      <button onClick={reorder}>🎲</button>\n      <div className=\"listContainer\">\n        {orderedVideos.map((video, i) => {\n          return (\n            <ViewTransition key={video.title}>\n              <Video video={video} />\n            </ViewTransition>\n          );\n        })}\n      </div>\n    </>\n  );\n}\n\n\nShow more\n\nHowever, this wouldn’t animate each individual item:\n\nfunction Component() {\n\n  return <div><ViewTransition>...</ViewTransition></div>;\n\n}\n\nInstead, any parent <ViewTransition> would cross-fade. If there is no parent <ViewTransition> then there’s no animation in that case.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from \"react\";\nimport {Video} from \"./Video\";\nimport videos from \"./data\";\n\nexport default function Component() {\n  const [orderedVideos, setOrderedVideos] = useState(videos);\n  const reorder = () => {\n    startTransition(() => {\n      setOrderedVideos((prev) => {\n        return [...prev.sort(() => Math.random() - 0.5)];\n      });\n    });\n  };\n  return (\n    <>\n      <button onClick={reorder}>🎲</button>\n      <ViewTransition>\n        <div className=\"listContainer\">\n          {orderedVideos.map((video, i) => {\n            return <Video video={video} key={video.title} />;\n          })}\n        </div>\n      </ViewTransition>\n    </>\n  );\n}\n\n\nShow more\n\nThis means you might want to avoid wrapper elements in lists where you want to allow the Component to control its own reorder animation:\n\nitems.map(item => <div><Component key={item.id} item={item} /></div>)\n\nThe above rule also applies if one of the items updates to resize, which then causes the siblings to resize, it’ll also animate its sibling <ViewTransition> but only if they’re immediate siblings.\n\nThis means that during an update, which causes a lot of re-layout, it doesn’t individually animate every <ViewTransition> on the page. That would lead to a lot of noisy animations which distracts from the actual change. Therefore React is more conservative about when an individual animation triggers.\n\nPitfall\n\nIt’s important to properly use keys to preserve identity when reordering lists. It might seem like you could use “name”, shared element transitions, to animate reorders but that would not trigger if one side was outside the viewport. To animate a reorder you often want to show that it went to a position outside the viewport.\n\nAnimating from Suspense content \n\nJust like any Transition, React waits for data and new CSS (<link rel=\"stylesheet\" precedence=\"...\">) before running the animation. In addition to this, ViewTransitions also wait up to 500ms for new fonts to load before starting the animation to avoid them flickering in later. For the same reason, an image wrapped in ViewTransition will wait for the image to load.\n\nIf it’s inside a new Suspense boundary instance, then the fallback is shown first. After the Suspense boundary fully loads, it triggers the <ViewTransition> to animate the reveal to the content.\n\nCurrently, this only happens for client-side Transition. In the future, this will also animate Suspense boundary for streaming SSR when content from the server suspends during the initial load.\n\nThere are two ways to animate Suspense boundaries depending on where you place the <ViewTransition>:\n\nUpdate:\n\n<ViewTransition>\n\n  <Suspense fallback={<A />}>\n\n    <B />\n\n  </Suspense>\n\n</ViewTransition>\n\nIn this scenario when the content goes from A to B, it’ll be treated as an “update” and apply that class if appropriate. Both A and B will get the same view-transition-name and therefore they’re acting as a cross-fade by default.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition,\n  Suspense\n} from 'react';\nimport {Video, VideoPlaceholder} from \"./Video\";\nimport {useLazyVideoData} from \"./data\"\n\nfunction LazyVideo() {\n  const video = useLazyVideoData();\n  return (\n    <Video video={video}/>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n      {showItem ? (\n        <ViewTransition>\n          <Suspense fallback={<VideoPlaceholder />}>\n            <LazyVideo />\n          </Suspense>\n        </ViewTransition>\n      ) : null}\n    </>\n  );\n}\n\n\nShow more\n\nEnter/Exit:\n\n<Suspense fallback={<ViewTransition><A /></ViewTransition>}>\n\n  <ViewTransition><B /></ViewTransition>\n\n</Suspense>\n\nIn this scenario, these are two separate ViewTransition instances each with their own view-transition-name. This will be treated as an “exit” of the <A> and an “enter” of the <B>.\n\nYou can achieve different effects depending on where you choose to place the <ViewTransition> boundary.\n\nOpting-out of an animation \n\nSometimes you’re wrapping a large existing component, like a whole page, and you want to animate some updates, such as changing the theme. However, you don’t want it to opt-in all updates inside the whole page to cross-fade when they’re updating. Especially if you’re incrementally adding more animations.\n\nYou can use the class “none” to opt-out of an animation. By wrapping your children in a “none” you can disable animations for updates to them while the parent still triggers.\n\n<ViewTransition>\n\n  <div className={theme}>\n\n    <ViewTransition update=\"none\">\n\n      {children}\n\n    </ViewTransition>\n\n  </div>\n\n</ViewTransition>\n\nThis will only animate if the theme changes and not if only the children update. The children can still opt-in again with their own <ViewTransition> but at least it’s manual again.\n\nCustomizing animations \n\nBy default, <ViewTransition> includes the default cross-fade from the browser.\n\nTo customize animations, you can provide props to the <ViewTransition> component to specify which animations to use, based on how the <ViewTransition> activates.\n\nFor example, we can slow down the default cross fade animation:\n\n<ViewTransition default=\"slow-fade\">\n\n  <Video />\n\n</ViewTransition>\n\nAnd define slow-fade in CSS using view transition classes:\n\n::view-transition-old(.slow-fade) {\n\n    animation-duration: 500ms;\n\n}\n\n\n\n::view-transition-new(.slow-fade) {\n\n    animation-duration: 500ms;\n\n}\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from 'react';\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition default=\"slow-fade\">\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\n\nIn addition to setting the default, you can also provide configurations for enter, exit, update, and share animations.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from 'react';\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition enter=\"slide-in\" exit=\"slide-out\">\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\nCustomizing animations with types \n\nYou can use the addTransitionType API to add a class name to the child elements when a specific transition type is activated for a specific activation trigger. This allows you to customize the animation for each type of transition.\n\nFor example, to customize the animation for all forward and backward navigations:\n\n<ViewTransition default={{\n\n  'navigation-back': 'slide-right',\n\n  'navigation-forward': 'slide-left',\n\n }}>\n\n  <div>...</div>\n\n</ViewTransition>\n\n \n\n// in your router:\n\nstartTransition(() => {\n\n  addTransitionType('navigation-' + navigationType);\n\n});\n\nWhen the ViewTransition activates a “navigation-back” animation, React will add the class name “slide-right”. When the ViewTransition activates a “navigation-forward” animation, React will add the class name “slide-left”.\n\nIn the future, routers and other libraries may add support for standard view-transition types and styles.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  addTransitionType,\n  useState,\n  startTransition,\n} from \"react\";\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition enter={\n        {\n          \"add-video-back\": \"slide-in-back\",\n          \"add-video-forward\": \"slide-in-forward\"\n        }\n      }\n      exit={\n        {\n          \"remove-video-back\": \"slide-in-forward\",\n          \"remove-video-forward\": \"slide-in-back\"\n        }\n      }>\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <div className=\"button-container\">\n        <button\n          onClick={() => {\n            startTransition(() => {\n              if (showItem) {\n                addTransitionType(\"remove-video-back\")\n              } else {\n                addTransitionType(\"add-video-back\")\n              }\n              setShowItem((prev) => !prev);\n            });\n          }}\n        >⬅️</button>\n        <button\n          onClick={() => {\n            startTransition(() => {\n              if (showItem) {\n                addTransitionType(\"remove-video-forward\")\n              } else {\n                addTransitionType(\"add-video-forward\")\n              }\n              setShowItem((prev) => !prev);\n            });\n          }}\n        >➡️</button>\n      </div>\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\nBuilding View Transition enabled routers \n\nReact waits for any pending Navigation to finish to ensure that scroll restoration happens within the animation. If the Navigation is blocked on React, your router must unblock in useLayoutEffect since useEffect would lead to a deadlock.\n\nIf a startTransition is started from the legacy popstate event, such as during a “back”-navigation then it must finish synchronously to ensure scroll and form restoration works correctly. This is in conflict with running a View Transition animation. Therefore, React will skip animations from popstate. Therefore animations won’t run for the back button. You can fix this by upgrading your router to use the Navigation API.\n\nTroubleshooting \nMy <ViewTransition> is not activating \n\n<ViewTransition> only activates if it is placed before any DOM node:\n\nfunction Component() {\n\n  return (\n\n    <div>\n\n      <ViewTransition>Hi</ViewTransition>\n\n    </div>\n\n  );\n\n}\n\nTo fix, ensure that the <ViewTransition> comes before any other DOM nodes:\n\nfunction Component() {\n\n  return (\n\n    <ViewTransition>\n\n      <div>Hi</div>\n\n    </ViewTransition>\n\n  );\n\n}\nI’m getting an error “There are two <ViewTransition name=%s> components with the same name mounted at the same time.” \n\nThis error occurs when two <ViewTransition> components with the same name are mounted at the same time:\n\nfunction Item() {\n\n  // 🚩 All items will get the same \"name\".\n\n  return <ViewTransition name=\"item\">...</ViewTransition>;\n\n}\n\n\n\nfunction ItemList({items}) {\n\n  return (\n\n    <>\n\n      {item.map(item => <Item key={item.id} />)}\n\n    </>\n\n  );\n\n}\n\nThis will cause the View Transition to error. In development, React detects this issue to surface it and logs two errors:\n\nConsole\nThere are two <ViewTransition name=%s> components with the same name mounted at the same time. This is not supported and will cause View Transitions to error. Try to use a more unique name e.g. by using a namespace prefix and adding the id of an item to the name.\n    at Item\n    at ItemList\nThe existing <ViewTransition name=%s> duplicate has this stack trace.\n    at Item\n    at ItemList\n\nTo fix, ensure that there’s only one <ViewTransition> with the same name mounted at a time in the entire app by ensuring the name is unique, or adding an id to the name:\n\nfunction Item({id}) {\n\n  // ✅ All items will get the same \"name\".\n\n  return <ViewTransition name={`item-${id}`}>...</ViewTransition>;\n\n}\n\n\n\nfunction ItemList({items}) {\n\n  return (\n\n    <>\n\n      {item.map(item => <Item key={item.id} item={item} />)}\n\n    </>\n\n  );\n\n}\nPREVIOUS\n<Activity>\nNEXT\nAPIs"
  },
  {
    "title": "Built-in React APIs – React",
    "url": "https://react.dev/reference/react/apis",
    "html": "API REFERENCE\nBuilt-in React APIs\n\nIn addition to Hooks and Components, the react package exports a few other APIs that are useful for defining components. This page lists all the remaining modern React APIs.\n\ncreateContext lets you define and provide context to the child components. Used with useContext.\nlazy lets you defer loading a component’s code until it’s rendered for the first time.\nmemo lets your component skip re-renders with same props. Used with useMemo and useCallback.\nstartTransition lets you mark a state update as non-urgent. Similar to useTransition.\nact lets you wrap renders and interactions in tests to ensure updates have processed before making assertions.\nResource APIs \n\nResources can be accessed by a component without having them as part of their state. For example, a component can read a message from a Promise or read styling information from a context.\n\nTo read a value from a resource, use this API:\n\nuse lets you read the value of a resource like a Promise or context.\nfunction MessageComponent({ messagePromise }) {\n\n  const message = use(messagePromise);\n\n  const theme = use(ThemeContext);\n\n  // ...\n\n}\nPREVIOUS\n<ViewTransition>\nNEXT\nact"
  },
  {
    "title": "act – React",
    "url": "https://react.dev/reference/react/act",
    "html": "API REFERENCE\nAPIS\nact\n\nact is a test helper to apply pending React updates before making assertions.\n\nawait act(async actFn)\n\nTo prepare a component for assertions, wrap the code rendering it and performing updates inside an await act() call. This makes your test run closer to how React works in the browser.\n\nNote\n\nYou might find using act() directly a bit too verbose. To avoid some of the boilerplate, you could use a library like React Testing Library, whose helpers are wrapped with act().\n\nReference\nawait act(async actFn)\nUsage\nRendering components in tests\nDispatching events in tests\nTroubleshooting\nI’m getting an error: “The current testing environment is not configured to support act”(…)”\nReference \nawait act(async actFn) \n\nWhen writing UI tests, tasks like rendering, user events, or data fetching can be considered as “units” of interaction with a user interface. React provides a helper called act() that makes sure all updates related to these “units” have been processed and applied to the DOM before you make any assertions.\n\nThe name act comes from the Arrange-Act-Assert pattern.\n\nit ('renders with button disabled', async () => {\n\n  await act(async () => {\n\n    root.render(<TestComponent />)\n\n  });\n\n  expect(container.querySelector('button')).toBeDisabled();\n\n});\nNote\n\nWe recommend using act with await and an async function. Although the sync version works in many cases, it doesn’t work in all cases and due to the way React schedules updates internally, it’s difficult to predict when you can use the sync version.\n\nWe will deprecate and remove the sync version in the future.\n\nParameters \nasync actFn: An async function wrapping renders or interactions for components being tested. Any updates triggered within the actFn, are added to an internal act queue, which are then flushed together to process and apply any changes to the DOM. Since it is async, React will also run any code that crosses an async boundary, and flush any updates scheduled.\nReturns \n\nact does not return anything.\n\nUsage \n\nWhen testing a component, you can use act to make assertions about its output.\n\nFor example, let’s say we have this Counter component, the usage examples below show how to test it:\n\nfunction Counter() {\n\n  const [count, setCount] = useState(0);\n\n  const handleClick = () => {\n\n    setCount(prev => prev + 1);\n\n  }\n\n\n\n  useEffect(() => {\n\n    document.title = `You clicked ${count} times`;\n\n  }, [count]);\n\n\n\n  return (\n\n    <div>\n\n      <p>You clicked {count} times</p>\n\n      <button onClick={handleClick}>\n\n        Click me\n\n      </button>\n\n    </div>\n\n  )\n\n}\nRendering components in tests \n\nTo test the render output of a component, wrap the render inside act():\n\nimport {act} from 'react';\n\nimport ReactDOMClient from 'react-dom/client';\n\nimport Counter from './Counter';\n\n\n\nit('can render and update a counter', async () => {\n\n  container = document.createElement('div');\n\n  document.body.appendChild(container);\n\n  \n\n  // ✅ Render the component inside act().\n\n  await act(() => {\n\n    ReactDOMClient.createRoot(container).render(<Counter />);\n\n  });\n\n  \n\n  const button = container.querySelector('button');\n\n  const label = container.querySelector('p');\n\n  expect(label.textContent).toBe('You clicked 0 times');\n\n  expect(document.title).toBe('You clicked 0 times');\n\n});\n\nHere, we create a container, append it to the document, and render the Counter component inside act(). This ensures that the component is rendered and its effects are applied before making assertions.\n\nUsing act ensures that all updates have been applied before we make assertions.\n\nDispatching events in tests \n\nTo test events, wrap the event dispatch inside act():\n\nimport {act} from 'react';\n\nimport ReactDOMClient from 'react-dom/client';\n\nimport Counter from './Counter';\n\n\n\nit.only('can render and update a counter', async () => {\n\n  const container = document.createElement('div');\n\n  document.body.appendChild(container);\n\n  \n\n  await act( async () => {\n\n    ReactDOMClient.createRoot(container).render(<Counter />);\n\n  });\n\n  \n\n  // ✅ Dispatch the event inside act().\n\n  await act(async () => {\n\n    button.dispatchEvent(new MouseEvent('click', { bubbles: true }));\n\n  });\n\n\n\n  const button = container.querySelector('button');\n\n  const label = container.querySelector('p');\n\n  expect(label.textContent).toBe('You clicked 1 times');\n\n  expect(document.title).toBe('You clicked 1 times');\n\n});\n\nHere, we render the component with act, and then dispatch the event inside another act(). This ensures that all updates from the event are applied before making assertions.\n\nPitfall\n\nDon’t forget that dispatching DOM events only works when the DOM container is added to the document. You can use a library like React Testing Library to reduce the boilerplate code.\n\nTroubleshooting \nI’m getting an error: “The current testing environment is not configured to support act”(…)” \n\nUsing act requires setting global.IS_REACT_ACT_ENVIRONMENT=true in your test environment. This is to ensure that act is only used in the correct environment.\n\nIf you don’t set the global, you will see an error like this:\n\nConsole\nWarning: The current testing environment is not configured to support act(…)\n\nTo fix, add this to your global setup file for React tests:\n\nglobal.IS_REACT_ACT_ENVIRONMENT=true\nNote\n\nIn testing frameworks like React Testing Library, IS_REACT_ACT_ENVIRONMENT is already set for you.\n\nPREVIOUS\nAPIs\nNEXT\naddTransitionType"
  },
  {
    "title": "addTransitionType – React",
    "url": "https://react.dev/reference/react/addTransitionType",
    "html": "API REFERENCE\nAPIS\naddTransitionType\nCanary\n\nThe addTransitionType API is currently only available in React’s Canary and Experimental channels.\n\nLearn more about React’s release channels here.\n\naddTransitionType lets you specify the cause of a transition.\n\nstartTransition(() => {\n\n  addTransitionType('my-transition-type');\n\n  setState(newState);\n\n});\nReference\naddTransitionType\nUsage\nAdding the cause of a transition\nCustomize animations using browser view transition types\nCustomize animations using View Transition Class\nCustomize animations using ViewTransition events\nReference \naddTransitionType \nParameters \ntype: The type of transition to add. This can be any string.\nReturns \n\nstartTransition does not return anything.\n\nCaveats \nIf multiple transitions are combined, all Transition Types are collected. You can also add more than one type to a Transition.\nTransition Types are reset after each commit. This means a <Suspense> fallback will associate the types after a startTransition, but revealing the content does not.\nUsage \nAdding the cause of a transition \n\nCall addTransitionType inside of startTransition to indicate the cause of a transition:\n\nimport { startTransition, addTransitionType } from 'react';\n\n\n\nfunction Submit({action) {\n\n  function handleClick() {\n\n    startTransition(() => {\n\n      addTransitionType('submit-click');\n\n      action();\n\n    });\n\n  }\n\n\n\n  return <button onClick={handleClick}>Click me</button>;\n\n}\n\nWhen you call addTransitionType inside the scope of startTransition, React will associate submit-click as one of the causes for the Transition.\n\nCurrently, Transition Types can be used to customize different animations based on what caused the Transition. You have three different ways to choose from for how to use them:\n\nCustomize animations using browser view transition types\nCustomize animations using View Transition Class\nCustomize animations using ViewTransition events\n\nIn the future, we plan to support more use cases for using the cause of a transition.\n\nCustomize animations using browser view transition types \n\nWhen a ViewTransition activates from a transition, React adds all the Transition Types as browser view transition types to the element.\n\nThis allows you to customize different animations based on CSS scopes:\n\nfunction Component() {\n\n  return (\n\n    <ViewTransition>\n\n      <div>Hello</div>\n\n    </ViewTransition>\n\n  );\n\n}\n\n\n\nstartTransition(() => {\n\n  addTransitionType('my-transition-type');\n\n  setShow(true);\n\n});\n:root:active-view-transition-type(my-transition-type) {\n\n  &::view-transition-...(...) {\n\n    ...\n\n  }\n\n}\nCustomize animations using View Transition Class \n\nYou can customize animations for an activated ViewTransition based on type by passing an object to the View Transition Class:\n\nfunction Component() {\n\n  return (\n\n    <ViewTransition enter={{\n\n      'my-transition-type': 'my-transition-class',\n\n    }}>\n\n      <div>Hello</div>\n\n    </ViewTransition>\n\n  );\n\n}\n\n\n\n// ...\n\nstartTransition(() => {\n\n  addTransitionType('my-transition-type');\n\n  setState(newState);\n\n});\n\nIf multiple types match, then they’re joined together. If no types match then the special “default” entry is used instead. If any type has the value “none” then that wins and the ViewTransition is disabled (not assigned a name).\n\nThese can be combined with enter/exit/update/layout/share props to match based on kind of trigger and Transition Type.\n\n<ViewTransition enter={{\n\n  'navigation-back': 'enter-right',\n\n  'navigation-forward': 'enter-left',\n\n}}\n\nexit={{\n\n  'navigation-back': 'exit-right',\n\n  'navigation-forward': 'exit-left',\n\n}}>\nCustomize animations using ViewTransition events \n\nYou can imperatively customize animations for an activated ViewTransition based on type using View Transition events:\n\n<ViewTransition onUpdate={(inst, types) => {\n\n  if (types.includes('navigation-back')) {\n\n    ...\n\n  } else if (types.includes('navigation-forward')) {\n\n    ...\n\n  } else {\n\n    ...\n\n  }\n\n}}>\n\nThis allows you to pick different imperative Animations based on the cause.\n\nPREVIOUS\nact\nNEXT\ncache"
  },
  {
    "title": "cache – React",
    "url": "https://react.dev/reference/react/cache",
    "html": "API REFERENCE\nAPIS\ncache\nReact Server Components\n\ncache is only for use with React Server Components.\n\ncache lets you cache the result of a data fetch or computation.\n\nconst cachedFn = cache(fn);\nReference\ncache(fn)\nUsage\nCache an expensive computation\nShare a snapshot of data\nPreload data\nTroubleshooting\nMy memoized function still runs even though I’ve called it with the same arguments\nReference \ncache(fn) \n\nCall cache outside of any components to create a version of the function with caching.\n\nimport {cache} from 'react';\n\nimport calculateMetrics from 'lib/metrics';\n\n\n\nconst getMetrics = cache(calculateMetrics);\n\n\n\nfunction Chart({data}) {\n\n  const report = getMetrics(data);\n\n  // ...\n\n}\n\nWhen getMetrics is first called with data, getMetrics will call calculateMetrics(data) and store the result in cache. If getMetrics is called again with the same data, it will return the cached result instead of calling calculateMetrics(data) again.\n\nSee more examples below.\n\nParameters \nfn: The function you want to cache results for. fn can take any arguments and return any value.\nReturns \n\ncache returns a cached version of fn with the same type signature. It does not call fn in the process.\n\nWhen calling cachedFn with given arguments, it first checks if a cached result exists in the cache. If a cached result exists, it returns the result. If not, it calls fn with the arguments, stores the result in the cache, and returns the result. The only time fn is called is when there is a cache miss.\n\nNote\n\nThe optimization of caching return values based on inputs is known as memoization. We refer to the function returned from cache as a memoized function.\n\nCaveats \nReact will invalidate the cache for all memoized functions for each server request.\nEach call to cache creates a new function. This means that calling cache with the same function multiple times will return different memoized functions that do not share the same cache.\ncachedFn will also cache errors. If fn throws an error for certain arguments, it will be cached, and the same error is re-thrown when cachedFn is called with those same arguments.\ncache is for use in Server Components only.\nUsage \nCache an expensive computation \n\nUse cache to skip duplicate work.\n\nimport {cache} from 'react';\n\nimport calculateUserMetrics from 'lib/user';\n\n\n\nconst getUserMetrics = cache(calculateUserMetrics);\n\n\n\nfunction Profile({user}) {\n\n  const metrics = getUserMetrics(user);\n\n  // ...\n\n}\n\n\n\nfunction TeamReport({users}) {\n\n  for (let user in users) {\n\n    const metrics = getUserMetrics(user);\n\n    // ...\n\n  }\n\n  // ...\n\n}\n\nIf the same user object is rendered in both Profile and TeamReport, the two components can share work and only call calculateUserMetrics once for that user.\n\nAssume Profile is rendered first. It will call getUserMetrics, and check if there is a cached result. Since it is the first time getUserMetrics is called with that user, there will be a cache miss. getUserMetrics will then call calculateUserMetrics with that user and write the result to cache.\n\nWhen TeamReport renders its list of users and reaches the same user object, it will call getUserMetrics and read the result from cache.\n\nIf calculateUserMetrics can be aborted by passing an AbortSignal, you can use cacheSignal() to cancel the expensive computation if React has finished rendering. calculateUserMetrics may already handle cancellation internally by using cacheSignal directly.\n\nPitfall\nCalling different memoized functions will read from different caches. \n\nTo access the same cache, components must call the same memoized function.\n\n// Temperature.js\n\nimport {cache} from 'react';\n\nimport {calculateWeekReport} from './report';\n\n\n\nexport function Temperature({cityData}) {\n\n  // 🚩 Wrong: Calling `cache` in component creates new `getWeekReport` for each render\n\n  const getWeekReport = cache(calculateWeekReport);\n\n  const report = getWeekReport(cityData);\n\n  // ...\n\n}\n// Precipitation.js\n\nimport {cache} from 'react';\n\nimport {calculateWeekReport} from './report';\n\n\n\n// 🚩 Wrong: `getWeekReport` is only accessible for `Precipitation` component.\n\nconst getWeekReport = cache(calculateWeekReport);\n\n\n\nexport function Precipitation({cityData}) {\n\n  const report = getWeekReport(cityData);\n\n  // ...\n\n}\n\nIn the above example, Precipitation and Temperature each call cache to create a new memoized function with their own cache look-up. If both components render for the same cityData, they will do duplicate work to call calculateWeekReport.\n\nIn addition, Temperature creates a new memoized function each time the component is rendered which doesn’t allow for any cache sharing.\n\nTo maximize cache hits and reduce work, the two components should call the same memoized function to access the same cache. Instead, define the memoized function in a dedicated module that can be import-ed across components.\n\n// getWeekReport.js\n\nimport {cache} from 'react';\n\nimport {calculateWeekReport} from './report';\n\n\n\nexport default cache(calculateWeekReport);\n// Temperature.js\n\nimport getWeekReport from './getWeekReport';\n\n\n\nexport default function Temperature({cityData}) {\n\n\tconst report = getWeekReport(cityData);\n\n  // ...\n\n}\n// Precipitation.js\n\nimport getWeekReport from './getWeekReport';\n\n\n\nexport default function Precipitation({cityData}) {\n\n  const report = getWeekReport(cityData);\n\n  // ...\n\n}\n\nHere, both components call the same memoized function exported from ./getWeekReport.js to read and write to the same cache.\n\nShare a snapshot of data \n\nTo share a snapshot of data between components, call cache with a data-fetching function like fetch. When multiple components make the same data fetch, only one request is made and the data returned is cached and shared across components. All components refer to the same snapshot of data across the server render.\n\nimport {cache} from 'react';\n\nimport {fetchTemperature} from './api.js';\n\n\n\nconst getTemperature = cache(async (city) => {\n\n\treturn await fetchTemperature(city);\n\n});\n\n\n\nasync function AnimatedWeatherCard({city}) {\n\n\tconst temperature = await getTemperature(city);\n\n\t// ...\n\n}\n\n\n\nasync function MinimalWeatherCard({city}) {\n\n\tconst temperature = await getTemperature(city);\n\n\t// ...\n\n}\n\nIf AnimatedWeatherCard and MinimalWeatherCard both render for the same city, they will receive the same snapshot of data from the memoized function.\n\nIf AnimatedWeatherCard and MinimalWeatherCard supply different city arguments to getTemperature, then fetchTemperature will be called twice and each call site will receive different data.\n\nThe city acts as a cache key.\n\nNote\n\nAsynchronous rendering is only supported for Server Components.\n\nasync function AnimatedWeatherCard({city}) {\n\n\tconst temperature = await getTemperature(city);\n\n\t// ...\n\n}\n\nTo render components that use asynchronous data in Client Components, see use() documentation.\n\nPreload data \n\nBy caching a long-running data fetch, you can kick off asynchronous work prior to rendering the component.\n\nconst getUser = cache(async (id) => {\n\n  return await db.user.query(id);\n\n});\n\n\n\nasync function Profile({id}) {\n\n  const user = await getUser(id);\n\n  return (\n\n    <section>\n\n      <img src={user.profilePic} />\n\n      <h2>{user.name}</h2>\n\n    </section>\n\n  );\n\n}\n\n\n\nfunction Page({id}) {\n\n  // ✅ Good: start fetching the user data\n\n  getUser(id);\n\n  // ... some computational work\n\n  return (\n\n    <>\n\n      <Profile id={id} />\n\n    </>\n\n  );\n\n}\n\nWhen rendering Page, the component calls getUser but note that it doesn’t use the returned data. This early getUser call kicks off the asynchronous database query that occurs while Page is doing other computational work and rendering children.\n\nWhen rendering Profile, we call getUser again. If the initial getUser call has already returned and cached the user data, when Profile asks and waits for this data, it can simply read from the cache without requiring another remote procedure call. If the  initial data request hasn’t been completed, preloading data in this pattern reduces delay in data-fetching.\n\nDEEP DIVE\nCaching asynchronous work \nShow Details\nPitfall\nCalling a memoized function outside of a component will not use the cache. \nimport {cache} from 'react';\n\n\n\nconst getUser = cache(async (userId) => {\n\n  return await db.user.query(userId);\n\n});\n\n\n\n// 🚩 Wrong: Calling memoized function outside of component will not memoize.\n\ngetUser('demo-id');\n\n\n\nasync function DemoProfile() {\n\n  // ✅ Good: `getUser` will memoize.\n\n  const user = await getUser('demo-id');\n\n  return <Profile user={user} />;\n\n}\n\nReact only provides cache access to the memoized function in a component. When calling getUser outside of a component, it will still evaluate the function but not read or update the cache.\n\nThis is because cache access is provided through a context which is only accessible from a component.\n\nDEEP DIVE\nWhen should I use cache, memo, or useMemo? \nShow Details\nTroubleshooting \nMy memoized function still runs even though I’ve called it with the same arguments \n\nSee prior mentioned pitfalls\n\nCalling different memoized functions will read from different caches.\nCalling a memoized function outside of a component will not use the cache.\n\nIf none of the above apply, it may be a problem with how React checks if something exists in cache.\n\nIf your arguments are not primitives (ex. objects, functions, arrays), ensure you’re passing the same object reference.\n\nWhen calling a memoized function, React will look up the input arguments to see if a result is already cached. React will use shallow equality of the arguments to determine if there is a cache hit.\n\nimport {cache} from 'react';\n\n\n\nconst calculateNorm = cache((vector) => {\n\n  // ...\n\n});\n\n\n\nfunction MapMarker(props) {\n\n  // 🚩 Wrong: props is an object that changes every render.\n\n  const length = calculateNorm(props);\n\n  // ...\n\n}\n\n\n\nfunction App() {\n\n  return (\n\n    <>\n\n      <MapMarker x={10} y={10} z={10} />\n\n      <MapMarker x={10} y={10} z={10} />\n\n    </>\n\n  );\n\n}\n\nIn this case the two MapMarkers look like they’re doing the same work and calling calculateNorm with the same value of {x: 10, y: 10, z:10}. Even though the objects contain the same values, they are not the same object reference as each component creates its own props object.\n\nReact will call Object.is on the input to verify if there is a cache hit.\n\nimport {cache} from 'react';\n\n\n\nconst calculateNorm = cache((x, y, z) => {\n\n  // ...\n\n});\n\n\n\nfunction MapMarker(props) {\n\n  // ✅ Good: Pass primitives to memoized function\n\n  const length = calculateNorm(props.x, props.y, props.z);\n\n  // ...\n\n}\n\n\n\nfunction App() {\n\n  return (\n\n    <>\n\n      <MapMarker x={10} y={10} z={10} />\n\n      <MapMarker x={10} y={10} z={10} />\n\n    </>\n\n  );\n\n}\n\nOne way to address this could be to pass the vector dimensions to calculateNorm. This works because the dimensions themselves are primitives.\n\nAnother solution may be to pass the vector object itself as a prop to the component. We’ll need to pass the same object to both component instances.\n\nimport {cache} from 'react';\n\n\n\nconst calculateNorm = cache((vector) => {\n\n  // ...\n\n});\n\n\n\nfunction MapMarker(props) {\n\n  // ✅ Good: Pass the same `vector` object\n\n  const length = calculateNorm(props.vector);\n\n  // ...\n\n}\n\n\n\nfunction App() {\n\n  const vector = [10, 10, 10];\n\n  return (\n\n    <>\n\n      <MapMarker vector={vector} />\n\n      <MapMarker vector={vector} />\n\n    </>\n\n  );\n\n}\nPREVIOUS\naddTransitionType\nNEXT\ncacheSignal"
  },
  {
    "title": "cacheSignal – React",
    "url": "https://react.dev/reference/react/cacheSignal",
    "html": "API REFERENCE\nAPIS\ncacheSignal\nReact Server Components\n\ncacheSignal is currently only used with React Server Components.\n\ncacheSignal allows you to know when the cache() lifetime is over.\n\nconst signal = cacheSignal();\nReference\ncacheSignal\nUsage\nCancel in-flight requests\nIgnore errors after React has finished rendering\nReference \ncacheSignal \n\nCall cacheSignal to get an AbortSignal.\n\nimport {cacheSignal} from 'react';\n\nasync function Component() {\n\n  await fetch(url, { signal: cacheSignal() });\n\n}\n\nWhen React has finished rendering, the AbortSignal will be aborted. This allows you to cancel any in-flight work that is no longer needed.\nRendering is considered finished when:\n\nReact has successfully completed rendering\nthe render was aborted\nthe render has failed\nParameters \n\nThis function does not accept any parameters.\n\nReturns \n\ncacheSignal returns an AbortSignal if called during rendering. Otherwise cacheSignal() returns null.\n\nCaveats \ncacheSignal is currently for use in React Server Components only. In Client Components, it will always return null. In the future it will also be used for Client Component when a client cache refreshes or invalidates. You should not assume it’ll always be null on the client.\nIf called outside of rendering, cacheSignal will return null to make it clear that the current scope isn’t cached forever.\nUsage \nCancel in-flight requests \n\nCall cacheSignal to abort in-flight requests.\n\nimport {cache, cacheSignal} from 'react';\n\nconst dedupedFetch = cache(fetch);\n\nasync function Component() {\n\n  await dedupedFetch(url, { signal: cacheSignal() });\n\n}\nPitfall\n\nYou can’t use cacheSignal to abort async work that was started outside of rendering e.g.\n\nimport {cacheSignal} from 'react';\n\n// 🚩 Pitfall: The request will not actually be aborted if the rendering of `Component` is finished.\n\nconst response = fetch(url, { signal: cacheSignal() });\n\nasync function Component() {\n\n  await response;\n\n}\nIgnore errors after React has finished rendering \n\nIf a function throws, it may be due to cancellation (e.g. the Database connection has been closed). You can use the aborted property to check if the error was due to cancellation or a real error. You may want to ignore errors that were due to cancellation.\n\nimport {cacheSignal} from \"react\";\n\nimport {queryDatabase, logError} from \"./database\";\n\n\n\nasync function getData(id) {\n\n  try {\n\n     return await queryDatabase(id);\n\n  } catch (x) {\n\n     if (!cacheSignal()?.aborted) {\n\n        // only log if it's a real error and not due to cancellation\n\n       logError(x);\n\n     }\n\n     return null;\n\n  }\n\n}\n\n\n\nasync function Component({id}) {\n\n  const data = await getData(id);\n\n  if (data === null) {\n\n    return <div>No data available</div>;\n\n  }\n\n  return <div>{data.name}</div>;\n\n}\nPREVIOUS\ncache\nNEXT\ncaptureOwnerStack"
  },
  {
    "title": "captureOwnerStack – React",
    "url": "https://react.dev/reference/react/captureOwnerStack",
    "html": "API REFERENCE\nAPIS\ncaptureOwnerStack\n\ncaptureOwnerStack reads the current Owner Stack in development and returns it as a string if available.\n\nconst stack = captureOwnerStack();\nReference\ncaptureOwnerStack()\nUsage\nEnhance a custom error overlay\nTroubleshooting\nThe Owner Stack is null\ncaptureOwnerStack is not available\nReference \ncaptureOwnerStack() \n\nCall captureOwnerStack to get the current Owner Stack.\n\nimport * as React from 'react';\n\n\n\nfunction Component() {\n\n  if (process.env.NODE_ENV !== 'production') {\n\n    const ownerStack = React.captureOwnerStack();\n\n    console.log(ownerStack);\n\n  }\n\n}\nParameters \n\ncaptureOwnerStack does not take any parameters.\n\nReturns \n\ncaptureOwnerStack returns string | null.\n\nOwner Stacks are available in\n\nComponent render\nEffects (e.g. useEffect)\nReact’s event handlers (e.g. <button onClick={...} />)\nReact error handlers (React Root options onCaughtError, onRecoverableError, and onUncaughtError)\n\nIf no Owner Stack is available, null is returned (see Troubleshooting: The Owner Stack is null).\n\nCaveats \nOwner Stacks are only available in development. captureOwnerStack will always return null outside of development.\nDEEP DIVE\nOwner Stack vs Component Stack \nShow Details\nUsage \nEnhance a custom error overlay \nimport { captureOwnerStack } from \"react\";\n\nimport { instrumentedConsoleError } from \"./errorOverlay\";\n\n\n\nconst originalConsoleError = console.error;\n\nconsole.error = function patchedConsoleError(...args) {\n\n  originalConsoleError.apply(console, args);\n\n  const ownerStack = captureOwnerStack();\n\n  onConsoleError({\n\n    // Keep in mind that in a real application, console.error can be\n\n    // called with multiple arguments which you should account for.\n\n    consoleMessage: args[0],\n\n    ownerStack,\n\n  });\n\n};\n\nIf you intercept console.error calls to highlight them in an error overlay, you can call captureOwnerStack to include the Owner Stack.\n\nindex.js\nerrorOverlay.js\nApp.js\nReload\nClear\nFork\nimport { captureOwnerStack } from \"react\";\nimport { createRoot } from \"react-dom/client\";\nimport App from './App';\nimport { onConsoleError } from \"./errorOverlay\";\nimport './styles.css';\n\nconst originalConsoleError = console.error;\nconsole.error = function patchedConsoleError(...args) {\n  originalConsoleError.apply(console, args);\n  const ownerStack = captureOwnerStack();\n  onConsoleError({\n    // Keep in mind that in a real application, console.error can be\n    // called with multiple arguments which you should account for.\n    consoleMessage: args[0],\n    ownerStack,\n  });\n};\n\nconst container = document.getElementById(\"root\");\ncreateRoot(container).render(<App />);\n\n\nShow more\nTroubleshooting \nThe Owner Stack is null \n\nThe call of captureOwnerStack happened outside of a React controlled function e.g. in a setTimeout callback, after a fetch call or in a custom DOM event handler. During render, Effects, React event handlers, and React error handlers (e.g. hydrateRoot#options.onCaughtError) Owner Stacks should be available.\n\nIn the example below, clicking the button will log an empty Owner Stack because captureOwnerStack was called during a custom DOM event handler. The Owner Stack must be captured earlier e.g. by moving the call of captureOwnerStack into the Effect body.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport {captureOwnerStack, useEffect} from 'react';\n\nexport default function App() {\n  useEffect(() => {\n    // Should call `captureOwnerStack` here.\n    function handleEvent() {\n      // Calling it in a custom DOM event handler is too late.\n      // The Owner Stack will be `null` at this point.\n      console.log('Owner Stack: ', captureOwnerStack());\n    }\n\n    document.addEventListener('click', handleEvent);\n\n    return () => {\n      document.removeEventListener('click', handleEvent);\n    }\n  })\n\n  return <button>Click me to see that Owner Stacks are not available in custom DOM event handlers</button>;\n}\n\n\nShow more\ncaptureOwnerStack is not available \n\ncaptureOwnerStack is only exported in development builds. It will be undefined in production builds. If captureOwnerStack is used in files that are bundled for production and development, you should conditionally access it from a namespace import.\n\n// Don't use named imports of `captureOwnerStack` in files that are bundled for development and production.\n\nimport {captureOwnerStack} from 'react';\n\n// Use a namespace import instead and access `captureOwnerStack` conditionally.\n\nimport * as React from 'react';\n\n\n\nif (process.env.NODE_ENV !== 'production') {\n\n  const ownerStack = React.captureOwnerStack();\n\n  console.log('Owner Stack', ownerStack);\n\n}\nPREVIOUS\ncacheSignal\nNEXT\ncreateContext"
  },
  {
    "title": "createContext – React",
    "url": "https://react.dev/reference/react/createContext",
    "html": "API REFERENCE\nAPIS\ncreateContext\n\ncreateContext lets you create a context that components can provide or read.\n\nconst SomeContext = createContext(defaultValue)\nReference\ncreateContext(defaultValue)\nSomeContext Provider\nSomeContext.Consumer\nUsage\nCreating context\nImporting and exporting context from a file\nTroubleshooting\nI can’t find a way to change the context value\nReference \ncreateContext(defaultValue) \n\nCall createContext outside of any components to create a context.\n\nimport { createContext } from 'react';\n\n\n\nconst ThemeContext = createContext('light');\n\nSee more examples below.\n\nParameters \ndefaultValue: The value that you want the context to have when there is no matching context provider in the tree above the component that reads context. If you don’t have any meaningful default value, specify null. The default value is meant as a “last resort” fallback. It is static and never changes over time.\nReturns \n\ncreateContext returns a context object.\n\nThe context object itself does not hold any information. It represents which context other components read or provide. Typically, you will use SomeContext in components above to specify the context value, and call useContext(SomeContext) in components below to read it. The context object has a few properties:\n\nSomeContext lets you provide the context value to components.\nSomeContext.Consumer is an alternative and rarely used way to read the context value.\nSomeContext.Provider is a legacy way to provide the context value before React 19.\nSomeContext Provider \n\nWrap your components into a context provider to specify the value of this context for all components inside:\n\nfunction App() {\n\n  const [theme, setTheme] = useState('light');\n\n  // ...\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <Page />\n\n    </ThemeContext>\n\n  );\n\n}\nNote\n\nStarting in React 19, you can render <SomeContext> as a provider.\n\nIn older versions of React, use <SomeContext.Provider>.\n\nProps \nvalue: The value that you want to pass to all the components reading this context inside this provider, no matter how deep. The context value can be of any type. A component calling useContext(SomeContext) inside of the provider receives the value of the innermost corresponding context provider above it.\nSomeContext.Consumer \n\nBefore useContext existed, there was an older way to read context:\n\nfunction Button() {\n\n  // 🟡 Legacy way (not recommended)\n\n  return (\n\n    <ThemeContext.Consumer>\n\n      {theme => (\n\n        <button className={theme} />\n\n      )}\n\n    </ThemeContext.Consumer>\n\n  );\n\n}\n\nAlthough this older way still works, newly written code should read context with useContext() instead:\n\nfunction Button() {\n\n  // ✅ Recommended way\n\n  const theme = useContext(ThemeContext);\n\n  return <button className={theme} />;\n\n}\nProps \nchildren: A function. React will call the function you pass with the current context value determined by the same algorithm as useContext() does, and render the result you return from this function. React will also re-run this function and update the UI whenever the context from the parent components changes.\nUsage \nCreating context \n\nContext lets components pass information deep down without explicitly passing props.\n\nCall createContext outside any components to create one or more contexts.\n\nimport { createContext } from 'react';\n\n\n\nconst ThemeContext = createContext('light');\n\nconst AuthContext = createContext(null);\n\ncreateContext returns a context object. Components can read context by passing it to useContext():\n\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\n}\n\n\n\nfunction Profile() {\n\n  const currentUser = useContext(AuthContext);\n\n  // ...\n\n}\n\nBy default, the values they receive will be the default values you have specified when creating the contexts. However, by itself this isn’t useful because the default values never change.\n\nContext is useful because you can provide other, dynamic values from your components:\n\nfunction App() {\n\n  const [theme, setTheme] = useState('dark');\n\n  const [currentUser, setCurrentUser] = useState({ name: 'Taylor' });\n\n\n\n  // ...\n\n\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <AuthContext value={currentUser}>\n\n        <Page />\n\n      </AuthContext>\n\n    </ThemeContext>\n\n  );\n\n}\n\nNow the Page component and any components inside it, no matter how deep, will “see” the passed context values. If the passed context values change, React will re-render the components reading the context as well.\n\nRead more about reading and providing context and see examples.\n\nImporting and exporting context from a file \n\nOften, components in different files will need access to the same context. This is why it’s common to declare contexts in a separate file. Then you can use the export statement to make context available for other files:\n\n// Contexts.js\n\nimport { createContext } from 'react';\n\n\n\nexport const ThemeContext = createContext('light');\n\nexport const AuthContext = createContext(null);\n\nComponents declared in other files can then use the import statement to read or provide this context:\n\n// Button.js\n\nimport { ThemeContext } from './Contexts.js';\n\n\n\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\n}\n// App.js\n\nimport { ThemeContext, AuthContext } from './Contexts.js';\n\n\n\nfunction App() {\n\n  // ...\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <AuthContext value={currentUser}>\n\n        <Page />\n\n      </AuthContext>\n\n    </ThemeContext>\n\n  );\n\n}\n\nThis works similar to importing and exporting components.\n\nTroubleshooting \nI can’t find a way to change the context value \n\nCode like this specifies the default context value:\n\nconst ThemeContext = createContext('light');\n\nThis value never changes. React only uses this value as a fallback if it can’t find a matching provider above.\n\nTo make context change over time, add state and wrap components in a context provider.\n\nPREVIOUS\ncaptureOwnerStack\nNEXT\nlazy"
  },
  {
    "title": "lazy – React",
    "url": "https://react.dev/reference/react/lazy",
    "html": "API REFERENCE\nAPIS\nlazy\n\nlazy lets you defer loading component’s code until it is rendered for the first time.\n\nconst SomeComponent = lazy(load)\nReference\nlazy(load)\nload function\nUsage\nLazy-loading components with Suspense\nTroubleshooting\nMy lazy component’s state gets reset unexpectedly\nReference \nlazy(load) \n\nCall lazy outside your components to declare a lazy-loaded React component:\n\nimport { lazy } from 'react';\n\n\n\nconst MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\nSee more examples below.\n\nParameters \nload: A function that returns a Promise or another thenable (a Promise-like object with a then method). React will not call load until the first time you attempt to render the returned component. After React first calls load, it will wait for it to resolve, and then render the resolved value’s .default as a React component. Both the returned Promise and the Promise’s resolved value will be cached, so React will not call load more than once. If the Promise rejects, React will throw the rejection reason for the nearest Error Boundary to handle.\nReturns \n\nlazy returns a React component you can render in your tree. While the code for the lazy component is still loading, attempting to render it will suspend. Use <Suspense> to display a loading indicator while it’s loading.\n\nload function \nParameters \n\nload receives no parameters.\n\nReturns \n\nYou need to return a Promise or some other thenable (a Promise-like object with a then method). It needs to eventually resolve to an object whose .default property is a valid React component type, such as a function, memo, or a forwardRef component.\n\nUsage \nLazy-loading components with Suspense \n\nUsually, you import components with the static import declaration:\n\nimport MarkdownPreview from './MarkdownPreview.js';\n\nTo defer loading this component’s code until it’s rendered for the first time, replace this import with:\n\nimport { lazy } from 'react';\n\n\n\nconst MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\nThis code relies on dynamic import(), which might require support from your bundler or framework. Using this pattern requires that the lazy component you’re importing was exported as the default export.\n\nNow that your component’s code loads on demand, you also need to specify what should be displayed while it is loading. You can do this by wrapping the lazy component or any of its parents into a <Suspense> boundary:\n\n<Suspense fallback={<Loading />}>\n\n  <h2>Preview</h2>\n\n  <MarkdownPreview />\n\n</Suspense>\n\nIn this example, the code for MarkdownPreview won’t be loaded until you attempt to render it. If MarkdownPreview hasn’t loaded yet, Loading will be shown in its place. Try ticking the checkbox:\n\nApp.js\nLoading.js\nMarkdownPreview.js\nReload\nClear\nFork\nimport { useState, Suspense, lazy } from 'react';\nimport Loading from './Loading.js';\n\nconst MarkdownPreview = lazy(() => delayForDemo(import('./MarkdownPreview.js')));\n\nexport default function MarkdownEditor() {\n  const [showPreview, setShowPreview] = useState(false);\n  const [markdown, setMarkdown] = useState('Hello, **world**!');\n  return (\n    <>\n      <textarea value={markdown} onChange={e => setMarkdown(e.target.value)} />\n      <label>\n        <input type=\"checkbox\" checked={showPreview} onChange={e => setShowPreview(e.target.checked)} />\n        Show preview\n      </label>\n      <hr />\n      {showPreview && (\n        <Suspense fallback={<Loading />}>\n          <h2>Preview</h2>\n          <MarkdownPreview markdown={markdown} />\n        </Suspense>\n      )}\n    </>\n  );\n}\n\n// Add a fixed delay so you can see the loading state\nfunction delayForDemo(promise) {\n  return new Promise(resolve => {\n    setTimeout(resolve, 2000);\n  }).then(() => promise);\n}\n\n\nShow more\n\nThis demo loads with an artificial delay. The next time you untick and tick the checkbox, Preview will be cached, so there will be no loading state. To see the loading state again, click “Reset” on the sandbox.\n\nLearn more about managing loading states with Suspense.\n\nTroubleshooting \nMy lazy component’s state gets reset unexpectedly \n\nDo not declare lazy components inside other components:\n\nimport { lazy } from 'react';\n\n\n\nfunction Editor() {\n\n  // 🔴 Bad: This will cause all state to be reset on re-renders\n\n  const MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\n  // ...\n\n}\n\nInstead, always declare them at the top level of your module:\n\nimport { lazy } from 'react';\n\n\n\n// ✅ Good: Declare lazy components outside of your components\n\nconst MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\n\n\nfunction Editor() {\n\n  // ...\n\n}\nPREVIOUS\ncreateContext\nNEXT\nmemo"
  },
  {
    "title": "memo – React",
    "url": "https://react.dev/reference/react/memo",
    "html": "API REFERENCE\nAPIS\nmemo\n\nmemo lets you skip re-rendering a component when its props are unchanged.\n\nconst MemoizedComponent = memo(SomeComponent, arePropsEqual?)\nNote\n\nReact Compiler automatically applies the equivalent of memo to all components, reducing the need for manual memoization. You can use the compiler to handle component memoization automatically.\n\nReference\nmemo(Component, arePropsEqual?)\nUsage\nSkipping re-rendering when props are unchanged\nUpdating a memoized component using state\nUpdating a memoized component using a context\nMinimizing props changes\nSpecifying a custom comparison function\nDo I still need React.memo if I use React Compiler?\nTroubleshooting\nMy component re-renders when a prop is an object, array, or function\nReference \nmemo(Component, arePropsEqual?) \n\nWrap a component in memo to get a memoized version of that component. This memoized version of your component will usually not be re-rendered when its parent component is re-rendered as long as its props have not changed. But React may still re-render it: memoization is a performance optimization, not a guarantee.\n\nimport { memo } from 'react';\n\n\n\nconst SomeComponent = memo(function SomeComponent(props) {\n\n  // ...\n\n});\n\nSee more examples below.\n\nParameters \n\nComponent: The component that you want to memoize. The memo does not modify this component, but returns a new, memoized component instead. Any valid React component, including functions and forwardRef components, is accepted.\n\noptional arePropsEqual: A function that accepts two arguments: the component’s previous props, and its new props. It should return true if the old and new props are equal: that is, if the component will render the same output and behave in the same way with the new props as with the old. Otherwise it should return false. Usually, you will not specify this function. By default, React will compare each prop with Object.is.\n\nReturns \n\nmemo returns a new React component. It behaves the same as the component provided to memo except that React will not always re-render it when its parent is being re-rendered unless its props have changed.\n\nUsage \nSkipping re-rendering when props are unchanged \n\nReact normally re-renders a component whenever its parent re-renders. With memo, you can create a component that React will not re-render when its parent re-renders so long as its new props are the same as the old props. Such a component is said to be memoized.\n\nTo memoize a component, wrap it in memo and use the value that it returns in place of your original component:\n\nconst Greeting = memo(function Greeting({ name }) {\n\n  return <h1>Hello, {name}!</h1>;\n\n});\n\n\n\nexport default Greeting;\n\nA React component should always have pure rendering logic. This means that it must return the same output if its props, state, and context haven’t changed. By using memo, you are telling React that your component complies with this requirement, so React doesn’t need to re-render as long as its props haven’t changed. Even with memo, your component will re-render if its own state changes or if a context that it’s using changes.\n\nIn this example, notice that the Greeting component re-renders whenever name is changed (because that’s one of its props), but not when address is changed (because it’s not passed to Greeting as a prop):\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { memo, useState } from 'react';\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n  return <h3>Hello{name && ', '}{name}!</h3>;\n});\n\n\nShow more\nNote\n\nYou should only rely on memo as a performance optimization. If your code doesn’t work without it, find the underlying problem and fix it first. Then you may add memo to improve performance.\n\nDEEP DIVE\nShould you add memo everywhere? \nShow Details\nUpdating a memoized component using state \n\nEven when a component is memoized, it will still re-render when its own state changes. Memoization only has to do with props that are passed to the component from its parent.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { memo, useState } from 'react';\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log('Greeting was rendered at', new Date().toLocaleTimeString());\n  const [greeting, setGreeting] = useState('Hello');\n  return (\n    <>\n      <h3>{greeting}{name && ', '}{name}!</h3>\n      <GreetingSelector value={greeting} onChange={setGreeting} />\n    </>\n  );\n});\n\nfunction GreetingSelector({ value, onChange }) {\n  return (\n    <>\n      <label>\n        <input\n          type=\"radio\"\n          checked={value === 'Hello'}\n          onChange={e => onChange('Hello')}\n        />\n        Regular greeting\n      </label>\n      <label>\n        <input\n          type=\"radio\"\n          checked={value === 'Hello and welcome'}\n          onChange={e => onChange('Hello and welcome')}\n        />\n        Enthusiastic greeting\n      </label>\n    </>\n  );\n}\n\n\nShow more\n\nIf you set a state variable to its current value, React will skip re-rendering your component even without memo. You may still see your component function being called an extra time, but the result will be discarded.\n\nUpdating a memoized component using a context \n\nEven when a component is memoized, it will still re-render when a context that it’s using changes. Memoization only has to do with props that are passed to the component from its parent.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, memo, useContext, useState } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  const [theme, setTheme] = useState('dark');\n\n  function handleClick() {\n    setTheme(theme === 'dark' ? 'light' : 'dark');\n  }\n\n  return (\n    <ThemeContext value={theme}>\n      <button onClick={handleClick}>\n        Switch theme\n      </button>\n      <Greeting name=\"Taylor\" />\n    </ThemeContext>\n  );\n}\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n  const theme = useContext(ThemeContext);\n  return (\n    <h3 className={theme}>Hello, {name}!</h3>\n  );\n});\n\n\nShow more\n\nTo make your component re-render only when a part of some context changes, split your component in two. Read what you need from the context in the outer component, and pass it down to a memoized child as a prop.\n\nMinimizing props changes \n\nWhen you use memo, your component re-renders whenever any prop is not shallowly equal to what it was previously. This means that React compares every prop in your component with its previous value using the Object.is comparison. Note that Object.is(3, 3) is true, but Object.is({}, {}) is false.\n\nTo get the most out of memo, minimize the times that the props change. For example, if the prop is an object, prevent the parent component from re-creating that object every time by using useMemo:\n\nfunction Page() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n\n\n  const person = useMemo(\n\n    () => ({ name, age }),\n\n    [name, age]\n\n  );\n\n\n\n  return <Profile person={person} />;\n\n}\n\n\n\nconst Profile = memo(function Profile({ person }) {\n\n  // ...\n\n});\n\nA better way to minimize props changes is to make sure the component accepts the minimum necessary information in its props. For example, it could accept individual values instead of a whole object:\n\nfunction Page() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n  return <Profile name={name} age={age} />;\n\n}\n\n\n\nconst Profile = memo(function Profile({ name, age }) {\n\n  // ...\n\n});\n\nEven individual values can sometimes be projected to ones that change less frequently. For example, here a component accepts a boolean indicating the presence of a value rather than the value itself:\n\nfunction GroupsLanding({ person }) {\n\n  const hasGroups = person.groups !== null;\n\n  return <CallToAction hasGroups={hasGroups} />;\n\n}\n\n\n\nconst CallToAction = memo(function CallToAction({ hasGroups }) {\n\n  // ...\n\n});\n\nWhen you need to pass a function to memoized component, either declare it outside your component so that it never changes, or useCallback to cache its definition between re-renders.\n\nSpecifying a custom comparison function \n\nIn rare cases it may be infeasible to minimize the props changes of a memoized component. In that case, you can provide a custom comparison function, which React will use to compare the old and new props instead of using shallow equality. This function is passed as a second argument to memo. It should return true only if the new props would result in the same output as the old props; otherwise it should return false.\n\nconst Chart = memo(function Chart({ dataPoints }) {\n\n  // ...\n\n}, arePropsEqual);\n\n\n\nfunction arePropsEqual(oldProps, newProps) {\n\n  return (\n\n    oldProps.dataPoints.length === newProps.dataPoints.length &&\n\n    oldProps.dataPoints.every((oldPoint, index) => {\n\n      const newPoint = newProps.dataPoints[index];\n\n      return oldPoint.x === newPoint.x && oldPoint.y === newPoint.y;\n\n    })\n\n  );\n\n}\n\nIf you do this, use the Performance panel in your browser developer tools to make sure that your comparison function is actually faster than re-rendering the component. You might be surprised.\n\nWhen you do performance measurements, make sure that React is running in the production mode.\n\nPitfall\n\nIf you provide a custom arePropsEqual implementation, you must compare every prop, including functions. Functions often close over the props and state of parent components. If you return true when oldProps.onClick !== newProps.onClick, your component will keep “seeing” the props and state from a previous render inside its onClick handler, leading to very confusing bugs.\n\nAvoid doing deep equality checks inside arePropsEqual unless you are 100% sure that the data structure you’re working with has a known limited depth. Deep equality checks can become incredibly slow and can freeze your app for many seconds if someone changes the data structure later.\n\nDo I still need React.memo if I use React Compiler? \n\nWhen you enable React Compiler, you typically don’t need React.memo anymore. The compiler automatically optimizes component re-rendering for you.\n\nHere’s how it works:\n\nWithout React Compiler, you need React.memo to prevent unnecessary re-renders:\n\n// Parent re-renders every second\n\nfunction Parent() {\n\n  const [seconds, setSeconds] = useState(0);\n\n\n\n  useEffect(() => {\n\n    const interval = setInterval(() => {\n\n      setSeconds(s => s + 1);\n\n    }, 1000);\n\n    return () => clearInterval(interval);\n\n  }, []);\n\n\n\n  return (\n\n    <>\n\n      <h1>Seconds: {seconds}</h1>\n\n      <ExpensiveChild name=\"John\" />\n\n    </>\n\n  );\n\n}\n\n\n\n// Without memo, this re-renders every second even though props don't change\n\nconst ExpensiveChild = memo(function ExpensiveChild({ name }) {\n\n  console.log('ExpensiveChild rendered');\n\n  return <div>Hello, {name}!</div>;\n\n});\n\nWith React Compiler enabled, the same optimization happens automatically:\n\n// No memo needed - compiler prevents re-renders automatically\n\nfunction ExpensiveChild({ name }) {\n\n  console.log('ExpensiveChild rendered');\n\n  return <div>Hello, {name}!</div>;\n\n}\n\nHere’s the key part of what the React Compiler generates:\n\nfunction Parent() {\n\n  const $ = _c(7);\n\n  const [seconds, setSeconds] = useState(0);\n\n  // ... other code ...\n\n\n\n  let t3;\n\n  if ($[4] === Symbol.for(\"react.memo_cache_sentinel\")) {\n\n    t3 = <ExpensiveChild name=\"John\" />;\n\n    $[4] = t3;\n\n  } else {\n\n    t3 = $[4];\n\n  }\n\n  // ... return statement ...\n\n}\n\nNotice the highlighted lines: The compiler wraps <ExpensiveChild name=\"John\" /> in a cache check. Since the name prop is always \"John\", this JSX is created once and reused on every parent re-render. This is exactly what React.memo does - it prevents the child from re-rendering when its props haven’t changed.\n\nThe React Compiler automatically:\n\nTracks that the name prop passed to ExpensiveChild hasn’t changed\nReuses the previously created JSX for <ExpensiveChild name=\"John\" />\nSkips re-rendering ExpensiveChild entirely\n\nThis means you can safely remove React.memo from your components when using React Compiler. The compiler provides the same optimization automatically, making your code cleaner and easier to maintain.\n\nNote\n\nThe compiler’s optimization is actually more comprehensive than React.memo. It also memoizes intermediate values and expensive computations within your components, similar to combining React.memo with useMemo throughout your component tree.\n\nTroubleshooting \nMy component re-renders when a prop is an object, array, or function \n\nReact compares old and new props by shallow equality: that is, it considers whether each new prop is reference-equal to the old prop. If you create a new object or array each time the parent is re-rendered, even if the individual elements are each the same, React will still consider it to be changed. Similarly, if you create a new function when rendering the parent component, React will consider it to have changed even if the function has the same definition. To avoid this, simplify props or memoize props in the parent component.\n\nPREVIOUS\nlazy\nNEXT\nstartTransition"
  },
  {
    "title": "startTransition – React",
    "url": "https://react.dev/reference/react/startTransition",
    "html": "API REFERENCE\nAPIS\nstartTransition\n\nstartTransition lets you render a part of the UI in the background.\n\nstartTransition(action)\nReference\nstartTransition(action)\nUsage\nMarking a state update as a non-blocking Transition\nReference \nstartTransition(action) \n\nThe startTransition function lets you mark a state update as a Transition.\n\nimport { startTransition } from 'react';\n\n\n\nfunction TabContainer() {\n\n  const [tab, setTab] = useState('about');\n\n\n\n  function selectTab(nextTab) {\n\n    startTransition(() => {\n\n      setTab(nextTab);\n\n    });\n\n  }\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \naction: A function that updates some state by calling one or more set functions. React calls action immediately with no parameters and marks all state updates scheduled synchronously during the action function call as Transitions. Any async calls awaited in the action will be included in the transition, but currently require wrapping any set functions after the await in an additional startTransition (see Troubleshooting). State updates marked as Transitions will be non-blocking and will not display unwanted loading indicators..\nReturns \n\nstartTransition does not return anything.\n\nCaveats \n\nstartTransition does not provide a way to track whether a Transition is pending. To show a pending indicator while the Transition is ongoing, you need useTransition instead.\n\nYou can wrap an update into a Transition only if you have access to the set function of that state. If you want to start a Transition in response to some prop or a custom Hook return value, try useDeferredValue instead.\n\nThe function you pass to startTransition is called immediately, marking all state updates that happen while it executes as Transitions. If you try to perform state updates in a setTimeout, for example, they won’t be marked as Transitions.\n\nYou must wrap any state updates after any async requests in another startTransition to mark them as Transitions. This is a known limitation that we will fix in the future (see Troubleshooting).\n\nA state update marked as a Transition will be interrupted by other state updates. For example, if you update a chart component inside a Transition, but then start typing into an input while the chart is in the middle of a re-render, React will restart the rendering work on the chart component after handling the input state update.\n\nTransition updates can’t be used to control text inputs.\n\nIf there are multiple ongoing Transitions, React currently batches them together. This is a limitation that may be removed in a future release.\n\nUsage \nMarking a state update as a non-blocking Transition \n\nYou can mark a state update as a Transition by wrapping it in a startTransition call:\n\nimport { startTransition } from 'react';\n\n\n\nfunction TabContainer() {\n\n  const [tab, setTab] = useState('about');\n\n\n\n  function selectTab(nextTab) {\n\n    startTransition(() => {\n\n      setTab(nextTab);\n\n    });\n\n  }\n\n  // ...\n\n}\n\nTransitions let you keep the user interface updates responsive even on slow devices.\n\nWith a Transition, your UI stays responsive in the middle of a re-render. For example, if the user clicks a tab but then change their mind and click another tab, they can do that without waiting for the first re-render to finish.\n\nNote\n\nstartTransition is very similar to useTransition, except that it does not provide the isPending flag to track whether a Transition is ongoing. You can call startTransition when useTransition is not available. For example, startTransition works outside components, such as from a data library.\n\nLearn about Transitions and see examples on the useTransition page.\n\nPREVIOUS\nmemo\nNEXT\nuse"
  },
  {
    "title": "use – React",
    "url": "https://react.dev/reference/react/use",
    "html": "API REFERENCE\nAPIS\nuse\n\nuse is a React API that lets you read the value of a resource like a Promise or context.\n\nconst value = use(resource);\nReference\nuse(resource)\nUsage\nReading context with use\nStreaming data from the server to the client\nDealing with rejected Promises\nTroubleshooting\n“Suspense Exception: This is not a real error!”\nReference \nuse(resource) \n\nCall use in your component to read the value of a resource like a Promise or context.\n\nimport { use } from 'react';\n\n\n\nfunction MessageComponent({ messagePromise }) {\n\n  const message = use(messagePromise);\n\n  const theme = use(ThemeContext);\n\n  // ...\n\nUnlike React Hooks, use can be called within loops and conditional statements like if. Like React Hooks, the function that calls use must be a Component or Hook.\n\nWhen called with a Promise, the use API integrates with Suspense and Error Boundaries. The component calling use suspends while the Promise passed to use is pending. If the component that calls use is wrapped in a Suspense boundary, the fallback will be displayed.  Once the Promise is resolved, the Suspense fallback is replaced by the rendered components using the data returned by the use API. If the Promise passed to use is rejected, the fallback of the nearest Error Boundary will be displayed.\n\nSee more examples below.\n\nParameters \nresource: this is the source of the data you want to read a value from. A resource can be a Promise or a context.\nReturns \n\nThe use API returns the value that was read from the resource like the resolved value of a Promise or context.\n\nCaveats \nThe use API must be called inside a Component or a Hook.\nWhen fetching data in a Server Component, prefer async and await over use. async and await pick up rendering from the point where await was invoked, whereas use re-renders the component after the data is resolved.\nPrefer creating Promises in Server Components and passing them to Client Components over creating Promises in Client Components. Promises created in Client Components are recreated on every render. Promises passed from a Server Component to a Client Component are stable across re-renders. See this example.\nUsage \nReading context with use \n\nWhen a context is passed to use, it works similarly to useContext. While useContext must be called at the top level of your component, use can be called inside conditionals like if and loops like for. use is preferred over useContext because it is more flexible.\n\nimport { use } from 'react';\n\n\n\nfunction Button() {\n\n  const theme = use(ThemeContext);\n\n  // ...\n\nuse returns the context value for the context you passed. To determine the context value, React searches the component tree and finds the closest context provider above for that particular context.\n\nTo pass context to a Button, wrap it or one of its parent components into the corresponding context provider.\n\nfunction MyPage() {\n\n  return (\n\n    <ThemeContext value=\"dark\">\n\n      <Form />\n\n    </ThemeContext>\n\n  );\n\n}\n\n\n\nfunction Form() {\n\n  // ... renders buttons inside ...\n\n}\n\nIt doesn’t matter how many layers of components there are between the provider and the Button. When a Button anywhere inside of Form calls use(ThemeContext), it will receive \"dark\" as the value.\n\nUnlike useContext, use can be called in conditionals and loops like if.\n\nfunction HorizontalRule({ show }) {\n\n  if (show) {\n\n    const theme = use(ThemeContext);\n\n    return <hr className={theme} />;\n\n  }\n\n  return false;\n\n}\n\nuse is called from inside a if statement, allowing you to conditionally read values from a Context.\n\nPitfall\n\nLike useContext, use(context) always looks for the closest context provider above the component that calls it. It searches upwards and does not consider context providers in the component from which you’re calling use(context).\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, use } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button show={true}>Sign up</Button>\n      <Button show={false}>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = use(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ show, children }) {\n  if (show) {\n    const theme = use(ThemeContext);\n    const className = 'button-' + theme;\n    return (\n      <button className={className}>\n        {children}\n      </button>\n    );\n  }\n  return false\n}\n\n\nShow more\nStreaming data from the server to the client \n\nData can be streamed from the server to the client by passing a Promise as a prop from a Server Component to a Client Component.\n\nimport { fetchMessage } from './lib.js';\n\nimport { Message } from './message.js';\n\n\n\nexport default function App() {\n\n  const messagePromise = fetchMessage();\n\n  return (\n\n    <Suspense fallback={<p>waiting for message...</p>}>\n\n      <Message messagePromise={messagePromise} />\n\n    </Suspense>\n\n  );\n\n}\n\nThe Client Component then takes the Promise it received as a prop and passes it to the use API. This allows the Client Component to read the value from the Promise that was initially created by the Server Component.\n\n// message.js\n\n'use client';\n\n\n\nimport { use } from 'react';\n\n\n\nexport function Message({ messagePromise }) {\n\n  const messageContent = use(messagePromise);\n\n  return <p>Here is the message: {messageContent}</p>;\n\n}\n\nBecause Message is wrapped in Suspense, the fallback will be displayed until the Promise is resolved. When the Promise is resolved, the value will be read by the use API and the Message component will replace the Suspense fallback.\n\nmessage.js\nReload\nClear\nFork\n\"use client\";\n\nimport { use, Suspense } from \"react\";\n\nfunction Message({ messagePromise }) {\n  const messageContent = use(messagePromise);\n  return <p>Here is the message: {messageContent}</p>;\n}\n\nexport function MessageContainer({ messagePromise }) {\n  return (\n    <Suspense fallback={<p>⌛Downloading message...</p>}>\n      <Message messagePromise={messagePromise} />\n    </Suspense>\n  );\n}\n\n\nShow more\nNote\n\nWhen passing a Promise from a Server Component to a Client Component, its resolved value must be serializable to pass between server and client. Data types like functions aren’t serializable and cannot be the resolved value of such a Promise.\n\nDEEP DIVE\nShould I resolve a Promise in a Server or Client Component? \nShow Details\nDealing with rejected Promises \n\nIn some cases a Promise passed to use could be rejected. You can handle rejected Promises by either:\n\nDisplaying an error to users with an Error Boundary.\nProviding an alternative value with Promise.catch\nPitfall\n\nuse cannot be called in a try-catch block. Instead of a try-catch block wrap your component in an Error Boundary, or provide an alternative value to use with the Promise’s .catch method.\n\nDisplaying an error to users with an Error Boundary \n\nIf you’d like to display an error to your users when a Promise is rejected, you can use an Error Boundary. To use an Error Boundary, wrap the component where you are calling the use API in an Error Boundary. If the Promise passed to use is rejected the fallback for the Error Boundary will be displayed.\n\nmessage.js\nReload\nClear\nFork\n\"use client\";\n\nimport { use, Suspense } from \"react\";\nimport { ErrorBoundary } from \"react-error-boundary\";\n\nexport function MessageContainer({ messagePromise }) {\n  return (\n    <ErrorBoundary fallback={<p>⚠️Something went wrong</p>}>\n      <Suspense fallback={<p>⌛Downloading message...</p>}>\n        <Message messagePromise={messagePromise} />\n      </Suspense>\n    </ErrorBoundary>\n  );\n}\n\nfunction Message({ messagePromise }) {\n  const content = use(messagePromise);\n  return <p>Here is the message: {content}</p>;\n}\n\n\nShow more\nProviding an alternative value with Promise.catch \n\nIf you’d like to provide an alternative value when the Promise passed to use is rejected you can use the Promise’s catch method.\n\nimport { Message } from './message.js';\n\n\n\nexport default function App() {\n\n  const messagePromise = new Promise((resolve, reject) => {\n\n    reject();\n\n  }).catch(() => {\n\n    return \"no new message found.\";\n\n  });\n\n\n\n  return (\n\n    <Suspense fallback={<p>waiting for message...</p>}>\n\n      <Message messagePromise={messagePromise} />\n\n    </Suspense>\n\n  );\n\n}\n\nTo use the Promise’s catch method, call catch on the Promise object. catch takes a single argument: a function that takes an error message as an argument. Whatever is returned by the function passed to catch will be used as the resolved value of the Promise.\n\nTroubleshooting \n“Suspense Exception: This is not a real error!” \n\nYou are either calling use outside of a React Component or Hook function, or calling use in a try–catch block. If you are calling use inside a try–catch block, wrap your component in an Error Boundary, or call the Promise’s catch to catch the error and resolve the Promise with another value. See these examples.\n\nIf you are calling use outside a React Component or Hook function, move the use call to a React Component or Hook function.\n\nfunction MessageComponent({messagePromise}) {\n\n  function download() {\n\n    // ❌ the function calling `use` is not a Component or Hook\n\n    const message = use(messagePromise);\n\n    // ...\n\nInstead, call use outside any component closures, where the function that calls use is a Component or Hook.\n\nfunction MessageComponent({messagePromise}) {\n\n  // ✅ `use` is being called from a component. \n\n  const message = use(messagePromise);\n\n  // ...\nPREVIOUS\nstartTransition\nNEXT\nexperimental_taintObjectReference"
  },
  {
    "title": "experimental_taintObjectReference – React",
    "url": "https://react.dev/reference/react/experimental_taintObjectReference",
    "html": "API REFERENCE\nAPIS\nexperimental_taintObjectReference\nExperimental Feature\n\nThis API is experimental and is not available in a stable version of React yet.\n\nYou can try it by upgrading React packages to the most recent experimental version:\n\nreact@experimental\nreact-dom@experimental\neslint-plugin-react-hooks@experimental\n\nExperimental versions of React may contain bugs. Don’t use them in production.\n\nThis API is only available inside React Server Components.\n\ntaintObjectReference lets you prevent a specific object instance from being passed to a Client Component like a user object.\n\nexperimental_taintObjectReference(message, object);\n\nTo prevent passing a key, hash or token, see taintUniqueValue.\n\nReference\ntaintObjectReference(message, object)\nUsage\nPrevent user data from unintentionally reaching the client\nReference \ntaintObjectReference(message, object) \n\nCall taintObjectReference with an object to register it with React as something that should not be allowed to be passed to the Client as is:\n\nimport {experimental_taintObjectReference} from 'react';\n\n\n\nexperimental_taintObjectReference(\n\n  'Do not pass ALL environment variables to the client.',\n\n  process.env\n\n);\n\nSee more examples below.\n\nParameters \n\nmessage: The message you want to display if the object gets passed to a Client Component. This message will be displayed as a part of the Error that will be thrown if the object gets passed to a Client Component.\n\nobject: The object to be tainted. Functions and class instances can be passed to taintObjectReference as object. Functions and classes are already blocked from being passed to Client Components but the React’s default error message will be replaced by what you defined in message. When a specific instance of a Typed Array is passed to taintObjectReference as object, any other copies of the Typed Array will not be tainted.\n\nReturns \n\nexperimental_taintObjectReference returns undefined.\n\nCaveats \nRecreating or cloning a tainted object creates a new untainted object which may contain sensitive data. For example, if you have a tainted user object, const userInfo = {name: user.name, ssn: user.ssn} or {...user} will create new objects which are not tainted. taintObjectReference only protects against simple mistakes when the object is passed through to a Client Component unchanged.\nPitfall\n\nDo not rely on just tainting for security. Tainting an object doesn’t prevent leaking of every possible derived value. For example, the clone of a tainted object will create a new untainted object. Using data from a tainted object (e.g. {secret: taintedObj.secret}) will create a new value or object that is not tainted. Tainting is a layer of protection; a secure app will have multiple layers of protection, well designed APIs, and isolation patterns.\n\nUsage \nPrevent user data from unintentionally reaching the client \n\nA Client Component should never accept objects that carry sensitive data. Ideally, the data fetching functions should not expose data that the current user should not have access to. Sometimes mistakes happen during refactoring. To protect against these mistakes happening down the line we can “taint” the user object in our data API.\n\nimport {experimental_taintObjectReference} from 'react';\n\n\n\nexport async function getUser(id) {\n\n  const user = await db`SELECT * FROM users WHERE id = ${id}`;\n\n  experimental_taintObjectReference(\n\n    'Do not pass the entire user object to the client. ' +\n\n      'Instead, pick off the specific properties you need for this use case.',\n\n    user,\n\n  );\n\n  return user;\n\n}\n\nNow whenever anyone tries to pass this object to a Client Component, an error will be thrown with the passed in error message instead.\n\nDEEP DIVE\nProtecting against leaks in data fetching \nShow Details\nPREVIOUS\nuse\nNEXT\nexperimental_taintUniqueValue"
  },
  {
    "title": "experimental_taintUniqueValue – React",
    "url": "https://react.dev/reference/react/experimental_taintUniqueValue",
    "html": "API REFERENCE\nAPIS\nexperimental_taintUniqueValue\nExperimental Feature\n\nThis API is experimental and is not available in a stable version of React yet.\n\nYou can try it by upgrading React packages to the most recent experimental version:\n\nreact@experimental\nreact-dom@experimental\neslint-plugin-react-hooks@experimental\n\nExperimental versions of React may contain bugs. Don’t use them in production.\n\nThis API is only available inside React Server Components.\n\ntaintUniqueValue lets you prevent unique values from being passed to Client Components like passwords, keys, or tokens.\n\ntaintUniqueValue(errMessage, lifetime, value)\n\nTo prevent passing an object containing sensitive data, see taintObjectReference.\n\nReference\ntaintUniqueValue(message, lifetime, value)\nUsage\nPrevent a token from being passed to Client Components\nReference \ntaintUniqueValue(message, lifetime, value) \n\nCall taintUniqueValue with a password, token, key or hash to register it with React as something that should not be allowed to be passed to the Client as is:\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nexperimental_taintUniqueValue(\n\n  'Do not pass secret keys to the client.',\n\n  process,\n\n  process.env.SECRET_KEY\n\n);\n\nSee more examples below.\n\nParameters \n\nmessage: The message you want to display if value is passed to a Client Component. This message will be displayed as a part of the Error that will be thrown if value is passed to a Client Component.\n\nlifetime: Any object that indicates how long value should be tainted. value will be blocked from being sent to any Client Component while this object still exists. For example, passing globalThis blocks the value for the lifetime of an app. lifetime is typically an object whose properties contains value.\n\nvalue: A string, bigint or TypedArray. value must be a unique sequence of characters or bytes with high entropy such as a cryptographic token, private key, hash, or a long password. value will be blocked from being sent to any Client Component.\n\nReturns \n\nexperimental_taintUniqueValue returns undefined.\n\nCaveats \nDeriving new values from tainted values can compromise tainting protection. New values created by uppercasing tainted values, concatenating tainted string values into a larger string, converting tainted values to base64, substringing tainted values, and other similar transformations are not tainted unless you explicitly call taintUniqueValue on these newly created values.\nDo not use taintUniqueValue to protect low-entropy values such as PIN codes or phone numbers. If any value in a request is controlled by an attacker, they could infer which value is tainted by enumerating all possible values of the secret.\nUsage \nPrevent a token from being passed to Client Components \n\nTo ensure that sensitive information such as passwords, session tokens, or other unique values do not inadvertently get passed to Client Components, the taintUniqueValue function provides a layer of protection. When a value is tainted, any attempt to pass it to a Client Component will result in an error.\n\nThe lifetime argument defines the duration for which the value remains tainted. For values that should remain tainted indefinitely, objects like globalThis or process can serve as the lifetime argument. These objects have a lifespan that spans the entire duration of your app’s execution.\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nexperimental_taintUniqueValue(\n\n  'Do not pass a user password to the client.',\n\n  globalThis,\n\n  process.env.SECRET_KEY\n\n);\n\nIf the tainted value’s lifespan is tied to a object, the lifetime should be the object that encapsulates the value. This ensures the tainted value remains protected for the lifetime of the encapsulating object.\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nexport async function getUser(id) {\n\n  const user = await db`SELECT * FROM users WHERE id = ${id}`;\n\n  experimental_taintUniqueValue(\n\n    'Do not pass a user session token to the client.',\n\n    user,\n\n    user.session.token\n\n  );\n\n  return user;\n\n}\n\nIn this example, the user object serves as the lifetime argument. If this object gets stored in a global cache or is accessible by another request, the session token remains tainted.\n\nPitfall\n\nDo not rely solely on tainting for security. Tainting a value doesn’t block every possible derived value. For example, creating a new value by upper casing a tainted string will not taint the new value.\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nconst password = 'correct horse battery staple';\n\n\n\nexperimental_taintUniqueValue(\n\n  'Do not pass the password to the client.',\n\n  globalThis,\n\n  password\n\n);\n\n\n\nconst uppercasePassword = password.toUpperCase() // `uppercasePassword` is not tainted\n\nIn this example, the constant password is tainted. Then password is used to create a new value uppercasePassword by calling the toUpperCase method on password. The newly created uppercasePassword is not tainted.\n\nOther similar ways of deriving new values from tainted values like concatenating it into a larger string, converting it to base64, or returning a substring create untained values.\n\nTainting only protects against simple mistakes like explicitly passing secret values to the client. Mistakes in calling the taintUniqueValue like using a global store outside of React, without the corresponding lifetime object, can cause the tainted value to become untainted. Tainting is a layer of protection; a secure app will have multiple layers of protection, well designed APIs, and isolation patterns.\n\nDEEP DIVE\nUsing server-only and taintUniqueValue to prevent leaking secrets \nShow Details\nPREVIOUS\nexperimental_taintObjectReference"
  },
  {
    "title": "Built-in React DOM Hooks – React",
    "url": "https://react.dev/reference/react-dom/hooks",
    "html": "API REFERENCE\nBuilt-in React DOM Hooks\n\nThe react-dom package contains Hooks that are only supported for web applications (which run in the browser DOM environment). These Hooks are not supported in non-browser environments like iOS, Android, or Windows applications. If you are looking for Hooks that are supported in web browsers and other environments see the React Hooks page. This page lists all the Hooks in the react-dom package.\n\nForm Hooks \n\nForms let you create interactive controls for submitting information.  To manage forms in your components, use one of these Hooks:\n\nuseFormStatus allows you to make updates to the UI based on the status of a form.\nfunction Form({ action }) {\n\n  async function increment(n) {\n\n    return n + 1;\n\n  }\n\n  const [count, incrementFormAction] = useActionState(increment, 0);\n\n  return (\n\n    <form action={action}>\n\n      <button formAction={incrementFormAction}>Count: {count}</button>\n\n      <Button />\n\n    </form>\n\n  );\n\n}\n\n\n\nfunction Button() {\n\n  const { pending } = useFormStatus();\n\n  return (\n\n    <button disabled={pending} type=\"submit\">\n\n      Submit\n\n    </button>\n\n  );\n\n}\nNEXT\nuseFormStatus"
  },
  {
    "title": "useFormStatus – React",
    "url": "https://react.dev/reference/react-dom/hooks/useFormStatus",
    "html": "API REFERENCE\nHOOKS\nuseFormStatus\n\nuseFormStatus is a Hook that gives you status information of the last form submission.\n\nconst { pending, data, method, action } = useFormStatus();\nReference\nuseFormStatus()\nUsage\nDisplay a pending state during form submission\nRead the form data being submitted\nTroubleshooting\nstatus.pending is never true\nReference \nuseFormStatus() \n\nThe useFormStatus Hook provides status information of the last form submission.\n\nimport { useFormStatus } from \"react-dom\";\n\nimport action from './actions';\n\n\n\nfunction Submit() {\n\n  const status = useFormStatus();\n\n  return <button disabled={status.pending}>Submit</button>\n\n}\n\n\n\nexport default function App() {\n\n  return (\n\n    <form action={action}>\n\n      <Submit />\n\n    </form>\n\n  );\n\n}\n\nTo get status information, the Submit component must be rendered within a <form>. The Hook returns information like the pending property which tells you if the form is actively submitting.\n\nIn the above example, Submit uses this information to disable <button> presses while the form is submitting.\n\nSee more examples below.\n\nParameters \n\nuseFormStatus does not take any parameters.\n\nReturns \n\nA status object with the following properties:\n\npending: A boolean. If true, this means the parent <form> is pending submission. Otherwise, false.\n\ndata: An object implementing the FormData interface that contains the data the parent <form> is submitting. If there is no active submission or no parent <form>, it will be null.\n\nmethod: A string value of either 'get' or 'post'. This represents whether the parent <form> is submitting with either a GET or POST HTTP method. By default, a <form> will use the GET method and can be specified by the method property.\n\naction: A reference to the function passed to the action prop on the parent <form>. If there is no parent <form>, the property is null. If there is a URI value provided to the action prop, or no action prop specified, status.action will be null.\nCaveats \nThe useFormStatus Hook must be called from a component that is rendered inside a <form>.\nuseFormStatus will only return status information for a parent <form>. It will not return status information for any <form> rendered in that same component or children components.\nUsage \nDisplay a pending state during form submission \n\nTo display a pending state while a form is submitting, you can call the useFormStatus Hook in a component rendered in a <form> and read the pending property returned.\n\nHere, we use the pending property to indicate the form is submitting.\n\nApp.js\nReload\nClear\nFork\nimport { useFormStatus } from \"react-dom\";\nimport { submitForm } from \"./actions.js\";\n\nfunction Submit() {\n  const { pending } = useFormStatus();\n  return (\n    <button type=\"submit\" disabled={pending}>\n      {pending ? \"Submitting...\" : \"Submit\"}\n    </button>\n  );\n}\n\nfunction Form({ action }) {\n  return (\n    <form action={action}>\n      <Submit />\n    </form>\n  );\n}\n\nexport default function App() {\n  return <Form action={submitForm} />;\n}\n\n\nShow more\nPitfall\nuseFormStatus will not return status information for a <form> rendered in the same component. \n\nThe useFormStatus Hook only returns status information for a parent <form> and not for any <form> rendered in the same component calling the Hook, or child components.\n\nfunction Form() {\n\n  // 🚩 `pending` will never be true\n\n  // useFormStatus does not track the form rendered in this component\n\n  const { pending } = useFormStatus();\n\n  return <form action={submit}></form>;\n\n}\n\nInstead call useFormStatus from inside a component that is located inside <form>.\n\nfunction Submit() {\n\n  // ✅ `pending` will be derived from the form that wraps the Submit component\n\n  const { pending } = useFormStatus(); \n\n  return <button disabled={pending}>...</button>;\n\n}\n\n\n\nfunction Form() {\n\n  // This is the <form> `useFormStatus` tracks\n\n  return (\n\n    <form action={submit}>\n\n      <Submit />\n\n    </form>\n\n  );\n\n}\nRead the form data being submitted \n\nYou can use the data property of the status information returned from useFormStatus to display what data is being submitted by the user.\n\nHere, we have a form where users can request a username. We can use useFormStatus to display a temporary status message confirming what username they have requested.\n\nUsernameForm.js\nApp.js\nReload\nClear\nFork\nimport {useState, useMemo, useRef} from 'react';\nimport {useFormStatus} from 'react-dom';\n\nexport default function UsernameForm() {\n  const {pending, data} = useFormStatus();\n\n  return (\n    <div>\n      <h3>Request a Username: </h3>\n      <input type=\"text\" name=\"username\" disabled={pending}/>\n      <button type=\"submit\" disabled={pending}>\n        Submit\n      </button>\n      <br />\n      <p>{data ? `Requesting ${data?.get(\"username\")}...`: ''}</p>\n    </div>\n  );\n}\n\n\nShow more\nTroubleshooting \nstatus.pending is never true \n\nuseFormStatus will only return status information for a parent <form>.\n\nIf the component that calls useFormStatus is not nested in a <form>, status.pending will always return false. Verify useFormStatus is called in a component that is a child of a <form> element.\n\nuseFormStatus will not track the status of a <form> rendered in the same component. See Pitfall for more details.\n\nPREVIOUS\nHooks\nNEXT\nComponents"
  },
  {
    "title": "React DOM Components – React",
    "url": "https://react.dev/reference/react-dom/components",
    "html": "API REFERENCE\nReact DOM Components\n\nReact supports all of the browser built-in HTML and SVG components.\n\nCommon components \n\nAll of the built-in browser components support some props and events.\n\nCommon components (e.g. <div>)\n\nThis includes React-specific props like ref and dangerouslySetInnerHTML.\n\nForm components \n\nThese built-in browser components accept user input:\n\n<input>\n<select>\n<textarea>\n\nThey are special in React because passing the value prop to them makes them controlled.\n\nResource and Metadata Components \n\nThese built-in browser components let you load external resources or annotate the document with metadata:\n\n<link>\n<meta>\n<script>\n<style>\n<title>\n\nThey are special in React because React can render them into the document head, suspend while resources are loading, and enact other behaviors that are described on the reference page for each specific component.\n\nAll HTML components \n\nReact supports all built-in browser HTML components. This includes:\n\n<aside>\n<audio>\n<b>\n<base>\n<bdi>\n<bdo>\n<blockquote>\n<body>\n<br>\n<button>\n<canvas>\n<caption>\n<cite>\n<code>\n<col>\n<colgroup>\n<data>\n<datalist>\n<dd>\n<del>\n<details>\n<dfn>\n<dialog>\n<div>\n<dl>\n<dt>\n<em>\n<embed>\n<fieldset>\n<figcaption>\n<figure>\n<footer>\n<form>\n<h1>\n<head>\n<header>\n<hgroup>\n<hr>\n<html>\n<i>\n<iframe>\n<img>\n<input>\n<ins>\n<kbd>\n<label>\n<legend>\n<li>\n<link>\n<main>\n<map>\n<mark>\n<menu>\n<meta>\n<meter>\n<nav>\n<noscript>\n<object>\n<ol>\n<optgroup>\n<option>\n<output>\n<p>\n<picture>\n<pre>\n<progress>\n<q>\n<rp>\n<rt>\n<ruby>\n<s>\n<samp>\n<script>\n<section>\n<select>\n<slot>\n<small>\n<source>\n<span>\n<strong>\n<style>\n<sub>\n<summary>\n<sup>\n<table>\n<tbody>\n<td>\n<template>\n<textarea>\n<tfoot>\n<th>\n<thead>\n<time>\n<title>\n<tr>\n<track>\n<u>\n<ul>\n<var>\n<video>\n<wbr>\nNote\n\nSimilar to the DOM standard, React uses a camelCase convention for prop names. For example, you’ll write tabIndex instead of tabindex. You can convert existing HTML to JSX with an online converter.\n\nCustom HTML elements \n\nIf you render a tag with a dash, like <my-element>, React will assume you want to render a custom HTML element.\n\nIf you render a built-in browser HTML element with an is attribute, it will also be treated as a custom element.\n\nSetting values on custom elements \n\nCustom elements have two methods of passing data into them:\n\nAttributes: Which are displayed in markup and can only be set to string values\nProperties: Which are not displayed in markup and can be set to arbitrary JavaScript values\n\nBy default, React will pass values bound in JSX as attributes:\n\n<my-element value=\"Hello, world!\"></my-element>\n\nNon-string JavaScript values passed to custom elements will be serialized by default:\n\n// Will be passed as `\"1,2,3\"` as the output of `[1,2,3].toString()`\n\n<my-element value={[1,2,3]}></my-element>\n\nReact will, however, recognize an custom element’s property as one that it may pass arbitrary values to if the property name shows up on the class during construction:\n\nMyElement.js\nApp.js\nReload\nClear\nFork\nexport class MyElement extends HTMLElement {\n  constructor() {\n    super();\n    // The value here will be overwritten by React \n    // when initialized as an element\n    this.value = undefined;\n  }\n\n  connectedCallback() {\n    this.innerHTML = this.value.join(\", \");\n  }\n}\n\n\nListening for events on custom elements \n\nA common pattern when using custom elements is that they may dispatch CustomEvents rather than accept a function to call when an event occur. You can listen for these events using an on prefix when binding to the event via JSX.\n\nMyElement.js\nApp.js\nReload\nClear\nFork\nexport function App() {\n  return (\n    <my-element\n      onspeak={e => console.log(e.detail.message)}\n    ></my-element>\n  )\n}\n\n\nNote\n\nEvents are case-sensitive and support dashes (-). Preserve the casing of the event and include all dashes when listening for custom element’s events:\n\n// Listens for `say-hi` events\n\n<my-element onsay-hi={console.log}></my-element>\n\n// Listens for `sayHi` events\n\n<my-element onsayHi={console.log}></my-element>\nAll SVG components \n\nReact supports all built-in browser SVG components. This includes:\n\n<a>\n<animate>\n<animateMotion>\n<animateTransform>\n<circle>\n<clipPath>\n<defs>\n<desc>\n<discard>\n<ellipse>\n<feBlend>\n<feColorMatrix>\n<feComponentTransfer>\n<feComposite>\n<feConvolveMatrix>\n<feDiffuseLighting>\n<feDisplacementMap>\n<feDistantLight>\n<feDropShadow>\n<feFlood>\n<feFuncA>\n<feFuncB>\n<feFuncG>\n<feFuncR>\n<feGaussianBlur>\n<feImage>\n<feMerge>\n<feMergeNode>\n<feMorphology>\n<feOffset>\n<fePointLight>\n<feSpecularLighting>\n<feSpotLight>\n<feTile>\n<feTurbulence>\n<filter>\n<foreignObject>\n<g>\n<hatch>\n<hatchpath>\n<image>\n<line>\n<linearGradient>\n<marker>\n<mask>\n<metadata>\n<mpath>\n<path>\n<pattern>\n<polygon>\n<polyline>\n<radialGradient>\n<rect>\n<script>\n<set>\n<stop>\n<style>\n<svg>\n<switch>\n<symbol>\n<text>\n<textPath>\n<title>\n<tspan>\n<use>\n<view>\nNote\n\nSimilar to the DOM standard, React uses a camelCase convention for prop names. For example, you’ll write tabIndex instead of tabindex. You can convert existing SVG to JSX with an online converter.\n\nNamespaced attributes also have to be written without the colon:\n\nxlink:actuate becomes xlinkActuate.\nxlink:arcrole becomes xlinkArcrole.\nxlink:href becomes xlinkHref.\nxlink:role becomes xlinkRole.\nxlink:show becomes xlinkShow.\nxlink:title becomes xlinkTitle.\nxlink:type becomes xlinkType.\nxml:base becomes xmlBase.\nxml:lang becomes xmlLang.\nxml:space becomes xmlSpace.\nxmlns:xlink becomes xmlnsXlink.\nPREVIOUS\nuseFormStatus\nNEXT\nCommon (e.g. <div>)"
  },
  {
    "title": "Common components (e.g. <div>) – React",
    "url": "https://react.dev/reference/react-dom/components/common",
    "html": "API REFERENCE\nCOMPONENTS\nCommon components (e.g. <div>)\n\nAll built-in browser components, such as <div>, support some common props and events.\n\nReference\nCommon components (e.g. <div>)\nref callback function\nReact event object\nAnimationEvent handler function\nClipboardEvent handler function\nCompositionEvent handler function\nDragEvent handler function\nFocusEvent handler function\nEvent handler function\nInputEvent handler function\nKeyboardEvent handler function\nMouseEvent handler function\nPointerEvent handler function\nTouchEvent handler function\nTransitionEvent handler function\nUIEvent handler function\nWheelEvent handler function\nUsage\nApplying CSS styles\nManipulating a DOM node with a ref\nDangerously setting the inner HTML\nHandling mouse events\nHandling pointer events\nHandling focus events\nHandling keyboard events\nReference \nCommon components (e.g. <div>) \n<div className=\"wrapper\">Some content</div>\n\nSee more examples below.\n\nProps \n\nThese special React props are supported for all built-in components:\n\nchildren: A React node (an element, a string, a number, a portal, an empty node like null, undefined and booleans, or an array of other React nodes). Specifies the content inside the component. When you use JSX, you will usually specify the children prop implicitly by nesting tags like <div><span /></div>.\n\ndangerouslySetInnerHTML: An object of the form { __html: '<p>some html</p>' } with a raw HTML string inside. Overrides the innerHTML property of the DOM node and displays the passed HTML inside. This should be used with extreme caution! If the HTML inside isn’t trusted (for example, if it’s based on user data), you risk introducing an XSS vulnerability. Read more about using dangerouslySetInnerHTML.\n\nref: A ref object from useRef or createRef, or a ref callback function, or a string for legacy refs. Your ref will be filled with the DOM element for this node. Read more about manipulating the DOM with refs.\n\nsuppressContentEditableWarning: A boolean. If true, suppresses the warning that React shows for elements that both have children and contentEditable={true} (which normally do not work together). Use this if you’re building a text input library that manages the contentEditable content manually.\n\nsuppressHydrationWarning: A boolean. If you use server rendering, normally there is a warning when the server and the client render different content. In some rare cases (like timestamps), it is very hard or impossible to guarantee an exact match. If you set suppressHydrationWarning to true, React will not warn you about mismatches in the attributes and the content of that element. It only works one level deep, and is intended to be used as an escape hatch. Don’t overuse it. Read about suppressing hydration errors.\n\nstyle: An object with CSS styles, for example { fontWeight: 'bold', margin: 20 }. Similarly to the DOM style property, the CSS property names need to be written as camelCase, for example fontWeight instead of font-weight. You can pass strings or numbers as values. If you pass a number, like width: 100, React will automatically append px (“pixels”) to the value unless it’s a unitless property. We recommend using style only for dynamic styles where you don’t know the style values ahead of time. In other cases, applying plain CSS classes with className is more efficient. Read more about className and style.\n\nThese standard DOM props are also supported for all built-in components:\n\naccessKey: A string. Specifies a keyboard shortcut for the element. Not generally recommended.\naria-*: ARIA attributes let you specify the accessibility tree information for this element. See ARIA attributes for a complete reference. In React, all ARIA attribute names are exactly the same as in HTML.\nautoCapitalize: A string. Specifies whether and how the user input should be capitalized.\nclassName: A string. Specifies the element’s CSS class name. Read more about applying CSS styles.\ncontentEditable: A boolean. If true, the browser lets the user edit the rendered element directly. This is used to implement rich text input libraries like Lexical. React warns if you try to pass React children to an element with contentEditable={true} because React will not be able to update its content after user edits.\ndata-*: Data attributes let you attach some string data to the element, for example data-fruit=\"banana\". In React, they are not commonly used because you would usually read data from props or state instead.\ndir: Either 'ltr' or 'rtl'. Specifies the text direction of the element.\ndraggable: A boolean. Specifies whether the element is draggable. Part of HTML Drag and Drop API.\nenterKeyHint: A string. Specifies which action to present for the enter key on virtual keyboards.\nhtmlFor: A string. For <label> and <output>, lets you associate the label with some control. Same as for HTML attribute. React uses the standard DOM property names (htmlFor) instead of HTML attribute names.\nhidden: A boolean or a string. Specifies whether the element should be hidden.\nid: A string. Specifies a unique identifier for this element, which can be used to find it later or connect it with other elements. Generate it with useId to avoid clashes between multiple instances of the same component.\nis: A string. If specified, the component will behave like a custom element.\ninputMode: A string. Specifies what kind of keyboard to display (for example, text, number or telephone).\nitemProp: A string. Specifies which property the element represents for structured data crawlers.\nlang: A string. Specifies the language of the element.\nonAnimationEnd: An AnimationEvent handler function. Fires when a CSS animation completes.\nonAnimationEndCapture: A version of onAnimationEnd that fires in the capture phase.\nonAnimationIteration: An AnimationEvent handler function. Fires when an iteration of a CSS animation ends, and another one begins.\nonAnimationIterationCapture: A version of onAnimationIteration that fires in the capture phase.\nonAnimationStart: An AnimationEvent handler function. Fires when a CSS animation starts.\nonAnimationStartCapture: onAnimationStart, but fires in the capture phase.\nonAuxClick: A MouseEvent handler function. Fires when a non-primary pointer button was clicked.\nonAuxClickCapture: A version of onAuxClick that fires in the capture phase.\nonBeforeInput: An InputEvent handler function. Fires before the value of an editable element is modified. React does not yet use the native beforeinput event, and instead attempts to polyfill it using other events.\nonBeforeInputCapture: A version of onBeforeInput that fires in the capture phase.\nonBlur: A FocusEvent handler function. Fires when an element lost focus. Unlike the built-in browser blur event, in React the onBlur event bubbles.\nonBlurCapture: A version of onBlur that fires in the capture phase.\nonClick: A MouseEvent handler function. Fires when the primary button was clicked on the pointing device.\nonClickCapture: A version of onClick that fires in the capture phase.\nonCompositionStart: A CompositionEvent handler function. Fires when an input method editor starts a new composition session.\nonCompositionStartCapture: A version of onCompositionStart that fires in the capture phase.\nonCompositionEnd: A CompositionEvent handler function. Fires when an input method editor completes or cancels a composition session.\nonCompositionEndCapture: A version of onCompositionEnd that fires in the capture phase.\nonCompositionUpdate: A CompositionEvent handler function. Fires when an input method editor receives a new character.\nonCompositionUpdateCapture: A version of onCompositionUpdate that fires in the capture phase.\nonContextMenu: A MouseEvent handler function. Fires when the user tries to open a context menu.\nonContextMenuCapture: A version of onContextMenu that fires in the capture phase.\nonCopy: A ClipboardEvent handler function. Fires when the user tries to copy something into the clipboard.\nonCopyCapture: A version of onCopy that fires in the capture phase.\nonCut: A ClipboardEvent handler function. Fires when the user tries to cut something into the clipboard.\nonCutCapture: A version of onCut that fires in the capture phase.\nonDoubleClick: A MouseEvent handler function. Fires when the user clicks twice. Corresponds to the browser dblclick event.\nonDoubleClickCapture: A version of onDoubleClick that fires in the capture phase.\nonDrag: A DragEvent handler function. Fires while the user is dragging something.\nonDragCapture: A version of onDrag that fires in the capture phase.\nonDragEnd: A DragEvent handler function. Fires when the user stops dragging something.\nonDragEndCapture: A version of onDragEnd that fires in the capture phase.\nonDragEnter: A DragEvent handler function. Fires when the dragged content enters a valid drop target.\nonDragEnterCapture: A version of onDragEnter that fires in the capture phase.\nonDragOver: A DragEvent handler function. Fires on a valid drop target while the dragged content is dragged over it. You must call e.preventDefault() here to allow dropping.\nonDragOverCapture: A version of onDragOver that fires in the capture phase.\nonDragStart: A DragEvent handler function. Fires when the user starts dragging an element.\nonDragStartCapture: A version of onDragStart that fires in the capture phase.\nonDrop: A DragEvent handler function. Fires when something is dropped on a valid drop target.\nonDropCapture: A version of onDrop that fires in the capture phase.\nonFocus: A FocusEvent handler function. Fires when an element receives focus. Unlike the built-in browser focus event, in React the onFocus event bubbles.\nonFocusCapture: A version of onFocus that fires in the capture phase.\nonGotPointerCapture: A PointerEvent handler function. Fires when an element programmatically captures a pointer.\nonGotPointerCaptureCapture: A version of onGotPointerCapture that fires in the capture phase.\nonKeyDown: A KeyboardEvent handler function. Fires when a key is pressed.\nonKeyDownCapture: A version of onKeyDown that fires in the capture phase.\nonKeyPress: A KeyboardEvent handler function. Deprecated. Use onKeyDown or onBeforeInput instead.\nonKeyPressCapture: A version of onKeyPress that fires in the capture phase.\nonKeyUp: A KeyboardEvent handler function. Fires when a key is released.\nonKeyUpCapture: A version of onKeyUp that fires in the capture phase.\nonLostPointerCapture: A PointerEvent handler function. Fires when an element stops capturing a pointer.\nonLostPointerCaptureCapture: A version of onLostPointerCapture that fires in the capture phase.\nonMouseDown: A MouseEvent handler function. Fires when the pointer is pressed down.\nonMouseDownCapture: A version of onMouseDown that fires in the capture phase.\nonMouseEnter: A MouseEvent handler function. Fires when the pointer moves inside an element. Does not have a capture phase. Instead, onMouseLeave and onMouseEnter propagate from the element being left to the one being entered.\nonMouseLeave: A MouseEvent handler function. Fires when the pointer moves outside an element. Does not have a capture phase. Instead, onMouseLeave and onMouseEnter propagate from the element being left to the one being entered.\nonMouseMove: A MouseEvent handler function. Fires when the pointer changes coordinates.\nonMouseMoveCapture: A version of onMouseMove that fires in the capture phase.\nonMouseOut: A MouseEvent handler function. Fires when the pointer moves outside an element, or if it moves into a child element.\nonMouseOutCapture: A version of onMouseOut that fires in the capture phase.\nonMouseUp: A MouseEvent handler function. Fires when the pointer is released.\nonMouseUpCapture: A version of onMouseUp that fires in the capture phase.\nonPointerCancel: A PointerEvent handler function. Fires when the browser cancels a pointer interaction.\nonPointerCancelCapture: A version of onPointerCancel that fires in the capture phase.\nonPointerDown: A PointerEvent handler function. Fires when a pointer becomes active.\nonPointerDownCapture: A version of onPointerDown that fires in the capture phase.\nonPointerEnter: A PointerEvent handler function. Fires when a pointer moves inside an element. Does not have a capture phase. Instead, onPointerLeave and onPointerEnter propagate from the element being left to the one being entered.\nonPointerLeave: A PointerEvent handler function. Fires when a pointer moves outside an element. Does not have a capture phase. Instead, onPointerLeave and onPointerEnter propagate from the element being left to the one being entered.\nonPointerMove: A PointerEvent handler function. Fires when a pointer changes coordinates.\nonPointerMoveCapture: A version of onPointerMove that fires in the capture phase.\nonPointerOut: A PointerEvent handler function. Fires when a pointer moves outside an element, if the pointer interaction is cancelled, and a few other reasons.\nonPointerOutCapture: A version of onPointerOut that fires in the capture phase.\nonPointerUp: A PointerEvent handler function. Fires when a pointer is no longer active.\nonPointerUpCapture: A version of onPointerUp that fires in the capture phase.\nonPaste: A ClipboardEvent handler function. Fires when the user tries to paste something from the clipboard.\nonPasteCapture: A version of onPaste that fires in the capture phase.\nonScroll: An Event handler function. Fires when an element has been scrolled. This event does not bubble.\nonScrollCapture: A version of onScroll that fires in the capture phase.\nonSelect: An Event handler function. Fires after the selection inside an editable element like an input changes. React extends the onSelect event to work for contentEditable={true} elements as well. In addition, React extends it to fire for empty selection and on edits (which may affect the selection).\nonSelectCapture: A version of onSelect that fires in the capture phase.\nonTouchCancel: A TouchEvent handler function. Fires when the browser cancels a touch interaction.\nonTouchCancelCapture: A version of onTouchCancel that fires in the capture phase.\nonTouchEnd: A TouchEvent handler function. Fires when one or more touch points are removed.\nonTouchEndCapture: A version of onTouchEnd that fires in the capture phase.\nonTouchMove: A TouchEvent handler function. Fires one or more touch points are moved.\nonTouchMoveCapture: A version of onTouchMove that fires in the capture phase.\nonTouchStart: A TouchEvent handler function. Fires when one or more touch points are placed.\nonTouchStartCapture: A version of onTouchStart that fires in the capture phase.\nonTransitionEnd: A TransitionEvent handler function. Fires when a CSS transition completes.\nonTransitionEndCapture: A version of onTransitionEnd that fires in the capture phase.\nonWheel: A WheelEvent handler function. Fires when the user rotates a wheel button.\nonWheelCapture: A version of onWheel that fires in the capture phase.\nrole: A string. Specifies the element role explicitly for assistive technologies.\nslot: A string. Specifies the slot name when using shadow DOM. In React, an equivalent pattern is typically achieved by passing JSX as props, for example <Layout left={<Sidebar />} right={<Content />} />.\nspellCheck: A boolean or null. If explicitly set to true or false, enables or disables spellchecking.\ntabIndex: A number. Overrides the default Tab button behavior. Avoid using values other than -1 and 0.\ntitle: A string. Specifies the tooltip text for the element.\ntranslate: Either 'yes' or 'no'. Passing 'no' excludes the element content from being translated.\n\nYou can also pass custom attributes as props, for example mycustomprop=\"someValue\". This can be useful when integrating with third-party libraries. The custom attribute name must be lowercase and must not start with on. The value will be converted to a string. If you pass null or undefined, the custom attribute will be removed.\n\nThese events fire only for the <form> elements:\n\nonReset: An Event handler function. Fires when a form gets reset.\nonResetCapture: A version of onReset that fires in the capture phase.\nonSubmit: An Event handler function. Fires when a form gets submitted.\nonSubmitCapture: A version of onSubmit that fires in the capture phase.\n\nThese events fire only for the <dialog> elements. Unlike browser events, they bubble in React:\n\nonCancel: An Event handler function. Fires when the user tries to dismiss the dialog.\nonCancelCapture: A version of onCancel that fires in the capture phase.\nonClose: An Event handler function. Fires when a dialog has been closed.\nonCloseCapture: A version of onClose that fires in the capture phase.\n\nThese events fire only for the <details> elements. Unlike browser events, they bubble in React:\n\nonToggle: An Event handler function. Fires when the user toggles the details.\nonToggleCapture: A version of onToggle that fires in the capture phase.\n\nThese events fire for <img>, <iframe>, <object>, <embed>, <link>, and SVG <image> elements. Unlike browser events, they bubble in React:\n\nonLoad: An Event handler function. Fires when the resource has loaded.\nonLoadCapture: A version of onLoad that fires in the capture phase.\nonError: An Event handler function. Fires when the resource could not be loaded.\nonErrorCapture: A version of onError that fires in the capture phase.\n\nThese events fire for resources like <audio> and <video>. Unlike browser events, they bubble in React:\n\nonAbort: An Event handler function. Fires when the resource has not fully loaded, but not due to an error.\nonAbortCapture: A version of onAbort that fires in the capture phase.\nonCanPlay: An Event handler function. Fires when there’s enough data to start playing, but not enough to play to the end without buffering.\nonCanPlayCapture: A version of onCanPlay that fires in the capture phase.\nonCanPlayThrough: An Event handler function. Fires when there’s enough data that it’s likely possible to start playing without buffering until the end.\nonCanPlayThroughCapture: A version of onCanPlayThrough that fires in the capture phase.\nonDurationChange: An Event handler function. Fires when the media duration has updated.\nonDurationChangeCapture: A version of onDurationChange that fires in the capture phase.\nonEmptied: An Event handler function. Fires when the media has become empty.\nonEmptiedCapture: A version of onEmptied that fires in the capture phase.\nonEncrypted: An Event handler function. Fires when the browser encounters encrypted media.\nonEncryptedCapture: A version of onEncrypted that fires in the capture phase.\nonEnded: An Event handler function. Fires when the playback stops because there’s nothing left to play.\nonEndedCapture: A version of onEnded that fires in the capture phase.\nonError: An Event handler function. Fires when the resource could not be loaded.\nonErrorCapture: A version of onError that fires in the capture phase.\nonLoadedData: An Event handler function. Fires when the current playback frame has loaded.\nonLoadedDataCapture: A version of onLoadedData that fires in the capture phase.\nonLoadedMetadata: An Event handler function. Fires when metadata has loaded.\nonLoadedMetadataCapture: A version of onLoadedMetadata that fires in the capture phase.\nonLoadStart: An Event handler function. Fires when the browser started loading the resource.\nonLoadStartCapture: A version of onLoadStart that fires in the capture phase.\nonPause: An Event handler function. Fires when the media was paused.\nonPauseCapture: A version of onPause that fires in the capture phase.\nonPlay: An Event handler function. Fires when the media is no longer paused.\nonPlayCapture: A version of onPlay that fires in the capture phase.\nonPlaying: An Event handler function. Fires when the media starts or restarts playing.\nonPlayingCapture: A version of onPlaying that fires in the capture phase.\nonProgress: An Event handler function. Fires periodically while the resource is loading.\nonProgressCapture: A version of onProgress that fires in the capture phase.\nonRateChange: An Event handler function. Fires when playback rate changes.\nonRateChangeCapture: A version of onRateChange that fires in the capture phase.\nonResize: An Event handler function. Fires when video changes size.\nonResizeCapture: A version of onResize that fires in the capture phase.\nonSeeked: An Event handler function. Fires when a seek operation completes.\nonSeekedCapture: A version of onSeeked that fires in the capture phase.\nonSeeking: An Event handler function. Fires when a seek operation starts.\nonSeekingCapture: A version of onSeeking that fires in the capture phase.\nonStalled: An Event handler function. Fires when the browser is waiting for data but it keeps not loading.\nonStalledCapture: A version of onStalled that fires in the capture phase.\nonSuspend: An Event handler function. Fires when loading the resource was suspended.\nonSuspendCapture: A version of onSuspend that fires in the capture phase.\nonTimeUpdate: An Event handler function. Fires when the current playback time updates.\nonTimeUpdateCapture: A version of onTimeUpdate that fires in the capture phase.\nonVolumeChange: An Event handler function. Fires when the volume has changed.\nonVolumeChangeCapture: A version of onVolumeChange that fires in the capture phase.\nonWaiting: An Event handler function. Fires when the playback stopped due to temporary lack of data.\nonWaitingCapture: A version of onWaiting that fires in the capture phase.\nCaveats \nYou cannot pass both children and dangerouslySetInnerHTML at the same time.\nSome events (like onAbort and onLoad) don’t bubble in the browser, but bubble in React.\nref callback function \n\nInstead of a ref object (like the one returned by useRef), you may pass a function to the ref attribute.\n\n<div ref={(node) => {\n\n  console.log('Attached', node);\n\n\n\n  return () => {\n\n    console.log('Clean up', node)\n\n  }\n\n}}>\n\nSee an example of using the ref callback.\n\nWhen the <div> DOM node is added to the screen, React will call your ref callback with the DOM node as the argument. When that <div> DOM node is removed, React will call your the cleanup function returned from the callback.\n\nReact will also call your ref callback whenever you pass a different ref callback. In the above example, (node) => { ... } is a different function on every render. When your component re-renders, the previous function will be called with null as the argument, and the next function will be called with the DOM node.\n\nParameters \nnode: A DOM node. React will pass you the DOM node when the ref gets attached. Unless you pass the same function reference for the ref callback on every render, the callback will get temporarily cleanup and re-create during every re-render of the component.\nNote\nReact 19 added cleanup functions for ref callbacks. \n\nTo support backwards compatibility, if a cleanup function is not returned from the ref callback, node will be called with null when the ref is detached. This behavior will be removed in a future version.\n\nReturns \noptional cleanup function: When the ref is detached, React will call the cleanup function. If a function is not returned by the ref callback, React will call the callback again with null as the argument when the ref gets detached. This behavior will be removed in a future version.\nCaveats \nWhen Strict Mode is on, React will run one extra development-only setup+cleanup cycle before the first real setup. This is a stress-test that ensures that your cleanup logic “mirrors” your setup logic and that it stops or undoes whatever the setup is doing. If this causes a problem, implement the cleanup function.\nWhen you pass a different ref callback, React will call the previous callback’s cleanup function if provided. If no cleanup function is defined, the ref callback will be called with null as the argument. The next function will be called with the DOM node.\nReact event object \n\nYour event handlers will receive a React event object. It is also sometimes known as a “synthetic event”.\n\n<button onClick={e => {\n\n  console.log(e); // React event object\n\n}} />\n\nIt conforms to the same standard as the underlying DOM events, but fixes some browser inconsistencies.\n\nSome React events do not map directly to the browser’s native events. For example in onMouseLeave, e.nativeEvent will point to a mouseout event. The specific mapping is not part of the public API and may change in the future. If you need the underlying browser event for some reason, read it from e.nativeEvent.\n\nProperties \n\nReact event objects implement some of the standard Event properties:\n\nbubbles: A boolean. Returns whether the event bubbles through the DOM.\ncancelable: A boolean. Returns whether the event can be canceled.\ncurrentTarget: A DOM node. Returns the node to which the current handler is attached in the React tree.\ndefaultPrevented: A boolean. Returns whether preventDefault was called.\neventPhase: A number. Returns which phase the event is currently in.\nisTrusted: A boolean. Returns whether the event was initiated by user.\ntarget: A DOM node. Returns the node on which the event has occurred (which could be a distant child).\ntimeStamp: A number. Returns the time when the event occurred.\n\nAdditionally, React event objects provide these properties:\n\nnativeEvent: A DOM Event. The original browser event object.\nMethods \n\nReact event objects implement some of the standard Event methods:\n\npreventDefault(): Prevents the default browser action for the event.\nstopPropagation(): Stops the event propagation through the React tree.\n\nAdditionally, React event objects provide these methods:\n\nisDefaultPrevented(): Returns a boolean value indicating whether preventDefault was called.\nisPropagationStopped(): Returns a boolean value indicating whether stopPropagation was called.\npersist(): Not used with React DOM. With React Native, call this to read event’s properties after the event.\nisPersistent(): Not used with React DOM. With React Native, returns whether persist has been called.\nCaveats \nThe values of currentTarget, eventPhase, target, and type reflect the values your React code expects. Under the hood, React attaches event handlers at the root, but this is not reflected in React event objects. For example, e.currentTarget may not be the same as the underlying e.nativeEvent.currentTarget. For polyfilled events, e.type (React event type) may differ from e.nativeEvent.type (underlying type).\nAnimationEvent handler function \n\nAn event handler type for the CSS animation events.\n\n<div\n\n  onAnimationStart={e => console.log('onAnimationStart')}\n\n  onAnimationIteration={e => console.log('onAnimationIteration')}\n\n  onAnimationEnd={e => console.log('onAnimationEnd')}\n\n/>\nParameters \ne: A React event object with these extra AnimationEvent properties:\nanimationName\nelapsedTime\npseudoElement\nClipboardEvent handler function \n\nAn event handler type for the Clipboard API events.\n\n<input\n\n  onCopy={e => console.log('onCopy')}\n\n  onCut={e => console.log('onCut')}\n\n  onPaste={e => console.log('onPaste')}\n\n/>\nParameters \n\ne: A React event object with these extra ClipboardEvent properties:\n\nclipboardData\nCompositionEvent handler function \n\nAn event handler type for the input method editor (IME) events.\n\n<input\n\n  onCompositionStart={e => console.log('onCompositionStart')}\n\n  onCompositionUpdate={e => console.log('onCompositionUpdate')}\n\n  onCompositionEnd={e => console.log('onCompositionEnd')}\n\n/>\nParameters \ne: A React event object with these extra CompositionEvent properties:\ndata\nDragEvent handler function \n\nAn event handler type for the HTML Drag and Drop API events.\n\n<>\n\n  <div\n\n    draggable={true}\n\n    onDragStart={e => console.log('onDragStart')}\n\n    onDragEnd={e => console.log('onDragEnd')}\n\n  >\n\n    Drag source\n\n  </div>\n\n\n\n  <div\n\n    onDragEnter={e => console.log('onDragEnter')}\n\n    onDragLeave={e => console.log('onDragLeave')}\n\n    onDragOver={e => { e.preventDefault(); console.log('onDragOver'); }}\n\n    onDrop={e => console.log('onDrop')}\n\n  >\n\n    Drop target\n\n  </div>\n\n</>\nParameters \n\ne: A React event object with these extra DragEvent properties:\n\ndataTransfer\n\nIt also includes the inherited MouseEvent properties:\n\naltKey\nbutton\nbuttons\nctrlKey\nclientX\nclientY\ngetModifierState(key)\nmetaKey\nmovementX\nmovementY\npageX\npageY\nrelatedTarget\nscreenX\nscreenY\nshiftKey\n\nIt also includes the inherited UIEvent properties:\n\ndetail\nview\nFocusEvent handler function \n\nAn event handler type for the focus events.\n\n<input\n\n  onFocus={e => console.log('onFocus')}\n\n  onBlur={e => console.log('onBlur')}\n\n/>\n\nSee an example.\n\nParameters \n\ne: A React event object with these extra FocusEvent properties:\n\nrelatedTarget\n\nIt also includes the inherited UIEvent properties:\n\ndetail\nview\nEvent handler function \n\nAn event handler type for generic events.\n\nParameters \ne: A React event object with no additional properties.\nInputEvent handler function \n\nAn event handler type for the onBeforeInput event.\n\n<input onBeforeInput={e => console.log('onBeforeInput')} />\nParameters \ne: A React event object with these extra InputEvent properties:\ndata\nKeyboardEvent handler function \n\nAn event handler type for keyboard events.\n\n<input\n\n  onKeyDown={e => console.log('onKeyDown')}\n\n  onKeyUp={e => console.log('onKeyUp')}\n\n/>\n\nSee an example.\n\nParameters \n\ne: A React event object with these extra KeyboardEvent properties:\n\naltKey\ncharCode\ncode\nctrlKey\ngetModifierState(key)\nkey\nkeyCode\nlocale\nmetaKey\nlocation\nrepeat\nshiftKey\nwhich\n\nIt also includes the inherited UIEvent properties:\n\ndetail\nview\nMouseEvent handler function \n\nAn event handler type for mouse events.\n\n<div\n\n  onClick={e => console.log('onClick')}\n\n  onMouseEnter={e => console.log('onMouseEnter')}\n\n  onMouseOver={e => console.log('onMouseOver')}\n\n  onMouseDown={e => console.log('onMouseDown')}\n\n  onMouseUp={e => console.log('onMouseUp')}\n\n  onMouseLeave={e => console.log('onMouseLeave')}\n\n/>\n\nSee an example.\n\nParameters \n\ne: A React event object with these extra MouseEvent properties:\n\naltKey\nbutton\nbuttons\nctrlKey\nclientX\nclientY\ngetModifierState(key)\nmetaKey\nmovementX\nmovementY\npageX\npageY\nrelatedTarget\nscreenX\nscreenY\nshiftKey\n\nIt also includes the inherited UIEvent properties:\n\ndetail\nview\nPointerEvent handler function \n\nAn event handler type for pointer events.\n\n<div\n\n  onPointerEnter={e => console.log('onPointerEnter')}\n\n  onPointerMove={e => console.log('onPointerMove')}\n\n  onPointerDown={e => console.log('onPointerDown')}\n\n  onPointerUp={e => console.log('onPointerUp')}\n\n  onPointerLeave={e => console.log('onPointerLeave')}\n\n/>\n\nSee an example.\n\nParameters \n\ne: A React event object with these extra PointerEvent properties:\n\nheight\nisPrimary\npointerId\npointerType\npressure\ntangentialPressure\ntiltX\ntiltY\ntwist\nwidth\n\nIt also includes the inherited MouseEvent properties:\n\naltKey\nbutton\nbuttons\nctrlKey\nclientX\nclientY\ngetModifierState(key)\nmetaKey\nmovementX\nmovementY\npageX\npageY\nrelatedTarget\nscreenX\nscreenY\nshiftKey\n\nIt also includes the inherited UIEvent properties:\n\ndetail\nview\nTouchEvent handler function \n\nAn event handler type for touch events.\n\n<div\n\n  onTouchStart={e => console.log('onTouchStart')}\n\n  onTouchMove={e => console.log('onTouchMove')}\n\n  onTouchEnd={e => console.log('onTouchEnd')}\n\n  onTouchCancel={e => console.log('onTouchCancel')}\n\n/>\nParameters \n\ne: A React event object with these extra TouchEvent properties:\n\naltKey\nctrlKey\nchangedTouches\ngetModifierState(key)\nmetaKey\nshiftKey\ntouches\ntargetTouches\n\nIt also includes the inherited UIEvent properties:\n\ndetail\nview\nTransitionEvent handler function \n\nAn event handler type for the CSS transition events.\n\n<div\n\n  onTransitionEnd={e => console.log('onTransitionEnd')}\n\n/>\nParameters \ne: A React event object with these extra TransitionEvent properties:\nelapsedTime\npropertyName\npseudoElement\nUIEvent handler function \n\nAn event handler type for generic UI events.\n\n<div\n\n  onScroll={e => console.log('onScroll')}\n\n/>\nParameters \ne: A React event object with these extra UIEvent properties:\ndetail\nview\nWheelEvent handler function \n\nAn event handler type for the onWheel event.\n\n<div\n\n  onWheel={e => console.log('onWheel')}\n\n/>\nParameters \n\ne: A React event object with these extra WheelEvent properties:\n\ndeltaMode\ndeltaX\ndeltaY\ndeltaZ\n\nIt also includes the inherited MouseEvent properties:\n\naltKey\nbutton\nbuttons\nctrlKey\nclientX\nclientY\ngetModifierState(key)\nmetaKey\nmovementX\nmovementY\npageX\npageY\nrelatedTarget\nscreenX\nscreenY\nshiftKey\n\nIt also includes the inherited UIEvent properties:\n\ndetail\nview\nUsage \nApplying CSS styles \n\nIn React, you specify a CSS class with className. It works like the class attribute in HTML:\n\n<img className=\"avatar\" />\n\nThen you write the CSS rules for it in a separate CSS file:\n\n/* In your CSS */\n\n.avatar {\n\n  border-radius: 50%;\n\n}\n\nReact does not prescribe how you add CSS files. In the simplest case, you’ll add a <link> tag to your HTML. If you use a build tool or a framework, consult its documentation to learn how to add a CSS file to your project.\n\nSometimes, the style values depend on data. Use the style attribute to pass some styles dynamically:\n\n<img\n\n  className=\"avatar\"\n\n  style={{\n\n    width: user.imageSize,\n\n    height: user.imageSize\n\n  }}\n\n/>\n\nIn the above example, style={{}} is not a special syntax, but a regular {} object inside the style={ } JSX curly braces. We recommend only using the style attribute when your styles depend on JavaScript variables.\n\nApp.js\nAvatar.js\nReload\nClear\nFork\nexport default function Avatar({ user }) {\n  return (\n    <img\n      src={user.imageUrl}\n      alt={'Photo of ' + user.name}\n      className=\"avatar\"\n      style={{\n        width: user.imageSize,\n        height: user.imageSize\n      }}\n    />\n  );\n}\n\n\nDEEP DIVE\nHow to apply multiple CSS classes conditionally? \nShow Details\nManipulating a DOM node with a ref \n\nSometimes, you’ll need to get the browser DOM node associated with a tag in JSX. For example, if you want to focus an <input> when a button is clicked, you need to call focus() on the browser <input> DOM node.\n\nTo obtain the browser DOM node for a tag, declare a ref and pass it as the ref attribute to that tag:\n\nimport { useRef } from 'react';\n\n\n\nexport default function Form() {\n\n  const inputRef = useRef(null);\n\n  // ...\n\n  return (\n\n    <input ref={inputRef} />\n\n    // ...\n\nReact will put the DOM node into inputRef.current after it’s been rendered to the screen.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useRef } from 'react';\n\nexport default function Form() {\n  const inputRef = useRef(null);\n\n  function handleClick() {\n    inputRef.current.focus();\n  }\n\n  return (\n    <>\n      <input ref={inputRef} />\n      <button onClick={handleClick}>\n        Focus the input\n      </button>\n    </>\n  );\n}\n\n\nShow more\n\nRead more about manipulating DOM with refs and check out more examples.\n\nFor more advanced use cases, the ref attribute also accepts a callback function.\n\nDangerously setting the inner HTML \n\nYou can pass a raw HTML string to an element like so:\n\nconst markup = { __html: '<p>some raw html</p>' };\n\nreturn <div dangerouslySetInnerHTML={markup} />;\n\nThis is dangerous. As with the underlying DOM innerHTML property, you must exercise extreme caution! Unless the markup is coming from a completely trusted source, it is trivial to introduce an XSS vulnerability this way.\n\nFor example, if you use a Markdown library that converts Markdown to HTML, you trust that its parser doesn’t contain bugs, and the user only sees their own input, you can display the resulting HTML like this:\n\npackage.json\nApp.js\nMarkdownPreview.js\nReload\nClear\nFork\nimport { Remarkable } from 'remarkable';\n\nconst md = new Remarkable();\n\nfunction renderMarkdownToHTML(markdown) {\n  // This is ONLY safe because the output HTML\n  // is shown to the same user, and because you\n  // trust this Markdown parser to not have bugs.\n  const renderedHTML = md.render(markdown);\n  return {__html: renderedHTML};\n}\n\nexport default function MarkdownPreview({ markdown }) {\n  const markup = renderMarkdownToHTML(markdown);\n  return <div dangerouslySetInnerHTML={markup} />;\n}\n\n\nShow more\n\nThe {__html} object should be created as close to where the HTML is generated as possible, like the above example does in the renderMarkdownToHTML function. This ensures that all raw HTML being used in your code is explicitly marked as such, and that only variables that you expect to contain HTML are passed to dangerouslySetInnerHTML. It is not recommended to create the object inline like <div dangerouslySetInnerHTML={{__html: markup}} />.\n\nTo see why rendering arbitrary HTML is dangerous, replace the code above with this:\n\nconst post = {\n\n  // Imagine this content is stored in the database.\n\n  content: `<img src=\"\" onerror='alert(\"you were hacked\")'>`\n\n};\n\n\n\nexport default function MarkdownPreview() {\n\n  // 🔴 SECURITY HOLE: passing untrusted input to dangerouslySetInnerHTML\n\n  const markup = { __html: post.content };\n\n  return <div dangerouslySetInnerHTML={markup} />;\n\n}\n\nThe code embedded in the HTML will run. A hacker could use this security hole to steal user information or to perform actions on their behalf. Only use dangerouslySetInnerHTML with trusted and sanitized data.\n\nHandling mouse events \n\nThis example shows some common mouse events and when they fire.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function MouseExample() {\n  return (\n    <div\n      onMouseEnter={e => console.log('onMouseEnter (parent)')}\n      onMouseLeave={e => console.log('onMouseLeave (parent)')}\n    >\n      <button\n        onClick={e => console.log('onClick (first button)')}\n        onMouseDown={e => console.log('onMouseDown (first button)')}\n        onMouseEnter={e => console.log('onMouseEnter (first button)')}\n        onMouseLeave={e => console.log('onMouseLeave (first button)')}\n        onMouseOver={e => console.log('onMouseOver (first button)')}\n        onMouseUp={e => console.log('onMouseUp (first button)')}\n      >\n        First button\n      </button>\n      <button\n        onClick={e => console.log('onClick (second button)')}\n        onMouseDown={e => console.log('onMouseDown (second button)')}\n        onMouseEnter={e => console.log('onMouseEnter (second button)')}\n        onMouseLeave={e => console.log('onMouseLeave (second button)')}\n        onMouseOver={e => console.log('onMouseOver (second button)')}\n        onMouseUp={e => console.log('onMouseUp (second button)')}\n      >\n        Second button\n      </button>\n    </div>\n  );\n}\n\n\nShow more\nHandling pointer events \n\nThis example shows some common pointer events and when they fire.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function PointerExample() {\n  return (\n    <div\n      onPointerEnter={e => console.log('onPointerEnter (parent)')}\n      onPointerLeave={e => console.log('onPointerLeave (parent)')}\n      style={{ padding: 20, backgroundColor: '#ddd' }}\n    >\n      <div\n        onPointerDown={e => console.log('onPointerDown (first child)')}\n        onPointerEnter={e => console.log('onPointerEnter (first child)')}\n        onPointerLeave={e => console.log('onPointerLeave (first child)')}\n        onPointerMove={e => console.log('onPointerMove (first child)')}\n        onPointerUp={e => console.log('onPointerUp (first child)')}\n        style={{ padding: 20, backgroundColor: 'lightyellow' }}\n      >\n        First child\n      </div>\n      <div\n        onPointerDown={e => console.log('onPointerDown (second child)')}\n        onPointerEnter={e => console.log('onPointerEnter (second child)')}\n        onPointerLeave={e => console.log('onPointerLeave (second child)')}\n        onPointerMove={e => console.log('onPointerMove (second child)')}\n        onPointerUp={e => console.log('onPointerUp (second child)')}\n        style={{ padding: 20, backgroundColor: 'lightblue' }}\n      >\n        Second child\n      </div>\n    </div>\n  );\n}\n\n\nShow more\nHandling focus events \n\nIn React, focus events bubble. You can use the currentTarget and relatedTarget to differentiate if the focusing or blurring events originated from outside of the parent element. The example shows how to detect focusing a child, focusing the parent element, and how to detect focus entering or leaving the whole subtree.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function FocusExample() {\n  return (\n    <div\n      tabIndex={1}\n      onFocus={(e) => {\n        if (e.currentTarget === e.target) {\n          console.log('focused parent');\n        } else {\n          console.log('focused child', e.target.name);\n        }\n        if (!e.currentTarget.contains(e.relatedTarget)) {\n          // Not triggered when swapping focus between children\n          console.log('focus entered parent');\n        }\n      }}\n      onBlur={(e) => {\n        if (e.currentTarget === e.target) {\n          console.log('unfocused parent');\n        } else {\n          console.log('unfocused child', e.target.name);\n        }\n        if (!e.currentTarget.contains(e.relatedTarget)) {\n          // Not triggered when swapping focus between children\n          console.log('focus left parent');\n        }\n      }}\n    >\n      <label>\n        First name:\n        <input name=\"firstName\" />\n      </label>\n      <label>\n        Last name:\n        <input name=\"lastName\" />\n      </label>\n    </div>\n  );\n}\n\n\nShow more\nHandling keyboard events \n\nThis example shows some common keyboard events and when they fire.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function KeyboardExample() {\n  return (\n    <label>\n      First name:\n      <input\n        name=\"firstName\"\n        onKeyDown={e => console.log('onKeyDown:', e.key, e.code)}\n        onKeyUp={e => console.log('onKeyUp:', e.key, e.code)}\n      />\n    </label>\n  );\n}\n\n\nPREVIOUS\nComponents\nNEXT\n<form>"
  },
  {
    "title": "<form> – React",
    "url": "https://react.dev/reference/react-dom/components/form",
    "html": "API REFERENCE\nCOMPONENTS\n<form>\n\nThe built-in browser <form> component lets you create interactive controls for submitting information.\n\n<form action={search}>\n\n    <input name=\"query\" />\n\n    <button type=\"submit\">Search</button>\n\n</form>\nReference\n<form>\nUsage\nHandle form submission on the client\nHandle form submission with a Server Function\nDisplay a pending state during form submission\nOptimistically updating form data\nHandling form submission errors\nDisplay a form submission error without JavaScript\nHandling multiple submission types\nReference \n<form> \n\nTo create interactive controls for submitting information, render the built-in browser <form> component.\n\n<form action={search}>\n\n    <input name=\"query\" />\n\n    <button type=\"submit\">Search</button>\n\n</form>\n\nSee more examples below.\n\nProps \n\n<form> supports all common element props.\n\naction: a URL or function. When a URL is passed to action the form will behave like the HTML form component. When a function is passed to action the function will handle the form submission in a Transition following the Action prop pattern. The function passed to action may be async and will be called with a single argument containing the form data of the submitted form. The action prop can be overridden by a formAction attribute on a <button>, <input type=\"submit\">, or <input type=\"image\"> component.\n\nCaveats \nWhen a function is passed to action or formAction the HTTP method will be POST regardless of value of the method prop.\nUsage \nHandle form submission on the client \n\nPass a function to the action prop of form to run the function when the form is submitted. formData will be passed to the function as an argument so you can access the data submitted by the form. This differs from the conventional HTML action, which only accepts URLs. After the action function succeeds, all uncontrolled field elements in the form are reset.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function Search() {\n  function search(formData) {\n    const query = formData.get(\"query\");\n    alert(`You searched for '${query}'`);\n  }\n  return (\n    <form action={search}>\n      <input name=\"query\" />\n      <button type=\"submit\">Search</button>\n    </form>\n  );\n}\n\n\nHandle form submission with a Server Function \n\nRender a <form> with an input and submit button. Pass a Server Function (a function marked with 'use server') to the action prop of form to run the function when the form is submitted.\n\nPassing a Server Function to <form action> allow users to submit forms without JavaScript enabled or before the code has loaded. This is beneficial to users who have a slow connection, device, or have JavaScript disabled and is similar to the way forms work when a URL is passed to the action prop.\n\nYou can use hidden form fields to provide data to the <form>’s action. The Server Function will be called with the hidden form field data as an instance of FormData.\n\nimport { updateCart } from './lib.js';\n\n\n\nfunction AddToCart({productId}) {\n\n  async function addToCart(formData) {\n\n    'use server'\n\n    const productId = formData.get('productId')\n\n    await updateCart(productId)\n\n  }\n\n  return (\n\n    <form action={addToCart}>\n\n        <input type=\"hidden\" name=\"productId\" value={productId} />\n\n        <button type=\"submit\">Add to Cart</button>\n\n    </form>\n\n\n\n  );\n\n}\n\nIn lieu of using hidden form fields to provide data to the <form>’s action, you can call the bind method to supply it with extra arguments. This will bind a new argument (productId) to the function in addition to the formData that is passed as an argument to the function.\n\nimport { updateCart } from './lib.js';\n\n\n\nfunction AddToCart({productId}) {\n\n  async function addToCart(productId, formData) {\n\n    \"use server\";\n\n    await updateCart(productId)\n\n  }\n\n  const addProductToCart = addToCart.bind(null, productId);\n\n  return (\n\n    <form action={addProductToCart}>\n\n      <button type=\"submit\">Add to Cart</button>\n\n    </form>\n\n  );\n\n}\n\nWhen <form> is rendered by a Server Component, and a Server Function is passed to the <form>’s action prop, the form is progressively enhanced.\n\nDisplay a pending state during form submission \n\nTo display a pending state when a form is being submitted, you can call the useFormStatus Hook in a component rendered in a <form> and read the pending property returned.\n\nHere, we use the pending property to indicate the form is submitting.\n\nApp.js\nReload\nClear\nFork\nimport { useFormStatus } from \"react-dom\";\nimport { submitForm } from \"./actions.js\";\n\nfunction Submit() {\n  const { pending } = useFormStatus();\n  return (\n    <button type=\"submit\" disabled={pending}>\n      {pending ? \"Submitting...\" : \"Submit\"}\n    </button>\n  );\n}\n\nfunction Form({ action }) {\n  return (\n    <form action={action}>\n      <Submit />\n    </form>\n  );\n}\n\nexport default function App() {\n  return <Form action={submitForm} />;\n}\n\n\nShow more\n\nTo learn more about the useFormStatus Hook see the reference documentation.\n\nOptimistically updating form data \n\nThe useOptimistic Hook provides a way to optimistically update the user interface before a background operation, like a network request, completes. In the context of forms, this technique helps to make apps feel more responsive. When a user submits a form, instead of waiting for the server’s response to reflect the changes, the interface is immediately updated with the expected outcome.\n\nFor example, when a user types a message into the form and hits the “Send” button, the useOptimistic Hook allows the message to immediately appear in the list with a “Sending…” label, even before the message is actually sent to a server. This “optimistic” approach gives the impression of speed and responsiveness. The form then attempts to truly send the message in the background. Once the server confirms the message has been received, the “Sending…” label is removed.\n\nApp.js\nactions.js\nReload\nClear\nFork\nimport { useOptimistic, useState, useRef } from \"react\";\nimport { deliverMessage } from \"./actions.js\";\n\nfunction Thread({ messages, sendMessage }) {\n  const formRef = useRef();\n  async function formAction(formData) {\n    addOptimisticMessage(formData.get(\"message\"));\n    formRef.current.reset();\n    await sendMessage(formData);\n  }\n  const [optimisticMessages, addOptimisticMessage] = useOptimistic(\n    messages,\n    (state, newMessage) => [\n      ...state,\n      {\n        text: newMessage,\n        sending: true\n      }\n    ]\n  );\n\n  return (\n    <>\n      {optimisticMessages.map((message, index) => (\n        <div key={index}>\n          {message.text}\n          {!!message.sending && <small> (Sending...)</small>}\n        </div>\n      ))}\n      <form action={formAction} ref={formRef}>\n        <input type=\"text\" name=\"message\" placeholder=\"Hello!\" />\n        <button type=\"submit\">Send</button>\n      </form>\n    </>\n  );\n}\n\nexport default function App() {\n  const [messages, setMessages] = useState([\n    { text: \"Hello there!\", sending: false, key: 1 }\n  ]);\n  async function sendMessage(formData) {\n    const sentMessage = await deliverMessage(formData.get(\"message\"));\n    setMessages((messages) => [...messages, { text: sentMessage }]);\n  }\n  return <Thread messages={messages} sendMessage={sendMessage} />;\n}\n\n\nShow more\nHandling form submission errors \n\nIn some cases the function called by a <form>’s action prop throws an error. You can handle these errors by wrapping <form> in an Error Boundary. If the function called by a <form>’s action prop throws an error, the fallback for the error boundary will be displayed.\n\nApp.js\nReload\nClear\nFork\nimport { ErrorBoundary } from \"react-error-boundary\";\n\nexport default function Search() {\n  function search() {\n    throw new Error(\"search error\");\n  }\n  return (\n    <ErrorBoundary\n      fallback={<p>There was an error while submitting the form</p>}\n    >\n      <form action={search}>\n        <input name=\"query\" />\n        <button type=\"submit\">Search</button>\n      </form>\n    </ErrorBoundary>\n  );\n}\n\n\nShow more\nDisplay a form submission error without JavaScript \n\nDisplaying a form submission error message before the JavaScript bundle loads for progressive enhancement requires that:\n\n<form> be rendered by a Client Component\nthe function passed to the <form>’s action prop be a Server Function\nthe useActionState Hook be used to display the error message\n\nuseActionState takes two parameters: a Server Function and an initial state. useActionState returns two values, a state variable and an action. The action returned by useActionState should be passed to the action prop of the form. The state variable returned by useActionState can be used to display an error message. The value returned by the Server Function passed to useActionState will be used to update the state variable.\n\nApp.js\nReload\nClear\nFork\nimport { useActionState } from \"react\";\nimport { signUpNewUser } from \"./api\";\n\nexport default function Page() {\n  async function signup(prevState, formData) {\n    \"use server\";\n    const email = formData.get(\"email\");\n    try {\n      await signUpNewUser(email);\n      alert(`Added \"${email}\"`);\n    } catch (err) {\n      return err.toString();\n    }\n  }\n  const [message, signupAction] = useActionState(signup, null);\n  return (\n    <>\n      <h1>Signup for my newsletter</h1>\n      <p>Signup with the same email twice to see an error</p>\n      <form action={signupAction} id=\"signup-form\">\n        <label htmlFor=\"email\">Email: </label>\n        <input name=\"email\" id=\"email\" placeholder=\"react@example.com\" />\n        <button>Sign up</button>\n        {!!message && <p>{message}</p>}\n      </form>\n    </>\n  );\n}\n\n\nShow more\n\nLearn more about updating state from a form action with the useActionState docs\n\nHandling multiple submission types \n\nForms can be designed to handle multiple submission actions based on the button pressed by the user. Each button inside a form can be associated with a distinct action or behavior by setting the formAction prop.\n\nWhen a user taps a specific button, the form is submitted, and a corresponding action, defined by that button’s attributes and action, is executed. For instance, a form might submit an article for review by default but have a separate button with formAction set to save the article as a draft.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function Search() {\n  function publish(formData) {\n    const content = formData.get(\"content\");\n    const button = formData.get(\"button\");\n    alert(`'${content}' was published with the '${button}' button`);\n  }\n\n  function save(formData) {\n    const content = formData.get(\"content\");\n    alert(`Your draft of '${content}' has been saved!`);\n  }\n\n  return (\n    <form action={publish}>\n      <textarea name=\"content\" rows={4} cols={40} />\n      <br />\n      <button type=\"submit\" name=\"button\" value=\"submit\">Publish</button>\n      <button formAction={save}>Save draft</button>\n    </form>\n  );\n}\n\n\nShow more\nPREVIOUS\nCommon (e.g. <div>)\nNEXT\n<input>"
  },
  {
    "title": "<input> – React",
    "url": "https://react.dev/reference/react-dom/components/input",
    "html": "API REFERENCE\nCOMPONENTS\n<input>\n\nThe built-in browser <input> component lets you render different kinds of form inputs.\n\n<input />\nReference\n<input>\nUsage\nDisplaying inputs of different types\nProviding a label for an input\nProviding an initial value for an input\nReading the input values when submitting a form\nControlling an input with a state variable\nOptimizing re-rendering on every keystroke\nTroubleshooting\nMy text input doesn’t update when I type into it\nMy checkbox doesn’t update when I click on it\nMy input caret jumps to the beginning on every keystroke\nI’m getting an error: “A component is changing an uncontrolled input to be controlled”\nReference \n<input> \n\nTo display an input, render the built-in browser <input> component.\n\n<input name=\"myInput\" />\n\nSee more examples below.\n\nProps \n\n<input> supports all common element props.\n\nformAction: A string or function. Overrides the parent <form action> for type=\"submit\" and type=\"image\". When a URL is passed to action the form will behave like a standard HTML form. When a function is passed to formAction the function will handle the form submission. See <form action>.\n\nYou can make an input controlled by passing one of these props:\n\nchecked: A boolean. For a checkbox input or a radio button, controls whether it is selected.\nvalue: A string. For a text input, controls its text. (For a radio button, specifies its form data.)\n\nWhen you pass either of them, you must also pass an onChange handler that updates the passed value.\n\nThese <input> props are only relevant for uncontrolled inputs:\n\ndefaultChecked: A boolean. Specifies the initial value for type=\"checkbox\" and type=\"radio\" inputs.\ndefaultValue: A string. Specifies the initial value for a text input.\n\nThese <input> props are relevant both for uncontrolled and controlled inputs:\n\naccept: A string. Specifies which filetypes are accepted by a type=\"file\" input.\nalt: A string. Specifies the alternative image text for a type=\"image\" input.\ncapture: A string. Specifies the media (microphone, video, or camera) captured by a type=\"file\" input.\nautoComplete: A string. Specifies one of the possible autocomplete behaviors.\nautoFocus: A boolean. If true, React will focus the element on mount.\ndirname: A string. Specifies the form field name for the element’s directionality.\ndisabled: A boolean. If true, the input will not be interactive and will appear dimmed.\nchildren: <input> does not accept children.\nform: A string. Specifies the id of the <form> this input belongs to. If omitted, it’s the closest parent form.\nformAction: A string. Overrides the parent <form action> for type=\"submit\" and type=\"image\".\nformEnctype: A string. Overrides the parent <form enctype> for type=\"submit\" and type=\"image\".\nformMethod: A string. Overrides the parent <form method> for type=\"submit\" and type=\"image\".\nformNoValidate: A string. Overrides the parent <form noValidate> for type=\"submit\" and type=\"image\".\nformTarget: A string. Overrides the parent <form target> for type=\"submit\" and type=\"image\".\nheight: A string. Specifies the image height for type=\"image\".\nlist: A string. Specifies the id of the <datalist> with the autocomplete options.\nmax: A number. Specifies the maximum value of numerical and datetime inputs.\nmaxLength: A number. Specifies the maximum length of text and other inputs.\nmin: A number. Specifies the minimum value of numerical and datetime inputs.\nminLength: A number. Specifies the minimum length of text and other inputs.\nmultiple: A boolean. Specifies whether multiple values are allowed for <type=\"file\" and type=\"email\".\nname: A string. Specifies the name for this input that’s submitted with the form.\nonChange: An Event handler function. Required for controlled inputs. Fires immediately when the input’s value is changed by the user (for example, it fires on every keystroke). Behaves like the browser input event.\nonChangeCapture: A version of onChange that fires in the capture phase.\nonInput: An Event handler function. Fires immediately when the value is changed by the user. For historical reasons, in React it is idiomatic to use onChange instead which works similarly.\nonInputCapture: A version of onInput that fires in the capture phase.\nonInvalid: An Event handler function. Fires if an input fails validation on form submit. Unlike the built-in invalid event, the React onInvalid event bubbles.\nonInvalidCapture: A version of onInvalid that fires in the capture phase.\nonSelect: An Event handler function. Fires after the selection inside the <input> changes. React extends the onSelect event to also fire for empty selection and on edits (which may affect the selection).\nonSelectCapture: A version of onSelect that fires in the capture phase.\npattern: A string. Specifies the pattern that the value must match.\nplaceholder: A string. Displayed in a dimmed color when the input value is empty.\nreadOnly: A boolean. If true, the input is not editable by the user.\nrequired: A boolean. If true, the value must be provided for the form to submit.\nsize: A number. Similar to setting width, but the unit depends on the control.\nsrc: A string. Specifies the image source for a type=\"image\" input.\nstep: A positive number or an 'any' string. Specifies the distance between valid values.\ntype: A string. One of the input types.\nwidth: A string. Specifies the image width for a type=\"image\" input.\nCaveats \nCheckboxes need checked (or defaultChecked), not value (or defaultValue).\nIf a text input receives a string value prop, it will be treated as controlled.\nIf a checkbox or a radio button receives a boolean checked prop, it will be treated as controlled.\nAn input can’t be both controlled and uncontrolled at the same time.\nAn input cannot switch between being controlled or uncontrolled over its lifetime.\nEvery controlled input needs an onChange event handler that synchronously updates its backing value.\nUsage \nDisplaying inputs of different types \n\nTo display an input, render an <input> component. By default, it will be a text input. You can pass type=\"checkbox\" for a checkbox, type=\"radio\" for a radio button, or one of the other input types.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function MyForm() {\n  return (\n    <>\n      <label>\n        Text input: <input name=\"myInput\" />\n      </label>\n      <hr />\n      <label>\n        Checkbox: <input type=\"checkbox\" name=\"myCheckbox\" />\n      </label>\n      <hr />\n      <p>\n        Radio buttons:\n        <label>\n          <input type=\"radio\" name=\"myRadio\" value=\"option1\" />\n          Option 1\n        </label>\n        <label>\n          <input type=\"radio\" name=\"myRadio\" value=\"option2\" />\n          Option 2\n        </label>\n        <label>\n          <input type=\"radio\" name=\"myRadio\" value=\"option3\" />\n          Option 3\n        </label>\n      </p>\n    </>\n  );\n}\n\n\nShow more\nProviding a label for an input \n\nTypically, you will place every <input> inside a <label> tag. This tells the browser that this label is associated with that input. When the user clicks the label, the browser will automatically focus the input. It’s also essential for accessibility: a screen reader will announce the label caption when the user focuses the associated input.\n\nIf you can’t nest <input> into a <label>, associate them by passing the same ID to <input id> and <label htmlFor>. To avoid conflicts between multiple instances of one component, generate such an ID with useId.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useId } from 'react';\n\nexport default function Form() {\n  const ageInputId = useId();\n  return (\n    <>\n      <label>\n        Your first name:\n        <input name=\"firstName\" />\n      </label>\n      <hr />\n      <label htmlFor={ageInputId}>Your age:</label>\n      <input id={ageInputId} name=\"age\" type=\"number\" />\n    </>\n  );\n}\n\n\nShow more\nProviding an initial value for an input \n\nYou can optionally specify the initial value for any input. Pass it as the defaultValue string for text inputs. Checkboxes and radio buttons should specify the initial value with the defaultChecked boolean instead.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function MyForm() {\n  return (\n    <>\n      <label>\n        Text input: <input name=\"myInput\" defaultValue=\"Some initial value\" />\n      </label>\n      <hr />\n      <label>\n        Checkbox: <input type=\"checkbox\" name=\"myCheckbox\" defaultChecked={true} />\n      </label>\n      <hr />\n      <p>\n        Radio buttons:\n        <label>\n          <input type=\"radio\" name=\"myRadio\" value=\"option1\" />\n          Option 1\n        </label>\n        <label>\n          <input\n            type=\"radio\"\n            name=\"myRadio\"\n            value=\"option2\"\n            defaultChecked={true} \n          />\n          Option 2\n        </label>\n        <label>\n          <input type=\"radio\" name=\"myRadio\" value=\"option3\" />\n          Option 3\n        </label>\n      </p>\n    </>\n  );\n}\n\n\nShow more\nReading the input values when submitting a form \n\nAdd a <form> around your inputs with a <button type=\"submit\"> inside. It will call your <form onSubmit> event handler. By default, the browser will send the form data to the current URL and refresh the page. You can override that behavior by calling e.preventDefault(). Read the form data with new FormData(e.target).\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function MyForm() {\n  function handleSubmit(e) {\n    // Prevent the browser from reloading the page\n    e.preventDefault();\n\n    // Read the form data\n    const form = e.target;\n    const formData = new FormData(form);\n\n    // You can pass formData as a fetch body directly:\n    fetch('/some-api', { method: form.method, body: formData });\n\n    // Or you can work with it as a plain object:\n    const formJson = Object.fromEntries(formData.entries());\n    console.log(formJson);\n  }\n\n  return (\n    <form method=\"post\" onSubmit={handleSubmit}>\n      <label>\n        Text input: <input name=\"myInput\" defaultValue=\"Some initial value\" />\n      </label>\n      <hr />\n      <label>\n        Checkbox: <input type=\"checkbox\" name=\"myCheckbox\" defaultChecked={true} />\n      </label>\n      <hr />\n      <p>\n        Radio buttons:\n        <label><input type=\"radio\" name=\"myRadio\" value=\"option1\" /> Option 1</label>\n        <label><input type=\"radio\" name=\"myRadio\" value=\"option2\" defaultChecked={true} /> Option 2</label>\n        <label><input type=\"radio\" name=\"myRadio\" value=\"option3\" /> Option 3</label>\n      </p>\n      <hr />\n      <button type=\"reset\">Reset form</button>\n      <button type=\"submit\">Submit form</button>\n    </form>\n  );\n}\n\n\nShow more\nNote\n\nGive a name to every <input>, for example <input name=\"firstName\" defaultValue=\"Taylor\" />. The name you specified will be used as a key in the form data, for example { firstName: \"Taylor\" }.\n\nPitfall\n\nBy default, a <button> inside a <form> without a type attribute will submit it. This can be surprising! If you have your own custom Button React component, consider using <button type=\"button\"> instead of <button> (with no type). Then, to be explicit, use <button type=\"submit\"> for buttons that are supposed to submit the form.\n\nControlling an input with a state variable \n\nAn input like <input /> is uncontrolled. Even if you pass an initial value like <input defaultValue=\"Initial text\" />, your JSX only specifies the initial value. It does not control what the value should be right now.\n\nTo render a controlled input, pass the value prop to it (or checked for checkboxes and radios). React will force the input to always have the value you passed. Usually, you would do this by declaring a state variable:\n\nfunction Form() {\n\n  const [firstName, setFirstName] = useState(''); // Declare a state variable...\n\n  // ...\n\n  return (\n\n    <input\n\n      value={firstName} // ...force the input's value to match the state variable...\n\n      onChange={e => setFirstName(e.target.value)} // ... and update the state variable on any edits!\n\n    />\n\n  );\n\n}\n\nA controlled input makes sense if you needed state anyway—for example, to re-render your UI on every edit:\n\nfunction Form() {\n\n  const [firstName, setFirstName] = useState('');\n\n  return (\n\n    <>\n\n      <label>\n\n        First name:\n\n        <input value={firstName} onChange={e => setFirstName(e.target.value)} />\n\n      </label>\n\n      {firstName !== '' && <p>Your name is {firstName}.</p>}\n\n      ...\n\nIt’s also useful if you want to offer multiple ways to adjust the input state (for example, by clicking a button):\n\nfunction Form() {\n\n  // ...\n\n  const [age, setAge] = useState('');\n\n  const ageAsNumber = Number(age);\n\n  return (\n\n    <>\n\n      <label>\n\n        Age:\n\n        <input\n\n          value={age}\n\n          onChange={e => setAge(e.target.value)}\n\n          type=\"number\"\n\n        />\n\n        <button onClick={() => setAge(ageAsNumber + 10)}>\n\n          Add 10 years\n\n        </button>\n\nThe value you pass to controlled components should not be undefined or null. If you need the initial value to be empty (such as with the firstName field below), initialize your state variable to an empty string ('').\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Form() {\n  const [firstName, setFirstName] = useState('');\n  const [age, setAge] = useState('20');\n  const ageAsNumber = Number(age);\n  return (\n    <>\n      <label>\n        First name:\n        <input\n          value={firstName}\n          onChange={e => setFirstName(e.target.value)}\n        />\n      </label>\n      <label>\n        Age:\n        <input\n          value={age}\n          onChange={e => setAge(e.target.value)}\n          type=\"number\"\n        />\n        <button onClick={() => setAge(ageAsNumber + 10)}>\n          Add 10 years\n        </button>\n      </label>\n      {firstName !== '' &&\n        <p>Your name is {firstName}.</p>\n      }\n      {ageAsNumber > 0 &&\n        <p>Your age is {ageAsNumber}.</p>\n      }\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\nIf you pass value without onChange, it will be impossible to type into the input. When you control an input by passing some value to it, you force it to always have the value you passed. So if you pass a state variable as a value but forget to update that state variable synchronously during the onChange event handler, React will revert the input after every keystroke back to the value that you specified.\n\nOptimizing re-rendering on every keystroke \n\nWhen you use a controlled input, you set the state on every keystroke. If the component containing your state re-renders a large tree, this can get slow. There’s a few ways you can optimize re-rendering performance.\n\nFor example, suppose you start with a form that re-renders all page content on every keystroke:\n\nfunction App() {\n\n  const [firstName, setFirstName] = useState('');\n\n  return (\n\n    <>\n\n      <form>\n\n        <input value={firstName} onChange={e => setFirstName(e.target.value)} />\n\n      </form>\n\n      <PageContent />\n\n    </>\n\n  );\n\n}\n\nSince <PageContent /> doesn’t rely on the input state, you can move the input state into its own component:\n\nfunction App() {\n\n  return (\n\n    <>\n\n      <SignupForm />\n\n      <PageContent />\n\n    </>\n\n  );\n\n}\n\n\n\nfunction SignupForm() {\n\n  const [firstName, setFirstName] = useState('');\n\n  return (\n\n    <form>\n\n      <input value={firstName} onChange={e => setFirstName(e.target.value)} />\n\n    </form>\n\n  );\n\n}\n\nThis significantly improves performance because now only SignupForm re-renders on every keystroke.\n\nIf there is no way to avoid re-rendering (for example, if PageContent depends on the search input’s value), useDeferredValue lets you keep the controlled input responsive even in the middle of a large re-render.\n\nTroubleshooting \nMy text input doesn’t update when I type into it \n\nIf you render an input with value but no onChange, you will see an error in the console:\n\n// 🔴 Bug: controlled text input with no onChange handler\n\n<input value={something} />\nConsole\nYou provided a value prop to a form field without an onChange handler. This will render a read-only field. If the field should be mutable use defaultValue. Otherwise, set either onChange or readOnly.\n\nAs the error message suggests, if you only wanted to specify the initial value, pass defaultValue instead:\n\n// ✅ Good: uncontrolled input with an initial value\n\n<input defaultValue={something} />\n\nIf you want to control this input with a state variable, specify an onChange handler:\n\n// ✅ Good: controlled input with onChange\n\n<input value={something} onChange={e => setSomething(e.target.value)} />\n\nIf the value is intentionally read-only, add a readOnly prop to suppress the error:\n\n// ✅ Good: readonly controlled input without on change\n\n<input value={something} readOnly={true} />\nMy checkbox doesn’t update when I click on it \n\nIf you render a checkbox with checked but no onChange, you will see an error in the console:\n\n// 🔴 Bug: controlled checkbox with no onChange handler\n\n<input type=\"checkbox\" checked={something} />\nConsole\nYou provided a checked prop to a form field without an onChange handler. This will render a read-only field. If the field should be mutable use defaultChecked. Otherwise, set either onChange or readOnly.\n\nAs the error message suggests, if you only wanted to specify the initial value, pass defaultChecked instead:\n\n// ✅ Good: uncontrolled checkbox with an initial value\n\n<input type=\"checkbox\" defaultChecked={something} />\n\nIf you want to control this checkbox with a state variable, specify an onChange handler:\n\n// ✅ Good: controlled checkbox with onChange\n\n<input type=\"checkbox\" checked={something} onChange={e => setSomething(e.target.checked)} />\nPitfall\n\nYou need to read e.target.checked rather than e.target.value for checkboxes.\n\nIf the checkbox is intentionally read-only, add a readOnly prop to suppress the error:\n\n// ✅ Good: readonly controlled input without on change\n\n<input type=\"checkbox\" checked={something} readOnly={true} />\nMy input caret jumps to the beginning on every keystroke \n\nIf you control an input, you must update its state variable to the input’s value from the DOM during onChange.\n\nYou can’t update it to something other than e.target.value (or e.target.checked for checkboxes):\n\nfunction handleChange(e) {\n\n  // 🔴 Bug: updating an input to something other than e.target.value\n\n  setFirstName(e.target.value.toUpperCase());\n\n}\n\nYou also can’t update it asynchronously:\n\nfunction handleChange(e) {\n\n  // 🔴 Bug: updating an input asynchronously\n\n  setTimeout(() => {\n\n    setFirstName(e.target.value);\n\n  }, 100);\n\n}\n\nTo fix your code, update it synchronously to e.target.value:\n\nfunction handleChange(e) {\n\n  // ✅ Updating a controlled input to e.target.value synchronously\n\n  setFirstName(e.target.value);\n\n}\n\nIf this doesn’t fix the problem, it’s possible that the input gets removed and re-added from the DOM on every keystroke. This can happen if you’re accidentally resetting state on every re-render, for example if the input or one of its parents always receives a different key attribute, or if you nest component function definitions (which is not supported and causes the “inner” component to always be considered a different tree).\n\nI’m getting an error: “A component is changing an uncontrolled input to be controlled” \n\nIf you provide a value to the component, it must remain a string throughout its lifetime.\n\nYou cannot pass value={undefined} first and later pass value=\"some string\" because React won’t know whether you want the component to be uncontrolled or controlled. A controlled component should always receive a string value, not null or undefined.\n\nIf your value is coming from an API or a state variable, it might be initialized to null or undefined. In that case, either set it to an empty string ('') initially, or pass value={someValue ?? ''} to ensure value is a string.\n\nSimilarly, if you pass checked to a checkbox, ensure it’s always a boolean.\n\nPREVIOUS\n<form>\nNEXT\n<option>"
  },
  {
    "title": "<option> – React",
    "url": "https://react.dev/reference/react-dom/components/option",
    "html": "API REFERENCE\nCOMPONENTS\n<option>\n\nThe built-in browser <option> component lets you render an option inside a <select> box.\n\n<select>\n\n  <option value=\"someOption\">Some option</option>\n\n  <option value=\"otherOption\">Other option</option>\n\n</select>\nReference\n<option>\nUsage\nDisplaying a select box with options\nReference \n<option> \n\nThe built-in browser <option> component lets you render an option inside a <select> box.\n\n<select>\n\n  <option value=\"someOption\">Some option</option>\n\n  <option value=\"otherOption\">Other option</option>\n\n</select>\n\nSee more examples below.\n\nProps \n\n<option> supports all common element props.\n\nAdditionally, <option> supports these props:\n\ndisabled: A boolean. If true, the option will not be selectable and will appear dimmed.\nlabel: A string. Specifies the meaning of the option. If not specified, the text inside the option is used.\nvalue: The value to be used when submitting the parent <select> in a form if this option is selected.\nCaveats \nReact does not support the selected attribute on <option>. Instead, pass this option’s value to the parent <select defaultValue> for an uncontrolled select box, or <select value> for a controlled select.\nUsage \nDisplaying a select box with options \n\nRender a <select> with a list of <option> components inside to display a select box. Give each <option> a value representing the data to be submitted with the form.\n\nRead more about displaying a <select> with a list of <option> components.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function FruitPicker() {\n  return (\n    <label>\n      Pick a fruit:\n      <select name=\"selectedFruit\">\n        <option value=\"apple\">Apple</option>\n        <option value=\"banana\">Banana</option>\n        <option value=\"orange\">Orange</option>\n      </select>\n    </label>\n  );\n}\n\n\nPREVIOUS\n<input>\nNEXT\n<progress>"
  },
  {
    "title": "<progress> – React",
    "url": "https://react.dev/reference/react-dom/components/progress",
    "html": "API REFERENCE\nCOMPONENTS\n<progress>\n\nThe built-in browser <progress> component lets you render a progress indicator.\n\n<progress value={0.5} />\nReference\n<progress>\nUsage\nControlling a progress indicator\nReference \n<progress> \n\nTo display a progress indicator, render the built-in browser <progress> component.\n\n<progress value={0.5} />\n\nSee more examples below.\n\nProps \n\n<progress> supports all common element props.\n\nAdditionally, <progress> supports these props:\n\nmax: A number. Specifies the maximum value. Defaults to 1.\nvalue: A number between 0 and max, or null for indeterminate progress. Specifies how much was done.\nUsage \nControlling a progress indicator \n\nTo display a progress indicator, render a <progress> component. You can pass a number value between 0 and the max value you specify. If you don’t pass a max value, it will assumed to be 1 by default.\n\nIf the operation is not ongoing, pass value={null} to put the progress indicator into an indeterminate state.\n\nApp.js\nDownload\nReload\nClear\nFork\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\nexport default function App() {\n  return (\n    <>\n      <progress value={0} />\n      <progress value={0.5} />\n      <progress value={0.7} />\n      <progress value={75} max={100} />\n      <progress value={1} />\n      <progress value={null} />\n    </>\n  );\n}\n\n\nPREVIOUS\n<option>\nNEXT\n<select>"
  },
  {
    "title": "<select> – React",
    "url": "https://react.dev/reference/react-dom/components/select",
    "html": "API REFERENCE\nCOMPONENTS\n<select>\n\nThe built-in browser <select> component lets you render a select box with options.\n\n<select>\n\n  <option value=\"someOption\">Some option</option>\n\n  <option value=\"otherOption\">Other option</option>\n\n</select>\nReference\n<select>\nUsage\nDisplaying a select box with options\nProviding a label for a select box\nProviding an initially selected option\nEnabling multiple selection\nReading the select box value when submitting a form\nControlling a select box with a state variable\nReference \n<select> \n\nTo display a select box, render the built-in browser <select> component.\n\n<select>\n\n  <option value=\"someOption\">Some option</option>\n\n  <option value=\"otherOption\">Other option</option>\n\n</select>\n\nSee more examples below.\n\nProps \n\n<select> supports all common element props.\n\nYou can make a select box controlled by passing a value prop:\n\nvalue: A string (or an array of strings for multiple={true}). Controls which option is selected. Every value string match the value of some <option> nested inside the <select>.\n\nWhen you pass value, you must also pass an onChange handler that updates the passed value.\n\nIf your <select> is uncontrolled, you may pass the defaultValue prop instead:\n\ndefaultValue: A string (or an array of strings for multiple={true}). Specifies the initially selected option.\n\nThese <select> props are relevant both for uncontrolled and controlled select boxes:\n\nautoComplete: A string. Specifies one of the possible autocomplete behaviors.\nautoFocus: A boolean. If true, React will focus the element on mount.\nchildren: <select> accepts <option>, <optgroup>, and <datalist> components as children. You can also pass your own components as long as they eventually render one of the allowed components. If you pass your own components that eventually render <option> tags, each <option> you render must have a value.\ndisabled: A boolean. If true, the select box will not be interactive and will appear dimmed.\nform: A string. Specifies the id of the <form> this select box belongs to. If omitted, it’s the closest parent form.\nmultiple: A boolean. If true, the browser allows multiple selection.\nname: A string. Specifies the name for this select box that’s submitted with the form.\nonChange: An Event handler function. Required for controlled select boxes. Fires immediately when the user picks a different option. Behaves like the browser input event.\nonChangeCapture: A version of onChange that fires in the capture phase.\nonInput: An Event handler function. Fires immediately when the value is changed by the user. For historical reasons, in React it is idiomatic to use onChange instead which works similarly.\nonInputCapture: A version of onInput that fires in the capture phase.\nonInvalid: An Event handler function. Fires if an input fails validation on form submit. Unlike the built-in invalid event, the React onInvalid event bubbles.\nonInvalidCapture: A version of onInvalid that fires in the capture phase.\nrequired: A boolean. If true, the value must be provided for the form to submit.\nsize: A number. For multiple={true} selects, specifies the preferred number of initially visible items.\nCaveats \nUnlike in HTML, passing a selected attribute to <option> is not supported. Instead, use <select defaultValue> for uncontrolled select boxes and <select value> for controlled select boxes.\nIf a select box receives a value prop, it will be treated as controlled.\nA select box can’t be both controlled and uncontrolled at the same time.\nA select box cannot switch between being controlled or uncontrolled over its lifetime.\nEvery controlled select box needs an onChange event handler that synchronously updates its backing value.\nUsage \nDisplaying a select box with options \n\nRender a <select> with a list of <option> components inside to display a select box. Give each <option> a value representing the data to be submitted with the form.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function FruitPicker() {\n  return (\n    <label>\n      Pick a fruit:\n      <select name=\"selectedFruit\">\n        <option value=\"apple\">Apple</option>\n        <option value=\"banana\">Banana</option>\n        <option value=\"orange\">Orange</option>\n      </select>\n    </label>\n  );\n}\n\n\nProviding a label for a select box \n\nTypically, you will place every <select> inside a <label> tag. This tells the browser that this label is associated with that select box. When the user clicks the label, the browser will automatically focus the select box. It’s also essential for accessibility: a screen reader will announce the label caption when the user focuses the select box.\n\nIf you can’t nest <select> into a <label>, associate them by passing the same ID to <select id> and <label htmlFor>. To avoid conflicts between multiple instances of one component, generate such an ID with useId.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useId } from 'react';\n\nexport default function Form() {\n  const vegetableSelectId = useId();\n  return (\n    <>\n      <label>\n        Pick a fruit:\n        <select name=\"selectedFruit\">\n          <option value=\"apple\">Apple</option>\n          <option value=\"banana\">Banana</option>\n          <option value=\"orange\">Orange</option>\n        </select>\n      </label>\n      <hr />\n      <label htmlFor={vegetableSelectId}>\n        Pick a vegetable:\n      </label>\n      <select id={vegetableSelectId} name=\"selectedVegetable\">\n        <option value=\"cucumber\">Cucumber</option>\n        <option value=\"corn\">Corn</option>\n        <option value=\"tomato\">Tomato</option>\n      </select>\n    </>\n  );\n}\n\n\nShow more\nProviding an initially selected option \n\nBy default, the browser will select the first <option> in the list. To select a different option by default, pass that <option>’s value as the defaultValue to the <select> element.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function FruitPicker() {\n  return (\n    <label>\n      Pick a fruit:\n      <select name=\"selectedFruit\" defaultValue=\"orange\">\n        <option value=\"apple\">Apple</option>\n        <option value=\"banana\">Banana</option>\n        <option value=\"orange\">Orange</option>\n      </select>\n    </label>\n  );\n}\n\n\nPitfall\n\nUnlike in HTML, passing a selected attribute to an individual <option> is not supported.\n\nEnabling multiple selection \n\nPass multiple={true} to the <select> to let the user select multiple options. In that case, if you also specify defaultValue to choose the initially selected options, it must be an array.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function FruitPicker() {\n  return (\n    <label>\n      Pick some fruits:\n      <select\n        name=\"selectedFruit\"\n        defaultValue={['orange', 'banana']}\n        multiple={true}\n      >\n        <option value=\"apple\">Apple</option>\n        <option value=\"banana\">Banana</option>\n        <option value=\"orange\">Orange</option>\n      </select>\n    </label>\n  );\n}\n\n\nShow more\nReading the select box value when submitting a form \n\nAdd a <form> around your select box with a <button type=\"submit\"> inside. It will call your <form onSubmit> event handler. By default, the browser will send the form data to the current URL and refresh the page. You can override that behavior by calling e.preventDefault(). Read the form data with new FormData(e.target).\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function EditPost() {\n  function handleSubmit(e) {\n    // Prevent the browser from reloading the page\n    e.preventDefault();\n    // Read the form data\n    const form = e.target;\n    const formData = new FormData(form);\n    // You can pass formData as a fetch body directly:\n    fetch('/some-api', { method: form.method, body: formData });\n    // You can generate a URL out of it, as the browser does by default:\n    console.log(new URLSearchParams(formData).toString());\n    // You can work with it as a plain object.\n    const formJson = Object.fromEntries(formData.entries());\n    console.log(formJson); // (!) This doesn't include multiple select values\n    // Or you can get an array of name-value pairs.\n    console.log([...formData.entries()]);\n  }\n\n  return (\n    <form method=\"post\" onSubmit={handleSubmit}>\n      <label>\n        Pick your favorite fruit:\n        <select name=\"selectedFruit\" defaultValue=\"orange\">\n          <option value=\"apple\">Apple</option>\n          <option value=\"banana\">Banana</option>\n          <option value=\"orange\">Orange</option>\n        </select>\n      </label>\n      <label>\n        Pick all your favorite vegetables:\n        <select\n          name=\"selectedVegetables\"\n          multiple={true}\n          defaultValue={['corn', 'tomato']}\n        >\n          <option value=\"cucumber\">Cucumber</option>\n          <option value=\"corn\">Corn</option>\n          <option value=\"tomato\">Tomato</option>\n        </select>\n      </label>\n      <hr />\n      <button type=\"reset\">Reset</button>\n      <button type=\"submit\">Submit</button>\n    </form>\n  );\n}\n\n\nShow more\nNote\n\nGive a name to your <select>, for example <select name=\"selectedFruit\" />. The name you specified will be used as a key in the form data, for example { selectedFruit: \"orange\" }.\n\nIf you use <select multiple={true}>, the FormData you’ll read from the form will include each selected value as a separate name-value pair. Look closely at the console logs in the example above.\n\nPitfall\n\nBy default, any <button> inside a <form> will submit it. This can be surprising! If you have your own custom Button React component, consider returning <button type=\"button\"> instead of <button>. Then, to be explicit, use <button type=\"submit\"> for buttons that are supposed to submit the form.\n\nControlling a select box with a state variable \n\nA select box like <select /> is uncontrolled. Even if you pass an initially selected value like <select defaultValue=\"orange\" />, your JSX only specifies the initial value, not the value right now.\n\nTo render a controlled select box, pass the value prop to it. React will force the select box to always have the value you passed. Typically, you will control a select box by declaring a state variable:\n\nfunction FruitPicker() {\n\n  const [selectedFruit, setSelectedFruit] = useState('orange'); // Declare a state variable...\n\n  // ...\n\n  return (\n\n    <select\n\n      value={selectedFruit} // ...force the select's value to match the state variable...\n\n      onChange={e => setSelectedFruit(e.target.value)} // ... and update the state variable on any change!\n\n    >\n\n      <option value=\"apple\">Apple</option>\n\n      <option value=\"banana\">Banana</option>\n\n      <option value=\"orange\">Orange</option>\n\n    </select>\n\n  );\n\n}\n\nThis is useful if you want to re-render some part of the UI in response to every selection.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function FruitPicker() {\n  const [selectedFruit, setSelectedFruit] = useState('orange');\n  const [selectedVegs, setSelectedVegs] = useState(['corn', 'tomato']);\n  return (\n    <>\n      <label>\n        Pick a fruit:\n        <select\n          value={selectedFruit}\n          onChange={e => setSelectedFruit(e.target.value)}\n        >\n          <option value=\"apple\">Apple</option>\n          <option value=\"banana\">Banana</option>\n          <option value=\"orange\">Orange</option>\n        </select>\n      </label>\n      <hr />\n      <label>\n        Pick all your favorite vegetables:\n        <select\n          multiple={true}\n          value={selectedVegs}\n          onChange={e => {\n            const options = [...e.target.selectedOptions];\n            const values = options.map(option => option.value);\n            setSelectedVegs(values);\n          }}\n        >\n          <option value=\"cucumber\">Cucumber</option>\n          <option value=\"corn\">Corn</option>\n          <option value=\"tomato\">Tomato</option>\n        </select>\n      </label>\n      <hr />\n      <p>Your favorite fruit: {selectedFruit}</p>\n      <p>Your favorite vegetables: {selectedVegs.join(', ')}</p>\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\nIf you pass value without onChange, it will be impossible to select an option. When you control a select box by passing some value to it, you force it to always have the value you passed. So if you pass a state variable as a value but forget to update that state variable synchronously during the onChange event handler, React will revert the select box after every keystroke back to the value that you specified.\n\nUnlike in HTML, passing a selected attribute to an individual <option> is not supported.\n\nPREVIOUS\n<progress>\nNEXT\n<textarea>"
  },
  {
    "title": "<textarea> – React",
    "url": "https://react.dev/reference/react-dom/components/textarea",
    "html": "API REFERENCE\nCOMPONENTS\n<textarea>\n\nThe built-in browser <textarea> component lets you render a multiline text input.\n\n<textarea />\nReference\n<textarea>\nUsage\nDisplaying a text area\nProviding a label for a text area\nProviding an initial value for a text area\nReading the text area value when submitting a form\nControlling a text area with a state variable\nTroubleshooting\nMy text area doesn’t update when I type into it\nMy text area caret jumps to the beginning on every keystroke\nI’m getting an error: “A component is changing an uncontrolled input to be controlled”\nReference \n<textarea> \n\nTo display a text area, render the built-in browser <textarea> component.\n\n<textarea name=\"postContent\" />\n\nSee more examples below.\n\nProps \n\n<textarea> supports all common element props.\n\nYou can make a text area controlled by passing a value prop:\n\nvalue: A string. Controls the text inside the text area.\n\nWhen you pass value, you must also pass an onChange handler that updates the passed value.\n\nIf your <textarea> is uncontrolled, you may pass the defaultValue prop instead:\n\ndefaultValue: A string. Specifies the initial value for a text area.\n\nThese <textarea> props are relevant both for uncontrolled and controlled text areas:\n\nautoComplete: Either 'on' or 'off'. Specifies the autocomplete behavior.\nautoFocus: A boolean. If true, React will focus the element on mount.\nchildren: <textarea> does not accept children. To set the initial value, use defaultValue.\ncols: A number. Specifies the default width in average character widths. Defaults to 20.\ndisabled: A boolean. If true, the input will not be interactive and will appear dimmed.\nform: A string. Specifies the id of the <form> this input belongs to. If omitted, it’s the closest parent form.\nmaxLength: A number. Specifies the maximum length of text.\nminLength: A number. Specifies the minimum length of text.\nname: A string. Specifies the name for this input that’s submitted with the form.\nonChange: An Event handler function. Required for controlled text areas. Fires immediately when the input’s value is changed by the user (for example, it fires on every keystroke). Behaves like the browser input event.\nonChangeCapture: A version of onChange that fires in the capture phase.\nonInput: An Event handler function. Fires immediately when the value is changed by the user. For historical reasons, in React it is idiomatic to use onChange instead which works similarly.\nonInputCapture: A version of onInput that fires in the capture phase.\nonInvalid: An Event handler function. Fires if an input fails validation on form submit. Unlike the built-in invalid event, the React onInvalid event bubbles.\nonInvalidCapture: A version of onInvalid that fires in the capture phase.\nonSelect: An Event handler function. Fires after the selection inside the <textarea> changes. React extends the onSelect event to also fire for empty selection and on edits (which may affect the selection).\nonSelectCapture: A version of onSelect that fires in the capture phase.\nplaceholder: A string. Displayed in a dimmed color when the text area value is empty.\nreadOnly: A boolean. If true, the text area is not editable by the user.\nrequired: A boolean. If true, the value must be provided for the form to submit.\nrows: A number. Specifies the default height in average character heights. Defaults to 2.\nwrap: Either 'hard', 'soft', or 'off'. Specifies how the text should be wrapped when submitting a form.\nCaveats \nPassing children like <textarea>something</textarea> is not allowed. Use defaultValue for initial content.\nIf a text area receives a string value prop, it will be treated as controlled.\nA text area can’t be both controlled and uncontrolled at the same time.\nA text area cannot switch between being controlled or uncontrolled over its lifetime.\nEvery controlled text area needs an onChange event handler that synchronously updates its backing value.\nUsage \nDisplaying a text area \n\nRender <textarea> to display a text area. You can specify its default size with the rows and cols attributes, but by default the user will be able to resize it. To disable resizing, you can specify resize: none in the CSS.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function NewPost() {\n  return (\n    <label>\n      Write your post:\n      <textarea name=\"postContent\" rows={4} cols={40} />\n    </label>\n  );\n}\n\n\nProviding a label for a text area \n\nTypically, you will place every <textarea> inside a <label> tag. This tells the browser that this label is associated with that text area. When the user clicks the label, the browser will focus the text area. It’s also essential for accessibility: a screen reader will announce the label caption when the user focuses the text area.\n\nIf you can’t nest <textarea> into a <label>, associate them by passing the same ID to <textarea id> and <label htmlFor>. To avoid conflicts between instances of one component, generate such an ID with useId.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useId } from 'react';\n\nexport default function Form() {\n  const postTextAreaId = useId();\n  return (\n    <>\n      <label htmlFor={postTextAreaId}>\n        Write your post:\n      </label>\n      <textarea\n        id={postTextAreaId}\n        name=\"postContent\"\n        rows={4}\n        cols={40}\n      />\n    </>\n  );\n}\n\n\nShow more\nProviding an initial value for a text area \n\nYou can optionally specify the initial value for the text area. Pass it as the defaultValue string.\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function EditPost() {\n  return (\n    <label>\n      Edit your post:\n      <textarea\n        name=\"postContent\"\n        defaultValue=\"I really enjoyed biking yesterday!\"\n        rows={4}\n        cols={40}\n      />\n    </label>\n  );\n}\n\n\nPitfall\n\nUnlike in HTML, passing initial text like <textarea>Some content</textarea> is not supported.\n\nReading the text area value when submitting a form \n\nAdd a <form> around your textarea with a <button type=\"submit\"> inside. It will call your <form onSubmit> event handler. By default, the browser will send the form data to the current URL and refresh the page. You can override that behavior by calling e.preventDefault(). Read the form data with new FormData(e.target).\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function EditPost() {\n  function handleSubmit(e) {\n    // Prevent the browser from reloading the page\n    e.preventDefault();\n\n    // Read the form data\n    const form = e.target;\n    const formData = new FormData(form);\n\n    // You can pass formData as a fetch body directly:\n    fetch('/some-api', { method: form.method, body: formData });\n\n    // Or you can work with it as a plain object:\n    const formJson = Object.fromEntries(formData.entries());\n    console.log(formJson);\n  }\n\n  return (\n    <form method=\"post\" onSubmit={handleSubmit}>\n      <label>\n        Post title: <input name=\"postTitle\" defaultValue=\"Biking\" />\n      </label>\n      <label>\n        Edit your post:\n        <textarea\n          name=\"postContent\"\n          defaultValue=\"I really enjoyed biking yesterday!\"\n          rows={4}\n          cols={40}\n        />\n      </label>\n      <hr />\n      <button type=\"reset\">Reset edits</button>\n      <button type=\"submit\">Save post</button>\n    </form>\n  );\n}\n\n\nShow more\nNote\n\nGive a name to your <textarea>, for example <textarea name=\"postContent\" />. The name you specified will be used as a key in the form data, for example { postContent: \"Your post\" }.\n\nPitfall\n\nBy default, any <button> inside a <form> will submit it. This can be surprising! If you have your own custom Button React component, consider returning <button type=\"button\"> instead of <button>. Then, to be explicit, use <button type=\"submit\"> for buttons that are supposed to submit the form.\n\nControlling a text area with a state variable \n\nA text area like <textarea /> is uncontrolled. Even if you pass an initial value like <textarea defaultValue=\"Initial text\" />, your JSX only specifies the initial value, not the value right now.\n\nTo render a controlled text area, pass the value prop to it. React will force the text area to always have the value you passed. Typically, you will control a text area by declaring a state variable:\n\nfunction NewPost() {\n\n  const [postContent, setPostContent] = useState(''); // Declare a state variable...\n\n  // ...\n\n  return (\n\n    <textarea\n\n      value={postContent} // ...force the input's value to match the state variable...\n\n      onChange={e => setPostContent(e.target.value)} // ... and update the state variable on any edits!\n\n    />\n\n  );\n\n}\n\nThis is useful if you want to re-render some part of the UI in response to every keystroke.\n\npackage.json\nApp.js\nMarkdownPreview.js\nReload\nClear\nFork\n{\n  \"dependencies\": {\n    \"react\": \"latest\",\n    \"react-dom\": \"latest\",\n    \"react-scripts\": \"latest\",\n    \"remarkable\": \"2.0.1\"\n  },\n  \"scripts\": {\n    \"start\": \"react-scripts start\",\n    \"build\": \"react-scripts build\",\n    \"test\": \"react-scripts test --env=jsdom\",\n    \"eject\": \"react-scripts eject\"\n  },\n  \"devDependencies\": {}\n}\nPitfall\n\nIf you pass value without onChange, it will be impossible to type into the text area. When you control a text area by passing some value to it, you force it to always have the value you passed. So if you pass a state variable as a value but forget to update that state variable synchronously during the onChange event handler, React will revert the text area after every keystroke back to the value that you specified.\n\nTroubleshooting \nMy text area doesn’t update when I type into it \n\nIf you render a text area with value but no onChange, you will see an error in the console:\n\n// 🔴 Bug: controlled text area with no onChange handler\n\n<textarea value={something} />\nConsole\nYou provided a value prop to a form field without an onChange handler. This will render a read-only field. If the field should be mutable use defaultValue. Otherwise, set either onChange or readOnly.\n\nAs the error message suggests, if you only wanted to specify the initial value, pass defaultValue instead:\n\n// ✅ Good: uncontrolled text area with an initial value\n\n<textarea defaultValue={something} />\n\nIf you want to control this text area with a state variable, specify an onChange handler:\n\n// ✅ Good: controlled text area with onChange\n\n<textarea value={something} onChange={e => setSomething(e.target.value)} />\n\nIf the value is intentionally read-only, add a readOnly prop to suppress the error:\n\n// ✅ Good: readonly controlled text area without on change\n\n<textarea value={something} readOnly={true} />\nMy text area caret jumps to the beginning on every keystroke \n\nIf you control a text area, you must update its state variable to the text area’s value from the DOM during onChange.\n\nYou can’t update it to something other than e.target.value:\n\nfunction handleChange(e) {\n\n  // 🔴 Bug: updating an input to something other than e.target.value\n\n  setFirstName(e.target.value.toUpperCase());\n\n}\n\nYou also can’t update it asynchronously:\n\nfunction handleChange(e) {\n\n  // 🔴 Bug: updating an input asynchronously\n\n  setTimeout(() => {\n\n    setFirstName(e.target.value);\n\n  }, 100);\n\n}\n\nTo fix your code, update it synchronously to e.target.value:\n\nfunction handleChange(e) {\n\n  // ✅ Updating a controlled input to e.target.value synchronously\n\n  setFirstName(e.target.value);\n\n}\n\nIf this doesn’t fix the problem, it’s possible that the text area gets removed and re-added from the DOM on every keystroke. This can happen if you’re accidentally resetting state on every re-render. For example, this can happen if the text area or one of its parents always receives a different key attribute, or if you nest component definitions (which is not allowed in React and causes the “inner” component to remount on every render).\n\nI’m getting an error: “A component is changing an uncontrolled input to be controlled” \n\nIf you provide a value to the component, it must remain a string throughout its lifetime.\n\nYou cannot pass value={undefined} first and later pass value=\"some string\" because React won’t know whether you want the component to be uncontrolled or controlled. A controlled component should always receive a string value, not null or undefined.\n\nIf your value is coming from an API or a state variable, it might be initialized to null or undefined. In that case, either set it to an empty string ('') initially, or pass value={someValue ?? ''} to ensure value is a string.\n\nPREVIOUS\n<select>\nNEXT\n<link>"
  },
  {
    "title": "<link> – React",
    "url": "https://react.dev/reference/react-dom/components/link",
    "html": "API REFERENCE\nCOMPONENTS\n<link>\n\nThe built-in browser <link> component lets you use external resources such as stylesheets or annotate the document with link metadata.\n\n<link rel=\"icon\" href=\"favicon.ico\" />\nReference\n<link>\nUsage\nLinking to related resources\nLinking to a stylesheet\nControlling stylesheet precedence\nDeduplicated stylesheet rendering\nAnnotating specific items within the document with links\nReference \n<link> \n\nTo link to external resources such as stylesheets, fonts, and icons, or to annotate the document with link metadata, render the built-in browser <link> component. You can render <link> from any component and React will in most cases place the corresponding DOM element in the document head.\n\n<link rel=\"icon\" href=\"favicon.ico\" />\n\nSee more examples below.\n\nProps \n\n<link> supports all common element props.\n\nrel: a string, required. Specifies the relationship to the resource. React treats links with rel=\"stylesheet\" differently from other links.\n\nThese props apply when rel=\"stylesheet\":\n\nprecedence: a string. Tells React where to rank the <link> DOM node relative to others in the document <head>, which determines which stylesheet can override the other. React will infer that precedence values it discovers first are “lower” and precedence values it discovers later are “higher”. Many style systems can work fine using a single precedence value because style rules are atomic. Stylesheets with the same precedence go together whether they are <link> or inline <style> tags or loaded using preinit functions.\nmedia: a string. Restricts the stylesheet to a certain media query.\ntitle: a string. Specifies the name of an alternative stylesheet.\n\nThese props apply when rel=\"stylesheet\" but disable React’s special treatment of stylesheets:\n\ndisabled: a boolean. Disables the stylesheet.\nonError: a function. Called when the stylesheet fails to load.\nonLoad: a function. Called when the stylesheet finishes being loaded.\n\nThese props apply when rel=\"preload\" or rel=\"modulepreload\":\n\nas: a string. The type of resource. Its possible values are audio, document, embed, fetch, font, image, object, script, style, track, video, worker.\nimageSrcSet: a string. Applicable only when as=\"image\". Specifies the source set of the image.\nimageSizes: a string. Applicable only when as=\"image\". Specifies the sizes of the image.\n\nThese props apply when rel=\"icon\" or rel=\"apple-touch-icon\":\n\nsizes: a string. The sizes of the icon.\n\nThese props apply in all cases:\n\nhref: a string. The URL of the linked resource.\ncrossOrigin: a string. The CORS policy to use. Its possible values are anonymous and use-credentials. It is required when as is set to \"fetch\".\nreferrerPolicy: a string. The Referrer header to send when fetching. Its possible values are no-referrer-when-downgrade (the default), no-referrer, origin, origin-when-cross-origin, and unsafe-url.\nfetchPriority: a string. Suggests a relative priority for fetching the resource. The possible values are auto (the default), high, and low.\nhrefLang: a string. The language of the linked resource.\nintegrity: a string. A cryptographic hash of the resource, to verify its authenticity.\ntype: a string. The MIME type of the linked resource.\n\nProps that are not recommended for use with React:\n\nblocking: a string. If set to \"render\", instructs the browser not to render the page until the stylesheet is loaded. React provides more fine-grained control using Suspense.\nSpecial rendering behavior \n\nReact will always place the DOM element corresponding to the <link> component within the document’s <head>, regardless of where in the React tree it is rendered. The <head> is the only valid place for <link> to exist within the DOM, yet it’s convenient and keeps things composable if a component representing a specific page can render <link> components itself.\n\nThere are a few exceptions to this:\n\nIf the <link> has a rel=\"stylesheet\" prop, then it has to also have a precedence prop to get this special behavior. This is because the order of stylesheets within the document is significant, so React needs to know how to order this stylesheet relative to others, which you specify using the precedence prop. If the precedence prop is omitted, there is no special behavior.\nIf the <link> has an itemProp prop, there is no special behavior, because in this case it doesn’t apply to the document but instead represents metadata about a specific part of the page.\nIf the <link> has an onLoad or onError prop, because in that case you are managing the loading of the linked resource manually within your React component.\nSpecial behavior for stylesheets \n\nIn addition, if the <link> is to a stylesheet (namely, it has rel=\"stylesheet\" in its props), React treats it specially in the following ways:\n\nThe component that renders <link> will suspend while the stylesheet is loading.\nIf multiple components render links to the same stylesheet, React will de-duplicate them and only put a single link into the DOM. Two links are considered the same if they have the same href prop.\n\nThere are two exception to this special behavior:\n\nIf the link doesn’t have a precedence prop, there is no special behavior, because the order of stylesheets within the document is significant, so React needs to know how to order this stylesheet relative to others, which you specify using the precedence prop.\nIf you supply any of the onLoad, onError, or disabled props, there is no special behavior, because these props indicate that you are managing the loading of the stylesheet manually within your component.\n\nThis special treatment comes with two caveats:\n\nReact will ignore changes to props after the link has been rendered. (React will issue a warning in development if this happens.)\nReact may leave the link in the DOM even after the component that rendered it has been unmounted.\nUsage \nLinking to related resources \n\nYou can annotate the document with links to related resources such as an icon, canonical URL, or pingback. React will place this metadata within the document <head> regardless of where in the React tree it is rendered.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nexport default function BlogPage() {\n  return (\n    <ShowRenderedHTML>\n      <link rel=\"icon\" href=\"favicon.ico\" />\n      <link rel=\"pingback\" href=\"http://www.example.com/xmlrpc.php\" />\n      <h1>My Blog</h1>\n      <p>...</p>\n    </ShowRenderedHTML>\n  );\n}\n\n\nLinking to a stylesheet \n\nIf a component depends on a certain stylesheet in order to be displayed correctly, you can render a link to that stylesheet within the component. Your component will suspend while the stylesheet is loading. You must supply the precedence prop, which tells React where to place this stylesheet relative to others — stylesheets with higher precedence can override those with lower precedence.\n\nNote\n\nWhen you want to use a stylesheet, it can be beneficial to call the preinit function. Calling this function may allow the browser to start fetching the stylesheet earlier than if you just render a <link> component, for example by sending an HTTP Early Hints response.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nexport default function SiteMapPage() {\n  return (\n    <ShowRenderedHTML>\n      <link rel=\"stylesheet\" href=\"sitemap.css\" precedence=\"medium\" />\n      <p>...</p>\n    </ShowRenderedHTML>\n  );\n}\n\n\nControlling stylesheet precedence \n\nStylesheets can conflict with each other, and when they do, the browser goes with the one that comes later in the document. React lets you control the order of stylesheets with the precedence prop. In this example, three components render stylesheets, and the ones with the same precedence are grouped together in the <head>.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nexport default function HomePage() {\n  return (\n    <ShowRenderedHTML>\n      <FirstComponent />\n      <SecondComponent />\n      <ThirdComponent/>\n      ...\n    </ShowRenderedHTML>\n  );\n}\n\nfunction FirstComponent() {\n  return <link rel=\"stylesheet\" href=\"first.css\" precedence=\"first\" />;\n}\n\nfunction SecondComponent() {\n  return <link rel=\"stylesheet\" href=\"second.css\" precedence=\"second\" />;\n}\n\nfunction ThirdComponent() {\n  return <link rel=\"stylesheet\" href=\"third.css\" precedence=\"first\" />;\n}\n\n\nShow more\n\nNote the precedence values themselves are arbitrary and their naming is up to you. React will infer that precedence values it discovers first are “lower” and precedence values it discovers later are “higher”.\n\nDeduplicated stylesheet rendering \n\nIf you render the same stylesheet from multiple components, React will place only a single <link> in the document head.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nexport default function HomePage() {\n  return (\n    <ShowRenderedHTML>\n      <Component />\n      <Component />\n      ...\n    </ShowRenderedHTML>\n  );\n}\n\nfunction Component() {\n  return <link rel=\"stylesheet\" href=\"styles.css\" precedence=\"medium\" />;\n}\n\n\nAnnotating specific items within the document with links \n\nYou can use the <link> component with the itemProp prop to annotate specific items within the document with links to related resources. In this case, React will not place these annotations within the document <head> but will place them like any other React component.\n\n<section itemScope>\n\n  <h3>Annotating specific items</h3>\n\n  <link itemProp=\"author\" href=\"http://example.com/\" />\n\n  <p>...</p>\n\n</section>\nPREVIOUS\n<textarea>\nNEXT\n<meta>"
  },
  {
    "title": "<script> – React",
    "url": "https://react.dev/reference/react-dom/components/script",
    "html": "API REFERENCE\nCOMPONENTS\n<script>\n\nThe built-in browser <script> component lets you add a script to your document.\n\n<script> alert(\"hi!\") </script>\nReference\n<script>\nUsage\nRendering an external script\nRendering an inline script\nReference \n<script> \n\nTo add inline or external scripts to your document, render the built-in browser <script> component. You can render <script> from any component and React will in certain cases place the corresponding DOM element in the document head and de-duplicate identical scripts.\n\n<script> alert(\"hi!\") </script>\n\n<script src=\"script.js\" />\n\nSee more examples below.\n\nProps \n\n<script> supports all common element props.\n\nIt should have either children or a src prop.\n\nchildren: a string. The source code of an inline script.\nsrc: a string. The URL of an external script.\n\nOther supported props:\n\nasync: a boolean. Allows the browser to defer execution of the script until the rest of the document has been processed — the preferred behavior for performance.\ncrossOrigin: a string. The CORS policy to use. Its possible values are anonymous and use-credentials.\nfetchPriority: a string. Lets the browser rank scripts in priority when fetching multiple scripts at the same time. Can be \"high\", \"low\", or \"auto\" (the default).\nintegrity: a string. A cryptographic hash of the script, to verify its authenticity.\nnoModule: a boolean. Disables the script in browsers that support ES modules — allowing for a fallback script for browsers that do not.\nnonce: a string. A cryptographic nonce to allow the resource when using a strict Content Security Policy.\nreferrer: a string. Says what Referer header to send when fetching the script and any resources that the script fetches in turn.\ntype: a string. Says whether the script is a classic script, ES module, or import map.\n\nProps that disable React’s special treatment of scripts:\n\nonError: a function. Called when the script fails to load.\nonLoad: a function. Called when the script finishes being loaded.\n\nProps that are not recommended for use with React:\n\nblocking: a string. If set to \"render\", instructs the browser not to render the page until the scriptsheet is loaded. React provides more fine-grained control using Suspense.\ndefer: a string. Prevents the browser from executing the script until the document is done loading. Not compatible with streaming server-rendered components. Use the async prop instead.\nSpecial rendering behavior \n\nReact can move <script> components to the document’s <head> and de-duplicate identical scripts.\n\nTo opt into this behavior, provide the src and async={true} props. React will de-duplicate scripts if they have the same src. The async prop must be true to allow scripts to be safely moved.\n\nThis special treatment comes with two caveats:\n\nReact will ignore changes to props after the script has been rendered. (React will issue a warning in development if this happens.)\nReact may leave the script in the DOM even after the component that rendered it has been unmounted. (This has no effect as scripts just execute once when they are inserted into the DOM.)\nUsage \nRendering an external script \n\nIf a component depends on certain scripts in order to be displayed correctly, you can render a <script> within the component.\nHowever, the component might be committed before the script has finished loading.\nYou can start depending on the script content once the load event is fired e.g. by using the onLoad prop.\n\nReact will de-duplicate scripts that have the same src, inserting only one of them into the DOM even if multiple components render it.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nfunction Map({lat, long}) {\n  return (\n    <>\n      <script async src=\"map-api.js\" onLoad={() => console.log('script loaded')} />\n      <div id=\"map\" data-lat={lat} data-long={long} />\n    </>\n  );\n}\n\nexport default function Page() {\n  return (\n    <ShowRenderedHTML>\n      <Map />\n    </ShowRenderedHTML>\n  );\n}\n\n\nShow more\nNote\n\nWhen you want to use a script, it can be beneficial to call the preinit function. Calling this function may allow the browser to start fetching the script earlier than if you just render a <script> component, for example by sending an HTTP Early Hints response.\n\nRendering an inline script \n\nTo include an inline script, render the <script> component with the script source code as its children. Inline scripts are not de-duplicated or moved to the document <head>.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nfunction Tracking() {\n  return (\n    <script>\n      ga('send', 'pageview');\n    </script>\n  );\n}\n\nexport default function Page() {\n  return (\n    <ShowRenderedHTML>\n      <h1>My Website</h1>\n      <Tracking />\n      <p>Welcome</p>\n    </ShowRenderedHTML>\n  );\n}\n\n\nShow more\nPREVIOUS\n<meta>\nNEXT\n<style>"
  },
  {
    "title": "<style> – React",
    "url": "https://react.dev/reference/react-dom/components/style",
    "html": "API REFERENCE\nCOMPONENTS\n<style>\n\nThe built-in browser <style> component lets you add inline CSS stylesheets to your document.\n\n<style>{` p { color: red; } `}</style>\nReference\n<style>\nUsage\nRendering an inline CSS stylesheet\nReference \n<style> \n\nTo add inline styles to your document, render the built-in browser <style> component. You can render <style> from any component and React will in certain cases place the corresponding DOM element in the document head and de-duplicate identical styles.\n\n<style>{` p { color: red; } `}</style>\n\nSee more examples below.\n\nProps \n\n<style> supports all common element props.\n\nchildren: a string, required. The contents of the stylesheet.\nprecedence: a string. Tells React where to rank the <style> DOM node relative to others in the document <head>, which determines which stylesheet can override the other. React will infer that precedence values it discovers first are “lower” and precedence values it discovers later are “higher”. Many style systems can work fine using a single precedence value because style rules are atomic. Stylesheets with the same precedence go together whether they are <link> or inline <style> tags or loaded using preinit functions.\nhref: a string. Allows React to de-duplicate styles that have the same href.\nmedia: a string. Restricts the stylesheet to a certain media query.\nnonce: a string. A cryptographic nonce to allow the resource when using a strict Content Security Policy.\ntitle: a string. Specifies the name of an alternative stylesheet.\n\nProps that are not recommended for use with React:\n\nblocking: a string. If set to \"render\", instructs the browser not to render the page until the stylesheet is loaded. React provides more fine-grained control using Suspense.\nSpecial rendering behavior \n\nReact can move <style> components to the document’s <head>, de-duplicate identical stylesheets, and suspend while the stylesheet is loading.\n\nTo opt into this behavior, provide the href and precedence props. React will de-duplicate styles if they have the same href. The precedence prop tells React where to rank the <style> DOM node relative to others in the document <head>, which determines which stylesheet can override the other.\n\nThis special treatment comes with three caveats:\n\nReact will ignore changes to props after the style has been rendered. (React will issue a warning in development if this happens.)\nReact will drop all extraneous props when using the precedence prop (beyond href and precedence).\nReact may leave the style in the DOM even after the component that rendered it has been unmounted.\nUsage \nRendering an inline CSS stylesheet \n\nIf a component depends on certain CSS styles in order to be displayed correctly, you can render an inline stylesheet within the component.\n\nThe href prop should uniquely identify the stylesheet, because React will de-duplicate stylesheets that have the same href.\nIf you supply a precedence prop, React will reorder inline stylesheets based on the order these values appear in the component tree.\n\nInline stylesheets will not trigger Suspense boundaries while they’re loading.\nEven if they load async resources like fonts or images.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\nimport { useId } from 'react';\n\nfunction PieChart({data, colors}) {\n  const id = useId();\n  const stylesheet = colors.map((color, index) =>\n    `#${id} .color-${index}: \\{ color: \"${color}\"; \\}`\n  ).join();\n  return (\n    <>\n      <style href={\"PieChart-\" + JSON.stringify(colors)} precedence=\"medium\">\n        {stylesheet}\n      </style>\n      <svg id={id}>\n        …\n      </svg>\n    </>\n  );\n}\n\nexport default function App() {\n  return (\n    <ShowRenderedHTML>\n      <PieChart data=\"...\" colors={['red', 'green', 'blue']} />\n    </ShowRenderedHTML>\n  );\n}\n\n\nShow more\nPREVIOUS\n<script>\nNEXT\n<title>"
  },
  {
    "title": "<meta> – React",
    "url": "https://react.dev/reference/react-dom/components/meta",
    "html": "API REFERENCE\nCOMPONENTS\n<meta>\n\nThe built-in browser <meta> component lets you add metadata to the document.\n\n<meta name=\"keywords\" content=\"React, JavaScript, semantic markup, html\" />\nReference\n<meta>\nUsage\nAnnotating the document with metadata\nAnnotating specific items within the document with metadata\nReference \n<meta> \n\nTo add document metadata, render the built-in browser <meta> component. You can render <meta> from any component and React will always place the corresponding DOM element in the document head.\n\n<meta name=\"keywords\" content=\"React, JavaScript, semantic markup, html\" />\n\nSee more examples below.\n\nProps \n\n<meta> supports all common element props.\n\nIt should have exactly one of the following props: name, httpEquiv, charset, itemProp. The <meta> component does something different depending on which of these props is specified.\n\nname: a string. Specifies the kind of metadata to be attached to the document.\ncharset: a string. Specifies the character set used by the document. The only valid value is \"utf-8\".\nhttpEquiv: a string. Specifies a directive for processing the document.\nitemProp: a string. Specifies metadata about a particular item within the document rather than the document as a whole.\ncontent: a string. Specifies the metadata to be attached when used with the name or itemProp props or the behavior of the directive when used with the httpEquiv prop.\nSpecial rendering behavior \n\nReact will always place the DOM element corresponding to the <meta> component within the document’s <head>, regardless of where in the React tree it is rendered. The <head> is the only valid place for <meta> to exist within the DOM, yet it’s convenient and keeps things composable if a component representing a specific page can render <meta> components itself.\n\nThere is one exception to this: if <meta> has an itemProp prop, there is no special behavior, because in this case it doesn’t represent metadata about the document but rather metadata about a specific part of the page.\n\nUsage \nAnnotating the document with metadata \n\nYou can annotate the document with metadata such as keywords, a summary, or the author’s name. React will place this metadata within the document <head> regardless of where in the React tree it is rendered.\n\n<meta name=\"author\" content=\"John Smith\" />\n\n<meta name=\"keywords\" content=\"React, JavaScript, semantic markup, html\" />\n\n<meta name=\"description\" content=\"API reference for the <meta> component in React DOM\" />\n\nYou can render the <meta> component from any component. React will put a <meta> DOM node in the document <head>.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nexport default function SiteMapPage() {\n  return (\n    <ShowRenderedHTML>\n      <meta name=\"keywords\" content=\"React\" />\n      <meta name=\"description\" content=\"A site map for the React website\" />\n      <h1>Site Map</h1>\n      <p>...</p>\n    </ShowRenderedHTML>\n  );\n}\n\n\nAnnotating specific items within the document with metadata \n\nYou can use the <meta> component with the itemProp prop to annotate specific items within the document with metadata. In this case, React will not place these annotations within the document <head> but will place them like any other React component.\n\n<section itemScope>\n\n  <h3>Annotating specific items</h3>\n\n  <meta itemProp=\"description\" content=\"API reference for using <meta> with itemProp\" />\n\n  <p>...</p>\n\n</section>\nPREVIOUS\n<link>\nNEXT\n<script>"
  },
  {
    "title": "<title> – React",
    "url": "https://react.dev/reference/react-dom/components/title",
    "html": "API REFERENCE\nCOMPONENTS\n<title>\n\nThe built-in browser <title> component lets you specify the title of the document.\n\n<title>My Blog</title>\nReference\n<title>\nUsage\nSet the document title\nUse variables in the title\nReference \n<title> \n\nTo specify the title of the document, render the built-in browser <title> component. You can render <title> from any component and React will always place the corresponding DOM element in the document head.\n\n<title>My Blog</title>\n\nSee more examples below.\n\nProps \n\n<title> supports all common element props.\n\nchildren: <title> accepts only text as a child. This text will become the title of the document. You can also pass your own components as long as they only render text.\nSpecial rendering behavior \n\nReact will always place the DOM element corresponding to the <title> component within the document’s <head>, regardless of where in the React tree it is rendered. The <head> is the only valid place for <title> to exist within the DOM, yet it’s convenient and keeps things composable if a component representing a specific page can render its <title> itself.\n\nThere are two exception to this:\n\nIf <title> is within an <svg> component, then there is no special behavior, because in this context it doesn’t represent the document’s title but rather is an accessibility annotation for that SVG graphic.\nIf the <title> has an itemProp prop, there is no special behavior, because in this case it doesn’t represent the document’s title but rather metadata about a specific part of the page.\nPitfall\n\nOnly render a single <title> at a time. If more than one component renders a <title> tag at the same time, React will place all of those titles in the document head. When this happens, the behavior of browsers and search engines is undefined.\n\nUsage \nSet the document title \n\nRender the <title> component from any component with text as its children. React will put a <title> DOM node in the document <head>.\n\nApp.js\nShowRenderedHTML.js\nReload\nClear\nFork\nimport ShowRenderedHTML from './ShowRenderedHTML.js';\n\nexport default function ContactUsPage() {\n  return (\n    <ShowRenderedHTML>\n      <title>My Site: Contact Us</title>\n      <h1>Contact Us</h1>\n      <p>Email us at support@example.com</p>\n    </ShowRenderedHTML>\n  );\n}\n\n\nUse variables in the title \n\nThe children of the <title> component must be a single string of text. (Or a single number or a single object with a toString method.) It might not be obvious, but using JSX curly braces like this:\n\n<title>Results page {pageNumber}</title> // 🔴 Problem: This is not a single string\n\n… actually causes the <title> component to get a two-element array as its children (the string \"Results page\" and the value of pageNumber). This will cause an error. Instead, use string interpolation to pass <title> a single string:\n\n<title>{`Results page ${pageNumber}`}</title>\nPREVIOUS\n<style>\nNEXT\nAPIs"
  },
  {
    "title": "createPortal – React",
    "url": "https://react.dev/reference/react-dom/createPortal",
    "html": "API REFERENCE\nAPIS\ncreatePortal\n\ncreatePortal lets you render some children into a different part of the DOM.\n\n<div>\n\n  <SomeComponent />\n\n  {createPortal(children, domNode, key?)}\n\n</div>\nReference\ncreatePortal(children, domNode, key?)\nUsage\nRendering to a different part of the DOM\nRendering a modal dialog with a portal\nRendering React components into non-React server markup\nRendering React components into non-React DOM nodes\nReference \ncreatePortal(children, domNode, key?) \n\nTo create a portal, call createPortal, passing some JSX, and the DOM node where it should be rendered:\n\nimport { createPortal } from 'react-dom';\n\n\n\n// ...\n\n\n\n<div>\n\n  <p>This child is placed in the parent div.</p>\n\n  {createPortal(\n\n    <p>This child is placed in the document body.</p>,\n\n    document.body\n\n  )}\n\n</div>\n\nSee more examples below.\n\nA portal only changes the physical placement of the DOM node. In every other way, the JSX you render into a portal acts as a child node of the React component that renders it. For example, the child can access the context provided by the parent tree, and events bubble up from children to parents according to the React tree.\n\nParameters \n\nchildren: Anything that can be rendered with React, such as a piece of JSX (e.g. <div /> or <SomeComponent />), a Fragment (<>...</>), a string or a number, or an array of these.\n\ndomNode: Some DOM node, such as those returned by document.getElementById(). The node must already exist. Passing a different DOM node during an update will cause the portal content to be recreated.\n\noptional key: A unique string or number to be used as the portal’s key.\n\nReturns \n\ncreatePortal returns a React node that can be included into JSX or returned from a React component. If React encounters it in the render output, it will place the provided children inside the provided domNode.\n\nCaveats \nEvents from portals propagate according to the React tree rather than the DOM tree. For example, if you click inside a portal, and the portal is wrapped in <div onClick>, that onClick handler will fire. If this causes issues, either stop the event propagation from inside the portal, or move the portal itself up in the React tree.\nUsage \nRendering to a different part of the DOM \n\nPortals let your components render some of their children into a different place in the DOM. This lets a part of your component “escape” from whatever containers it may be in. For example, a component can display a modal dialog or a tooltip that appears above and outside of the rest of the page.\n\nTo create a portal, render the result of createPortal with some JSX and the DOM node where it should go:\n\nimport { createPortal } from 'react-dom';\n\n\n\nfunction MyComponent() {\n\n  return (\n\n    <div style={{ border: '2px solid black' }}>\n\n      <p>This child is placed in the parent div.</p>\n\n      {createPortal(\n\n        <p>This child is placed in the document body.</p>,\n\n        document.body\n\n      )}\n\n    </div>\n\n  );\n\n}\n\nReact will put the DOM nodes for the JSX you passed inside of the DOM node you provided.\n\nWithout a portal, the second <p> would be placed inside the parent <div>, but the portal “teleported” it into the document.body:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createPortal } from 'react-dom';\n\nexport default function MyComponent() {\n  return (\n    <div style={{ border: '2px solid black' }}>\n      <p>This child is placed in the parent div.</p>\n      {createPortal(\n        <p>This child is placed in the document body.</p>,\n        document.body\n      )}\n    </div>\n  );\n}\n\n\n\nNotice how the second paragraph visually appears outside the parent <div> with the border. If you inspect the DOM structure with developer tools, you’ll see that the second <p> got placed directly into the <body>:\n\n<body>\n\n  <div id=\"root\">\n\n    ...\n\n      <div style=\"border: 2px solid black\">\n\n        <p>This child is placed inside the parent div.</p>\n\n      </div>\n\n    ...\n\n  </div>\n\n  <p>This child is placed in the document body.</p>\n\n</body>\n\nA portal only changes the physical placement of the DOM node. In every other way, the JSX you render into a portal acts as a child node of the React component that renders it. For example, the child can access the context provided by the parent tree, and events still bubble up from children to parents according to the React tree.\n\nRendering a modal dialog with a portal \n\nYou can use a portal to create a modal dialog that floats above the rest of the page, even if the component that summons the dialog is inside a container with overflow: hidden or other styles that interfere with the dialog.\n\nIn this example, the two containers have styles that disrupt the modal dialog, but the one rendered into a portal is unaffected because, in the DOM, the modal is not contained within the parent JSX elements.\n\nApp.js\nNoPortalExample.js\nPortalExample.js\nModalContent.js\nReload\nClear\nFork\nimport NoPortalExample from './NoPortalExample';\nimport PortalExample from './PortalExample';\n\nexport default function App() {\n  return (\n    <>\n      <div className=\"clipping-container\">\n        <NoPortalExample  />\n      </div>\n      <div className=\"clipping-container\">\n        <PortalExample />\n      </div>\n    </>\n  );\n}\n\n\nPitfall\n\nIt’s important to make sure that your app is accessible when using portals. For instance, you may need to manage keyboard focus so that the user can move the focus in and out of the portal in a natural way.\n\nFollow the WAI-ARIA Modal Authoring Practices when creating modals. If you use a community package, ensure that it is accessible and follows these guidelines.\n\nRendering React components into non-React server markup \n\nPortals can be useful if your React root is only part of a static or server-rendered page that isn’t built with React. For example, if your page is built with a server framework like Rails, you can create areas of interactivity within static areas such as sidebars. Compared with having multiple separate React roots, portals let you treat the app as a single React tree with shared state even though its parts render to different parts of the DOM.\n\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nimport { createPortal } from 'react-dom';\n\nconst sidebarContentEl = document.getElementById('sidebar-content');\n\nexport default function App() {\n  return (\n    <>\n      <MainContent />\n      {createPortal(\n        <SidebarContent />,\n        sidebarContentEl\n      )}\n    </>\n  );\n}\n\nfunction MainContent() {\n  return <p>This part is rendered by React</p>;\n}\n\nfunction SidebarContent() {\n  return <p>This part is also rendered by React!</p>;\n}\n\n\nShow more\nRendering React components into non-React DOM nodes \n\nYou can also use a portal to manage the content of a DOM node that’s managed outside of React. For example, suppose you’re integrating with a non-React map widget and you want to render React content inside a popup. To do this, declare a popupContainer state variable to store the DOM node you’re going to render into:\n\nconst [popupContainer, setPopupContainer] = useState(null);\n\nWhen you create the third-party widget, store the DOM node returned by the widget so you can render into it:\n\nuseEffect(() => {\n\n  if (mapRef.current === null) {\n\n    const map = createMapWidget(containerRef.current);\n\n    mapRef.current = map;\n\n    const popupDiv = addPopupToMapWidget(map);\n\n    setPopupContainer(popupDiv);\n\n  }\n\n}, []);\n\nThis lets you use createPortal to render React content into popupContainer once it becomes available:\n\nreturn (\n\n  <div style={{ width: 250, height: 250 }} ref={containerRef}>\n\n    {popupContainer !== null && createPortal(\n\n      <p>Hello from React!</p>,\n\n      popupContainer\n\n    )}\n\n  </div>\n\n);\n\nHere is a complete example you can play with:\n\nApp.js\nmap-widget.js\nReload\nClear\nFork\nimport { useRef, useEffect, useState } from 'react';\nimport { createPortal } from 'react-dom';\nimport { createMapWidget, addPopupToMapWidget } from './map-widget.js';\n\nexport default function Map() {\n  const containerRef = useRef(null);\n  const mapRef = useRef(null);\n  const [popupContainer, setPopupContainer] = useState(null);\n\n  useEffect(() => {\n    if (mapRef.current === null) {\n      const map = createMapWidget(containerRef.current);\n      mapRef.current = map;\n      const popupDiv = addPopupToMapWidget(map);\n      setPopupContainer(popupDiv);\n    }\n  }, []);\n\n  return (\n    <div style={{ width: 250, height: 250 }} ref={containerRef}>\n      {popupContainer !== null && createPortal(\n        <p>Hello from React!</p>,\n        popupContainer\n      )}\n    </div>\n  );\n}\n\n\nShow more\nPREVIOUS\nAPIs\nNEXT\nflushSync"
  },
  {
    "title": "flushSync – React",
    "url": "https://react.dev/reference/react-dom/flushSync",
    "html": "API REFERENCE\nAPIS\nflushSync\nPitfall\n\nUsing flushSync is uncommon and can hurt the performance of your app.\n\nflushSync lets you force React to flush any updates inside the provided callback synchronously. This ensures that the DOM is updated immediately.\n\nflushSync(callback)\nReference\nflushSync(callback)\nUsage\nFlushing updates for third-party integrations\nTroubleshooting\nI’m getting an error: “flushSync was called from inside a lifecycle method”\nReference \nflushSync(callback) \n\nCall flushSync to force React to flush any pending work and update the DOM synchronously.\n\nimport { flushSync } from 'react-dom';\n\n\n\nflushSync(() => {\n\n  setSomething(123);\n\n});\n\nMost of the time, flushSync can be avoided. Use flushSync as last resort.\n\nSee more examples below.\n\nParameters \ncallback: A function. React will immediately call this callback and flush any updates it contains synchronously. It may also flush any pending updates, or Effects, or updates inside of Effects. If an update suspends as a result of this flushSync call, the fallbacks may be re-shown.\nReturns \n\nflushSync returns undefined.\n\nCaveats \nflushSync can significantly hurt performance. Use sparingly.\nflushSync may force pending Suspense boundaries to show their fallback state.\nflushSync may run pending Effects and synchronously apply any updates they contain before returning.\nflushSync may flush updates outside the callback when necessary to flush the updates inside the callback. For example, if there are pending updates from a click, React may flush those before flushing the updates inside the callback.\nUsage \nFlushing updates for third-party integrations \n\nWhen integrating with third-party code such as browser APIs or UI libraries, it may be necessary to force React to flush updates. Use flushSync to force React to flush any state updates inside the callback synchronously:\n\nflushSync(() => {\n\n  setSomething(123);\n\n});\n\n// By this line, the DOM is updated.\n\nThis ensures that, by the time the next line of code runs, React has already updated the DOM.\n\nUsing flushSync is uncommon, and using it often can significantly hurt the performance of your app. If your app only uses React APIs, and does not integrate with third-party libraries, flushSync should be unnecessary.\n\nHowever, it can be helpful for integrating with third-party code like browser APIs.\n\nSome browser APIs expect results inside of callbacks to be written to the DOM synchronously, by the end of the callback, so the browser can do something with the rendered DOM. In most cases, React handles this for you automatically. But in some cases it may be necessary to force a synchronous update.\n\nFor example, the browser onbeforeprint API allows you to change the page immediately before the print dialog opens. This is useful for applying custom print styles that allow the document to display better for printing. In the example below, you use flushSync inside of the onbeforeprint callback to immediately “flush” the React state to the DOM. Then, by the time the print dialog opens, isPrinting displays “yes”:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { flushSync } from 'react-dom';\n\nexport default function PrintApp() {\n  const [isPrinting, setIsPrinting] = useState(false);\n\n  useEffect(() => {\n    function handleBeforePrint() {\n      flushSync(() => {\n        setIsPrinting(true);\n      })\n    }\n\n    function handleAfterPrint() {\n      setIsPrinting(false);\n    }\n\n    window.addEventListener('beforeprint', handleBeforePrint);\n    window.addEventListener('afterprint', handleAfterPrint);\n    return () => {\n      window.removeEventListener('beforeprint', handleBeforePrint);\n      window.removeEventListener('afterprint', handleAfterPrint);\n    }\n  }, []);\n\n  return (\n    <>\n      <h1>isPrinting: {isPrinting ? 'yes' : 'no'}</h1>\n      <button onClick={() => window.print()}>\n        Print\n      </button>\n    </>\n  );\n}\n\n\nShow more\n\nWithout flushSync, the print dialog will display isPrinting as “no”. This is because React batches the updates asynchronously and the print dialog is displayed before the state is updated.\n\nPitfall\n\nflushSync can significantly hurt performance, and may unexpectedly force pending Suspense boundaries to show their fallback state.\n\nMost of the time, flushSync can be avoided, so use flushSync as a last resort.\n\nTroubleshooting \nI’m getting an error: “flushSync was called from inside a lifecycle method” \n\nReact cannot flushSync in the middle of a render. If you do, it will noop and warn:\n\nConsole\nWarning: flushSync was called from inside a lifecycle method. React cannot flush when React is already rendering. Consider moving this call to a scheduler task or micro task.\n\nThis includes calling flushSync inside:\n\nrendering a component.\nuseLayoutEffect or useEffect hooks.\nClass component lifecycle methods.\n\nFor example, calling flushSync in an Effect will noop and warn:\n\nimport { useEffect } from 'react';\n\nimport { flushSync } from 'react-dom';\n\n\n\nfunction MyComponent() {\n\n  useEffect(() => {\n\n    // 🚩 Wrong: calling flushSync inside an effect\n\n    flushSync(() => {\n\n      setSomething(newValue);\n\n    });\n\n  }, []);\n\n\n\n  return <div>{/* ... */}</div>;\n\n}\n\nTo fix this, you usually want to move the flushSync call to an event:\n\nfunction handleClick() {\n\n  // ✅ Correct: flushSync in event handlers is safe\n\n  flushSync(() => {\n\n    setSomething(newValue);\n\n  });\n\n}\n\nIf it’s difficult to move to an event, you can defer flushSync in a microtask:\n\nuseEffect(() => {\n\n  // ✅ Correct: defer flushSync to a microtask\n\n  queueMicrotask(() => {\n\n    flushSync(() => {\n\n      setSomething(newValue);\n\n    });\n\n  });\n\n}, []);\n\nThis will allow the current render to finish and schedule another syncronous render to flush the updates.\n\nPitfall\n\nflushSync can significantly hurt performance, but this particular pattern is even worse for performance. Exhaust all other options before calling flushSync in a microtask as an escape hatch.\n\nPREVIOUS\ncreatePortal\nNEXT\npreconnect"
  },
  {
    "title": "preconnect – React",
    "url": "https://react.dev/reference/react-dom/preconnect",
    "html": "API REFERENCE\nAPIS\npreconnect\n\npreconnect lets you eagerly connect to a server that you expect to load resources from.\n\npreconnect(\"https://example.com\");\nReference\npreconnect(href)\nUsage\nPreconnecting when rendering\nPreconnecting in an event handler\nReference \npreconnect(href) \n\nTo preconnect to a host, call the preconnect function from react-dom.\n\nimport { preconnect } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preconnect(\"https://example.com\");\n\n  // ...\n\n}\n\nSee more examples below.\n\nThe preconnect function provides the browser with a hint that it should open a connection to the given server. If the browser chooses to do so, this can speed up the loading of resources from that server.\n\nParameters \nhref: a string. The URL of the server you want to connect to.\nReturns \n\npreconnect returns nothing.\n\nCaveats \nMultiple calls to preconnect with the same server have the same effect as a single call.\nIn the browser, you can call preconnect in any situation: while rendering a component, in an Effect, in an event handler, and so on.\nIn server-side rendering or when rendering Server Components, preconnect only has an effect if you call it while rendering a component or in an async context originating from rendering a component. Any other calls will be ignored.\nIf you know the specific resources you’ll need, you can call other functions instead that will start loading the resources right away.\nThere is no benefit to preconnecting to the same server the webpage itself is hosted from because it’s already been connected to by the time the hint would be given.\nUsage \nPreconnecting when rendering \n\nCall preconnect when rendering a component if you know that its children will load external resources from that host.\n\nimport { preconnect } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preconnect(\"https://example.com\");\n\n  return ...;\n\n}\nPreconnecting in an event handler \n\nCall preconnect in an event handler before transitioning to a page or state where external resources will be needed. This gets the process started earlier than if you call it during the rendering of the new page or state.\n\nimport { preconnect } from 'react-dom';\n\n\n\nfunction CallToAction() {\n\n  const onClick = () => {\n\n    preconnect('http://example.com');\n\n    startWizard();\n\n  }\n\n  return (\n\n    <button onClick={onClick}>Start Wizard</button>\n\n  );\n\n}\nPREVIOUS\nflushSync\nNEXT\nprefetchDNS"
  },
  {
    "title": "prefetchDNS – React",
    "url": "https://react.dev/reference/react-dom/prefetchDNS",
    "html": "API REFERENCE\nAPIS\nprefetchDNS\n\nprefetchDNS lets you eagerly look up the IP of a server that you expect to load resources from.\n\nprefetchDNS(\"https://example.com\");\nReference\nprefetchDNS(href)\nUsage\nPrefetching DNS when rendering\nPrefetching DNS in an event handler\nReference \nprefetchDNS(href) \n\nTo look up a host, call the prefetchDNS function from react-dom.\n\nimport { prefetchDNS } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  prefetchDNS(\"https://example.com\");\n\n  // ...\n\n}\n\nSee more examples below.\n\nThe prefetchDNS function provides the browser with a hint that it should look up the IP address of a given server. If the browser chooses to do so, this can speed up the loading of resources from that server.\n\nParameters \nhref: a string. The URL of the server you want to connect to.\nReturns \n\nprefetchDNS returns nothing.\n\nCaveats \nMultiple calls to prefetchDNS with the same server have the same effect as a single call.\nIn the browser, you can call prefetchDNS in any situation: while rendering a component, in an Effect, in an event handler, and so on.\nIn server-side rendering or when rendering Server Components, prefetchDNS only has an effect if you call it while rendering a component or in an async context originating from rendering a component. Any other calls will be ignored.\nIf you know the specific resources you’ll need, you can call other functions instead that will start loading the resources right away.\nThere is no benefit to prefetching the same server the webpage itself is hosted from because it’s already been looked up by the time the hint would be given.\nCompared with preconnect, prefetchDNS may be better if you are speculatively connecting to a large number of domains, in which case the overhead of preconnections might outweigh the benefit.\nUsage \nPrefetching DNS when rendering \n\nCall prefetchDNS when rendering a component if you know that its children will load external resources from that host.\n\nimport { prefetchDNS } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  prefetchDNS(\"https://example.com\");\n\n  return ...;\n\n}\nPrefetching DNS in an event handler \n\nCall prefetchDNS in an event handler before transitioning to a page or state where external resources will be needed. This gets the process started earlier than if you call it during the rendering of the new page or state.\n\nimport { prefetchDNS } from 'react-dom';\n\n\n\nfunction CallToAction() {\n\n  const onClick = () => {\n\n    prefetchDNS('http://example.com');\n\n    startWizard();\n\n  }\n\n  return (\n\n    <button onClick={onClick}>Start Wizard</button>\n\n  );\n\n}\nPREVIOUS\npreconnect\nNEXT\npreinit"
  },
  {
    "title": "preinit – React",
    "url": "https://react.dev/reference/react-dom/preinit",
    "html": "API REFERENCE\nAPIS\npreinit\nNote\n\nReact-based frameworks frequently handle resource loading for you, so you might not have to call this API yourself. Consult your framework’s documentation for details.\n\npreinit lets you eagerly fetch and evaluate a stylesheet or external script.\n\npreinit(\"https://example.com/script.js\", {as: \"script\"});\nReference\npreinit(href, options)\nUsage\nPreiniting when rendering\nPreiniting in an event handler\nReference \npreinit(href, options) \n\nTo preinit a script or stylesheet, call the preinit function from react-dom.\n\nimport { preinit } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preinit(\"https://example.com/script.js\", {as: \"script\"});\n\n  // ...\n\n}\n\nSee more examples below.\n\nThe preinit function provides the browser with a hint that it should start downloading and executing the given resource, which can save time. Scripts that you preinit are executed when they finish downloading. Stylesheets that you preinit are inserted into the document, which causes them to go into effect right away.\n\nParameters \nhref: a string. The URL of the resource you want to download and execute.\noptions: an object. It contains the following properties:\nas: a required string. The type of resource. Its possible values are script and style.\nprecedence: a string. Required with stylesheets. Says where to insert the stylesheet relative to others. Stylesheets with higher precedence can override those with lower precedence. The possible values are reset, low, medium, high.\ncrossOrigin: a string. The CORS policy to use. Its possible values are anonymous and use-credentials.\nintegrity: a string. A cryptographic hash of the resource, to verify its authenticity.\nnonce: a string. A cryptographic nonce to allow the resource when using a strict Content Security Policy.\nfetchPriority: a string. Suggests a relative priority for fetching the resource. The possible values are auto (the default), high, and low.\nReturns \n\npreinit returns nothing.\n\nCaveats \nMultiple calls to preinit with the same href have the same effect as a single call.\nIn the browser, you can call preinit in any situation: while rendering a component, in an Effect, in an event handler, and so on.\nIn server-side rendering or when rendering Server Components, preinit only has an effect if you call it while rendering a component or in an async context originating from rendering a component. Any other calls will be ignored.\nUsage \nPreiniting when rendering \n\nCall preinit when rendering a component if you know that it or its children will use a specific resource, and you’re OK with the resource being evaluated and thereby taking effect immediately upon being downloaded.\n\nExamples of preiniting\n1. Preiniting an external script\n2. Preiniting a stylesheet\nExample 1 of 2: Preiniting an external script \nimport { preinit } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preinit(\"https://example.com/script.js\", {as: \"script\"});\n\n  return ...;\n\n}\n\nIf you want the browser to download the script but not to execute it right away, use preload instead. If you want to load an ESM module, use preinitModule.\n\nNext Example\nPreiniting in an event handler \n\nCall preinit in an event handler before transitioning to a page or state where external resources will be needed. This gets the process started earlier than if you call it during the rendering of the new page or state.\n\nimport { preinit } from 'react-dom';\n\n\n\nfunction CallToAction() {\n\n  const onClick = () => {\n\n    preinit(\"https://example.com/wizardStyles.css\", {as: \"style\"});\n\n    startWizard();\n\n  }\n\n  return (\n\n    <button onClick={onClick}>Start Wizard</button>\n\n  );\n\n}\nPREVIOUS\nprefetchDNS\nNEXT\npreinitModule"
  },
  {
    "title": "preinitModule – React",
    "url": "https://react.dev/reference/react-dom/preinitModule",
    "html": "API REFERENCE\nAPIS\npreinitModule\nNote\n\nReact-based frameworks frequently handle resource loading for you, so you might not have to call this API yourself. Consult your framework’s documentation for details.\n\npreinitModule lets you eagerly fetch and evaluate an ESM module.\n\npreinitModule(\"https://example.com/module.js\", {as: \"script\"});\nReference\npreinitModule(href, options)\nUsage\nPreloading when rendering\nPreloading in an event handler\nReference \npreinitModule(href, options) \n\nTo preinit an ESM module, call the preinitModule function from react-dom.\n\nimport { preinitModule } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preinitModule(\"https://example.com/module.js\", {as: \"script\"});\n\n  // ...\n\n}\n\nSee more examples below.\n\nThe preinitModule function provides the browser with a hint that it should start downloading and executing the given module, which can save time. Modules that you preinit are executed when they finish downloading.\n\nParameters \nhref: a string. The URL of the module you want to download and execute.\noptions: an object. It contains the following properties:\nas: a required string. It must be 'script'.\ncrossOrigin: a string. The CORS policy to use. Its possible values are anonymous and use-credentials.\nintegrity: a string. A cryptographic hash of the module, to verify its authenticity.\nnonce: a string. A cryptographic nonce to allow the module when using a strict Content Security Policy.\nReturns \n\npreinitModule returns nothing.\n\nCaveats \nMultiple calls to preinitModule with the same href have the same effect as a single call.\nIn the browser, you can call preinitModule in any situation: while rendering a component, in an Effect, in an event handler, and so on.\nIn server-side rendering or when rendering Server Components, preinitModule only has an effect if you call it while rendering a component or in an async context originating from rendering a component. Any other calls will be ignored.\nUsage \nPreloading when rendering \n\nCall preinitModule when rendering a component if you know that it or its children will use a specific module and you’re OK with the module being evaluated and thereby taking effect immediately upon being downloaded.\n\nimport { preinitModule } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preinitModule(\"https://example.com/module.js\", {as: \"script\"});\n\n  return ...;\n\n}\n\nIf you want the browser to download the module but not to execute it right away, use preloadModule instead. If you want to preinit a script that isn’t an ESM module, use preinit.\n\nPreloading in an event handler \n\nCall preinitModule in an event handler before transitioning to a page or state where the module will be needed. This gets the process started earlier than if you call it during the rendering of the new page or state.\n\nimport { preinitModule } from 'react-dom';\n\n\n\nfunction CallToAction() {\n\n  const onClick = () => {\n\n    preinitModule(\"https://example.com/module.js\", {as: \"script\"});\n\n    startWizard();\n\n  }\n\n  return (\n\n    <button onClick={onClick}>Start Wizard</button>\n\n  );\n\n}\nPREVIOUS\npreinit\nNEXT\npreload"
  },
  {
    "title": "preload – React",
    "url": "https://react.dev/reference/react-dom/preload",
    "html": "API REFERENCE\nAPIS\npreload\nNote\n\nReact-based frameworks frequently handle resource loading for you, so you might not have to call this API yourself. Consult your framework’s documentation for details.\n\npreload lets you eagerly fetch a resource such as a stylesheet, font, or external script that you expect to use.\n\npreload(\"https://example.com/font.woff2\", {as: \"font\"});\nReference\npreload(href, options)\nUsage\nPreloading when rendering\nPreloading in an event handler\nReference \npreload(href, options) \n\nTo preload a resource, call the preload function from react-dom.\n\nimport { preload } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preload(\"https://example.com/font.woff2\", {as: \"font\"});\n\n  // ...\n\n}\n\nSee more examples below.\n\nThe preload function provides the browser with a hint that it should start downloading the given resource, which can save time.\n\nParameters \nhref: a string. The URL of the resource you want to download.\noptions: an object. It contains the following properties:\nas: a required string. The type of resource. Its possible values are audio, document, embed, fetch, font, image, object, script, style, track, video, worker.\ncrossOrigin: a string. The CORS policy to use. Its possible values are anonymous and use-credentials. It is required when as is set to \"fetch\".\nreferrerPolicy: a string. The Referrer header to send when fetching. Its possible values are no-referrer-when-downgrade (the default), no-referrer, origin, origin-when-cross-origin, and unsafe-url.\nintegrity: a string. A cryptographic hash of the resource, to verify its authenticity.\ntype: a string. The MIME type of the resource.\nnonce: a string. A cryptographic nonce to allow the resource when using a strict Content Security Policy.\nfetchPriority: a string. Suggests a relative priority for fetching the resource. The possible values are auto (the default), high, and low.\nimageSrcSet: a string. For use only with as: \"image\". Specifies the source set of the image.\nimageSizes: a string. For use only with as: \"image\". Specifies the sizes of the image.\nReturns \n\npreload returns nothing.\n\nCaveats \nMultiple equivalent calls to preload have the same effect as a single call. Calls to preload are considered equivalent according to the following rules:\nTwo calls are equivalent if they have the same href, except:\nIf as is set to image, two calls are equivalent if they have the same href, imageSrcSet, and imageSizes.\nIn the browser, you can call preload in any situation: while rendering a component, in an Effect, in an event handler, and so on.\nIn server-side rendering or when rendering Server Components, preload only has an effect if you call it while rendering a component or in an async context originating from rendering a component. Any other calls will be ignored.\nUsage \nPreloading when rendering \n\nCall preload when rendering a component if you know that it or its children will use a specific resource.\n\nExamples of preloading\n1. Preloading an external script\n2. Preloading a stylesheet\n3. Preloading a font\n4. Preloading an image\nExample 1 of 4: Preloading an external script \nimport { preload } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preload(\"https://example.com/script.js\", {as: \"script\"});\n\n  return ...;\n\n}\n\nIf you want the browser to start executing the script immediately (rather than just downloading it), use preinit instead. If you want to load an ESM module, use preloadModule.\n\nNext Example\nPreloading in an event handler \n\nCall preload in an event handler before transitioning to a page or state where external resources will be needed. This gets the process started earlier than if you call it during the rendering of the new page or state.\n\nimport { preload } from 'react-dom';\n\n\n\nfunction CallToAction() {\n\n  const onClick = () => {\n\n    preload(\"https://example.com/wizardStyles.css\", {as: \"style\"});\n\n    startWizard();\n\n  }\n\n  return (\n\n    <button onClick={onClick}>Start Wizard</button>\n\n  );\n\n}\nPREVIOUS\npreinitModule\nNEXT\npreloadModule"
  },
  {
    "title": "preloadModule – React",
    "url": "https://react.dev/reference/react-dom/preloadModule",
    "html": "API REFERENCE\nAPIS\npreloadModule\nNote\n\nReact-based frameworks frequently handle resource loading for you, so you might not have to call this API yourself. Consult your framework’s documentation for details.\n\npreloadModule lets you eagerly fetch an ESM module that you expect to use.\n\npreloadModule(\"https://example.com/module.js\", {as: \"script\"});\nReference\npreloadModule(href, options)\nUsage\nPreloading when rendering\nPreloading in an event handler\nReference \npreloadModule(href, options) \n\nTo preload an ESM module, call the preloadModule function from react-dom.\n\nimport { preloadModule } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preloadModule(\"https://example.com/module.js\", {as: \"script\"});\n\n  // ...\n\n}\n\nSee more examples below.\n\nThe preloadModule function provides the browser with a hint that it should start downloading the given module, which can save time.\n\nParameters \nhref: a string. The URL of the module you want to download.\noptions: an object. It contains the following properties:\nas: a required string. It must be 'script'.\ncrossOrigin: a string. The CORS policy to use. Its possible values are anonymous and use-credentials.\nintegrity: a string. A cryptographic hash of the module, to verify its authenticity.\nnonce: a string. A cryptographic nonce to allow the module when using a strict Content Security Policy.\nReturns \n\npreloadModule returns nothing.\n\nCaveats \nMultiple calls to preloadModule with the same href have the same effect as a single call.\nIn the browser, you can call preloadModule in any situation: while rendering a component, in an Effect, in an event handler, and so on.\nIn server-side rendering or when rendering Server Components, preloadModule only has an effect if you call it while rendering a component or in an async context originating from rendering a component. Any other calls will be ignored.\nUsage \nPreloading when rendering \n\nCall preloadModule when rendering a component if you know that it or its children will use a specific module.\n\nimport { preloadModule } from 'react-dom';\n\n\n\nfunction AppRoot() {\n\n  preloadModule(\"https://example.com/module.js\", {as: \"script\"});\n\n  return ...;\n\n}\n\nIf you want the browser to start executing the module immediately (rather than just downloading it), use preinitModule instead. If you want to load a script that isn’t an ESM module, use preload.\n\nPreloading in an event handler \n\nCall preloadModule in an event handler before transitioning to a page or state where the module will be needed. This gets the process started earlier than if you call it during the rendering of the new page or state.\n\nimport { preloadModule } from 'react-dom';\n\n\n\nfunction CallToAction() {\n\n  const onClick = () => {\n\n    preloadModule(\"https://example.com/module.js\", {as: \"script\"});\n\n    startWizard();\n\n  }\n\n  return (\n\n    <button onClick={onClick}>Start Wizard</button>\n\n  );\n\n}\nPREVIOUS\npreload\nNEXT\nClient APIs"
  },
  {
    "title": "Client React DOM APIs – React",
    "url": "https://react.dev/reference/react-dom/client",
    "html": "API REFERENCE\nClient React DOM APIs\n\nThe react-dom/client APIs let you render React components on the client (in the browser). These APIs are typically used at the top level of your app to initialize your React tree. A framework may call them for you. Most of your components don’t need to import or use them.\n\nClient APIs \ncreateRoot lets you create a root to display React components inside a browser DOM node.\nhydrateRoot lets you display React components inside a browser DOM node whose HTML content was previously generated by react-dom/server.\nBrowser support \n\nReact supports all popular browsers, including Internet Explorer 9 and above. Some polyfills are required for older browsers such as IE 9 and IE 10.\n\nPREVIOUS\npreloadModule\nNEXT\ncreateRoot"
  },
  {
    "title": "createRoot – React",
    "url": "https://react.dev/reference/react-dom/client/createRoot",
    "html": "API REFERENCE\nCLIENT APIS\ncreateRoot\n\ncreateRoot lets you create a root to display React components inside a browser DOM node.\n\nconst root = createRoot(domNode, options?)\nReference\ncreateRoot(domNode, options?)\nroot.render(reactNode)\nroot.unmount()\nUsage\nRendering an app fully built with React\nRendering a page partially built with React\nUpdating a root component\nError logging in production\nTroubleshooting\nI’ve created a root, but nothing is displayed\nI’m getting an error: “You passed a second argument to root.render”\nI’m getting an error: “Target container is not a DOM element”\nI’m getting an error: “Functions are not valid as a React child.”\nMy server-rendered HTML gets re-created from scratch\nReference \ncreateRoot(domNode, options?) \n\nCall createRoot to create a React root for displaying content inside a browser DOM element.\n\nimport { createRoot } from 'react-dom/client';\n\n\n\nconst domNode = document.getElementById('root');\n\nconst root = createRoot(domNode);\n\nReact will create a root for the domNode, and take over managing the DOM inside it. After you’ve created a root, you need to call root.render to display a React component inside of it:\n\nroot.render(<App />);\n\nAn app fully built with React will usually only have one createRoot call for its root component. A page that uses “sprinkles” of React for parts of the page may have as many separate roots as needed.\n\nSee more examples below.\n\nParameters \n\ndomNode: A DOM element. React will create a root for this DOM element and allow you to call functions on the root, such as render to display rendered React content.\n\noptional options: An object with options for this React root.\n\noptional onCaughtError: Callback called when React catches an error in an Error Boundary. Called with the error caught by the Error Boundary, and an errorInfo object containing the componentStack.\noptional onUncaughtError: Callback called when an error is thrown and not caught by an Error Boundary. Called with the error that was thrown, and an errorInfo object containing the componentStack.\noptional onRecoverableError: Callback called when React automatically recovers from errors. Called with an error React throws, and an errorInfo object containing the componentStack. Some recoverable errors may include the original error cause as error.cause.\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page.\nReturns \n\ncreateRoot returns an object with two methods: render and unmount.\n\nCaveats \nIf your app is server-rendered, using createRoot() is not supported. Use hydrateRoot() instead.\nYou’ll likely have only one createRoot call in your app. If you use a framework, it might do this call for you.\nWhen you want to render a piece of JSX in a different part of the DOM tree that isn’t a child of your component (for example, a modal or a tooltip), use createPortal instead of createRoot.\nroot.render(reactNode) \n\nCall root.render to display a piece of JSX (“React node”) into the React root’s browser DOM node.\n\nroot.render(<App />);\n\nReact will display <App /> in the root, and take over managing the DOM inside it.\n\nSee more examples below.\n\nParameters \nreactNode: A React node that you want to display. This will usually be a piece of JSX like <App />, but you can also pass a React element constructed with createElement(), a string, a number, null, or undefined.\nReturns \n\nroot.render returns undefined.\n\nCaveats \n\nThe first time you call root.render, React will clear all the existing HTML content inside the React root before rendering the React component into it.\n\nIf your root’s DOM node contains HTML generated by React on the server or during the build, use hydrateRoot() instead, which attaches the event handlers to the existing HTML.\n\nIf you call render on the same root more than once, React will update the DOM as necessary to reflect the latest JSX you passed. React will decide which parts of the DOM can be reused and which need to be recreated by “matching it up” with the previously rendered tree. Calling render on the same root again is similar to calling the set function on the root component: React avoids unnecessary DOM updates.\n\nAlthough rendering is synchronous once it starts, root.render(...) is not. This means code after root.render() may run before any effects (useLayoutEffect, useEffect) of that specific render are fired. This is usually fine and rarely needs adjustment. In rare cases where effect timing matters, you can wrap root.render(...) in flushSync to ensure the initial render runs fully synchronously.\n\nconst root = createRoot(document.getElementById('root'));\n\nroot.render(<App />);\n\n// 🚩 The HTML will not include the rendered <App /> yet:\n\nconsole.log(document.body.innerHTML);\nroot.unmount() \n\nCall root.unmount to destroy a rendered tree inside a React root.\n\nroot.unmount();\n\nAn app fully built with React will usually not have any calls to root.unmount.\n\nThis is mostly useful if your React root’s DOM node (or any of its ancestors) may get removed from the DOM by some other code. For example, imagine a jQuery tab panel that removes inactive tabs from the DOM. If a tab gets removed, everything inside it (including the React roots inside) would get removed from the DOM as well. In that case, you need to tell React to “stop” managing the removed root’s content by calling root.unmount. Otherwise, the components inside the removed root won’t know to clean up and free up global resources like subscriptions.\n\nCalling root.unmount will unmount all the components in the root and “detach” React from the root DOM node, including removing any event handlers or state in the tree.\n\nParameters \n\nroot.unmount does not accept any parameters.\n\nReturns \n\nroot.unmount returns undefined.\n\nCaveats \n\nCalling root.unmount will unmount all the components in the tree and “detach” React from the root DOM node.\n\nOnce you call root.unmount you cannot call root.render again on the same root. Attempting to call root.render on an unmounted root will throw a “Cannot update an unmounted root” error. However, you can create a new root for the same DOM node after the previous root for that node has been unmounted.\n\nUsage \nRendering an app fully built with React \n\nIf your app is fully built with React, create a single root for your entire app.\n\nimport { createRoot } from 'react-dom/client';\n\n\n\nconst root = createRoot(document.getElementById('root'));\n\nroot.render(<App />);\n\nUsually, you only need to run this code once at startup. It will:\n\nFind the browser DOM node defined in your HTML.\nDisplay the React component for your app inside.\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport App from './App.js';\nimport './styles.css';\n\nconst root = createRoot(document.getElementById('root'));\nroot.render(<App />);\n\n\n\nIf your app is fully built with React, you shouldn’t need to create any more roots, or to call root.render again.\n\nFrom this point on, React will manage the DOM of your entire app. To add more components, nest them inside the App component. When you need to update the UI, each of your components can do this by using state. When you need to display extra content like a modal or a tooltip outside the DOM node, render it with a portal.\n\nNote\n\nWhen your HTML is empty, the user sees a blank page until the app’s JavaScript code loads and runs:\n\n<div id=\"root\"></div>\n\nThis can feel very slow! To solve this, you can generate the initial HTML from your components on the server or during the build. Then your visitors can read text, see images, and click links before any of the JavaScript code loads. We recommend using a framework that does this optimization out of the box. Depending on when it runs, this is called server-side rendering (SSR) or static site generation (SSG).\n\nPitfall\n\nApps using server rendering or static generation must call hydrateRoot instead of createRoot. React will then hydrate (reuse) the DOM nodes from your HTML instead of destroying and re-creating them.\n\nRendering a page partially built with React \n\nIf your page isn’t fully built with React, you can call createRoot multiple times to create a root for each top-level piece of UI managed by React. You can display different content in each root by calling root.render.\n\nHere, two different React components are rendered into two DOM nodes defined in the index.html file:\n\nindex.js\nindex.html\nComponents.js\nReload\nClear\nFork\nimport './styles.css';\nimport { createRoot } from 'react-dom/client';\nimport { Comments, Navigation } from './Components.js';\n\nconst navDomNode = document.getElementById('navigation');\nconst navRoot = createRoot(navDomNode); \nnavRoot.render(<Navigation />);\n\nconst commentDomNode = document.getElementById('comments');\nconst commentRoot = createRoot(commentDomNode); \ncommentRoot.render(<Comments />);\n\n\n\nYou could also create a new DOM node with document.createElement() and add it to the document manually.\n\nconst domNode = document.createElement('div');\n\nconst root = createRoot(domNode); \n\nroot.render(<Comment />);\n\ndocument.body.appendChild(domNode); // You can add it anywhere in the document\n\nTo remove the React tree from the DOM node and clean up all the resources used by it, call root.unmount.\n\nroot.unmount();\n\nThis is mostly useful if your React components are inside an app written in a different framework.\n\nUpdating a root component \n\nYou can call render more than once on the same root. As long as the component tree structure matches up with what was previously rendered, React will preserve the state. Notice how you can type in the input, which means that the updates from repeated render calls every second in this example are not destructive:\n\nindex.js\nApp.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\nimport App from './App.js';\n\nconst root = createRoot(document.getElementById('root'));\n\nlet i = 0;\nsetInterval(() => {\n  root.render(<App counter={i} />);\n  i++;\n}, 1000);\n\n\n\nIt is uncommon to call render multiple times. Usually, your components will update state instead.\n\nError logging in production \n\nBy default, React will log all errors to the console. To implement your own error reporting, you can provide the optional error handler root options onUncaughtError, onCaughtError and onRecoverableError:\n\nimport { createRoot } from \"react-dom/client\";\n\nimport { reportCaughtError } from \"./reportError\";\n\n\n\nconst container = document.getElementById(\"root\");\n\nconst root = createRoot(container, {\n\n  onCaughtError: (error, errorInfo) => {\n\n    if (error.message !== \"Known error\") {\n\n      reportCaughtError({\n\n        error,\n\n        componentStack: errorInfo.componentStack,\n\n      });\n\n    }\n\n  },\n\n});\n\nThe onCaughtError option is a function called with two arguments:\n\nThe error that was thrown.\nAn errorInfo object that contains the componentStack of the error.\n\nTogether with onUncaughtError and onRecoverableError, you can can implement your own error reporting system:\n\nindex.js\nreportError.js\nApp.js\nReload\nClear\nFork\nimport { createRoot } from \"react-dom/client\";\nimport App from \"./App.js\";\nimport {\n  onCaughtErrorProd,\n  onRecoverableErrorProd,\n  onUncaughtErrorProd,\n} from \"./reportError\";\n\nconst container = document.getElementById(\"root\");\nconst root = createRoot(container, {\n  // Keep in mind to remove these options in development to leverage\n  // React's default handlers or implement your own overlay for development.\n  // The handlers are only specfied unconditionally here for demonstration purposes.\n  onCaughtError: onCaughtErrorProd,\n  onRecoverableError: onRecoverableErrorProd,\n  onUncaughtError: onUncaughtErrorProd,\n});\nroot.render(<App />);\n\n\nShow more\nTroubleshooting \nI’ve created a root, but nothing is displayed \n\nMake sure you haven’t forgotten to actually render your app into the root:\n\nimport { createRoot } from 'react-dom/client';\n\nimport App from './App.js';\n\n\n\nconst root = createRoot(document.getElementById('root'));\n\nroot.render(<App />);\n\nUntil you do that, nothing is displayed.\n\nI’m getting an error: “You passed a second argument to root.render” \n\nA common mistake is to pass the options for createRoot to root.render(...):\n\nConsole\nWarning: You passed a second argument to root.render(…) but it only accepts one argument.\n\nTo fix, pass the root options to createRoot(...), not root.render(...):\n\n// 🚩 Wrong: root.render only takes one argument.\n\nroot.render(App, {onUncaughtError});\n\n\n\n// ✅ Correct: pass options to createRoot.\n\nconst root = createRoot(container, {onUncaughtError}); \n\nroot.render(<App />);\nI’m getting an error: “Target container is not a DOM element” \n\nThis error means that whatever you’re passing to createRoot is not a DOM node.\n\nIf you’re not sure what’s happening, try logging it:\n\nconst domNode = document.getElementById('root');\n\nconsole.log(domNode); // ???\n\nconst root = createRoot(domNode);\n\nroot.render(<App />);\n\nFor example, if domNode is null, it means that getElementById returned null. This will happen if there is no node in the document with the given ID at the time of your call. There may be a few reasons for it:\n\nThe ID you’re looking for might differ from the ID you used in the HTML file. Check for typos!\nYour bundle’s <script> tag cannot “see” any DOM nodes that appear after it in the HTML.\n\nAnother common way to get this error is to write createRoot(<App />) instead of createRoot(domNode).\n\nI’m getting an error: “Functions are not valid as a React child.” \n\nThis error means that whatever you’re passing to root.render is not a React component.\n\nThis may happen if you call root.render with Component instead of <Component />:\n\n// 🚩 Wrong: App is a function, not a Component.\n\nroot.render(App);\n\n\n\n// ✅ Correct: <App /> is a component.\n\nroot.render(<App />);\n\nOr if you pass a function to root.render, instead of the result of calling it:\n\n// 🚩 Wrong: createApp is a function, not a component.\n\nroot.render(createApp);\n\n\n\n// ✅ Correct: call createApp to return a component.\n\nroot.render(createApp());\nMy server-rendered HTML gets re-created from scratch \n\nIf your app is server-rendered and includes the initial HTML generated by React, you might notice that creating a root and calling root.render deletes all that HTML, and then re-creates all the DOM nodes from scratch. This can be slower, resets focus and scroll positions, and may lose other user input.\n\nServer-rendered apps must use hydrateRoot instead of createRoot:\n\nimport { hydrateRoot } from 'react-dom/client';\n\nimport App from './App.js';\n\n\n\nhydrateRoot(\n\n  document.getElementById('root'),\n\n  <App />\n\n);\n\nNote that its API is different. In particular, usually there will be no further root.render call.\n\nPREVIOUS\nClient APIs\nNEXT\nhydrateRoot"
  },
  {
    "title": "hydrateRoot – React",
    "url": "https://react.dev/reference/react-dom/client/hydrateRoot",
    "html": "API REFERENCE\nCLIENT APIS\nhydrateRoot\n\nhydrateRoot lets you display React components inside a browser DOM node whose HTML content was previously generated by react-dom/server.\n\nconst root = hydrateRoot(domNode, reactNode, options?)\nReference\nhydrateRoot(domNode, reactNode, options?)\nroot.render(reactNode)\nroot.unmount()\nUsage\nHydrating server-rendered HTML\nHydrating an entire document\nSuppressing unavoidable hydration mismatch errors\nHandling different client and server content\nUpdating a hydrated root component\nError logging in production\nTroubleshooting\nI’m getting an error: “You passed a second argument to root.render”\nReference \nhydrateRoot(domNode, reactNode, options?) \n\nCall hydrateRoot to “attach” React to existing HTML that was already rendered by React in a server environment.\n\nimport { hydrateRoot } from 'react-dom/client';\n\n\n\nconst domNode = document.getElementById('root');\n\nconst root = hydrateRoot(domNode, reactNode);\n\nReact will attach to the HTML that exists inside the domNode, and take over managing the DOM inside it. An app fully built with React will usually only have one hydrateRoot call with its root component.\n\nSee more examples below.\n\nParameters \n\ndomNode: A DOM element that was rendered as the root element on the server.\n\nreactNode: The “React node” used to render the existing HTML. This will usually be a piece of JSX like <App /> which was rendered with a ReactDOM Server method such as renderToPipeableStream(<App />).\n\noptional options: An object with options for this React root.\n\noptional onCaughtError: Callback called when React catches an error in an Error Boundary. Called with the error caught by the Error Boundary, and an errorInfo object containing the componentStack.\noptional onUncaughtError: Callback called when an error is thrown and not caught by an Error Boundary. Called with the error that was thrown and an errorInfo object containing the componentStack.\noptional onRecoverableError: Callback called when React automatically recovers from errors. Called with the error React throws, and an errorInfo object containing the componentStack. Some recoverable errors may include the original error cause as error.cause.\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page. Must be the same prefix as used on the server.\nReturns \n\nhydrateRoot returns an object with two methods: render and unmount.\n\nCaveats \nhydrateRoot() expects the rendered content to be identical with the server-rendered content. You should treat mismatches as bugs and fix them.\nIn development mode, React warns about mismatches during hydration. There are no guarantees that attribute differences will be patched up in case of mismatches. This is important for performance reasons because in most apps, mismatches are rare, and so validating all markup would be prohibitively expensive.\nYou’ll likely have only one hydrateRoot call in your app. If you use a framework, it might do this call for you.\nIf your app is client-rendered with no HTML rendered already, using hydrateRoot() is not supported. Use createRoot() instead.\nroot.render(reactNode) \n\nCall root.render to update a React component inside a hydrated React root for a browser DOM element.\n\nroot.render(<App />);\n\nReact will update <App /> in the hydrated root.\n\nSee more examples below.\n\nParameters \nreactNode: A “React node” that you want to update. This will usually be a piece of JSX like <App />, but you can also pass a React element constructed with createElement(), a string, a number, null, or undefined.\nReturns \n\nroot.render returns undefined.\n\nCaveats \nIf you call root.render before the root has finished hydrating, React will clear the existing server-rendered HTML content and switch the entire root to client rendering.\nroot.unmount() \n\nCall root.unmount to destroy a rendered tree inside a React root.\n\nroot.unmount();\n\nAn app fully built with React will usually not have any calls to root.unmount.\n\nThis is mostly useful if your React root’s DOM node (or any of its ancestors) may get removed from the DOM by some other code. For example, imagine a jQuery tab panel that removes inactive tabs from the DOM. If a tab gets removed, everything inside it (including the React roots inside) would get removed from the DOM as well. You need to tell React to “stop” managing the removed root’s content by calling root.unmount. Otherwise, the components inside the removed root won’t clean up and free up resources like subscriptions.\n\nCalling root.unmount will unmount all the components in the root and “detach” React from the root DOM node, including removing any event handlers or state in the tree.\n\nParameters \n\nroot.unmount does not accept any parameters.\n\nReturns \n\nroot.unmount returns undefined.\n\nCaveats \n\nCalling root.unmount will unmount all the components in the tree and “detach” React from the root DOM node.\n\nOnce you call root.unmount you cannot call root.render again on the root. Attempting to call root.render on an unmounted root will throw a “Cannot update an unmounted root” error.\n\nUsage \nHydrating server-rendered HTML \n\nIf your app’s HTML was generated by react-dom/server, you need to hydrate it on the client.\n\nimport { hydrateRoot } from 'react-dom/client';\n\n\n\nhydrateRoot(document.getElementById('root'), <App />);\n\nThis will hydrate the server HTML inside the browser DOM node with the React component for your app. Usually, you will do it once at startup. If you use a framework, it might do this behind the scenes for you.\n\nTo hydrate your app, React will “attach” your components’ logic to the initial generated HTML from the server. Hydration turns the initial HTML snapshot from the server into a fully interactive app that runs in the browser.\n\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nimport './styles.css';\nimport { hydrateRoot } from 'react-dom/client';\nimport App from './App.js';\n\nhydrateRoot(\n  document.getElementById('root'),\n  <App />\n);\n\n\n\nYou shouldn’t need to call hydrateRoot again or to call it in more places. From this point on, React will be managing the DOM of your application. To update the UI, your components will use state instead.\n\nPitfall\n\nThe React tree you pass to hydrateRoot needs to produce the same output as it did on the server.\n\nThis is important for the user experience. The user will spend some time looking at the server-generated HTML before your JavaScript code loads. Server rendering creates an illusion that the app loads faster by showing the HTML snapshot of its output. Suddenly showing different content breaks that illusion. This is why the server render output must match the initial render output on the client.\n\nThe most common causes leading to hydration errors include:\n\nExtra whitespace (like newlines) around the React-generated HTML inside the root node.\nUsing checks like typeof window !== 'undefined' in your rendering logic.\nUsing browser-only APIs like window.matchMedia in your rendering logic.\nRendering different data on the server and the client.\n\nReact recovers from some hydration errors, but you must fix them like other bugs. In the best case, they’ll lead to a slowdown; in the worst case, event handlers can get attached to the wrong elements.\n\nHydrating an entire document \n\nApps fully built with React can render the entire document as JSX, including the <html> tag:\n\nfunction App() {\n\n  return (\n\n    <html>\n\n      <head>\n\n        <meta charSet=\"utf-8\" />\n\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n        <link rel=\"stylesheet\" href=\"/styles.css\"></link>\n\n        <title>My app</title>\n\n      </head>\n\n      <body>\n\n        <Router />\n\n      </body>\n\n    </html>\n\n  );\n\n}\n\nTo hydrate the entire document, pass the document global as the first argument to hydrateRoot:\n\nimport { hydrateRoot } from 'react-dom/client';\n\nimport App from './App.js';\n\n\n\nhydrateRoot(document, <App />);\nSuppressing unavoidable hydration mismatch errors \n\nIf a single element’s attribute or text content is unavoidably different between the server and the client (for example, a timestamp), you may silence the hydration mismatch warning.\n\nTo silence hydration warnings on an element, add suppressHydrationWarning={true}:\n\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nexport default function App() {\n  return (\n    <h1 suppressHydrationWarning={true}>\n      Current Date: {new Date().toLocaleDateString()}\n    </h1>\n  );\n}\n\n\n\nThis only works one level deep, and is intended to be an escape hatch. Don’t overuse it. React will not attempt to patch mismatched text content.\n\nHandling different client and server content \n\nIf you intentionally need to render something different on the server and the client, you can do a two-pass rendering. Components that render something different on the client can read a state variable like isClient, which you can set to true in an Effect:\n\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nimport { useState, useEffect } from \"react\";\n\nexport default function App() {\n  const [isClient, setIsClient] = useState(false);\n\n  useEffect(() => {\n    setIsClient(true);\n  }, []);\n\n  return (\n    <h1>\n      {isClient ? 'Is Client' : 'Is Server'}\n    </h1>\n  );\n}\n\n\n\nThis way the initial render pass will render the same content as the server, avoiding mismatches, but an additional pass will happen synchronously right after hydration.\n\nPitfall\n\nThis approach makes hydration slower because your components have to render twice. Be mindful of the user experience on slow connections. The JavaScript code may load significantly later than the initial HTML render, so rendering a different UI immediately after hydration may also feel jarring to the user.\n\nUpdating a hydrated root component \n\nAfter the root has finished hydrating, you can call root.render to update the root React component. Unlike with createRoot, you don’t usually need to do this because the initial content was already rendered as HTML.\n\nIf you call root.render at some point after hydration, and the component tree structure matches up with what was previously rendered, React will preserve the state. Notice how you can type in the input, which means that the updates from repeated render calls every second in this example are not destructive:\n\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nimport { hydrateRoot } from 'react-dom/client';\nimport './styles.css';\nimport App from './App.js';\n\nconst root = hydrateRoot(\n  document.getElementById('root'),\n  <App counter={0} />\n);\n\nlet i = 0;\nsetInterval(() => {\n  root.render(<App counter={i} />);\n  i++;\n}, 1000);\n\n\n\nIt is uncommon to call root.render on a hydrated root. Usually, you’ll update state inside one of the components instead.\n\nError logging in production \n\nBy default, React will log all errors to the console. To implement your own error reporting, you can provide the optional error handler root options onUncaughtError, onCaughtError and onRecoverableError:\n\nimport { hydrateRoot } from \"react-dom/client\";\n\nimport App from \"./App.js\";\n\nimport { reportCaughtError } from \"./reportError\";\n\n\n\nconst container = document.getElementById(\"root\");\n\nconst root = hydrateRoot(container, <App />, {\n\n  onCaughtError: (error, errorInfo) => {\n\n    if (error.message !== \"Known error\") {\n\n      reportCaughtError({\n\n        error,\n\n        componentStack: errorInfo.componentStack,\n\n      });\n\n    }\n\n  },\n\n});\n\nThe onCaughtError option is a function called with two arguments:\n\nThe error that was thrown.\nAn errorInfo object that contains the componentStack of the error.\n\nTogether with onUncaughtError and onRecoverableError, you can implement your own error reporting system:\n\nindex.js\nreportError.js\nApp.js\nReload\nClear\nFork\nimport { hydrateRoot } from \"react-dom/client\";\nimport App from \"./App.js\";\nimport {\n  onCaughtErrorProd,\n  onRecoverableErrorProd,\n  onUncaughtErrorProd,\n} from \"./reportError\";\n\nconst container = document.getElementById(\"root\");\nhydrateRoot(container, <App />, {\n  // Keep in mind to remove these options in development to leverage\n  // React's default handlers or implement your own overlay for development.\n  // The handlers are only specfied unconditionally here for demonstration purposes.\n  onCaughtError: onCaughtErrorProd,\n  onRecoverableError: onRecoverableErrorProd,\n  onUncaughtError: onUncaughtErrorProd,\n});\n\n\nShow more\nTroubleshooting \nI’m getting an error: “You passed a second argument to root.render” \n\nA common mistake is to pass the options for hydrateRoot to root.render(...):\n\nConsole\nWarning: You passed a second argument to root.render(…) but it only accepts one argument.\n\nTo fix, pass the root options to hydrateRoot(...), not root.render(...):\n\n// 🚩 Wrong: root.render only takes one argument.\n\nroot.render(App, {onUncaughtError});\n\n\n\n// ✅ Correct: pass options to createRoot.\n\nconst root = hydrateRoot(container, <App />, {onUncaughtError});\nPREVIOUS\ncreateRoot\nNEXT\nServer APIs"
  },
  {
    "title": "Server React DOM APIs – React",
    "url": "https://react.dev/reference/react-dom/server",
    "html": "API REFERENCE\nServer React DOM APIs\n\nThe react-dom/server APIs let you server-side render React components to HTML. These APIs are only used on the server at the top level of your app to generate the initial HTML. A framework may call them for you. Most of your components don’t need to import or use them.\n\nServer APIs for Web Streams \n\nThese methods are only available in the environments with Web Streams, which includes browsers, Deno, and some modern edge runtimes:\n\nrenderToReadableStream renders a React tree to a Readable Web Stream.\nresume resumes prerender to a Readable Web Stream.\nNote\n\nNode.js also includes these methods for compatibility, but they are not recommended due to worse performance. Use the dedicated Node.js APIs instead.\n\nServer APIs for Node.js Streams \n\nThese methods are only available in the environments with Node.js Streams:\n\nrenderToPipeableStream renders a React tree to a pipeable Node.js Stream.\nresumeToPipeableStream resumes prerenderToNodeStream to a pipeable Node.js Stream.\nLegacy Server APIs for non-streaming environments \n\nThese methods can be used in the environments that don’t support streams:\n\nrenderToString renders a React tree to a string.\nrenderToStaticMarkup renders a non-interactive React tree to a string.\n\nThey have limited functionality compared to the streaming APIs.\n\nPREVIOUS\nhydrateRoot\nNEXT\nrenderToPipeableStream"
  },
  {
    "title": "renderToPipeableStream – React",
    "url": "https://react.dev/reference/react-dom/server/renderToPipeableStream",
    "html": "API REFERENCE\nSERVER APIS\nrenderToPipeableStream\n\nrenderToPipeableStream renders a React tree to a pipeable Node.js Stream.\n\nconst { pipe, abort } = renderToPipeableStream(reactNode, options?)\nReference\nrenderToPipeableStream(reactNode, options?)\nUsage\nRendering a React tree as HTML to a Node.js Stream\nStreaming more content as it loads\nSpecifying what goes into the shell\nLogging crashes on the server\nRecovering from errors inside the shell\nRecovering from errors outside the shell\nSetting the status code\nHandling different errors in different ways\nWaiting for all content to load for crawlers and static generation\nAborting server rendering\nNote\n\nThis API is specific to Node.js. Environments with Web Streams, like Deno and modern edge runtimes, should use renderToReadableStream instead.\n\nReference \nrenderToPipeableStream(reactNode, options?) \n\nCall renderToPipeableStream to render your React tree as HTML into a Node.js Stream.\n\nimport { renderToPipeableStream } from 'react-dom/server';\n\n\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    response.setHeader('content-type', 'text/html');\n\n    pipe(response);\n\n  }\n\n});\n\nOn the client, call hydrateRoot to make the server-generated HTML interactive.\n\nSee more examples below.\n\nParameters \n\nreactNode: A React node you want to render to HTML. For example, a JSX element like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\n\noptional options: An object with streaming options.\n\noptional bootstrapScriptContent: If specified, this string will be placed in an inline <script> tag.\noptional bootstrapScripts: An array of string URLs for the <script> tags to emit on the page. Use this to include the <script> that calls hydrateRoot. Omit it if you don’t want to run React on the client at all.\noptional bootstrapModules: Like bootstrapScripts, but emits <script type=\"module\"> instead.\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page. Must be the same prefix as passed to hydrateRoot.\noptional namespaceURI: A string with the root namespace URI for the stream. Defaults to regular HTML. Pass 'http://www.w3.org/2000/svg' for SVG or 'http://www.w3.org/1998/Math/MathML' for MathML.\noptional nonce: A nonce string to allow scripts for script-src Content-Security-Policy.\noptional onAllReady: A callback that fires when all rendering is complete, including both the shell and all additional content. You can use this instead of onShellReady for crawlers and static generation. If you start streaming here, you won’t get any progressive loading. The stream will contain the final HTML.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error. You can also use it to adjust the status code before the shell is emitted.\noptional onShellReady: A callback that fires right after the initial shell has been rendered. You can set the status code and call pipe here to start streaming. React will stream the additional content after the shell along with the inline <script> tags that replace the HTML loading fallbacks with the content.\noptional onShellError: A callback that fires if there was an error rendering the initial shell. It receives the error as an argument. No bytes were emitted from the stream yet, and neither onShellReady nor onAllReady will get called, so you can output a fallback HTML shell.\noptional progressiveChunkSize: The number of bytes in a chunk. Read more about the default heuristic.\nReturns \n\nrenderToPipeableStream returns an object with two methods:\n\npipe outputs the HTML into the provided Writable Node.js Stream. Call pipe in onShellReady if you want to enable streaming, or in onAllReady for crawlers and static generation.\nabort lets you abort server rendering and render the rest on the client.\nUsage \nRendering a React tree as HTML to a Node.js Stream \n\nCall renderToPipeableStream to render your React tree as HTML into a Node.js Stream:\n\nimport { renderToPipeableStream } from 'react-dom/server';\n\n\n\n// The route handler syntax depends on your backend framework\n\napp.use('/', (request, response) => {\n\n  const { pipe } = renderToPipeableStream(<App />, {\n\n    bootstrapScripts: ['/main.js'],\n\n    onShellReady() {\n\n      response.setHeader('content-type', 'text/html');\n\n      pipe(response);\n\n    }\n\n  });\n\n});\n\nAlong with the root component, you need to provide a list of bootstrap <script> paths. Your root component should return the entire document including the root <html> tag.\n\nFor example, it might look like this:\n\nexport default function App() {\n\n  return (\n\n    <html>\n\n      <head>\n\n        <meta charSet=\"utf-8\" />\n\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n        <link rel=\"stylesheet\" href=\"/styles.css\"></link>\n\n        <title>My app</title>\n\n      </head>\n\n      <body>\n\n        <Router />\n\n      </body>\n\n    </html>\n\n  );\n\n}\n\nReact will inject the doctype and your bootstrap <script> tags into the resulting HTML stream:\n\n<!DOCTYPE html>\n\n<html>\n\n  <!-- ... HTML from your components ... -->\n\n</html>\n\n<script src=\"/main.js\" async=\"\"></script>\n\nOn the client, your bootstrap script should hydrate the entire document with a call to hydrateRoot:\n\nimport { hydrateRoot } from 'react-dom/client';\n\nimport App from './App.js';\n\n\n\nhydrateRoot(document, <App />);\n\nThis will attach event listeners to the server-generated HTML and make it interactive.\n\nDEEP DIVE\nReading CSS and JS asset paths from the build output \nShow Details\nStreaming more content as it loads \n\nStreaming allows the user to start seeing the content even before all the data has loaded on the server. For example, consider a profile page that shows a cover, a sidebar with friends and photos, and a list of posts:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Sidebar>\n\n        <Friends />\n\n        <Photos />\n\n      </Sidebar>\n\n      <Posts />\n\n    </ProfileLayout>\n\n  );\n\n}\n\nImagine that loading data for <Posts /> takes some time. Ideally, you’d want to show the rest of the profile page content to the user without waiting for the posts. To do this, wrap Posts in a <Suspense> boundary:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Sidebar>\n\n        <Friends />\n\n        <Photos />\n\n      </Sidebar>\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nThis tells React to start streaming the HTML before Posts loads its data. React will send the HTML for the loading fallback (PostsGlimmer) first, and then, when Posts finishes loading its data, React will send the remaining HTML along with an inline <script> tag that replaces the loading fallback with that HTML. From the user’s perspective, the page will first appear with the PostsGlimmer, later replaced by the Posts.\n\nYou can further nest <Suspense> boundaries to create a more granular loading sequence:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<BigSpinner />}>\n\n        <Sidebar>\n\n          <Friends />\n\n          <Photos />\n\n        </Sidebar>\n\n        <Suspense fallback={<PostsGlimmer />}>\n\n          <Posts />\n\n        </Suspense>\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIn this example, React can start streaming the page even earlier. Only ProfileLayout and ProfileCover must finish rendering first because they are not wrapped in any <Suspense> boundary. However, if Sidebar, Friends, or Photos need to load some data, React will send the HTML for the BigSpinner fallback instead. Then, as more data becomes available, more content will continue to be revealed until all of it becomes visible.\n\nStreaming does not need to wait for React itself to load in the browser, or for your app to become interactive. The HTML content from the server will get progressively revealed before any of the <script> tags load.\n\nRead more about how streaming HTML works.\n\nNote\n\nOnly Suspense-enabled data sources will activate the Suspense component. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a Promise with use\n\nSuspense does not detect when data is fetched inside an Effect or event handler.\n\nThe exact way you would load data in the Posts component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nSpecifying what goes into the shell \n\nThe part of your app outside of any <Suspense> boundaries is called the shell:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<BigSpinner />}>\n\n        <Sidebar>\n\n          <Friends />\n\n          <Photos />\n\n        </Sidebar>\n\n        <Suspense fallback={<PostsGlimmer />}>\n\n          <Posts />\n\n        </Suspense>\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIt determines the earliest loading state that the user may see:\n\n<ProfileLayout>\n\n  <ProfileCover />\n\n  <BigSpinner />\n\n</ProfileLayout>\n\nIf you wrap the whole app into a <Suspense> boundary at the root, the shell will only contain that spinner. However, that’s not a pleasant user experience because seeing a big spinner on the screen can feel slower and more annoying than waiting a bit more and seeing the real layout. This is why usually you’ll want to place the <Suspense> boundaries so that the shell feels minimal but complete—like a skeleton of the entire page layout.\n\nThe onShellReady callback fires when the entire shell has been rendered. Usually, you’ll start streaming then:\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    response.setHeader('content-type', 'text/html');\n\n    pipe(response);\n\n  }\n\n});\n\nBy the time onShellReady fires, components in nested <Suspense> boundaries might still be loading data.\n\nLogging crashes on the server \n\nBy default, all errors on the server are logged to console. You can override this behavior to log crash reports:\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    response.setHeader('content-type', 'text/html');\n\n    pipe(response);\n\n  },\n\n  onError(error) {\n\n    console.error(error);\n\n    logServerCrashReport(error);\n\n  }\n\n});\n\nIf you provide a custom onError implementation, don’t forget to also log errors to the console like above.\n\nRecovering from errors inside the shell \n\nIn this example, the shell contains ProfileLayout, ProfileCover, and PostsGlimmer:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIf an error occurs while rendering those components, React won’t have any meaningful HTML to send to the client. Override onShellError to send a fallback HTML that doesn’t rely on server rendering as the last resort:\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    response.setHeader('content-type', 'text/html');\n\n    pipe(response);\n\n  },\n\n  onShellError(error) {\n\n    response.statusCode = 500;\n\n    response.setHeader('content-type', 'text/html');\n\n    response.send('<h1>Something went wrong</h1>'); \n\n  },\n\n  onError(error) {\n\n    console.error(error);\n\n    logServerCrashReport(error);\n\n  }\n\n});\n\nIf there is an error while generating the shell, both onError and onShellError will fire. Use onError for error reporting and use onShellError to send the fallback HTML document. Your fallback HTML does not have to be an error page. Instead, you may include an alternative shell that renders your app on the client only.\n\nRecovering from errors outside the shell \n\nIn this example, the <Posts /> component is wrapped in <Suspense> so it is not a part of the shell:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIf an error happens in the Posts component or somewhere inside it, React will try to recover from it:\n\nIt will emit the loading fallback for the closest <Suspense> boundary (PostsGlimmer) into the HTML.\nIt will “give up” on trying to render the Posts content on the server anymore.\nWhen the JavaScript code loads on the client, React will retry rendering Posts on the client.\n\nIf retrying rendering Posts on the client also fails, React will throw the error on the client. As with all the errors thrown during rendering, the closest parent error boundary determines how to present the error to the user. In practice, this means that the user will see a loading indicator until it is certain that the error is not recoverable.\n\nIf retrying rendering Posts on the client succeeds, the loading fallback from the server will be replaced with the client rendering output. The user will not know that there was a server error. However, the server onError callback and the client onRecoverableError callbacks will fire so that you can get notified about the error.\n\nSetting the status code \n\nStreaming introduces a tradeoff. You want to start streaming the page as early as possible so that the user can see the content sooner. However, once you start streaming, you can no longer set the response status code.\n\nBy dividing your app into the shell (above all <Suspense> boundaries) and the rest of the content, you’ve already solved a part of this problem. If the shell errors, you’ll get the onShellError callback which lets you set the error status code. Otherwise, you know that the app may recover on the client, so you can send “OK”.\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    response.statusCode = 200;\n\n    response.setHeader('content-type', 'text/html');\n\n    pipe(response);\n\n  },\n\n  onShellError(error) {\n\n    response.statusCode = 500;\n\n    response.setHeader('content-type', 'text/html');\n\n    response.send('<h1>Something went wrong</h1>'); \n\n  },\n\n  onError(error) {\n\n    console.error(error);\n\n    logServerCrashReport(error);\n\n  }\n\n});\n\nIf a component outside the shell (i.e. inside a <Suspense> boundary) throws an error, React will not stop rendering. This means that the onError callback will fire, but you will still get onShellReady instead of onShellError. This is because React will try to recover from that error on the client, as described above.\n\nHowever, if you’d like, you can use the fact that something has errored to set the status code:\n\nlet didError = false;\n\n\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    response.statusCode = didError ? 500 : 200;\n\n    response.setHeader('content-type', 'text/html');\n\n    pipe(response);\n\n  },\n\n  onShellError(error) {\n\n    response.statusCode = 500;\n\n    response.setHeader('content-type', 'text/html');\n\n    response.send('<h1>Something went wrong</h1>'); \n\n  },\n\n  onError(error) {\n\n    didError = true;\n\n    console.error(error);\n\n    logServerCrashReport(error);\n\n  }\n\n});\n\nThis will only catch errors outside the shell that happened while generating the initial shell content, so it’s not exhaustive. If knowing whether an error occurred for some content is critical, you can move it up into the shell.\n\nHandling different errors in different ways \n\nYou can create your own Error subclasses and use the instanceof operator to check which error is thrown. For example, you can define a custom NotFoundError and throw it from your component. Then your onError, onShellReady, and onShellError callbacks can do something different depending on the error type:\n\nlet didError = false;\n\nlet caughtError = null;\n\n\n\nfunction getStatusCode() {\n\n  if (didError) {\n\n    if (caughtError instanceof NotFoundError) {\n\n      return 404;\n\n    } else {\n\n      return 500;\n\n    }\n\n  } else {\n\n    return 200;\n\n  }\n\n}\n\n\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    response.statusCode = getStatusCode();\n\n    response.setHeader('content-type', 'text/html');\n\n    pipe(response);\n\n  },\n\n  onShellError(error) {\n\n   response.statusCode = getStatusCode();\n\n   response.setHeader('content-type', 'text/html');\n\n   response.send('<h1>Something went wrong</h1>'); \n\n  },\n\n  onError(error) {\n\n    didError = true;\n\n    caughtError = error;\n\n    console.error(error);\n\n    logServerCrashReport(error);\n\n  }\n\n});\n\nKeep in mind that once you emit the shell and start streaming, you can’t change the status code.\n\nWaiting for all content to load for crawlers and static generation \n\nStreaming offers a better user experience because the user can see the content as it becomes available.\n\nHowever, when a crawler visits your page, or if you’re generating the pages at the build time, you might want to let all of the content load first and then produce the final HTML output instead of revealing it progressively.\n\nYou can wait for all the content to load using the onAllReady callback:\n\nlet didError = false;\n\nlet isCrawler = // ... depends on your bot detection strategy ...\n\n\n\nconst { pipe } = renderToPipeableStream(<App />, {\n\n  bootstrapScripts: ['/main.js'],\n\n  onShellReady() {\n\n    if (!isCrawler) {\n\n      response.statusCode = didError ? 500 : 200;\n\n      response.setHeader('content-type', 'text/html');\n\n      pipe(response);\n\n    }\n\n  },\n\n  onShellError(error) {\n\n    response.statusCode = 500;\n\n    response.setHeader('content-type', 'text/html');\n\n    response.send('<h1>Something went wrong</h1>'); \n\n  },\n\n  onAllReady() {\n\n    if (isCrawler) {\n\n      response.statusCode = didError ? 500 : 200;\n\n      response.setHeader('content-type', 'text/html');\n\n      pipe(response);      \n\n    }\n\n  },\n\n  onError(error) {\n\n    didError = true;\n\n    console.error(error);\n\n    logServerCrashReport(error);\n\n  }\n\n});\n\nA regular visitor will get a stream of progressively loaded content. A crawler will receive the final HTML output after all the data loads. However, this also means that the crawler will have to wait for all data, some of which might be slow to load or error. Depending on your app, you could choose to send the shell to the crawlers too.\n\nAborting server rendering \n\nYou can force the server rendering to “give up” after a timeout:\n\nconst { pipe, abort } = renderToPipeableStream(<App />, {\n\n  // ...\n\n});\n\n\n\nsetTimeout(() => {\n\n  abort();\n\n}, 10000);\n\nReact will flush the remaining loading fallbacks as HTML, and will attempt to render the rest on the client.\n\nPREVIOUS\nServer APIs\nNEXT\nrenderToReadableStream"
  },
  {
    "title": "renderToReadableStream – React",
    "url": "https://react.dev/reference/react-dom/server/renderToReadableStream",
    "html": "API REFERENCE\nSERVER APIS\nrenderToReadableStream\n\nrenderToReadableStream renders a React tree to a Readable Web Stream.\n\nconst stream = await renderToReadableStream(reactNode, options?)\nReference\nrenderToReadableStream(reactNode, options?)\nUsage\nRendering a React tree as HTML to a Readable Web Stream\nStreaming more content as it loads\nSpecifying what goes into the shell\nLogging crashes on the server\nRecovering from errors inside the shell\nRecovering from errors outside the shell\nSetting the status code\nHandling different errors in different ways\nWaiting for all content to load for crawlers and static generation\nAborting server rendering\nNote\n\nThis API depends on Web Streams. For Node.js, use renderToPipeableStream instead.\n\nReference \nrenderToReadableStream(reactNode, options?) \n\nCall renderToReadableStream to render your React tree as HTML into a Readable Web Stream.\n\nimport { renderToReadableStream } from 'react-dom/server';\n\n\n\nasync function handler(request) {\n\n  const stream = await renderToReadableStream(<App />, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n  return new Response(stream, {\n\n    headers: { 'content-type': 'text/html' },\n\n  });\n\n}\n\nOn the client, call hydrateRoot to make the server-generated HTML interactive.\n\nSee more examples below.\n\nParameters \n\nreactNode: A React node you want to render to HTML. For example, a JSX element like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\n\noptional options: An object with streaming options.\n\noptional bootstrapScriptContent: If specified, this string will be placed in an inline <script> tag.\noptional bootstrapScripts: An array of string URLs for the <script> tags to emit on the page. Use this to include the <script> that calls hydrateRoot. Omit it if you don’t want to run React on the client at all.\noptional bootstrapModules: Like bootstrapScripts, but emits <script type=\"module\"> instead.\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page. Must be the same prefix as passed to hydrateRoot.\noptional namespaceURI: A string with the root namespace URI for the stream. Defaults to regular HTML. Pass 'http://www.w3.org/2000/svg' for SVG or 'http://www.w3.org/1998/Math/MathML' for MathML.\noptional nonce: A nonce string to allow scripts for script-src Content-Security-Policy.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error. You can also use it to adjust the status code before the shell is emitted.\noptional progressiveChunkSize: The number of bytes in a chunk. Read more about the default heuristic.\noptional signal: An abort signal that lets you abort server rendering and render the rest on the client.\nReturns \n\nrenderToReadableStream returns a Promise:\n\nIf rendering the shell is successful, that Promise will resolve to a Readable Web Stream.\nIf rendering the shell fails, the Promise will be rejected. Use this to output a fallback shell.\n\nThe returned stream has an additional property:\n\nallReady: A Promise that resolves when all rendering is complete, including both the shell and all additional content. You can await stream.allReady before returning a response for crawlers and static generation. If you do that, you won’t get any progressive loading. The stream will contain the final HTML.\nUsage \nRendering a React tree as HTML to a Readable Web Stream \n\nCall renderToReadableStream to render your React tree as HTML into a Readable Web Stream:\n\nimport { renderToReadableStream } from 'react-dom/server';\n\n\n\nasync function handler(request) {\n\n  const stream = await renderToReadableStream(<App />, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n  return new Response(stream, {\n\n    headers: { 'content-type': 'text/html' },\n\n  });\n\n}\n\nAlong with the root component, you need to provide a list of bootstrap <script> paths. Your root component should return the entire document including the root <html> tag.\n\nFor example, it might look like this:\n\nexport default function App() {\n\n  return (\n\n    <html>\n\n      <head>\n\n        <meta charSet=\"utf-8\" />\n\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n        <link rel=\"stylesheet\" href=\"/styles.css\"></link>\n\n        <title>My app</title>\n\n      </head>\n\n      <body>\n\n        <Router />\n\n      </body>\n\n    </html>\n\n  );\n\n}\n\nReact will inject the doctype and your bootstrap <script> tags into the resulting HTML stream:\n\n<!DOCTYPE html>\n\n<html>\n\n  <!-- ... HTML from your components ... -->\n\n</html>\n\n<script src=\"/main.js\" async=\"\"></script>\n\nOn the client, your bootstrap script should hydrate the entire document with a call to hydrateRoot:\n\nimport { hydrateRoot } from 'react-dom/client';\n\nimport App from './App.js';\n\n\n\nhydrateRoot(document, <App />);\n\nThis will attach event listeners to the server-generated HTML and make it interactive.\n\nDEEP DIVE\nReading CSS and JS asset paths from the build output \nShow Details\nStreaming more content as it loads \n\nStreaming allows the user to start seeing the content even before all the data has loaded on the server. For example, consider a profile page that shows a cover, a sidebar with friends and photos, and a list of posts:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Sidebar>\n\n        <Friends />\n\n        <Photos />\n\n      </Sidebar>\n\n      <Posts />\n\n    </ProfileLayout>\n\n  );\n\n}\n\nImagine that loading data for <Posts /> takes some time. Ideally, you’d want to show the rest of the profile page content to the user without waiting for the posts. To do this, wrap Posts in a <Suspense> boundary:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Sidebar>\n\n        <Friends />\n\n        <Photos />\n\n      </Sidebar>\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nThis tells React to start streaming the HTML before Posts loads its data. React will send the HTML for the loading fallback (PostsGlimmer) first, and then, when Posts finishes loading its data, React will send the remaining HTML along with an inline <script> tag that replaces the loading fallback with that HTML. From the user’s perspective, the page will first appear with the PostsGlimmer, later replaced by the Posts.\n\nYou can further nest <Suspense> boundaries to create a more granular loading sequence:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<BigSpinner />}>\n\n        <Sidebar>\n\n          <Friends />\n\n          <Photos />\n\n        </Sidebar>\n\n        <Suspense fallback={<PostsGlimmer />}>\n\n          <Posts />\n\n        </Suspense>\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIn this example, React can start streaming the page even earlier. Only ProfileLayout and ProfileCover must finish rendering first because they are not wrapped in any <Suspense> boundary. However, if Sidebar, Friends, or Photos need to load some data, React will send the HTML for the BigSpinner fallback instead. Then, as more data becomes available, more content will continue to be revealed until all of it becomes visible.\n\nStreaming does not need to wait for React itself to load in the browser, or for your app to become interactive. The HTML content from the server will get progressively revealed before any of the <script> tags load.\n\nRead more about how streaming HTML works.\n\nNote\n\nOnly Suspense-enabled data sources will activate the Suspense component. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a Promise with use\n\nSuspense does not detect when data is fetched inside an Effect or event handler.\n\nThe exact way you would load data in the Posts component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nSpecifying what goes into the shell \n\nThe part of your app outside of any <Suspense> boundaries is called the shell:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<BigSpinner />}>\n\n        <Sidebar>\n\n          <Friends />\n\n          <Photos />\n\n        </Sidebar>\n\n        <Suspense fallback={<PostsGlimmer />}>\n\n          <Posts />\n\n        </Suspense>\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIt determines the earliest loading state that the user may see:\n\n<ProfileLayout>\n\n  <ProfileCover />\n\n  <BigSpinner />\n\n</ProfileLayout>\n\nIf you wrap the whole app into a <Suspense> boundary at the root, the shell will only contain that spinner. However, that’s not a pleasant user experience because seeing a big spinner on the screen can feel slower and more annoying than waiting a bit more and seeing the real layout. This is why usually you’ll want to place the <Suspense> boundaries so that the shell feels minimal but complete—like a skeleton of the entire page layout.\n\nThe async call to renderToReadableStream will resolve to a stream as soon as the entire shell has been rendered. Usually, you’ll start streaming then by creating and returning a response with that stream:\n\nasync function handler(request) {\n\n  const stream = await renderToReadableStream(<App />, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n  return new Response(stream, {\n\n    headers: { 'content-type': 'text/html' },\n\n  });\n\n}\n\nBy the time the stream is returned, components in nested <Suspense> boundaries might still be loading data.\n\nLogging crashes on the server \n\nBy default, all errors on the server are logged to console. You can override this behavior to log crash reports:\n\nasync function handler(request) {\n\n  const stream = await renderToReadableStream(<App />, {\n\n    bootstrapScripts: ['/main.js'],\n\n    onError(error) {\n\n      console.error(error);\n\n      logServerCrashReport(error);\n\n    }\n\n  });\n\n  return new Response(stream, {\n\n    headers: { 'content-type': 'text/html' },\n\n  });\n\n}\n\nIf you provide a custom onError implementation, don’t forget to also log errors to the console like above.\n\nRecovering from errors inside the shell \n\nIn this example, the shell contains ProfileLayout, ProfileCover, and PostsGlimmer:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIf an error occurs while rendering those components, React won’t have any meaningful HTML to send to the client. Wrap your renderToReadableStream call in a try...catch to send a fallback HTML that doesn’t rely on server rendering as the last resort:\n\nasync function handler(request) {\n\n  try {\n\n    const stream = await renderToReadableStream(<App />, {\n\n      bootstrapScripts: ['/main.js'],\n\n      onError(error) {\n\n        console.error(error);\n\n        logServerCrashReport(error);\n\n      }\n\n    });\n\n    return new Response(stream, {\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  } catch (error) {\n\n    return new Response('<h1>Something went wrong</h1>', {\n\n      status: 500,\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  }\n\n}\n\nIf there is an error while generating the shell, both onError and your catch block will fire. Use onError for error reporting and use the catch block to send the fallback HTML document. Your fallback HTML does not have to be an error page. Instead, you may include an alternative shell that renders your app on the client only.\n\nRecovering from errors outside the shell \n\nIn this example, the <Posts /> component is wrapped in <Suspense> so it is not a part of the shell:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nIf an error happens in the Posts component or somewhere inside it, React will try to recover from it:\n\nIt will emit the loading fallback for the closest <Suspense> boundary (PostsGlimmer) into the HTML.\nIt will “give up” on trying to render the Posts content on the server anymore.\nWhen the JavaScript code loads on the client, React will retry rendering Posts on the client.\n\nIf retrying rendering Posts on the client also fails, React will throw the error on the client. As with all the errors thrown during rendering, the closest parent error boundary determines how to present the error to the user. In practice, this means that the user will see a loading indicator until it is certain that the error is not recoverable.\n\nIf retrying rendering Posts on the client succeeds, the loading fallback from the server will be replaced with the client rendering output. The user will not know that there was a server error. However, the server onError callback and the client onRecoverableError callbacks will fire so that you can get notified about the error.\n\nSetting the status code \n\nStreaming introduces a tradeoff. You want to start streaming the page as early as possible so that the user can see the content sooner. However, once you start streaming, you can no longer set the response status code.\n\nBy dividing your app into the shell (above all <Suspense> boundaries) and the rest of the content, you’ve already solved a part of this problem. If the shell errors, your catch block will run which lets you set the error status code. Otherwise, you know that the app may recover on the client, so you can send “OK”.\n\nasync function handler(request) {\n\n  try {\n\n    const stream = await renderToReadableStream(<App />, {\n\n      bootstrapScripts: ['/main.js'],\n\n      onError(error) {\n\n        console.error(error);\n\n        logServerCrashReport(error);\n\n      }\n\n    });\n\n    return new Response(stream, {\n\n      status: 200,\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  } catch (error) {\n\n    return new Response('<h1>Something went wrong</h1>', {\n\n      status: 500,\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  }\n\n}\n\nIf a component outside the shell (i.e. inside a <Suspense> boundary) throws an error, React will not stop rendering. This means that the onError callback will fire, but your code will continue running without getting into the catch block. This is because React will try to recover from that error on the client, as described above.\n\nHowever, if you’d like, you can use the fact that something has errored to set the status code:\n\nasync function handler(request) {\n\n  try {\n\n    let didError = false;\n\n    const stream = await renderToReadableStream(<App />, {\n\n      bootstrapScripts: ['/main.js'],\n\n      onError(error) {\n\n        didError = true;\n\n        console.error(error);\n\n        logServerCrashReport(error);\n\n      }\n\n    });\n\n    return new Response(stream, {\n\n      status: didError ? 500 : 200,\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  } catch (error) {\n\n    return new Response('<h1>Something went wrong</h1>', {\n\n      status: 500,\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  }\n\n}\n\nThis will only catch errors outside the shell that happened while generating the initial shell content, so it’s not exhaustive. If knowing whether an error occurred for some content is critical, you can move it up into the shell.\n\nHandling different errors in different ways \n\nYou can create your own Error subclasses and use the instanceof operator to check which error is thrown. For example, you can define a custom NotFoundError and throw it from your component. Then you can save the error in onError and do something different before returning the response depending on the error type:\n\nasync function handler(request) {\n\n  let didError = false;\n\n  let caughtError = null;\n\n\n\n  function getStatusCode() {\n\n    if (didError) {\n\n      if (caughtError instanceof NotFoundError) {\n\n        return 404;\n\n      } else {\n\n        return 500;\n\n      }\n\n    } else {\n\n      return 200;\n\n    }\n\n  }\n\n\n\n  try {\n\n    const stream = await renderToReadableStream(<App />, {\n\n      bootstrapScripts: ['/main.js'],\n\n      onError(error) {\n\n        didError = true;\n\n        caughtError = error;\n\n        console.error(error);\n\n        logServerCrashReport(error);\n\n      }\n\n    });\n\n    return new Response(stream, {\n\n      status: getStatusCode(),\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  } catch (error) {\n\n    return new Response('<h1>Something went wrong</h1>', {\n\n      status: getStatusCode(),\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  }\n\n}\n\nKeep in mind that once you emit the shell and start streaming, you can’t change the status code.\n\nWaiting for all content to load for crawlers and static generation \n\nStreaming offers a better user experience because the user can see the content as it becomes available.\n\nHowever, when a crawler visits your page, or if you’re generating the pages at the build time, you might want to let all of the content load first and then produce the final HTML output instead of revealing it progressively.\n\nYou can wait for all the content to load by awaiting the stream.allReady Promise:\n\nasync function handler(request) {\n\n  try {\n\n    let didError = false;\n\n    const stream = await renderToReadableStream(<App />, {\n\n      bootstrapScripts: ['/main.js'],\n\n      onError(error) {\n\n        didError = true;\n\n        console.error(error);\n\n        logServerCrashReport(error);\n\n      }\n\n    });\n\n    let isCrawler = // ... depends on your bot detection strategy ...\n\n    if (isCrawler) {\n\n      await stream.allReady;\n\n    }\n\n    return new Response(stream, {\n\n      status: didError ? 500 : 200,\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  } catch (error) {\n\n    return new Response('<h1>Something went wrong</h1>', {\n\n      status: 500,\n\n      headers: { 'content-type': 'text/html' },\n\n    });\n\n  }\n\n}\n\nA regular visitor will get a stream of progressively loaded content. A crawler will receive the final HTML output after all the data loads. However, this also means that the crawler will have to wait for all data, some of which might be slow to load or error. Depending on your app, you could choose to send the shell to the crawlers too.\n\nAborting server rendering \n\nYou can force the server rendering to “give up” after a timeout:\n\nasync function handler(request) {\n\n  try {\n\n    const controller = new AbortController();\n\n    setTimeout(() => {\n\n      controller.abort();\n\n    }, 10000);\n\n\n\n    const stream = await renderToReadableStream(<App />, {\n\n      signal: controller.signal,\n\n      bootstrapScripts: ['/main.js'],\n\n      onError(error) {\n\n        didError = true;\n\n        console.error(error);\n\n        logServerCrashReport(error);\n\n      }\n\n    });\n\n    // ...\n\nReact will flush the remaining loading fallbacks as HTML, and will attempt to render the rest on the client.\n\nPREVIOUS\nrenderToPipeableStream\nNEXT\nrenderToStaticMarkup"
  },
  {
    "title": "renderToStaticMarkup – React",
    "url": "https://react.dev/reference/react-dom/server/renderToStaticMarkup",
    "html": "API REFERENCE\nSERVER APIS\nrenderToStaticMarkup\n\nrenderToStaticMarkup renders a non-interactive React tree to an HTML string.\n\nconst html = renderToStaticMarkup(reactNode, options?)\nReference\nrenderToStaticMarkup(reactNode, options?)\nUsage\nRendering a non-interactive React tree as HTML to a string\nReference \nrenderToStaticMarkup(reactNode, options?) \n\nOn the server, call renderToStaticMarkup to render your app to HTML.\n\nimport { renderToStaticMarkup } from 'react-dom/server';\n\n\n\nconst html = renderToStaticMarkup(<Page />);\n\nIt will produce non-interactive HTML output of your React components.\n\nSee more examples below.\n\nParameters \nreactNode: A React node you want to render to HTML. For example, a JSX node like <Page />.\noptional options: An object for server render.\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page.\nReturns \n\nAn HTML string.\n\nCaveats \n\nrenderToStaticMarkup output cannot be hydrated.\n\nrenderToStaticMarkup has limited Suspense support. If a component suspends, renderToStaticMarkup immediately sends its fallback as HTML.\n\nrenderToStaticMarkup works in the browser, but using it in the client code is not recommended. If you need to render a component to HTML in the browser, get the HTML by rendering it into a DOM node.\n\nUsage \nRendering a non-interactive React tree as HTML to a string \n\nCall renderToStaticMarkup to render your app to an HTML string which you can send with your server response:\n\nimport { renderToStaticMarkup } from 'react-dom/server';\n\n\n\n// The route handler syntax depends on your backend framework\n\napp.use('/', (request, response) => {\n\n  const html = renderToStaticMarkup(<Page />);\n\n  response.send(html);\n\n});\n\nThis will produce the initial non-interactive HTML output of your React components.\n\nPitfall\n\nThis method renders non-interactive HTML that cannot be hydrated.  This is useful if you want to use React as a simple static page generator, or if you’re rendering completely static content like emails.\n\nInteractive apps should use renderToString on the server and hydrateRoot on the client.\n\nPREVIOUS\nrenderToReadableStream\nNEXT\nrenderToString"
  },
  {
    "title": "renderToString – React",
    "url": "https://react.dev/reference/react-dom/server/renderToString",
    "html": "API REFERENCE\nSERVER APIS\nrenderToString\nPitfall\n\nrenderToString does not support streaming or waiting for data. See the alternatives.\n\nrenderToString renders a React tree to an HTML string.\n\nconst html = renderToString(reactNode, options?)\nReference\nrenderToString(reactNode, options?)\nUsage\nRendering a React tree as HTML to a string\nAlternatives\nMigrating from renderToString to a streaming render on the server\nMigrating from renderToString to a static prerender on the server\nRemoving renderToString from the client code\nTroubleshooting\nWhen a component suspends, the HTML always contains a fallback\nReference \nrenderToString(reactNode, options?) \n\nOn the server, call renderToString to render your app to HTML.\n\nimport { renderToString } from 'react-dom/server';\n\n\n\nconst html = renderToString(<App />);\n\nOn the client, call hydrateRoot to make the server-generated HTML interactive.\n\nSee more examples below.\n\nParameters \n\nreactNode: A React node you want to render to HTML. For example, a JSX node like <App />.\n\noptional options: An object for server render.\n\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page. Must be the same prefix as passed to hydrateRoot.\nReturns \n\nAn HTML string.\n\nCaveats \n\nrenderToString has limited Suspense support. If a component suspends, renderToString immediately sends its fallback as HTML.\n\nrenderToString works in the browser, but using it in the client code is not recommended.\n\nUsage \nRendering a React tree as HTML to a string \n\nCall renderToString to render your app to an HTML string which you can send with your server response:\n\nimport { renderToString } from 'react-dom/server';\n\n\n\n// The route handler syntax depends on your backend framework\n\napp.use('/', (request, response) => {\n\n  const html = renderToString(<App />);\n\n  response.send(html);\n\n});\n\nThis will produce the initial non-interactive HTML output of your React components. On the client, you will need to call hydrateRoot to hydrate that server-generated HTML and make it interactive.\n\nPitfall\n\nrenderToString does not support streaming or waiting for data. See the alternatives.\n\nAlternatives \nMigrating from renderToString to a streaming render on the server \n\nrenderToString returns a string immediately, so it does not support streaming content as it loads.\n\nWhen possible, we recommend using these fully-featured alternatives:\n\nIf you use Node.js, use renderToPipeableStream.\nIf you use Deno or a modern edge runtime with Web Streams, use renderToReadableStream.\n\nYou can continue using renderToString if your server environment does not support streams.\n\nMigrating from renderToString to a static prerender on the server \n\nrenderToString returns a string immediately, so it does not support waiting for data to load for static HTML generation.\n\nWe recommend using these fully-featured alternatives:\n\nIf you use Node.js, use prerenderToNodeStream.\nIf you use Deno or a modern edge runtime with Web Streams, use prerender.\n\nYou can continue using renderToString if your static site generation environment does not support streams.\n\nRemoving renderToString from the client code \n\nSometimes, renderToString is used on the client to convert some component to HTML.\n\n// 🚩 Unnecessary: using renderToString on the client\n\nimport { renderToString } from 'react-dom/server';\n\n\n\nconst html = renderToString(<MyIcon />);\n\nconsole.log(html); // For example, \"<svg>...</svg>\"\n\nImporting react-dom/server on the client unnecessarily increases your bundle size and should be avoided. If you need to render some component to HTML in the browser, use createRoot and read HTML from the DOM:\n\nimport { createRoot } from 'react-dom/client';\n\nimport { flushSync } from 'react-dom';\n\n\n\nconst div = document.createElement('div');\n\nconst root = createRoot(div);\n\nflushSync(() => {\n\n  root.render(<MyIcon />);\n\n});\n\nconsole.log(div.innerHTML); // For example, \"<svg>...</svg>\"\n\nThe flushSync call is necessary so that the DOM is updated before reading its innerHTML property.\n\nTroubleshooting \nWhen a component suspends, the HTML always contains a fallback \n\nrenderToString does not fully support Suspense.\n\nIf some component suspends (for example, because it’s defined with lazy or fetches data), renderToString will not wait for its content to resolve. Instead, renderToString will find the closest <Suspense> boundary above it and render its fallback prop in the HTML. The content will not appear until the client code loads.\n\nTo solve this, use one of the recommended streaming solutions. For server side rendering, they can stream content in chunks as it resolves on the server so that the user sees the page being progressively filled in before the client code loads. For static site generation, they can wait for all the content to resolve before generating the static HTML.\n\nPREVIOUS\nrenderToStaticMarkup\nNEXT\nresume"
  },
  {
    "title": "resume – React",
    "url": "https://react.dev/reference/react-dom/server/resume",
    "html": "API REFERENCE\nSERVER APIS\nresume\n\nresume streams a pre-rendered React tree to a Readable Web Stream.\n\nconst stream = await resume(reactNode, postponedState, options?)\nReference\nresume(node, postponedState, options?)\nUsage\nResuming a prerender\nFurther reading\nNote\n\nThis API depends on Web Streams. For Node.js, use resumeToNodeStream instead.\n\nReference \nresume(node, postponedState, options?) \n\nCall resume to resume rendering a pre-rendered React tree as HTML into a Readable Web Stream.\n\nimport { resume } from 'react-dom/server';\n\nimport {getPostponedState} from './storage';\n\n\n\nasync function handler(request, writable) {\n\n  const postponed = await getPostponedState(request);\n\n  const resumeStream = await resume(<App />, postponed);\n\n  return resumeStream.pipeTo(writable)\n\n}\n\nSee more examples below.\n\nParameters \nreactNode: The React node you called prerender with. For example, a JSX element like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\npostponedState: The opaque postpone object returned from a prerender API, loaded from wherever you stored it (e.g. redis, a file, or S3).\noptional options: An object with streaming options.\noptional nonce: A nonce string to allow scripts for script-src Content-Security-Policy.\noptional signal: An abort signal that lets you abort server rendering and render the rest on the client.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error.\nReturns \n\nresume returns a Promise:\n\nIf resume successfully produced a shell, that Promise will resolve to a Readable Web Stream. that can be piped to a Writable Web Stream..\nIf an error happens in the shell, the Promise will reject with that error.\n\nThe returned stream has an additional property:\n\nallReady: A Promise that resolves when all rendering is complete. You can await stream.allReady before returning a response for crawlers and static generation. If you do that, you won’t get any progressive loading. The stream will contain the final HTML.\nCaveats \nresume does not accept options for bootstrapScripts, bootstrapScriptContent, or bootstrapModules. Instead, you need to pass these options to the prerender call that generates the postponedState. You can also inject bootstrap content into the writable stream manually.\nresume does not accept identifierPrefix since the prefix needs to be the same in both prerender and resume.\nSince nonce cannot be provided to prerender, you should only provide nonce to resume if you’re not providing scripts to prerender.\nresume re-renders from the root until it finds a component that was not fully pre-rendered. Only fully prerendered Components (the Component and its children finished prerendering) are skipped entirely.\nUsage \nResuming a prerender \nindex.js\nindex.html\ndemo-helpers.js\nReload\nClear\nFork\nimport {\n  flushReadableStreamToFrame,\n  getUser,\n  Postponed,\n  sleep,\n} from \"./demo-helpers\";\nimport { StrictMode, Suspense, use, useEffect } from \"react\";\nimport { prerender } from \"react-dom/static\";\nimport { resume } from \"react-dom/server\";\nimport { hydrateRoot } from \"react-dom/client\";\n\nfunction Header() {\n  return <header>Me and my descendants can be prerendered</header>;\n}\n\nconst { promise: cookies, resolve: resolveCookies } = Promise.withResolvers();\n\nfunction Main() {\n  const { sessionID } = use(cookies);\n  const user = getUser(sessionID);\n\n  useEffect(() => {\n    console.log(\"reached interactivity!\");\n  }, []);\n\n  return (\n    <main>\n      Hello, {user.name}!\n      <button onClick={() => console.log(\"hydrated!\")}>\n        Clicking me requires hydration.\n      </button>\n    </main>\n  );\n}\n\nfunction Shell({ children }) {\n  // In a real app, this is where you would put your html and body.\n  // We're just using tags here we can include in an existing body for demonstration purposes\n  return (\n    <html>\n      <body>{children}</body>\n    </html>\n  );\n}\n\nfunction App() {\n  return (\n    <Shell>\n      <Suspense fallback=\"loading header\">\n        <Header />\n      </Suspense>\n      <Suspense fallback=\"loading main\">\n        <Main />\n      </Suspense>\n    </Shell>\n  );\n}\n\nasync function main(frame) {\n  // Layer 1\n  const controller = new AbortController();\n  const prerenderedApp = prerender(<App />, {\n    signal: controller.signal,\n    onError(error) {\n      if (error instanceof Postponed) {\n      } else {\n        console.error(error);\n      }\n    },\n  });\n  // We're immediately aborting in a macrotask.\n  // Any data fetching that's not available synchronously, or in a microtask, will not have finished.\n  setTimeout(() => {\n    controller.abort(new Postponed());\n  });\n\n  const { prelude, postponed } = await prerenderedApp;\n  await flushReadableStreamToFrame(prelude, frame);\n\n  // Layer 2\n  // Just waiting here for demonstration purposes.\n  // In a real app, the prelude and postponed state would've been serialized in Layer 1 and Layer would deserialize them.\n  // The prelude content could be flushed immediated as plain HTML while\n  // React is continuing to render from where the prerender left off.\n  await sleep(2000);\n\n  // You would get the cookies from the incoming HTTP request\n  resolveCookies({ sessionID: \"abc\" });\n\n  const stream = await resume(<App />, postponed);\n\n  await flushReadableStreamToFrame(stream, frame);\n\n  // Layer 3\n  // Just waiting here for demonstration purposes.\n  await sleep(2000);\n\n  hydrateRoot(frame.contentWindow.document, <App />);\n}\n\nmain(document.getElementById(\"container\"));\n\n\nShow more\nFurther reading \n\nResuming behaves like renderToReadableStream. For more examples, check out the usage section of renderToReadableStream.\nThe usage section of prerender includes examples of how to use prerender specifically.\n\nPREVIOUS\nrenderToString\nNEXT\nresumeToPipeableStream"
  },
  {
    "title": "resumeToPipeableStream – React",
    "url": "https://react.dev/reference/react-dom/server/resumeToPipeableStream",
    "html": "API REFERENCE\nSERVER APIS\nresumeToPipeableStream\n\nresumeToPipeableStream streams a pre-rendered React tree  to a pipeable Node.js Stream.\n\nconst {pipe, abort} = await resumeToPipeableStream(reactNode, postponedState, options?)\nReference\nresumeToPipeableStream(node, postponed, options?)\nUsage\nFurther reading\nNote\n\nThis API is specific to Node.js. Environments with Web Streams, like Deno and modern edge runtimes, should use resume instead.\n\nReference \nresumeToPipeableStream(node, postponed, options?) \n\nCall resume to resume rendering a pre-rendered React tree as HTML into a Node.js Stream.\n\nimport { resume } from 'react-dom/server';\n\nimport {getPostponedState} from './storage';\n\n\n\nasync function handler(request, response) {\n\n  const postponed = await getPostponedState(request);\n\n  const {pipe} = resumeToPipeableStream(<App />, postponed, {\n\n    onShellReady: () => {\n\n      pipe(response);\n\n    }\n\n  });\n\n}\n\nSee more examples below.\n\nParameters \nreactNode: The React node you called prerender with. For example, a JSX element like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\npostponedState: The opaque postpone object returned from a prerender API, loaded from wherever you stored it (e.g. redis, a file, or S3).\noptional options: An object with streaming options.\noptional nonce: A nonce string to allow scripts for script-src Content-Security-Policy.\noptional signal: An abort signal that lets you abort server rendering and render the rest on the client.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error.\noptional onShellReady: A callback that fires right after the shell has finished. You can call pipe here to start streaming. React will stream the additional content after the shell along with the inline <script> tags that replace the HTML loading fallbacks with the content.\noptional onShellError: A callback that fires if there was an error rendering the shell. It receives the error as an argument. No bytes were emitted from the stream yet, and neither onShellReady nor onAllReady will get called, so you can output a fallback HTML shell or use the prelude.\nReturns \n\nresume returns an object with two methods:\n\npipe outputs the HTML into the provided Writable Node.js Stream. Call pipe in onShellReady if you want to enable streaming, or in onAllReady for crawlers and static generation.\nabort lets you abort server rendering and render the rest on the client.\nCaveats \nresumeToPipeableStream does not accept options for bootstrapScripts, bootstrapScriptContent, or bootstrapModules. Instead, you need to pass these options to the prerender call that generates the postponedState. You can also inject bootstrap content into the writable stream manually.\nresumeToPipeableStream does not accept identifierPrefix since the prefix needs to be the same in both prerender and resumeToPipeableStream.\nSince nonce cannot be provided to prerender, you should only provide nonce to resumeToPipeableStream if you’re not providing scripts to prerender.\nresumeToPipeableStream re-renders from the root until it finds a component that was not fully pre-rendered. Only fully prerendered Components (the Component and its children finished prerendering) are skipped entirely.\nUsage \nFurther reading \n\nResuming behaves like renderToReadableStream. For more examples, check out the usage section of renderToReadableStream.\nThe usage section of prerender includes examples of how to use prerenderToNodeStream specifically.\n\nPREVIOUS\nresume\nNEXT\nStatic APIs"
  },
  {
    "title": "Static React DOM APIs – React",
    "url": "https://react.dev/reference/react-dom/static",
    "html": "API REFERENCE\nStatic React DOM APIs\n\nThe react-dom/static APIs let you generate static HTML for React components. They have limited functionality compared to the streaming APIs. A framework may call them for you. Most of your components don’t need to import or use them.\n\nStatic APIs for Web Streams \n\nThese methods are only available in the environments with Web Streams, which includes browsers, Deno, and some modern edge runtimes:\n\nprerender renders a React tree to static HTML with a Readable Web Stream.\nExperimental only resumeAndPrerender continues a prerendered React tree to static HTML with a Readable Web Stream.\n\nNode.js also includes these methods for compatibility, but they are not recommended due to worse performance. Use the dedicated Node.js APIs instead.\n\nStatic APIs for Node.js Streams \n\nThese methods are only available in the environments with Node.js Streams:\n\nprerenderToNodeStream renders a React tree to static HTML with a Node.js Stream.\nExperimental only resumeAndPrerenderToNodeStream continues a prerendered React tree to static HTML with a Node.js Stream.\nPREVIOUS\nresumeToPipeableStream\nNEXT\nprerender"
  },
  {
    "title": "prerender – React",
    "url": "https://react.dev/reference/react-dom/static/prerender",
    "html": "API REFERENCE\nSTATIC APIS\nprerender\n\nprerender renders a React tree to a static HTML string using a Web Stream.\n\nconst {prelude, postponed} = await prerender(reactNode, options?)\nReference\nprerender(reactNode, options?)\nUsage\nRendering a React tree to a stream of static HTML\nRendering a React tree to a string of static HTML\nWaiting for all data to load\nAborting prerendering\nTroubleshooting\nMy stream doesn’t start until the entire app is rendered\nNote\n\nThis API depends on Web Streams. For Node.js, use prerenderToNodeStream instead.\n\nReference \nprerender(reactNode, options?) \n\nCall prerender to render your app to static HTML.\n\nimport { prerender } from 'react-dom/static';\n\n\n\nasync function handler(request, response) {\n\n  const {prelude} = await prerender(<App />, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n  return new Response(prelude, {\n\n    headers: { 'content-type': 'text/html' },\n\n  });\n\n}\n\nOn the client, call hydrateRoot to make the server-generated HTML interactive.\n\nSee more examples below.\n\nParameters \n\nreactNode: A React node you want to render to HTML. For example, a JSX node like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\n\noptional options: An object with static generation options.\n\noptional bootstrapScriptContent: If specified, this string will be placed in an inline <script> tag.\noptional bootstrapScripts: An array of string URLs for the <script> tags to emit on the page. Use this to include the <script> that calls hydrateRoot. Omit it if you don’t want to run React on the client at all.\noptional bootstrapModules: Like bootstrapScripts, but emits <script type=\"module\"> instead.\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page. Must be the same prefix as passed to hydrateRoot.\noptional namespaceURI: A string with the root namespace URI for the stream. Defaults to regular HTML. Pass 'http://www.w3.org/2000/svg' for SVG or 'http://www.w3.org/1998/Math/MathML' for MathML.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error. You can also use it to adjust the status code before the shell is emitted.\noptional progressiveChunkSize: The number of bytes in a chunk. Read more about the default heuristic.\noptional signal: An abort signal that lets you abort prerendering and render the rest on the client.\nReturns \n\nprerender returns a Promise:\n\nIf rendering the is successful, the Promise will resolve to an object containing:\nprelude: a Web Stream of HTML. You can use this stream to send a response in chunks, or you can read the entire stream into a string.\npostponed: a JSON-serializeable, opaque object that can be passed to resume if prerender did not finish. Otherwise null indicating that the prelude contains all the content and no resume is necessary.\nIf rendering fails, the Promise will be rejected. Use this to output a fallback shell.\nCaveats \n\nnonce is not an available option when prerendering. Nonces must be unique per request and if you use nonces to secure your application with CSP it would be inappropriate and insecure to include the nonce value in the prerender itself.\n\nNote\nWhen should I use prerender? \n\nThe static prerender API is used for static server-side generation (SSG). Unlike renderToString, prerender waits for all data to load before resolving. This makes it suitable for generating static HTML for a full page, including data that needs to be fetched using Suspense. To stream content as it loads, use a streaming server-side render (SSR) API like renderToReadableStream.\n\nprerender can be aborted and later either continued with resumeAndPrerender or resumed with resume to support partial pre-rendering.\n\nUsage \nRendering a React tree to a stream of static HTML \n\nCall prerender to render your React tree to static HTML into a Readable Web Stream::\n\nimport { prerender } from 'react-dom/static';\n\n\n\nasync function handler(request) {\n\n  const {prelude} = await prerender(<App />, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n  return new Response(prelude, {\n\n    headers: { 'content-type': 'text/html' },\n\n  });\n\n}\n\nAlong with the root component, you need to provide a list of bootstrap <script> paths. Your root component should return the entire document including the root <html> tag.\n\nFor example, it might look like this:\n\nexport default function App() {\n\n  return (\n\n    <html>\n\n      <head>\n\n        <meta charSet=\"utf-8\" />\n\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n        <link rel=\"stylesheet\" href=\"/styles.css\"></link>\n\n        <title>My app</title>\n\n      </head>\n\n      <body>\n\n        <Router />\n\n      </body>\n\n    </html>\n\n  );\n\n}\n\nReact will inject the doctype and your bootstrap <script> tags into the resulting HTML stream:\n\n<!DOCTYPE html>\n\n<html>\n\n  <!-- ... HTML from your components ... -->\n\n</html>\n\n<script src=\"/main.js\" async=\"\"></script>\n\nOn the client, your bootstrap script should hydrate the entire document with a call to hydrateRoot:\n\nimport { hydrateRoot } from 'react-dom/client';\n\nimport App from './App.js';\n\n\n\nhydrateRoot(document, <App />);\n\nThis will attach event listeners to the static server-generated HTML and make it interactive.\n\nDEEP DIVE\nReading CSS and JS asset paths from the build output \nShow Details\nRendering a React tree to a string of static HTML \n\nCall prerender to render your app to a static HTML string:\n\nimport { prerender } from 'react-dom/static';\n\n\n\nasync function renderToString() {\n\n  const {prelude} = await prerender(<App />, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n\n\n  const reader = prelude.getReader();\n\n  let content = '';\n\n  while (true) {\n\n    const {done, value} = await reader.read();\n\n    if (done) {\n\n      return content;\n\n    }\n\n    content += Buffer.from(value).toString('utf8');\n\n  }\n\n}\n\nThis will produce the initial non-interactive HTML output of your React components. On the client, you will need to call hydrateRoot to hydrate that server-generated HTML and make it interactive.\n\nWaiting for all data to load \n\nprerender waits for all data to load before finishing the static HTML generation and resolving. For example, consider a profile page that shows a cover, a sidebar with friends and photos, and a list of posts:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Sidebar>\n\n        <Friends />\n\n        <Photos />\n\n      </Sidebar>\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nImagine that <Posts /> needs to load some data, which takes some time. Ideally, you’d want wait for the posts to finish so it’s included in the HTML. To do this, you can use Suspense to suspend on the data, and prerender will wait for the suspended content to finish before resolving to the static HTML.\n\nNote\n\nOnly Suspense-enabled data sources will activate the Suspense component. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a Promise with use\n\nSuspense does not detect when data is fetched inside an Effect or event handler.\n\nThe exact way you would load data in the Posts component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nAborting prerendering \n\nYou can force the prerender to “give up” after a timeout:\n\nasync function renderToString() {\n\n  const controller = new AbortController();\n\n  setTimeout(() => {\n\n    controller.abort()\n\n  }, 10000);\n\n\n\n  try {\n\n    // the prelude will contain all the HTML that was prerendered\n\n    // before the controller aborted.\n\n    const {prelude} = await prerender(<App />, {\n\n      signal: controller.signal,\n\n    });\n\n    //...\n\nAny Suspense boundaries with incomplete children will be included in the prelude in the fallback state.\n\nThis can be used for partial prerendering together with resume or resumeAndPrerender.\n\nTroubleshooting \nMy stream doesn’t start until the entire app is rendered \n\nThe prerender response waits for the entire app to finish rendering, including waiting for all Suspense boundaries to resolve, before resolving. It is designed for static site generation (SSG) ahead of time and does not support streaming more content as it loads.\n\nTo stream content as it loads, use a streaming server render API like renderToReadableStream.\n\nPREVIOUS\nStatic APIs\nNEXT\nprerenderToNodeStream"
  },
  {
    "title": "prerenderToNodeStream – React",
    "url": "https://react.dev/reference/react-dom/static/prerenderToNodeStream",
    "html": "API REFERENCE\nSTATIC APIS\nprerenderToNodeStream\n\nprerenderToNodeStream renders a React tree to a static HTML string using a Node.js Stream.\n\nconst {prelude, postponed} = await prerenderToNodeStream(reactNode, options?)\nReference\nprerenderToNodeStream(reactNode, options?)\nUsage\nRendering a React tree to a stream of static HTML\nRendering a React tree to a string of static HTML\nWaiting for all data to load\nAborting prerendering\nTroubleshooting\nMy stream doesn’t start until the entire app is rendered\nNote\n\nThis API is specific to Node.js. Environments with Web Streams, like Deno and modern edge runtimes, should use prerender instead.\n\nReference \nprerenderToNodeStream(reactNode, options?) \n\nCall prerenderToNodeStream to render your app to static HTML.\n\nimport { prerenderToNodeStream } from 'react-dom/static';\n\n\n\n// The route handler syntax depends on your backend framework\n\napp.use('/', async (request, response) => {\n\n  const { prelude } = await prerenderToNodeStream(<App />, {\n\n    bootstrapScripts: ['/main.js'],\n\n  });\n\n\n\n  response.setHeader('Content-Type', 'text/plain');\n\n  prelude.pipe(response);\n\n});\n\nOn the client, call hydrateRoot to make the server-generated HTML interactive.\n\nSee more examples below.\n\nParameters \n\nreactNode: A React node you want to render to HTML. For example, a JSX node like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\n\noptional options: An object with static generation options.\n\noptional bootstrapScriptContent: If specified, this string will be placed in an inline <script> tag.\noptional bootstrapScripts: An array of string URLs for the <script> tags to emit on the page. Use this to include the <script> that calls hydrateRoot. Omit it if you don’t want to run React on the client at all.\noptional bootstrapModules: Like bootstrapScripts, but emits <script type=\"module\"> instead.\noptional identifierPrefix: A string prefix React uses for IDs generated by useId. Useful to avoid conflicts when using multiple roots on the same page. Must be the same prefix as passed to hydrateRoot.\noptional namespaceURI: A string with the root namespace URI for the stream. Defaults to regular HTML. Pass 'http://www.w3.org/2000/svg' for SVG or 'http://www.w3.org/1998/Math/MathML' for MathML.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error. You can also use it to adjust the status code before the shell is emitted.\noptional progressiveChunkSize: The number of bytes in a chunk. Read more about the default heuristic.\noptional signal: An abort signal that lets you abort prerendering and render the rest on the client.\nReturns \n\nprerenderToNodeStream returns a Promise:\n\nIf rendering the is successful, the Promise will resolve to an object containing:\nprelude: a Node.js Stream. of HTML. You can use this stream to send a response in chunks, or you can read the entire stream into a string.\npostponed: a JSON-serializeable, opaque object that can be passed to resumeToPipeableStream if prerenderToNodeStream did not finish. Otherwise null indicating that the prelude contains all the content and no resume is necessary.\nIf rendering fails, the Promise will be rejected. Use this to output a fallback shell.\nCaveats \n\nnonce is not an available option when prerendering. Nonces must be unique per request and if you use nonces to secure your application with CSP it would be inappropriate and insecure to include the nonce value in the prerender itself.\n\nNote\nWhen should I use prerenderToNodeStream? \n\nThe static prerenderToNodeStream API is used for static server-side generation (SSG). Unlike renderToString, prerenderToNodeStream waits for all data to load before resolving. This makes it suitable for generating static HTML for a full page, including data that needs to be fetched using Suspense. To stream content as it loads, use a streaming server-side render (SSR) API like renderToReadableStream.\n\nprerenderToNodeStream can be aborted and resumed later with resumeToPipeableStream to support partial pre-rendering.\n\nUsage \nRendering a React tree to a stream of static HTML \n\nCall prerenderToNodeStream to render your React tree to static HTML into a Node.js Stream:\n\nimport { prerenderToNodeStream } from 'react-dom/static';\n\n\n\n// The route handler syntax depends on your backend framework\n\napp.use('/', async (request, response) => {\n\n  const { prelude } = await prerenderToNodeStream(<App />, {\n\n    bootstrapScripts: ['/main.js'],\n\n  });\n\n\n\n  response.setHeader('Content-Type', 'text/plain');\n\n  prelude.pipe(response);\n\n});\n\nAlong with the root component, you need to provide a list of bootstrap <script> paths. Your root component should return the entire document including the root <html> tag.\n\nFor example, it might look like this:\n\nexport default function App() {\n\n  return (\n\n    <html>\n\n      <head>\n\n        <meta charSet=\"utf-8\" />\n\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n        <link rel=\"stylesheet\" href=\"/styles.css\"></link>\n\n        <title>My app</title>\n\n      </head>\n\n      <body>\n\n        <Router />\n\n      </body>\n\n    </html>\n\n  );\n\n}\n\nReact will inject the doctype and your bootstrap <script> tags into the resulting HTML stream:\n\n<!DOCTYPE html>\n\n<html>\n\n  <!-- ... HTML from your components ... -->\n\n</html>\n\n<script src=\"/main.js\" async=\"\"></script>\n\nOn the client, your bootstrap script should hydrate the entire document with a call to hydrateRoot:\n\nimport { hydrateRoot } from 'react-dom/client';\n\nimport App from './App.js';\n\n\n\nhydrateRoot(document, <App />);\n\nThis will attach event listeners to the static server-generated HTML and make it interactive.\n\nDEEP DIVE\nReading CSS and JS asset paths from the build output \nShow Details\nRendering a React tree to a string of static HTML \n\nCall prerenderToNodeStream to render your app to a static HTML string:\n\nimport { prerenderToNodeStream } from 'react-dom/static';\n\n\n\nasync function renderToString() {\n\n  const {prelude} = await prerenderToNodeStream(<App />, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n\n\n  return new Promise((resolve, reject) => {\n\n    let data = '';\n\n    prelude.on('data', chunk => {\n\n      data += chunk;\n\n    });\n\n    prelude.on('end', () => resolve(data));\n\n    prelude.on('error', reject);\n\n  });\n\n}\n\nThis will produce the initial non-interactive HTML output of your React components. On the client, you will need to call hydrateRoot to hydrate that server-generated HTML and make it interactive.\n\nWaiting for all data to load \n\nprerenderToNodeStream waits for all data to load before finishing the static HTML generation and resolving. For example, consider a profile page that shows a cover, a sidebar with friends and photos, and a list of posts:\n\nfunction ProfilePage() {\n\n  return (\n\n    <ProfileLayout>\n\n      <ProfileCover />\n\n      <Sidebar>\n\n        <Friends />\n\n        <Photos />\n\n      </Sidebar>\n\n      <Suspense fallback={<PostsGlimmer />}>\n\n        <Posts />\n\n      </Suspense>\n\n    </ProfileLayout>\n\n  );\n\n}\n\nImagine that <Posts /> needs to load some data, which takes some time. Ideally, you’d want wait for the posts to finish so it’s included in the HTML. To do this, you can use Suspense to suspend on the data, and prerenderToNodeStream will wait for the suspended content to finish before resolving to the static HTML.\n\nNote\n\nOnly Suspense-enabled data sources will activate the Suspense component. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a Promise with use\n\nSuspense does not detect when data is fetched inside an Effect or event handler.\n\nThe exact way you would load data in the Posts component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nAborting prerendering \n\nYou can force the prerender to “give up” after a timeout:\n\nasync function renderToString() {\n\n  const controller = new AbortController();\n\n  setTimeout(() => {\n\n    controller.abort()\n\n  }, 10000);\n\n\n\n  try {\n\n    // the prelude will contain all the HTML that was prerendered\n\n    // before the controller aborted.\n\n    const {prelude} = await prerenderToNodeStream(<App />, {\n\n      signal: controller.signal,\n\n    });\n\n    //...\n\nAny Suspense boundaries with incomplete children will be included in the prelude in the fallback state.\n\nThis can be used for partial prerendering together with resumeToPipeableStream or resumeAndPrerenderToNodeStream.\n\nTroubleshooting \nMy stream doesn’t start until the entire app is rendered \n\nThe prerenderToNodeStream response waits for the entire app to finish rendering, including waiting for all Suspense boundaries to resolve, before resolving. It is designed for static site generation (SSG) ahead of time and does not support streaming more content as it loads.\n\nTo stream content as it loads, use a streaming server render API like renderToPipeableStream.\n\nPREVIOUS\nprerender\nNEXT\nresumeAndPrerender"
  },
  {
    "title": "resumeAndPrerender – React",
    "url": "https://react.dev/reference/react-dom/static/resumeAndPrerender",
    "html": "API REFERENCE\nSTATIC APIS\nresumeAndPrerender\n\nresumeAndPrerender continues a prerendered React tree to a static HTML string using a Web Stream.\n\nconst { prelude,postpone } = await resumeAndPrerender(reactNode, postponedState, options?)\nReference\nresumeAndPrerender(reactNode, postponedState, options?)\nUsage\nFurther reading\nNote\n\nThis API depends on Web Streams. For Node.js, use resumeAndPrerenderToNodeStream instead.\n\nReference \nresumeAndPrerender(reactNode, postponedState, options?) \n\nCall resumeAndPrerender to continue a prerendered React tree to a static HTML string.\n\nimport { resumeAndPrerender } from 'react-dom/static';\n\nimport { getPostponedState } from 'storage';\n\n\n\nasync function handler(request, response) {\n\n  const postponedState = getPostponedState(request);\n\n  const { prelude } = await resumeAndPrerender(<App />, postponedState, {\n\n    bootstrapScripts: ['/main.js']\n\n  });\n\n  return new Response(prelude, {\n\n    headers: { 'content-type': 'text/html' },\n\n  });\n\n}\n\nOn the client, call hydrateRoot to make the server-generated HTML interactive.\n\nSee more examples below.\n\nParameters \nreactNode: The React node you called prerender (or a previous resumeAndPrerender) with. For example, a JSX element like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\npostponedState: The opaque postpone object returned from a prerender API, loaded from wherever you stored it (e.g. redis, a file, or S3).\noptional options: An object with streaming options.\noptional signal: An abort signal that lets you abort server rendering and render the rest on the client.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error.\nReturns \n\nprerender returns a Promise:\n\nIf rendering the is successful, the Promise will resolve to an object containing:\nprelude: a Web Stream of HTML. You can use this stream to send a response in chunks, or you can read the entire stream into a string.\npostponed: an JSON-serializeable, opaque object that can be passed to resume or resumeAndPrerender if prerender is aborted.\nIf rendering fails, the Promise will be rejected. Use this to output a fallback shell.\nCaveats \n\nnonce is not an available option when prerendering. Nonces must be unique per request and if you use nonces to secure your application with CSP it would be inappropriate and insecure to include the nonce value in the prerender itself.\n\nNote\nWhen should I use resumeAndPrerender? \n\nThe static resumeAndPrerender API is used for static server-side generation (SSG). Unlike renderToString, resumeAndPrerender waits for all data to load before resolving. This makes it suitable for generating static HTML for a full page, including data that needs to be fetched using Suspense. To stream content as it loads, use a streaming server-side render (SSR) API like renderToReadableStream.\n\nresumeAndPrerender can be aborted and later either continued with another resumeAndPrerender or resumed with resume to support partial pre-rendering.\n\nUsage \nFurther reading \n\nresumeAndPrerender behaves similarly to prerender but can be used to continue a previously started prerendering process that was aborted.\nFor more information about resuming a prerendered tree, see the resume documentation.\n\nPREVIOUS\nprerenderToNodeStream\nNEXT\nresumeAndPrerenderToNodeStream"
  },
  {
    "title": "resumeAndPrerenderToNodeStream – React",
    "url": "https://react.dev/reference/react-dom/static/resumeAndPrerenderToNodeStream",
    "html": "API REFERENCE\nSTATIC APIS\nresumeAndPrerenderToNodeStream\n\nresumeAndPrerenderToNodeStream continues a prerendered React tree to a static HTML string using a a Node.js Stream..\n\nconst {prelude, postponed} = await resumeAndPrerenderToNodeStream(reactNode, postponedState, options?)\nReference\nresumeAndPrerenderToNodeStream(reactNode, postponedState, options?)\nUsage\nFurther reading\nNote\n\nThis API is specific to Node.js. Environments with Web Streams, like Deno and modern edge runtimes, should use prerender instead.\n\nReference \nresumeAndPrerenderToNodeStream(reactNode, postponedState, options?) \n\nCall resumeAndPrerenderToNodeStream to continue a prerendered React tree to a static HTML string.\n\nimport { resumeAndPrerenderToNodeStream } from 'react-dom/static';\n\nimport { getPostponedState } from 'storage';\n\n\n\nasync function handler(request, writable) {\n\n  const postponedState = getPostponedState(request);\n\n  const { prelude } = await resumeAndPrerenderToNodeStream(<App />, JSON.parse(postponedState));\n\n  prelude.pipe(writable);\n\n}\n\nOn the client, call hydrateRoot to make the server-generated HTML interactive.\n\nSee more examples below.\n\nParameters \nreactNode: The React node you called prerender (or a previous resumeAndPrerenderToNodeStream) with. For example, a JSX element like <App />. It is expected to represent the entire document, so the App component should render the <html> tag.\npostponedState: The opaque postpone object returned from a prerender API, loaded from wherever you stored it (e.g. redis, a file, or S3).\noptional options: An object with streaming options.\noptional signal: An abort signal that lets you abort server rendering and render the rest on the client.\noptional onError: A callback that fires whenever there is a server error, whether recoverable or not. By default, this only calls console.error. If you override it to log crash reports, make sure that you still call console.error.\nReturns \n\nresumeAndPrerenderToNodeStream returns a Promise:\n\nIf rendering the is successful, the Promise will resolve to an object containing:\nprelude: a Web Stream of HTML. You can use this stream to send a response in chunks, or you can read the entire stream into a string.\npostponed: an JSON-serializeable, opaque object that can be passed to resumeToNodeStream or resumeAndPrerenderToNodeStream if resumeAndPrerenderToNodeStream is aborted.\nIf rendering fails, the Promise will be rejected. Use this to output a fallback shell.\nCaveats \n\nnonce is not an available option when prerendering. Nonces must be unique per request and if you use nonces to secure your application with CSP it would be inappropriate and insecure to include the nonce value in the prerender itself.\n\nNote\nWhen should I use resumeAndPrerenderToNodeStream? \n\nThe static resumeAndPrerenderToNodeStream API is used for static server-side generation (SSG). Unlike renderToString, resumeAndPrerenderToNodeStream waits for all data to load before resolving. This makes it suitable for generating static HTML for a full page, including data that needs to be fetched using Suspense. To stream content as it loads, use a streaming server-side render (SSR) API like renderToReadableStream.\n\nresumeAndPrerenderToNodeStream can be aborted and later either continued with another resumeAndPrerenderToNodeStream or resumed with resume to support partial pre-rendering.\n\nUsage \nFurther reading \n\nresumeAndPrerenderToNodeStream behaves similarly to prerender but can be used to continue a previously started prerendering process that was aborted.\nFor more information about resuming a prerendered tree, see the resume documentation.\n\nPREVIOUS\nresumeAndPrerender"
  },
  {
    "title": "Legacy React APIs – React",
    "url": "https://react.dev/reference/react/legacy",
    "html": "API REFERENCE\nLegacy React APIs\n\nThese APIs are exported from the react package, but they are not recommended for use in newly written code. See the linked individual API pages for the suggested alternatives.\n\nLegacy APIs \nChildren lets you manipulate and transform the JSX received as the children prop. See alternatives.\ncloneElement lets you create a React element using another element as a starting point. See alternatives.\nComponent lets you define a React component as a JavaScript class. See alternatives.\ncreateElement lets you create a React element. Typically, you’ll use JSX instead.\ncreateRef creates a ref object which can contain arbitrary value. See alternatives.\nforwardRef lets your component expose a DOM node to parent component with a ref.\nisValidElement checks whether a value is a React element. Typically used with cloneElement.\nPureComponent is similar to Component, but it skip re-renders with same props. See alternatives.\nRemoved APIs \n\nThese APIs were removed in React 19:\n\ncreateFactory: use JSX instead.\nClass Components: static contextTypes: use static contextType instead.\nClass Components: static childContextTypes: use static contextType instead.\nClass Components: static getChildContext: use Context instead.\nClass Components: static propTypes: use a type system like TypeScript instead.\nClass Components: this.refs: use createRef instead.\nNEXT\nChildren"
  },
  {
    "title": "Children – React",
    "url": "https://react.dev/reference/react/Children",
    "html": "API REFERENCE\nLEGACY REACT APIS\nChildren\nPitfall\n\nUsing Children is uncommon and can lead to fragile code. See common alternatives.\n\nChildren lets you manipulate and transform the JSX you received as the children prop.\n\nconst mappedChildren = Children.map(children, child =>\n\n  <div className=\"Row\">\n\n    {child}\n\n  </div>\n\n);\nReference\nChildren.count(children)\nChildren.forEach(children, fn, thisArg?)\nChildren.map(children, fn, thisArg?)\nChildren.only(children)\nChildren.toArray(children)\nUsage\nTransforming children\nRunning some code for each child\nCounting children\nConverting children to an array\nAlternatives\nExposing multiple components\nAccepting an array of objects as a prop\nCalling a render prop to customize rendering\nTroubleshooting\nI pass a custom component, but the Children methods don’t show its render result\nReference \nChildren.count(children) \n\nCall Children.count(children) to count the number of children in the children data structure.\n\nimport { Children } from 'react';\n\n\n\nfunction RowList({ children }) {\n\n  return (\n\n    <>\n\n      <h1>Total rows: {Children.count(children)}</h1>\n\n      ...\n\n    </>\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \nchildren: The value of the children prop received by your component.\nReturns \n\nThe number of nodes inside these children.\n\nCaveats \nEmpty nodes (null, undefined, and Booleans), strings, numbers, and React elements count as individual nodes. Arrays don’t count as individual nodes, but their children do. The traversal does not go deeper than React elements: they don’t get rendered, and their children aren’t traversed. Fragments don’t get traversed.\nChildren.forEach(children, fn, thisArg?) \n\nCall Children.forEach(children, fn, thisArg?) to run some code for each child in the children data structure.\n\nimport { Children } from 'react';\n\n\n\nfunction SeparatorList({ children }) {\n\n  const result = [];\n\n  Children.forEach(children, (child, index) => {\n\n    result.push(child);\n\n    result.push(<hr key={index} />);\n\n  });\n\n  // ...\n\nSee more examples below.\n\nParameters \nchildren: The value of the children prop received by your component.\nfn: The function you want to run for each child, similar to the array forEach method callback. It will be called with the child as the first argument and its index as the second argument. The index starts at 0 and increments on each call.\noptional thisArg: The this value with which the fn function should be called. If omitted, it’s undefined.\nReturns \n\nChildren.forEach returns undefined.\n\nCaveats \nEmpty nodes (null, undefined, and Booleans), strings, numbers, and React elements count as individual nodes. Arrays don’t count as individual nodes, but their children do. The traversal does not go deeper than React elements: they don’t get rendered, and their children aren’t traversed. Fragments don’t get traversed.\nChildren.map(children, fn, thisArg?) \n\nCall Children.map(children, fn, thisArg?) to map or transform each child in the children data structure.\n\nimport { Children } from 'react';\n\n\n\nfunction RowList({ children }) {\n\n  return (\n\n    <div className=\"RowList\">\n\n      {Children.map(children, child =>\n\n        <div className=\"Row\">\n\n          {child}\n\n        </div>\n\n      )}\n\n    </div>\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \nchildren: The value of the children prop received by your component.\nfn: The mapping function, similar to the array map method callback. It will be called with the child as the first argument and its index as the second argument. The index starts at 0 and increments on each call. You need to return a React node from this function. This may be an empty node (null, undefined, or a Boolean), a string, a number, a React element, or an array of other React nodes.\noptional thisArg: The this value with which the fn function should be called. If omitted, it’s undefined.\nReturns \n\nIf children is null or undefined, returns the same value.\n\nOtherwise, returns a flat array consisting of the nodes you’ve returned from the fn function. The returned array will contain all nodes you returned except for null and undefined.\n\nCaveats \n\nEmpty nodes (null, undefined, and Booleans), strings, numbers, and React elements count as individual nodes. Arrays don’t count as individual nodes, but their children do. The traversal does not go deeper than React elements: they don’t get rendered, and their children aren’t traversed. Fragments don’t get traversed.\n\nIf you return an element or an array of elements with keys from fn, the returned elements’ keys will be automatically combined with the key of the corresponding original item from children. When you return multiple elements from fn in an array, their keys only need to be unique locally amongst each other.\n\nChildren.only(children) \n\nCall Children.only(children) to assert that children represent a single React element.\n\nfunction Box({ children }) {\n\n  const element = Children.only(children);\n\n  // ...\nParameters \nchildren: The value of the children prop received by your component.\nReturns \n\nIf children is a valid element, returns that element.\n\nOtherwise, throws an error.\n\nCaveats \nThis method always throws if you pass an array (such as the return value of Children.map) as children. In other words, it enforces that children is a single React element, not that it’s an array with a single element.\nChildren.toArray(children) \n\nCall Children.toArray(children) to create an array out of the children data structure.\n\nimport { Children } from 'react';\n\n\n\nexport default function ReversedList({ children }) {\n\n  const result = Children.toArray(children);\n\n  result.reverse();\n\n  // ...\nParameters \nchildren: The value of the children prop received by your component.\nReturns \n\nReturns a flat array of elements in children.\n\nCaveats \nEmpty nodes (null, undefined, and Booleans) will be omitted in the returned array. The returned elements’ keys will be calculated from the original elements’ keys and their level of nesting and position. This ensures that flattening the array does not introduce changes in behavior.\nUsage \nTransforming children \n\nTo transform the children JSX that your component receives as the children prop, call Children.map:\n\nimport { Children } from 'react';\n\n\n\nfunction RowList({ children }) {\n\n  return (\n\n    <div className=\"RowList\">\n\n      {Children.map(children, child =>\n\n        <div className=\"Row\">\n\n          {child}\n\n        </div>\n\n      )}\n\n    </div>\n\n  );\n\n}\n\nIn the example above, the RowList wraps every child it receives into a <div className=\"Row\"> container. For example, let’s say the parent component passes three <p> tags as the children prop to RowList:\n\n<RowList>\n\n  <p>This is the first item.</p>\n\n  <p>This is the second item.</p>\n\n  <p>This is the third item.</p>\n\n</RowList>\n\nThen, with the RowList implementation above, the final rendered result will look like this:\n\n<div className=\"RowList\">\n\n  <div className=\"Row\">\n\n    <p>This is the first item.</p>\n\n  </div>\n\n  <div className=\"Row\">\n\n    <p>This is the second item.</p>\n\n  </div>\n\n  <div className=\"Row\">\n\n    <p>This is the third item.</p>\n\n  </div>\n\n</div>\n\nChildren.map is similar to to transforming arrays with map(). The difference is that the children data structure is considered opaque. This means that even if it’s sometimes an array, you should not assume it’s an array or any other particular data type. This is why you should use Children.map if you need to transform it.\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function RowList({ children }) {\n  return (\n    <div className=\"RowList\">\n      {Children.map(children, child =>\n        <div className=\"Row\">\n          {child}\n        </div>\n      )}\n    </div>\n  );\n}\n\n\nDEEP DIVE\nWhy is the children prop not always an array? \nShow Details\nPitfall\n\nThe children data structure does not include rendered output of the components you pass as JSX. In the example below, the children received by the RowList only contains two items rather than three:\n\n<p>This is the first item.</p>\n<MoreRows />\n\nThis is why only two row wrappers are generated in this example:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport RowList from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList>\n      <p>This is the first item.</p>\n      <MoreRows />\n    </RowList>\n  );\n}\n\nfunction MoreRows() {\n  return (\n    <>\n      <p>This is the second item.</p>\n      <p>This is the third item.</p>\n    </>\n  );\n}\n\n\nShow more\n\nThere is no way to get the rendered output of an inner component like <MoreRows /> when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nRunning some code for each child \n\nCall Children.forEach to iterate over each child in the children data structure. It does not return any value and is similar to the array forEach method. You can use it to run custom logic like constructing your own array.\n\nApp.js\nSeparatorList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function SeparatorList({ children }) {\n  const result = [];\n  Children.forEach(children, (child, index) => {\n    result.push(child);\n    result.push(<hr key={index} />);\n  });\n  result.pop(); // Remove the last separator\n  return result;\n}\n\n\nPitfall\n\nAs mentioned earlier, there is no way to get the rendered output of an inner component when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nCounting children \n\nCall Children.count(children) to calculate the number of children.\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function RowList({ children }) {\n  return (\n    <div className=\"RowList\">\n      <h1 className=\"RowListHeader\">\n        Total rows: {Children.count(children)}\n      </h1>\n      {Children.map(children, child =>\n        <div className=\"Row\">\n          {child}\n        </div>\n      )}\n    </div>\n  );\n}\n\n\nShow more\nPitfall\n\nAs mentioned earlier, there is no way to get the rendered output of an inner component when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nConverting children to an array \n\nCall Children.toArray(children) to turn the children data structure into a regular JavaScript array. This lets you manipulate the array with built-in array methods like filter, sort, or reverse.\n\nApp.js\nReversedList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function ReversedList({ children }) {\n  const result = Children.toArray(children);\n  result.reverse();\n  return result;\n}\n\n\nPitfall\n\nAs mentioned earlier, there is no way to get the rendered output of an inner component when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nAlternatives \nNote\n\nThis section describes alternatives to the Children API (with capital C) that’s imported like this:\n\nimport { Children } from 'react';\n\nDon’t confuse it with using the children prop (lowercase c), which is good and encouraged.\n\nExposing multiple components \n\nManipulating children with the Children methods often leads to fragile code. When you pass children to a component in JSX, you don’t usually expect the component to manipulate or transform the individual children.\n\nWhen you can, try to avoid using the Children methods. For example, if you want every child of RowList to be wrapped in <div className=\"Row\">, export a Row component, and manually wrap every row into it like this:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList>\n      <Row>\n        <p>This is the first item.</p>\n      </Row>\n      <Row>\n        <p>This is the second item.</p>\n      </Row>\n      <Row>\n        <p>This is the third item.</p>\n      </Row>\n    </RowList>\n  );\n}\n\n\nShow more\n\nUnlike using Children.map, this approach does not wrap every child automatically. However, this approach has a significant benefit compared to the earlier example with Children.map because it works even if you keep extracting more components. For example, it still works if you extract your own MoreRows component:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList>\n      <Row>\n        <p>This is the first item.</p>\n      </Row>\n      <MoreRows />\n    </RowList>\n  );\n}\n\nfunction MoreRows() {\n  return (\n    <>\n      <Row>\n        <p>This is the second item.</p>\n      </Row>\n      <Row>\n        <p>This is the third item.</p>\n      </Row>\n    </>\n  );\n}\n\n\nShow more\n\nThis wouldn’t work with Children.map because it would “see” <MoreRows /> as a single child (and a single row).\n\nAccepting an array of objects as a prop \n\nYou can also explicitly pass an array as a prop. For example, this RowList accepts a rows array as a prop:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList rows={[\n      { id: 'first', content: <p>This is the first item.</p> },\n      { id: 'second', content: <p>This is the second item.</p> },\n      { id: 'third', content: <p>This is the third item.</p> }\n    ]} />\n  );\n}\n\n\n\nSince rows is a regular JavaScript array, the RowList component can use built-in array methods like map on it.\n\nThis pattern is especially useful when you want to be able to pass more information as structured data together with children. In the below example, the TabSwitcher component receives an array of objects as the tabs prop:\n\nApp.js\nTabSwitcher.js\nReload\nClear\nFork\nimport TabSwitcher from './TabSwitcher.js';\n\nexport default function App() {\n  return (\n    <TabSwitcher tabs={[\n      {\n        id: 'first',\n        header: 'First',\n        content: <p>This is the first item.</p>\n      },\n      {\n        id: 'second',\n        header: 'Second',\n        content: <p>This is the second item.</p>\n      },\n      {\n        id: 'third',\n        header: 'Third',\n        content: <p>This is the third item.</p>\n      }\n    ]} />\n  );\n}\n\n\nShow more\n\nUnlike passing the children as JSX, this approach lets you associate some extra data like header with each item. Because you are working with the tabs directly, and it is an array, you do not need the Children methods.\n\nCalling a render prop to customize rendering \n\nInstead of producing JSX for every single item, you can also pass a function that returns JSX, and call that function when necessary. In this example, the App component passes a renderContent function to the TabSwitcher component. The TabSwitcher component calls renderContent only for the selected tab:\n\nApp.js\nTabSwitcher.js\nReload\nClear\nFork\nimport TabSwitcher from './TabSwitcher.js';\n\nexport default function App() {\n  return (\n    <TabSwitcher\n      tabIds={['first', 'second', 'third']}\n      getHeader={tabId => {\n        return tabId[0].toUpperCase() + tabId.slice(1);\n      }}\n      renderContent={tabId => {\n        return <p>This is the {tabId} item.</p>;\n      }}\n    />\n  );\n}\n\n\n\nA prop like renderContent is called a render prop because it is a prop that specifies how to render a piece of the user interface. However, there is nothing special about it: it is a regular prop which happens to be a function.\n\nRender props are functions, so you can pass information to them. For example, this RowList component passes the id and the index of each row to the renderRow render prop, which uses index to highlight even rows:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList\n      rowIds={['first', 'second', 'third']}\n      renderRow={(id, index) => {\n        return (\n          <Row isHighlighted={index % 2 === 0}>\n            <p>This is the {id} item.</p>\n          </Row> \n        );\n      }}\n    />\n  );\n}\n\n\nShow more\n\nThis is another example of how parent and child components can cooperate without manipulating the children.\n\nTroubleshooting \nI pass a custom component, but the Children methods don’t show its render result \n\nSuppose you pass two children to RowList like this:\n\n<RowList>\n\n  <p>First item</p>\n\n  <MoreRows />\n\n</RowList>\n\nIf you do Children.count(children) inside RowList, you will get 2. Even if MoreRows renders 10 different items, or if it returns null, Children.count(children) will still be 2. From the RowList’s perspective, it only “sees” the JSX it has received. It does not “see” the internals of the MoreRows component.\n\nThe limitation makes it hard to extract a component. This is why alternatives are preferred to using Children.\n\nPREVIOUS\nLegacy React APIs\nNEXT\ncloneElement"
  },
  {
    "title": "cloneElement – React",
    "url": "https://react.dev/reference/react/cloneElement",
    "html": "API REFERENCE\nLEGACY REACT APIS\ncloneElement\nPitfall\n\nUsing cloneElement is uncommon and can lead to fragile code. See common alternatives.\n\ncloneElement lets you create a new React element using another element as a starting point.\n\nconst clonedElement = cloneElement(element, props, ...children)\nReference\ncloneElement(element, props, ...children)\nUsage\nOverriding props of an element\nAlternatives\nPassing data with a render prop\nPassing data through context\nExtracting logic into a custom Hook\nReference \ncloneElement(element, props, ...children) \n\nCall cloneElement to create a React element based on the element, but with different props and children:\n\nimport { cloneElement } from 'react';\n\n\n\n// ...\n\nconst clonedElement = cloneElement(\n\n  <Row title=\"Cabbage\">\n\n    Hello\n\n  </Row>,\n\n  { isHighlighted: true },\n\n  'Goodbye'\n\n);\n\n\n\nconsole.log(clonedElement); // <Row title=\"Cabbage\" isHighlighted={true}>Goodbye</Row>\n\nSee more examples below.\n\nParameters \n\nelement: The element argument must be a valid React element. For example, it could be a JSX node like <Something />, the result of calling createElement, or the result of another cloneElement call.\n\nprops: The props argument must either be an object or null. If you pass null, the cloned element will retain all of the original element.props. Otherwise, for every prop in the props object, the returned element will “prefer” the value from props over the value from element.props. The rest of the props will be filled from the original element.props. If you pass props.key or props.ref, they will replace the original ones.\n\noptional ...children: Zero or more child nodes. They can be any React nodes, including React elements, strings, numbers, portals, empty nodes (null, undefined, true, and false), and arrays of React nodes. If you don’t pass any ...children arguments, the original element.props.children will be preserved.\n\nReturns \n\ncloneElement returns a React element object with a few properties:\n\ntype: Same as element.type.\nprops: The result of shallowly merging element.props with the overriding props you have passed.\nref: The original element.ref, unless it was overridden by props.ref.\nkey: The original element.key, unless it was overridden by props.key.\n\nUsually, you’ll return the element from your component or make it a child of another element. Although you may read the element’s properties, it’s best to treat every element as opaque after it’s created, and only render it.\n\nCaveats \n\nCloning an element does not modify the original element.\n\nYou should only pass children as multiple arguments to cloneElement if they are all statically known, like cloneElement(element, null, child1, child2, child3). If your children are dynamic, pass the entire array as the third argument: cloneElement(element, null, listItems). This ensures that React will warn you about missing keys for any dynamic lists. For static lists this is not necessary because they never reorder.\n\ncloneElement makes it harder to trace the data flow, so try the alternatives instead.\n\nUsage \nOverriding props of an element \n\nTo override the props of some React element, pass it to cloneElement with the props you want to override:\n\nimport { cloneElement } from 'react';\n\n\n\n// ...\n\nconst clonedElement = cloneElement(\n\n  <Row title=\"Cabbage\" />,\n\n  { isHighlighted: true }\n\n);\n\nHere, the resulting cloned element will be <Row title=\"Cabbage\" isHighlighted={true} />.\n\nLet’s walk through an example to see when it’s useful.\n\nImagine a List component that renders its children as a list of selectable rows with a “Next” button that changes which row is selected. The List component needs to render the selected Row differently, so it clones every <Row> child that it has received, and adds an extra isHighlighted: true or isHighlighted: false prop:\n\nexport default function List({ children }) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n  return (\n\n    <div className=\"List\">\n\n      {Children.map(children, (child, index) =>\n\n        cloneElement(child, {\n\n          isHighlighted: index === selectedIndex \n\n        })\n\n      )}\n\nLet’s say the original JSX received by List looks like this:\n\n<List>\n\n  <Row title=\"Cabbage\" />\n\n  <Row title=\"Garlic\" />\n\n  <Row title=\"Apple\" />\n\n</List>\n\nBy cloning its children, the List can pass extra information to every Row inside. The result looks like this:\n\n<List>\n\n  <Row\n\n    title=\"Cabbage\"\n\n    isHighlighted={true} \n\n  />\n\n  <Row\n\n    title=\"Garlic\"\n\n    isHighlighted={false} \n\n  />\n\n  <Row\n\n    title=\"Apple\"\n\n    isHighlighted={false} \n\n  />\n\n</List>\n\nNotice how pressing “Next” updates the state of the List, and highlights a different row:\n\nApp.js\nList.js\nRow.js\ndata.js\nReload\nClear\nFork\nimport { Children, cloneElement, useState } from 'react';\n\nexport default function List({ children }) {\n  const [selectedIndex, setSelectedIndex] = useState(0);\n  return (\n    <div className=\"List\">\n      {Children.map(children, (child, index) =>\n        cloneElement(child, {\n          isHighlighted: index === selectedIndex \n        })\n      )}\n      <hr />\n      <button onClick={() => {\n        setSelectedIndex(i =>\n          (i + 1) % Children.count(children)\n        );\n      }}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nTo summarize, the List cloned the <Row /> elements it received and added an extra prop to them.\n\nPitfall\n\nCloning children makes it hard to tell how the data flows through your app. Try one of the alternatives.\n\nAlternatives \nPassing data with a render prop \n\nInstead of using cloneElement, consider accepting a render prop like renderItem. Here, List receives renderItem as a prop. List calls renderItem for every item and passes isHighlighted as an argument:\n\nexport default function List({ items, renderItem }) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n  return (\n\n    <div className=\"List\">\n\n      {items.map((item, index) => {\n\n        const isHighlighted = index === selectedIndex;\n\n        return renderItem(item, isHighlighted);\n\n      })}\n\nThe renderItem prop is called a “render prop” because it’s a prop that specifies how to render something. For example, you can pass a renderItem implementation that renders a <Row> with the given isHighlighted value:\n\n<List\n\n  items={products}\n\n  renderItem={(product, isHighlighted) =>\n\n    <Row\n\n      key={product.id}\n\n      title={product.title}\n\n      isHighlighted={isHighlighted}\n\n    />\n\n  }\n\n/>\n\nThe end result is the same as with cloneElement:\n\n<List>\n\n  <Row\n\n    title=\"Cabbage\"\n\n    isHighlighted={true} \n\n  />\n\n  <Row\n\n    title=\"Garlic\"\n\n    isHighlighted={false} \n\n  />\n\n  <Row\n\n    title=\"Apple\"\n\n    isHighlighted={false} \n\n  />\n\n</List>\n\nHowever, you can clearly trace where the isHighlighted value is coming from.\n\nApp.js\nList.js\nRow.js\ndata.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function List({ items, renderItem }) {\n  const [selectedIndex, setSelectedIndex] = useState(0);\n  return (\n    <div className=\"List\">\n      {items.map((item, index) => {\n        const isHighlighted = index === selectedIndex;\n        return renderItem(item, isHighlighted);\n      })}\n      <hr />\n      <button onClick={() => {\n        setSelectedIndex(i =>\n          (i + 1) % items.length\n        );\n      }}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nThis pattern is preferred to cloneElement because it is more explicit.\n\nPassing data through context \n\nAnother alternative to cloneElement is to pass data through context.\n\nFor example, you can call createContext to define a HighlightContext:\n\nexport const HighlightContext = createContext(false);\n\nYour List component can wrap every item it renders into a HighlightContext provider:\n\nexport default function List({ items, renderItem }) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n  return (\n\n    <div className=\"List\">\n\n      {items.map((item, index) => {\n\n        const isHighlighted = index === selectedIndex;\n\n        return (\n\n          <HighlightContext key={item.id} value={isHighlighted}>\n\n            {renderItem(item)}\n\n          </HighlightContext>\n\n        );\n\n      })}\n\nWith this approach, Row does not need to receive an isHighlighted prop at all. Instead, it reads the context:\n\nexport default function Row({ title }) {\n\n  const isHighlighted = useContext(HighlightContext);\n\n  // ...\n\nThis allows the calling component to not know or worry about passing isHighlighted to <Row>:\n\n<List\n\n  items={products}\n\n  renderItem={product =>\n\n    <Row title={product.title} />\n\n  }\n\n/>\n\nInstead, List and Row coordinate the highlighting logic through context.\n\nApp.js\nList.js\nRow.js\nHighlightContext.js\ndata.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport { HighlightContext } from './HighlightContext.js';\n\nexport default function List({ items, renderItem }) {\n  const [selectedIndex, setSelectedIndex] = useState(0);\n  return (\n    <div className=\"List\">\n      {items.map((item, index) => {\n        const isHighlighted = index === selectedIndex;\n        return (\n          <HighlightContext\n            key={item.id}\n            value={isHighlighted}\n          >\n            {renderItem(item)}\n          </HighlightContext>\n        );\n      })}\n      <hr />\n      <button onClick={() => {\n        setSelectedIndex(i =>\n          (i + 1) % items.length\n        );\n      }}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nLearn more about passing data through context.\n\nExtracting logic into a custom Hook \n\nAnother approach you can try is to extract the “non-visual” logic into your own Hook, and use the information returned by your Hook to decide what to render. For example, you could write a useList custom Hook like this:\n\nimport { useState } from 'react';\n\n\n\nexport default function useList(items) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n\n\n  function onNext() {\n\n    setSelectedIndex(i =>\n\n      (i + 1) % items.length\n\n    );\n\n  }\n\n\n\n  const selected = items[selectedIndex];\n\n  return [selected, onNext];\n\n}\n\nThen you could use it like this:\n\nexport default function App() {\n\n  const [selected, onNext] = useList(products);\n\n  return (\n\n    <div className=\"List\">\n\n      {products.map(product =>\n\n        <Row\n\n          key={product.id}\n\n          title={product.title}\n\n          isHighlighted={selected === product}\n\n        />\n\n      )}\n\n      <hr />\n\n      <button onClick={onNext}>\n\n        Next\n\n      </button>\n\n    </div>\n\n  );\n\n}\n\nThe data flow is explicit, but the state is inside the useList custom Hook that you can use from any component:\n\nApp.js\nuseList.js\nRow.js\ndata.js\nReload\nClear\nFork\nimport Row from './Row.js';\nimport useList from './useList.js';\nimport { products } from './data.js';\n\nexport default function App() {\n  const [selected, onNext] = useList(products);\n  return (\n    <div className=\"List\">\n      {products.map(product =>\n        <Row\n          key={product.id}\n          title={product.title}\n          isHighlighted={selected === product}\n        />\n      )}\n      <hr />\n      <button onClick={onNext}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nThis approach is particularly useful if you want to reuse this logic between different components.\n\nPREVIOUS\nChildren\nNEXT\nComponent"
  },
  {
    "title": "Component – React",
    "url": "https://react.dev/reference/react/Component",
    "html": "API REFERENCE\nLEGACY REACT APIS\nComponent\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nComponent is the base class for the React components defined as JavaScript classes. Class components are still supported by React, but we don’t recommend using them in new code.\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\nReference\nComponent\ncontext\nprops\nstate\nconstructor(props)\ncomponentDidCatch(error, info)\ncomponentDidMount()\ncomponentDidUpdate(prevProps, prevState, snapshot?)\ncomponentWillMount()\ncomponentWillReceiveProps(nextProps)\ncomponentWillUpdate(nextProps, nextState)\ncomponentWillUnmount()\nforceUpdate(callback?)\ngetSnapshotBeforeUpdate(prevProps, prevState)\nrender()\nsetState(nextState, callback?)\nshouldComponentUpdate(nextProps, nextState, nextContext)\nUNSAFE_componentWillMount()\nUNSAFE_componentWillReceiveProps(nextProps, nextContext)\nUNSAFE_componentWillUpdate(nextProps, nextState)\nstatic contextType\nstatic defaultProps\nstatic getDerivedStateFromError(error)\nstatic getDerivedStateFromProps(props, state)\nUsage\nDefining a class component\nAdding state to a class component\nAdding lifecycle methods to a class component\nCatching rendering errors with an Error Boundary\nAlternatives\nMigrating a simple component from a class to a function\nMigrating a component with state from a class to a function\nMigrating a component with lifecycle methods from a class to a function\nMigrating a component with context from a class to a function\nReference \nComponent \n\nTo define a React component as a class, extend the built-in Component class and define a render method:\n\nimport { Component } from 'react';\n\n\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nOnly the render method is required, other methods are optional.\n\nSee more examples below.\n\ncontext \n\nThe context of a class component is available as this.context. It is only available if you specify which context you want to receive using static contextType.\n\nA class component can only read one context at a time.\n\nclass Button extends Component {\n\n  static contextType = ThemeContext;\n\n\n\n  render() {\n\n    const theme = this.context;\n\n    const className = 'button-' + theme;\n\n    return (\n\n      <button className={className}>\n\n        {this.props.children}\n\n      </button>\n\n    );\n\n  }\n\n}\nNote\n\nReading this.context in class components is equivalent to useContext in function components.\n\nSee how to migrate.\n\nprops \n\nThe props passed to a class component are available as this.props.\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\n\n\n<Greeting name=\"Taylor\" />\nNote\n\nReading this.props in class components is equivalent to declaring props in function components.\n\nSee how to migrate.\n\nstate \n\nThe state of a class component is available as this.state. The state field must be an object. Do not mutate the state directly. If you wish to change the state, call setState with the new state.\n\nclass Counter extends Component {\n\n  state = {\n\n    age: 42,\n\n  };\n\n\n\n  handleAgeChange = () => {\n\n    this.setState({\n\n      age: this.state.age + 1 \n\n    });\n\n  };\n\n\n\n  render() {\n\n    return (\n\n      <>\n\n        <button onClick={this.handleAgeChange}>\n\n        Increment age\n\n        </button>\n\n        <p>You are {this.state.age}.</p>\n\n      </>\n\n    );\n\n  }\n\n}\nNote\n\nDefining state in class components is equivalent to calling useState in function components.\n\nSee how to migrate.\n\nconstructor(props) \n\nThe constructor runs before your class component mounts (gets added to the screen). Typically, a constructor is only used for two purposes in React. It lets you declare state and bind your class methods to the class instance:\n\nclass Counter extends Component {\n\n  constructor(props) {\n\n    super(props);\n\n    this.state = { counter: 0 };\n\n    this.handleClick = this.handleClick.bind(this);\n\n  }\n\n\n\n  handleClick() {\n\n    // ...\n\n  }\n\nIf you use modern JavaScript syntax, constructors are rarely needed. Instead, you can rewrite this code above using the public class field syntax which is supported both by modern browsers and tools like Babel:\n\nclass Counter extends Component {\n\n  state = { counter: 0 };\n\n\n\n  handleClick = () => {\n\n    // ...\n\n  }\n\nA constructor should not contain any side effects or subscriptions.\n\nParameters \nprops: The component’s initial props.\nReturns \n\nconstructor should not return anything.\n\nCaveats \n\nDo not run any side effects or subscriptions in the constructor. Instead, use componentDidMount for that.\n\nInside a constructor, you need to call super(props) before any other statement. If you don’t do that, this.props will be undefined while the constructor runs, which can be confusing and cause bugs.\n\nConstructor is the only place where you can assign this.state directly. In all other methods, you need to use this.setState() instead. Do not call setState in the constructor.\n\nWhen you use server rendering, the constructor will run on the server too, followed by the render method. However, lifecycle methods like componentDidMount or componentWillUnmount will not run on the server.\n\nWhen Strict Mode is on, React will call constructor twice in development and then throw away one of the instances. This helps you notice the accidental side effects that need to be moved out of the constructor.\n\nNote\n\nThere is no exact equivalent for constructor in function components. To declare state in a function component, call useState. To avoid recalculating the initial state, pass a function to useState.\n\ncomponentDidCatch(error, info) \n\nIf you define componentDidCatch, React will call it when some child component (including distant children) throws an error during rendering. This lets you log that error to an error reporting service in production.\n\nTypically, it is used together with static getDerivedStateFromError which lets you update state in response to an error and display an error message to the user. A component with these methods is called an Error Boundary.\n\nSee an example.\n\nParameters \n\nerror: The error that was thrown. In practice, it will usually be an instance of Error but this is not guaranteed because JavaScript allows to throw any value, including strings or even null.\n\ninfo: An object containing additional information about the error. Its componentStack field contains a stack trace with the component that threw, as well as the names and source locations of all its parent components. In production, the component names will be minified. If you set up production error reporting, you can decode the component stack using sourcemaps the same way as you would do for regular JavaScript error stacks.\n\nReturns \n\ncomponentDidCatch should not return anything.\n\nCaveats \n\nIn the past, it was common to call setState inside componentDidCatch in order to update the UI and display the fallback error message. This is deprecated in favor of defining static getDerivedStateFromError.\n\nProduction and development builds of React slightly differ in the way componentDidCatch handles errors. In development, the errors will bubble up to window, which means that any window.onerror or window.addEventListener('error', callback) will intercept the errors that have been caught by componentDidCatch. In production, instead, the errors will not bubble up, which means any ancestor error handler will only receive errors not explicitly caught by componentDidCatch.\n\nNote\n\nThere is no direct equivalent for componentDidCatch in function components yet. If you’d like to avoid creating class components, write a single ErrorBoundary component like above and use it throughout your app. Alternatively, you can use the react-error-boundary package which does that for you.\n\ncomponentDidMount() \n\nIf you define the componentDidMount method, React will call it when your component is added (mounted) to the screen. This is a common place to start data fetching, set up subscriptions, or manipulate the DOM nodes.\n\nIf you implement componentDidMount, you usually need to implement other lifecycle methods to avoid bugs. For example, if componentDidMount reads some state or props, you also have to implement componentDidUpdate to handle their changes, and componentWillUnmount to clean up whatever componentDidMount was doing.\n\nclass ChatRoom extends Component {\n\n  state = {\n\n    serverUrl: 'https://localhost:1234'\n\n  };\n\n\n\n  componentDidMount() {\n\n    this.setupConnection();\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState) {\n\n    if (\n\n      this.props.roomId !== prevProps.roomId ||\n\n      this.state.serverUrl !== prevState.serverUrl\n\n    ) {\n\n      this.destroyConnection();\n\n      this.setupConnection();\n\n    }\n\n  }\n\n\n\n  componentWillUnmount() {\n\n    this.destroyConnection();\n\n  }\n\n\n\n  // ...\n\n}\n\nSee more examples.\n\nParameters \n\ncomponentDidMount does not take any parameters.\n\nReturns \n\ncomponentDidMount should not return anything.\n\nCaveats \n\nWhen Strict Mode is on, in development React will call componentDidMount, then immediately call componentWillUnmount, and then call componentDidMount again. This helps you notice if you forgot to implement componentWillUnmount or if its logic doesn’t fully “mirror” what componentDidMount does.\n\nAlthough you may call setState immediately in componentDidMount, it’s best to avoid that when you can. It will trigger an extra rendering, but it will happen before the browser updates the screen. This guarantees that even though the render will be called twice in this case, the user won’t see the intermediate state. Use this pattern with caution because it often causes performance issues. In most cases, you should be able to assign the initial state in the constructor instead. It can, however, be necessary for cases like modals and tooltips when you need to measure a DOM node before rendering something that depends on its size or position.\n\nNote\n\nFor many use cases, defining componentDidMount, componentDidUpdate, and componentWillUnmount together in class components is equivalent to calling useEffect in function components. In the rare cases where it’s important for the code to run before browser paint, useLayoutEffect is a closer match.\n\nSee how to migrate.\n\ncomponentDidUpdate(prevProps, prevState, snapshot?) \n\nIf you define the componentDidUpdate method, React will call it immediately after your component has been re-rendered with updated props or state.  This method is not called for the initial render.\n\nYou can use it to manipulate the DOM after an update. This is also a common place to do network requests as long as you compare the current props to previous props (e.g. a network request may not be necessary if the props have not changed). Typically, you’d use it together with componentDidMount and componentWillUnmount:\n\nclass ChatRoom extends Component {\n\n  state = {\n\n    serverUrl: 'https://localhost:1234'\n\n  };\n\n\n\n  componentDidMount() {\n\n    this.setupConnection();\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState) {\n\n    if (\n\n      this.props.roomId !== prevProps.roomId ||\n\n      this.state.serverUrl !== prevState.serverUrl\n\n    ) {\n\n      this.destroyConnection();\n\n      this.setupConnection();\n\n    }\n\n  }\n\n\n\n  componentWillUnmount() {\n\n    this.destroyConnection();\n\n  }\n\n\n\n  // ...\n\n}\n\nSee more examples.\n\nParameters \n\nprevProps: Props before the update. Compare prevProps to this.props to determine what changed.\n\nprevState: State before the update. Compare prevState to this.state to determine what changed.\n\nsnapshot: If you implemented getSnapshotBeforeUpdate, snapshot will contain the value you returned from that method. Otherwise, it will be undefined.\n\nReturns \n\ncomponentDidUpdate should not return anything.\n\nCaveats \n\ncomponentDidUpdate will not get called if shouldComponentUpdate is defined and returns false.\n\nThe logic inside componentDidUpdate should usually be wrapped in conditions comparing this.props with prevProps, and this.state with prevState. Otherwise, there’s a risk of creating infinite loops.\n\nAlthough you may call setState immediately in componentDidUpdate, it’s best to avoid that when you can. It will trigger an extra rendering, but it will happen before the browser updates the screen. This guarantees that even though the render will be called twice in this case, the user won’t see the intermediate state. This pattern often causes performance issues, but it may be necessary for rare cases like modals and tooltips when you need to measure a DOM node before rendering something that depends on its size or position.\n\nNote\n\nFor many use cases, defining componentDidMount, componentDidUpdate, and componentWillUnmount together in class components is equivalent to calling useEffect in function components. In the rare cases where it’s important for the code to run before browser paint, useLayoutEffect is a closer match.\n\nSee how to migrate.\n\ncomponentWillMount() \nDeprecated\n\nThis API has been renamed from componentWillMount to UNSAFE_componentWillMount. The old name has been deprecated. In a future major version of React, only the new name will work.\n\nRun the rename-unsafe-lifecycles codemod to automatically update your components.\n\ncomponentWillReceiveProps(nextProps) \nDeprecated\n\nThis API has been renamed from componentWillReceiveProps to UNSAFE_componentWillReceiveProps. The old name has been deprecated. In a future major version of React, only the new name will work.\n\nRun the rename-unsafe-lifecycles codemod to automatically update your components.\n\ncomponentWillUpdate(nextProps, nextState) \nDeprecated\n\nThis API has been renamed from componentWillUpdate to UNSAFE_componentWillUpdate. The old name has been deprecated. In a future major version of React, only the new name will work.\n\nRun the rename-unsafe-lifecycles codemod to automatically update your components.\n\ncomponentWillUnmount() \n\nIf you define the componentWillUnmount method, React will call it before your component is removed (unmounted) from the screen. This is a common place to cancel data fetching or remove subscriptions.\n\nThe logic inside componentWillUnmount should “mirror” the logic inside componentDidMount. For example, if componentDidMount sets up a subscription, componentWillUnmount should clean up that subscription. If the cleanup logic in your componentWillUnmount reads some props or state, you will usually also need to implement componentDidUpdate to clean up resources (such as subscriptions) corresponding to the old props and state.\n\nclass ChatRoom extends Component {\n\n  state = {\n\n    serverUrl: 'https://localhost:1234'\n\n  };\n\n\n\n  componentDidMount() {\n\n    this.setupConnection();\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState) {\n\n    if (\n\n      this.props.roomId !== prevProps.roomId ||\n\n      this.state.serverUrl !== prevState.serverUrl\n\n    ) {\n\n      this.destroyConnection();\n\n      this.setupConnection();\n\n    }\n\n  }\n\n\n\n  componentWillUnmount() {\n\n    this.destroyConnection();\n\n  }\n\n\n\n  // ...\n\n}\n\nSee more examples.\n\nParameters \n\ncomponentWillUnmount does not take any parameters.\n\nReturns \n\ncomponentWillUnmount should not return anything.\n\nCaveats \nWhen Strict Mode is on, in development React will call componentDidMount, then immediately call componentWillUnmount, and then call componentDidMount again. This helps you notice if you forgot to implement componentWillUnmount or if its logic doesn’t fully “mirror” what componentDidMount does.\nNote\n\nFor many use cases, defining componentDidMount, componentDidUpdate, and componentWillUnmount together in class components is equivalent to calling useEffect in function components. In the rare cases where it’s important for the code to run before browser paint, useLayoutEffect is a closer match.\n\nSee how to migrate.\n\nforceUpdate(callback?) \n\nForces a component to re-render.\n\nUsually, this is not necessary. If your component’s render method only reads from this.props, this.state, or this.context, it will re-render automatically when you call setState inside your component or one of its parents. However, if your component’s render method reads directly from an external data source, you have to tell React to update the user interface when that data source changes. That’s what forceUpdate lets you do.\n\nTry to avoid all uses of forceUpdate and only read from this.props and this.state in render.\n\nParameters \noptional callback If specified, React will call the callback you’ve provided after the update is committed.\nReturns \n\nforceUpdate does not return anything.\n\nCaveats \nIf you call forceUpdate, React will re-render without calling shouldComponentUpdate.\nNote\n\nReading an external data source and forcing class components to re-render in response to its changes with forceUpdate has been superseded by useSyncExternalStore in function components.\n\ngetSnapshotBeforeUpdate(prevProps, prevState) \n\nIf you implement getSnapshotBeforeUpdate, React will call it immediately before React updates the DOM. It enables your component to capture some information from the DOM (e.g. scroll position) before it is potentially changed. Any value returned by this lifecycle method will be passed as a parameter to componentDidUpdate.\n\nFor example, you can use it in a UI like a chat thread that needs to preserve its scroll position during updates:\n\nclass ScrollingList extends React.Component {\n\n  constructor(props) {\n\n    super(props);\n\n    this.listRef = React.createRef();\n\n  }\n\n\n\n  getSnapshotBeforeUpdate(prevProps, prevState) {\n\n    // Are we adding new items to the list?\n\n    // Capture the scroll position so we can adjust scroll later.\n\n    if (prevProps.list.length < this.props.list.length) {\n\n      const list = this.listRef.current;\n\n      return list.scrollHeight - list.scrollTop;\n\n    }\n\n    return null;\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState, snapshot) {\n\n    // If we have a snapshot value, we've just added new items.\n\n    // Adjust scroll so these new items don't push the old ones out of view.\n\n    // (snapshot here is the value returned from getSnapshotBeforeUpdate)\n\n    if (snapshot !== null) {\n\n      const list = this.listRef.current;\n\n      list.scrollTop = list.scrollHeight - snapshot;\n\n    }\n\n  }\n\n\n\n  render() {\n\n    return (\n\n      <div ref={this.listRef}>{/* ...contents... */}</div>\n\n    );\n\n  }\n\n}\n\nIn the above example, it is important to read the scrollHeight property directly in getSnapshotBeforeUpdate. It is not safe to read it in render, UNSAFE_componentWillReceiveProps, or UNSAFE_componentWillUpdate because there is a potential time gap between these methods getting called and React updating the DOM.\n\nParameters \n\nprevProps: Props before the update. Compare prevProps to this.props to determine what changed.\n\nprevState: State before the update. Compare prevState to this.state to determine what changed.\n\nReturns \n\nYou should return a snapshot value of any type that you’d like, or null. The value you returned will be passed as the third argument to componentDidUpdate.\n\nCaveats \ngetSnapshotBeforeUpdate will not get called if shouldComponentUpdate is defined and returns false.\nNote\n\nAt the moment, there is no equivalent to getSnapshotBeforeUpdate for function components. This use case is very uncommon, but if you have the need for it, for now you’ll have to write a class component.\n\nrender() \n\nThe render method is the only required method in a class component.\n\nThe render method should specify what you want to appear on the screen, for example:\n\nimport { Component } from 'react';\n\n\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nReact may call render at any moment, so you shouldn’t assume that it runs at a particular time. Usually, the render method should return a piece of JSX, but a few other return types (like strings) are supported. To calculate the returned JSX, the render method can read this.props, this.state, and this.context.\n\nYou should write the render method as a pure function, meaning that it should return the same result if props, state, and context are the same. It also shouldn’t contain side effects (like setting up subscriptions) or interact with the browser APIs. Side effects should happen either in event handlers or methods like componentDidMount.\n\nParameters \n\nrender does not take any parameters.\n\nReturns \n\nrender can return any valid React node. This includes React elements such as <div />, strings, numbers, portals, empty nodes (null, undefined, true, and false), and arrays of React nodes.\n\nCaveats \n\nrender should be written as a pure function of props, state, and context. It should not have side effects.\n\nrender will not get called if shouldComponentUpdate is defined and returns false.\n\nWhen Strict Mode is on, React will call render twice in development and then throw away one of the results. This helps you notice the accidental side effects that need to be moved out of the render method.\n\nThere is no one-to-one correspondence between the render call and the subsequent componentDidMount or componentDidUpdate call. Some of the render call results may be discarded by React when it’s beneficial.\n\nsetState(nextState, callback?) \n\nCall setState to update the state of your React component.\n\nclass Form extends Component {\n\n  state = {\n\n    name: 'Taylor',\n\n  };\n\n\n\n  handleNameChange = (e) => {\n\n    const newName = e.target.value;\n\n    this.setState({\n\n      name: newName\n\n    });\n\n  }\n\n\n\n  render() {\n\n    return (\n\n      <>\n\n        <input value={this.state.name} onChange={this.handleNameChange} />\n\n        <p>Hello, {this.state.name}.</p>\n\n      </>\n\n    );\n\n  }\n\n}\n\nsetState enqueues changes to the component state. It tells React that this component and its children need to re-render with the new state. This is the main way you’ll update the user interface in response to interactions.\n\nPitfall\n\nCalling setState does not change the current state in the already executing code:\n\nfunction handleClick() {\n\n  console.log(this.state.name); // \"Taylor\"\n\n  this.setState({\n\n    name: 'Robin'\n\n  });\n\n  console.log(this.state.name); // Still \"Taylor\"!\n\n}\n\nIt only affects what this.state will return starting from the next render.\n\nYou can also pass a function to setState. It lets you update state based on the previous state:\n\n  handleIncreaseAge = () => {\n\n    this.setState(prevState => {\n\n      return {\n\n        age: prevState.age + 1\n\n      };\n\n    });\n\n  }\n\nYou don’t have to do this, but it’s handy if you want to update state multiple times during the same event.\n\nParameters \n\nnextState: Either an object or a function.\n\nIf you pass an object as nextState, it will be shallowly merged into this.state.\nIf you pass a function as nextState, it will be treated as an updater function. It must be pure, should take the pending state and props as arguments, and should return the object to be shallowly merged into this.state. React will put your updater function in a queue and re-render your component. During the next render, React will calculate the next state by applying all of the queued updaters to the previous state.\n\noptional callback: If specified, React will call the callback you’ve provided after the update is committed.\n\nReturns \n\nsetState does not return anything.\n\nCaveats \n\nThink of setState as a request rather than an immediate command to update the component. When multiple components update their state in response to an event, React will batch their updates and re-render them together in a single pass at the end of the event. In the rare case that you need to force a particular state update to be applied synchronously, you may wrap it in flushSync, but this may hurt performance.\n\nsetState does not update this.state immediately. This makes reading this.state right after calling setState a potential pitfall. Instead, use componentDidUpdate or the setState callback argument, either of which are guaranteed to fire after the update has been applied. If you need to set the state based on the previous state, you can pass a function to nextState as described above.\n\nNote\n\nCalling setState in class components is similar to calling a set function in function components.\n\nSee how to migrate.\n\nshouldComponentUpdate(nextProps, nextState, nextContext) \n\nIf you define shouldComponentUpdate, React will call it to determine whether a re-render can be skipped.\n\nIf you are confident you want to write it by hand, you may compare this.props with nextProps and this.state with nextState and return false to tell React the update can be skipped.\n\nclass Rectangle extends Component {\n\n  state = {\n\n    isHovered: false\n\n  };\n\n\n\n  shouldComponentUpdate(nextProps, nextState) {\n\n    if (\n\n      nextProps.position.x === this.props.position.x &&\n\n      nextProps.position.y === this.props.position.y &&\n\n      nextProps.size.width === this.props.size.width &&\n\n      nextProps.size.height === this.props.size.height &&\n\n      nextState.isHovered === this.state.isHovered\n\n    ) {\n\n      // Nothing has changed, so a re-render is unnecessary\n\n      return false;\n\n    }\n\n    return true;\n\n  }\n\n\n\n  // ...\n\n}\n\nReact calls shouldComponentUpdate before rendering when new props or state are being received. Defaults to true. This method is not called for the initial render or when forceUpdate is used.\n\nParameters \nnextProps: The next props that the component is about to render with. Compare nextProps to this.props to determine what changed.\nnextState: The next state that the component is about to render with. Compare nextState to this.state to determine what changed.\nnextContext: The next context that the component is about to render with. Compare nextContext to this.context to determine what changed. Only available if you specify static contextType.\nReturns \n\nReturn true if you want the component to re-render. That’s the default behavior.\n\nReturn false to tell React that re-rendering can be skipped.\n\nCaveats \n\nThis method only exists as a performance optimization. If your component breaks without it, fix that first.\n\nConsider using PureComponent instead of writing shouldComponentUpdate by hand. PureComponent shallowly compares props and state, and reduces the chance that you’ll skip a necessary update.\n\nWe do not recommend doing deep equality checks or using JSON.stringify in shouldComponentUpdate. It makes performance unpredictable and dependent on the data structure of every prop and state. In the best case, you risk introducing multi-second stalls to your application, and in the worst case you risk crashing it.\n\nReturning false does not prevent child components from re-rendering when their state changes.\n\nReturning false does not guarantee that the component will not re-render. React will use the return value as a hint but it may still choose to re-render your component if it makes sense to do for other reasons.\n\nNote\n\nOptimizing class components with shouldComponentUpdate is similar to optimizing function components with memo. Function components also offer more granular optimization with useMemo.\n\nUNSAFE_componentWillMount() \n\nIf you define UNSAFE_componentWillMount, React will call it immediately after the constructor. It only exists for historical reasons and should not be used in any new code. Instead, use one of the alternatives:\n\nTo initialize state, declare state as a class field or set this.state inside the constructor.\nIf you need to run a side effect or set up a subscription, move that logic to componentDidMount instead.\n\nSee examples of migrating away from unsafe lifecycles.\n\nParameters \n\nUNSAFE_componentWillMount does not take any parameters.\n\nReturns \n\nUNSAFE_componentWillMount should not return anything.\n\nCaveats \n\nUNSAFE_componentWillMount will not get called if the component implements static getDerivedStateFromProps or getSnapshotBeforeUpdate.\n\nDespite its naming, UNSAFE_componentWillMount does not guarantee that the component will get mounted if your app uses modern React features like Suspense. If a render attempt is suspended (for example, because the code for some child component has not loaded yet), React will throw the in-progress tree away and attempt to construct the component from scratch during the next attempt. This is why this method is “unsafe”. Code that relies on mounting (like adding a subscription) should go into componentDidMount.\n\nUNSAFE_componentWillMount is the only lifecycle method that runs during server rendering. For all practical purposes, it is identical to constructor, so you should use the constructor for this type of logic instead.\n\nNote\n\nCalling setState inside UNSAFE_componentWillMount in a class component to initialize state is equivalent to passing that state as the initial state to useState in a function component.\n\nUNSAFE_componentWillReceiveProps(nextProps, nextContext) \n\nIf you define UNSAFE_componentWillReceiveProps, React will call it when the component receives new props. It only exists for historical reasons and should not be used in any new code. Instead, use one of the alternatives:\n\nIf you need to run a side effect (for example, fetch data, run an animation, or reinitialize a subscription) in response to prop changes, move that logic to componentDidUpdate instead.\nIf you need to avoid re-computing some data only when a prop changes, use a memoization helper instead.\nIf you need to “reset” some state when a prop changes, consider either making a component fully controlled or fully uncontrolled with a key instead.\nIf you need to “adjust” some state when a prop changes, check whether you can compute all the necessary information from props alone during rendering. If you can’t, use static getDerivedStateFromProps instead.\n\nSee examples of migrating away from unsafe lifecycles.\n\nParameters \nnextProps: The next props that the component is about to receive from its parent component. Compare nextProps to this.props to determine what changed.\nnextContext: The next context that the component is about to receive from the closest provider. Compare nextContext to this.context to determine what changed. Only available if you specify static contextType.\nReturns \n\nUNSAFE_componentWillReceiveProps should not return anything.\n\nCaveats \n\nUNSAFE_componentWillReceiveProps will not get called if the component implements static getDerivedStateFromProps or getSnapshotBeforeUpdate.\n\nDespite its naming, UNSAFE_componentWillReceiveProps does not guarantee that the component will receive those props if your app uses modern React features like Suspense. If a render attempt is suspended (for example, because the code for some child component has not loaded yet), React will throw the in-progress tree away and attempt to construct the component from scratch during the next attempt. By the time of the next render attempt, the props might be different. This is why this method is “unsafe”. Code that should run only for committed updates (like resetting a subscription) should go into componentDidUpdate.\n\nUNSAFE_componentWillReceiveProps does not mean that the component has received different props than the last time. You need to compare nextProps and this.props yourself to check if something changed.\n\nReact doesn’t call UNSAFE_componentWillReceiveProps with initial props during mounting. It only calls this method if some of component’s props are going to be updated. For example, calling setState doesn’t generally trigger UNSAFE_componentWillReceiveProps inside the same component.\n\nNote\n\nCalling setState inside UNSAFE_componentWillReceiveProps in a class component to “adjust” state is equivalent to calling the set function from useState during rendering in a function component.\n\nUNSAFE_componentWillUpdate(nextProps, nextState) \n\nIf you define UNSAFE_componentWillUpdate, React will call it before rendering with the new props or state. It only exists for historical reasons and should not be used in any new code. Instead, use one of the alternatives:\n\nIf you need to run a side effect (for example, fetch data, run an animation, or reinitialize a subscription) in response to prop or state changes, move that logic to componentDidUpdate instead.\nIf you need to read some information from the DOM (for example, to save the current scroll position) so that you can use it in componentDidUpdate later, read it inside getSnapshotBeforeUpdate instead.\n\nSee examples of migrating away from unsafe lifecycles.\n\nParameters \nnextProps: The next props that the component is about to render with. Compare nextProps to this.props to determine what changed.\nnextState: The next state that the component is about to render with. Compare nextState to this.state to determine what changed.\nReturns \n\nUNSAFE_componentWillUpdate should not return anything.\n\nCaveats \n\nUNSAFE_componentWillUpdate will not get called if shouldComponentUpdate is defined and returns false.\n\nUNSAFE_componentWillUpdate will not get called if the component implements static getDerivedStateFromProps or getSnapshotBeforeUpdate.\n\nIt’s not supported to call setState (or any method that leads to setState being called, like dispatching a Redux action) during componentWillUpdate.\n\nDespite its naming, UNSAFE_componentWillUpdate does not guarantee that the component will update if your app uses modern React features like Suspense. If a render attempt is suspended (for example, because the code for some child component has not loaded yet), React will throw the in-progress tree away and attempt to construct the component from scratch during the next attempt. By the time of the next render attempt, the props and state might be different. This is why this method is “unsafe”. Code that should run only for committed updates (like resetting a subscription) should go into componentDidUpdate.\n\nUNSAFE_componentWillUpdate does not mean that the component has received different props or state than the last time. You need to compare nextProps with this.props and nextState with this.state yourself to check if something changed.\n\nReact doesn’t call UNSAFE_componentWillUpdate with initial props and state during mounting.\n\nNote\n\nThere is no direct equivalent to UNSAFE_componentWillUpdate in function components.\n\nstatic contextType \n\nIf you want to read this.context from your class component, you must specify which context it needs to read. The context you specify as the static contextType must be a value previously created by createContext.\n\nclass Button extends Component {\n\n  static contextType = ThemeContext;\n\n\n\n  render() {\n\n    const theme = this.context;\n\n    const className = 'button-' + theme;\n\n    return (\n\n      <button className={className}>\n\n        {this.props.children}\n\n      </button>\n\n    );\n\n  }\n\n}\nNote\n\nReading this.context in class components is equivalent to useContext in function components.\n\nSee how to migrate.\n\nstatic defaultProps \n\nYou can define static defaultProps to set the default props for the class. They will be used for undefined and missing props, but not for null props.\n\nFor example, here is how you define that the color prop should default to 'blue':\n\nclass Button extends Component {\n\n  static defaultProps = {\n\n    color: 'blue'\n\n  };\n\n\n\n  render() {\n\n    return <button className={this.props.color}>click me</button>;\n\n  }\n\n}\n\nIf the color prop is not provided or is undefined, it will be set by default to 'blue':\n\n<>\n\n  {/* this.props.color is \"blue\" */}\n\n  <Button />\n\n\n\n  {/* this.props.color is \"blue\" */}\n\n  <Button color={undefined} />\n\n\n\n  {/* this.props.color is null */}\n\n  <Button color={null} />\n\n\n\n  {/* this.props.color is \"red\" */}\n\n  <Button color=\"red\" />\n\n</>\nNote\n\nDefining defaultProps in class components is similar to using default values in function components.\n\nstatic getDerivedStateFromError(error) \n\nIf you define static getDerivedStateFromError, React will call it when a child component (including distant children) throws an error during rendering. This lets you display an error message instead of clearing the UI.\n\nTypically, it is used together with componentDidCatch which lets you send the error report to some analytics service. A component with these methods is called an Error Boundary.\n\nSee an example.\n\nParameters \nerror: The error that was thrown. In practice, it will usually be an instance of Error but this is not guaranteed because JavaScript allows to throw any value, including strings or even null.\nReturns \n\nstatic getDerivedStateFromError should return the state telling the component to display the error message.\n\nCaveats \nstatic getDerivedStateFromError should be a pure function. If you want to perform a side effect (for example, to call an analytics service), you need to also implement componentDidCatch.\nNote\n\nThere is no direct equivalent for static getDerivedStateFromError in function components yet. If you’d like to avoid creating class components, write a single ErrorBoundary component like above and use it throughout your app. Alternatively, use the react-error-boundary package which does that.\n\nstatic getDerivedStateFromProps(props, state) \n\nIf you define static getDerivedStateFromProps, React will call it right before calling render, both on the initial mount and on subsequent updates. It should return an object to update the state, or null to update nothing.\n\nThis method exists for rare use cases where the state depends on changes in props over time. For example, this Form component resets the email state when the userID prop changes:\n\nclass Form extends Component {\n\n  state = {\n\n    email: this.props.defaultEmail,\n\n    prevUserID: this.props.userID\n\n  };\n\n\n\n  static getDerivedStateFromProps(props, state) {\n\n    // Any time the current user changes,\n\n    // Reset any parts of state that are tied to that user.\n\n    // In this simple example, that's just the email.\n\n    if (props.userID !== state.prevUserID) {\n\n      return {\n\n        prevUserID: props.userID,\n\n        email: props.defaultEmail\n\n      };\n\n    }\n\n    return null;\n\n  }\n\n\n\n  // ...\n\n}\n\nNote that this pattern requires you to keep a previous value of the prop (like userID) in state (like prevUserID).\n\nPitfall\n\nDeriving state leads to verbose code and makes your components difficult to think about. Make sure you’re familiar with simpler alternatives:\n\nIf you need to perform a side effect (for example, data fetching or an animation) in response to a change in props, use componentDidUpdate method instead.\nIf you want to re-compute some data only when a prop changes, use a memoization helper instead.\nIf you want to “reset” some state when a prop changes, consider either making a component fully controlled or fully uncontrolled with a key instead.\nParameters \nprops: The next props that the component is about to render with.\nstate: The next state that the component is about to render with.\nReturns \n\nstatic getDerivedStateFromProps return an object to update the state, or null to update nothing.\n\nCaveats \n\nThis method is fired on every render, regardless of the cause. This is different from UNSAFE_componentWillReceiveProps, which only fires when the parent causes a re-render and not as a result of a local setState.\n\nThis method doesn’t have access to the component instance. If you’d like, you can reuse some code between static getDerivedStateFromProps and the other class methods by extracting pure functions of the component props and state outside the class definition.\n\nNote\n\nImplementing static getDerivedStateFromProps in a class component is equivalent to calling the set function from useState during rendering in a function component.\n\nUsage \nDefining a class component \n\nTo define a React component as a class, extend the built-in Component class and define a render method:\n\nimport { Component } from 'react';\n\n\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nReact will call your render method whenever it needs to figure out what to display on the screen. Usually, you will return some JSX from it. Your render method should be a pure function: it should only calculate the JSX.\n\nSimilarly to function components, a class component can receive information by props from its parent component. However, the syntax for reading props is different. For example, if the parent component renders <Greeting name=\"Taylor\" />, then you can read the name prop from this.props, like this.props.name:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nclass Greeting extends Component {\n  render() {\n    return <h1>Hello, {this.props.name}!</h1>;\n  }\n}\n\nexport default function App() {\n  return (\n    <>\n      <Greeting name=\"Sara\" />\n      <Greeting name=\"Cahal\" />\n      <Greeting name=\"Edite\" />\n    </>\n  );\n}\n\n\nShow more\n\nNote that Hooks (functions starting with use, like useState) are not supported inside class components.\n\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nAdding state to a class component \n\nTo add state to a class, assign an object to a property called state. To update state, call this.setState.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nexport default class Counter extends Component {\n  state = {\n    name: 'Taylor',\n    age: 42,\n  };\n\n  handleNameChange = (e) => {\n    this.setState({\n      name: e.target.value\n    });\n  }\n\n  handleAgeChange = () => {\n    this.setState({\n      age: this.state.age + 1 \n    });\n  };\n\n  render() {\n    return (\n      <>\n        <input\n          value={this.state.name}\n          onChange={this.handleNameChange}\n        />\n        <button onClick={this.handleAgeChange}>\n          Increment age\n        </button>\n        <p>Hello, {this.state.name}. You are {this.state.age}.</p>\n      </>\n    );\n  }\n}\n\n\nShow more\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nAdding lifecycle methods to a class component \n\nThere are a few special methods you can define on your class.\n\nIf you define the componentDidMount method, React will call it when your component is added (mounted) to the screen. React will call componentDidUpdate after your component re-renders due to changed props or state. React will call componentWillUnmount after your component has been removed (unmounted) from the screen.\n\nIf you implement componentDidMount, you usually need to implement all three lifecycles to avoid bugs. For example, if componentDidMount reads some state or props, you also have to implement componentDidUpdate to handle their changes, and componentWillUnmount to clean up whatever componentDidMount was doing.\n\nFor example, this ChatRoom component keeps a chat connection synchronized with props and state:\n\nApp.js\nChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { Component } from 'react';\nimport { createConnection } from './chat.js';\n\nexport default class ChatRoom extends Component {\n  state = {\n    serverUrl: 'https://localhost:1234'\n  };\n\n  componentDidMount() {\n    this.setupConnection();\n  }\n\n  componentDidUpdate(prevProps, prevState) {\n    if (\n      this.props.roomId !== prevProps.roomId ||\n      this.state.serverUrl !== prevState.serverUrl\n    ) {\n      this.destroyConnection();\n      this.setupConnection();\n    }\n  }\n\n  componentWillUnmount() {\n    this.destroyConnection();\n  }\n\n  setupConnection() {\n    this.connection = createConnection(\n      this.state.serverUrl,\n      this.props.roomId\n    );\n    this.connection.connect();    \n  }\n\n  destroyConnection() {\n    this.connection.disconnect();\n    this.connection = null;\n  }\n\n  render() {\n    return (\n      <>\n        <label>\n          Server URL:{' '}\n          <input\n            value={this.state.serverUrl}\n            onChange={e => {\n              this.setState({\n                serverUrl: e.target.value\n              });\n            }}\n          />\n        </label>\n        <h1>Welcome to the {this.props.roomId} room!</h1>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nNote that in development when Strict Mode is on, React will call componentDidMount, immediately call componentWillUnmount, and then call componentDidMount again. This helps you notice if you forgot to implement componentWillUnmount or if its logic doesn’t fully “mirror” what componentDidMount does.\n\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nCatching rendering errors with an Error Boundary \n\nBy default, if your application throws an error during rendering, React will remove its UI from the screen. To prevent this, you can wrap a part of your UI into an Error Boundary. An Error Boundary is a special component that lets you display some fallback UI instead of the part that crashed—for example, an error message.\n\nTo implement an Error Boundary component, you need to provide static getDerivedStateFromError which lets you update state in response to an error and display an error message to the user. You can also optionally implement componentDidCatch to add some extra logic, for example, to log the error to an analytics service.\n\nWith captureOwnerStack you can include the Owner Stack during development.\n\nimport * as React from 'react';\n\n\n\nclass ErrorBoundary extends React.Component {\n\n  constructor(props) {\n\n    super(props);\n\n    this.state = { hasError: false };\n\n  }\n\n\n\n  static getDerivedStateFromError(error) {\n\n    // Update state so the next render will show the fallback UI.\n\n    return { hasError: true };\n\n  }\n\n\n\n  componentDidCatch(error, info) {\n\n    logErrorToMyService(\n\n      error,\n\n      // Example \"componentStack\":\n\n      //   in ComponentThatThrows (created by App)\n\n      //   in ErrorBoundary (created by App)\n\n      //   in div (created by App)\n\n      //   in App\n\n      info.componentStack,\n\n      // Warning: `captureOwnerStack` is not available in production.\n\n      React.captureOwnerStack(),\n\n    );\n\n  }\n\n\n\n  render() {\n\n    if (this.state.hasError) {\n\n      // You can render any custom fallback UI\n\n      return this.props.fallback;\n\n    }\n\n\n\n    return this.props.children;\n\n  }\n\n}\n\nThen you can wrap a part of your component tree with it:\n\n<ErrorBoundary fallback={<p>Something went wrong</p>}>\n\n  <Profile />\n\n</ErrorBoundary>\n\nIf Profile or its child component throws an error, ErrorBoundary will “catch” that error, display a fallback UI with the error message you’ve provided, and send a production error report to your error reporting service.\n\nYou don’t need to wrap every component into a separate Error Boundary. When you think about the granularity of Error Boundaries, consider where it makes sense to display an error message. For example, in a messaging app, it makes sense to place an Error Boundary around the list of conversations. It also makes sense to place one around every individual message. However, it wouldn’t make sense to place a boundary around every avatar.\n\nNote\n\nThere is currently no way to write an Error Boundary as a function component. However, you don’t have to write the Error Boundary class yourself. For example, you can use react-error-boundary instead.\n\nAlternatives \nMigrating a simple component from a class to a function \n\nTypically, you will define components as functions instead.\n\nFor example, suppose you’re converting this Greeting class component to a function:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nclass Greeting extends Component {\n  render() {\n    return <h1>Hello, {this.props.name}!</h1>;\n  }\n}\n\nexport default function App() {\n  return (\n    <>\n      <Greeting name=\"Sara\" />\n      <Greeting name=\"Cahal\" />\n      <Greeting name=\"Edite\" />\n    </>\n  );\n}\n\n\nShow more\n\nDefine a function called Greeting. This is where you will move the body of your render function.\n\nfunction Greeting() {\n\n  // ... move the code from the render method here ...\n\n}\n\nInstead of this.props.name, define the name prop using the destructuring syntax and read it directly:\n\nfunction Greeting({ name }) {\n\n  return <h1>Hello, {name}!</h1>;\n\n}\n\nHere is a complete example:\n\nApp.js\nDownload\nReload\nClear\nFork\nfunction Greeting({ name }) {\n  return <h1>Hello, {name}!</h1>;\n}\n\nexport default function App() {\n  return (\n    <>\n      <Greeting name=\"Sara\" />\n      <Greeting name=\"Cahal\" />\n      <Greeting name=\"Edite\" />\n    </>\n  );\n}\n\n\nMigrating a component with state from a class to a function \n\nSuppose you’re converting this Counter class component to a function:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nexport default class Counter extends Component {\n  state = {\n    name: 'Taylor',\n    age: 42,\n  };\n\n  handleNameChange = (e) => {\n    this.setState({\n      name: e.target.value\n    });\n  }\n\n  handleAgeChange = (e) => {\n    this.setState({\n      age: this.state.age + 1 \n    });\n  };\n\n  render() {\n    return (\n      <>\n        <input\n          value={this.state.name}\n          onChange={this.handleNameChange}\n        />\n        <button onClick={this.handleAgeChange}>\n          Increment age\n        </button>\n        <p>Hello, {this.state.name}. You are {this.state.age}.</p>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nStart by declaring a function with the necessary state variables:\n\nimport { useState } from 'react';\n\n\n\nfunction Counter() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n  // ...\n\nNext, convert the event handlers:\n\nfunction Counter() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n\n\n  function handleNameChange(e) {\n\n    setName(e.target.value);\n\n  }\n\n\n\n  function handleAgeChange() {\n\n    setAge(age + 1);\n\n  }\n\n  // ...\n\nFinally, replace all references starting with this with the variables and functions you defined in your component. For example, replace this.state.age with age, and replace this.handleNameChange with handleNameChange.\n\nHere is a fully converted component:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [name, setName] = useState('Taylor');\n  const [age, setAge] = useState(42);\n\n  function handleNameChange(e) {\n    setName(e.target.value);\n  }\n\n  function handleAgeChange() {\n    setAge(age + 1);\n  }\n\n  return (\n    <>\n      <input\n        value={name}\n        onChange={handleNameChange}\n      />\n      <button onClick={handleAgeChange}>\n        Increment age\n      </button>\n      <p>Hello, {name}. You are {age}.</p>\n    </>\n  )\n}\n\n\nShow more\nMigrating a component with lifecycle methods from a class to a function \n\nSuppose you’re converting this ChatRoom class component with lifecycle methods to a function:\n\nApp.js\nChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { Component } from 'react';\nimport { createConnection } from './chat.js';\n\nexport default class ChatRoom extends Component {\n  state = {\n    serverUrl: 'https://localhost:1234'\n  };\n\n  componentDidMount() {\n    this.setupConnection();\n  }\n\n  componentDidUpdate(prevProps, prevState) {\n    if (\n      this.props.roomId !== prevProps.roomId ||\n      this.state.serverUrl !== prevState.serverUrl\n    ) {\n      this.destroyConnection();\n      this.setupConnection();\n    }\n  }\n\n  componentWillUnmount() {\n    this.destroyConnection();\n  }\n\n  setupConnection() {\n    this.connection = createConnection(\n      this.state.serverUrl,\n      this.props.roomId\n    );\n    this.connection.connect();    \n  }\n\n  destroyConnection() {\n    this.connection.disconnect();\n    this.connection = null;\n  }\n\n  render() {\n    return (\n      <>\n        <label>\n          Server URL:{' '}\n          <input\n            value={this.state.serverUrl}\n            onChange={e => {\n              this.setState({\n                serverUrl: e.target.value\n              });\n            }}\n          />\n        </label>\n        <h1>Welcome to the {this.props.roomId} room!</h1>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nFirst, verify that your componentWillUnmount does the opposite of componentDidMount. In the above example, that’s true: it disconnects the connection that componentDidMount sets up. If such logic is missing, add it first.\n\nNext, verify that your componentDidUpdate method handles changes to any props and state you’re using in componentDidMount. In the above example, componentDidMount calls setupConnection which reads this.state.serverUrl and this.props.roomId. This is why componentDidUpdate checks whether this.state.serverUrl and this.props.roomId have changed, and resets the connection if they did. If your componentDidUpdate logic is missing or doesn’t handle changes to all relevant props and state, fix that first.\n\nIn the above example, the logic inside the lifecycle methods connects the component to a system outside of React (a chat server). To connect a component to an external system, describe this logic as a single Effect:\n\nimport { useState, useEffect } from 'react';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => {\n\n      connection.disconnect();\n\n    };\n\n  }, [serverUrl, roomId]);\n\n\n\n  // ...\n\n}\n\nThis useEffect call is equivalent to the logic in the lifecycle methods above. If your lifecycle methods do multiple unrelated things, split them into multiple independent Effects. Here is a complete example you can play with:\n\nApp.js\nChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nexport default function ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  useEffect(() => {\n    const connection = createConnection(serverUrl, roomId);\n    connection.connect();\n    return () => {\n      connection.disconnect();\n    };\n  }, [roomId, serverUrl]);\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n    </>\n  );\n}\n\n\nShow more\nNote\n\nIf your component does not synchronize with any external systems, you might not need an Effect.\n\nMigrating a component with context from a class to a function \n\nIn this example, the Panel and Button class components read context from this.context:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, Component } from 'react';\n\nconst ThemeContext = createContext(null);\n\nclass Panel extends Component {\n  static contextType = ThemeContext;\n\n  render() {\n    const theme = this.context;\n    const className = 'panel-' + theme;\n    return (\n      <section className={className}>\n        <h1>{this.props.title}</h1>\n        {this.props.children}\n      </section>\n    );    \n  }\n}\n\nclass Button extends Component {\n  static contextType = ThemeContext;\n\n  render() {\n    const theme = this.context;\n    const className = 'button-' + theme;\n    return (\n      <button className={className}>\n        {this.props.children}\n      </button>\n    );\n  }\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\n\nShow more\n\nWhen you convert them to function components, replace this.context with useContext calls:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext } from 'react';\n\nconst ThemeContext = createContext(null);\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\n\nShow more\nPREVIOUS\ncloneElement\nNEXT\ncreateElement"
  },
  {
    "title": "createElement – React",
    "url": "https://react.dev/reference/react/createElement",
    "html": "API REFERENCE\nLEGACY REACT APIS\ncreateElement\n\ncreateElement lets you create a React element. It serves as an alternative to writing JSX.\n\nconst element = createElement(type, props, ...children)\nReference\ncreateElement(type, props, ...children)\nUsage\nCreating an element without JSX\nReference \ncreateElement(type, props, ...children) \n\nCall createElement to create a React element with the given type, props, and children.\n\nimport { createElement } from 'react';\n\n\n\nfunction Greeting({ name }) {\n\n  return createElement(\n\n    'h1',\n\n    { className: 'greeting' },\n\n    'Hello'\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \n\ntype: The type argument must be a valid React component type. For example, it could be a tag name string (such as 'div' or 'span'), or a React component (a function, a class, or a special component like Fragment).\n\nprops: The props argument must either be an object or null. If you pass null, it will be treated the same as an empty object. React will create an element with props matching the props you have passed. Note that ref and key from your props object are special and will not be available as element.props.ref and element.props.key on the returned element. They will be available as element.ref and element.key.\n\noptional ...children: Zero or more child nodes. They can be any React nodes, including React elements, strings, numbers, portals, empty nodes (null, undefined, true, and false), and arrays of React nodes.\n\nReturns \n\ncreateElement returns a React element object with a few properties:\n\ntype: The type you have passed.\nprops: The props you have passed except for ref and key.\nref: The ref you have passed. If missing, null.\nkey: The key you have passed, coerced to a string. If missing, null.\n\nUsually, you’ll return the element from your component or make it a child of another element. Although you may read the element’s properties, it’s best to treat every element as opaque after it’s created, and only render it.\n\nCaveats \n\nYou must treat React elements and their props as immutable and never change their contents after creation. In development, React will freeze the returned element and its props property shallowly to enforce this.\n\nWhen you use JSX, you must start a tag with a capital letter to render your own custom component. In other words, <Something /> is equivalent to createElement(Something), but <something /> (lowercase) is equivalent to createElement('something') (note it’s a string, so it will be treated as a built-in HTML tag).\n\nYou should only pass children as multiple arguments to createElement if they are all statically known, like createElement('h1', {}, child1, child2, child3). If your children are dynamic, pass the entire array as the third argument: createElement('ul', {}, listItems). This ensures that React will warn you about missing keys for any dynamic lists. For static lists this is not necessary because they never reorder.\n\nUsage \nCreating an element without JSX \n\nIf you don’t like JSX or can’t use it in your project, you can use createElement as an alternative.\n\nTo create an element without JSX, call createElement with some type, props, and children:\n\nimport { createElement } from 'react';\n\n\n\nfunction Greeting({ name }) {\n\n  return createElement(\n\n    'h1',\n\n    { className: 'greeting' },\n\n    'Hello ',\n\n    createElement('i', null, name),\n\n    '. Welcome!'\n\n  );\n\n}\n\nThe children are optional, and you can pass as many as you need (the example above has three children). This code will display a <h1> header with a greeting. For comparison, here is the same example rewritten with JSX:\n\nfunction Greeting({ name }) {\n\n  return (\n\n    <h1 className=\"greeting\">\n\n      Hello <i>{name}</i>. Welcome!\n\n    </h1>\n\n  );\n\n}\n\nTo render your own React component, pass a function like Greeting as the type instead of a string like 'h1':\n\nexport default function App() {\n\n  return createElement(Greeting, { name: 'Taylor' });\n\n}\n\nWith JSX, it would look like this:\n\nexport default function App() {\n\n  return <Greeting name=\"Taylor\" />;\n\n}\n\nHere is a complete example written with createElement:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createElement } from 'react';\n\nfunction Greeting({ name }) {\n  return createElement(\n    'h1',\n    { className: 'greeting' },\n    'Hello ',\n    createElement('i', null, name),\n    '. Welcome!'\n  );\n}\n\nexport default function App() {\n  return createElement(\n    Greeting,\n    { name: 'Taylor' }\n  );\n}\n\n\nShow more\n\nAnd here is the same example written using JSX:\n\nApp.js\nDownload\nReload\nClear\nFork\nfunction Greeting({ name }) {\n  return (\n    <h1 className=\"greeting\">\n      Hello <i>{name}</i>. Welcome!\n    </h1>\n  );\n}\n\nexport default function App() {\n  return <Greeting name=\"Taylor\" />;\n}\n\n\n\nBoth coding styles are fine, so you can use whichever one you prefer for your project. The main benefit of using JSX compared to createElement is that it’s easy to see which closing tag corresponds to which opening tag.\n\nDEEP DIVE\nWhat is a React element, exactly? \nShow Details\nPREVIOUS\nComponent\nNEXT\ncreateRef"
  },
  {
    "title": "createRef – React",
    "url": "https://react.dev/reference/react/createRef",
    "html": "API REFERENCE\nLEGACY REACT APIS\ncreateRef\nPitfall\n\ncreateRef is mostly used for class components. Function components typically rely on useRef instead.\n\ncreateRef creates a ref object which can contain arbitrary value.\n\nclass MyInput extends Component {\n\n  inputRef = createRef();\n\n  // ...\n\n}\nReference\ncreateRef()\nUsage\nDeclaring a ref in a class component\nAlternatives\nMigrating from a class with createRef to a function with useRef\nReference \ncreateRef() \n\nCall createRef to declare a ref inside a class component.\n\nimport { createRef, Component } from 'react';\n\n\n\nclass MyComponent extends Component {\n\n  intervalRef = createRef();\n\n  inputRef = createRef();\n\n  // ...\n\nSee more examples below.\n\nParameters \n\ncreateRef takes no parameters.\n\nReturns \n\ncreateRef returns an object with a single property:\n\ncurrent: Initially, it’s set to the null. You can later set it to something else. If you pass the ref object to React as a ref attribute to a JSX node, React will set its current property.\nCaveats \ncreateRef always returns a different object. It’s equivalent to writing { current: null } yourself.\nIn a function component, you probably want useRef instead which always returns the same object.\nconst ref = useRef() is equivalent to const [ref, _] = useState(() => createRef(null)).\nUsage \nDeclaring a ref in a class component \n\nTo declare a ref inside a class component, call createRef and assign its result to a class field:\n\nimport { Component, createRef } from 'react';\n\n\n\nclass Form extends Component {\n\n  inputRef = createRef();\n\n\n\n  // ...\n\n}\n\nIf you now pass ref={this.inputRef} to an <input> in your JSX, React will populate this.inputRef.current with the input DOM node. For example, here is how you make a button that focuses the input:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component, createRef } from 'react';\n\nexport default class Form extends Component {\n  inputRef = createRef();\n\n  handleClick = () => {\n    this.inputRef.current.focus();\n  }\n\n  render() {\n    return (\n      <>\n        <input ref={this.inputRef} />\n        <button onClick={this.handleClick}>\n          Focus the input\n        </button>\n      </>\n    );\n  }\n}\n\n\nShow more\nPitfall\n\ncreateRef is mostly used for class components. Function components typically rely on useRef instead.\n\nAlternatives \nMigrating from a class with createRef to a function with useRef \n\nWe recommend using function components instead of class components in new code. If you have some existing class components using createRef, here is how you can convert them. This is the original code:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component, createRef } from 'react';\n\nexport default class Form extends Component {\n  inputRef = createRef();\n\n  handleClick = () => {\n    this.inputRef.current.focus();\n  }\n\n  render() {\n    return (\n      <>\n        <input ref={this.inputRef} />\n        <button onClick={this.handleClick}>\n          Focus the input\n        </button>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nWhen you convert this component from a class to a function, replace calls to createRef with calls to useRef:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useRef } from 'react';\n\nexport default function Form() {\n  const inputRef = useRef(null);\n\n  function handleClick() {\n    inputRef.current.focus();\n  }\n\n  return (\n    <>\n      <input ref={inputRef} />\n      <button onClick={handleClick}>\n        Focus the input\n      </button>\n    </>\n  );\n}\n\n\nShow more\nPREVIOUS\ncreateElement\nNEXT\nforwardRef"
  },
  {
    "title": "forwardRef – React",
    "url": "https://react.dev/reference/react/forwardRef",
    "html": "API REFERENCE\nLEGACY REACT APIS\nforwardRef\nDeprecated\n\nIn React 19, forwardRef is no longer necessary. Pass ref as a prop instead.\n\nforwardRef will be deprecated in a future release. Learn more here.\n\nforwardRef lets your component expose a DOM node to the parent component with a ref.\n\nconst SomeComponent = forwardRef(render)\nReference\nforwardRef(render)\nrender function\nUsage\nExposing a DOM node to the parent component\nForwarding a ref through multiple components\nExposing an imperative handle instead of a DOM node\nTroubleshooting\nMy component is wrapped in forwardRef, but the ref to it is always null\nReference \nforwardRef(render) \n\nCall forwardRef() to let your component receive a ref and forward it to a child component:\n\nimport { forwardRef } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  // ...\n\n});\n\nSee more examples below.\n\nParameters \nrender: The render function for your component. React calls this function with the props and ref that your component received from its parent. The JSX you return will be the output of your component.\nReturns \n\nforwardRef returns a React component that you can render in JSX. Unlike React components defined as plain functions, a component returned by forwardRef is also able to receive a ref prop.\n\nCaveats \nIn Strict Mode, React will call your render function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your render function is pure (as it should be), this should not affect the logic of your component. The result from one of the calls will be ignored.\nrender function \n\nforwardRef accepts a render function as an argument. React calls this function with props and ref:\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  return (\n\n    <label>\n\n      {props.label}\n\n      <input ref={ref} />\n\n    </label>\n\n  );\n\n});\nParameters \n\nprops: The props passed by the parent component.\n\nref:  The ref attribute passed by the parent component. The ref can be an object or a function. If the parent component has not passed a ref, it will be null. You should either pass the ref you receive to another component, or pass it to useImperativeHandle.\n\nReturns \n\nforwardRef returns a React component that you can render in JSX. Unlike React components defined as plain functions, the component returned by forwardRef is able to take a ref prop.\n\nUsage \nExposing a DOM node to the parent component \n\nBy default, each component’s DOM nodes are private. However, sometimes it’s useful to expose a DOM node to the parent—for example, to allow focusing it. To opt in, wrap your component definition into forwardRef():\n\nimport { forwardRef } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const { label, ...otherProps } = props;\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input {...otherProps} />\n\n    </label>\n\n  );\n\n});\n\nYou will receive a ref as the second argument after props. Pass it to the DOM node that you want to expose:\n\nimport { forwardRef } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const { label, ...otherProps } = props;\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input {...otherProps} ref={ref} />\n\n    </label>\n\n  );\n\n});\n\nThis lets the parent Form component access the <input> DOM node exposed by MyInput:\n\nfunction Form() {\n\n  const ref = useRef(null);\n\n\n\n  function handleClick() {\n\n    ref.current.focus();\n\n  }\n\n\n\n  return (\n\n    <form>\n\n      <MyInput label=\"Enter your name:\" ref={ref} />\n\n      <button type=\"button\" onClick={handleClick}>\n\n        Edit\n\n      </button>\n\n    </form>\n\n  );\n\n}\n\nThis Form component passes a ref to MyInput. The MyInput component forwards that ref to the <input> browser tag. As a result, the Form component can access that <input> DOM node and call focus() on it.\n\nKeep in mind that exposing a ref to the DOM node inside your component makes it harder to change your component’s internals later. You will typically expose DOM nodes from reusable low-level components like buttons or text inputs, but you won’t do it for application-level components like an avatar or a comment.\n\nExamples of forwarding a ref\n1. Focusing a text input\n2. Playing and pausing a video\nExample 1 of 2: Focusing a text input \n\nClicking the button will focus the input. The Form component defines a ref and passes it to the MyInput component. The MyInput component forwards that ref to the browser <input>. This lets the Form component focus the <input>.\n\nApp.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport MyInput from './MyInput.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n  }\n\n  return (\n    <form>\n      <MyInput label=\"Enter your name:\" ref={ref} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\nNext Example\nForwarding a ref through multiple components \n\nInstead of forwarding a ref to a DOM node, you can forward it to your own component like MyInput:\n\nconst FormField = forwardRef(function FormField(props, ref) {\n\n  // ...\n\n  return (\n\n    <>\n\n      <MyInput ref={ref} />\n\n      ...\n\n    </>\n\n  );\n\n});\n\nIf that MyInput component forwards a ref to its <input>, a ref to FormField will give you that <input>:\n\nfunction Form() {\n\n  const ref = useRef(null);\n\n\n\n  function handleClick() {\n\n    ref.current.focus();\n\n  }\n\n\n\n  return (\n\n    <form>\n\n      <FormField label=\"Enter your name:\" ref={ref} isRequired={true} />\n\n      <button type=\"button\" onClick={handleClick}>\n\n        Edit\n\n      </button>\n\n    </form>\n\n  );\n\n}\n\nThe Form component defines a ref and passes it to FormField. The FormField component forwards that ref to MyInput, which forwards it to a browser <input> DOM node. This is how Form accesses that DOM node.\n\nApp.js\nFormField.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport FormField from './FormField.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n  }\n\n  return (\n    <form>\n      <FormField label=\"Enter your name:\" ref={ref} isRequired={true} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\nExposing an imperative handle instead of a DOM node \n\nInstead of exposing an entire DOM node, you can expose a custom object, called an imperative handle, with a more constrained set of methods. To do this, you’d need to define a separate ref to hold the DOM node:\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const inputRef = useRef(null);\n\n\n\n  // ...\n\n\n\n  return <input {...props} ref={inputRef} />;\n\n});\n\nPass the ref you received to useImperativeHandle and specify the value you want to expose to the ref:\n\nimport { forwardRef, useRef, useImperativeHandle } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const inputRef = useRef(null);\n\n\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      focus() {\n\n        inputRef.current.focus();\n\n      },\n\n      scrollIntoView() {\n\n        inputRef.current.scrollIntoView();\n\n      },\n\n    };\n\n  }, []);\n\n\n\n  return <input {...props} ref={inputRef} />;\n\n});\n\nIf some component gets a ref to MyInput, it will only receive your { focus, scrollIntoView } object instead of the DOM node. This lets you limit the information you expose about your DOM node to the minimum.\n\nApp.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport MyInput from './MyInput.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n    // This won't work because the DOM node isn't exposed:\n    // ref.current.style.opacity = 0.5;\n  }\n\n  return (\n    <form>\n      <MyInput placeholder=\"Enter your name\" ref={ref} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\n\nRead more about using imperative handles.\n\nPitfall\n\nDo not overuse refs. You should only use refs for imperative behaviors that you can’t express as props: for example, scrolling to a node, focusing a node, triggering an animation, selecting text, and so on.\n\nIf you can express something as a prop, you should not use a ref. For example, instead of exposing an imperative handle like { open, close } from a Modal component, it is better to take isOpen as a prop like <Modal isOpen={isOpen} />. Effects can help you expose imperative behaviors via props.\n\nTroubleshooting \nMy component is wrapped in forwardRef, but the ref to it is always null \n\nThis usually means that you forgot to actually use the ref that you received.\n\nFor example, this component doesn’t do anything with its ref:\n\nconst MyInput = forwardRef(function MyInput({ label }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input />\n\n    </label>\n\n  );\n\n});\n\nTo fix it, pass the ref down to a DOM node or another component that can accept a ref:\n\nconst MyInput = forwardRef(function MyInput({ label }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input ref={ref} />\n\n    </label>\n\n  );\n\n});\n\nThe ref to MyInput could also be null if some of the logic is conditional:\n\nconst MyInput = forwardRef(function MyInput({ label, showInput }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      {showInput && <input ref={ref} />}\n\n    </label>\n\n  );\n\n});\n\nIf showInput is false, then the ref won’t be forwarded to any node, and a ref to MyInput will remain empty. This is particularly easy to miss if the condition is hidden inside another component, like Panel in this example:\n\nconst MyInput = forwardRef(function MyInput({ label, showInput }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      <Panel isExpanded={showInput}>\n\n        <input ref={ref} />\n\n      </Panel>\n\n    </label>\n\n  );\n\n});\nPREVIOUS\ncreateRef\nNEXT\nisValidElement"
  },
  {
    "title": "isValidElement – React",
    "url": "https://react.dev/reference/react/isValidElement",
    "html": "API REFERENCE\nLEGACY REACT APIS\nisValidElement\n\nisValidElement checks whether a value is a React element.\n\nconst isElement = isValidElement(value)\nReference\nisValidElement(value)\nUsage\nChecking if something is a React element\nReference \nisValidElement(value) \n\nCall isValidElement(value) to check whether value is a React element.\n\nimport { isValidElement, createElement } from 'react';\n\n\n\n// ✅ React elements\n\nconsole.log(isValidElement(<p />)); // true\n\nconsole.log(isValidElement(createElement('p'))); // true\n\n\n\n// ❌ Not React elements\n\nconsole.log(isValidElement(25)); // false\n\nconsole.log(isValidElement('Hello')); // false\n\nconsole.log(isValidElement({ age: 42 })); // false\n\nSee more examples below.\n\nParameters \nvalue: The value you want to check. It can be any a value of any type.\nReturns \n\nisValidElement returns true if the value is a React element. Otherwise, it returns false.\n\nCaveats \nOnly JSX tags and objects returned by createElement are considered to be React elements. For example, even though a number like 42 is a valid React node (and can be returned from a component), it is not a valid React element. Arrays and portals created with createPortal are also not considered to be React elements.\nUsage \nChecking if something is a React element \n\nCall isValidElement to check if some value is a React element.\n\nReact elements are:\n\nValues produced by writing a JSX tag\nValues produced by calling createElement\n\nFor React elements, isValidElement returns true:\n\nimport { isValidElement, createElement } from 'react';\n\n\n\n// ✅ JSX tags are React elements\n\nconsole.log(isValidElement(<p />)); // true\n\nconsole.log(isValidElement(<MyComponent />)); // true\n\n\n\n// ✅ Values returned by createElement are React elements\n\nconsole.log(isValidElement(createElement('p'))); // true\n\nconsole.log(isValidElement(createElement(MyComponent))); // true\n\nAny other values, such as strings, numbers, or arbitrary objects and arrays, are not React elements.\n\nFor them, isValidElement returns false:\n\n// ❌ These are *not* React elements\n\nconsole.log(isValidElement(null)); // false\n\nconsole.log(isValidElement(25)); // false\n\nconsole.log(isValidElement('Hello')); // false\n\nconsole.log(isValidElement({ age: 42 })); // false\n\nconsole.log(isValidElement([<div />, <div />])); // false\n\nconsole.log(isValidElement(MyComponent)); // false\n\nIt is very uncommon to need isValidElement. It’s mostly useful if you’re calling another API that only accepts elements (like cloneElement does) and you want to avoid an error when your argument is not a React element.\n\nUnless you have some very specific reason to add an isValidElement check, you probably don’t need it.\n\nDEEP DIVE\nReact elements vs React nodes \nShow Details\nPREVIOUS\nforwardRef\nNEXT\nPureComponent"
  },
  {
    "title": "PureComponent – React",
    "url": "https://react.dev/reference/react/PureComponent",
    "html": "API REFERENCE\nLEGACY REACT APIS\nPureComponent\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nPureComponent is similar to Component but it skips re-renders for same props and state. Class components are still supported by React, but we don’t recommend using them in new code.\n\nclass Greeting extends PureComponent {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\nReference\nPureComponent\nUsage\nSkipping unnecessary re-renders for class components\nAlternatives\nMigrating from a PureComponent class component to a function\nReference \nPureComponent \n\nTo skip re-rendering a class component for same props and state, extend PureComponent instead of Component:\n\nimport { PureComponent } from 'react';\n\n\n\nclass Greeting extends PureComponent {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nPureComponent is a subclass of Component and supports all the Component APIs. Extending PureComponent is equivalent to defining a custom shouldComponentUpdate method that shallowly compares props and state.\n\nSee more examples below.\n\nUsage \nSkipping unnecessary re-renders for class components \n\nReact normally re-renders a component whenever its parent re-renders. As an optimization, you can create a component that React will not re-render when its parent re-renders so long as its new props and state are the same as the old props and state. Class components can opt into this behavior by extending PureComponent:\n\nclass Greeting extends PureComponent {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nA React component should always have pure rendering logic. This means that it must return the same output if its props, state, and context haven’t changed. By using PureComponent, you are telling React that your component complies with this requirement, so React doesn’t need to re-render as long as its props and state haven’t changed. However, your component will still re-render if a context that it’s using changes.\n\nIn this example, notice that the Greeting component re-renders whenever name is changed (because that’s one of its props), but not when address is changed (because it’s not passed to Greeting as a prop):\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { PureComponent, useState } from 'react';\n\nclass Greeting extends PureComponent {\n  render() {\n    console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n    return <h3>Hello{this.props.name && ', '}{this.props.name}!</h3>;\n  }\n}\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nAlternatives \nMigrating from a PureComponent class component to a function \n\nWe recommend using function components instead of class components in new code. If you have some existing class components using PureComponent, here is how you can convert them. This is the original code:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { PureComponent, useState } from 'react';\n\nclass Greeting extends PureComponent {\n  render() {\n    console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n    return <h3>Hello{this.props.name && ', '}{this.props.name}!</h3>;\n  }\n}\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\n\nShow more\n\nWhen you convert this component from a class to a function, wrap it in memo:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { memo, useState } from 'react';\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n  return <h3>Hello{name && ', '}{name}!</h3>;\n});\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\n\nShow more\nNote\n\nUnlike PureComponent, memo does not compare the new and the old state. In function components, calling the set function with the same state already prevents re-renders by default, even without memo.\n\nPREVIOUS\nisValidElement"
  },
  {
    "title": "Not Found – React",
    "url": "https://react.dev/reference/react-dom/static/index",
    "html": "LEARN REACT\nNot Found\n\nThis page doesn’t exist.\n\nIf this is a mistake, let us know, and we will try to fix it!"
  }
]
</file>

<file path="output/jobs/better-auth.json">
[
  {
    "title": "Comparison | Better Auth",
    "url": "https://www.better-auth.com/docs/comparison",
    "html": "Comparison\n\nComparison is the thief of joy.\n\nHere are non detailed reasons why you may want to use Better Auth over other auth libraries and services.\n\nvs Other Auth Libraries\nFramework agnostic - Works with any framework, not just specific ones\nAdvanced features built-in - 2FA, multi-tenancy, multi-session, rate limiting, and many more\nPlugin system - Extend functionality without forking or complex workarounds\nFull control - Customize auth flows exactly how you want\nvs Self-Hosted Auth Servers\nNo separate infrastructure - Runs in your app, users stay in your database\nZero server maintenance - No auth servers to deploy, monitor, or update\nComplete feature set - Everything you need without the operational overhead\nvs Managed Auth Services\nKeep your data - Users stay in your database, not a third-party service\nNo per-user costs - Scale without worrying about auth billing\nSingle source of truth - All user data in one place\nvs Rolling Your Own\nSecurity handled - Battle-tested auth flows and security practices\nFocus on your product - Spend time on features that matter to your business\nPlugin extensibility - Add custom features without starting from scratch\nEdit on GitHub\n\nPrevious Page\n\nIntroduction\n\nNext Page\n\nInstallation"
  },
  {
    "title": "Introduction | Better Auth",
    "url": "https://www.better-auth.com/docs/introduction",
    "html": "Introduction\n\nBetter Auth is a framework-agnostic, universal authentication and authorization framework for TypeScript. It provides a comprehensive set of features out of the box and includes a plugin ecosystem that simplifies adding advanced functionalities. Whether you need 2FA, passkey, multi-tenancy, multi-session support, or even enterprise features like SSO, creating your own IDP, it lets you focus on building your application instead of reinventing the wheel.\n\nFeatures\n\nBetter Auth aims to be the most comprehensive auth library. It provides a wide range of features out of the box and allows you to extend it with plugins. Here are some of the features:\n\nFramework Agnostic\n\nSupport for most popular frameworks\n\nEmail & Password\n\nBuilt-in support for secure email and password authentication\n\nAccount & Session Management\n\nManage user accounts and sessions with ease\n\nBuilt-In Rate Limiter\n\nBuilt-in rate limiter with custom rules\n\nAutomatic Database Management\n\nAutomatic database management and migrations\n\nSocial Sign-on\n\nMultiple social sign-on providers\n\nOrganization & Access Control\n\nManage organizations and access control\n\nTwo Factor Authentication\n\nSecure your users with two factor authentication\n\nPlugin Ecosystem\n\nEven more capabilities with plugins\n\n...and much more!\n\nAI tooling\nLLMs.txt\n\nBetter Auth exposes an LLMs.txt that helps AI models understand how to integrate and interact with your authentication system. See it at https://better-auth.com/llms.txt.\n\nMCP\n\nBetter Auth provides an MCP server so you can use it with any AI model that supports the Model Context Protocol (MCP).\n\nCLI Options\n\nUse the Better Auth CLI to easily add the MCP server to your preferred client:\n\nCursor\nClaude Code\nOpen Code\nManual\nterminal\npnpm @better-auth/cli mcp --cursor\nManual Configuration\n\nAlternatively, you can manually configure the MCP server for each client:\n\nClaude Code\nOpen Code\nManual\nterminal\nclaude mcp add --transport http better-auth https://mcp.chonkie.ai/better-auth/better-auth-builder/mcp\n\nWe provide a first‑party MCP, powered by Chonkie. You can alternatively use context7 and other MCP providers.\n\nEdit on GitHub\n\nNext Page\n\nComparison"
  },
  {
    "title": "Installation | Better Auth",
    "url": "https://www.better-auth.com/docs/installation",
    "html": "Installation\nCopy Markdown\nOpen in\nInstall the Package\n\nLet's start by adding Better Auth to your project:\n\nnpm\npnpm\nyarn\nbun\nnpm install better-auth\n\nIf you're using a separate client and server setup, make sure to install Better Auth in both parts of your project.\n\nSet Environment Variables\n\nCreate a .env file in the root of your project and add the following environment variables:\n\nSecret Key\n\nRandom value used by the library for encryption and generating hashes. You can generate one using the button below or you can use something like openssl.\n\n.env\nBETTER_AUTH_SECRET=\nGenerate Secret\nSet Base URL\n.env\nBETTER_AUTH_URL=http://localhost:3000 # Base URL of your app\nCreate A Better Auth Instance\n\nCreate a file named auth.ts in one of these locations:\n\nProject root\nlib/ folder\nutils/ folder\n\nYou can also nest any of these folders under src/, app/ or server/ folder. (e.g. src/lib/auth.ts, app/lib/auth.ts).\n\nAnd in this file, import Better Auth and create your auth instance. Make sure to export the auth instance with the variable name auth or as a default export.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  //...\n});\nConfigure Database\n\nBetter Auth requires a database to store user data. You can easily configure Better Auth to use SQLite, PostgreSQL, or MySQL, and more!\n\nsqlite\npostgres\nmysql\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport Database from \"better-sqlite3\";\nexport const auth = betterAuth({\n    database: new Database(\"./sqlite.db\"),\n})\n\nAlternatively, if you prefer to use an ORM, you can use one of the built-in adapters.\n\ndrizzle\nprisma\nmongodb\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { drizzleAdapter } from \"better-auth/adapters/drizzle\";\nimport { db } from \"@/db\"; // your drizzle instance\nexport const auth = betterAuth({\n    database: drizzleAdapter(db, {\n        provider: \"pg\", // or \"mysql\", \"sqlite\"\n    }),\n});\n\nIf your database is not listed above, check out our other supported databases for more information, or use one of the supported ORMs.\n\nCreate Database Tables\n\nBetter Auth includes a CLI tool to help manage the schema required by the library.\n\nGenerate: This command generates an ORM schema or SQL migration file.\n\nIf you're using Kysely, you can apply the migration directly with migrate command below. Use generate only if you plan to apply the migration manually.\n\nTerminal\nnpx @better-auth/cli generate\nMigrate: This command creates the required tables directly in the database. (Available only for the built-in Kysely adapter)\nTerminal\nnpx @better-auth/cli migrate\n\nsee the CLI documentation for more information.\n\nIf you instead want to create the schema manually, you can find the core schema required in the database section.\n\nAuthentication Methods\n\nConfigure the authentication methods you want to use. Better Auth comes with built-in support for email/password, and social sign-on providers.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  //...other options\n  emailAndPassword: { \n    enabled: true, \n  }, \n  socialProviders: { \n    github: { \n      clientId: process.env.GITHUB_CLIENT_ID as string, \n      clientSecret: process.env.GITHUB_CLIENT_SECRET as string, \n    }, \n  }, \n});\n\nYou can use even more authentication methods like passkey, username, magic link and more through plugins.\n\nMount Handler\n\nTo handle API requests, you need to set up a route handler on your server.\n\nCreate a new file or route in your framework's designated catch-all route handler. This route should handle requests for the path /api/auth/* (unless you've configured a different base path).\n\nBetter Auth supports any backend framework with standard Request and Response objects and offers helper functions for popular frameworks.\n\nnext-js\nnuxt\nsvelte-kit\nremix\nsolid-start\nhono\nexpress\nelysia\ntanstack-start\nexpo\nCreate Client Instance\n\nThe client-side library helps you interact with the auth server. Better Auth comes with a client for all the popular web frameworks, including vanilla JavaScript.\n\nImport createAuthClient from the package for your framework (e.g., \"better-auth/react\" for React).\nCall the function to create your client.\nPass the base URL of your auth server. (If the auth server is running on the same domain as your client, you can skip this step.)\n\nIf you're using a different base path other than /api/auth make sure to pass the whole URL including the path. (e.g. http://localhost:3000/custom-path/auth)\n\nreact\nvue\nsvelte\nsolid\nvanilla\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\"\nexport const authClient = createAuthClient({\n    /** The base URL of the server (optional if you're using the same domain) */\n    baseURL: \"http://localhost:3000\"\n})\n\nTip: You can also export specific methods if you prefer:\n\nexport const { signIn, signUp, useSession } = createAuthClient()\n🎉 That's it!\n\nThat's it! You're now ready to use better-auth in your application. Continue to basic usage to learn how to use the auth instance to sign in users.\n\nEdit on GitHub\n\nPrevious Page\n\nComparison\n\nNext Page\n\nBasic Usage"
  },
  {
    "title": "Basic Usage | Better Auth",
    "url": "https://www.better-auth.com/docs/basic-usage",
    "html": "Basic Usage\nCopy Markdown\nOpen in\n\nBetter Auth provides built-in authentication support for:\n\nEmail and password\nSocial provider (Google, GitHub, Apple, and more)\n\nBut also can easily be extended using plugins, such as: username, magic link, passkey, email-otp, and more.\n\nEmail & Password\n\nTo enable email and password authentication:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    emailAndPassword: {    \n        enabled: true\n    } \n})\nSign Up\n\nTo sign up a user you need to call the client method signUp.email with the user's information.\n\nsign-up.ts\nimport { authClient } from \"@/lib/auth-client\"; //import the auth client\nconst { data, error } = await authClient.signUp.email({\n        email, // user email address\n        password, // user password -> min 8 characters by default\n        name, // user display name\n        image, // User image URL (optional)\n        callbackURL: \"/dashboard\" // A URL to redirect to after the user verifies their email (optional)\n    }, {\n        onRequest: (ctx) => {\n            //show loading\n        },\n        onSuccess: (ctx) => {\n            //redirect to the dashboard or sign in page\n        },\n        onError: (ctx) => {\n            // display the error message\n            alert(ctx.error.message);\n        },\n});\n\nBy default, the users are automatically signed in after they successfully sign up. To disable this behavior you can set autoSignIn to false.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    emailAndPassword: {\n    \tenabled: true,\n    \tautoSignIn: false //defaults to true\n  },\n})\nSign In\n\nTo sign a user in, you can use the signIn.email function provided by the client.\n\nsign-in\nconst { data, error } = await authClient.signIn.email({\n        /**\n         * The user email\n         */\n        email,\n        /**\n         * The user password\n         */\n        password,\n        /**\n         * A URL to redirect to after the user verifies their email (optional)\n         */\n        callbackURL: \"/dashboard\",\n        /**\n         * remember the user session after the browser is closed. \n         * @default true\n         */\n        rememberMe: false\n}, {\n    //callbacks\n})\n\nAlways invoke client methods from the client side. Don't call them from the server.\n\nServer-Side Authentication\n\nTo authenticate a user on the server, you can use the auth.api methods.\n\nserver.ts\nimport { auth } from \"./auth\"; // path to your Better Auth server instance\nconst response = await auth.api.signInEmail({\n    body: {\n        email,\n        password\n    },\n    asResponse: true // returns a response object instead of data\n});\n\nIf the server cannot return a response object, you'll need to manually parse and set cookies. But for frameworks like Next.js we provide a plugin to handle this automatically\n\nSocial Sign-On\n\nBetter Auth supports multiple social providers, including Google, GitHub, Apple, Discord, and more. To use a social provider, you need to configure the ones you need in the socialProviders option on your auth object.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    socialProviders: { \n        github: { \n            clientId: process.env.GITHUB_CLIENT_ID!, \n            clientSecret: process.env.GITHUB_CLIENT_SECRET!, \n        } \n    }, \n})\nSign in with social providers\n\nTo sign in using a social provider you need to call signIn.social. It takes an object with the following properties:\n\nsign-in.ts\nimport { authClient } from \"@/lib/auth-client\"; //import the auth client\nawait authClient.signIn.social({\n    /**\n     * The social provider ID\n     * @example \"github\", \"google\", \"apple\"\n     */\n    provider: \"github\",\n    /**\n     * A URL to redirect after the user authenticates with the provider\n     * @default \"/\"\n     */\n    callbackURL: \"/dashboard\", \n    /**\n     * A URL to redirect if an error occurs during the sign in process\n     */\n    errorCallbackURL: \"/error\",\n    /**\n     * A URL to redirect if the user is newly registered\n     */\n    newUserCallbackURL: \"/welcome\",\n    /**\n     * disable the automatic redirect to the provider. \n     * @default false\n     */\n    disableRedirect: true,\n});\n\nYou can also authenticate using idToken or accessToken from the social provider instead of redirecting the user to the provider's site. See social providers documentation for more details.\n\nSignout\n\nTo signout a user, you can use the signOut function provided by the client.\n\nuser-card.tsx\nawait authClient.signOut();\n\nyou can pass fetchOptions to redirect onSuccess\n\nuser-card.tsx\nawait authClient.signOut({\n  fetchOptions: {\n    onSuccess: () => {\n      router.push(\"/login\"); // redirect to login page\n    },\n  },\n});\nSession\n\nOnce a user is signed in, you'll want to access the user session. Better Auth allows you to easily access the session data from both the server and client sides.\n\nClient Side\nUse Session\n\nBetter Auth provides a useSession hook to easily access session data on the client side. This hook is implemented using nanostore and has support for each supported framework and vanilla client, ensuring that any changes to the session (such as signing out) are immediately reflected in your UI.\n\nReact\nVue\nSvelte\nSolid\nVanilla\nuser.tsx\nimport { authClient } from \"@/lib/auth-client\" // import the auth client\nexport function User(){\n    const { \n        data: session, \n        isPending, //loading state\n        error, //error object\n        refetch //refetch the session\n    } = authClient.useSession() \n    return (\n        //...\n    )\n}\nGet Session\n\nIf you prefer not to use the hook, you can use the getSession method provided by the client.\n\nuser.tsx\nimport { authClient } from \"@/lib/auth-client\" // import the auth client\nconst { data: session, error } = await authClient.getSession()\n\nYou can also use it with client-side data-fetching libraries like TanStack Query.\n\nServer Side\n\nThe server provides a session object that you can use to access the session data. It requires request headers object to be passed to the getSession method.\n\nExample: Using some popular frameworks\n\nNext.js\nNuxt\nSvelte\nAstro\nHono\nTanStack\nserver.ts\nimport { auth } from \"./auth\"; // path to your Better Auth server instance\nimport { headers } from \"next/headers\";\nconst session = await auth.api.getSession({\n    headers: await headers() // you need to pass the headers object.\n})\n\nFor more details check session-management documentation.\n\nUsing Plugins\n\nOne of the unique features of Better Auth is a plugins ecosystem. It allows you to add complex auth related functionality with small lines of code.\n\nBelow is an example of how to add two factor authentication using two factor plugin.\n\nServer Configuration\n\nTo add a plugin, you need to import the plugin and pass it to the plugins option of the auth instance. For example, to add two factor authentication, you can use the following code:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { twoFactor } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    //...rest of the options\n    plugins: [ \n        twoFactor() \n    ] \n})\n\nnow two factor related routes and method will be available on the server.\n\nMigrate Database\n\nAfter adding the plugin, you'll need to add the required tables to your database. You can do this by running the migrate command, or by using the generate command to create the schema and handle the migration manually.\n\ngenerating the schema:\n\nterminal\nnpx @better-auth/cli generate\n\nusing the migrate command:\n\nterminal\nnpx @better-auth/cli migrate\n\nIf you prefer adding the schema manually, you can check the schema required on the two factor plugin documentation.\n\nClient Configuration\n\nOnce we're done with the server, we need to add the plugin to the client. To do this, you need to import the plugin and pass it to the plugins option of the auth client. For example, to add two factor authentication, you can use the following code:\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { twoFactorClient } from \"better-auth/client/plugins\"; \nconst authClient = createAuthClient({\n    plugins: [ \n        twoFactorClient({ \n            twoFactorPage: \"/two-factor\" // the page to redirect if a user needs to verify 2nd factor\n        }) \n    ] \n})\n\nnow two factor related methods will be available on the client.\n\nprofile.ts\nimport { authClient } from \"./auth-client\"\nconst enableTwoFactor = async() => {\n    const data = await authClient.twoFactor.enable({\n        password // the user password is required\n    }) // this will enable two factor\n}\nconst disableTwoFactor = async() => {\n    const data = await authClient.twoFactor.disable({\n        password // the user password is required\n    }) // this will disable two factor\n}\nconst signInWith2Factor = async() => {\n    const data = await authClient.signIn.email({\n        //...\n    })\n    //if the user has two factor enabled, it will redirect to the two factor page\n}\nconst verifyTOTP = async() => {\n    const data = await authClient.twoFactor.verifyTOTP({\n        code: \"123456\", // the code entered by the user \n        /**\n         * If the device is trusted, the user won't\n         * need to pass 2FA again on the same device\n         */\n        trustDevice: true\n    })\n}\n\nNext step: See the two factor plugin documentation.\n\nEdit on GitHub\n\nPrevious Page\n\nInstallation\n\nNext Page\n\nAPI"
  },
  {
    "title": "Other Relational Databases | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/other-relational-databases",
    "html": "Other Relational Databases\nCopy Markdown\nOpen in\n\nBetter Auth supports a wide range of database dialects out of the box thanks to Kysely.\n\nAny dialect supported by Kysely can be utilized with Better Auth, including capabilities for generating and migrating database schemas through the CLI.\n\nCore Dialects\nMySQL\nSQLite\nPostgreSQL\nMS SQL\nKysely Organization Dialects\nPostgres.js\nSingleStore Data API\nSupabase\nKysely Community dialects\nPlanetScale Serverless Driver\nCloudflare D1\nAWS RDS Data API\nPrisma Postgres\nSurrealDB\nNeon\nXata\nAWS S3 Select\nlibSQL/sqld\nFetch driver\nSQLite WASM\nDeno SQLite\nTiDB Cloud Serverless Driver\nCapacitor SQLite Kysely\nBigQuery\nClickhouse\nPGLite\n\nYou can see the full list of supported Kysely dialects here.\n\nEdit on GitHub\n\nPrevious Page\n\nMS SQL\n\nNext Page\n\nAdapters"
  },
  {
    "title": "CLI | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/cli",
    "html": "CLI\nCopy Markdown\nOpen in\n\nBetter Auth comes with a built-in CLI to help you manage the database schemas, initialize your project, generate a secret key for your application, and gather diagnostic information about your setup.\n\nGenerate\n\nThe generate command creates the schema required by Better Auth. If you're using a database adapter like Prisma or Drizzle, this command will generate the right schema for your ORM. If you're using the built-in Kysely adapter, it will generate an SQL file you can run directly on your database.\n\nTerminal\nnpx @better-auth/cli@latest generate\nOptions\n--output - Where to save the generated schema. For Prisma, it will be saved in prisma/schema.prisma. For Drizzle, it goes to schema.ts in your project root. For Kysely, it's an SQL file saved as schema.sql in your project root.\n--config - The path to your Better Auth config file. By default, the CLI will search for an auth.ts file in ./, ./utils, ./lib, or any of these directories under the src directory.\n--yes - Skip the confirmation prompt and generate the schema directly.\nMigrate\n\nThe migrate command applies the Better Auth schema directly to your database. This is available if you're using the built-in Kysely adapter. For other adapters, you'll need to apply the schema using your ORM's migration tool.\n\nTerminal\nnpx @better-auth/cli@latest migrate\nOptions\n--config - The path to your Better Auth config file. By default, the CLI will search for an auth.ts file in ./, ./utils, ./lib, or any of these directories under the src directory.\n--yes - Skip the confirmation prompt and apply the schema directly.\n\nUsing PostgreSQL with a non-default schema?\n\nThe migrate command automatically detects your configured search_path and creates tables in the correct schema. See the PostgreSQL adapter documentation for configuration details.\n\nInit\n\nThe init command allows you to initialize Better Auth in your project.\n\nTerminal\nnpx @better-auth/cli@latest init\nOptions\n--name - The name of your application. (defaults to the name property in your package.json).\n--framework - The framework your codebase is using. Currently, the only supported framework is Next.js.\n--plugins - The plugins you want to use. You can specify multiple plugins by separating them with a comma.\n--database - The database you want to use. Currently, the only supported database is SQLite.\n--package-manager - The package manager you want to use. Currently, the only supported package managers are npm, pnpm, yarn, bun (defaults to the manager you used to initialize the CLI).\nInfo\n\nThe info command provides diagnostic information about your Better Auth setup and environment. Useful for debugging and sharing when seeking support.\n\nTerminal\nnpx @better-auth/cli@latest info\nOutput\n\nThe command displays:\n\nSystem: OS, CPU, memory, Node.js version\nPackage Manager: Detected manager and version\nBetter Auth: Version and configuration (sensitive data auto-redacted)\nFrameworks: Detected frameworks (Next.js, React, Vue, etc.)\nDatabases: Database clients and ORMs (Prisma, Drizzle, etc.)\nOptions\n--config - Path to your Better Auth config file\n--json - Output as JSON for sharing or programmatic use\nExamples\n# Basic usage\nnpx @better-auth/cli@latest info\n# Custom config path\nnpx @better-auth/cli@latest info --config ./config/auth.ts\n# JSON output\nnpx @better-auth/cli@latest info --json > auth-info.json\n\nSensitive data like secrets, API keys, and database URLs are automatically replaced with [REDACTED] for safe sharing.\n\nSecret\n\nThe CLI also provides a way to generate a secret key for your Better Auth instance.\n\nTerminal\nnpx @better-auth/cli@latest secret\nCommon Issues\n\nError: Cannot find module X\n\nIf you see this error, it means the CLI can't resolve imported modules in your Better Auth config file. We are working on a fix for many of these issues, but in the meantime, you can try the following:\n\nRemove any import aliases in your config file and use relative paths instead. After running the CLI, you can revert to using aliases.\nEdit on GitHub\n\nPrevious Page\n\nAPI\n\nNext Page\n\nClient"
  },
  {
    "title": "Database | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/database#core-schema",
    "html": "Database\nCopy Markdown\nOpen in\nAdapters\n\nBetter Auth requires a database connection to store data. The database will be used to store data such as users, sessions, and more. Plugins can also define their own database tables to store data.\n\nYou can pass a database connection to Better Auth by passing a supported database instance in the database options. You can learn more about supported database adapters in the Other relational databases documentation.\n\nCLI\n\nBetter Auth comes with a CLI tool to manage database migrations and generate schema.\n\nRunning Migrations\n\nThe cli checks your database and prompts you to add missing tables or update existing ones with new columns. This is only supported for the built-in Kysely adapter. For other adapters, you can use the generate command to create the schema and handle the migration through your ORM.\n\nnpx @better-auth/cli migrate\n\nFor PostgreSQL users: The migrate command supports non-default schemas. It automatically detects your search_path configuration and creates tables in the correct schema. See PostgreSQL adapter for details.\n\nGenerating Schema\n\nBetter Auth also provides a generate command to generate the schema required by Better Auth. The generate command creates the schema required by Better Auth. If you're using a database adapter like Prisma or Drizzle, this command will generate the right schema for your ORM. If you're using the built-in Kysely adapter, it will generate an SQL file you can run directly on your database.\n\nnpx @better-auth/cli generate\n\nSee the CLI documentation for more information on the CLI.\n\nIf you prefer adding tables manually, you can do that as well. The core schema required by Better Auth is described below and you can find additional schema required by plugins in the plugin documentation.\n\nSecondary Storage\n\nSecondary storage in Better Auth allows you to use key-value stores for managing session data, rate limiting counters, etc. This can be useful when you want to offload the storage of this intensive records to a high performance storage or even RAM.\n\nImplementation\n\nTo use secondary storage, implement the SecondaryStorage interface:\n\ninterface SecondaryStorage {\n  get: (key: string) => Promise<unknown>; \n  set: (key: string, value: string, ttl?: number) => Promise<void>;\n  delete: (key: string) => Promise<void>;\n}\n\nThen, provide your implementation to the betterAuth function:\n\nbetterAuth({\n  // ... other options\n  secondaryStorage: {\n    // Your implementation here\n  },\n});\n\nBetter Auth uses seconds for the TTL value in set(). If your storage expects milliseconds, multiply by 1000 when passing the TTL (ttl * 1000).\n\nExample: Redis Implementation\n\nHere's a basic example using Redis:\n\nimport { createClient } from \"redis\";\nimport { betterAuth } from \"better-auth\";\nconst redis = createClient();\nawait redis.connect();\nexport const auth = betterAuth({\n\t// ... other options\n\tsecondaryStorage: {\n\t\tget: async (key) => {\n\t\t\treturn await redis.get(key);\n\t\t},\n\t\tset: async (key, value, ttl) => {\n\t\t\t// TTL in seconds — convert ms with ttl * 1000.\n\t\t\tif (ttl) await redis.set(key, value, { EX: ttl });\n\t\t\t// or for ioredis:\n\t\t\t// if (ttl) await redis.set(key, value, 'EX', ttl)\n\t\t\telse await redis.set(key, value);\n\t\t},\n\t\tdelete: async (key) => {\n\t\t\tawait redis.del(key);\n\t\t}\n\t}\n});\n\nThis implementation allows Better Auth to use Redis for storing session data and rate limiting counters. You can also add prefixes to the keys names.\n\nCore Schema\n\nBetter Auth requires the following tables to be present in the database. The types are in typescript format. You can use corresponding types in your database.\n\nUser\n\nTable Name: user\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each user\nname\tstring\t-\tUser's chosen display name\nemail\tstring\t-\tUser's email address for communication and login\nemailVerified\tboolean\t-\tWhether the user's email is verified\nimage\tstring\t?\tUser's image url\ncreatedAt\tDate\t-\tTimestamp of when the user account was created\nupdatedAt\tDate\t-\tTimestamp of the last update to the user's information\nSession\n\nTable Name: session\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each session\nuserId\tstring\t\nFK\tThe ID of the user\ntoken\tstring\t-\tThe unique session token\nexpiresAt\tDate\t-\tThe time when the session expires\nipAddress\tstring\t?\tThe IP address of the device\nuserAgent\tstring\t?\tThe user agent information of the device\ncreatedAt\tDate\t-\tTimestamp of when the session was created\nupdatedAt\tDate\t-\tTimestamp of when the session was updated\nAccount\n\nTable Name: account\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each account\nuserId\tstring\t\nFK\tThe ID of the user\naccountId\tstring\t-\tThe ID of the account as provided by the SSO or equal to userId for credential accounts\nproviderId\tstring\t-\tThe ID of the provider\naccessToken\tstring\t?\tThe access token of the account. Returned by the provider\nrefreshToken\tstring\t?\tThe refresh token of the account. Returned by the provider\naccessTokenExpiresAt\tDate\t?\tThe time when the access token expires\nrefreshTokenExpiresAt\tDate\t?\tThe time when the refresh token expires\nscope\tstring\t?\tThe scope of the account. Returned by the provider\nidToken\tstring\t?\tThe ID token returned from the provider\npassword\tstring\t?\tThe password of the account. Mainly used for email and password authentication\ncreatedAt\tDate\t-\tTimestamp of when the account was created\nupdatedAt\tDate\t-\tTimestamp of when the account was updated\nVerification\n\nTable Name: verification\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each verification\nidentifier\tstring\t-\tThe identifier for the verification request\nvalue\tstring\t-\tThe value to be verified\nexpiresAt\tDate\t-\tThe time when the verification request expires\ncreatedAt\tDate\t-\tTimestamp of when the verification request was created\nupdatedAt\tDate\t-\tTimestamp of when the verification request was updated\nCustom Tables\n\nBetter Auth allows you to customize the table names and column names for the core schema. You can also extend the core schema by adding additional fields to the user and session tables.\n\nCustom Table Names\n\nYou can customize the table names and column names for the core schema by using the modelName and fields properties in your auth config:\n\nauth.ts\nexport const auth = betterAuth({\n  user: {\n    modelName: \"users\",\n    fields: {\n      name: \"full_name\",\n      email: \"email_address\",\n    },\n  },\n  session: {\n    modelName: \"user_sessions\",\n    fields: {\n      userId: \"user_id\",\n    },\n  },\n});\n\nType inference in your code will still use the original field names (e.g., user.name, not user.full_name).\n\nTo customize table names and column name for plugins, you can use the schema property in the plugin config:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { twoFactor } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  plugins: [\n    twoFactor({\n      schema: {\n        user: {\n          fields: {\n            twoFactorEnabled: \"two_factor_enabled\",\n            secret: \"two_factor_secret\",\n          },\n        },\n      },\n    }),\n  ],\n});\nExtending Core Schema\n\nBetter Auth provides a type-safe way to extend the user and session schemas. You can add custom fields to your auth config, and the CLI will automatically update the database schema. These additional fields will be properly inferred in functions like useSession, signUp.email, and other endpoints that work with user or session objects.\n\nTo add custom fields, use the additionalFields property in the user or session object of your auth config. The additionalFields object uses field names as keys, with each value being a FieldAttributes object containing:\n\ntype: The data type of the field (e.g., \"string\", \"number\", \"boolean\").\nrequired: A boolean indicating if the field is mandatory.\ndefaultValue: The default value for the field (note: this only applies in the JavaScript layer; in the database, the field will be optional).\ninput: This determines whether a value can be provided when creating a new record (default: true). If there are additional fields, like role, that should not be provided by the user during signup, you can set this to false.\n\nHere's an example of how to extend the user schema with additional fields:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  user: {\n    additionalFields: {\n      role: {\n        type: \"string\",\n        required: false,\n        defaultValue: \"user\",\n        input: false, // don't allow user to set role\n      },\n      lang: {\n        type: \"string\",\n        required: false,\n        defaultValue: \"en\",\n      },\n    },\n  },\n});\n\nNow you can access the additional fields in your application logic.\n\n//on signup\nconst res = await auth.api.signUpEmail({\n  email: \"test@example.com\",\n  password: \"password\",\n  name: \"John Doe\",\n  lang: \"fr\",\n});\n//user object\nres.user.role; // > \"admin\"\nres.user.lang; // > \"fr\"\n\nSee the TypeScript documentation for more information on how to infer additional fields on the client side.\n\nIf you're using social / OAuth providers, you may want to provide mapProfileToUser to map the profile data to the user object. So, you can populate additional fields from the provider's profile.\n\nExample: Mapping Profile to User For firstName and lastName\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  socialProviders: {\n    github: {\n      clientId: \"YOUR_GITHUB_CLIENT_ID\",\n      clientSecret: \"YOUR_GITHUB_CLIENT_SECRET\",\n      mapProfileToUser: (profile) => {\n        return {\n          firstName: profile.name.split(\" \")[0],\n          lastName: profile.name.split(\" \")[1],\n        };\n      },\n    },\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      mapProfileToUser: (profile) => {\n        return {\n          firstName: profile.given_name,\n          lastName: profile.family_name,\n        };\n      },\n    },\n  },\n});\nID Generation\n\nBetter Auth by default will generate unique IDs for users, sessions, and other entities. If you want to customize how IDs are generated, you can configure this in the advanced.database.generateId option in your auth config.\n\nYou can also disable ID generation by setting the advanced.database.generateId option to false. This will assume your database will generate the ID automatically.\n\nExample: Automatic Database IDs\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { db } from \"./db\";\nexport const auth = betterAuth({\n  database: db,\n  advanced: {\n    database: {\n      generateId: false,\n    },\n  },\n});\n\nExample: Using a Custom ID Generator\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { db } from \"./db\";\nexport const auth = betterAuth({\n  database: db,\n  advanced: {\n    database: {\n      generateId: () => crypto.randomUUID(),\n    },\n  },\n});\nNumeric IDs\n\nIf you prefer auto-incrementing numeric IDs, you can set the advanced.database.useNumberId option to true. Doing this will disable Better-Auth from generating IDs for any table, and will assume your database will generate the numeric ID automatically.\n\nWhen enabled, the Better-Auth CLI will generate or migrate the schema with the id field as a numeric type for your database with auto-incrementing attributes associated with it.\n\nimport { betterAuth } from \"better-auth\";\nimport { db } from \"./db\";\nexport const auth = betterAuth({\n  database: db,\n  advanced: {\n    database: {\n      useNumberId: true,\n    },\n  },\n});\n\nBetter-Auth will continue to infer the type of the id field as a string for the database, but will automatically convert it to a numeric type when fetching or inserting data from the database.\n\nIt's likely when grabbing id values returned from Better-Auth that you'll receive a string version of a number, this is normal. It's also expected that all id values passed to Better-Auth (eg via an endpoint body) is expected to be a string.\n\nDatabase Hooks\n\nDatabase hooks allow you to define custom logic that can be executed during the lifecycle of core database operations in Better Auth. You can create hooks for the following models: user, session, and account.\n\nAdditional fields are supported, however full type inference for these fields isn't yet supported. Improved type support is planned.\n\nThere are two types of hooks you can define:\n\n1. Before Hook\nPurpose: This hook is called before the respective entity (user, session, or account) is created or updated.\nBehavior: If the hook returns false, the operation will be aborted. And If it returns a data object, it'll replace the original payload.\n2. After Hook\nPurpose: This hook is called after the respective entity is created or updated.\nBehavior: You can perform additional actions or modifications after the entity has been successfully created or updated.\n\nExample Usage\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  databaseHooks: {\n    user: {\n      create: {\n        before: async (user, ctx) => {\n          // Modify the user object before it is created\n          return {\n            data: {\n              // Ensure to return Better-Auth named fields, not the original field names in your database.\n              ...user,\n              firstName: user.name.split(\" \")[0],\n              lastName: user.name.split(\" \")[1],\n            },\n          };\n        },\n        after: async (user) => {\n          //perform additional actions, like creating a stripe customer\n        },\n      },\n    },\n  },\n});\nThrowing Errors\n\nIf you want to stop the database hook from proceeding, you can throw errors using the APIError class imported from better-auth/api.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { APIError } from \"better-auth/api\";\nexport const auth = betterAuth({\n  databaseHooks: {\n    user: {\n      create: {\n        before: async (user, ctx) => {\n          if (user.isAgreedToTerms === false) {\n            // Your special condition.\n            // Send the API error.\n            throw new APIError(\"BAD_REQUEST\", {\n              message: \"User must agree to the TOS before signing up.\",\n            });\n          }\n          return {\n            data: user,\n          };\n        },\n      },\n    },\n  },\n});\nUsing the Context Object\n\nThe context object (ctx), passed as the second argument to the hook, contains useful information. For update hooks, this includes the current session, which you can use to access the logged-in user's details.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  databaseHooks: {\n    user: {\n      update: {\n        before: async (data, ctx) => {\n          // You can access the session from the context object.\n          if (ctx.context.session) {\n            console.log(\"User update initiated by:\", ctx.context.session.userId);\n          }\n          return { data };\n        },\n      },\n    },\n  },\n});\n\nMuch like standard hooks, database hooks also provide a ctx object that offers a variety of useful properties. Learn more in the Hooks Documentation.\n\nPlugins Schema\n\nPlugins can define their own tables in the database to store additional data. They can also add columns to the core tables to store additional data. For example, the two factor authentication plugin adds the following columns to the user table:\n\ntwoFactorEnabled: Whether two factor authentication is enabled for the user.\ntwoFactorSecret: The secret key used to generate TOTP codes.\ntwoFactorBackupCodes: Encrypted backup codes for account recovery.\n\nTo add new tables and columns to your database, you have two options:\n\nCLI: Use the migrate or generate command. These commands will scan your database and guide you through adding any missing tables or columns. Manual Method: Follow the instructions in the plugin documentation to manually add tables and columns.\n\nBoth methods ensure your database schema stays up to date with your plugins' requirements.\n\nEdit on GitHub\n\nPrevious Page\n\nCookies\n\nNext Page\n\nEmail"
  },
  {
    "title": "Next.js Example | Better Auth",
    "url": "https://www.better-auth.com/docs/examples/next-js",
    "html": "Next.js Example\nCopy Markdown\nOpen in\n\nThis is an example of how to use Better Auth with Next.\n\nImplements the following features: Email & Password . Social Sign-in . Passkeys . Email Verification . Password Reset . Two Factor Authentication . Profile Update . Session Management . Organization, Members and Roles\n\nSee Demo\n\nOpen in Stackblitz\nView on GitHub\nHow to run\nClone the code sandbox (or the repo) and open it in your code editor\nMove .env.example to .env and provide necessary variables\nRun the following commands\npnpm install\npnpm dev\nOpen the browser and navigate to http://localhost:3000\nSSO Login Example\n\nFor this example, we utilize DummyIDP. Initiate the login from the DummyIDP login, click \"Proceed\", and from here it will direct you to user's dashboard.\n\nEdit on GitHub\n\nPrevious Page\n\nRemix\n\nNext Page\n\nNuxt"
  },
  {
    "title": "Passkey | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/passkey",
    "html": "Passkey\nCopy Markdown\nOpen in\n\nPasskeys are a secure, passwordless authentication method using cryptographic key pairs, supported by WebAuthn and FIDO2 standards in web browsers. They replace passwords with unique key pairs: a private key stored on the user's device and a public key shared with the website. Users can log in using biometrics, PINs, or security keys, providing strong, phishing-resistant authentication without traditional passwords.\n\nThe passkey plugin implementation is powered by SimpleWebAuthn behind the scenes.\n\nInstallation\nAdd the plugin to your auth config\n\nTo add the passkey plugin to your auth config, you need to import the plugin and pass it to the plugins option of the auth instance.\n\nOptions\n\nrpID: A unique identifier for your website. 'localhost' is okay for local dev\n\nrpName: Human-readable title for your website\n\norigin: The URL at which registrations and authentications should occur. http://localhost and http://localhost:PORT are also valid. Do NOT include any trailing /\n\nauthenticatorSelection: Allows customization of WebAuthn authenticator selection criteria. Leave unspecified for default settings.\n\nauthenticatorAttachment: Specifies the type of authenticator\nplatform: Authenticator is attached to the platform (e.g., fingerprint reader)\ncross-platform: Authenticator is not attached to the platform (e.g., security key)\nDefault: not set (both platform and cross-platform allowed, with platform preferred)\nresidentKey: Determines credential storage behavior.\nrequired: User MUST store credentials on the authenticator (highest security)\npreferred: Encourages credential storage but not mandatory\ndiscouraged: No credential storage required (fastest experience)\nDefault: preferred\nuserVerification: Controls biometric/PIN verification during authentication:\nrequired: User MUST verify identity (highest security)\npreferred: Verification encouraged but not mandatory\ndiscouraged: No verification required (fastest experience)\nDefault: preferred\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { passkey } from \"better-auth/plugins/passkey\"\nexport const auth = betterAuth({\n    plugins: [ \n        passkey(), \n    ], \n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { passkeyClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [ \n        passkeyClient() \n    ] \n})\nUsage\nAdd/Register a passkey\n\nTo add or register a passkey make sure a user is authenticated and then call the passkey.addPasskey function provided by the client.\n\nClient\nServer\nPOST\n/passkey/add-passkey\nconst { data, error } = await authClient.passkey.addPasskey({\n    name: \"example-passkey-name\",\n    authenticatorAttachment: \"cross-platform\",\n});\nProp\tDescription\tType\nname?\t\nAn optional name to label the authenticator account being registered. If not provided, it will default to the user's email address or user ID\n\tstring\nauthenticatorAttachment?\t\nYou can also specify the type of authenticator you want to register. Default behavior allows both platform and cross-platform passkeys\n\t\"platform\" | \"cross-platform\"\n\nSetting throw: true in the fetch options has no effect for the register and sign-in passkey responses — they will always return a data object containing the error object.\n\nSign in with a passkey\n\nTo sign in with a passkey you can use the signIn.passkey method. This will prompt the user to sign in with their passkey.\n\nClient\nServer\nPOST\n/sign-in/passkey\nconst { data, error } = await authClient.signIn.passkey({\n    autoFill: true,\n});\nProp\tDescription\tType\nautoFill?\t\nBrowser autofill, a.k.a. Conditional UI. Read more: https://simplewebauthn.dev/docs/packages/browser#browser-autofill-aka-conditional-ui\n\tboolean\nExample Usage\n// With post authentication redirect\nawait authClient.signIn.passkey({\n    autoFill: true,\n    fetchOptions: {\n        onSuccess(context) {\n            // Redirect to dashboard after successful authentication\n            window.location.href = \"/dashboard\";\n        },\n        onError(context) {\n            // Handle authentication errors\n            console.error(\"Authentication failed:\", context.error.message);\n        }\n    }\n});\nList passkeys\n\nYou can list all of the passkeys for the authenticated user by calling passkey.listUserPasskeys:\n\nClient\nServer\nGET\n/passkey/list-user-passkeys\nconst { data: passkeys, error } = await authClient.passkey.listUserPasskeys();\nDeleting passkeys\n\nYou can delete a passkey by calling passkey.delete and providing the passkey ID.\n\nClient\nServer\nPOST\n/passkey/delete-passkey\nconst { data, error } = await authClient.passkey.deletePasskey({\n    id: \"some-passkey-id\", // required\n});\nProp\tDescription\tType\nid\t\nThe ID of the passkey to delete.\n\tstring\nUpdating passkey names\nClient\nServer\nPOST\n/passkey/update-passkey\nconst { data, error } = await authClient.passkey.updatePasskey({\n    id: \"id of passkey\", // required\n    name: \"my-new-passkey-name\", // required\n});\nProp\tDescription\tType\nid\t\nThe ID of the passkey which you want to update.\n\tstring\nname\t\nThe new name which the passkey will be updated to.\n\tstring\nConditional UI\n\nThe plugin supports conditional UI, which allows the browser to autofill the passkey if the user has already registered a passkey.\n\nThere are two requirements for conditional UI to work:\n\nUpdate input fields\n\nAdd the autocomplete attribute with the value webauthn to your input fields. You can add this attribute to multiple input fields, but at least one is required for conditional UI to work.\n\nThe webauthn value should also be the last entry of the autocomplete attribute.\n\n<label for=\"name\">Username:</label>\n<input type=\"text\" name=\"name\" autocomplete=\"username webauthn\">\n<label for=\"password\">Password:</label>\n<input type=\"password\" name=\"password\" autocomplete=\"current-password webauthn\">\nPreload the passkeys\n\nWhen your component mounts, you can preload the user's passkeys by calling the authClient.signIn.passkey method with the autoFill option set to true.\n\nTo prevent unnecessary calls, we will also add a check to see if the browser supports conditional UI.\n\nReact\nuseEffect(() => {\n   if (!PublicKeyCredential.isConditionalMediationAvailable ||\n       !PublicKeyCredential.isConditionalMediationAvailable()) {\n     return;\n   }\n  void authClient.signIn.passkey({ autoFill: true })\n}, [])\n\nDepending on the browser, a prompt will appear to autofill the passkey. If the user has multiple passkeys, they can select the one they want to use.\n\nSome browsers also require the user to first interact with the input field before the autofill prompt appears.\n\nDebugging\n\nTo test your passkey implementation you can use emulated authenticators. This way you can test the registration and sign-in process without even owning a physical device.\n\nSchema\n\nThe plugin require a new table in the database to store passkey data.\n\nTable Name: passkey\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each passkey\nname\tstring\t?\tThe name of the passkey\npublicKey\tstring\t-\tThe public key of the passkey\nuserId\tstring\t\nFK\tThe ID of the user\ncredentialID\tstring\t-\tThe unique identifier of the registered credential\ncounter\tnumber\t-\tThe counter of the passkey\ndeviceType\tstring\t-\tThe type of device used to register the passkey\nbackedUp\tboolean\t-\tWhether the passkey is backed up\ntransports\tstring\t-\tThe transports used to register the passkey\ncreatedAt\tDate\t-\tThe time when the passkey was created\naaguid\tstring\t?\tAuthenticator's Attestation GUID indicating the type of the authenticator\nOptions\n\nrpID: A unique identifier for your website. 'localhost' is okay for local dev.\n\nrpName: Human-readable title for your website.\n\norigin: The URL at which registrations and authentications should occur. http://localhost and http://localhost:PORT are also valid. Do NOT include any trailing /.\n\nauthenticatorSelection: Allows customization of WebAuthn authenticator selection criteria. When unspecified, both platform and cross-platform authenticators are allowed with preferred settings for residentKey and userVerification.\n\naaguid: (optional) Authenticator Attestation GUID. This is a unique identifier for the passkey provider (device or authenticator type) and can be used to identify the type of passkey device used during registration or authentication.\n\nEdit on GitHub\n\nPrevious Page\n\nEmail OTP\n\nNext Page\n\nGeneric OAuth"
  },
  {
    "title": "Magic link | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/magic-link",
    "html": "Magic link\nCopy Markdown\nOpen in\n\nMagic link or email link is a way to authenticate users without a password. When a user enters their email, a link is sent to their email. When the user clicks on the link, they are authenticated.\n\nInstallation\nAdd the server Plugin\n\nAdd the magic link plugin to your server:\n\nserver.ts\nimport { betterAuth } from \"better-auth\";\nimport { magicLink } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [\n        magicLink({\n            sendMagicLink: async ({ email, token, url }, request) => {\n                // send email to user\n            }\n        })\n    ]\n})\nAdd the client Plugin\n\nAdd the magic link plugin to your client:\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { magicLinkClient } from \"better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n    plugins: [\n        magicLinkClient()\n    ]\n});\nUsage\nSign In with Magic Link\n\nTo sign in with a magic link, you need to call signIn.magicLink with the user's email address. The sendMagicLink function is called to send the magic link to the user's email.\n\nClient\nServer\nPOST\n/sign-in/magic-link\nconst { data, error } = await authClient.signIn.magicLink({\n    email: \"user@email.com\", // required\n    name: \"my-name\",\n    callbackURL: \"/dashboard\",\n    newUserCallbackURL: \"/welcome\",\n    errorCallbackURL: \"/error\",\n});\nProp\tDescription\tType\nemail\t\nEmail address to send the magic link.\n\tstring\nname?\t\nUser display name. Only used if the user is registering for the first time.\n\tstring\ncallbackURL?\t\nURL to redirect after magic link verification.\n\tstring\nnewUserCallbackURL?\t\nURL to redirect after new user signup\n\tstring\nerrorCallbackURL?\t\nURL to redirect if an error happen on verification If only callbackURL is provided but without an errorCallbackURL then they will be redirected to the callbackURL with an error query parameter.\n\tstring\n\nIf the user has not signed up, unless disableSignUp is set to true, the user will be signed up automatically.\n\nVerify Magic Link\n\nWhen you send the URL generated by the sendMagicLink function to a user, clicking the link will authenticate them and redirect them to the callbackURL specified in the signIn.magicLink function. If an error occurs, the user will be redirected to the callbackURL with an error query parameter.\n\nIf no callbackURL is provided, the user will be redirected to the root URL.\n\nIf you want to handle the verification manually, (e.g, if you send the user a different URL), you can use the verify function.\n\nClient\nServer\nGET\n/magic-link/verify\nconst { data, error } = await authClient.magicLink.verify({\n    query: {\n        token: \"123456\", // required\n        callbackURL: \"/dashboard\",\n    },\n});\nProp\tDescription\tType\ntoken\t\nVerification token.\n\tstring\ncallbackURL?\t\nURL to redirect after magic link verification, if not provided will return the session.\n\tstring\nConfiguration Options\n\nsendMagicLink: The sendMagicLink function is called when a user requests a magic link. It takes an object with the following properties:\n\nemail: The email address of the user.\nurl: The URL to be sent to the user. This URL contains the token.\ntoken: The token if you want to send the token with custom URL.\n\nand a request object as the second parameter.\n\nexpiresIn: specifies the time in seconds after which the magic link will expire. The default value is 300 seconds (5 minutes).\n\ndisableSignUp: If set to true, the user will not be able to sign up using the magic link. The default value is false.\n\ngenerateToken: The generateToken function is called to generate a token which is used to uniquely identify the user. The default value is a random string. There is one parameter:\n\nemail: The email address of the user.\n\nWhen using generateToken, ensure that the returned string is hard to guess because it is used to verify who someone actually is in a confidential way. By default, we return a long and cryptographically secure string.\n\nstoreToken: The storeToken function is called to store the magic link token in the database. The default value is \"plain\".\n\nThe storeToken function can be one of the following:\n\n\"plain\": The token is stored in plain text.\n\"hashed\": The token is hashed using the default hasher.\n{ type: \"custom-hasher\", hash: (token: string) => Promise<string> }: The token is hashed using a custom hasher.\nEdit on GitHub\n\nPrevious Page\n\nPhone Number\n\nNext Page\n\nEmail OTP"
  },
  {
    "title": "Username | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/username",
    "html": "Username\nCopy Markdown\nOpen in\n\nThe username plugin is a lightweight plugin that adds username support to the email and password authenticator. This allows users to sign in and sign up with their username instead of their email.\n\nInstallation\nAdd Plugin to the server\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [ \n        username() \n    ] \n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { usernameClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [ \n        usernameClient() \n    ] \n})\nUsage\nSign up\n\nTo sign up a user with username, you can use the existing signUp.email function provided by the client. The signUp function should take a new username property in the object.\n\nClient\nServer\nPOST\n/sign-up/email\nconst { data, error } = await authClient.signUp.email({\n    email: \"email@domain.com\", // required\n    name: \"Test User\", // required\n    password: \"password1234\", // required\n    username: \"test\", // required\n    displayUsername: \"Test User123\",\n});\nProp\tDescription\tType\nemail\t\nThe email of the user.\n\tstring\nname\t\nThe name of the user.\n\tstring\npassword\t\nThe password of the user.\n\tstring\nusername\t\nThe username of the user.\n\tstring\ndisplayUsername?\t\nAn optional display username of the user.\n\tstring\n\nIf only username is provided, the displayUsername will be set to the pre normalized version of the username. You can see the Username Normalization and Display Username Normalization sections for more details.\n\nSign in\n\nTo sign in a user with username, you can use the signIn.username function provided by the client.\n\nClient\nServer\nPOST\n/sign-in/username\nconst { data, error } = await authClient.signIn.username({\n    username: \"test\", // required\n    password: \"password1234\", // required\n});\nProp\tDescription\tType\nusername\t\nThe username of the user.\n\tstring\npassword\t\nThe password of the user.\n\tstring\nUpdate username\n\nTo update the username of a user, you can use the updateUser function provided by the client.\n\nClient\nServer\nPOST\n/update-user\nconst { data, error } = await authClient.updateUser({\n    username: \"new-username\",\n});\nProp\tDescription\tType\nusername?\t\nThe username to update.\n\tstring\nCheck if username is available\n\nTo check if a username is available, you can use the isUsernameAvailable function provided by the client.\n\nClient\nServer\nPOST\n/is-username-available\nconst { data: response, error } = await authClient.isUsernameAvailable({\n    username: \"new-username\", // required\n});\nif(response?.available) {\n    console.log(\"Username is available\");\n} else {\n    console.log(\"Username is not available\");\n}\nProp\tDescription\tType\nusername\t\nThe username to check.\n\tstring\nOptions\nMin Username Length\n\nThe minimum length of the username. Default is 3.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [\n        username({\n            minUsernameLength: 5\n        })\n    ]\n})\nMax Username Length\n\nThe maximum length of the username. Default is 30.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [\n        username({\n            maxUsernameLength: 100\n        })\n    ]\n})\nUsername Validator\n\nA function that validates the username. The function should return false if the username is invalid. By default, the username should only contain alphanumeric characters, underscores, and dots.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [\n        username({\n            usernameValidator: (username) => {\n                if (username === \"admin\") {\n                    return false\n                }\n                return true\n            }\n        })\n    ]\n})\nDisplay Username Validator\n\nA function that validates the display username. The function should return false if the display username is invalid. By default, no validation is applied to display username.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [\n        username({\n            displayUsernameValidator: (displayUsername) => {\n                // Allow only alphanumeric characters, underscores, and hyphens\n                return /^[a-zA-Z0-9_-]+$/.test(displayUsername)\n            }\n        })\n    ]\n})\nUsername Normalization\n\nA function that normalizes the username, or false if you want to disable normalization.\n\nBy default, usernames are normalized to lowercase, so \"TestUser\" and \"testuser\", for example, are considered the same username. The username field will contain the normalized (lower case) username, while displayUsername will contain the original username.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [\n        username({\n            usernameNormalization: (username) => {\n                return username.toLowerCase()\n                    .replaceAll(\"0\", \"o\")\n                    .replaceAll(\"3\", \"e\")\n                    .replaceAll(\"4\", \"a\");\n            }\n        })\n    ]\n})\nDisplay Username Normalization\n\nA function that normalizes the display username, or false to disable normalization.\n\nBy default, display usernames are not normalized. When only username is provided during signup or update, the displayUsername will be set to match the original username value (before normalization). You can also explicitly set a displayUsername which will be preserved as-is. For custom normalization, provide a function that takes the display username as input and returns the normalized version.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [\n        username({\n            displayUsernameNormalization: (displayUsername) => displayUsername.toLowerCase(),\n        })\n    ]   \n})\nValidation Order\n\nBy default, username and display username are validated before normalization. You can change this behavior by setting validationOrder to post-normalization.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { username } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [\n        username({\n            validationOrder: {\n                username: \"post-normalization\",\n                displayUsername: \"post-normalization\",\n            }\n        })\n    ]\n})\nSchema\n\nThe plugin requires 2 fields to be added to the user table:\n\nField Name\tType\tKey\tDescription\nusername\tstring\t-\tThe username of the user\ndisplayUsername\tstring\t-\tNon normalized username of the user\nEdit on GitHub\n\nPrevious Page\n\nTwo Factor\n\nNext Page\n\nAnonymous"
  },
  {
    "title": "Better Auth Fastify Integration Guide | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/fastify",
    "html": "Better Auth Fastify Integration Guide\nCopy Markdown\nOpen in\n\nThis guide provides step-by-step instructions for configuring both essential handlers and CORS settings.\n\nA configured Better Auth instance is required before proceeding. If you haven't set this up yet, please consult our Installation Guide.\n\nPrerequisites\n\nVerify the following requirements before integration:\n\nNode.js Environment: v16 or later installed\nES Module Support: Enable ES modules in either:\npackage.json: { \"type\": \"module\" }\nTypeScript tsconfig.json: { \"module\": \"ESNext\" }\nFastify Dependencies:\nnpm\npnpm\nyarn\nbun\nnpm install fastify @fastify/cors\nFor TypeScript: Ensure your tsconfig.json includes \"esModuleInterop\": true for optimal compatibility.\nAuthentication Handler Setup\n\nConfigure Better Auth to process authentication requests by creating a catch-all route:\n\nserver.ts\nimport Fastify from \"fastify\";\nimport { auth } from \"./auth\"; // Your configured Better Auth instance\nconst fastify = Fastify({ logger: true });\n// Register authentication endpoint\nfastify.route({\n  method: [\"GET\", \"POST\"],\n  url: \"/api/auth/*\",\n  async handler(request, reply) {\n    try {\n      // Construct request URL\n      const url = new URL(request.url, `http://${request.headers.host}`);\n      \n      // Convert Fastify headers to standard Headers object\n      const headers = new Headers();\n      Object.entries(request.headers).forEach(([key, value]) => {\n        if (value) headers.append(key, value.toString());\n      });\n      // Create Fetch API-compatible request\n      const req = new Request(url.toString(), {\n        method: request.method,\n        headers,\n        body: request.body ? JSON.stringify(request.body) : undefined,\n      });\n      // Process authentication request\n      const response = await auth.handler(req);\n      // Forward response to client\n      reply.status(response.status);\n      response.headers.forEach((value, key) => reply.header(key, value));\n      reply.send(response.body ? await response.text() : null);\n    } catch (error) {\n      fastify.log.error(\"Authentication Error:\", error);\n      reply.status(500).send({ \n        error: \"Internal authentication error\",\n        code: \"AUTH_FAILURE\"\n      });\n    }\n  }\n});\n// Initialize server\nfastify.listen({ port: 4000 }, (err) => {\n  if (err) {\n    fastify.log.error(err);\n    process.exit(1);\n  }\n  console.log(\"Server running on port 4000\");\n});\nTrusted origins\n\nWhen a request is made from a different origin, the request will be blocked by default. You can add trusted origins to the auth instance.\n\nexport const auth = betterAuth({\n  trustedOrigins: [\"http://localhost:3000\", \"https://example.com\"],\n});\nConfiguring CORS\n\nSecure your API endpoints with proper CORS configuration:\n\nimport fastifyCors from \"@fastify/cors\";\n// Configure CORS policies\nfastify.register(fastifyCors, {\n  origin: process.env.CLIENT_ORIGIN || \"http://localhost:3000\",\n  methods: [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n  allowedHeaders: [\n    \"Content-Type\",\n    \"Authorization\",\n    \"X-Requested-With\"\n  ],\n  credentials: true,\n  maxAge: 86400\n});\n// Mount authentication handler after CORS registration\n// (Use previous handler configuration here)\nAlways restrict CORS origins in production environments. Use environment variables for dynamic configuration.\nEdit on GitHub\n\nPrevious Page\n\nHono\n\nNext Page\n\nExpress"
  },
  {
    "title": "Email OTP | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/email-otp",
    "html": "Email OTP\nCopy Markdown\nOpen in\n\nThe Email OTP plugin allows user to sign in, verify their email, or reset their password using a one-time password (OTP) sent to their email address.\n\nInstallation\nAdd the plugin to your auth config\n\nAdd the emailOTP plugin to your auth config and implement the sendVerificationOTP() method.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { emailOTP } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    // ... other config options\n    plugins: [\n        emailOTP({ \n            async sendVerificationOTP({ email, otp, type }) { \n                if (type === \"sign-in\") { \n                    // Send the OTP for sign in\n                } else if (type === \"email-verification\") { \n                    // Send the OTP for email verification\n                } else { \n                    // Send the OTP for password reset\n                } \n            }, \n        }) \n    ]\n})\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { emailOTPClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        emailOTPClient()\n    ]\n})\nUsage\nSend an OTP\n\nUse the sendVerificationOtp() method to send an OTP to the user's email address.\n\nClient\nServer\nPOST\n/email-otp/send-verification-otp\nconst { data, error } = await authClient.emailOtp.sendVerificationOtp({\n    email: \"user@example.com\", // required\n    type: \"sign-in\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to send the OTP.\n\tstring\ntype\t\nType of the OTP. sign-in, email-verification, or forget-password.\n\t\"email-verification\" | \"sign-in\" | \"forget-password\"\nCheck an OTP (optional)\n\nUse the checkVerificationOtp() method to check if an OTP is valid.\n\nClient\nServer\nPOST\n/email-otp/check-verification-otp\nconst { data, error } = await authClient.emailOtp.checkVerificationOtp({\n    email: \"user@example.com\", // required\n    type: \"sign-in\", // required\n    otp: \"123456\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to send the OTP.\n\tstring\ntype\t\nType of the OTP. sign-in, email-verification, or forget-password.\n\t\"email-verification\" | \"sign-in\" | \"forget-password\"\notp\t\nOTP sent to the email.\n\tstring\nSign In with OTP\n\nTo sign in with OTP, use the sendVerificationOtp() method to send a \"sign-in\" OTP to the user's email address.\n\nClient\nServer\nPOST\n/email-otp/send-verification-otp\nconst { data, error } = await authClient.emailOtp.sendVerificationOtp({\n    email: \"user@example.com\", // required\n    type: \"sign-in\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to send the OTP.\n\tstring\ntype\t\nType of the OTP.\n\t\"sign-in\"\n\nOnce the user provides the OTP, you can sign in the user using the signIn.emailOtp() method.\n\nClient\nServer\nPOST\n/sign-in/email-otp\nconst { data, error } = await authClient.signIn.emailOtp({\n    email: \"user@example.com\", // required\n    otp: \"123456\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to sign in.\n\tstring\notp\t\nOTP sent to the email.\n\tstring\n\nIf the user is not registered, they'll be automatically registered. If you want to prevent this, you can pass disableSignUp as true in the options.\n\nVerify Email with OTP\n\nTo verify the user's email address with OTP, use the sendVerificationOtp() method to send an \"email-verification\" OTP to the user's email address.\n\nClient\nServer\nPOST\n/email-otp/send-verification-otp\nconst { data, error } = await authClient.emailOtp.sendVerificationOtp({\n    email: \"user@example.com\", // required\n    type: \"email-verification\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to send the OTP.\n\tstring\ntype\t\nType of the OTP.\n\t\"email-verification\"\n\nOnce the user provides the OTP, use the verifyEmail() method to complete email verification.\n\nClient\nServer\nPOST\n/email-otp/verify-email\nconst { data, error } = await authClient.emailOtp.verifyEmail({\n    email: \"user@example.com\", // required\n    otp: \"123456\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to verify.\n\tstring\notp\t\nOTP to verify.\n\tstring\nReset Password with OTP\n\nTo reset the user's password with OTP, use the forgetPassword.emailOTP() method to send a \"forget-password\" OTP to the user's email address.\n\nClient\nServer\nPOST\n/forget-password/email-otp\nconst { data, error } = await authClient.forgetPassword.emailOtp({\n    email: \"user@example.com\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to send the OTP.\n\tstring\n\nOnce the user provides the OTP, use the checkVerificationOtp() method to check if it's valid (optional).\n\nClient\nServer\nPOST\n/email-otp/check-verification-otp\nconst { data, error } = await authClient.emailOtp.checkVerificationOtp({\n    email: \"user@example.com\", // required\n    type: \"forget-password\", // required\n    otp: \"123456\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to send the OTP.\n\tstring\ntype\t\nType of the OTP.\n\t\"forget-password\"\notp\t\nOTP sent to the email.\n\tstring\n\nThen, use the resetPassword() method to reset the user's password.\n\nClient\nServer\nPOST\n/email-otp/reset-password\nconst { data, error } = await authClient.emailOtp.resetPassword({\n    email: \"user@example.com\", // required\n    otp: \"123456\", // required\n    password: \"new-secure-password\", // required\n});\nProp\tDescription\tType\nemail\t\nEmail address to reset the password.\n\tstring\notp\t\nOTP sent to the email.\n\tstring\npassword\t\nNew password.\n\tstring\nOverride Default Email Verification\n\nTo override the default email verification, pass overrideDefaultEmailVerification: true in the options. This will make the system use an email OTP instead of the default verification link whenever email verification is triggered. In other words, the user will verify their email using an OTP rather than clicking a link.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  plugins: [\n    emailOTP({\n      overrideDefaultEmailVerification: true, \n      async sendVerificationOTP({ email, otp, type }) {\n        // Implement the sendVerificationOTP method to send the OTP to the user's email address\n      },\n    }),\n  ],\n});\nOptions\n\nsendVerificationOTP: A function that sends the OTP to the user's email address. The function receives an object with the following properties:\n\nemail: The user's email address.\notp: The OTP to send.\ntype: The type of OTP to send. Can be \"sign-in\", \"email-verification\", or \"forget-password\".\n\notpLength: The length of the OTP. Defaults to 6.\n\nexpiresIn: The expiry time of the OTP in seconds. Defaults to 300 seconds.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    plugins: [\n        emailOTP({\n            otpLength: 8,\n            expiresIn: 600\n        })\n    ]\n})\n\nsendVerificationOnSignUp: A boolean value that determines whether to send the OTP when a user signs up. Defaults to false.\n\ndisableSignUp: A boolean value that determines whether to prevent automatic sign-up when the user is not registered. Defaults to false.\n\ngenerateOTP: A function that generates the OTP. Defaults to a random 6-digit number.\n\nallowedAttempts: The maximum number of attempts allowed for verifying an OTP. Defaults to 3. After exceeding this limit, the OTP becomes invalid and the user needs to request a new one.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    plugins: [\n        emailOTP({\n            allowedAttempts: 5, // Allow 5 attempts before invalidating the OTP\n            expiresIn: 300\n        })\n    ]\n})\n\nWhen the maximum attempts are exceeded, the verifyOTP, signIn.emailOtp, verifyEmail, and resetPassword methods will return an error with code TOO_MANY_ATTEMPTS.\n\nstoreOTP: The method to store the OTP in your database, whether encrypted, hashed or plain text. Default is plain text.\n\nNote: This will not affect the OTP sent to the user, it will only affect the OTP stored in your database.\n\nAlternatively, you can pass a custom encryptor or hasher to store the OTP in your database.\n\nCustom encryptor\n\nauth.ts\nemailOTP({\n    storeOTP: { \n        encrypt: async (otp) => {\n            return myCustomEncryptor(otp);\n        },\n        decrypt: async (otp) => {\n            return myCustomDecryptor(otp);\n        },\n    }\n})\n\nCustom hasher\n\nauth.ts\nemailOTP({\n    storeOTP: {\n        hash: async (otp) => {\n            return myCustomHasher(otp);\n        },\n    }\n})\nEdit on GitHub\n\nPrevious Page\n\nMagic Link\n\nNext Page\n\nPasskey"
  },
  {
    "title": "Next.js integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/next#server-action-cookies",
    "html": "Next.js integration\nCopy Markdown\nOpen in\n\nBetter Auth can be easily integrated with Next.js. Before you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nCreate API Route\n\nWe need to mount the handler to an API route. Create a route file inside /api/auth/[...all] directory. And add the following code:\n\napi/auth/[...all]/route.ts\nimport { auth } from \"@/lib/auth\";\nimport { toNextJsHandler } from \"better-auth/next-js\";\nexport const { GET, POST } = toNextJsHandler(auth.handler);\n\nYou can change the path on your better-auth configuration but it's recommended to keep it as /api/auth/[...all]\n\nFor pages route, you need to use toNodeHandler instead of toNextJsHandler and set bodyParser to false in the config object. Here is an example:\n\npages/api/auth/[...all].ts\nimport { toNodeHandler } from \"better-auth/node\"\nimport { auth } from \"@/lib/auth\"\n// Disallow body parsing, we will parse it manually\nexport const config = { api: { bodyParser: false } }\nexport default toNodeHandler(auth.handler)\nCreate a client\n\nCreate a client instance. You can name the file anything you want. Here we are creating client.ts file inside the lib/ directory.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/react\" // make sure to import from better-auth/react\nexport const authClient =  createAuthClient({\n    //you can pass client configuration here\n})\n\nOnce you have created the client, you can use it to sign up, sign in, and perform other actions. Some of the actions are reactive. The client uses nano-store to store the state and re-render the components when the state changes.\n\nThe client also uses better-fetch to make the requests. You can pass the fetch configuration to the client.\n\nRSC and Server actions\n\nThe api object exported from the auth instance contains all the actions that you can perform on the server. Every endpoint made inside Better Auth is a invocable as a function. Including plugins endpoints.\n\nExample: Getting Session on a server action\n\nserver.ts\nimport { auth } from \"@/lib/auth\"\nimport { headers } from \"next/headers\"\nconst someAuthenticatedAction = async () => {\n    \"use server\";\n    const session = await auth.api.getSession({\n        headers: await headers()\n    })\n};\n\nExample: Getting Session on a RSC\n\nimport { auth } from \"@/lib/auth\"\nimport { headers } from \"next/headers\"\nexport async function ServerComponent() {\n    const session = await auth.api.getSession({\n        headers: await headers()\n    })\n    if(!session) {\n        return <div>Not authenticated</div>\n    }\n    return (\n        <div>\n            <h1>Welcome {session.user.name}</h1>\n        </div>\n    )\n}\nAs RSCs cannot set cookies, the cookie cache will not be refreshed until the server is interacted with from the client via Server Actions or Route Handlers.\nServer Action Cookies\n\nWhen you call a function that needs to set cookies, like signInEmail or signUpEmail in a server action, cookies won’t be set. This is because server actions need to use the cookies helper from Next.js to set cookies.\n\nTo simplify this, you can use the nextCookies plugin, which will automatically set cookies for you whenever a Set-Cookie header is present in the response.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { nextCookies } from \"better-auth/next-js\";\nexport const auth = betterAuth({\n    //...your config\n    plugins: [nextCookies()] // make sure this is the last plugin in the array\n})\n\nNow, when you call functions that set cookies, they will be automatically set.\n\n\"use server\";\nimport { auth } from \"@/lib/auth\"\nconst signIn = async () => {\n    await auth.api.signInEmail({\n        body: {\n            email: \"user@email.com\",\n            password: \"password\",\n        }\n    })\n}\nMiddleware\n\nIn Next.js middleware, it's recommended to only check for the existence of a session cookie to handle redirection. To avoid blocking requests by making API or database calls.\n\nYou can use the getSessionCookie helper from Better Auth for this purpose:\n\nThe getSessionCookie() function does not automatically reference the auth config specified in auth.ts. Therefore, if you customized the cookie name or prefix, you need to ensure that the configuration in getSessionCookie() matches the config defined in your auth.ts.\n\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { getSessionCookie } from \"better-auth/cookies\";\nexport async function middleware(request: NextRequest) {\n\tconst sessionCookie = getSessionCookie(request);\n    // THIS IS NOT SECURE!\n    // This is the recommended approach to optimistically redirect users\n    // We recommend handling auth checks in each page/route\n\tif (!sessionCookie) {\n\t\treturn NextResponse.redirect(new URL(\"/\", request.url));\n\t}\n\treturn NextResponse.next();\n}\nexport const config = {\n\tmatcher: [\"/dashboard\"], // Specify the routes the middleware applies to\n};\n\nSecurity Warning: The getSessionCookie function only checks for the existence of a session cookie; it does not validate it. Relying solely on this check for security is dangerous, as anyone can manually create a cookie to bypass it. You must always validate the session on your server for any protected actions or pages.\n\nIf you have a custom cookie name or prefix, you can pass it to the getSessionCookie function.\n\nconst sessionCookie = getSessionCookie(request, {\n    cookieName: \"my_session_cookie\",\n    cookiePrefix: \"my_prefix\"\n});\n\nAlternatively, you can use the getCookieCache helper to get the session object from the cookie cache.\n\nimport { getCookieCache } from \"better-auth/cookies\";\nexport async function middleware(request: NextRequest) {\n\tconst session = await getCookieCache(request);\n\tif (!session) {\n\t\treturn NextResponse.redirect(new URL(\"/sign-in\", request.url));\n\t}\n\treturn NextResponse.next();\n}\nHow to handle auth checks in each page/route\n\nIn this example, we are using the auth.api.getSession function within a server component to get the session object, then we are checking if the session is valid. If it's not, we are redirecting the user to the sign-in page.\n\napp/dashboard/page.tsx\nimport { auth } from \"@/lib/auth\";\nimport { headers } from \"next/headers\";\nimport { redirect } from \"next/navigation\";\nexport default async function DashboardPage() {\n    const session = await auth.api.getSession({\n        headers: await headers()\n    })\n    if(!session) {\n        redirect(\"/sign-in\")\n    }\n    return (\n        <div>\n            <h1>Welcome {session.user.name}</h1>\n        </div>\n    )\n}\nFor Next.js release 15.1.7 and below\n\nIf you need the full session object, you'll have to fetch it from the /get-session API route. Since Next.js middleware doesn't support running Node.js APIs directly, you must make an HTTP request.\n\nThe example uses better-fetch, but you can use any fetch library.\n\nimport { betterFetch } from \"@better-fetch/fetch\";\nimport type { auth } from \"@/lib/auth\";\nimport { NextRequest, NextResponse } from \"next/server\";\ntype Session = typeof auth.$Infer.Session;\nexport async function middleware(request: NextRequest) {\n\tconst { data: session } = await betterFetch<Session>(\"/api/auth/get-session\", {\n\t\tbaseURL: request.nextUrl.origin,\n\t\theaders: {\n\t\t\tcookie: request.headers.get(\"cookie\") || \"\", // Forward the cookies from the request\n\t\t},\n\t});\n\tif (!session) {\n\t\treturn NextResponse.redirect(new URL(\"/sign-in\", request.url));\n\t}\n\treturn NextResponse.next();\n}\nexport const config = {\n\tmatcher: [\"/dashboard\"], // Apply middleware to specific routes\n};\nFor Next.js release 15.2.0 and above\n\nFrom the version 15.2.0, Next.js allows you to use the Node.js runtime in middleware. This means you can use the auth.api object directly in middleware.\n\nYou may refer to the Next.js documentation for more information about runtime configuration, and how to enable it. Be careful when using the new runtime. It's an experimental feature and it may be subject to breaking changes.\n\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { headers } from \"next/headers\";\nimport { auth } from \"@/lib/auth\";\nexport async function middleware(request: NextRequest) {\n    const session = await auth.api.getSession({\n        headers: await headers()\n    })\n    if(!session) {\n        return NextResponse.redirect(new URL(\"/sign-in\", request.url));\n    }\n    return NextResponse.next();\n}\nexport const config = {\n  runtime: \"nodejs\",\n  matcher: [\"/dashboard\"], // Apply middleware to specific routes\n};\nEdit on GitHub\n\nPrevious Page\n\nRemix\n\nNext Page\n\nNuxt"
  },
  {
    "title": "Session Management | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/session-management",
    "html": "Session Management\nCopy Markdown\nOpen in\n\nBetter Auth manages session using a traditional cookie-based session management. The session is stored in a cookie and is sent to the server on every request. The server then verifies the session and returns the user data if the session is valid.\n\nSession table\n\nThe session table stores the session data. The session table has the following fields:\n\nid: The session token. Which is also used as the session cookie.\nuserId: The user ID of the user.\nexpiresAt: The expiration date of the session.\nipAddress: The IP address of the user.\nuserAgent: The user agent of the user. It stores the user agent header from the request.\nSession Expiration\n\nThe session expires after 7 days by default. But whenever the session is used and the updateAge is reached, the session expiration is updated to the current time plus the expiresIn value.\n\nYou can change both the expiresIn and updateAge values by passing the session object to the auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    //... other config options\n    session: {\n        expiresIn: 60 * 60 * 24 * 7, // 7 days\n        updateAge: 60 * 60 * 24 // 1 day (every 1 day the session expiration is updated)\n    }\n})\nDisable Session Refresh\n\nYou can disable session refresh so that the session is not updated regardless of the updateAge option.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    //... other config options\n    session: {\n        disableSessionRefresh: true\n    }\n})\nSession Freshness\n\nSome endpoints in Better Auth require the session to be fresh. A session is considered fresh if its createdAt is within the freshAge limit. By default, the freshAge is set to 1 day (60 * 60 * 24).\n\nYou can customize the freshAge value by passing a session object in the auth configuration:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    //... other config options\n    session: {\n        freshAge: 60 * 5 // 5 minutes (the session is fresh if created within the last 5 minutes)\n    }\n})\n\nTo disable the freshness check, set freshAge to 0:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    //... other config options\n    session: {\n        freshAge: 0 // Disable freshness check\n    }\n})\nSession Management\n\nBetter Auth provides a set of functions to manage sessions.\n\nGet Session\n\nThe getSession function retrieves the current active session.\n\nimport { authClient } from \"@/lib/client\"\nconst { data: session } = await authClient.getSession()\n\nTo learn how to customize the session response check the Customizing Session Response section.\n\nUse Session\n\nThe useSession action provides a reactive way to access the current session.\n\nimport { authClient } from \"@/lib/client\"\nconst { data: session } = authClient.useSession()\nList Sessions\n\nThe listSessions function returns a list of sessions that are active for the user.\n\nauth-client.ts\nimport { authClient } from \"@/lib/client\"\nconst sessions = await authClient.listSessions()\nRevoke Session\n\nWhen a user signs out of a device, the session is automatically ended. However, you can also end a session manually from any device the user is signed into.\n\nTo end a session, use the revokeSession function. Just pass the session token as a parameter.\n\nauth-client.ts\nawait authClient.revokeSession({\n    token: \"session-token\"\n})\nRevoke Other Sessions\n\nTo revoke all other sessions except the current session, you can use the revokeOtherSessions function.\n\nauth-client.ts\nawait authClient.revokeOtherSessions()\nRevoke All Sessions\n\nTo revoke all sessions, you can use the revokeSessions function.\n\nauth-client.ts\nawait authClient.revokeSessions()\nRevoking Sessions on Password Change\n\nYou can revoke all sessions when the user changes their password by passing revokeOtherSessions as true on changePassword function.\n\nauth.ts\nawait authClient.changePassword({\n    newPassword: newPassword,\n    currentPassword: currentPassword,\n    revokeOtherSessions: true,\n})\nSession Caching\nCookie Cache\n\nCalling your database every time useSession or getSession invoked isn’t ideal, especially if sessions don’t change frequently. Cookie caching handles this by storing session data in a short-lived, signed cookie—similar to how JWT access tokens are used with refresh tokens.\n\nWhen cookie caching is enabled, the server can check session validity from the cookie itself instead of hitting the database each time. The cookie is signed to prevent tampering, and a short maxAge ensures that the session data gets refreshed regularly. If a session is revoked or expires, the cookie will be invalidated automatically.\n\nTo turn on cookie caching, just set session.cookieCache in your auth config:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    session: {\n        cookieCache: {\n            enabled: true,\n            maxAge: 5 * 60 // Cache duration in seconds\n        }\n    }\n});\n\nIf you want to disable returning from the cookie cache when fetching the session, you can pass disableCookieCache:true this will force the server to fetch the session from the database and also refresh the cookie cache.\n\nauth-client.ts\nconst session = await authClient.getSession({ query: {\n    disableCookieCache: true\n}})\n\nor on the server\n\nserver.ts\nawait auth.api.getSession({\n    query: {\n        disableCookieCache: true,\n    }, \n    headers: req.headers, // pass the headers\n});\nCustomizing Session Response\n\nWhen you call getSession or useSession, the session data is returned as a user and session object. You can customize this response using the customSession plugin.\n\nauth.ts\nimport { customSession } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [\n        customSession(async ({ user, session }) => {\n            const roles = findUserRoles(session.session.userId);\n            return {\n                roles,\n                user: {\n                    ...user,\n                    newField: \"newField\",\n                },\n                session\n            };\n        }),\n    ],\n});\n\nThis will add roles and user.newField to the session response.\n\nInfer on the Client\n\nauth-client.ts\nimport { customSessionClient } from \"better-auth/client/plugins\";\nimport type { auth } from \"@/lib/auth\"; // Import the auth instance as a type\nconst authClient = createAuthClient({\n    plugins: [customSessionClient<typeof auth>()],\n});\nconst { data } = authClient.useSession();\nconst { data: sessionData } = await authClient.getSession();\n// data.roles\n// data.user.newField\nCaveats on Customizing Session Response\nThe passed session object to the callback does not infer fields added by plugins.\n\nHowever, as a workaround, you can pull up your auth options and pass it to the plugin to infer the fields.\n\nimport { betterAuth, BetterAuthOptions } from \"better-auth\";\nconst options = {\n  //...config options\n  plugins: [\n    //...plugins \n  ]\n} satisfies BetterAuthOptions;\nexport const auth = betterAuth({\n    ...options,\n    plugins: [\n        ...(options.plugins ?? []),\n        customSession(async ({ user, session }, ctx) => {\n            // now both user and session will infer the fields added by plugins and your custom fields\n            return {\n                user,\n                session\n            }\n        }, options), // pass options here\n    ]\n})\nWhen your server and client code are in separate projects or repositories, and you cannot import the auth instance as a type reference, type inference for custom session fields will not work on the client side.\nSession caching, including secondary storage or cookie cache, does not include custom fields. Each time the session is fetched, your custom session function will be called.\n\nMutating the list-device-sessions endpoint The /multi-session/list-device-sessions endpoint from the multi-session plugin is used to list the devices that the user is signed into.\n\nYou can mutate the response of this endpoint by passing the shouldMutateListDeviceSessionsEndpoint option to the customSession plugin.\n\nBy default, we do not mutate the response of this endpoint.\n\nauth.ts\nimport { customSession } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [\n        customSession(async ({ user, session }, ctx) => {\n            return {\n                user,\n                session\n            }\n        }, {}, { shouldMutateListDeviceSessionsEndpoint: true }), \n    ],\n});\nEdit on GitHub\n\nPrevious Page\n\nRate Limit\n\nNext Page\n\nTypeScript"
  },
  {
    "title": "Two-Factor Authentication (2FA) | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/2fa#schema",
    "html": "Two-Factor Authentication (2FA)\nCopy Markdown\nOpen in\n\nOTP TOTP Backup Codes Trusted Devices\n\nTwo-Factor Authentication (2FA) adds an extra security step when users log in. Instead of just using a password, they'll need to provide a second form of verification. This makes it much harder for unauthorized people to access accounts, even if they've somehow gotten the password.\n\nThis plugin offers two main methods to do a second factor verification:\n\nOTP (One-Time Password): A temporary code sent to the user's email or phone.\nTOTP (Time-based One-Time Password): A code generated by an app on the user's device.\n\nAdditional features include:\n\nGenerating backup codes for account recovery\nEnabling/disabling 2FA\nManaging trusted devices\nInstallation\nAdd the plugin to your auth config\n\nAdd the two-factor plugin to your auth configuration and specify your app name as the issuer.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { twoFactor } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    // ... other config options\n    appName: \"My App\", // provide your app name. It'll be used as an issuer.\n    plugins: [\n        twoFactor() \n    ]\n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\n\nAdd the client plugin and Specify where the user should be redirected if they need to verify 2nd factor\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { twoFactorClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        twoFactorClient()\n    ]\n})\nUsage\nEnabling 2FA\n\nTo enable two-factor authentication, call twoFactor.enable with the user's password and issuer (optional):\n\nClient\nServer\nPOST\n/two-factor/enable\nconst { data, error } = await authClient.twoFactor.enable({\n    password: \"secure-password\", // required\n    issuer: \"my-app-name\",\n});\nProp\tDescription\tType\npassword\t\nThe user's password\n\tstring\nissuer?\t\nAn optional custom issuer for the TOTP URI. Defaults to app-name defined in your auth config.\n\tstring\n\nWhen 2FA is enabled:\n\nAn encrypted secret and backupCodes are generated.\nenable returns totpURI and backupCodes.\n\nNote: twoFactorEnabled won’t be set to true until the user verifies their TOTP code. Learn more about verifying TOTP here. You can skip verification by setting skipVerificationOnEnable to true in your plugin config.\n\nTwo Factor can only be enabled for credential accounts at the moment. For social accounts, it's assumed the provider already handles 2FA.\n\nSign In with 2FA\n\nWhen a user with 2FA enabled tries to sign in via email, the response object will contain twoFactorRedirect set to true. This indicates that the user needs to verify their 2FA code.\n\nYou can handle this in the onSuccess callback or by providing a onTwoFactorRedirect callback in the plugin config.\n\nsign-in.tsx\nawait authClient.signIn.email({\n        email: \"user@example.com\",\n        password: \"password123\",\n    },\n    {\n        async onSuccess(context) {\n            if (context.data.twoFactorRedirect) {\n                // Handle the 2FA verification in place\n            }\n        },\n    }\n)\n\nUsing the onTwoFactorRedirect config:\n\nsign-in.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { twoFactorClient } from \"better-auth/client/plugins\";\nconst authClient = createAuthClient({\n    plugins: [\n        twoFactorClient({\n            onTwoFactorRedirect(){\n                // Handle the 2FA verification globally\n            },\n        }),\n    ],\n});\n\nWith auth.api\n\nWhen you call auth.api.signInEmail on the server, and the user has 2FA enabled, it will return an object where twoFactorRedirect is set to true. This behavior isn’t inferred in TypeScript, which can be misleading. You can check using in instead to check if twoFactorRedirect is set to true.\n\nconst response = await auth.api.signInEmail({\n\tbody: {\n\t\temail: \"test@test.com\",\n\t\tpassword: \"test\",\n\t},\n});\nif (\"twoFactorRedirect\" in response) {\n\t// Handle the 2FA verification in place\n}\nDisabling 2FA\n\nTo disable two-factor authentication, call twoFactor.disable with the user's password:\n\nClient\nServer\nPOST\n/two-factor/disable\nconst { data, error } = await authClient.twoFactor.disable({\n    password, // required\n});\nProp\tDescription\tType\npassword\t\nThe user's password\n\tstring\nTOTP\n\nTOTP (Time-Based One-Time Password) is an algorithm that generates a unique password for each login attempt using time as a counter. Every fixed interval (Better Auth defaults to 30 seconds), a new password is generated. This addresses several issues with traditional passwords: they can be forgotten, stolen, or guessed. OTPs solve some of these problems, but their delivery via SMS or email can be unreliable (or even risky, considering it opens new attack vectors).\n\nTOTP, however, generates codes offline, making it both secure and convenient. You just need an authenticator app on your phone.\n\nGetting TOTP URI\n\nAfter enabling 2FA, you can get the TOTP URI to display to the user. This URI is generated by the server using the secret and issuer and can be used to generate a QR code for the user to scan with their authenticator app.\n\nClient\nServer\nPOST\n/two-factor/get-totp-uri\nconst { data, error } = await authClient.twoFactor.getTotpUri({\n    password, // required\n});\nProp\tDescription\tType\npassword\t\nThe user's password\n\tstring\n\nExample: Using React\n\nOnce you have the TOTP URI, you can use it to generate a QR code for the user to scan with their authenticator app.\n\nuser-card.tsx\nimport QRCode from \"react-qr-code\";\nexport default function UserCard({ password }: { password: string }){\n    const { data: session } = client.useSession();\n\tconst { data: qr } = useQuery({\n\t\tqueryKey: [\"two-factor-qr\"],\n\t\tqueryFn: async () => {\n\t\t\tconst res = await authClient.twoFactor.getTotpUri({ password });\n\t\t\treturn res.data;\n\t\t},\n\t\tenabled: !!session?.user.twoFactorEnabled,\n\t});\n    return (\n        <QRCode value={qr?.totpURI || \"\"} />\n   )\n}\n\nBy default the issuer for TOTP is set to the app name provided in the auth config or if not provided it will be set to Better Auth. You can override this by passing issuer to the plugin config.\n\nVerifying TOTP\n\nAfter the user has entered their 2FA code, you can verify it using twoFactor.verifyTotp method. Better Auth follows standard practice by accepting TOTP codes from one period before and one after the current code, ensuring users can authenticate even with minor time delays on their end.\n\nClient\nServer\nPOST\n/two-factor/verify-totp\nconst { data, error } = await authClient.twoFactor.verifyTotp({\n    code: \"012345\", // required\n    trustDevice: true,\n});\nProp\tDescription\tType\ncode\t\nThe otp code to verify.\n\tstring\ntrustDevice?\t\nIf true, the device will be trusted for 30 days. It'll be refreshed on every sign in request within this time.\n\tboolean\nOTP\n\nOTP (One-Time Password) is similar to TOTP but a random code is generated and sent to the user's email or phone.\n\nBefore using OTP to verify the second factor, you need to configure sendOTP in your Better Auth instance. This function is responsible for sending the OTP to the user's email, phone, or any other method supported by your application.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { twoFactor } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [\n        twoFactor({\n          \totpOptions: {\n\t\t\t\tasync sendOTP({ user, otp }, request) {\n                    // send otp to user\n\t\t\t\t},\n\t\t\t},\n        })\n    ]\n})\nSending OTP\n\nSending an OTP is done by calling the twoFactor.sendOtp function. This function will trigger your sendOTP implementation that you provided in the Better Auth configuration.\n\nClient\nServer\nPOST\n/two-factor/send-otp\nconst { data, error } = await authClient.twoFactor.sendOtp({\n    trustDevice: true,\n});\nif (data) {\n    // redirect or show the user to enter the code\n}\nProp\tDescription\tType\ntrustDevice?\t\nIf true, the device will be trusted for 30 days. It'll be refreshed on every sign in request within this time.\n\tboolean\nVerifying OTP\n\nAfter the user has entered their OTP code, you can verify it\n\nClient\nServer\nPOST\n/two-factor/verify-otp\nconst { data, error } = await authClient.twoFactor.verifyOtp({\n    code: \"012345\", // required\n    trustDevice: true,\n});\nProp\tDescription\tType\ncode\t\nThe otp code to verify.\n\tstring\ntrustDevice?\t\nIf true, the device will be trusted for 30 days. It'll be refreshed on every sign in request within this time.\n\tboolean\nBackup Codes\n\nBackup codes are generated and stored in the database. This can be used to recover access to the account if the user loses access to their phone or email.\n\nGenerating Backup Codes\n\nGenerate backup codes for account recovery:\n\nClient\nServer\nPOST\n/two-factor/generate-backup-codes\nconst { data, error } = await authClient.twoFactor.generateBackupCodes({\n    password, // required\n});\nif (data) {\n    // Show the backup codes to the user\n}\nProp\tDescription\tType\npassword\t\nThe users password.\n\tstring\n\nWhen you generate backup codes, the old backup codes will be deleted and new ones will be generated.\n\nUsing Backup Codes\n\nYou can now allow users to provider backup code as account recover method.\n\nClient\nServer\nPOST\n/two-factor/verify-backup-code\nconst { data, error } = await authClient.twoFactor.verifyBackupCode({\n    code: \"123456\", // required\n    disableSession: false,\n    trustDevice: true,\n});\nProp\tDescription\tType\ncode\t\nA backup code to verify.\n\tstring\ndisableSession?\t\nIf true, the session cookie will not be set.\n\tboolean\ntrustDevice?\t\nIf true, the device will be trusted for 30 days. It'll be refreshed on every sign in request within this time.\n\tboolean\n\nOnce a backup code is used, it will be removed from the database and can't be used again.\n\nViewing Backup Codes\n\nTo display the backup codes to the user, you can call viewBackupCodes on the server. This will return the backup codes in the response. You should only this if the user has a fresh session - a session that was just created.\n\nClient\nServer\nGET\n/two-factor/view-backup-codes\nconst data = await auth.api.viewBackupCodes({\n    body: {\n        userId: \"user-id\",\n    },\n});\nProp\tDescription\tType\nuserId?\t\nThe user ID to view all backup codes.\n\tstring | null\nTrusted Devices\n\nYou can mark a device as trusted by passing trustDevice to verifyTotp or verifyOtp.\n\nconst verify2FA = async (code: string) => {\n    const { data, error } = await authClient.twoFactor.verifyTotp({\n        code,\n        callbackURL: \"/dashboard\",\n        trustDevice: true // Mark this device as trusted\n    })\n    if (data) {\n        // 2FA verified and device trusted\n    }\n}\n\nWhen trustDevice is set to true, the current device will be remembered for 60 days. During this period, the user won't be prompted for 2FA on subsequent sign-ins from this device. The trust period is refreshed each time the user signs in successfully.\n\nIssuer\n\nBy adding an issuer you can set your application name for the 2fa application.\n\nFor example, if your user uses Google Auth, the default appName will show up as Better Auth. However, by using the following code, it will show up as my-app-name.\n\ntwoFactor({\n    issuer: \"my-app-name\"\n})\nSchema\n\nThe plugin requires 1 additional fields in the user table and 1 additional table to store the two factor authentication data.\n\nTable: user\n\nField Name\tType\tKey\tDescription\ntwoFactorEnabled\tboolean\t?\tWhether two factor authentication is enabled for the user.\n\nTable: twoFactor\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tThe ID of the two factor authentication.\nuserId\tstring\t\nFK\tThe ID of the user\nsecret\tstring\t?\tThe secret used to generate the TOTP code.\nbackupCodes\tstring\t?\tThe backup codes used to recover access to the account if the user loses access to their phone or email.\nOptions\nServer\n\ntwoFactorTable: The name of the table that stores the two factor authentication data. Default: twoFactor.\n\nskipVerificationOnEnable: Skip the verification process before enabling two factor for a user.\n\nIssuer: The issuer is the name of your application. It's used to generate TOTP codes. It'll be displayed in the authenticator apps.\n\nTOTP options\n\nthese are options for TOTP.\n\nProp\n\nType\n\ndigits?\nnumber\nperiod?\nnumber\n\nOTP options\n\nthese are options for OTP.\n\nProp\n\nType\n\nsendOTP?\nfunction\nperiod?\nnumber\nstoreOTP?\nstring\n\nBackup Code Options\n\nbackup codes are generated and stored in the database when the user enabled two factor authentication. This can be used to recover access to the account if the user loses access to their phone or email.\n\nProp\n\nType\n\namount?\nnumber\nlength?\nnumber\ncustomBackupCodesGenerate?\nfunction\nstoreBackupCodes?\nstring\nClient\n\nTo use the two factor plugin in the client, you need to add it on your plugins list.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { twoFactorClient } from \"better-auth/client/plugins\"\nconst authClient =  createAuthClient({\n    plugins: [\n        twoFactorClient({ \n            onTwoFactorRedirect(){ \n                window.location.href = \"/2fa\" // Handle the 2FA verification redirect\n            } \n        }) \n    ]\n})\n\nOptions\n\nonTwoFactorRedirect: A callback that will be called when the user needs to verify their 2FA code. This can be used to redirect the user to the 2FA page.\n\nEdit on GitHub\n\nPrevious Page\n\nAuthentication\n\nNext Page\n\nUsername"
  },
  {
    "title": "API | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/api",
    "html": "API\nCopy Markdown\nOpen in\n\nWhen you create a new Better Auth instance, it provides you with an api object. This object exposes every endpoint that exists in your Better Auth instance. And you can use this to interact with Better Auth server side.\n\nAny endpoint added to Better Auth, whether from plugins or the core, will be accessible through the api object.\n\nCalling API Endpoints on the Server\n\nTo call an API endpoint on the server, import your auth instance and call the endpoint using the api object.\n\nserver.ts\nimport { betterAuth } from \"better-auth\";\nimport { headers } from \"next/headers\";\nexport const auth = betterAuth({\n    //...\n})\n// calling get session on the server\nawait auth.api.getSession({\n    headers: await headers() // some endpoints might require headers\n})\nBody, Headers, Query\n\nUnlike the client, the server needs the values to be passed as an object with the key body for the body, headers for the headers, and query for query parameters.\n\nserver.ts\nawait auth.api.getSession({\n    headers: await headers()\n})\nawait auth.api.signInEmail({\n    body: {\n        email: \"john@doe.com\",\n        password: \"password\"\n    },\n    headers: await headers() // optional but would be useful to get the user IP, user agent, etc.\n})\nawait auth.api.verifyEmail({\n    query: {\n        token: \"my_token\"\n    }\n})\n\nBetter Auth API endpoints are built on top of better-call, a tiny web framework that lets you call REST API endpoints as if they were regular functions and allows us to easily infer client types from the server.\n\nGetting headers and Response Object\n\nWhen you invoke an API endpoint on the server, it will return a standard JavaScript object or array directly as it's just a regular function call.\n\nBut there are times when you might want to get the headers or the Response object instead. For example, if you need to get the cookies or the headers.\n\nGetting headers\n\nTo get the headers, you can pass the returnHeaders option to the endpoint.\n\nconst { headers, response } = await auth.api.signUpEmail({\n\treturnHeaders: true,\n\tbody: {\n\t\temail: \"john@doe.com\",\n\t\tpassword: \"password\",\n\t\tname: \"John Doe\",\n\t},\n});\n\nThe headers will be a Headers object, which you can use to get the cookies or the headers.\n\nconst cookies = headers.get(\"set-cookie\");\nconst headers = headers.get(\"x-custom-header\");\nGetting Response Object\n\nTo get the Response object, you can pass the asResponse option to the endpoint.\n\nserver.ts\nconst response = await auth.api.signInEmail({\n    body: {\n        email: \"\",\n        password: \"\"\n    },\n    asResponse: true\n})\nError Handling\n\nWhen you call an API endpoint on the server, it will throw an error if the request fails. You can catch the error and handle it as you see fit. The error instance is an instance of APIError.\n\nserver.ts\nimport { APIError } from \"better-auth/api\";\ntry {\n    await auth.api.signInEmail({\n        body: {\n            email: \"\",\n            password: \"\"\n        }\n    })\n} catch (error) {\n    if (error instanceof APIError) {\n        console.log(error.message, error.status)\n    }\n}\nEdit on GitHub\n\nPrevious Page\n\nBasic Usage\n\nNext Page\n\nCLI"
  },
  {
    "title": "SQLite | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/sqlite",
    "html": "SQLite\nCopy Markdown\nOpen in\n\nSQLite is a lightweight, serverless, self-contained SQL database engine that is widely used for local data storage in applications. Read more here.\n\nExample Usage\n\nBetter Auth supports multiple SQLite drivers. Choose the one that best fits your environment:\n\nBetter-SQLite3 (Recommended)\n\nThe most popular and stable SQLite driver for Node.js:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport Database from \"better-sqlite3\";\nexport const auth = betterAuth({\n  database: new Database(\"database.sqlite\"),\n});\n\nFor more information, read Kysely's documentation to the SqliteDialect.\n\nNode.js Built-in SQLite (Experimental)\n\nThe node:sqlite module is still experimental and may change at any time. It requires Node.js 22.5.0 or later.\n\nStarting from Node.js 22.5.0, you can use the built-in SQLite module:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { DatabaseSync } from \"node:sqlite\";\nexport const auth = betterAuth({\n  database: new DatabaseSync(\"database.sqlite\"),\n});\n\nTo run your application with Node.js SQLite:\n\nnode your-app.js\nBun Built-in SQLite\n\nYou can also use the built-in SQLite module in Bun, which is similar to the Node.js version:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { Database } from \"bun:sqlite\";\nexport const auth = betterAuth({\n  database: new Database(\"database.sqlite\"),\n});\nSchema generation & migration\n\nThe Better Auth CLI allows you to generate or migrate your database schema based on your Better Auth configuration and plugins.\n\nSQLite Schema Generation\n\n\t\n\nSQLite Schema Migration\n\n\n✅ Supported\t✅ Supported\nSchema Generation\nnpx @better-auth/cli@latest generate\nSchema Migration\nnpx @better-auth/cli@latest migrate\nAdditional Information\n\nSQLite is supported under the hood via the Kysely adapter, any database supported by Kysely would also be supported. (Read more here)\n\nIf you're looking for performance improvements or tips, take a look at our guide to performance optimizations.\n\nEdit on GitHub\n\nPrevious Page\n\nMySQL\n\nNext Page\n\nPostgreSQL"
  },
  {
    "title": "MySQL | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/mysql",
    "html": "MySQL\nCopy Markdown\nOpen in\n\nMySQL is a popular open-source relational database management system (RDBMS) that is widely used for building web applications and other types of software. It provides a flexible and scalable database solution that allows for efficient storage and retrieval of data. Read more here: MySQL.\n\nExample Usage\n\nMake sure you have MySQL installed and configured. Then, you can connect it straight into Better Auth.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { createPool } from \"mysql2/promise\";\nexport const auth = betterAuth({\n  database: createPool({\n    host: \"localhost\",\n    user: \"root\",\n    password: \"password\",\n    database: \"database\",\n    timezone: \"Z\", // Important to ensure consistent timezone values\n  }),\n});\n\nFor more information, read Kysely's documentation to the MySQLDialect.\n\nSchema generation & migration\n\nThe Better Auth CLI allows you to generate or migrate your database schema based on your Better Auth configuration and plugins.\n\nMySQL Schema Generation\n\n\t\n\nMySQL Schema Migration\n\n\n✅ Supported\t✅ Supported\nSchema Generation\nnpx @better-auth/cli@latest generate\nSchema Migration\nnpx @better-auth/cli@latest migrate\nAdditional Information\n\nMySQL is supported under the hood via the Kysely adapter, any database supported by Kysely would also be supported. (Read more here)\n\nIf you're looking for performance improvements or tips, take a look at our guide to performance optimizations.\n\nEdit on GitHub\n\nPrevious Page\n\nOther Social Providers\n\nNext Page\n\nSQLite"
  },
  {
    "title": "MS SQL | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/mssql",
    "html": "MS SQL\nCopy Markdown\nOpen in\n\nMicrosoft SQL Server is a relational database management system developed by Microsoft, designed for enterprise-level data storage, management, and analytics with robust security and scalability features. Read more here.\n\nExample Usage\n\nMake sure you have MS SQL installed and configured. Then, you can connect it straight into Better Auth.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { MssqlDialect } from \"kysely\";\nimport * as Tedious from 'tedious'\nimport * as Tarn from 'tarn'\nconst dialect = new MssqlDialect({\n  tarn: {\n    ...Tarn,\n    options: {\n      min: 0,\n      max: 10,\n    },\n  },\n  tedious: {\n    ...Tedious,\n    connectionFactory: () => new Tedious.Connection({\n      authentication: {\n        options: {\n          password: 'password',\n          userName: 'username',\n        },\n        type: 'default',\n      },\n      options: {\n        database: 'some_db',\n        port: 1433,\n        trustServerCertificate: true,\n      },\n      server: 'localhost',\n    }),\n  },\n  TYPES: {\n\t\t...Tedious.TYPES,\n\t\tDateTime: Tedious.TYPES.DateTime2,\n\t},\n})\nexport const auth = betterAuth({\n  database: {\n    dialect,\n    type: \"mssql\"\n  }\n});\n\nFor more information, read Kysely's documentation to the MssqlDialect.\n\nSchema generation & migration\n\nThe Better Auth CLI allows you to generate or migrate your database schema based on your Better Auth configuration and plugins.\n\nMS SQL Schema Generation\n\n\t\n\nMS SQL Schema Migration\n\n\n✅ Supported\t✅ Supported\nSchema Generation\nnpx @better-auth/cli@latest generate\nSchema Migration\nnpx @better-auth/cli@latest migrate\nAdditional Information\n\nMS SQL is supported under the hood via the Kysely adapter, any database supported by Kysely would also be supported. (Read more here)\n\nIf you're looking for performance improvements or tips, take a look at our guide to performance optimizations.\n\nEdit on GitHub\n\nPrevious Page\n\nPostgreSQL\n\nNext Page\n\nOther Relational Databases"
  },
  {
    "title": "PostgreSQL | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/postgresql",
    "html": "PostgreSQL\nCopy Markdown\nOpen in\n\nPostgreSQL is a powerful, open-source relational database management system known for its advanced features, extensibility, and support for complex queries and large datasets. Read more here.\n\nExample Usage\n\nMake sure you have PostgreSQL installed and configured. Then, you can connect it straight into Better Auth.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { Pool } from \"pg\";\nexport const auth = betterAuth({\n  database: new Pool({\n    connectionString: \"postgres://user:password@localhost:5432/database\",\n  }),\n});\n\nFor more information, read Kysely's documentation to the PostgresDialect.\n\nSchema generation & migration\n\nThe Better Auth CLI allows you to generate or migrate your database schema based on your Better Auth configuration and plugins.\n\nPostgreSQL Schema Generation\n\n\t\n\nPostgreSQL Schema Migration\n\n\n✅ Supported\t✅ Supported\nSchema Generation\nnpx @better-auth/cli@latest generate\nSchema Migration\nnpx @better-auth/cli@latest migrate\nUse a non-default schema\n\nIn most cases, the default schema is public. To have Better Auth use a non-default schema (e.g., auth) for its tables, you have several options:\n\nOption 1: Set search_path in connection string (Recommended)\n\nAppend the options parameter to your connection URI:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { Pool } from \"pg\";\nexport const auth = betterAuth({\n  database: new Pool({\n    connectionString: \"postgres://user:password@localhost:5432/database?options=-c search_path=auth\",\n  }),\n});\n\nURL-encode if needed: ?options=-c%20search_path%3Dauth.\n\nOption 2: Set search_path using Pool options\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { Pool } from \"pg\";\nexport const auth = betterAuth({\n  database: new Pool({\n    host: \"localhost\",\n    port: 5432,\n    user: \"postgres\",\n    password: \"password\",\n    database: \"mydb\",\n    options: \"-c search_path=auth\",\n  }),\n});\nOption 3: Set default schema for database user\n\nSet the PostgreSQL user's default schema:\n\nALTER USER your_user SET search_path TO auth;\n\nAfter setting this, reconnect to apply the changes.\n\nPrerequisites\n\nBefore using a non-default schema, ensure:\n\nThe schema exists:\n\nCREATE SCHEMA IF NOT EXISTS auth;\n\nThe user has appropriate permissions:\n\nGRANT ALL PRIVILEGES ON SCHEMA auth TO your_user;\nGRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA auth TO your_user;\nALTER DEFAULT PRIVILEGES IN SCHEMA auth GRANT ALL ON TABLES TO your_user;\nHow it works\n\nThe Better Auth CLI migration system automatically detects your configured search_path:\n\nWhen running npx @better-auth/cli migrate, it inspects only the tables in your configured schema\nTables in other schemas (e.g., public) are ignored, preventing conflicts\nAll new tables are created in your specified schema\nTroubleshooting\n\nIssue: \"relation does not exist\" error during migration\n\nSolution: This usually means the schema doesn't exist or the user lacks permissions. Create the schema and grant permissions as shown above.\n\nVerifying your schema configuration:\n\nYou can verify which schema Better Auth will use by checking the search_path:\n\nSHOW search_path;\n\nThis should return your custom schema (e.g., auth) as the first value.\n\nAdditional Information\n\nPostgreSQL is supported under the hood via the Kysely adapter, any database supported by Kysely would also be supported. (Read more here)\n\nIf you're looking for performance improvements or tips, take a look at our guide to performance optimizations.\n\nEdit on GitHub\n\nPrevious Page\n\nSQLite\n\nNext Page\n\nMS SQL"
  },
  {
    "title": "Drizzle ORM Adapter | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/drizzle",
    "html": "Drizzle ORM Adapter\nCopy Markdown\nOpen in\n\nDrizzle ORM is a powerful and flexible ORM for Node.js and TypeScript. It provides a simple and intuitive API for working with databases, and supports a wide range of databases including MySQL, PostgreSQL, SQLite, and more. Read more here: Drizzle ORM.\n\nExample Usage\n\nMake sure you have Drizzle installed and configured. Then, you can use the Drizzle adapter to connect to your database.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { drizzleAdapter } from \"better-auth/adapters/drizzle\";\nimport { db } from \"./database.ts\";\nexport const auth = betterAuth({\n  database: drizzleAdapter(db, {\n    provider: \"sqlite\", // or \"pg\" or \"mysql\"\n  }), \n  //... the rest of your config\n});\nSchema generation & migration\n\nThe Better Auth CLI allows you to generate or migrate your database schema based on your Better Auth configuration and plugins.\n\nTo generate the schema required by Better Auth, run the following command:\n\nSchema Generation\nnpx @better-auth/cli@latest generate\n\nTo generate and apply the migration, run the following commands:\n\nSchema Migration\nnpx drizzle-kit generate # generate the migration file\nnpx drizzle-kit migrate # apply the migration\nAdditional Information\n\nThe Drizzle adapter expects the schema you define to match the table names. For example, if your Drizzle schema maps the user table to users, you need to manually pass the schema and map it to the user table.\n\nimport { betterAuth } from \"better-auth\";\nimport { db } from \"./drizzle\";\nimport { drizzleAdapter } from \"better-auth/adapters/drizzle\";\nimport { schema } from \"./schema\";\nexport const auth = betterAuth({\n  database: drizzleAdapter(db, {\n    provider: \"sqlite\", // or \"pg\" or \"mysql\"\n    schema: {\n      ...schema,\n      user: schema.users,\n    },\n  }),\n});\n\nIf all your tables are using plural form, you can just pass the usePlural option:\n\nexport const auth = betterAuth({\n  database: drizzleAdapter(db, {\n    ...\n    usePlural: true,\n  }),\n});\n\nIf you're looking for performance improvements or tips, take a look at our guide to performance optimizations.\n\nEdit on GitHub\n\nPrevious Page\n\nAdapters\n\nNext Page\n\nPrisma"
  },
  {
    "title": "Prisma | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/prisma",
    "html": "Prisma\nCopy Markdown\nOpen in\n\nPrisma ORM is an open-source database toolkit that simplifies database access and management in applications by providing a type-safe query builder and an intuitive data modeling interface. Read more here.\n\nExample Usage\n\nMake sure you have Prisma installed and configured. Then, you can use the Prisma adapter to connect to your database.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { prismaAdapter } from \"better-auth/adapters/prisma\";\nimport { PrismaClient } from \"@prisma/client\";\nconst prisma = new PrismaClient();\nexport const auth = betterAuth({\n  database: prismaAdapter(prisma, {\n    provider: \"sqlite\",\n  }),\n});\n\nIf you have configured a custom output directory in your schema.prisma file (e.g., output = \"../src/generated/prisma\"), make sure to import the Prisma client from that location instead of @prisma/client. Learn more about custom output directories in the Prisma documentation.\n\nSchema generation & migration\n\nThe Better Auth CLI allows you to generate or migrate your database schema based on your Better Auth configuration and plugins.\n\nPrisma Schema Generation\n\n\t\n\nPrisma Schema Migration\n\n\n✅ Supported\t❌ Not Supported\nSchema Generation\nnpx @better-auth/cli@latest generate\nAdditional Information\n\nIf you're looking for performance improvements or tips, take a look at our guide to performance optimizations.\n\nEdit on GitHub\n\nPrevious Page\n\nDrizzle\n\nNext Page\n\nMongoDB"
  },
  {
    "title": "MongoDB Adapter | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/mongo",
    "html": "MongoDB Adapter\nCopy Markdown\nOpen in\n\nMongoDB is a popular NoSQL database that is widely used for building scalable and flexible applications. It provides a flexible schema that allows for easy data modeling and querying. Read more here: MongoDB.\n\nExample Usage\n\nMake sure you have MongoDB installed and configured. Then, you can use the mongodb adapter.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { MongoClient } from \"mongodb\";\nimport { mongodbAdapter } from \"better-auth/adapters/mongodb\";\nconst client = new MongoClient(\"mongodb://localhost:27017/database\");\nconst db = client.db();\nexport const auth = betterAuth({\n  database: mongodbAdapter(db, {\n    // Optional: if you don't provide a client, database transactions won't be enabled.\n    client\n  }),\n});\nSchema generation & migration\n\nFor MongoDB, we don't need to generate or migrate the schema.\n\nEdit on GitHub\n\nPrevious Page\n\nPrisma\n\nNext Page\n\nOthers"
  },
  {
    "title": "Community Adapters | Better Auth",
    "url": "https://www.better-auth.com/docs/adapters/community-adapters",
    "html": "Community Adapters\nCopy Markdown\nOpen in\n\nThis page showcases a list of recommended community made database adapters. We encourage you to create any missing database adapters and maybe get added to the list!\n\nAdapter\tDatabase Dialect\tAuthor\nconvex-better-auth\tConvex Database\t erquhart\nsurreal-better-auth\tSurrealDB\t Oskar Gmerek\nsurrealdb-better-auth\tSurreal Database\t Necmttn\nbetter-auth-surrealdb\tSurreal Database\t msanchezdev\npayload-better-auth\tPayload CMS\t forrestdevs\n@ronin/better-auth\tRONIN\t ronin-co\nbetter-auth-instantdb\tInstantDB\t daveycodez\n@nerdfolio/remult-better-auth\tRemult\t Tai Vo\nEdit on GitHub\n\nPrevious Page\n\nOthers\n\nNext Page\n\nFull Stack"
  },
  {
    "title": "Client | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/client",
    "html": "Client\nCopy Markdown\nOpen in\n\nBetter Auth offers a client library compatible with popular frontend frameworks like React, Vue, Svelte, and more. This client library includes a set of functions for interacting with the Better Auth server. Each framework's client library is built on top of a core client library that is framework-agnostic, so that all methods and hooks are consistently available across all client libraries.\n\nInstallation\n\nIf you haven't already, install better-auth.\n\nnpm\npnpm\nyarn\nbun\nnpm i better-auth\nCreate Client Instance\n\nImport createAuthClient from the package for your framework (e.g., \"better-auth/react\" for React). Call the function to create your client. Pass the base URL of your auth server. If the auth server is running on the same domain as your client, you can skip this step.\n\nIf you're using a different base path other than /api/auth, make sure to pass the whole URL, including the path. (e.g., http://localhost:3000/custom-path/auth)\n\nreact\nvue\nsvelte\nsolid\nvanilla\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\"\nexport const authClient = createAuthClient({\n    baseURL: \"http://localhost:3000\" // The base URL of your auth server\n})\nUsage\n\nOnce you've created your client instance, you can use the client to interact with the Better Auth server. The client provides a set of functions by default and they can be extended with plugins.\n\nExample: Sign In\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient = createAuthClient()\nawait authClient.signIn.email({\n    email: \"test@user.com\",\n    password: \"password1234\"\n})\nHooks\n\nIn addition to the standard methods, the client provides hooks to easily access different reactive data. Every hook is available in the root object of the client and they all start with use.\n\nExample: useSession\n\nReact\nVue\nSvelte\nSolid\nuser.tsx\n//make sure you're using the react client\nimport { createAuthClient } from \"better-auth/react\"\nconst { useSession } = createAuthClient() \nexport function User() {\n    const {\n        data: session,\n        isPending, //loading state\n        error, //error object \n        refetch //refetch the session\n    } = useSession()\n    return (\n        //...\n    )\n}\nFetch Options\n\nThe client uses a library called better fetch to make requests to the server.\n\nBetter fetch is a wrapper around the native fetch API that provides a more convenient way to make requests. It's created by the same team behind Better Auth and is designed to work seamlessly with it.\n\nYou can pass any default fetch options to the client by passing fetchOptions object to the createAuthClient.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient = createAuthClient({\n    fetchOptions: {\n        //any better-fetch options\n    },\n})\n\nYou can also pass fetch options to most of the client functions. Either as the second argument or as a property in the object.\n\nauth-client.ts\nawait authClient.signIn.email({\n    email: \"email@email.com\",\n    password: \"password1234\",\n}, {\n    onSuccess(ctx) {\n            //      \n    }\n})\n//or\nawait authClient.signIn.email({\n    email: \"email@email.com\",\n    password: \"password1234\",\n    fetchOptions: {\n        onSuccess(ctx) {\n            //      \n        }\n    },\n})\nHandling Errors\n\nMost of the client functions return a response object with the following properties:\n\ndata: The response data.\nerror: The error object if there was an error.\n\nThe error object contains the following properties:\n\nmessage: The error message. (e.g., \"Invalid email or password\")\nstatus: The HTTP status code.\nstatusText: The HTTP status text.\nauth-client.ts\nconst { data, error } = await authClient.signIn.email({\n    email: \"email@email.com\",\n    password: \"password1234\"\n})\nif (error) {\n    //handle error\n}\n\nIf the action accepts a fetchOptions option, you can pass an onError callback to handle errors.\n\nauth-client.ts\nawait authClient.signIn.email({\n    email: \"email@email.com\",\n    password: \"password1234\",\n}, {\n    onError(ctx) {\n        //handle error\n    }\n})\n//or\nawait authClient.signIn.email({\n    email: \"email@email.com\",\n    password: \"password1234\",\n    fetchOptions: {\n        onError(ctx) {\n            //handle error\n        }\n    }\n})\n\nHooks like useSession also return an error object if there was an error fetching the session. On top of that, they also return an isPending property to indicate if the request is still pending.\n\nauth-client.ts\nconst { data, error, isPending } = useSession()\nif (error) {\n    //handle error\n}\nError Codes\n\nThe client instance contains $ERROR_CODES object that contains all the error codes returned by the server. You can use this to handle error translations or custom error messages.\n\nauth-client.ts\nconst authClient = createAuthClient();\ntype ErrorTypes = Partial<\n\tRecord<\n\t\tkeyof typeof authClient.$ERROR_CODES,\n\t\t{\n\t\t\ten: string;\n\t\t\tes: string;\n\t\t}\n\t>\n>;\nconst errorCodes = {\n\tUSER_ALREADY_EXISTS: {\n\t\ten: \"user already registered\",\n\t\tes: \"usuario ya registrada\",\n\t},\n} satisfies ErrorTypes;\nconst getErrorMessage = (code: string, lang: \"en\" | \"es\") => {\n\tif (code in errorCodes) {\n\t\treturn errorCodes[code as keyof typeof errorCodes][lang];\n\t}\n\treturn \"\";\n};\nconst { error } = await authClient.signUp.email({\n\temail: \"user@email.com\",\n\tpassword: \"password\",\n\tname: \"User\",\n});\nif(error?.code){\n    alert(getErrorMessage(error.code, \"en\"));\n}\nPlugins\n\nYou can extend the client with plugins to add more functionality. Plugins can add new functions to the client or modify existing ones.\n\nExample: Magic Link Plugin\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { magicLinkClient } from \"better-auth/client/plugins\"\nconst authClient = createAuthClient({\n    plugins: [\n        magicLinkClient()\n    ]\n})\n\nonce you've added the plugin, you can use the new functions provided by the plugin.\n\nauth-client.ts\nawait authClient.signIn.magicLink({\n    email: \"test@email.com\"\n})\nEdit on GitHub\n\nPrevious Page\n\nCLI\n\nNext Page\n\nCookies"
  },
  {
    "title": "Cookies | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/cookies",
    "html": "Cookies\nCopy Markdown\nOpen in\n\nCookies are used to store data such as session tokens, OAuth state, and more. All cookies are signed using the secret key provided in the auth options.\n\nCookie Prefix\n\nBy default, Better Auth cookies follow the format ${prefix}.${cookie_name}. The default prefix is \"better-auth\". You can change the prefix by setting cookiePrefix in the advanced object of the auth options.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    advanced: {\n        cookiePrefix: \"my-app\"\n    }\n})\nCustom Cookies\n\nAll cookies are httpOnly and secure when the server is running in production mode.\n\nIf you want to set custom cookie names and attributes, you can do so by setting cookieOptions in the advanced object of the auth options.\n\nBy default, Better Auth uses the following cookies:\n\nsession_token to store the session token\nsession_data to store the session data if cookie cache is enabled\ndont_remember to store the flag when rememberMe is disabled\n\nPlugins may also use cookies to store data. For example, the Two Factor Authentication plugin uses the two_factor cookie to store the two-factor authentication state.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    advanced: {\n        cookies: {\n            session_token: {\n                name: \"custom_session_token\",\n                attributes: {\n                    // Set custom cookie attributes\n                }\n            },\n        }\n    }\n})\nCross Subdomain Cookies\n\nSometimes you may need to share cookies across subdomains. For example, if you authenticate on auth.example.com, you may also want to access the same session on app.example.com.\n\nThe domain attribute controls which domains can access the cookie. Setting it to your root domain (e.g. example.com) makes the cookie accessible across all subdomains. For security, follow these guidelines:\n\nOnly enable cross-subdomain cookies if it's necessary\nSet the domain to the most specific scope needed (e.g. app.example.com instead of .example.com)\nBe cautious of untrusted subdomains that could potentially access these cookies\nConsider using separate domains for untrusted services (e.g. status.company.com vs app.company.com)\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    advanced: {\n        crossSubDomainCookies: {\n            enabled: true,\n            domain: \"app.example.com\", // your domain\n        },\n    },\n    trustedOrigins: [\n        'https://example.com',\n        'https://app1.example.com',\n        'https://app2.example.com',\n    ],\n})\nSecure Cookies\n\nBy default, cookies are secure only when the server is running in production mode. You can force cookies to be always secure by setting useSecureCookies to true in the advanced object in the auth options.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    advanced: {\n        useSecureCookies: true\n    }\n})\nEdit on GitHub\n\nPrevious Page\n\nClient\n\nNext Page\n\nDatabase"
  },
  {
    "title": "Email | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/email",
    "html": "Email\nCopy Markdown\nOpen in\n\nEmail is a key part of Better Auth, required for all users regardless of their authentication method. Better Auth provides email and password authentication out of the box, and a lot of utilities to help you manage email verification, password reset, and more.\n\nEmail Verification\n\nEmail verification is a security feature that ensures users provide a valid email address. It helps prevent spam and abuse by confirming that the email address belongs to the user. In this guide, you'll get a walk through of how to implement token based email verification in your app. To use otp based email verification, check out the OTP Verification guide.\n\nAdding Email Verification to Your App\n\nTo enable email verification, you need to pass a function that sends a verification email with a link.\n\nsendVerificationEmail: This function is triggered when email verification starts. It accepts a data object with the following properties:\nuser: The user object containing the email address.\nurl: The verification URL the user must click to verify their email.\ntoken: The verification token used to complete the email verification to be used when implementing a custom verification URL.\n\nand a request object as the second parameter.\n\nauth.ts\nimport { betterAuth } from 'better-auth';\nimport { sendEmail } from './email'; // your email sending function\nexport const auth = betterAuth({\n    emailVerification: {\n        sendVerificationEmail: async ({ user, url, token }, request) => {\n            await sendEmail({\n                to: user.email,\n                subject: 'Verify your email address',\n                text: `Click the link to verify your email: ${url}`\n            })\n        }\n    }\n})\nTriggering Email Verification\n\nYou can initiate email verification in several ways:\n\n1. During Sign-up\n\nTo automatically send a verification email at signup, set emailVerification.sendOnSignUp to true.\n\nauth.ts\nimport { betterAuth } from 'better-auth';\nexport const auth = betterAuth({\n    emailVerification: {\n        sendOnSignUp: true\n    }\n})\n\nThis sends a verification email when a user signs up. For social logins, email verification status is read from the SSO.\n\nWith sendOnSignUp enabled, when the user logs in with an SSO that does not claim the email as verified, Better Auth will dispatch a verification email, but the verification is not required to login even when requireEmailVerification is enabled.\n\n2. Require Email Verification\n\nIf you enable require email verification, users must verify their email before they can log in. And every time a user tries to sign in, sendVerificationEmail is called.\n\nThis only works if you have sendVerificationEmail implemented, if sendOnSignIn is set to true and if the user is trying to sign in with email and password.\n\nauth.ts\nexport const auth = betterAuth({\n  emailVerification: {\n    sendVerificationEmail: async ({ user, url }) => {\n      await sendEmail({\n        to: user.email,\n        subject: \"Verify your email address\",\n        text: `Click the link to verify your email: ${url}`,\n      });\n    sendOnSignIn: true,\n    },\n  },\n  emailAndPassword: {\n    requireEmailVerification: true,\n  },\n});\n\nIf a user tries to sign in without verifying their email, you can handle the error and show a message to the user.\n\nauth-client.ts\nawait authClient.signIn.email({\n    email: \"email@example.com\",\n    password: \"password\"\n}, {\n    onError: (ctx) => {\n        // Handle the error\n        if(ctx.error.status === 403) {\n            alert(\"Please verify your email address\")\n        }\n        //you can also show the original error message\n        alert(ctx.error.message)\n    }\n})\n3. Manually\n\nYou can also manually trigger email verification by calling sendVerificationEmail.\n\nawait authClient.sendVerificationEmail({\n    email: \"user@email.com\",\n    callbackURL: \"/\" // The redirect URL after verification\n})\nVerifying the Email\n\nIf the user clicks the provided verification URL, their email is automatically verified, and they are redirected to the callbackURL.\n\nFor manual verification, you can send the user a custom link with the token and call the verifyEmail function.\n\nawait authClient.verifyEmail({\n    query: {\n        token: \"\" // Pass the token here\n    }\n})\nAuto Sign In After Verification\n\nTo sign in the user automatically after they successfully verify their email, set the autoSignInAfterVerification option to true:\n\nconst auth = betterAuth({\n    //...your other options\n    emailVerification: {\n        autoSignInAfterVerification: true\n    }\n})\nCallback after successful email verification\n\nYou can run custom code immediately after a user verifies their email using the afterEmailVerification callback. This is useful for any side-effects you want to trigger, like granting access to special features or logging the event.\n\nThe afterEmailVerification function runs automatically when a user's email is confirmed, receiving the user object and request details so you can perform actions for that specific user.\n\nHere's how you can set it up:\n\nauth.ts\nimport { betterAuth } from 'better-auth';\nexport const auth = betterAuth({\n    emailVerification: {\n        async afterEmailVerification(user, request) {\n            // Your custom logic here, e.g., grant access to premium features\n            console.log(`${user.email} has been successfully verified!`);\n        }\n    }\n})\nPassword Reset Email\n\nPassword reset allows users to reset their password if they forget it. Better Auth provides a simple way to implement password reset functionality.\n\nYou can enable password reset by passing a function that sends a password reset email with a link.\n\nauth.ts\nimport { betterAuth } from 'better-auth';\nimport { sendEmail } from './email'; // your email sending function\nexport const auth = betterAuth({\n    emailAndPassword: {\n        enabled: true,\n        sendResetPassword: async ({ user, url, token }, request) => {\n            await sendEmail({\n                to: user.email,\n                subject: 'Reset your password',\n                text: `Click the link to reset your password: ${url}`\n            })\n        }\n    }\n})\n\nCheck out the Email and Password guide for more details on how to implement password reset in your app. Also you can check out the Otp verification guide for how to implement password reset with OTP in your app.\n\nEdit on GitHub\n\nPrevious Page\n\nDatabase\n\nNext Page\n\nHooks"
  },
  {
    "title": "Hooks | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/hooks",
    "html": "Hooks\nCopy Markdown\nOpen in\n\nHooks in Better Auth let you \"hook into\" the lifecycle and execute custom logic. They provide a way to customize Better Auth's behavior without writing a full plugin.\n\nWe highly recommend using hooks if you need to make custom adjustments to an endpoint rather than making another endpoint outside of Better Auth.\n\nBefore Hooks\n\nBefore hooks run before an endpoint is executed. Use them to modify requests, pre validate data, or return early.\n\nExample: Enforce Email Domain Restriction\n\nThis hook ensures that users can only sign up if their email ends with @example.com:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { createAuthMiddleware, APIError } from \"better-auth/api\";\nexport const auth = betterAuth({\n    hooks: {\n        before: createAuthMiddleware(async (ctx) => {\n            if (ctx.path !== \"/sign-up/email\") {\n                return;\n            }\n            if (!ctx.body?.email.endsWith(\"@example.com\")) {\n                throw new APIError(\"BAD_REQUEST\", {\n                    message: \"Email must end with @example.com\",\n                });\n            }\n        }),\n    },\n});\nExample: Modify Request Context\n\nTo adjust the request context before proceeding:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { createAuthMiddleware } from \"better-auth/api\";\nexport const auth = betterAuth({\n    hooks: {\n        before: createAuthMiddleware(async (ctx) => {\n            if (ctx.path === \"/sign-up/email\") {\n                return {\n                    context: {\n                        ...ctx,\n                        body: {\n                            ...ctx.body,\n                            name: \"John Doe\",\n                        },\n                    }\n                };\n            }\n        }),\n    },\n});\nAfter Hooks\n\nAfter hooks run after an endpoint is executed. Use them to modify responses.\n\nExample: Send a notification to your channel when a new user is registered\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { createAuthMiddleware } from \"better-auth/api\";\nimport { sendMessage } from \"@/lib/notification\"\nexport const auth = betterAuth({\n    hooks: {\n        after: createAuthMiddleware(async (ctx) => {\n            if(ctx.path.startsWith(\"/sign-up\")){\n                const newSession = ctx.context.newSession;\n                if(newSession){\n                    sendMessage({\n                        type: \"user-register\",\n                        name: newSession.user.name,\n                    })\n                }\n            }\n        }),\n    },\n});\nCtx\n\nWhen you call createAuthMiddleware a ctx object is passed that provides a lot of useful properties. Including:\n\nPath: ctx.path to get the current endpoint path.\nBody: ctx.body for parsed request body (available for POST requests).\nHeaders: ctx.headers to access request headers.\nRequest: ctx.request to access the request object (may not exist in server-only endpoints).\nQuery Parameters: ctx.query to access query parameters.\nContext: ctx.context auth related context, useful for accessing new session, auth cookies configuration, password hashing, config...\n\nand more.\n\nRequest Response\n\nThis utilities allows you to get request information and to send response from a hook.\n\nJSON Responses\n\nUse ctx.json to send JSON responses:\n\nconst hook = createAuthMiddleware(async (ctx) => {\n    return ctx.json({\n        message: \"Hello World\",\n    });\n});\nRedirects\n\nUse ctx.redirect to redirect users:\n\nimport { createAuthMiddleware } from \"better-auth/api\";\nconst hook = createAuthMiddleware(async (ctx) => {\n    throw ctx.redirect(\"/sign-up/name\");\n});\nCookies\nSet cookies: ctx.setCookies or ctx.setSignedCookie.\nGet cookies: ctx.getCookies or ctx.getSignedCookie.\n\nExample:\n\nimport { createAuthMiddleware } from \"better-auth/api\";\nconst hook = createAuthMiddleware(async (ctx) => {\n    ctx.setCookies(\"my-cookie\", \"value\");\n    await ctx.setSignedCookie(\"my-signed-cookie\", \"value\", ctx.context.secret, {\n        maxAge: 1000,\n    });\n    const cookie = ctx.getCookies(\"my-cookie\");\n    const signedCookie = await ctx.getSignedCookie(\"my-signed-cookie\");\n});\nErrors\n\nThrow errors with APIError for a specific status code and message:\n\nimport { createAuthMiddleware, APIError } from \"better-auth/api\";\nconst hook = createAuthMiddleware(async (ctx) => {\n    throw new APIError(\"BAD_REQUEST\", {\n        message: \"Invalid request\",\n    });\n});\nContext\n\nThe ctx object contains another context object inside that's meant to hold contexts related to auth. Including a newly created session on after hook, cookies configuration, password hasher and so on.\n\nNew Session\n\nThe newly created session after an endpoint is run. This only exist in after hook.\n\nauth.ts\ncreateAuthMiddleware(async (ctx) => {\n    const newSession = ctx.context.newSession\n});\nReturned\n\nThe returned value from the hook is passed to the next hook in the chain.\n\nauth.ts\ncreateAuthMiddleware(async (ctx) => {\n    const returned = ctx.context.returned; //this could be a successful response or an APIError\n});\nResponse Headers\n\nThe response headers added by endpoints and hooks that run before this hook.\n\nauth.ts\ncreateAuthMiddleware(async (ctx) => {\n    const responseHeaders = ctx.context.responseHeaders;\n});\nPredefined Auth Cookies\n\nAccess BetterAuth’s predefined cookie properties:\n\nauth.ts\ncreateAuthMiddleware(async (ctx) => {\n    const cookieName = ctx.context.authCookies.sessionToken.name;\n});\nSecret\n\nYou can access the secret for your auth instance on ctx.context.secret\n\nPassword\n\nThe password object provider hash and verify\n\nctx.context.password.hash: let's you hash a given password.\nctx.context.password.verify: let's you verify given password and a hash.\nAdapter\n\nAdapter exposes the adapter methods used by Better Auth. Including findOne, findMany, create, delete, update and updateMany. You generally should use your actually db instance from your orm rather than this adapter.\n\nInternal Adapter\n\nThese are calls to your db that perform specific actions. createUser, createSession, updateSession...\n\nThis may be useful to use instead of using your db directly to get access to databaseHooks, proper secondaryStorage support and so on. If you're make a query similar to what exist in this internal adapter actions it's worth a look.\n\ngenerateId\n\nYou can use ctx.context.generateId to generate Id for various reasons.\n\nReusable Hooks\n\nIf you need to reuse a hook across multiple endpoints, consider creating a plugin. Learn more in the Plugins Documentation.\n\nEdit on GitHub\n\nPrevious Page\n\nEmail\n\nNext Page\n\nPlugins"
  },
  {
    "title": "Plugins | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/plugins",
    "html": "Plugins\nCopy Markdown\nOpen in\n\nPlugins are a key part of Better Auth, they let you extend the base functionalities. You can use them to add new authentication methods, features, or customize behaviors.\n\nBetter Auth comes with many built-in plugins ready to use. Check the plugins section for details. You can also create your own plugins.\n\nUsing a Plugin\n\nPlugins can be a server-side plugin, a client-side plugin, or both.\n\nTo add a plugin on the server, include it in the plugins array in your auth configuration. The plugin will initialize with the provided options.\n\nserver.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    plugins: [\n        // Add your plugins here\n    ]\n});\n\nClient plugins are added when creating the client. Most plugin require both server and client plugins to work correctly. The Better Auth auth client on the frontend uses the createAuthClient function provided by better-auth/client.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nconst authClient =  createAuthClient({\n    plugins: [\n        // Add your client plugins here\n    ]\n});\n\nWe recommend keeping the auth-client and your normal auth instance in separate files.\n\nauth\nserver.ts\nauth-client.ts\nCreating a Plugin\n\nTo get started, you'll need a server plugin. Server plugins are the backbone of all plugins, and client plugins are there to provide an interface with frontend APIs to easily work with your server plugins.\n\nIf your server plugins has endpoints that needs to be called from the client, you'll also need to create a client plugin.\n\nWhat can a plugin do?\nCreate custom endpoints to perform any action you want.\nExtend database tables with custom schemas.\nUse a middleware to target a group of routes using it's route matcher, and run only when those routes are called through a request.\nUse hooks to target a specific route or request. And if you want to run the hook even if the endpoint is called directly.\nUse onRequest or onResponse if you want to do something that affects all requests or responses.\nCreate custom rate-limit rule.\nCreate a Server plugin\n\nTo create a server plugin you need to pass an object that satisfies the BetterAuthPlugin interface.\n\nThe only required property is id, which is a unique identifier for the plugin. Both server and client plugins can use the same id.\n\nplugin.ts\nimport type { BetterAuthPlugin } from \"better-auth\";\nexport const myPlugin = ()=>{\n    return {\n        id: \"my-plugin\",\n    } satisfies BetterAuthPlugin\n}\n\nYou don't have to make the plugin a function, but it's recommended to do so. This way you can pass options to the plugin and it's consistent with the built-in plugins.\n\nEndpoints\n\nTo add endpoints to the server, you can pass endpoints which requires an object with the key being any string and the value being an AuthEndpoint.\n\nTo create an Auth Endpoint you'll need to import createAuthEndpoint from better-auth.\n\nBetter Auth uses wraps around another library called Better Call to create endpoints. Better call is a simple ts web framework made by the same team behind Better Auth.\n\nplugin.ts\nimport { createAuthEndpoint } from \"better-auth/api\";\nconst myPlugin = ()=> {\n    return {\n        id: \"my-plugin\",\n        endpoints: {\n            getHelloWorld: createAuthEndpoint(\"/my-plugin/hello-world\", {\n                method: \"GET\",\n            }, async(ctx) => {\n                return ctx.json({\n                    message: \"Hello World\"\n                })\n            })\n        }\n    } satisfies BetterAuthPlugin\n}\n\nCreate Auth endpoints wraps around createEndpoint from Better Call. Inside the ctx object, it'll provide another object called context that give you access better-auth specific contexts including options, db, baseURL and more.\n\nContext Object\n\nappName: The name of the application. Defaults to \"Better Auth\".\noptions: The options passed to the Better Auth instance.\ntables: Core tables definition. It is an object which has the table name as the key and the schema definition as the value.\nbaseURL: the baseURL of the auth server. This includes the path. For example, if the server is running on http://localhost:3000, the baseURL will be http://localhost:3000/api/auth by default unless changed by the user.\nsession: The session configuration. Includes updateAge and expiresIn values.\nsecret: The secret key used for various purposes. This is defined by the user.\nauthCookie: The default cookie configuration for core auth cookies.\nlogger: The logger instance used by Better Auth.\ndb: The Kysely instance used by Better Auth to interact with the database.\nadapter: This is the same as db but it give you orm like functions to interact with the database. (we recommend using this over db unless you need raw sql queries or for performance reasons)\ninternalAdapter: These are internal db calls that are used by Better Auth. For example, you can use these calls to create a session instead of using adapter directly. internalAdapter.createSession(userId)\ncreateAuthCookie: This is a helper function that let's you get a cookie name and options for either to set or get cookies. It implements things like __secure prefix and __host prefix for cookies based on\n\nFor other properties, you can check the Better Call documentation and the source code .\n\nRules for Endpoints\n\nMakes sure you use kebab-case for the endpoint path\nMake sure to only use POST or GET methods for the endpoints.\nAny function that modifies a data should be a POST method.\nAny function that fetches data should be a GET method.\nMake sure to use the createAuthEndpoint function to create API endpoints.\nMake sure your paths are unique to avoid conflicts with other plugins. If you're using a common path, add the plugin name as a prefix to the path. (/my-plugin/hello-world instead of /hello-world.)\nSchema\n\nYou can define a database schema for your plugin by passing a schema object. The schema object should have the table name as the key and the schema definition as the value.\n\nplugin.ts\nimport { BetterAuthPlugin } from \"better-auth/plugins\";\nconst myPlugin = ()=> {\n    return {\n        id: \"my-plugin\",\n        schema: {\n            myTable: {\n                fields: {\n                    name: {\n                        type: \"string\"\n                    }\n                },\n                modelName: \"myTable\" // optional if you want to use a different name than the key\n            }\n        }\n    } satisfies BetterAuthPlugin\n}\n\nFields\n\nBy default better-auth will create an id field for each table. You can add additional fields to the table by adding them to the fields object.\n\nThe key is the column name and the value is the column definition. The column definition can have the following properties:\n\ntype: The type of the field. It can be string, number, boolean, date.\n\nrequired: if the field should be required on a new record. (default: false)\n\nunique: if the field should be unique. (default: false)\n\nreference: if the field is a reference to another table. (default: null) It takes an object with the following properties:\n\nmodel: The table name to reference.\nfield: The field name to reference.\nonDelete: The action to take when the referenced record is deleted. (default: null)\n\nOther Schema Properties\n\ndisableMigration: if the table should not be migrated. (default: false)\n\nplugin.ts\nconst myPlugin = (opts: PluginOptions)=>{\n    return {\n        id: \"my-plugin\",\n        schema: {\n            rateLimit: {\n                fields: {\n                    key: {\n                        type: \"string\",\n                    },\n                },\n                disableMigration: opts.storage.provider !== \"database\", \n            },\n        },\n    } satisfies BetterAuthPlugin\n}\n\nif you add additional fields to a user or session table, the types will be inferred automatically on getSession and signUpEmail calls.\n\nplugin.ts\nconst myPlugin = ()=>{\n    return {\n        id: \"my-plugin\",\n        schema: {\n            user: {\n                fields: {\n                    age: {\n                        type: \"number\",\n                    },\n                },\n            },\n        },\n    } satisfies BetterAuthPlugin\n}\n\nThis will add an age field to the user table and all user returning endpoints will include the age field and it'll be inferred properly by typescript.\n\nDon't store sensitive information in user or session table. Crate a new table if you need to store sensitive information.\n\nHooks\n\nHooks are used to run code before or after an action is performed, either from a client or directly on the server. You can add hooks to the server by passing a hooks object, which should contain before and after properties.\n\nplugin.ts\nimport {  createAuthMiddleware } from \"better-auth/plugins\";\nconst myPlugin = ()=>{\n    return {\n        id: \"my-plugin\",\n        hooks: {\n            before: [{\n                    matcher: (context)=>{\n                        return context.headers.get(\"x-my-header\") === \"my-value\"\n                    },\n                    handler: createAuthMiddleware(async (ctx)=>{\n                        //do something before the request\n                        return  {\n                            context: ctx // if you want to modify the context\n                        }\n                    })\n                }],\n            after: [{\n                matcher: (context)=>{\n                    return context.path === \"/sign-up/email\"\n                },\n                handler: createAuthMiddleware(async (ctx)=>{\n                    return ctx.json({\n                        message: \"Hello World\"\n                    }) // if you want to modify the response\n                })\n            }]\n        }\n    } satisfies BetterAuthPlugin\n}\nMiddleware\n\nYou can add middleware to the server by passing a middlewares array. This array should contain middleware objects, each with a path and a middleware property. Unlike hooks, middleware only runs on api requests from a client. If the endpoint is invoked directly, the middleware will not run.\n\nThe path can be either a string or a path matcher, using the same path-matching system as better-call.\n\nIf you throw an APIError from the middleware or returned a Response object, the request will be stopped and the response will be sent to the client.\n\nplugin.ts\nconst myPlugin = ()=>{\n    return {\n        id: \"my-plugin\",\n        middlewares: [\n            {\n                path: \"/my-plugin/hello-world\",\n                middleware: createAuthMiddleware(async(ctx)=>{\n                    //do something\n                })\n            }\n        ]\n    } satisfies BetterAuthPlugin\n}\nOn Request & On Response\n\nAdditional to middlewares, you can also hook into right before a request is made and right after a response is returned. This is mostly useful if you want to do something that affects all requests or responses.\n\nOn Request\n\nThe onRequest function is called right before the request is made. It takes two parameters: the request and the context object.\n\nHere’s how it works:\n\nContinue as Normal: If you don't return anything, the request will proceed as usual.\nInterrupt the Request: To stop the request and send a response, return an object with a response property that contains a Response object.\nModify the Request: You can also return a modified request object to change the request before it's sent.\nplugin.ts\nconst myPlugin = ()=> {\n    return  {\n        id: \"my-plugin\",\n        onRequest: async (request, context) => {\n            //do something\n        },\n    } satisfies BetterAuthPlugin\n}\nOn Response\n\nThe onResponse function is executed immediately after a response is returned. It takes two parameters: the response and the context object.\n\nHere’s how to use it:\n\nModify the Response: You can return a modified response object to change the response before it is sent to the client.\nContinue Normally: If you don't return anything, the response will be sent as is.\nplugin.ts\nconst myPlugin = ()=>{\n    return {\n        id: \"my-plugin\",\n        onResponse: async (response, context) => {\n            //do something\n        },\n    } satisfies BetterAuthPlugin\n}\nRate Limit\n\nYou can define custom rate limit rules for your plugin by passing a rateLimit array. The rate limit array should contain an array of rate limit objects.\n\nplugin.ts\nconst myPlugin = ()=>{\n    return {\n        id: \"my-plugin\",\n        rateLimit: [\n            {\n                pathMatcher: (path)=>{\n                    return path === \"/my-plugin/hello-world\"\n                },\n                limit: 10,\n                window: 60,\n            }\n        ]\n    } satisfies BetterAuthPlugin\n}\nServer-plugin helper functions\n\nSome additional helper functions for creating server plugins.\n\ngetSessionFromCtx\n\nAllows you to get the client's session data by passing the auth middleware's context.\n\nplugin.ts\nimport {  createAuthMiddleware } from \"better-auth/plugins\";\nimport { getSessionFromCtx } from \"better-auth/api\";\nconst myPlugin = {\n    id: \"my-plugin\",\n    hooks: {\n        before: [{\n                matcher: (context)=>{\n                    return context.headers.get(\"x-my-header\") === \"my-value\"\n                },\n                handler: createAuthMiddleware(async (ctx) => {\n                    const session = await getSessionFromCtx(ctx);\n                    //do something with the client's session.\n                    return  {\n                        context: ctx\n                    }\n                })\n            }],\n    }\n} satisfies BetterAuthPlugin\nsessionMiddleware\n\nA middleware that checks if the client has a valid session. If the client has a valid session, it'll add the session data to the context object.\n\nplugin.ts\nimport { createAuthMiddleware } from \"better-auth/plugins\";\nimport { sessionMiddleware } from \"better-auth/api\";\nconst myPlugin = ()=>{\n    return {\n        id: \"my-plugin\",\n        endpoints: {\n            getHelloWorld: createAuthEndpoint(\"/my-plugin/hello-world\", {\n                method: \"GET\",\n                use: [sessionMiddleware], \n            }, async(ctx) => {\n                const session = ctx.context.session;\n                return ctx.json({\n                    message: \"Hello World\"\n                })\n            })\n        }\n    } satisfies BetterAuthPlugin\n}\nCreating a client plugin\n\nIf your endpoints needs to be called from the client, you'll need to also create a client plugin. Better Auth clients can infer the endpoints from the server plugins. You can also add additional client side logic.\n\nclient-plugin.ts\nimport type { BetterAuthClientPlugin } from \"better-auth\";\nexport const myPluginClient = ()=>{\n    return {\n        id: \"my-plugin\",\n    } satisfies BetterAuthClientPlugin\n}\nEndpoint Interface\n\nEndpoints are inferred from the server plugin by adding a $InferServerPlugin key to the client plugin.\n\nThe client infers the path as an object and converts kebab-case to camelCase. For example, /my-plugin/hello-world becomes myPlugin.helloWorld.\n\nclient-plugin.ts\nimport type { BetterAuthClientPlugin } from \"better-auth/client\";\nimport type { myPlugin } from \"./plugin\";\nconst myPluginClient = ()=> {\n    return  {\n        id: \"my-plugin\",\n        $InferServerPlugin: {} as ReturnType<typeof myPlugin>,\n    } satisfies BetterAuthClientPlugin\n}\nGet actions\n\nIf you need to add additional methods or what not to the client you can use the getActions function. This function is called with the fetch function from the client.\n\nBetter Auth uses Better fetch to make requests. Better fetch is a simple fetch wrapper made by the same author of Better Auth.\n\nclient-plugin.ts\nimport type { BetterAuthClientPlugin } from \"better-auth/client\";\nimport type { myPlugin } from \"./plugin\";\nimport type { BetterFetchOption } from \"@better-fetch/fetch\";\nconst myPluginClient = {\n    id: \"my-plugin\",\n    $InferServerPlugin: {} as ReturnType<typeof myPlugin>,\n    getActions: ($fetch)=>{\n        return {\n            myCustomAction: async (data: {\n                foo: string,\n            }, fetchOptions?: BetterFetchOption)=>{\n                const res = $fetch(\"/custom/action\", {\n                    method: \"POST\",\n                    body: {\n                        foo: data.foo\n                    },\n                    ...fetchOptions\n                })\n                return res\n            }\n        }\n    }\n} satisfies BetterAuthClientPlugin\n\nAs a general guideline, ensure that each function accepts only one argument, with an optional second argument for fetchOptions to allow users to pass additional options to the fetch call. The function should return an object containing data and error keys.\n\nIf your use case involves actions beyond API calls, feel free to deviate from this rule.\n\nGet Atoms\n\nThis is only useful if you want to provide hooks like useSession.\n\nGet atoms is called with the fetch function from better fetch and it should return an object with the atoms. The atoms should be created using nanostores. The atoms will be resolved by each framework useStore hook provided by nanostores.\n\nclient-plugin.ts\nimport { atom } from \"nanostores\";\nimport type { BetterAuthClientPlugin } from \"better-auth/client\";\nconst myPluginClient = {\n    id: \"my-plugin\",\n    $InferServerPlugin: {} as ReturnType<typeof myPlugin>,\n    getAtoms: ($fetch)=>{\n        const myAtom = atom<null>()\n        return {\n            myAtom\n        }\n    }\n} satisfies BetterAuthClientPlugin\n\nSee built-in plugins for examples of how to use atoms properly.\n\nPath methods\n\nBy default, inferred paths use GET method if they don't require a body and POST if they do. You can override this by passing a pathMethods object. The key should be the path and the value should be the method (\"POST\" | \"GET\").\n\nclient-plugin.ts\nimport type { BetterAuthClientPlugin } from \"better-auth/client\";\nimport type { myPlugin } from \"./plugin\";\nconst myPluginClient = {\n    id: \"my-plugin\",\n    $InferServerPlugin: {} as ReturnType<typeof myPlugin>,\n    pathMethods: {\n        \"/my-plugin/hello-world\": \"POST\"\n    }\n} satisfies BetterAuthClientPlugin\nFetch plugins\n\nIf you need to use better fetch plugins you can pass them to the fetchPlugins array. You can read more about better fetch plugins in the better fetch documentation.\n\nAtom Listeners\n\nThis is only useful if you want to provide hooks like useSession and you want to listen to atoms and re-evaluate them when they change.\n\nYou can see how this is used in the built-in plugins.\n\nEdit on GitHub\n\nPrevious Page\n\nHooks\n\nNext Page\n\nOAuth"
  },
  {
    "title": "OAuth | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/oauth",
    "html": "OAuth\nCopy Markdown\nOpen in\n\nBetter Auth comes with built-in support for OAuth 2.0 and OpenID Connect. This allows you to authenticate users via popular OAuth providers like Google, Facebook, GitHub, and more.\n\nIf your desired provider isn't directly supported, you can use the Generic OAuth Plugin for custom integrations.\n\nConfiguring Social Providers\n\nTo enable a social provider, you need to provide clientId and clientSecret for the provider.\n\nHere's an example of how to configure Google as a provider:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n    },\n  },\n});\nUsage\nSign In\n\nTo sign in with a social provider, you can use the signIn.social function with the authClient or auth.api for server-side usage.\n\n// client-side usage\nawait authClient.signIn.social({\n  provider: \"google\", // or any other provider id\n})\n// server-side usage\nawait auth.api.signInSocial({\n  body: {\n    provider: \"google\", // or any other provider id\n  },\n});\nLink account\n\nTo link an account to a social provider, you can use the linkAccount function with the authClient or auth.api for server-side usage.\n\nawait authClient.linkSocial({\n  provider: \"google\", // or any other provider id\n})\n\nserver-side usage:\n\nawait auth.api.linkSocialAccount({\n  body: {\n    provider: \"google\", // or any other provider id\n  },\n  headers: // pass headers with authenticated token\n});\nGet Access Token\n\nTo get the access token for a social provider, you can use the getAccessToken function with the authClient or auth.api for server-side usage. When you use this endpoint, if the access token is expired, it will be refreshed.\n\nconst { accessToken } = await authClient.getAccessToken({\n  providerId: \"google\", // or any other provider id\n  accountId: \"accountId\", // optional, if you want to get the access token for a specific account\n})\n\nserver-side usage:\n\nawait auth.api.getAccessToken({\n  body: {\n    providerId: \"google\", // or any other provider id\n    accountId: \"accountId\", // optional, if you want to get the access token for a specific account\n    userId: \"userId\", // optional, if you don't provide headers with authenticated token\n  },\n  headers: // pass headers with authenticated token\n});\nGet Account Info Provided by the provider\n\nTo get provider specific account info you can use the accountInfo function with the authClient or auth.api for server-side usage.\n\nconst info = await authClient.accountInfo({\n  accountId: \"accountId\", // here you pass in the provider given account id, the provider is automatically detected from the account id\n})\n\nserver-side usage:\n\nawait auth.api.accountInfo({\n  body: { accountId: \"accountId\" },\n  headers: // pass headers with authenticated token\n});\nRequesting Additional Scopes\n\nSometimes your application may need additional OAuth scopes after the user has already signed up (e.g., for accessing GitHub repositories or Google Drive). Users may not want to grant extensive permissions initially, preferring to start with minimal permissions and grant additional access as needed.\n\nYou can request additional scopes by using the linkSocial method with the same provider. This will trigger a new OAuth flow that requests the additional scopes while maintaining the existing account connection.\n\nconst requestAdditionalScopes = async () => {\n    await authClient.linkSocial({\n        provider: \"google\",\n        scopes: [\"https://www.googleapis.com/auth/drive.file\"],\n    });\n};\n\nMake sure you're running Better Auth version 1.2.7 or later. Earlier versions (like 1.2.2) may show a \"Social account already linked\" error when trying to link with an existing provider for additional scopes.\n\nProvider Options\nscope\n\nThe scope of the access request. For example, email or profile.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      scope: [\"email\", \"profile\"],\n    },\n  },\n});\nredirectURI\n\nCustom redirect URI for the provider. By default, it uses /api/auth/callback/${providerName}\n\nauth.ts\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      redirectURI: \"https://your-app.com/auth/callback\",\n    },\n  },\n});\ndisableSignUp\n\nDisables sign-up for new users.\n\ndisableIdTokenSignIn\n\nDisables the use of the ID token for sign-in. By default, it's enabled for some providers like Google and Apple.\n\nverifyIdToken\n\nA custom function to verify the ID token.\n\noverrideUserInfoOnSignIn\n\nA boolean value that determines whether to override the user information in the database when signing in. By default, it is set to false, meaning that the user information will not be overridden during sign-in. If you want to update the user information every time they sign in, set this to true.\n\nmapProfileToUser\n\nA custom function to map the user profile returned from the provider to the user object in your database.\n\nUseful, if you have additional fields in your user object you want to populate from the provider's profile. Or if you want to change how by default the user object is mapped.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      mapProfileToUser: (profile) => {\n        return {\n          firstName: profile.given_name,\n          lastName: profile.family_name,\n        };\n      },\n    },\n  },\n});\nrefreshAccessToken\n\nA custom function to refresh the token. This feature is only supported for built-in social providers (Google, Facebook, GitHub, etc.) and is not currently supported for custom OAuth providers configured through the Generic OAuth Plugin. For built-in providers, you can provide a custom function to refresh the token if needed.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      refreshAccessToken: async (token) => {\n        return {\n          accessToken: \"new-access-token\",\n          refreshToken: \"new-refresh-token\",\n        };\n      },\n    },\n  },\n});\nclientKey\n\nThe client key of your application. This is used by TikTok Social Provider instead of clientId.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    tiktok: {\n      clientKey: \"YOUR_TIKTOK_CLIENT_KEY\",\n      clientSecret: \"YOUR_TIKTOK_CLIENT_SECRET\",\n    },\n  },\n});\ngetUserInfo\n\nA custom function to get user info from the provider. This allows you to override the default user info retrieval process.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      getUserInfo: async (token) => {\n        // Custom implementation to get user info\n        const response = await fetch(\"https://www.googleapis.com/oauth2/v2/userinfo\", {\n          headers: {\n            Authorization: `Bearer ${token.accessToken}`,\n          },\n        });\n        const profile = await response.json();\n        return {\n          user: {\n            id: profile.id,\n            name: profile.name,\n            email: profile.email,\n            image: profile.picture,\n            emailVerified: profile.verified_email,\n          },\n          data: profile,\n        };\n      },\n    },\n  },\n});\ndisableImplicitSignUp\n\nDisables implicit sign up for new users. When set to true for the provider, sign-in needs to be called with requestSignUp as true to create new users.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      disableImplicitSignUp: true,\n    },\n  },\n});\nprompt\n\nThe prompt to use for the authorization code request. This controls the authentication flow behavior.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      prompt: \"select_account\", // or \"consent\", \"login\", \"none\", \"select_account+consent\"\n    },\n  },\n});\nresponseMode\n\nThe response mode to use for the authorization code request. This determines how the authorization response is returned.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      responseMode: \"query\", // or \"form_post\"\n    },\n  },\n});\ndisableDefaultScope\n\nRemoves the default scopes of the provider. By default, providers include certain scopes like email and profile. Set this to true to remove these default scopes and use only the scopes you specify.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  // Other configurations...\n  socialProviders: {\n    google: {\n      clientId: \"YOUR_GOOGLE_CLIENT_ID\",\n      clientSecret: \"YOUR_GOOGLE_CLIENT_SECRET\",\n      disableDefaultScope: true,\n      scope: [\"https://www.googleapis.com/auth/userinfo.email\"], // Only this scope will be used\n    },\n  },\n});\nOther Provider Configurations\n\nEach provider may have additional options, check the specific provider documentation for more details.\n\nEdit on GitHub\n\nPrevious Page\n\nPlugins\n\nNext Page\n\nRate Limit"
  },
  {
    "title": "Rate Limit | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/rate-limit",
    "html": "Rate Limit\nCopy Markdown\nOpen in\n\nBetter Auth includes a built-in rate limiter to help manage traffic and prevent abuse. By default, in production mode, the rate limiter is set to:\n\nWindow: 60 seconds\nMax Requests: 100 requests\n\nServer-side requests made using auth.api aren't affected by rate limiting. Rate limits only apply to client-initiated requests.\n\nYou can easily customize these settings by passing the rateLimit object to the betterAuth function.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    rateLimit: {\n        window: 10, // time window in seconds\n        max: 100, // max requests in the window\n    },\n})\n\nRate limiting is disabled in development mode by default. In order to enable it, set enabled to true:\n\nauth.ts\nexport const auth = betterAuth({\n    rateLimit: {\n        enabled: true,\n        //...other options\n    },\n})\n\nIn addition to the default settings, Better Auth provides custom rules for specific paths. For example:\n\n/sign-in/email: Is limited to 3 requests within 10 seconds.\n\nIn addition, plugins also define custom rules for specific paths. For example, twoFactor plugin has custom rules:\n\n/two-factor/verify: Is limited to 3 requests within 10 seconds.\n\nThese custom rules ensure that sensitive operations are protected with stricter limits.\n\nConfiguring Rate Limit\nConnecting IP Address\n\nRate limiting uses the connecting IP address to track the number of requests made by a user. The default header checked is x-forwarded-for, which is commonly used in production environments. If you are using a different header to track the user's IP address, you'll need to specify it.\n\nauth.ts\nexport const auth = betterAuth({\n    //...other options\n    advanced: {\n        ipAddress: {\n          ipAddressHeaders: [\"cf-connecting-ip\"], // Cloudflare specific header example\n      },\n    },\n    rateLimit: {\n        enabled: true,\n        window: 60, // time window in seconds\n        max: 100, // max requests in the window\n    },\n})\nRate Limit Window\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    //...other options\n    rateLimit: {\n        window: 60, // time window in seconds\n        max: 100, // max requests in the window\n    },\n})\n\nYou can also pass custom rules for specific paths.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    //...other options\n    rateLimit: {\n        window: 60, // time window in seconds\n        max: 100, // max requests in the window\n        customRules: {\n            \"/sign-in/email\": {\n                window: 10,\n                max: 3,\n            },\n            \"/two-factor/*\": async (request)=> {\n                // custom function to return rate limit window and max\n                return {\n                    window: 10,\n                    max: 3,\n                }\n            }\n        },\n    },\n})\n\nIf you like to disable rate limiting for a specific path, you can set it to false or return false from the custom rule function.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    //...other options\n    rateLimit: {\n        customRules: {\n            \"/get-session\": false,\n        },\n    },\n})\nStorage\n\nBy default, rate limit data is stored in memory, which may not be suitable for many use cases, particularly in serverless environments. To address this, you can use a database, secondary storage, or custom storage for storing rate limit data.\n\nUsing Database\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    //...other options\n    rateLimit: {\n        storage: \"database\",\n        modelName: \"rateLimit\", //optional by default \"rateLimit\" is used\n    },\n})\n\nMake sure to run migrate to create the rate limit table in your database.\n\nnpx @better-auth/cli migrate\n\nUsing Secondary Storage\n\nIf a Secondary Storage has been configured you can use that to store rate limit data.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    //...other options\n    rateLimit: {\n\t\tstorage: \"secondary-storage\"\n    },\n})\n\nCustom Storage\n\nIf none of the above solutions suits your use case you can implement a customStorage.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    //...other options\n    rateLimit: {\n        customStorage: {\n            get: async (key) => {\n                // get rate limit data\n            },\n            set: async (key, value) => {\n                // set rate limit data\n            },\n        },\n    },\n})\nHandling Rate Limit Errors\n\nWhen a request exceeds the rate limit, Better Auth returns the following header:\n\nX-Retry-After: The number of seconds until the user can make another request.\n\nTo handle rate limit errors on the client side, you can manage them either globally or on a per-request basis. Since Better Auth clients wrap over Better Fetch, you can pass fetchOptions to handle rate limit errors\n\nGlobal Handling\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nexport const authClient = createAuthClient({\n    fetchOptions: {\n        onError: async (context) => {\n            const { response } = context;\n            if (response.status === 429) {\n                const retryAfter = response.headers.get(\"X-Retry-After\");\n                console.log(`Rate limit exceeded. Retry after ${retryAfter} seconds`);\n            }\n        },\n    }\n})\n\nPer Request Handling\n\nauth-client.ts\nimport { authClient } from \"./auth-client\";\nawait authClient.signIn.email({\n    fetchOptions: {\n        onError: async (context) => {\n            const { response } = context;\n            if (response.status === 429) {\n                const retryAfter = response.headers.get(\"X-Retry-After\");\n                console.log(`Rate limit exceeded. Retry after ${retryAfter} seconds`);\n            }\n        },\n    }\n})\nSchema\n\nIf you are using a database to store rate limit data you need this schema:\n\nTable Name: rateLimit\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tDatabase ID\nkey\tstring\t-\tUnique identifier for each rate limit key\ncount\tinteger\t-\tTime window in seconds\nlastRequest\tbigint\t-\tMax requests in the window\nEdit on GitHub\n\nPrevious Page\n\nOAuth\n\nNext Page\n\nSessions"
  },
  {
    "title": "TypeScript | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/typescript",
    "html": "TypeScript\nCopy Markdown\nOpen in\n\nBetter Auth is designed to be type-safe. Both the client and server are built with TypeScript, allowing you to easily infer types.\n\nTypeScript Config\nStrict Mode\n\nBetter Auth is designed to work with TypeScript's strict mode. We recommend enabling strict mode in your TypeScript config file:\n\ntsconfig.json\n{\n  \"compilerOptions\": {\n    \"strict\": true\n  }\n}\n\nif you can't set strict to true, you can enable strictNullChecks:\n\ntsconfig.json\n{\n  \"compilerOptions\": {\n    \"strictNullChecks\": true,\n  }\n}\n\nIf you're running into issues with TypeScript inference exceeding maximum length the compiler will serialize, then please make sure you're following the instructions above, as well as ensuring that both declaration and composite are not enabled.\n\nInferring Types\n\nBoth the client SDK and the server offer types that can be inferred using the $Infer property. Plugins can extend base types like User and Session, and you can use $Infer to infer these types. Additionally, plugins can provide extra types that can also be inferred through $Infer.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient = createAuthClient()\nexport type Session = typeof authClient.$Infer.Session\n\nThe Session type includes both session and user properties. The user property represents the user object type, and the session property represents the session object type.\n\nYou can also infer types on the server side.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport Database from \"better-sqlite3\"\nexport const auth = betterAuth({\n    database: new Database(\"database.db\")\n})\ntype Session = typeof auth.$Infer.Session\nAdditional Fields\n\nBetter Auth allows you to add additional fields to the user and session objects. All additional fields are properly inferred and available on the server and client side.\n\nimport { betterAuth } from \"better-auth\"\nimport Database from \"better-sqlite3\"\nexport const auth = betterAuth({\n    database: new Database(\"database.db\"),\n    user: {\n       additionalFields: {\n          role: {\n              type: \"string\",\n              input: false\n            } \n        }\n    }\n   \n})\ntype Session = typeof auth.$Infer.Session\n\nIn the example above, we added a role field to the user object. This field is now available on the Session type.\n\nThe input property\n\nThe input property in an additional field configuration determines whether the field should be included in the user input. This property defaults to true, meaning the field will be part of the user input during operations like registration.\n\nTo prevent a field from being part of the user input, you must explicitly set input: false:\n\nadditionalFields: {\n    role: {\n        type: \"string\",\n        input: false\n    }\n}\n\nWhen input is set to false, the field will be excluded from user input, preventing users from passing a value for it.\n\nBy default, additional fields are included in the user input, which can lead to security vulnerabilities if not handled carefully. For fields that should not be set by the user, like a role, it is crucial to set input: false in the configuration.\n\nInferring Additional Fields on Client\n\nTo make sure proper type inference for additional fields on the client side, you need to inform the client about these fields. There are two approaches to achieve this, depending on your project structure:\n\nFor Monorepo or Single-Project Setups\n\nIf your server and client code reside in the same project, you can use the inferAdditionalFields plugin to automatically infer the additional fields from your server configuration.\n\nimport { inferAdditionalFields } from \"better-auth/client/plugins\";\nimport { createAuthClient } from \"better-auth/react\";\nimport type { auth } from \"./auth\";\nexport const authClient = createAuthClient({\n  plugins: [inferAdditionalFields<typeof auth>()],\n});\nFor Separate Client-Server Projects\n\nIf your client and server are in separate projects, you'll need to manually specify the additional fields when creating the auth client.\n\nimport { inferAdditionalFields } from \"better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n  plugins: [inferAdditionalFields({\n      user: {\n        role: {\n          type: \"string\"\n        }\n      }\n  })],\n});\nEdit on GitHub\n\nPrevious Page\n\nSessions\n\nNext Page\n\nUsers & Accounts"
  },
  {
    "title": "User & Accounts | Better Auth",
    "url": "https://www.better-auth.com/docs/concepts/users-accounts",
    "html": "User & Accounts\nCopy Markdown\nOpen in\n\nBeyond authenticating users, Better Auth also provides a set of methods to manage users. This includes, updating user information, changing passwords, and more.\n\nThe user table stores the authentication data of the user Click here to view the schema.\n\nThe user table can be extended using additional fields or by plugins to store additional data.\n\nUpdate User\nUpdate User Information\n\nTo update user information, you can use the updateUser function provided by the client. The updateUser function takes an object with the following properties:\n\nawait authClient.updateUser({\n    image: \"https://example.com/image.jpg\",\n    name: \"John Doe\",\n})\nChange Email\n\nTo allow users to change their email, first enable the changeEmail feature, which is disabled by default. Set changeEmail.enabled to true:\n\nexport const auth = betterAuth({\n    user: {\n        changeEmail: {\n            enabled: true,\n        }\n    }\n})\n\nFor users with a verified email, provide the sendChangeEmailVerification function. This function triggers when a user changes their email, sending a verification email with a URL and token. If the current email isn't verified, the change happens immediately without verification.\n\nexport const auth = betterAuth({\n    user: {\n        changeEmail: {\n            enabled: true,\n            sendChangeEmailVerification: async ({ user, newEmail, url, token }, request) => {\n                await sendEmail({\n                    to: user.email, // verification email must be sent to the current user email to approve the change\n                    subject: 'Approve email change',\n                    text: `Click the link to approve the change: ${url}`\n                })\n            }\n        }\n    }\n})\n\nOnce enabled, use the changeEmail function on the client to update a user’s email. The user must verify their current email before changing it.\n\nawait authClient.changeEmail({\n    newEmail: \"new-email@email.com\",\n    callbackURL: \"/dashboard\", //to redirect after verification\n});\n\nAfter verification, the new email is updated in the user table, and a confirmation is sent to the new address.\n\nIf the current email is unverified, the new email is updated without the verification step.\n\nChange Password\n\nA user's password isn't stored in the user table. Instead, it's stored in the account table. To change the password of a user, you can use one of the following approaches:\n\nClient\nServer\nPOST\n/change-password\nconst { data, error } = await authClient.changePassword({\n    newPassword: \"newpassword1234\", // required\n    currentPassword: \"oldpassword1234\", // required\n    revokeOtherSessions: true,\n});\nProp\tDescription\tType\nnewPassword\t\nThe new password to set\n\tstring\ncurrentPassword\t\nThe current user password\n\tstring\nrevokeOtherSessions?\t\nWhen set to true, all other active sessions for this user will be invalidated\n\tboolean\nSet Password\n\nIf a user was registered using OAuth or other providers, they won't have a password or a credential account. In this case, you can use the setPassword action to set a password for the user. For security reasons, this function can only be called from the server. We recommend having users go through a 'forgot password' flow to set a password for their account.\n\nawait auth.api.setPassword({\n    body: { newPassword: \"password\" },\n    headers: // headers containing the user's session token\n});\nDelete User\n\nBetter Auth provides a utility to hard delete a user from your database. It's disabled by default, but you can enable it easily by passing enabled:true\n\nexport const auth = betterAuth({\n    //...other config\n    user: {\n        deleteUser: { \n            enabled: true\n        } \n    }\n})\n\nOnce enabled, you can call authClient.deleteUser to permanently delete user data from your database.\n\nAdding Verification Before Deletion\n\nFor added security, you’ll likely want to confirm the user’s intent before deleting their account. A common approach is to send a verification email. Better Auth provides a sendDeleteAccountVerification utility for this purpose. This is especially needed if you have OAuth setup and want them to be able to delete their account without forcing them to login again for a fresh session.\n\nHere’s how you can set it up:\n\nexport const auth = betterAuth({\n    user: {\n        deleteUser: {\n            enabled: true,\n            sendDeleteAccountVerification: async (\n                {\n                    user,   // The user object\n                    url, // The auto-generated URL for deletion\n                    token  // The verification token  (can be used to generate custom URL)\n                },\n                request  // The original request object (optional)\n            ) => {\n                // Your email sending logic here\n                // Example: sendEmail(data.user.email, \"Verify Deletion\", data.url);\n            },\n        },\n    },\n});\n\nHow callback verification works:\n\nCallback URL: The URL provided in sendDeleteAccountVerification is a pre-generated link that deletes the user data when accessed.\ndelete-user.ts\nawait authClient.deleteUser({\n    callbackURL: \"/goodbye\" // you can provide a callback URL to redirect after deletion\n});\nAuthentication Check: The user must be signed in to the account they’re attempting to delete. If they aren’t signed in, the deletion process will fail.\n\nIf you have sent a custom URL, you can use the deleteUser method with the token to delete the user.\n\ndelete-user.ts\nawait authClient.deleteUser({\n    token\n});\nAuthentication Requirements\n\nTo delete a user, the user must meet one of the following requirements:\n\nA valid password\n\nif the user has a password, they can delete their account by providing the password.\n\ndelete-user.ts\nawait authClient.deleteUser({\n    password: \"password\"\n});\nFresh session\n\nThe user must have a fresh session token, meaning the user must have signed in recently. This is checked if the password is not provided.\n\nBy default session.freshAge is set to 60 * 60 * 24 (1 day). You can change this value by passing the session object to the auth configuration. If it is set to 0, the freshness check is disabled. It is recommended not to disable this check if you are not using email verification for deleting the account.\n\ndelete-user.ts\nawait authClient.deleteUser();\nEnabled email verification (needed for OAuth users)\n\nAs OAuth users don't have a password, we need to send a verification email to confirm the user's intent to delete their account. If you have already added the sendDeleteAccountVerification callback, you can just call the deleteUser method without providing any other information.\n\ndelete-user.ts\nawait authClient.deleteUser();\nIf you have a custom delete account page and sent that url via the sendDeleteAccountVerification callback. Then you need to call the deleteUser method with the token to complete the deletion.\ndelete-user.ts\nawait authClient.deleteUser({\n    token\n});\nCallbacks\n\nbeforeDelete: This callback is called before the user is deleted. You can use this callback to perform any cleanup or additional checks before deleting the user.\n\nauth.ts\nexport const auth = betterAuth({\n    user: {\n        deleteUser: {\n            enabled: true,\n            beforeDelete: async (user) => {\n                // Perform any cleanup or additional checks here\n            },\n        },\n    },\n});\n\nyou can also throw APIError to interrupt the deletion process.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { APIError } from \"better-auth/api\";\nexport const auth = betterAuth({\n    user: {\n        deleteUser: {\n            enabled: true,\n            beforeDelete: async (user, request) => {\n                if (user.email.includes(\"admin\")) {\n                    throw new APIError(\"BAD_REQUEST\", {\n                        message: \"Admin accounts can't be deleted\",\n                    });\n                }\n            },\n        },\n    },\n});\n\nafterDelete: This callback is called after the user is deleted. You can use this callback to perform any cleanup or additional actions after the user is deleted.\n\nauth.ts\nexport const auth = betterAuth({\n    user: {\n        deleteUser: {\n            enabled: true,\n            afterDelete: async (user, request) => {\n                // Perform any cleanup or additional actions here\n            },\n        },\n    },\n});\nAccounts\n\nBetter Auth supports multiple authentication methods. Each authentication method is called a provider. For example, email and password authentication is a provider, Google authentication is a provider, etc.\n\nWhen a user signs in using a provider, an account is created for the user. The account stores the authentication data returned by the provider. This data includes the access token, refresh token, and other information returned by the provider.\n\nThe account table stores the authentication data of the user Click here to view the schema\n\nList User Accounts\n\nTo list user accounts you can use client.user.listAccounts method. Which will return all accounts associated with a user.\n\nconst accounts = await authClient.listAccounts();\nToken Encryption\n\nBetter Auth doesn’t encrypt tokens by default and that’s intentional. We want you to have full control over how encryption and decryption are handled, rather than baking in behavior that could be confusing or limiting. If you need to store encrypted tokens (like accessToken or refreshToken), you can use databaseHooks to encrypt them before they’re saved to your database.\n\nexport const auth = betterAuth({\n    databaseHooks: {\n        account: {\n            create: {\n                before(account, context) {\n                    const withEncryptedTokens = { ...account };\n                    if (account.accessToken) {\n                        const encryptedAccessToken = encrypt(account.accessToken)  \n                        withEncryptedTokens.accessToken = encryptedAccessToken;\n                    }\n                    if (account.refreshToken) {\n                        const encryptedRefreshToken = encrypt(account.refreshToken); \n                        withEncryptedTokens.refreshToken = encryptedRefreshToken;\n                    }\n                    return {\n                        data: withEncryptedTokens\n                    }\n                },\n            }\n        }\n    }\n})\n\nThen whenever you retrieve back the account make sure to decrypt the tokens before using them.\n\nAccount Linking\n\nAccount linking enables users to associate multiple authentication methods with a single account. With Better Auth, users can connect additional social sign-ons or OAuth providers to their existing accounts if the provider confirms the user's email as verified.\n\nIf account linking is disabled, no accounts can be linked, regardless of the provider or email verification status.\n\nauth.ts\nexport const auth = betterAuth({\n    account: {\n        accountLinking: {\n            enabled: true, \n        }\n    },\n});\nForced Linking\n\nYou can specify a list of \"trusted providers.\" When a user logs in using a trusted provider, their account will be automatically linked even if the provider doesn’t confirm the email verification status. Use this with caution as it may increase the risk of account takeover.\n\nauth.ts\nexport const auth = betterAuth({\n    account: {\n        accountLinking: {\n            enabled: true,\n            trustedProviders: [\"google\", \"github\"]\n        }\n    },\n});\nManually Linking Accounts\n\nUsers already signed in can manually link their account to additional social providers or credential-based accounts.\n\nLinking Social Accounts: Use the linkSocial method on the client to link a social provider to the user's account.\n\nawait authClient.linkSocial({\n    provider: \"google\", // Provider to link\n    callbackURL: \"/callback\" // Callback URL after linking completes\n});\n\nYou can also request specific scopes when linking a social account, which can be different from the scopes used during the initial authentication:\n\nawait authClient.linkSocial({\n    provider: \"google\",\n    callbackURL: \"/callback\",\n    scopes: [\"https://www.googleapis.com/auth/drive.readonly\"] // Request additional scopes\n});\n\nYou can also link accounts using ID tokens directly, without redirecting to the provider's OAuth flow:\n\nawait authClient.linkSocial({\n    provider: \"google\",\n    idToken: {\n        token: \"id_token_from_provider\",\n        nonce: \"nonce_used_for_token\", // Optional\n        accessToken: \"access_token\", // Optional, may be required by some providers\n        refreshToken: \"refresh_token\" // Optional\n    }\n});\n\nThis is useful when you already have valid tokens from the provider, for example:\n\nAfter signing in with a native SDK\nWhen using a mobile app that handles authentication\nWhen implementing custom OAuth flows\n\nThe ID token must be valid and the provider must support ID token verification.\n\nIf you want your users to be able to link a social account with a different email address than the user, or if you want to use a provider that does not return email addresses, you will need to enable this in the account linking settings.\n\nauth.ts\nexport const auth = betterAuth({\n    account: {\n        accountLinking: {\n            allowDifferentEmails: true\n        }\n    },\n});\n\nIf you want the newly linked accounts to update the user information, you need to enable this in the account linking settings.\n\nauth.ts\nexport const auth = betterAuth({\n    account: {\n        accountLinking: {\n            updateUserInfoOnLink: true\n        }\n    },\n});\n\nLinking Credential-Based Accounts: To link a credential-based account (e.g., email and password), users can initiate a \"forgot password\" flow, or you can call the setPassword method on the server.\n\nawait auth.api.setPassword({\n    headers: /* headers containing the user's session token */,\n    password: /* new password */\n});\n\nsetPassword can't be called from the client for security reasons.\n\nAccount Unlinking\n\nYou can unlink a user account by providing a providerId.\n\nawait authClient.unlinkAccount({\n    providerId: \"google\"\n});\n// Unlink a specific account\nawait authClient.unlinkAccount({\n    providerId: \"google\",\n    accountId: \"123\"\n});\n\nIf the account doesn't exist, it will throw an error. Additionally, if the user only has one account, unlinking will be prevented to stop account lockout (unless allowUnlinkingAll is set to true).\n\nauth.ts\nexport const auth = betterAuth({\n    account: {\n        accountLinking: {\n            allowUnlinkingAll: true\n        }\n    },\n});\nEdit on GitHub\n\nPrevious Page\n\nTypeScript\n\nNext Page\n\nEmail & Password"
  },
  {
    "title": "Astro Example | Better Auth",
    "url": "https://www.better-auth.com/docs/examples/astro",
    "html": "Astro Example\nCopy Markdown\nOpen in\n\nThis is an example of how to use Better Auth with Astro. It uses Solid for building the components.\n\nImplements the following features: Email & Password . Social Sign-in with Google . Passkeys . Email Verification . Password Reset . Two Factor Authentication . Profile Update . Session Management\n\nOpen in Stackblitz\nView on GitHub\nHow to run\n\nClone the code sandbox (or the repo) and open it in your code editor\n\nProvide .env file with the following variables\n\nGOOGLE_CLIENT_ID=\nGOOGLE_CLIENT_SECRET=\nBETTER_AUTH_SECRET=\n\n//if you don't have these, you can get them from the google developer console. If you don't want to use google sign-in, you can remove the google config from the auth.ts file.\n\nRun the following commands\n\npnpm install\npnpm run dev\n\nOpen the browser and navigate to http://localhost:3000\n\nEdit on GitHub\n\nPrevious Page\n\nExamples\n\nNext Page\n\nRemix"
  },
  {
    "title": "Remix Example | Better Auth",
    "url": "https://www.better-auth.com/docs/examples/remix",
    "html": "Remix Example\nCopy Markdown\nOpen in\n\nThis is an example of how to use Better Auth with Remix.\n\nImplements the following features: Email & Password . Social Sign-in with Google . Passkeys . Email Verification . Password Reset . Two Factor Authentication . Profile Update . Session Management\n\nOpen in Stackblitz\nView on GitHub\nHow to run\nClone the code sandbox (or the repo) and open it in your code editor\nProvide .env file with by copying the .env.example file and adding the variables\nRun the following commands\npnpm install\npnpm run dev\nOpen the browser and navigate to http://localhost:3000\nEdit on GitHub\n\nPrevious Page\n\nAstro + SolidJs\n\nNext Page\n\nNext.js"
  },
  {
    "title": "SvelteKit Example | Better Auth",
    "url": "https://www.better-auth.com/docs/examples/svelte-kit",
    "html": "SvelteKit Example\nCopy Markdown\nOpen in\n\nThis is an example of how to use Better Auth with SvelteKit.\n\nImplements the following features: Email & Password . Social Sign-in with Google . Passkeys . Email Verification . Password Reset . Two Factor Authentication . Profile Update . Session Management\n\nOpen in Stackblitz\nView on GitHub\nHow to run\nClone the code sandbox (or the repo) and open it in your code editor\nMove .env.example to .env and provide necessary variables\nRun the following commands\npnpm install\npnpm dev\nOpen the browser and navigate to http://localhost:3000\nEdit on GitHub\n\nPrevious Page\n\nNuxt"
  },
  {
    "title": "Nuxt Example | Better Auth",
    "url": "https://www.better-auth.com/docs/examples/nuxt",
    "html": "Nuxt Example\nCopy Markdown\nOpen in\n\nThis is an example of how to use Better Auth with Nuxt.\n\nImplements the following features: Email & Password . Social Sign-in with Google\n\nOpen in Stackblitz\nView on GitHub\nHow to run\nClone the code sandbox (or the repo) and open it in your code editor\nMove .env.example to .env and provide necessary variables\nRun the following commands\npnpm install\npnpm dev\nOpen the browser and navigate to http://localhost:3000\nEdit on GitHub\n\nPrevious Page\n\nNext.js\n\nNext Page\n\nSvelteKit"
  },
  {
    "title": "Anonymous | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/anonymous",
    "html": "Anonymous\nCopy Markdown\nOpen in\n\nThe Anonymous plugin allows users to have an authenticated experience without requiring them to provide an email address, password, OAuth provider, or any other Personally Identifiable Information (PII). Users can later link an authentication method to their account when ready.\n\nInstallation\nAdd the plugin to your auth config\n\nTo enable anonymous authentication, add the anonymous plugin to your authentication configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { anonymous } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    // ... other config options\n    plugins: [\n        anonymous() \n    ]\n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\n\nNext, include the anonymous client plugin in your authentication client instance.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { anonymousClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        anonymousClient()\n    ]\n})\nUsage\nSign In\n\nTo sign in a user anonymously, use the signIn.anonymous() method.\n\nexample.ts\nconst user = await authClient.signIn.anonymous()\nLink Account\n\nIf a user is already signed in anonymously and tries to signIn or signUp with another method, their anonymous activities can be linked to the new account.\n\nTo do that you first need to provide onLinkAccount callback to the plugin.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    plugins: [\n        anonymous({\n            onLinkAccount: async ({ anonymousUser, newUser }) => {\n               // perform actions like moving the cart items from anonymous user to the new user\n            }\n        })\n    ]\n\nThen when you call signIn or signUp with another method, the onLinkAccount callback will be called. And the anonymousUser will be deleted by default.\n\nexample.ts\nconst user = await authClient.signIn.email({\n    email,\n})\nOptions\nemailDomainName: The domain name to use when generating an email address for anonymous users. Defaults to the domain name of the current site.\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    plugins: [\n        anonymous({\n            emailDomainName: \"example.com\"\n        })\n    ]\n})\n\nonLinkAccount: A callback function that is called when an anonymous user links their account to a new authentication method. The callback receives an object with the anonymousUser and the newUser.\n\ndisableDeleteAnonymousUser: By default, the anonymous user is deleted when the account is linked to a new authentication method. Set this option to true to disable this behavior.\n\ngenerateName: A callback function that is called to generate a name for the anonymous user. Useful if you want to have random names for anonymous users, or if name is unique in your database.\n\nSchema\n\nThe anonymous plugin requires an additional field in the user table:\n\nField Name\tType\tKey\tDescription\nisAnonymous\tboolean\t?\tIndicates whether the user is anonymous.\nEdit on GitHub\n\nPrevious Page\n\nUsername\n\nNext Page\n\nPhone Number"
  },
  {
    "title": "Phone Number | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/phone-number",
    "html": "Phone Number\nCopy Markdown\nOpen in\n\nThe phone number plugin extends the authentication system by allowing users to sign in and sign up using their phone number. It includes OTP (One-Time Password) functionality to verify phone numbers.\n\nInstallation\nAdd Plugin to the server\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { phoneNumber } from \"better-auth/plugins\"\nconst auth = betterAuth({\n    plugins: [ \n        phoneNumber({  \n            sendOTP: ({ phoneNumber, code }, request) => { \n                // Implement sending OTP code via SMS\n            } \n        }) \n    ] \n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { phoneNumberClient } from \"better-auth/client/plugins\"\nconst authClient =  createAuthClient({\n    plugins: [ \n        phoneNumberClient() \n    ] \n})\nUsage\nSend OTP for Verification\n\nTo send an OTP to a user's phone number for verification, you can use the sendVerificationCode endpoint.\n\nClient\nServer\nPOST\n/phone-number/send-otp\nconst { data, error } = await authClient.phoneNumber.sendOtp({\n    phoneNumber: \"+1234567890\", // required\n});\nProp\tDescription\tType\nphoneNumber\t\nPhone number to send OTP.\n\tstring\nVerify Phone Number\n\nAfter the OTP is sent, users can verify their phone number by providing the code.\n\nClient\nServer\nPOST\n/phone-number/verify\nconst { data, error } = await authClient.phoneNumber.verify({\n    phoneNumber: \"+1234567890\", // required\n    code: \"123456\", // required\n    disableSession: false,\n    updatePhoneNumber: true,\n});\nProp\tDescription\tType\nphoneNumber\t\nPhone number to verify.\n\tstring\ncode\t\nOTP code.\n\tstring\ndisableSession?\t\nDisable session creation after verification.\n\tboolean\nupdatePhoneNumber?\t\nCheck if there is a session and update the phone number.\n\tboolean\n\nWhen the phone number is verified, the phoneNumberVerified field in the user table is set to true. If disableSession is not set to true, a session is created for the user. Additionally, if callbackOnVerification is provided, it will be called.\n\nAllow Sign-Up with Phone Number\n\nTo allow users to sign up using their phone number, you can pass signUpOnVerification option to your plugin configuration. It requires you to pass getTempEmail function to generate a temporary email for the user.\n\nauth.ts\nexport const auth = betterAuth({\n    plugins: [\n        phoneNumber({\n            sendOTP: ({ phoneNumber, code }, request) => {\n                // Implement sending OTP code via SMS\n            },\n            signUpOnVerification: {\n                getTempEmail: (phoneNumber) => {\n                    return `${phoneNumber}@my-site.com`\n                },\n                //optionally, you can also pass `getTempName` function to generate a temporary name for the user\n                getTempName: (phoneNumber) => {\n                    return phoneNumber //by default, it will use the phone number as the name\n                }\n            }\n        })\n    ]\n})\nSign In with Phone Number\n\nIn addition to signing in a user using send-verify flow, you can also use phone number as an identifier and sign in a user using phone number and password.\n\nClient\nServer\nPOST\n/sign-in/phone-number\nconst { data, error } = await authClient.signIn.phoneNumber({\n    phoneNumber: \"+1234567890\", // required\n    password, // required\n    rememberMe: true,\n});\nProp\tDescription\tType\nphoneNumber\t\nPhone number to sign in.\n\tstring\npassword\t\nPassword to use for sign in.\n\tstring\nrememberMe?\t\nRemember the session.\n\tboolean\nUpdate Phone Number\n\nUpdating phone number uses the same process as verifying a phone number. The user will receive an OTP code to verify the new phone number.\n\nauth-client.ts\nawait authClient.phoneNumber.sendOtp({\n    phoneNumber: \"+1234567890\" // New phone number\n})\n\nThen verify the new phone number with the OTP code.\n\nauth-client.ts\nconst isVerified = await authClient.phoneNumber.verify({\n    phoneNumber: \"+1234567890\",\n    code: \"123456\",\n    updatePhoneNumber: true // Set to true to update the phone number\n})\n\nIf a user session exist the phone number will be updated automatically.\n\nDisable Session Creation\n\nBy default, the plugin creates a session for the user after verifying the phone number. You can disable this behavior by passing disableSession: true to the verify method.\n\nauth-client.ts\nconst isVerified = await authClient.phoneNumber.verify({\n    phoneNumber: \"+1234567890\",\n    code: \"123456\",\n    disableSession: true\n})\nRequest Password Reset\n\nTo initiate a request password reset flow using phoneNumber, you can start by calling requestPasswordReset on the client to send an OTP code to the user's phone number.\n\nClient\nServer\nPOST\n/phone-number/request-password-reset\nconst { data, error } = await authClient.phoneNumber.requestPasswordReset({\n    phoneNumber: \"+1234567890\", // required\n});\nProp\tDescription\tType\nphoneNumber\t\nThe phone number which is associated with the user.\n\tstring\n\nThen, you can reset the password by calling resetPassword on the client with the OTP code and the new password.\n\nClient\nServer\nPOST\n/phone-number/reset-password\nconst { data, error } = await authClient.phoneNumber.resetPassword({\n    otp: \"123456\", // required\n    phoneNumber: \"+1234567890\", // required\n    newPassword: \"new-and-secure-password\", // required\n});\nProp\tDescription\tType\notp\t\nThe one time password to reset the password.\n\tstring\nphoneNumber\t\nThe phone number to the account which intends to reset the password for.\n\tstring\nnewPassword\t\nThe new password.\n\tstring\nOptions\notpLength: The length of the OTP code to be generated. Default is 6.\nsendOTP: A function that sends the OTP code to the user's phone number. It takes the phone number and the OTP code as arguments.\nexpiresIn: The time in seconds after which the OTP code expires. Default is 300 seconds.\ncallbackOnVerification: A function that is called after the phone number is verified. It takes the phone number and the user object as the first argument and a request object as the second argument.\nexport const auth = betterAuth({\n    plugins: [\n        phoneNumber({\n            sendOTP: ({ phoneNumber, code }, request) => {\n                // Implement sending OTP code via SMS\n            },\n            callbackOnVerification: async ({ phoneNumber, user }, request) => {\n                // Implement callback after phone number verification\n            }\n        })\n    ]\n})\n\nsendPasswordResetOTP: A function that sends the OTP code to the user's phone number for password reset. It takes the phone number and the OTP code as arguments.\n\nphoneNumberValidator: A custom function to validate the phone number. It takes the phone number as an argument and returns a boolean indicating whether the phone number is valid.\n\nsignUpOnVerification: An object with the following properties:\n\ngetTempEmail: A function that generates a temporary email for the user. It takes the phone number as an argument and returns the temporary email.\ngetTempName: A function that generates a temporary name for the user. It takes the phone number as an argument and returns the temporary name.\n\nrequireVerification: When enabled, users cannot sign in with their phone number until it has been verified. If an unverified user attempts to sign in, the server will respond with a 401 error (PHONE_NUMBER_NOT_VERIFIED) and automatically trigger an OTP send to start the verification process.\n\nSchema\n\nThe plugin requires 2 fields to be added to the user table\n\nUser Table\nField Name\tType\tKey\tDescription\nphoneNumber\tstring\t?\tThe phone number of the user\nphoneNumberVerified\tboolean\t?\tWhether the phone number is verified or not\nOTP Verification Attempts\n\nThe phone number plugin includes a built-in protection against brute force attacks by limiting the number of verification attempts for each OTP code.\n\nphoneNumber({\n  allowedAttempts: 3, // default is 3\n  // ... other options\n})\n\nWhen a user exceeds the allowed number of verification attempts:\n\nThe OTP code is automatically deleted\nFurther verification attempts will return a 403 (Forbidden) status with \"Too many attempts\" message\nThe user will need to request a new OTP code to continue\n\nExample error response after exceeding attempts:\n\n{\n  \"error\": {\n    \"status\": 403,\n    \"message\": \"Too many attempts\"\n  }\n}\n\nWhen receiving a 403 status, prompt the user to request a new OTP code\n\nEdit on GitHub\n\nPrevious Page\n\nAnonymous\n\nNext Page\n\nMagic Link"
  },
  {
    "title": "One Tap | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/one-tap",
    "html": "One Tap\nCopy Markdown\nOpen in\n\nThe One Tap plugin allows users to log in with a single tap using Google's One Tap API. The plugin provides a simple way to integrate One Tap into your application, handling the client-side and server-side logic for you.\n\nInstallation\nAdd the Server Plugin\n\nAdd the One Tap plugin to your auth configuration:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { oneTap } from \"better-auth/plugins\"; \nexport const auth = betterAuth({\n    plugins: [ \n        oneTap(), // Add the One Tap server plugin\n    ] \n});\nAdd the Client Plugin\n\nAdd the client plugin and specify where the user should be redirected after sign-in or if additional verification (like 2FA) is needed.\n\nimport { createAuthClient } from \"better-auth/client\";\nimport { oneTapClient } from \"better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n  plugins: [\n    oneTapClient({\n      clientId: \"YOUR_CLIENT_ID\",\n      // Optional client configuration:\n      autoSelect: false,\n      cancelOnTapOutside: true,\n      context: \"signin\",\n      additionalOptions: {\n        // Any extra options for the Google initialize method\n      },\n      // Configure prompt behavior and exponential backoff:\n      promptOptions: {\n        baseDelay: 1000,   // Base delay in ms (default: 1000)\n        maxAttempts: 5     // Maximum number of attempts before triggering onPromptNotification (default: 5)\n      }\n    })\n  ]\n});\nUsage\n\nTo display the One Tap popup, simply call the oneTap method on your auth client:\n\nawait authClient.oneTap();\nCustomizing Redirect Behavior\n\nBy default, after a successful login the plugin will hard redirect the user to /. You can customize this behavior as follows:\n\nAvoiding a Hard Redirect\n\nPass fetchOptions with an onSuccess callback to handle the login response without a page reload:\n\nawait authClient.oneTap({\n  fetchOptions: {\n    onSuccess: () => {\n      // For example, use a router to navigate without a full reload:\n      router.push(\"/dashboard\");\n    }\n  }\n});\nSpecifying a Custom Callback URL\n\nTo perform a hard redirect to a different page after login, use the callbackURL option:\n\nawait authClient.oneTap({\n  callbackURL: \"/dashboard\"\n});\nHandling Prompt Dismissals with Exponential Backoff\n\nIf the user dismisses or skips the prompt, the plugin will retry showing the One Tap prompt using exponential backoff based on your configured promptOptions.\n\nIf the maximum number of attempts is reached without a successful sign-in, you can use the onPromptNotification callback to be notified—allowing you to render an alternative UI (e.g., a traditional Google Sign-In button) so users can restart the process manually:\n\nawait authClient.oneTap({\n  onPromptNotification: (notification) => {\n    console.warn(\"Prompt was dismissed or skipped. Consider displaying an alternative sign-in option.\", notification);\n    // Render your alternative UI here\n  }\n});\nClient Options\nclientId: The client ID for your Google One Tap API.\nautoSelect: Automatically select the account if the user is already signed in. Default is false.\ncontext: The context in which the One Tap API should be used (e.g., \"signin\"). Default is \"signin\".\ncancelOnTapOutside: Cancel the One Tap popup when the user taps outside it. Default is true.\nadditionalOptions: Extra options to pass to Google's initialize method as per the Google Identity Services docs.\npromptOptions: Configuration for the prompt behavior and exponential backoff:\nbaseDelay: Base delay in milliseconds for retries. Default is 1000.\nmaxAttempts: Maximum number of prompt attempts before invoking the onPromptNotification callback. Default is 5.\nServer Options\ndisableSignUp: Disable the sign-up option, allowing only existing users to sign in. Default is false.\nClientId: Optionally, pass a client ID here if it is not provided in your social provider configuration.\nEdit on GitHub\n\nPrevious Page\n\nGeneric OAuth\n\nNext Page\n\nSign In With Ethereum"
  },
  {
    "title": "Generic OAuth | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/generic-oauth",
    "html": "Generic OAuth\nCopy Markdown\nOpen in\n\nThe Generic OAuth plugin provides a flexible way to integrate authentication with any OAuth provider. It supports both OAuth 2.0 and OpenID Connect (OIDC) flows, allowing you to easily add social login or custom OAuth authentication to your application.\n\nInstallation\nAdd the plugin to your auth config\n\nTo use the Generic OAuth plugin, add it to your auth config.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { genericOAuth } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    // ... other config options\n    plugins: [ \n        genericOAuth({ \n            config: [ \n                { \n                    providerId: \"provider-id\", \n                    clientId: \"test-client-id\", \n                    clientSecret: \"test-client-secret\", \n                    discoveryUrl: \"https://auth.example.com/.well-known/openid-configuration\", \n                    // ... other config options\n                }, \n                // Add more providers as needed\n            ] \n        }) \n    ]\n})\nAdd the client plugin\n\nInclude the Generic OAuth client plugin in your authentication client instance.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { genericOAuthClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        genericOAuthClient()\n    ]\n})\nUsage\n\nThe Generic OAuth plugin provides endpoints for initiating the OAuth flow and handling the callback. Here's how to use them:\n\nInitiate OAuth Sign-In\n\nTo start the OAuth sign-in process:\n\nClient\nServer\nPOST\n/sign-in/oauth2\nconst { data, error } = await authClient.signIn.oauth2({\n    providerId: \"provider-id\", // required\n    callbackURL: \"/dashboard\",\n    errorCallbackURL: \"/error-page\",\n    newUserCallbackURL: \"/welcome\",\n    disableRedirect: false,\n    scopes: [\"my-scope\"],\n    requestSignUp: false,\n});\nProp\tDescription\tType\nproviderId\t\nThe provider ID for the OAuth provider.\n\tstring\ncallbackURL?\t\nThe URL to redirect to after sign in.\n\tstring\nerrorCallbackURL?\t\nThe URL to redirect to if an error occurs.\n\tstring\nnewUserCallbackURL?\t\nThe URL to redirect to after login if the user is new.\n\tstring\ndisableRedirect?\t\nDisable redirect.\n\tboolean\nscopes?\t\nScopes to be passed to the provider authorization request.\n\tstring[]\nrequestSignUp?\t\nExplicitly request sign-up. Useful when disableImplicitSignUp is true for this provider.\n\tboolean\nLinking OAuth Accounts\n\nTo link an OAuth account to an existing user:\n\nClient\nServer\nPOST\n/oauth2/link\nconst { data, error } = await authClient.oauth2.link({\n    providerId: \"my-provider-id\", // required\n    callbackURL: \"/successful-link\", // required\n});\nProp\tDescription\tType\nproviderId\t\nThe OAuth provider ID.\n\tstring\ncallbackURL\t\nThe URL to redirect to once the account linking was complete.\n\tstring\nHandle OAuth Callback\n\nThe plugin mounts a route to handle the OAuth callback /oauth2/callback/:providerId. This means by default ${baseURL}/api/auth/oauth2/callback/:providerId will be used as the callback URL. Make sure your OAuth provider is configured to use this URL.\n\nConfiguration\n\nWhen adding the plugin to your auth config, you can configure multiple OAuth providers. Each provider configuration object supports the following options:\n\ninterface GenericOAuthConfig {\n  providerId: string;\n  discoveryUrl?: string;\n  authorizationUrl?: string;\n  tokenUrl?: string;\n  userInfoUrl?: string;\n  clientId: string;\n  clientSecret: string;\n  scopes?: string[];\n  redirectURI?: string;\n  responseType?: string;\n  prompt?: string;\n  pkce?: boolean;\n  accessType?: string;\n  getUserInfo?: (tokens: OAuth2Tokens) => Promise<User | null>;\n}\nOther Provider Configurations\n\nproviderId: A unique string to identify the OAuth provider configuration.\n\ndiscoveryUrl: (Optional) URL to fetch the provider's OAuth 2.0/OIDC configuration. If provided, endpoints like authorizationUrl, tokenUrl, and userInfoUrl can be auto-discovered.\n\nauthorizationUrl: (Optional) The OAuth provider's authorization endpoint. Not required if using discoveryUrl.\n\ntokenUrl: (Optional) The OAuth provider's token endpoint. Not required if using discoveryUrl.\n\nuserInfoUrl: (Optional) The endpoint to fetch user profile information. Not required if using discoveryUrl.\n\nclientId: The OAuth client ID issued by your provider.\n\nclientSecret: The OAuth client secret issued by your provider.\n\nscopes: (Optional) An array of scopes to request from the provider (e.g., [\"openid\", \"email\", \"profile\"]).\n\nredirectURI: (Optional) The redirect URI to use for the OAuth flow. If not set, a default is constructed based on your app's base URL.\n\nresponseType: (Optional) The OAuth response type. Defaults to \"code\" for authorization code flow.\n\nresponseMode: (Optional) The response mode for the authorization code request, such as \"query\" or \"form_post\".\n\nprompt: (Optional) Controls the authentication experience (e.g., force login, consent, etc.).\n\npkce: (Optional) If true, enables PKCE (Proof Key for Code Exchange) for enhanced security. Defaults to false.\n\naccessType: (Optional) The access type for the authorization request. Use \"offline\" to request a refresh token.\n\ngetUserInfo: (Optional) A custom function to fetch user info from the provider, given the OAuth tokens. If not provided, a default fetch is used.\n\nmapProfileToUser: (Optional) A function to map the provider's user profile to your app's user object. Useful for custom field mapping or transformations.\n\nauthorizationUrlParams: (Optional) Additional query parameters to add to the authorization URL. These can override default parameters. You can also provide a function that returns the parameters.\n\ntokenUrlParams: (Optional) Additional query parameters to add to the token URL. These can override default parameters. You can also provide a function that returns the parameters.\n\ndisableImplicitSignUp: (Optional) If true, disables automatic sign-up for new users. Sign-in must be explicitly requested with sign-up intent.\n\ndisableSignUp: (Optional) If true, disables sign-up for new users entirely. Only existing users can sign in.\n\nauthentication: (Optional) The authentication method for token requests. Can be 'basic' or 'post'. Defaults to 'post'.\n\ndiscoveryHeaders: (Optional) Custom headers to include in the discovery request. Useful for providers that require special headers.\n\nauthorizationHeaders: (Optional) Custom headers to include in the authorization request. Useful for providers that require special headers.\n\noverrideUserInfo: (Optional) If true, the user's info in your database will be updated with the provider's info every time they sign in. Defaults to false.\n\nAdvanced Usage\nCustom User Info Fetching\n\nYou can provide a custom getUserInfo function to handle specific provider requirements:\n\ngenericOAuth({\n  config: [\n    {\n      providerId: \"custom-provider\",\n      // ... other config options\n      getUserInfo: async (tokens) => {\n        // Custom logic to fetch and return user info\n        const userInfo = await fetchUserInfoFromCustomProvider(tokens);\n        return {\n          id: userInfo.sub,\n          email: userInfo.email,\n          name: userInfo.name,\n          // ... map other fields as needed\n        };\n      }\n    }\n  ]\n})\nMap User Info Fields\n\nIf the user info returned by the provider does not match the expected format, or you need to map additional fields, you can use the mapProfileToUser:\n\ngenericOAuth({\n  config: [\n    {\n      providerId: \"custom-provider\",\n      // ... other config options\n      mapProfileToUser: async (profile) => {\n        return {\n          firstName: profile.given_name,\n          // ... map other fields as needed\n        };\n      }\n    }\n  ]\n})\nError Handling\n\nThe plugin includes built-in error handling for common OAuth issues. Errors are typically redirected to your application's error page with an appropriate error message in the URL parameters. If the callback URL is not provided, the user will be redirected to Better Auth's default error page.\n\nEdit on GitHub\n\nPrevious Page\n\nPasskey\n\nNext Page\n\nOne Tap"
  },
  {
    "title": "Admin | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/admin",
    "html": "Admin\nCopy Markdown\nOpen in\n\nThe Admin plugin provides a set of administrative functions for user management in your application. It allows administrators to perform various operations such as creating users, managing user roles, banning/unbanning users, impersonating users, and more.\n\nInstallation\nAdd the plugin to your auth config\n\nTo use the Admin plugin, add it to your auth config.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { admin } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    // ... other config options\n    plugins: [\n        admin() \n    ]\n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\n\nNext, include the admin client plugin in your authentication client instance.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { adminClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        adminClient()\n    ]\n})\nUsage\n\nBefore performing any admin operations, the user must be authenticated with an admin account. An admin is any user assigned the admin role or any user whose ID is included in the adminUserIds option.\n\nCreate User\n\nAllows an admin to create a new user.\n\nClient\nServer\nPOST\n/admin/create-user\nconst { data: newUser, error } = await authClient.admin.createUser({\n    email: \"user@example.com\", // required\n    password: \"some-secure-password\", // required\n    name: \"James Smith\", // required\n    role: \"user\",\n    data: { customField: \"customValue\" },\n});\nProp\tDescription\tType\nemail\t\nThe email of the user.\n\tstring\npassword\t\nThe password of the user.\n\tstring\nname\t\nThe name of the user.\n\tstring\nrole?\t\nA string or array of strings representing the roles to apply to the new user.\n\tstring | string[]\ndata?\t\nExtra fields for the user. Including custom additional fields.\n\tRecord<string, any>\nList Users\n\nAllows an admin to list all users in the database.\n\nClient\nServer\nGET\n/admin/list-users\nNotes\n\nAll properties are optional to configure. By default, 100 rows are returned, you can configure this by the limit property.\n\nconst { data: users, error } = await authClient.admin.listUsers({\n    query: {\n        searchValue: \"some name\",\n        searchField: \"name\",\n        searchOperator: \"contains\",\n        limit: 100,\n        offset: 100,\n        sortBy: \"name\",\n        sortDirection: \"desc\",\n        filterField: \"email\",\n        filterValue: \"hello@example.com\",\n        filterOperator: \"eq\",\n    },\n});\nProp\tDescription\tType\nsearchValue?\t\nThe value to search for.\n\tstring\nsearchField?\t\nThe field to search in, defaults to email. Can be email or name.\n\t\"email\" | \"name\"\nsearchOperator?\t\nThe operator to use for the search. Can be contains, starts_with or ends_with.\n\t\"contains\" | \"starts_with\" | \"ends_with\"\nlimit?\t\nThe number of users to return. Defaults to 100.\n\tstring | number\noffset?\t\nThe offset to start from.\n\tstring | number\nsortBy?\t\nThe field to sort by.\n\tstring\nsortDirection?\t\nThe direction to sort by.\n\t\"asc\" | \"desc\"\nfilterField?\t\nThe field to filter by.\n\tstring\nfilterValue?\t\nThe value to filter by.\n\tstring | number | boolean\nfilterOperator?\t\nThe operator to use for the filter.\n\t\"eq\" | \"ne\" | \"lt\" | \"lte\" | \"gt\" | \"gte\"\nQuery Filtering\n\nThe listUsers function supports various filter operators including eq, contains, starts_with, and ends_with.\n\nPagination\n\nThe listUsers function supports pagination by returning metadata alongside the user list. The response includes the following fields:\n\n{\n  users: User[],   // Array of returned users\n  total: number,   // Total number of users after filters and search queries\n  limit: number | undefined,   // The limit provided in the query\n  offset: number | undefined   // The offset provided in the query\n}\nHow to Implement Pagination\n\nTo paginate results, use the total, limit, and offset values to calculate:\n\nTotal pages: Math.ceil(total / limit)\nCurrent page: (offset / limit) + 1\nNext page offset: Math.min(offset + limit, (total - 1)) – The value to use as offset for the next page, ensuring it does not exceed the total number of pages.\nPrevious page offset: Math.max(0, offset - limit) – The value to use as offset for the previous page (ensuring it doesn’t go below zero).\nExample Usage\n\nFetching the second page with 10 users per page:\n\nadmin.ts\nconst pageSize = 10;\nconst currentPage = 2;\nconst users = await authClient.admin.listUsers({\n    query: {\n        limit: pageSize,\n        offset: (currentPage - 1) * pageSize\n    }\n});\nconst totalUsers = users.total;\nconst totalPages = Math.ceil(totalUsers / pageSize)\nSet User Role\n\nChanges the role of a user.\n\nClient\nServer\nPOST\n/admin/set-role\nconst { data, error } = await authClient.admin.setRole({\n    userId: \"user-id\",\n    role: \"admin\", // required\n});\nProp\tDescription\tType\nuserId?\t\nThe user id which you want to set the role for.\n\tstring\nrole\t\nThe role to set, this can be a string or an array of strings.\n\tstring | string[]\nSet User Password\n\nChanges the password of a user.\n\nClient\nServer\nPOST\n/admin/set-user-password\nconst { data, error } = await authClient.admin.setUserPassword({\n    newPassword: 'new-password', // required\n    userId: 'user-id', // required\n});\nProp\tDescription\tType\nnewPassword\t\nThe new password.\n\tstring\nuserId\t\nThe user id which you want to set the password for.\n\tstring\nUpdate user\n\nUpdate a user's details.\n\nClient\nServer\nPOST\n/admin/update-user\nconst { data, error } = await authClient.admin.updateUser({\n    userId: \"user-id\", // required\n    data: { name: \"John Doe\" }, // required\n});\nProp\tDescription\tType\nuserId\t\nThe user id which you want to update.\n\tstring\ndata\t\nThe data to update.\n\tRecord<string, any>\nBan User\n\nBans a user, preventing them from signing in and revokes all of their existing sessions.\n\nClient\nServer\nPOST\n/admin/ban-user\nawait authClient.admin.banUser({\n    userId: \"user-id\", // required\n    banReason: \"Spamming\",\n    banExpiresIn: 60 * 60 * 24 * 7,\n});\nProp\tDescription\tType\nuserId\t\nThe user id which you want to ban.\n\tstring\nbanReason?\t\nThe reason for the ban.\n\tstring\nbanExpiresIn?\t\nThe number of seconds until the ban expires. If not provided, the ban will never expire.\n\tnumber\nUnban User\n\nRemoves the ban from a user, allowing them to sign in again.\n\nClient\nServer\nPOST\n/admin/unban-user\nawait authClient.admin.unbanUser({\n    userId: \"user-id\", // required\n});\nProp\tDescription\tType\nuserId\t\nThe user id which you want to unban.\n\tstring\nList User Sessions\n\nLists all sessions for a user.\n\nClient\nServer\nPOST\n/admin/list-user-sessions\nconst { data, error } = await authClient.admin.listUserSessions({\n    userId: \"user-id\", // required\n});\nProp\tDescription\tType\nuserId\t\nThe user id.\n\tstring\nRevoke User Session\n\nRevokes a specific session for a user.\n\nClient\nServer\nPOST\n/admin/revoke-user-session\nconst { data, error } = await authClient.admin.revokeUserSession({\n    sessionToken: \"session_token_here\", // required\n});\nProp\tDescription\tType\nsessionToken\t\nThe session token which you want to revoke.\n\tstring\nRevoke All Sessions for a User\n\nRevokes all sessions for a user.\n\nClient\nServer\nPOST\n/admin/revoke-user-sessions\nconst { data, error } = await authClient.admin.revokeUserSessions({\n    userId: \"user-id\", // required\n});\nProp\tDescription\tType\nuserId\t\nThe user id which you want to revoke all sessions for.\n\tstring\nImpersonate User\n\nThis feature allows an admin to create a session that mimics the specified user. The session will remain active until either the browser session ends or it reaches 1 hour. You can change this duration by setting the impersonationSessionDuration option.\n\nClient\nServer\nPOST\n/admin/impersonate-user\nconst { data, error } = await authClient.admin.impersonateUser({\n    userId: \"user-id\", // required\n});\nProp\tDescription\tType\nuserId\t\nThe user id which you want to impersonate.\n\tstring\nStop Impersonating User\n\nTo stop impersonating a user and continue with the admin account, you can use stopImpersonating\n\nClient\nServer\nPOST\n/admin/stop-impersonating\nawait authClient.admin.stopImpersonating();\nRemove User\n\nHard deletes a user from the database.\n\nClient\nServer\nPOST\n/admin/remove-user\nconst { data: deletedUser, error } = await authClient.admin.removeUser({\n    userId: \"user-id\", // required\n});\nProp\tDescription\tType\nuserId\t\nThe user id which you want to remove.\n\tstring\nAccess Control\n\nThe admin plugin offers a highly flexible access control system, allowing you to manage user permissions based on their role. You can define custom permission sets to fit your needs.\n\nRoles\n\nBy default, there are two roles:\n\nadmin: Users with the admin role have full control over other users.\n\nuser: Users with the user role have no control over other users.\n\nA user can have multiple roles. Multiple roles are stored as string separated by comma (\",\").\n\nPermissions\n\nBy default, there are two resources with up to six permissions.\n\nuser: create list set-role ban impersonate delete set-password\n\nsession: list revoke delete\n\nUsers with the admin role have full control over all the resources and actions. Users with the user role have no control over any of those actions.\n\nCustom Permissions\n\nThe plugin provides an easy way to define your own set of permissions for each role.\n\nCreate Access Control\n\nYou first need to create an access controller by calling the createAccessControl function and passing the statement object. The statement object should have the resource name as the key and the array of actions as the value.\n\npermissions.ts\nimport { createAccessControl } from \"better-auth/plugins/access\";\n/**\n * make sure to use `as const` so typescript can infer the type correctly\n */\nconst statement = { \n    project: [\"create\", \"share\", \"update\", \"delete\"], \n} as const; \nconst ac = createAccessControl(statement); \nCreate Roles\n\nOnce you have created the access controller you can create roles with the permissions you have defined.\n\npermissions.ts\nimport { createAccessControl } from \"better-auth/plugins/access\";\nexport const statement = {\n    project: [\"create\", \"share\", \"update\", \"delete\"], // <-- Permissions available for created roles\n} as const;\nconst ac = createAccessControl(statement);\nexport const user = ac.newRole({ \n    project: [\"create\"], \n}); \nexport const admin = ac.newRole({ \n    project: [\"create\", \"update\"], \n}); \nexport const myCustomRole = ac.newRole({ \n    project: [\"create\", \"update\", \"delete\"], \n    user: [\"ban\"], \n}); \n\nWhen you create custom roles for existing roles, the predefined permissions for those roles will be overridden. To add the existing permissions to the custom role, you need to import defaultStatements and merge it with your new statement, plus merge the roles' permissions set with the default roles.\n\npermissions.ts\nimport { createAccessControl } from \"better-auth/plugins/access\";\nimport { defaultStatements, adminAc } from \"better-auth/plugins/admin/access\";\nconst statement = {\n    ...defaultStatements, \n    project: [\"create\", \"share\", \"update\", \"delete\"],\n} as const;\nconst ac = createAccessControl(statement);\nconst admin = ac.newRole({\n    project: [\"create\", \"update\"],\n    ...adminAc.statements, \n});\nPass Roles to the Plugin\n\nOnce you have created the roles you can pass them to the admin plugin both on the client and the server.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { admin as adminPlugin } from \"better-auth/plugins\"\nimport { ac, admin, user } from \"@/auth/permissions\"\nexport const auth = betterAuth({\n    plugins: [\n        adminPlugin({\n            ac,\n            roles: {\n                admin,\n                user,\n                myCustomRole\n            }\n        }),\n    ],\n});\n\nYou also need to pass the access controller and the roles to the client plugin.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { adminClient } from \"better-auth/client/plugins\"\nimport { ac, admin, user, myCustomRole } from \"@/auth/permissions\"\nexport const client = createAuthClient({\n    plugins: [\n        adminClient({\n            ac,\n            roles: {\n                admin,\n                user,\n                myCustomRole\n            }\n        })\n    ]\n})\nAccess Control Usage\n\nHas Permission:\n\nTo check a user's permissions, you can use the hasPermission function provided by the client.\n\nClient\nServer\nPOST\n/admin/has-permission\nconst { data, error } = await authClient.admin.hasPermission({\n    userId: \"user-id\",\n    permission: { \"project\": [\"create\", \"update\"] } /* Must use this, or permissions */,\n    permissions,\n});\nProp\tDescription\tType\nuserId?\t\nThe user id which you want to check the permissions for.\n\tstring\npermission?\t\nOptionally check if a single permission is granted. Must use this, or permissions.\n\tRecord<string, string[]>\npermissions?\t\nOptionally check if multiple permissions are granted. Must use this, or permission.\n\tRecord<string, string[]>\n\nExample usage:\n\nauth-client.ts\nconst canCreateProject = await authClient.admin.hasPermission({\n  permissions: {\n    project: [\"create\"],\n  },\n});\n// You can also check multiple resource permissions at the same time\nconst canCreateProjectAndCreateSale = await authClient.admin.hasPermission({\n  permissions: {\n    project: [\"create\"],\n    sale: [\"create\"]\n  },\n});\n\nIf you want to check a user's permissions server-side, you can use the userHasPermission action provided by the api to check the user's permissions.\n\napi.ts\nimport { auth } from \"@/auth\";\nawait auth.api.userHasPermission({\n  body: {\n    userId: 'id', //the user id\n    permissions: {\n      project: [\"create\"], // This must match the structure in your access control\n    },\n  },\n});\n// You can also just pass the role directly\nawait auth.api.userHasPermission({\n  body: {\n   role: \"admin\",\n    permissions: {\n      project: [\"create\"], // This must match the structure in your access control\n    },\n  },\n});\n// You can also check multiple resource permissions at the same time\nawait auth.api.userHasPermission({\n  body: {\n   role: \"admin\",\n    permissions: {\n      project: [\"create\"], // This must match the structure in your access control\n      sale: [\"create\"]\n    },\n  },\n});\n\nCheck Role Permission:\n\nUse the checkRolePermission function on the client side to verify whether a given role has a specific permission. This is helpful after defining roles and their permissions, as it allows you to perform permission checks without needing to contact the server.\n\nNote that this function does not check the permissions of the currently logged-in user directly. Instead, it checks what permissions are assigned to a specified role. The function is synchronous, so you don't need to use await when calling it.\n\nauth-client.ts\nconst canCreateProject = authClient.admin.checkRolePermission({\n  permissions: {\n    user: [\"delete\"],\n  },\n  role: \"admin\",\n});\n// You can also check multiple resource permissions at the same time\nconst canDeleteUserAndRevokeSession = authClient.admin.checkRolePermission({\n  permissions: {\n    user: [\"delete\"],\n    session: [\"revoke\"]\n  },\n  role: \"admin\",\n});\nSchema\n\nThis plugin adds the following fields to the user table:\n\nField Name\tType\tKey\tDescription\nrole\tstring\t?\tThe user's role. Defaults to `user`. Admins will have the `admin` role.\nbanned\tboolean\t?\tIndicates whether the user is banned.\nbanReason\tstring\t?\tThe reason for the user's ban.\nbanExpires\tdate\t?\tThe date when the user's ban will expire.\n\nAnd adds one field in the session table:\n\nField Name\tType\tKey\tDescription\nimpersonatedBy\tstring\t?\tThe ID of the admin that is impersonating this session.\nOptions\nDefault Role\n\nThe default role for a user. Defaults to user.\n\nauth.ts\nadmin({\n  defaultRole: \"regular\",\n});\nAdmin Roles\n\nThe roles that are considered admin roles when not using custom access control. Defaults to [\"admin\"].\n\nauth.ts\nadmin({\n  adminRoles: [\"admin\", \"superadmin\"],\n});\n\nNote: The adminRoles option is not required when using custom access control (via ac and roles). When you define custom roles with specific permissions, those roles will have exactly the permissions you grant them through the access control system.\n\nWarning: When not using custom access control, any role that isn't in the adminRoles list will not be able to perform admin operations.\n\nAdmin userIds\n\nYou can pass an array of userIds that should be considered as admin. Default to []\n\nauth.ts\nadmin({\n    adminUserIds: [\"user_id_1\", \"user_id_2\"]\n})\n\nIf a user is in the adminUserIds list, they will be able to perform any admin operation.\n\nimpersonationSessionDuration\n\nThe duration of the impersonation session in seconds. Defaults to 1 hour.\n\nauth.ts\nadmin({\n  impersonationSessionDuration: 60 * 60 * 24, // 1 day\n});\nDefault Ban Reason\n\nThe default ban reason for a user created by the admin. Defaults to No reason.\n\nauth.ts\nadmin({\n  defaultBanReason: \"Spamming\",\n});\nDefault Ban Expires In\n\nThe default ban expires in for a user created by the admin in seconds. Defaults to undefined (meaning the ban never expires).\n\nauth.ts\nadmin({\n  defaultBanExpiresIn: 60 * 60 * 24, // 1 day\n});\nbannedUserMessage\n\nThe message to show when a banned user tries to sign in. Defaults to \"You have been banned from this application. Please contact support if you believe this is an error.\"\n\nauth.ts\nadmin({\n  bannedUserMessage: \"Custom banned user message\",\n});\nEdit on GitHub\n\nPrevious Page\n\nAuthorization\n\nNext Page\n\nAPI Key"
  },
  {
    "title": "Sign In With Ethereum (SIWE) | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/siwe",
    "html": "Sign In With Ethereum (SIWE)\nCopy Markdown\nOpen in\n\nThe Sign in with Ethereum (SIWE) plugin allows users to authenticate using their Ethereum wallets following the ERC-4361 standard. This plugin provides flexibility by allowing you to implement your own message verification and nonce generation logic.\n\nInstallation\nAdd the Server Plugin\n\nAdd the SIWE plugin to your auth configuration:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { siwe } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [\n        siwe({\n            domain: \"example.com\",\n            emailDomainName: \"example.com\", // optional\n            anonymous: false, // optional, default is true\n            getNonce: async () => {\n                // Implement your nonce generation logic here\n                return \"your-secure-random-nonce\";\n            },\n            verifyMessage: async (args) => {\n                // Implement your SIWE message verification logic here\n                // This should verify the signature against the message\n                return true; // return true if signature is valid\n            },\n            ensLookup: async (args) => {\n                // Optional: Implement ENS lookup for user names and avatars\n                return {\n                    name: \"user.eth\",\n                    avatar: \"https://example.com/avatar.png\"\n                };\n            },\n        }),\n    ],\n});\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the Client Plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { siweClient } from \"better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n    plugins: [siweClient()],\n});\nUsage\nGenerate a Nonce\n\nBefore signing a SIWE message, you need to generate a nonce for the wallet address:\n\ngenerate-nonce.ts\nconst { data, error } = await authClient.siwe.nonce({\n  walletAddress: \"0x1234567890abcdef1234567890abcdef12345678\",\n  chainId: 1, // optional for Ethereum mainnet, required for other chains. Defaults to 1\n});\nif (data) {\n  console.log(\"Nonce:\", data.nonce);\n}\nSign In with Ethereum\n\nAfter generating a nonce and creating a SIWE message, verify the signature to authenticate:\n\nsign-in-siwe.ts\nconst { data, error } = await authClient.siwe.verify({\n  message: \"Your SIWE message string\",\n  signature: \"0x...\", // The signature from the user's wallet\n  walletAddress: \"0x1234567890abcdef1234567890abcdef12345678\",\n  chainId: 1, // optional for Ethereum mainnet, required for other chains. Must match Chain ID in SIWE message\n  email: \"user@example.com\", // optional, required if anonymous is false\n});\nif (data) {\n  console.log(\"Authentication successful:\", data.user);\n}\nChain-Specific Examples\n\nHere are examples for different blockchain networks:\n\nethereum-mainnet.ts\n// Ethereum Mainnet (chainId can be omitted, defaults to 1)\nconst { data, error } = await authClient.siwe.verify({\n  message,\n  signature,\n  walletAddress,\n  // chainId: 1 (default)\n});\npolygon.ts\n// Polygon (chainId REQUIRED)\nconst { data, error } = await authClient.siwe.verify({\n  message,\n  signature,\n  walletAddress,\n  chainId: 137, // Required for Polygon\n});\narbitrum.ts\n// Arbitrum (chainId REQUIRED)\nconst { data, error } = await authClient.siwe.verify({\n  message,\n  signature,\n  walletAddress,\n  chainId: 42161, // Required for Arbitrum\n});\nbase.ts\n// Base (chainId REQUIRED)\nconst { data, error } = await authClient.siwe.verify({\n  message,\n  signature,\n  walletAddress,\n  chainId: 8453, // Required for Base\n});\n\nThe chainId must match the Chain ID specified in your SIWE message. Verification will fail with a 401 error if there's a mismatch between the message's Chain ID and the chainId parameter.\n\nConfiguration Options\nServer Options\n\nThe SIWE plugin accepts the following configuration options:\n\ndomain: The domain name of your application (required for SIWE message generation)\nemailDomainName: The email domain name for creating user accounts when not using anonymous mode. Defaults to the domain from your base URL\nanonymous: Whether to allow anonymous sign-ins without requiring an email. Default is true\ngetNonce: Function to generate a unique nonce for each sign-in attempt. You must implement this function to return a cryptographically secure random string. Must return a Promise<string>\nverifyMessage: Function to verify the signed SIWE message. Receives message details and should return Promise<boolean>\nensLookup: Optional function to lookup ENS names and avatars for Ethereum addresses\nClient Options\n\nThe SIWE client plugin doesn't require any configuration options, but you can pass them if needed for future extensibility:\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { siweClient } from \"better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n  plugins: [\n    siweClient({\n      // Optional client configuration can go here\n    }),\n  ],\n});\nSchema\n\nThe SIWE plugin adds a walletAddress table to store user wallet associations:\n\nField\tType\tDescription\nid\tstring\tPrimary key\nuserId\tstring\tReference to user.id\naddress\tstring\tEthereum wallet address\nchainId\tnumber\tChain ID (e.g., 1 for Ethereum mainnet)\nisPrimary\tboolean\tWhether this is the user's primary wallet\ncreatedAt\tdate\tCreation timestamp\nExample Implementation\n\nHere's a complete example showing how to implement SIWE authentication:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { siwe } from \"better-auth/plugins\";\nimport { generateRandomString } from \"better-auth/crypto\";\nimport { verifyMessage, createPublicClient, http } from \"viem\";\nimport { mainnet } from \"viem/chains\";\nexport const auth = betterAuth({\n  database: {\n    // your database configuration\n  },\n  plugins: [\n    siwe({\n      domain: \"myapp.com\",\n      emailDomainName: \"myapp.com\",\n      anonymous: false,\n      getNonce: async () => {\n        // Generate a cryptographically secure random nonce\n        return generateRandomString(32);\n      },\n      verifyMessage: async ({ message, signature, address }) => {\n        try {\n          // Verify the signature using viem (recommended)\n          const isValid = await verifyMessage({\n            address: address as `0x${string}`,\n            message,\n            signature: signature as `0x${string}`,\n          });\n          return isValid;\n        } catch (error) {\n          console.error(\"SIWE verification failed:\", error);\n          return false;\n        }\n      },\n      ensLookup: async ({ walletAddress }) => {\n        try {\n          // Optional: lookup ENS name and avatar using viem\n          // You can use viem's ENS utilities here\n          const client = createPublicClient({\n            chain: mainnet,\n            transport: http(),\n          });\n          const ensName = await client.getEnsName({\n            address: walletAddress as `0x${string}`,\n          });\n          const ensAvatar = ensName\n            ? await client.getEnsAvatar({\n                name: ensName,\n              })\n            : null;\n          return {\n            name: ensName || walletAddress,\n            avatar: ensAvatar || \"\",\n          };\n        } catch {\n          return {\n            name: walletAddress,\n            avatar: \"\",\n          };\n        }\n      },\n    }),\n  ],\n});\nEdit on GitHub\n\nPrevious Page\n\nOne Tap\n\nNext Page\n\nAuthorization"
  },
  {
    "title": "MCP | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/mcp",
    "html": "MCP\nCopy Markdown\nOpen in\n\nOAuth MCP\n\nThe MCP plugin lets your app act as an OAuth provider for MCP clients. It handles authentication and makes it easy to issue and manage access tokens for MCP applications.\n\nInstallation\nAdd the Plugin\n\nAdd the MCP plugin to your auth configuration and specify the login page path.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { mcp } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [\n        mcp({\n            loginPage: \"/sign-in\" // path to your login page\n        })\n    ]\n});\n\nThis doesn't have a client plugin, so you don't need to make any changes to your authClient.\n\nGenerate Schema\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nThe MCP plugin uses the same schema as the OIDC Provider plugin. See the OIDC Provider Schema section for details.\n\nUsage\nOAuth Discovery Metadata\n\nBetter Auth already handles the /api/auth/.well-known/oauth-authorization-server route automatically but some client may fail to parse the WWW-Authenticate header and default to /.well-known/oauth-authorization-server (this can happen, for example, if your CORS configuration doesn't expose the WWW-Authenticate). For this reason it's better to add a route to expose OAuth metadata for MCP clients:\n\n.well-known/oauth-authorization-server/route.ts\nimport { oAuthDiscoveryMetadata } from \"better-auth/plugins\";\nimport { auth } from \"../../../lib/auth\";\nexport const GET = oAuthDiscoveryMetadata(auth);\nOAuth Protected Resource Metadata\n\nBetter Auth already handles the /api/auth/.well-known/oauth-protected-resource route automatically but some client may fail to parse the WWW-Authenticate header and default to /.well-known/oauth-protected-resource (this can happen, for example, if your CORS configuration doesn't expose the WWW-Authenticate). For this reason it's better to add a route to expose OAuth metadata for MCP clients:\n\n/.well-known/oauth-protected-resource/route.ts\nimport { oAuthProtectedResourceMetadata } from \"better-auth/plugins\";\nimport { auth } from \"@/lib/auth\";\nexport const GET = oAuthProtectedResourceMetadata(auth);\nMCP Session Handling\n\nYou can use the helper function withMcpAuth to get the session and handle unauthenticated calls automatically.\n\napi/[transport]/route.ts\nimport { auth } from \"@/lib/auth\";\nimport { createMcpHandler } from \"@vercel/mcp-adapter\";\nimport { withMcpAuth } from \"better-auth/plugins\";\nimport { z } from \"zod\";\nconst handler = withMcpAuth(auth, (req, session) => {\n    // session contains the access token record with scopes and user ID\n    return createMcpHandler(\n        (server) => {\n            server.tool(\n                \"echo\",\n                \"Echo a message\",\n                { message: z.string() },\n                async ({ message }) => {\n                    return {\n                        content: [{ type: \"text\", text: `Tool echo: ${message}` }],\n                    };\n                },\n            );\n        },\n        {\n            capabilities: {\n                tools: {\n                    echo: {\n                        description: \"Echo a message\",\n                    },\n                },\n            },\n        },\n        {\n            redisUrl: process.env.REDIS_URL,\n            basePath: \"/api\",\n            verboseLogs: true,\n            maxDuration: 60,\n        },\n    )(req);\n});\nexport { handler as GET, handler as POST, handler as DELETE };\n\nYou can also use auth.api.getMcpSession to get the session using the access token sent from the MCP client:\n\napi/[transport]/route.ts\nimport { auth } from \"@/lib/auth\";\nimport { createMcpHandler } from \"@vercel/mcp-adapter\";\nimport { z } from \"zod\";\nconst handler = async (req: Request) => {\n     // session contains the access token record with scopes and user ID\n    const session = await auth.api.getMcpSession({\n        headers: req.headers\n    })\n    if(!session){\n        //this is important and you must return 401\n        return new Response(null, {\n            status: 401\n        })\n    }\n    return createMcpHandler(\n        (server) => {\n            server.tool(\n                \"echo\",\n                \"Echo a message\",\n                { message: z.string() },\n                async ({ message }) => {\n                    return {\n                        content: [{ type: \"text\", text: `Tool echo: ${message}` }],\n                    };\n                },\n            );\n        },\n        {\n            capabilities: {\n                tools: {\n                    echo: {\n                        description: \"Echo a message\",\n                    },\n                },\n            },\n        },\n        {\n            redisUrl: process.env.REDIS_URL,\n            basePath: \"/api\",\n            verboseLogs: true,\n            maxDuration: 60,\n        },\n    )(req);\n}\nexport { handler as GET, handler as POST, handler as DELETE };\nConfiguration\n\nThe MCP plugin accepts the following configuration options:\n\nProp\n\nType\n\nloginPage\nstring\nresource?\nstring\noidcConfig?\nobject\nOIDC Configuration\n\nThe plugin supports additional OIDC configuration options through the oidcConfig parameter:\n\nProp\n\nType\n\ncodeExpiresIn?\nnumber\naccessTokenExpiresIn?\nnumber\nrefreshTokenExpiresIn?\nnumber\ndefaultScope?\nstring\nscopes?\nstring[]\nSchema\n\nThe MCP plugin uses the same schema as the OIDC Provider plugin. See the OIDC Provider Schema section for details.\n\nEdit on GitHub\n\nPrevious Page\n\nAPI Key\n\nNext Page\n\nOrganization"
  },
  {
    "title": "API Key | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/api-key",
    "html": "API Key\nCopy Markdown\nOpen in\n\nThe API Key plugin allows you to create and manage API keys for your application. It provides a way to authenticate and authorize API requests by verifying API keys.\n\nFeatures\nCreate, manage, and verify API keys\nBuilt-in rate limiting\nCustom expiration times, remaining count, and refill systems\nmetadata for API keys\nCustom prefix\nSessions from API keys\nInstallation\nAdd Plugin to the server\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { apiKey } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [ \n        apiKey() \n    ] \n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { apiKeyClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [ \n        apiKeyClient() \n    ] \n})\nUsage\n\nYou can view the list of API Key plugin options here.\n\nCreate an API key\nClient\nServer\nPOST\n/api-key/create\nNotes\n\nYou can adjust more specific API key configurations by using the server method instead.\n\nconst { data, error } = await authClient.apiKey.create({\n    name: 'project-api-key',\n    expiresIn: 60 * 60 * 24 * 7,\n    prefix: 'project-api-key',\n    metadata: { someKey: 'someValue' },\n    permissions,\n});\nProp\tDescription\tType\nname?\t\nName of the Api Key.\n\tstring\nexpiresIn?\t\nExpiration time of the Api Key in seconds.\n\tnumber\nprefix?\t\nPrefix of the Api Key.\n\tstring\nmetadata?\t\nMetadata of the Api Key.\n\tany | null\npermissions?\t\nPermissions of the Api Key.\n\tRecord<string, string[]>\nAPI keys are assigned to a user.\nResult\n\nIt'll return the ApiKey object which includes the key value for you to use. Otherwise if it throws, it will throw an APIError.\n\nVerify an API key\nClient\nServer\nPOST\n/api-key/verify\nconst permissions = { // Permissions to check are optional.\n  projects: [\"read\", \"read-write\"],\n}\nconst data = await auth.api.verifyApiKey({\n    body: {\n        key: \"your_api_key_here\", // required\n        permissions,\n    },\n});\nProp\tDescription\tType\nkey\t\nThe key to verify.\n\tstring\npermissions?\t\nThe permissions to verify. Optional.\n\tRecord<string, string[]>\nResult\ntype Result = {\n  valid: boolean;\n  error: { message: string; code: string } | null;\n  key: Omit<ApiKey, \"key\"> | null;\n};\nGet an API key\nClient\nServer\nGET\n/api-key/get\nconst { data, error } = await authClient.apiKey.get({\n    query: {\n        id: \"some-api-key-id\", // required\n    },\n});\nProp\tDescription\tType\nid\t\nThe id of the Api Key.\n\tstring\nResult\n\nYou'll receive everything about the API key details, except for the key value itself. If it fails, it will throw an APIError.\n\ntype Result = Omit<ApiKey, \"key\">;\nUpdate an API key\nClient\nServer\nPOST\n/api-key/update\nconst { data, error } = await authClient.apiKey.update({\n    keyId: \"some-api-key-id\", // required\n    name: \"some-api-key-name\",\n});\nProp\tDescription\tType\nkeyId\t\nThe id of the Api Key to update.\n\tstring\nname?\t\nThe name of the key.\n\tstring\nResult\n\nIf fails, throws APIError. Otherwise, you'll receive the API Key details, except for the key value itself.\n\nDelete an API Key\nClient\nServer\nPOST\n/api-key/delete\nNotes\n\nThis endpoint is attempting to delete the API key from the perspective of the user. It will check if the user's ID matches the key owner to be able to delete it. If you want to delete a key without these checks, we recommend you use an ORM to directly mutate your DB instead.\n\nconst { data, error } = await authClient.apiKey.delete({\n    keyId: \"some-api-key-id\", // required\n});\nProp\tDescription\tType\nkeyId\t\nThe id of the Api Key to delete.\n\tstring\nResult\n\nIf fails, throws APIError. Otherwise, you'll receive:\n\ntype Result = {\n  success: boolean;\n};\nList API keys\nClient\nServer\nGET\n/api-key/list\nconst { data, error } = await authClient.apiKey.list();\nResult\n\nIf fails, throws APIError. Otherwise, you'll receive:\n\ntype Result = ApiKey[];\nDelete all expired API keys\n\nThis function will delete all API keys that have an expired expiration date.\n\nClient\nServer\nPOST\n/api-key/delete-all-expired-api-keys\nconst data = await auth.api.deleteAllExpiredApiKeys();\n\nWe automatically delete expired API keys every time any apiKey plugin endpoints were called, however they are rate-limited to a 10 second cool down each call to prevent multiple calls to the database.\n\nSessions from API keys\n\nAny time an endpoint in Better Auth is called that has a valid API key in the headers, you can automatically create a mock session to represent the user by enabling sessionForAPIKeys option.\n\nThis is generally not recommended, as it can lead to security issues if not used carefully. A leaked api key can be used to impersonate a user.\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      enableSessionForAPIKeys: true,\n    }),\n  ],\n});\nServer\nconst session = await auth.api.getSession({\n      headers: new Headers({\n            'x-api-key': apiKey,\n      }),\n});\n\nThe default header key is x-api-key, but this can be changed by setting the apiKeyHeaders option in the plugin options.\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      apiKeyHeaders: [\"x-api-key\", \"xyz-api-key\"], // or you can pass just a string, eg: \"x-api-key\"\n    }),\n  ],\n});\n\nOr optionally, you can pass an apiKeyGetter function to the plugin options, which will be called with the GenericEndpointContext, and from there, you should return the API key, or null if the request is invalid.\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      apiKeyGetter: (ctx) => {\n        const has = ctx.request.headers.has(\"x-api-key\");\n        if (!has) return null;\n        return ctx.request.headers.get(\"x-api-key\");\n      },\n    }),\n  ],\n});\nRate Limiting\n\nEvery API key can have its own rate limit settings, however, the built-in rate-limiting only applies to the verification process for a given API key. For every other endpoint/method, you should utilize Better Auth's built-in rate-limiting.\n\nYou can refer to the rate-limit default configurations below in the API Key plugin options.\n\nAn example default value:\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      rateLimit: {\n        enabled: true,\n        timeWindow: 1000 * 60 * 60 * 24, // 1 day\n        maxRequests: 10, // 10 requests per day\n      },\n    }),\n  ],\n});\n\nFor each API key, you can customize the rate-limit options on create.\n\nYou can only customize the rate-limit options on the server auth instance.\n\nconst apiKey = await auth.api.createApiKey({\n  body: {\n    rateLimitEnabled: true,\n    rateLimitTimeWindow: 1000 * 60 * 60 * 24, // 1 day\n    rateLimitMax: 10, // 10 requests per day\n  },\n  headers: user_headers,\n});\nHow does it work?\n\nFor each request, a counter (internally called requestCount) is incremented. If the rateLimitMax is reached, the request will be rejected until the timeWindow has passed, at which point the timeWindow will be reset.\n\nRemaining, refill, and expiration\n\nThe remaining count is the number of requests left before the API key is disabled. The refill interval is the interval in milliseconds where the remaining count is refilled by day. The expiration time is the expiration date of the API key.\n\nHow does it work?\nRemaining:\n\nWhenever an API key is used, the remaining count is updated. If the remaining count is null, then there is no cap to key usage. Otherwise, the remaining count is decremented by 1. If the remaining count is 0, then the API key is disabled & removed.\n\nrefillInterval & refillAmount:\n\nWhenever an API key is created, the refillInterval and refillAmount are set to null. This means that the API key will not be refilled automatically. However, if refillInterval & refillAmount are set, then the API key will be refilled accordingly.\n\nExpiration:\n\nWhenever an API key is created, the expiresAt is set to null. This means that the API key will never expire. However, if the expiresIn is set, then the API key will expire after the expiresIn time.\n\nCustom Key generation & verification\n\nYou can customize the key generation and verification process straight from the plugin options.\n\nHere's an example:\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      customKeyGenerator: (options: {\n        length: number;\n        prefix: string | undefined;\n      }) => {\n        const apiKey = mySuperSecretApiKeyGenerator(\n          options.length,\n          options.prefix\n        );\n        return apiKey;\n      },\n      customAPIKeyValidator: async ({ ctx, key }) => {\n        const res = await keyService.verify(key)\n        return res.valid\n      },\n    }),\n  ],\n});\n\nIf you're not using the length property provided by customKeyGenerator, you must set the defaultKeyLength property to how long generated keys will be.\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      customKeyGenerator: () => {\n        return crypto.randomUUID();\n      },\n      defaultKeyLength: 36, // Or whatever the length is\n    }),\n  ],\n});\n\nIf an API key is validated from your customAPIKeyValidator, we still must match that against the database's key. However, by providing this custom function, you can improve the performance of the API key verification process, as all failed keys can be invalidated without having to query your database.\n\nMetadata\n\nWe allow you to store metadata alongside your API keys. This is useful for storing information about the key, such as a subscription plan for example.\n\nTo store metadata, make sure you haven't disabled the metadata feature in the plugin options.\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      enableMetadata: true,\n    }),\n  ],\n});\n\nThen, you can store metadata in the metadata field of the API key object.\n\nconst apiKey = await auth.api.createApiKey({\n  body: {\n    metadata: {\n      plan: \"premium\",\n    },\n  },\n});\n\nYou can then retrieve the metadata from the API key object.\n\nconst apiKey = await auth.api.getApiKey({\n  body: {\n    keyId: \"your_api_key_id_here\",\n  },\n});\nconsole.log(apiKey.metadata.plan); // \"premium\"\nAPI Key plugin options\n\napiKeyHeaders string | string[];\n\nThe header name to check for API key. Default is x-api-key.\n\ncustomAPIKeyGetter (ctx: GenericEndpointContext) => string | null\n\nA custom function to get the API key from the context.\n\ncustomAPIKeyValidator (options: { ctx: GenericEndpointContext; key: string; }) => boolean | Promise<boolean>\n\nA custom function to validate the API key.\n\ncustomKeyGenerator (options: { length: number; prefix: string | undefined; }) => string | Promise<string>\n\nA custom function to generate the API key.\n\nstartingCharactersConfig { shouldStore?: boolean; charactersLength?: number; }\n\nCustomize the starting characters configuration.\n\nstartingCharactersConfig Options\n\ndefaultKeyLength number\n\nThe length of the API key. Longer is better. Default is 64. (Doesn't include the prefix length)\n\ndefaultPrefix string\n\nThe prefix of the API key.\n\nNote: We recommend you append an underscore to the prefix to make the prefix more identifiable. (eg hello_)\n\nmaximumPrefixLength number\n\nThe maximum length of the prefix.\n\nminimumPrefixLength number\n\nThe minimum length of the prefix.\n\nrequireName boolean\n\nWhether to require a name for the API key. Default is false.\n\nmaximumNameLength number\n\nThe maximum length of the name.\n\nminimumNameLength number\n\nThe minimum length of the name.\n\nenableMetadata boolean\n\nWhether to enable metadata for an API key.\n\nkeyExpiration { defaultExpiresIn?: number | null; disableCustomExpiresTime?: boolean; minExpiresIn?: number; maxExpiresIn?: number; }\n\nCustomize the key expiration.\n\nkeyExpiration options\n\nrateLimit { enabled?: boolean; timeWindow?: number; maxRequests?: number; }\n\nCustomize the rate-limiting.\n\nrateLimit options\n\nschema InferOptionSchema<ReturnType<typeof apiKeySchema>>\n\nCustom schema for the API key plugin.\n\nenableSessionForAPIKeys boolean\n\nAn API Key can represent a valid session, so we can mock a session for the user if we find a valid API key in the request headers. Default is false.\n\npermissions { defaultPermissions?: Statements | ((userId: string, ctx: GenericEndpointContext) => Statements | Promise<Statements>) }\n\nPermissions for the API key.\n\nRead more about permissions here.\n\npermissions Options\n\ndisableKeyHashing boolean\n\nDisable hashing of the API key.\n\n⚠️ Security Warning: It's strongly recommended to not disable hashing. Storing API keys in plaintext makes them vulnerable to database breaches, potentially exposing all your users' API keys.\n\nPermissions\n\nAPI keys can have permissions associated with them, allowing you to control access at a granular level. Permissions are structured as a record of resource types to arrays of allowed actions.\n\nSetting Default Permissions\n\nYou can configure default permissions that will be applied to all newly created API keys:\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      permissions: {\n        defaultPermissions: {\n          files: [\"read\"],\n          users: [\"read\"],\n        },\n      },\n    }),\n  ],\n});\n\nYou can also provide a function that returns permissions dynamically:\n\nexport const auth = betterAuth({\n  plugins: [\n    apiKey({\n      permissions: {\n        defaultPermissions: async (userId, ctx) => {\n          // Fetch user role or other data to determine permissions\n          return {\n            files: [\"read\"],\n            users: [\"read\"],\n          };\n        },\n      },\n    }),\n  ],\n});\nCreating API Keys with Permissions\n\nWhen creating an API key, you can specify custom permissions:\n\nconst apiKey = await auth.api.createApiKey({\n  body: {\n    name: \"My API Key\",\n    permissions: {\n      files: [\"read\", \"write\"],\n      users: [\"read\"],\n    },\n    userId: \"userId\",\n  },\n});\nVerifying API Keys with Required Permissions\n\nWhen verifying an API key, you can check if it has the required permissions:\n\nconst result = await auth.api.verifyApiKey({\n  body: {\n    key: \"your_api_key_here\",\n    permissions: {\n      files: [\"read\"],\n    },\n  },\n});\nif (result.valid) {\n  // API key is valid and has the required permissions\n} else {\n  // API key is invalid or doesn't have the required permissions\n}\nUpdating API Key Permissions\n\nYou can update the permissions of an existing API key:\n\nconst apiKey = await auth.api.updateApiKey({\n  body: {\n    keyId: existingApiKeyId,\n    permissions: {\n      files: [\"read\", \"write\", \"delete\"],\n      users: [\"read\", \"write\"],\n    },\n  },\n  headers: user_headers,\n});\nPermissions Structure\n\nPermissions follow a resource-based structure:\n\ntype Permissions = {\n  [resourceType: string]: string[];\n};\n// Example:\nconst permissions = {\n  files: [\"read\", \"write\", \"delete\"],\n  users: [\"read\"],\n  projects: [\"read\", \"write\"],\n};\n\nWhen verifying an API key, all required permissions must be present in the API key's permissions for validation to succeed.\n\nSchema\n\nTable: apiKey\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tThe ID of the API key.\nname\tstring\t?\tThe name of the API key.\nstart\tstring\t?\tThe starting characters of the API key. Useful for showing the first few characters of the API key in the UI for the users to easily identify.\nprefix\tstring\t?\tThe API Key prefix. Stored as plain text.\nkey\tstring\t-\tThe hashed API key itself.\nuserId\tstring\t\nFK\tThe ID of the user associated with the API key.\nrefillInterval\tnumber\t?\tThe interval to refill the key in milliseconds.\nrefillAmount\tnumber\t?\tThe amount to refill the remaining count of the key.\nlastRefillAt\tDate\t?\tThe date and time when the key was last refilled.\nenabled\tboolean\t-\tWhether the API key is enabled.\nrateLimitEnabled\tboolean\t-\tWhether the API key has rate limiting enabled.\nrateLimitTimeWindow\tnumber\t?\tThe time window in milliseconds for the rate limit.\nrateLimitMax\tnumber\t?\tThe maximum number of requests allowed within the `rateLimitTimeWindow`.\nrequestCount\tnumber\t-\tThe number of requests made within the rate limit time window.\nremaining\tnumber\t?\tThe number of requests remaining.\nlastRequest\tDate\t?\tThe date and time of the last request made to the key.\nexpiresAt\tDate\t?\tThe date and time when the key will expire.\ncreatedAt\tDate\t-\tThe date and time the API key was created.\nupdatedAt\tDate\t-\tThe date and time the API key was updated.\npermissions\tstring\t?\tThe permissions of the key.\nmetadata\tObject\t?\tAny additional metadata you want to store with the key.\nEdit on GitHub\n\nPrevious Page\n\nAdmin\n\nNext Page\n\nMCP"
  },
  {
    "title": "OIDC Provider | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/oidc-provider",
    "html": "OIDC Provider\nCopy Markdown\nOpen in\n\nThe OIDC Provider Plugin enables you to build and manage your own OpenID Connect (OIDC) provider, granting full control over user authentication without relying on third-party services like Okta or Azure AD. It also allows other services to authenticate users through your OIDC provider.\n\nKey Features:\n\nClient Registration: Register clients to authenticate with your OIDC provider.\nDynamic Client Registration: Allow clients to register dynamically.\nTrusted Clients: Configure hard-coded trusted clients with optional consent bypass.\nAuthorization Code Flow: Support the Authorization Code Flow.\nPublic Clients: Support public clients for SPA, mobile apps, CLI tools, etc.\nJWKS Endpoint: Publish a JWKS endpoint to allow clients to verify tokens. (Not fully implemented)\nRefresh Tokens: Issue refresh tokens and handle access token renewal using the refresh_token grant.\nOAuth Consent: Implement OAuth consent screens for user authorization, with an option to bypass consent for trusted applications.\nUserInfo Endpoint: Provide a UserInfo endpoint for clients to retrieve user details.\n\nThis plugin is in active development and may not be suitable for production use. Please report any issues or bugs on GitHub.\n\nInstallation\nMount the Plugin\n\nAdd the OIDC plugin to your auth config. See OIDC Configuration on how to configure the plugin.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { oidcProvider } from \"better-auth/plugins\";\nconst auth = betterAuth({\n    plugins: [oidcProvider({\n        loginPage: \"/sign-in\", // path to the login page\n        // ...other options\n    })]\n})\nMigrate the Database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the Client Plugin\n\nAdd the OIDC client plugin to your auth client config.\n\nimport { createAuthClient } from \"better-auth/client\";\nimport { oidcClient } from \"better-auth/client/plugins\"\nconst authClient = createAuthClient({\n    plugins: [oidcClient({\n        // Your OIDC configuration\n    })]\n})\nUsage\n\nOnce installed, you can utilize the OIDC Provider to manage authentication flows within your application.\n\nRegister a New Client\n\nTo register a new OIDC client, use the oauth2.register method.\n\nSimple Example\nconst application = await client.oauth2.register({\n    client_name: \"My Client\",\n    redirect_uris: [\"https://client.example.com/callback\"],\n});\nFull Method\nClient\nServer\nPOST\n/oauth2/register\nconst { data, error } = await authClient.oauth2.register({\n    redirect_uris: [\"https://client.example.com/callback\"], // required\n    token_endpoint_auth_method: \"client_secret_basic\",\n    grant_types: [\"authorization_code\"],\n    response_types: [\"code\"],\n    client_name: \"My App\",\n    client_uri: \"https://client.example.com\",\n    logo_uri: \"https://client.example.com/logo.png\",\n    scope: \"profile email\",\n    contacts: [\"admin@example.com\"],\n    tos_uri: \"https://client.example.com/tos\",\n    policy_uri: \"https://client.example.com/policy\",\n    jwks_uri: \"https://client.example.com/jwks\",\n    jwks: {\"keys\": [{\"kty\": \"RSA\", \"alg\": \"RS256\", \"use\": \"sig\", \"n\": \"...\", \"e\": \"...\"}]},\n    metadata: {\"key\": \"value\"},\n    software_id: \"my-software\",\n    software_version: \"1.0.0\",\n    software_statement,\n});\nProp\tDescription\tType\nredirect_uris\t\nA list of redirect URIs.\n\tstring[]\ntoken_endpoint_auth_method?\t\nThe authentication method for the token endpoint.\n\t\"none\" | \"client_secret_basic\" | \"client_secret_post\"\ngrant_types?\t\nThe grant types supported by the application.\n\t(\"authorization_code\" | \"implicit\" | \"password\" | \"client_credentials\" | \"refresh_token\" | \"urn:ietf:params:oauth:grant-type:jwt-bearer\" | \"urn:ietf:params:oauth:grant-type:saml2-bearer\")[]\nresponse_types?\t\nThe response types supported by the application.\n\t(\"code\" | \"token\")[]\nclient_name?\t\nThe name of the application.\n\tstring\nclient_uri?\t\nThe URI of the application.\n\tstring\nlogo_uri?\t\nThe URI of the application logo.\n\tstring\nscope?\t\nThe scopes supported by the application. Separated by spaces.\n\tstring\ncontacts?\t\nThe contact information for the application.\n\tstring[]\ntos_uri?\t\nThe URI of the application terms of service.\n\tstring\npolicy_uri?\t\nThe URI of the application privacy policy.\n\tstring\njwks_uri?\t\nThe URI of the application JWKS.\n\tstring\njwks?\t\nThe JWKS of the application.\n\tRecord<string, any>\nmetadata?\t\nThe metadata of the application.\n\tRecord<string, any>\nsoftware_id?\t\nThe software ID of the application.\n\tstring\nsoftware_version?\t\nThe software version of the application.\n\tstring\nsoftware_statement?\t\nThe software statement of the application.\n\tstring\n\nThis endpoint supports RFC7591 compliant client registration.\n\nOnce the application is created, you will receive a client_id and client_secret that you can display to the user.\n\nTrusted Clients\n\nFor first-party applications and internal services, you can configure trusted clients directly in your OIDC provider configuration. Trusted clients bypass database lookups for better performance and can optionally skip consent screens for improved user experience.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { oidcProvider } from \"better-auth/plugins\";\nconst auth = betterAuth({\n    plugins: [\n      oidcProvider({\n        loginPage: \"/sign-in\",\n        trustedClients: [\n            {\n                clientId: \"internal-dashboard\",\n                clientSecret: \"secure-secret-here\",\n                name: \"Internal Dashboard\",\n                type: \"web\",\n                redirectURLs: [\"https://dashboard.company.com/auth/callback\"],\n                disabled: false,\n                skipConsent: true, // Skip consent for this trusted client\n                metadata: { internal: true }\n            },\n            {\n                clientId: \"mobile-app\",\n                clientSecret: \"mobile-secret\", \n                name: \"Company Mobile App\",\n                type: \"native\",\n                redirectURLs: [\"com.company.app://auth\"],\n                disabled: false,\n                skipConsent: false, // Still require consent if needed\n                metadata: {}\n            }\n        ]\n    })]\n})\nUserInfo Endpoint\n\nThe OIDC Provider includes a UserInfo endpoint that allows clients to retrieve information about the authenticated user. This endpoint is available at /oauth2/userinfo and requires a valid access token.\n\nGET\n/oauth2/userinfo\nclient-app.ts\n// Example of how a client would use the UserInfo endpoint\nconst response = await fetch('https://your-domain.com/api/auth/oauth2/userinfo', {\n  headers: {\n    'Authorization': 'Bearer ACCESS_TOKEN'\n  }\n});\nconst userInfo = await response.json();\n// userInfo contains user details based on the scopes granted\n\nThe UserInfo endpoint returns different claims based on the scopes that were granted during authorization:\n\nWith openid scope: Returns the user's ID (sub claim)\nWith profile scope: Returns name, picture, given_name, family_name\nWith email scope: Returns email and email_verified\n\nThe getAdditionalUserInfoClaim function receives the user object, requested scopes array, and the client, allowing you to conditionally include claims based on the scopes granted during authorization. These additional claims will be included in both the UserInfo endpoint response and the ID token.\n\nConsent Screen\n\nWhen a user is redirected to the OIDC provider for authentication, they may be prompted to authorize the application to access their data. This is known as the consent screen. By default, Better Auth will display a sample consent screen. You can customize the consent screen by providing a consentPage option during initialization.\n\nNote: Trusted clients with skipConsent: true will bypass the consent screen entirely, providing a seamless experience for first-party applications.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    plugins: [oidcProvider({\n        consentPage: \"/path/to/consent/page\"\n    })]\n})\n\nThe plugin will redirect the user to the specified path with consent_code, client_id and scope query parameters. You can use this information to display a custom consent screen. Once the user consents, you can call oauth2.consent to complete the authorization.\n\nPOST\n/oauth2/consent\n\nThe consent endpoint supports two methods for passing the consent code:\n\nMethod 1: URL Parameter\n\nconsent-page.ts\n// Get the consent code from the URL\nconst params = new URLSearchParams(window.location.search);\n// Submit consent with the code in the request body\nconst consentCode = params.get('consent_code');\nif (!consentCode) {\n\tthrow new Error('Consent code not found in URL parameters');\n}\nconst res = await client.oauth2.consent({\n\taccept: true, // or false to deny\n\tconsent_code: consentCode,\n});\n\nMethod 2: Cookie-Based\n\nconsent-page.ts\n// The consent code is automatically stored in a signed cookie\n// Just submit the consent decision\nconst res = await client.oauth2.consent({\n\taccept: true, // or false to deny\n\t// consent_code not needed when using cookie-based flow\n});\n\nBoth methods are fully supported. The URL parameter method works well with mobile apps and third-party contexts, while the cookie-based method provides a simpler implementation for web applications.\n\nHandling Login\n\nWhen a user is redirected to the OIDC provider for authentication, if they are not already logged in, they will be redirected to the login page. You can customize the login page by providing a loginPage option during initialization.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    plugins: [oidcProvider({\n        loginPage: \"/sign-in\"\n    })]\n})\n\nYou don't need to handle anything from your side; when a new session is created, the plugin will handle continuing the authorization flow.\n\nConfiguration\nOIDC Metadata\n\nCustomize the OIDC metadata by providing a configuration object during initialization.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { oidcProvider } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [oidcProvider({\n        metadata: {\n            issuer: \"https://your-domain.com\",\n            authorization_endpoint: \"/custom/oauth2/authorize\",\n            token_endpoint: \"/custom/oauth2/token\",\n            // ...other custom metadata\n        }\n    })]\n})\nJWKS Endpoint\n\nThe OIDC Provider plugin can integrate with the JWT plugin to provide asymmetric key signing for ID tokens verifiable at a JWKS endpoint.\n\nTo make your plugin OIDC compliant, you MUST disable the /token endpoint, the OAuth equivalent is located at /oauth2/token instead.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { oidcProvider } from \"better-auth/plugins\";\nimport { jwt } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    disabledPaths: [\n        \"/token\",\n    ],\n    plugins: [\n        jwt(), // Make sure to add the JWT plugin\n        oidcProvider({\n            useJWTPlugin: true, // Enable JWT plugin integration\n            loginPage: \"/sign-in\",\n            // ... other options\n        })\n    ]\n})\n\nWhen useJWTPlugin: false (default), ID tokens are signed with the application secret.\n\nDynamic Client Registration\n\nIf you want to allow clients to register dynamically, you can enable this feature by setting the allowDynamicClientRegistration option to true.\n\nauth.ts\nconst auth = betterAuth({\n    plugins: [oidcProvider({\n        allowDynamicClientRegistration: true,\n    })]\n})\n\nThis will allow clients to register using the /register endpoint to be publicly available.\n\nSchema\n\nThe OIDC Provider plugin adds the following tables to the database:\n\nOAuth Application\n\nTable Name: oauthApplication\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tDatabase ID of the OAuth client\nclientId\tstring\t\nPK\tUnique identifier for each OAuth client\nclientSecret\tstring\t?\tSecret key for the OAuth client. Optional for public clients using PKCE.\nname\tstring\t-\tName of the OAuth client\nredirectURLs\tstring\t-\tComma-separated list of redirect URLs\nmetadata\tstring\t?\tAdditional metadata for the OAuth client\ntype\tstring\t-\tType of OAuth client (e.g., web, mobile)\ndisabled\tboolean\t-\tIndicates if the client is disabled\nuserId\tstring\t?\tID of the user who owns the client. (optional)\ncreatedAt\tDate\t-\tTimestamp of when the OAuth client was created\nupdatedAt\tDate\t-\tTimestamp of when the OAuth client was last updated\nOAuth Access Token\n\nTable Name: oauthAccessToken\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tDatabase ID of the access token\naccessToken\tstring\t-\tAccess token issued to the client\nrefreshToken\tstring\t-\tRefresh token issued to the client\naccessTokenExpiresAt\tDate\t-\tExpiration date of the access token\nrefreshTokenExpiresAt\tDate\t-\tExpiration date of the refresh token\nclientId\tstring\t\nFK\tID of the OAuth client\nuserId\tstring\t\nFK\tID of the user associated with the token\nscopes\tstring\t-\tComma-separated list of scopes granted\ncreatedAt\tDate\t-\tTimestamp of when the access token was created\nupdatedAt\tDate\t-\tTimestamp of when the access token was last updated\nOAuth Consent\n\nTable Name: oauthConsent\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tDatabase ID of the consent\nuserId\tstring\t\nFK\tID of the user who gave consent\nclientId\tstring\t\nFK\tID of the OAuth client\nscopes\tstring\t-\tComma-separated list of scopes consented to\nconsentGiven\tboolean\t-\tIndicates if consent was given\ncreatedAt\tDate\t-\tTimestamp of when the consent was given\nupdatedAt\tDate\t-\tTimestamp of when the consent was last updated\nOptions\n\nallowDynamicClientRegistration: boolean - Enable or disable dynamic client registration.\n\nmetadata: OIDCMetadata - Customize the OIDC provider metadata.\n\nloginPage: string - Path to the custom login page.\n\nconsentPage: string - Path to the custom consent page.\n\ntrustedClients: (Client & { skipConsent?: boolean })[] - Array of trusted clients that are configured directly in the provider options. These clients bypass database lookups and can optionally skip consent screens.\n\ngetAdditionalUserInfoClaim: (user: User, scopes: string[], client: Client) => Record<string, any> - Function to get additional user info claims.\n\nuseJWTPlugin: boolean - When true, ID tokens are signed using the JWT plugin's asymmetric keys. When false (default), ID tokens are signed with HMAC-SHA256 using the application secret.\n\nschema: AuthPluginSchema - Customize the OIDC provider schema.\n\nEdit on GitHub\n\nPrevious Page\n\nEnterprise\n\nNext Page\n\nSSO"
  },
  {
    "title": "Organization | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/organization",
    "html": "Organization\nCopy Markdown\nOpen in\n\nOrganizations simplifies user access and permissions management. Assign roles and permissions to streamline project management, team coordination, and partnerships.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { organization } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [ \n        organization() \n    ] \n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { organizationClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [ \n        organizationClient() \n    ] \n})\nUsage\n\nOnce you've installed the plugin, you can start using the organization plugin to manage your organization's members and teams. The client plugin will provide you with methods under the organization namespace, and the server api will provide you with the necessary endpoints to manage your organization and give you an easier way to call the functions on your own backend.\n\nOrganization\nCreate an organization\nClient\nServer\nPOST\n/organization/create\nconst metadata = { someKey: \"someValue\" };\nconst { data, error } = await authClient.organization.create({\n    name: \"My Organization\", // required\n    slug: \"my-org\", // required\n    logo: \"https://example.com/logo.png\",\n    metadata,\n    keepCurrentActiveOrganization: false,\n});\nProp\tDescription\tType\nname\t\nThe organization name.\n\tstring\nslug\t\nThe organization slug.\n\tstring\nlogo?\t\nThe organization logo.\n\tstring\nmetadata?\t\nThe metadata of the organization.\n\tRecord<string, any>\nkeepCurrentActiveOrganization?\t\nWhether to keep the current active organization active after creating a new one.\n\tboolean\nRestrict who can create an organization\n\nBy default, any user can create an organization. To restrict this, set the allowUserToCreateOrganization option to a function that returns a boolean, or directly to true or false.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nconst auth = betterAuth({\n  //...\n  plugins: [\n    organization({\n      allowUserToCreateOrganization: async (user) => {\n        const subscription = await getSubscription(user.id); \n        return subscription.plan === \"pro\"; \n      }, \n    }),\n  ],\n});\nCheck if organization slug is taken\n\nTo check if an organization slug is taken or not you can use the checkSlug function provided by the client. The function takes an object with the following properties:\n\nClient\nServer\nPOST\n/organization/check-slug\nconst { data, error } = await authClient.organization.checkSlug({\n    slug: \"my-org\", // required\n});\nProp\tDescription\tType\nslug\t\nThe organization slug to check.\n\tstring\nOrganization Hooks\n\nYou can customize organization operations using hooks that run before and after various organization-related activities. Better Auth provides two ways to configure hooks:\n\nLegacy organizationCreation hooks (deprecated, use organizationHooks instead)\nModern organizationHooks (recommended) - provides comprehensive control over all organization-related activities\nOrganization Creation and Management Hooks\n\nControl organization lifecycle operations:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      organizationHooks: {\n        // Organization creation hooks\n        beforeCreateOrganization: async ({ organization, user }) => {\n          // Run custom logic before organization is created\n          // Optionally modify the organization data\n          return {\n            data: {\n              ...organization,\n              metadata: {\n                customField: \"value\",\n              },\n            },\n          };\n        },\n        afterCreateOrganization: async ({ organization, member, user }) => {\n          // Run custom logic after organization is created\n          // e.g., create default resources, send notifications\n          await setupDefaultResources(organization.id);\n        },\n        // Organization update hooks\n        beforeUpdateOrganization: async ({ organization, user, member }) => {\n          // Validate updates, apply business rules\n          return {\n            data: {\n              ...organization,\n              name: organization.name?.toLowerCase(),\n            },\n          };\n        },\n        afterUpdateOrganization: async ({ organization, user, member }) => {\n          // Sync changes to external systems\n          await syncOrganizationToExternalSystems(organization);\n        },\n      },\n    }),\n  ],\n});\n\nThe legacy organizationCreation hooks are still supported but deprecated. Use organizationHooks.beforeCreateOrganization and organizationHooks.afterCreateOrganization instead for new projects.\n\nMember Hooks\n\nControl member operations within organizations:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      organizationHooks: {\n        // Before a member is added to an organization\n        beforeAddMember: async ({ member, user, organization }) => {\n          // Custom validation or modification\n          console.log(`Adding ${user.email} to ${organization.name}`);\n          // Optionally modify member data\n          return {\n            data: {\n              ...member,\n              role: \"custom-role\", // Override the role\n            },\n          };\n        },\n        // After a member is added\n        afterAddMember: async ({ member, user, organization }) => {\n          // Send welcome email, create default resources, etc.\n          await sendWelcomeEmail(user.email, organization.name);\n        },\n        // Before a member is removed\n        beforeRemoveMember: async ({ member, user, organization }) => {\n          // Cleanup user's resources, send notification, etc.\n          await cleanupUserResources(user.id, organization.id);\n        },\n        // After a member is removed\n        afterRemoveMember: async ({ member, user, organization }) => {\n          await logMemberRemoval(user.id, organization.id);\n        },\n        // Before updating a member's role\n        beforeUpdateMemberRole: async ({\n          member,\n          newRole,\n          user,\n          organization,\n        }) => {\n          // Validate role change permissions\n          if (newRole === \"owner\" && !hasOwnerUpgradePermission(user)) {\n            throw new Error(\"Cannot upgrade to owner role\");\n          }\n          // Optionally modify the role\n          return {\n            data: {\n              role: newRole,\n            },\n          };\n        },\n        // After updating a member's role\n        afterUpdateMemberRole: async ({\n          member,\n          previousRole,\n          user,\n          organization,\n        }) => {\n          await logRoleChange(user.id, previousRole, member.role);\n        },\n      },\n    }),\n  ],\n});\nInvitation Hooks\n\nControl invitation lifecycle:\n\nauth.ts\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      organizationHooks: {\n        // Before creating an invitation\n        beforeCreateInvitation: async ({\n          invitation,\n          inviter,\n          organization,\n        }) => {\n          // Custom validation or expiration logic\n          const customExpiration = new Date(\n            Date.now() + 1000 * 60 * 60 * 24 * 7\n          ); // 7 days\n          return {\n            data: {\n              ...invitation,\n              expiresAt: customExpiration,\n            },\n          };\n        },\n        // After creating an invitation\n        afterCreateInvitation: async ({\n          invitation,\n          inviter,\n          organization,\n        }) => {\n          // Send custom invitation email, track metrics, etc.\n          await sendCustomInvitationEmail(invitation, organization);\n        },\n        // Before accepting an invitation\n        beforeAcceptInvitation: async ({ invitation, user, organization }) => {\n          // Additional validation before acceptance\n          await validateUserEligibility(user, organization);\n        },\n        // After accepting an invitation\n        afterAcceptInvitation: async ({\n          invitation,\n          member,\n          user,\n          organization,\n        }) => {\n          // Setup user account, assign default resources\n          await setupNewMemberResources(user, organization);\n        },\n        // Before/after rejecting invitations\n        beforeRejectInvitation: async ({ invitation, user, organization }) => {\n          // Log rejection reason, send notification to inviter\n        },\n        afterRejectInvitation: async ({ invitation, user, organization }) => {\n          await notifyInviterOfRejection(invitation.inviterId, user.email);\n        },\n        // Before/after cancelling invitations\n        beforeCancelInvitation: async ({\n          invitation,\n          cancelledBy,\n          organization,\n        }) => {\n          // Verify cancellation permissions\n        },\n        afterCancelInvitation: async ({\n          invitation,\n          cancelledBy,\n          organization,\n        }) => {\n          await logInvitationCancellation(invitation.id, cancelledBy.id);\n        },\n      },\n    }),\n  ],\n});\nTeam Hooks\n\nControl team operations (when teams are enabled):\n\nauth.ts\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      teams: { enabled: true },\n      organizationHooks: {\n        // Before creating a team\n        beforeCreateTeam: async ({ team, user, organization }) => {\n          // Validate team name, apply naming conventions\n          return {\n            data: {\n              ...team,\n              name: team.name.toLowerCase().replace(/\\s+/g, \"-\"),\n            },\n          };\n        },\n        // After creating a team\n        afterCreateTeam: async ({ team, user, organization }) => {\n          // Create default team resources, channels, etc.\n          await createDefaultTeamResources(team.id);\n        },\n        // Before updating a team\n        beforeUpdateTeam: async ({ team, updates, user, organization }) => {\n          // Validate updates, apply business rules\n          return {\n            data: {\n              ...updates,\n              name: updates.name?.toLowerCase(),\n            },\n          };\n        },\n        // After updating a team\n        afterUpdateTeam: async ({ team, user, organization }) => {\n          await syncTeamChangesToExternalSystems(team);\n        },\n        // Before deleting a team\n        beforeDeleteTeam: async ({ team, user, organization }) => {\n          // Backup team data, notify members\n          await backupTeamData(team.id);\n        },\n        // After deleting a team\n        afterDeleteTeam: async ({ team, user, organization }) => {\n          await cleanupTeamResources(team.id);\n        },\n        // Team member operations\n        beforeAddTeamMember: async ({\n          teamMember,\n          team,\n          user,\n          organization,\n        }) => {\n          // Validate team membership limits, permissions\n          const memberCount = await getTeamMemberCount(team.id);\n          if (memberCount >= 10) {\n            throw new Error(\"Team is full\");\n          }\n        },\n        afterAddTeamMember: async ({\n          teamMember,\n          team,\n          user,\n          organization,\n        }) => {\n          await grantTeamAccess(user.id, team.id);\n        },\n        beforeRemoveTeamMember: async ({\n          teamMember,\n          team,\n          user,\n          organization,\n        }) => {\n          // Backup user's team-specific data\n          await backupTeamMemberData(user.id, team.id);\n        },\n        afterRemoveTeamMember: async ({\n          teamMember,\n          team,\n          user,\n          organization,\n        }) => {\n          await revokeTeamAccess(user.id, team.id);\n        },\n      },\n    }),\n  ],\n});\nHook Error Handling\n\nAll hooks support error handling. Throwing an error in a before hook will prevent the operation from proceeding:\n\nauth.ts\nimport { APIError } from \"better-auth/api\";\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      organizationHooks: {\n        beforeAddMember: async ({ member, user, organization }) => {\n          // Check if user has pending violations\n          const violations = await checkUserViolations(user.id);\n          if (violations.length > 0) {\n            throw new APIError(\"BAD_REQUEST\", {\n              message:\n                \"User has pending violations and cannot join organizations\",\n            });\n          }\n        },\n        beforeCreateTeam: async ({ team, user, organization }) => {\n          // Validate team name uniqueness\n          const existingTeam = await findTeamByName(team.name, organization.id);\n          if (existingTeam) {\n            throw new APIError(\"BAD_REQUEST\", {\n              message: \"Team name already exists in this organization\",\n            });\n          }\n        },\n      },\n    }),\n  ],\n});\nList User's Organizations\n\nTo list the organizations that a user is a member of, you can use useListOrganizations hook. It implements a reactive way to get the organizations that the user is a member of.\n\nReact\nVue\nSvelte\nclient.tsx\nimport { authClient } from \"@/lib/auth-client\"\nfunction App(){\nconst { data: organizations } = authClient.useListOrganizations()\nreturn (\n  <div>\n    {organizations.map((org) => (\n      <p>{org.name}</p>\n    ))}\n  </div>)\n}\n\nOr alternatively, you can call organization.list if you don't want to use a hook.\n\nClient\nServer\nGET\n/organization/list\nconst { data, error } = await authClient.organization.list();\nActive Organization\n\nActive organization is the workspace the user is currently working on. By default when the user is signed in the active organization is set to null. You can set the active organization to the user session.\n\nIt's not always you want to persist the active organization in the session. You can manage the active organization in the client side only. For example, multiple tabs can have different active organizations.\n\nSet Active Organization\n\nYou can set the active organization by calling the organization.setActive function. It'll set the active organization for the user session.\n\nIn some applications, you may want the ability to unset an active organization. In this case, you can call this endpoint with organizationId set to null.\n\nClient\nServer\nPOST\n/organization/set-active\nconst { data, error } = await authClient.organization.setActive({\n    organizationId: \"org-id\",\n    organizationSlug: \"org-slug\",\n});\nProp\tDescription\tType\norganizationId?\t\nThe organization ID to set as active. It can be null to unset the active organization.\n\tstring | null\norganizationSlug?\t\nThe organization slug to set as active. It can be null to unset the active organization if organizationId is not provided.\n\tstring\n\nTo set active organization when a session is created you can use database hooks.\n\nauth.ts\nexport const auth = betterAuth({\n  databaseHooks: {\n    session: {\n      create: {\n        before: async (session) => {\n          const organization = await getActiveOrganization(session.userId);\n          return {\n            data: {\n              ...session,\n              activeOrganizationId: organization.id,\n            },\n          };\n        },\n      },\n    },\n  },\n});\nUse Active Organization\n\nTo retrieve the active organization for the user, you can call the useActiveOrganization hook. It returns the active organization for the user. Whenever the active organization changes, the hook will re-evaluate and return the new active organization.\n\nReact\nVue\nSvelte\nclient.tsx\nimport { authClient } from \"@/lib/auth-client\"\nfunction App(){\n    const { data: activeOrganization } = authClient.useActiveOrganization()\n    return (\n        <div>\n            {activeOrganization ? <p>{activeOrganization.name}</p> : null}\n        </div>\n    )\n}\nGet Full Organization\n\nTo get the full details of an organization, you can use the getFullOrganization function. By default, if you don't pass any properties, it will use the active organization.\n\nClient\nServer\nGET\n/organization/get-full-organization\nconst { data, error } = await authClient.organization.getFullOrganization({\n    query: {\n        organizationId: \"org-id\",\n        organizationSlug: \"org-slug\",\n        membersLimit: 100,\n    },\n});\nProp\tDescription\tType\norganizationId?\t\nThe organization ID to get. By default, it will use the active organization.\n\tstring\norganizationSlug?\t\nThe organization slug to get.\n\tstring\nmembersLimit?\t\nThe limit of members to get. By default, it uses the membershipLimit option which defaults to 100.\n\tnumber\nUpdate Organization\n\nTo update organization info, you can use organization.update\n\nClient\nServer\nPOST\n/organization/update\nconst { data, error } = await authClient.organization.update({\n    data: { // required\n        name: \"updated-name\",\n        slug: \"updated-slug\",\n        logo: \"new-logo.url\",\n        metadata: { customerId: \"test\" },\n    },\n    organizationId: \"org-id\",\n});\nProp\tDescription\tType\ndata\t\nA partial list of data to update the organization.\n\tObject\ndata.name?\t\nThe name of the organization.\n\tstring\ndata.slug?\t\nThe slug of the organization.\n\tstring\ndata.logo?\t\nThe logo of the organization.\n\tstring\ndata.metadata?\t\nThe metadata of the organization.\n\tRecord<string, any> | null\norganizationId?\t\nThe organization ID. to update.\n\tstring\nDelete Organization\n\nTo remove user owned organization, you can use organization.delete\n\nClient\nServer\nPOST\n/organization/delete\nconst { data, error } = await authClient.organization.delete({\n    organizationId: \"org-id\", // required\n});\nProp\tDescription\tType\norganizationId\t\nThe organization ID to delete.\n\tstring\n\nIf the user has the necessary permissions (by default: role is owner) in the specified organization, all members, invitations and organization information will be removed.\n\nYou can configure how organization deletion is handled through organizationDeletion option:\n\nconst auth = betterAuth({\n  plugins: [\n    organization({\n      disableOrganizationDeletion: true, //to disable it altogether\n      organizationHooks: {\n        beforeDeleteOrganization: async (data, request) => {\n          // a callback to run before deleting org\n        },\n        afterDeleteOrganization: async (data, request) => {\n          // a callback to run after deleting org\n        },\n      },\n    }),\n  ],\n});\nInvitations\n\nTo add a member to an organization, we first need to send an invitation to the user. The user will receive an email/sms with the invitation link. Once the user accepts the invitation, they will be added to the organization.\n\nSetup Invitation Email\n\nFor member invitation to work we first need to provide sendInvitationEmail to the better-auth instance. This function is responsible for sending the invitation email to the user.\n\nYou'll need to construct and send the invitation link to the user. The link should include the invitation ID, which will be used with the acceptInvitation function when the user clicks on it.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nimport { sendOrganizationInvitation } from \"./email\";\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      async sendInvitationEmail(data) {\n        const inviteLink = `https://example.com/accept-invitation/${data.id}`;\n        sendOrganizationInvitation({\n          email: data.email,\n          invitedByUsername: data.inviter.user.name,\n          invitedByEmail: data.inviter.user.email,\n          teamName: data.organization.name,\n          inviteLink,\n        });\n      },\n    }),\n  ],\n});\nSend Invitation\n\nTo invite users to an organization, you can use the invite function provided by the client. The invite function takes an object with the following properties:\n\nClient\nServer\nPOST\n/organization/invite-member\nconst { data, error } = await authClient.organization.inviteMember({\n    email: \"example@gmail.com\", // required\n    role: \"member\", // required\n    organizationId: \"org-id\",\n    resend: true,\n    teamId: \"team-id\",\n});\nProp\tDescription\tType\nemail\t\nThe email address of the user to invite.\n\tstring\nrole\t\nThe role(s) to assign to the user. It can be admin, member, or guest.\n\tstring | string[]\norganizationId?\t\nThe organization ID to invite the user to. Defaults to the active organization.\n\tstring\nresend?\t\nResend the invitation email, if the user is already invited.\n\tboolean\nteamId?\t\nThe team ID to invite the user to.\n\tstring\nIf the user is already a member of the organization, the invitation will be canceled. - If the user is already invited to the organization, unless resend is set to true, the invitation will not be sent again. - If cancelPendingInvitationsOnReInvite is set to true, the invitation will be canceled if the user is already invited to the organization and a new invitation is sent.\nAccept Invitation\n\nWhen a user receives an invitation email, they can click on the invitation link to accept the invitation. The invitation link should include the invitation ID, which will be used to accept the invitation.\n\nMake sure to call the acceptInvitation function after the user is logged in.\n\nClient\nServer\nPOST\n/organization/accept-invitation\nconst { data, error } = await authClient.organization.acceptInvitation({\n    invitationId: \"invitation-id\", // required\n});\nProp\tDescription\tType\ninvitationId\t\nThe ID of the invitation to accept.\n\tstring\nEmail Verification Requirement\n\nIf the requireEmailVerificationOnInvitation option is enabled in your organization configuration, users must verify their email address before they can accept invitations. This adds an extra security layer to ensure that only verified users can join your organization.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      requireEmailVerificationOnInvitation: true, \n      async sendInvitationEmail(data) {\n        // ... your email sending logic\n      },\n    }),\n  ],\n});\nInvitation Accepted Callback\n\nYou can configure Better Auth to execute a callback function when an invitation is accepted. This is useful for logging events, updating analytics, sending notifications, or any other custom logic you need to run when someone joins your organization.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      async sendInvitationEmail(data) {\n        // ... your invitation email logic\n      },\n      async onInvitationAccepted(data) {\n        // This callback gets triggered when an invitation is accepted\n      },\n    }),\n  ],\n});\n\nThe callback receives the following data:\n\nid: The invitation ID\nrole: The role assigned to the user\norganization: The organization the user joined\ninvitation: The invitation object\ninviter: The member who sent the invitation (including user details)\nacceptedUser: The user who accepted the invitation\nCancel Invitation\n\nIf a user has sent out an invitation, you can use this method to cancel it.\n\nIf you're looking for how a user can reject an invitation, you can find that here.\n\nClient\nServer\nPOST\n/organization/cancel-invitation\nawait authClient.organization.cancelInvitation({\n    invitationId: \"invitation-id\", // required\n});\nProp\tDescription\tType\ninvitationId\t\nThe ID of the invitation to cancel.\n\tstring\nReject Invitation\n\nIf this user has received an invitation, but wants to decline it, this method will allow you to do so by rejecting it.\n\nClient\nServer\nPOST\n/organization/reject-invitation\nawait authClient.organization.rejectInvitation({\n    invitationId: \"invitation-id\", // required\n});\nProp\tDescription\tType\ninvitationId\t\nThe ID of the invitation to reject.\n\tstring\n\nLike accepting invitations, rejecting invitations also requires email verification when the requireEmailVerificationOnInvitation option is enabled. Users with unverified emails will receive an error when attempting to reject invitations.\n\nGet Invitation\n\nTo get an invitation you can use the organization.getInvitation function provided by the client. You need to provide the invitation id as a query parameter.\n\nClient\nServer\nGET\n/organization/get-invitation\nconst { data, error } = await authClient.organization.getInvitation({\n    query: {\n        id: \"invitation-id\", // required\n    },\n});\nProp\tDescription\tType\nid\t\nThe ID of the invitation to get.\n\tstring\nList Invitations\n\nTo list all invitations for a given organization you can use the listInvitations function provided by the client.\n\nClient\nServer\nGET\n/organization/list-invitations\nconst { data, error } = await authClient.organization.listInvitations({\n    query: {\n        organizationId: \"organization-id\",\n    },\n});\nProp\tDescription\tType\norganizationId?\t\nAn optional ID of the organization to list invitations for. If not provided, will default to the user's active organization.\n\tstring\nList user invitations\n\nTo list all invitations for a given user you can use the listUserInvitations function provided by the client.\n\nauth-client.ts\nconst invitations = await authClient.organization.listUserInvitations();\n\nOn the server, you can pass the user ID as a query parameter.\n\napi.ts\nconst invitations = await auth.api.listUserInvitations({\n  query: {\n    email: \"user@example.com\",\n  },\n});\n\nThe email query parameter is only available on the server to query for invitations for a specific user.\n\nMembers\nList Members\n\nTo list all members of an organization you can use the listMembers function.\n\nClient\nServer\nGET\n/organization/list-members\nconst { data, error } = await authClient.organization.listMembers({\n    query: {\n        organizationId: \"organization-id\",\n        limit: 100,\n        offset: 0,\n        sortBy: \"createdAt\",\n        sortDirection: \"desc\",\n        filterField: \"createdAt\",\n        filterOperator: \"eq\",\n        filterValue: \"value\",\n    },\n});\nProp\tDescription\tType\norganizationId?\t\nAn optional organization ID to list members for. If not provided, will default to the user's active organization.\n\tstring\nlimit?\t\nThe limit of members to return.\n\tnumber\noffset?\t\nThe offset to start from.\n\tnumber\nsortBy?\t\nThe field to sort by.\n\tstring\nsortDirection?\t\nThe direction to sort by.\n\t\"asc\" | \"desc\"\nfilterField?\t\nThe field to filter by.\n\tstring\nfilterOperator?\t\nThe operator to filter by.\n\t\"eq\" | \"ne\" | \"gt\" | \"gte\" | \"lt\" | \"lte\" | \"in\" | \"nin\" | \"contains\"\nfilterValue?\t\nThe value to filter by.\n\tstring\nRemove Member\n\nTo remove you can use organization.removeMember\n\nClient\nServer\nPOST\n/organization/remove-member\nconst { data, error } = await authClient.organization.removeMember({\n    memberIdOrEmail: \"user@example.com\", // required\n    organizationId: \"org-id\",\n});\nProp\tDescription\tType\nmemberIdOrEmail\t\nThe ID or email of the member to remove.\n\tstring\norganizationId?\t\nThe ID of the organization to remove the member from. If not provided, the active organization will be used.\n\tstring\nUpdate Member Role\n\nTo update the role of a member in an organization, you can use the organization.updateMemberRole. If the user has the permission to update the role of the member, the role will be updated.\n\nClient\nServer\nPOST\n/organization/update-member-role\nawait authClient.organization.updateMemberRole({\n    role: [\"admin\", \"sale\"], // required\n    memberId: \"member-id\", // required\n    organizationId: \"organization-id\",\n});\nProp\tDescription\tType\nrole\t\nThe new role to be applied. This can be a string or array of strings representing the roles.\n\tstring | string[]\nmemberId\t\nThe member id to apply the role update to.\n\tstring\norganizationId?\t\nAn optional organization ID which the member is a part of to apply the role update. If not provided, you must provide session headers to get the active organization.\n\tstring\nGet Active Member\n\nTo get the current member of the active organization you can use the organization.getActiveMember function. This function will return the user's member details in their active organization.\n\nClient\nServer\nGET\n/organization/get-active-member\nconst { data: member, error } = await authClient.organization.getActiveMember();\nGet Active Member Role\n\nTo get the current role member of the active organization you can use the organization.getActiveMemberRole function. This function will return the user's member role in their active organization.\n\nClient\nServer\nGET\n/organization/get-active-member-role\nconst { data: { role }, error } = await authClient.organization.getActiveMemberRole();\nAdd Member\n\nIf you want to add a member directly to an organization without sending an invitation, you can use the addMember function which can only be invoked on the server.\n\nClient\nServer\nPOST\n/organization/add-member\nconst data = await auth.api.addMember({\n    body: {\n        userId: \"user-id\",\n        role: [\"admin\", \"sale\"], // required\n        organizationId: \"org-id\",\n        teamId: \"team-id\",\n    },\n});\nProp\tDescription\tType\nuserId?\t\nThe user ID which represents the user to be added as a member. If null is provided, then it's expected to provide session headers.\n\tstring | null\nrole\t\nThe role(s) to assign to the new member.\n\tstring | string[]\norganizationId?\t\nAn optional organization ID to pass. If not provided, will default to the user's active organization.\n\tstring\nteamId?\t\nAn optional team ID to add the member to.\n\tstring\nLeave Organization\n\nTo leave organization you can use organization.leave function. This function will remove the current user from the organization.\n\nClient\nServer\nPOST\n/organization/leave\nawait authClient.organization.leave({\n    organizationId: \"organization-id\", // required\n});\nProp\tDescription\tType\norganizationId\t\nThe organization ID for the member to leave.\n\tstring\nAccess Control\n\nThe organization plugin provides a very flexible access control system. You can control the access of the user based on the role they have in the organization. You can define your own set of permissions based on the role of the user.\n\nRoles\n\nBy default, there are three roles in the organization:\n\nowner: The user who created the organization by default. The owner has full control over the organization and can perform any action.\n\nadmin: Users with the admin role have full control over the organization except for deleting the organization or changing the owner.\n\nmember: Users with the member role have limited control over the organization. They can create projects, invite users, and manage projects they have created.\n\nA user can have multiple roles. Multiple roles are stored as string separated by comma (\",\").\n\nPermissions\n\nBy default, there are three resources, and these have two to three actions.\n\norganization:\n\nupdate delete\n\nmember:\n\ncreate update delete\n\ninvitation:\n\ncreate cancel\n\nThe owner has full control over all the resources and actions. The admin has full control over all the resources except for deleting the organization or changing the owner. The member has no control over any of those actions other than reading the data.\n\nCustom Permissions\n\nThe plugin provides an easy way to define your own set of permissions for each role.\n\nCreate Access Control\n\nYou first need to create access controller by calling createAccessControl function and passing the statement object. The statement object should have the resource name as the key and the array of actions as the value.\n\npermissions.ts\nimport { createAccessControl } from \"better-auth/plugins/access\";\n/**\n * make sure to use `as const` so typescript can infer the type correctly\n */\nconst statement = { \n    project: [\"create\", \"share\", \"update\", \"delete\"], \n} as const; \nconst ac = createAccessControl(statement); \nCreate Roles\n\nOnce you have created the access controller you can create roles with the permissions you have defined.\n\npermissions.ts\nimport { createAccessControl } from \"better-auth/plugins/access\";\nconst statement = {\n    project: [\"create\", \"share\", \"update\", \"delete\"],\n} as const;\nconst ac = createAccessControl(statement);\nconst member = ac.newRole({ \n    project: [\"create\"], \n}); \nconst admin = ac.newRole({ \n    project: [\"create\", \"update\"], \n}); \nconst owner = ac.newRole({ \n    project: [\"create\", \"update\", \"delete\"], \n}); \nconst myCustomRole = ac.newRole({ \n    project: [\"create\", \"update\", \"delete\"], \n    organization: [\"update\"], \n}); \n\nWhen you create custom roles for existing roles, the predefined permissions for those roles will be overridden. To add the existing permissions to the custom role, you need to import defaultStatements and merge it with your new statement, plus merge the roles' permissions set with the default roles.\n\npermissions.ts\nimport { createAccessControl } from \"better-auth/plugins/access\";\nimport { defaultStatements, adminAc } from 'better-auth/plugins/organization/access'\nconst statement = {\n    ...defaultStatements, \n    project: [\"create\", \"share\", \"update\", \"delete\"],\n} as const;\nconst ac = createAccessControl(statement);\nconst admin = ac.newRole({\n    project: [\"create\", \"update\"],\n    ...adminAc.statements, \n});\nPass Roles to the Plugin\n\nOnce you have created the roles you can pass them to the organization plugin both on the client and the server.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { organization } from \"better-auth/plugins\"\nimport { ac, owner, admin, member } from \"@/auth/permissions\"\nexport const auth = betterAuth({\n    plugins: [\n        organization({\n            ac,\n            roles: {\n                owner,\n                admin,\n                member,\n                myCustomRole\n            }\n        }),\n    ],\n});\n\nYou also need to pass the access controller and the roles to the client plugin.\n\nauth-client\nimport { createAuthClient } from \"better-auth/client\"\nimport { organizationClient } from \"better-auth/client/plugins\"\nimport { ac, owner, admin, member, myCustomRole } from \"@/auth/permissions\"\nexport const authClient = createAuthClient({\n    plugins: [\n        organizationClient({\n            ac,\n            roles: {\n                owner,\n                admin,\n                member,\n                myCustomRole\n            }\n        })\n  ]\n})\nAccess Control Usage\n\nHas Permission:\n\nYou can use the hasPermission action provided by the api to check the permission of the user.\n\napi.ts\nimport { auth } from \"@/auth\";\nawait auth.api.hasPermission({\n  headers: await headers(),\n  body: {\n    permissions: {\n      project: [\"create\"], // This must match the structure in your access control\n    },\n  },\n});\n// You can also check multiple resource permissions at the same time\nawait auth.api.hasPermission({\n  headers: await headers(),\n  body: {\n    permissions: {\n      project: [\"create\"], // This must match the structure in your access control\n      sale: [\"create\"],\n    },\n  },\n});\n\nIf you want to check the permission of the user on the client from the server you can use the hasPermission function provided by the client.\n\nauth-client.ts\nconst canCreateProject = await authClient.organization.hasPermission({\n  permissions: {\n    project: [\"create\"],\n  },\n});\n// You can also check multiple resource permissions at the same time\nconst canCreateProjectAndCreateSale =\n  await authClient.organization.hasPermission({\n    permissions: {\n      project: [\"create\"],\n      sale: [\"create\"],\n    },\n  });\n\nCheck Role Permission:\n\nOnce you have defined the roles and permissions to avoid checking the permission from the server you can use the checkRolePermission function provided by the client.\n\nauth-client.ts\nconst canCreateProject = authClient.organization.checkRolePermission({\n  permissions: {\n    organization: [\"delete\"],\n  },\n  role: \"admin\",\n});\n// You can also check multiple resource permissions at the same time\nconst canCreateProjectAndCreateSale =\n  authClient.organization.checkRolePermission({\n    permissions: {\n      organization: [\"delete\"],\n      member: [\"delete\"],\n    },\n    role: \"admin\",\n  });\n\nThis will not include any dynamic roles as everything is ran synchronously on the client side. Please use the hasPermission APIs to include checks for any dynamic roles & permissions.\n\nDynamic Access Control\n\nDynamic access control allows you to create roles at runtime for organizations. This is achieved by storing the created roles and permissions associated with an organization in a database table.\n\nEnabling Dynamic Access Control\n\nTo enable dynamic access control, pass the dynamicAccessControl configuration option with enabled set to true to both server and client plugins.\n\nEnsure you have pre-defined an ac instance on the server auth plugin. This is important as this is how we can infer the permissions that are available for use.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nimport { ac } from \"@/auth/permissions\";\nexport const auth = betterAuth({\n    plugins: [ \n        organization({ \n            ac, // Must be defined in order for dynamic access control to work\n            dynamicAccessControl: { \n              enabled: true, \n            }, \n        }) \n    ] \n})\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { organizationClient } from \"better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n    plugins: [ \n        organizationClient({ \n            dynamicAccessControl: { \n              enabled: true, \n            }, \n        }) \n    ] \n})\n\nThis will require you to run migrations to add the new organizationRole table to the database.\n\nThe authClient.organization.checkRolePermission function will not include any dynamic roles as everything is ran synchronously on the client side. Please use the hasPermission APIs to include checks for any dynamic roles.\n\nCreating a role\n\nTo create a new role for an organization at runtime, you can use the createRole function.\n\nOnly users with roles which contain the ac resource with the create permission can create a new role. By default, only the admin and owner roles have this permission. You also cannot add permissions that your current role in that organization can't already access.\n\nTIP: You can validate role names by using the dynamicAccessControl.validateRoleName option in the organization plugin config. Learn more here.\n\nClient\nServer\nPOST\n/organization/create-role\n// To use custom resources or permissions,\n// make sure they are defined in the `ac` instance of your organization config.\nconst permission = {\n  project: [\"create\", \"update\", \"delete\"]\n}\nawait authClient.organization.createRole({\n    role: \"my-unique-role\", // required\n    permission: permission,\n    organizationId: \"organization-id\",\n});\nProp\tDescription\tType\nrole\t\nA unique name of the role to create.\n\tstring\npermission?\t\nThe permissions to assign to the role.\n\tRecord<string, string[]>\norganizationId?\t\nThe organization ID which the role will be created in. Defaults to the active organization.\n\tstring\n\nNow you can freely call updateMemberRole to update the role of a member with your newly created role!\n\nDeleting a role\n\nTo delete a role, you can use the deleteRole function, then provide either a roleName or roleId parameter along with the organizationId parameter.\n\nClient\nServer\nPOST\n/organization/delete-role\nawait authClient.organization.deleteRole({\n    roleName: \"my-role\",\n    roleId: \"role-id\",\n    organizationId: \"organization-id\",\n});\nProp\tDescription\tType\nroleName?\t\nThe name of the role to delete. Alternatively, you can pass a roleId parameter instead.\n\tstring\nroleId?\t\nThe id of the role to delete. Alternatively, you can pass a roleName parameter instead.\n\tstring\norganizationId?\t\nThe organization ID which the role will be deleted in. Defaults to the active organization.\n\tstring\nListing roles\n\nTo list roles, you can use the listOrgRoles function. This requires the ac resource with the read permission for the member to be able to list roles.\n\nClient\nServer\nGET\n/organization/list-roles\nconst { data: roles, error } = await authClient.organization.listRoles({\n    query: {\n        organizationId: \"organization-id\",\n    },\n});\nProp\tDescription\tType\norganizationId?\t\nThe organization ID which the roles are under to list. Defaults to the user's active organization.\n\tstring\nGetting a specific role\n\nTo get a specific role, you can use the getOrgRole function and pass either a roleName or roleId parameter. This requires the ac resource with the read permission for the member to be able to get a role.\n\nClient\nServer\nGET\n/organization/get-role\nconst { data: role, error } = await authClient.organization.getRole({\n    query: {\n        roleName: \"my-role\",\n        roleId: \"role-id\",\n        organizationId: \"organization-id\",\n    },\n});\nProp\tDescription\tType\nroleName?\t\nThe name of the role to get. Alternatively, you can pass a roleId parameter instead.\n\tstring\nroleId?\t\nThe id of the role to get. Alternatively, you can pass a roleName parameter instead.\n\tstring\norganizationId?\t\nThe organization ID which the role will be deleted in. Defaults to the active organization.\n\tstring\nUpdating a role\n\nTo update a role, you can use the updateOrgRole function and pass either a roleName or roleId parameter.\n\nClient\nServer\nPOST\n/organization/update-role\nconst { data: updatedRole, error } = await authClient.organization.updateRole({\n    roleName: \"my-role\",\n    roleId: \"role-id\",\n    organizationId: \"organization-id\",\n    data: { // required\n        permission: { project: [\"create\", \"update\", \"delete\"] },\n        roleName: \"my-new-role\",\n    },\n});\nProp\tDescription\tType\nroleName?\t\nThe name of the role to update. Alternatively, you can pass a roleId parameter instead.\n\tstring\nroleId?\t\nThe id of the role to update. Alternatively, you can pass a roleName parameter instead.\n\tstring\norganizationId?\t\nThe organization ID which the role will be updated in. Defaults to the active organization.\n\tstring\ndata\t\nThe data which will be updated\n\tObject\ndata.permission?\t\nOptionally update the permissions of the role.\n\tRecord<string, string[]>\ndata.roleName?\t\nOptionally update the name of the role.\n\tstring\nConfiguration Options\n\nBelow is a list of options that can be passed to the dynamicAccessControl object.\n\nenabled\n\nThis option is used to enable or disable dynamic access control. By default, it is disabled.\n\norganization({\n  dynamicAccessControl: {\n    enabled: true\n  }\n})\nmaximumRolesPerOrganization\n\nThis option is used to limit the number of roles that can be created for an organization.\n\nBy default, the maximum number of roles that can be created for an organization is infinite.\n\norganization({\n  dynamicAccessControl: {\n    maximumRolesPerOrganization: 10\n  }\n})\n\nYou can also pass a function that returns a number.\n\norganization({\n  dynamicAccessControl: {\n    maximumRolesPerOrganization: async (organizationId) => { \n      const organization = await getOrganization(organizationId); \n      return organization.plan === \"pro\" ? 100 : 10; \n    } \n  }\n})\nAdditional Fields\n\nTo add additional fields to the organizationRole table, you can pass the additionalFields configuration option to the organization plugin.\n\norganization({\n  schema: {\n    organizationRole: {\n      additionalFields: {\n        // Role colors!\n        color: {\n          type: \"string\",\n          defaultValue: \"#ffffff\",\n        },\n        //... other fields\n      },\n    },\n  },\n})\n\nThen, if you don't already use inferOrgAdditionalFields to infer the additional fields, you can use it to infer the additional fields.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { organizationClient, inferOrgAdditionalFields } from \"better-auth/client/plugins\"\nimport type { auth } from \"./auth\"\nexport const authClient = createAuthClient({\n    plugins: [\n        organizationClient({\n            schema: inferOrgAdditionalFields<typeof auth>()\n        })\n    ]\n})\n\nOtherwise, you can pass the schema values directly, the same way you do on the org plugin in the server.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { organizationClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        organizationClient({\n            schema: {\n                organizationRole: {\n                    additionalFields: {\n                        color: {\n                            type: \"string\",\n                            defaultValue: \"#ffffff\",\n                        }\n                    }\n                }\n            }\n        })\n    ]\n})\nTeams\n\nTeams allow you to group members within an organization. The teams feature provides additional organization structure and can be used to manage permissions at a more granular level.\n\nEnabling Teams\n\nTo enable teams, pass the teams configuration option to both server and client plugins:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { organization } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  plugins: [\n    organization({\n      teams: {\n        enabled: true,\n        maximumTeams: 10, // Optional: limit teams per organization\n        allowRemovingAllTeams: false, // Optional: prevent removing the last team\n      },\n    }),\n  ],\n});\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { organizationClient } from \"better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n  plugins: [\n    organizationClient({\n      teams: {\n        enabled: true,\n      },\n    }),\n  ],\n});\nManaging Teams\nCreate Team\n\nCreate a new team within an organization:\n\nClient\nServer\nPOST\n/organization/create-team\nconst { data, error } = await authClient.organization.createTeam({\n    name: \"my-team\", // required\n    organizationId: \"organization-id\",\n});\nProp\tDescription\tType\nname\t\nThe name of the team.\n\tstring\norganizationId?\t\nThe organization ID which the team will be created in. Defaults to the active organization.\n\tstring\nList Teams\n\nGet all teams in an organization:\n\nClient\nServer\nGET\n/organization/list-teams\nconst { data, error } = await authClient.organization.listTeams({\n    query: {\n        organizationId: \"organization-id\",\n    },\n});\nProp\tDescription\tType\norganizationId?\t\nThe organization ID which the teams are under to list. Defaults to the user's active organization.\n\tstring\nUpdate Team\n\nUpdate a team's details:\n\nClient\nServer\nPOST\n/organization/update-team\nconst { data, error } = await authClient.organization.updateTeam({\n    teamId: \"team-id\", // required\n    data: { // required\n        name: \"My new team name\",\n        organizationId: \"My new organization ID for this team\",\n        createdAt: new Date(),\n        updatedAt: new Date(),\n    },\n});\nProp\tDescription\tType\nteamId\t\nThe ID of the team to be updated.\n\tstring\ndata\t\nA partial object containing options for you to update.\n\tObject\ndata.name?\t\nThe name of the team to be updated.\n\tstring\ndata.organizationId?\t\nThe organization ID which the team falls under.\n\tstring\ndata.createdAt?\t\nThe timestamp of when the team was created.\n\tDate\ndata.updatedAt?\t\nThe timestamp of when the team was last updated.\n\tDate\nRemove Team\n\nDelete a team from an organization:\n\nClient\nServer\nPOST\n/organization/remove-team\nconst { data, error } = await authClient.organization.removeTeam({\n    teamId: \"team-id\", // required\n    organizationId: \"organization-id\",\n});\nProp\tDescription\tType\nteamId\t\nThe team ID of the team to remove.\n\tstring\norganizationId?\t\nThe organization ID which the team falls under. If not provided, it will default to the user's active organization.\n\tstring\nSet Active Team\n\nSets the given team as the current active team. If teamId is null the current active team is unset.\n\nClient\nServer\nPOST\n/organization/set-active-team\nconst { data, error } = await authClient.organization.setActiveTeam({\n    teamId: \"team-id\",\n});\nProp\tDescription\tType\nteamId?\t\nThe team ID of the team to set as the current active team.\n\tstring\nList User Teams\n\nList all teams that the current user is a part of.\n\nClient\nServer\nGET\n/organization/list-user-teams\nconst { data, error } = await authClient.organization.listUserTeams();\nList Team Members\n\nList the members of the given team.\n\nClient\nServer\nPOST\n/organization/list-team-members\nconst { data, error } = await authClient.organization.listTeamMembers({\n    query: {\n        teamId: \"team-id\",\n    },\n});\nProp\tDescription\tType\nteamId?\t\nThe team whose members we should return. If this is not provided the members of the current active team get returned.\n\tstring\nAdd Team Member\n\nAdd a member to a team.\n\nClient\nServer\nPOST\n/organization/add-team-member\nconst { data, error } = await authClient.organization.addTeamMember({\n    teamId: \"team-id\", // required\n    userId: \"user-id\", // required\n});\nProp\tDescription\tType\nteamId\t\nThe team the user should be a member of.\n\tstring\nuserId\t\nThe user ID which represents the user to be added as a member.\n\tstring\nRemove Team Member\n\nRemove a member from a team.\n\nClient\nServer\nPOST\n/organization/remove-team-member\nconst { data, error } = await authClient.organization.removeTeamMember({\n    teamId: \"team-id\", // required\n    userId: \"user-id\", // required\n});\nProp\tDescription\tType\nteamId\t\nThe team the user should be removed from.\n\tstring\nuserId\t\nThe user which should be removed from the team.\n\tstring\nTeam Permissions\n\nTeams follow the organization's permission system. To manage teams, users need the following permissions:\n\nteam:create - Create new teams\nteam:update - Update team details\nteam:delete - Remove teams\n\nBy default:\n\nOrganization owners and admins can manage teams\nRegular members cannot create, update, or delete teams\nTeam Configuration Options\n\nThe teams feature supports several configuration options:\n\nmaximumTeams: Limit the number of teams per organization\n\nteams: {\n  enabled: true,\n  maximumTeams: 10 // Fixed number\n  // OR\n  maximumTeams: async ({ organizationId, session }, request) => {\n    // Dynamic limit based on organization plan\n    const plan = await getPlan(organizationId)\n    return plan === 'pro' ? 20 : 5\n  },\n  maximumMembersPerTeam: 10 // Fixed number\n  // OR\n  maximumMembersPerTeam: async ({ teamId, session, organizationId }, request) => {\n    // Dynamic limit based on team plan\n    const plan = await getPlan(organizationId, teamId)\n    return plan === 'pro' ? 50 : 10\n  },\n}\n\nallowRemovingAllTeams: Control whether the last team can be removed\n\nteams: {\n  enabled: true,\n  allowRemovingAllTeams: false // Prevent removing the last team\n}\nTeam Members\n\nWhen inviting members to an organization, you can specify a team:\n\nawait authClient.organization.inviteMember({\n  email: \"user@example.com\",\n  role: \"member\",\n  teamId: \"team-id\",\n});\n\nThe invited member will be added to the specified team upon accepting the invitation.\n\nDatabase Schema\n\nWhen teams are enabled, new team and teamMember tables are added to the database.\n\nTable Name: team\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each team\nname\tstring\t-\tThe name of the team\norganizationId\tstring\t\nFK\tThe ID of the organization\ncreatedAt\tDate\t-\tTimestamp of when the team was created\nupdatedAt\tDate\t?\tTimestamp of when the team was created\n\nTable Name: teamMember\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each team member\nteamId\tstring\t\nFK\tUnique identifier for each team\nuserId\tstring\t\nFK\tThe ID of the user\ncreatedAt\tDate\t-\tTimestamp of when the team member was created\nSchema\n\nThe organization plugin adds the following tables to the database:\n\nOrganization\n\nTable Name: organization\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each organization\nname\tstring\t-\tThe name of the organization\nslug\tstring\t-\tThe slug of the organization\nlogo\tstring\t?\tThe logo of the organization\nmetadata\tstring\t?\tAdditional metadata for the organization\ncreatedAt\tDate\t-\tTimestamp of when the organization was created\nMember\n\nTable Name: member\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each member\nuserId\tstring\t\nFK\tThe ID of the user\norganizationId\tstring\t\nFK\tThe ID of the organization\nrole\tstring\t-\tThe role of the user in the organization\ncreatedAt\tDate\t-\tTimestamp of when the member was added to the organization\nInvitation\n\nTable Name: invitation\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each invitation\nemail\tstring\t-\tThe email address of the user\ninviterId\tstring\t\nFK\tThe ID of the inviter\norganizationId\tstring\t\nFK\tThe ID of the organization\nrole\tstring\t-\tThe role of the user in the organization\nstatus\tstring\t-\tThe status of the invitation\nexpiresAt\tDate\t-\tTimestamp of when the invitation expires\n\nIf teams are enabled, you need to add the following fields to the invitation table:\n\nField Name\tType\tKey\tDescription\nteamId\tstring\t?\tThe ID of the team\nSession\n\nTable Name: session\n\nYou need to add two more fields to the session table to store the active organization ID and the active team ID.\n\nField Name\tType\tKey\tDescription\nactiveOrganizationId\tstring\t?\tThe ID of the active organization\nactiveTeamId\tstring\t?\tThe ID of the active team\nTeams (optional)\n\nTable Name: team\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each team\nname\tstring\t-\tThe name of the team\norganizationId\tstring\t\nFK\tThe ID of the organization\ncreatedAt\tDate\t-\tTimestamp of when the team was created\nupdatedAt\tDate\t?\tTimestamp of when the team was created\n\nTable Name: teamMember\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each team member\nteamId\tstring\t\nFK\tUnique identifier for each team\nuserId\tstring\t\nFK\tThe ID of the user\ncreatedAt\tDate\t-\tTimestamp of when the team member was created\n\nTable Name: invitation\n\nField Name\tType\tKey\tDescription\nteamId\tstring\t?\tThe ID of the team\nCustomizing the Schema\n\nTo change the schema table name or fields, you can pass schema option to the organization plugin.\n\nauth.ts\nconst auth = betterAuth({\n  plugins: [\n    organization({\n      schema: {\n        organization: {\n          modelName: \"organizations\", //map the organization table to organizations\n          fields: {\n            name: \"title\", //map the name field to title\n          },\n          additionalFields: {\n            // Add a new field to the organization table\n            myCustomField: {\n              type: \"string\",\n              input: true,\n              required: false,\n            },\n          },\n        },\n      },\n    }),\n  ],\n});\nAdditional Fields\n\nStarting with Better Auth v1.3, you can easily add custom fields to the organization, invitation, member, and team tables.\n\nWhen you add extra fields to a model, the relevant API endpoints will automatically accept and return these new properties. For instance, if you add a custom field to the organization table, the createOrganization endpoint will include this field in its request and response payloads as needed.\n\nauth.ts\nconst auth = betterAuth({\n  plugins: [\n    organization({\n      schema: {\n        organization: {\n          additionalFields: {\n            myCustomField: {\n              type: \"string\", \n              input: true, \n              required: false, \n            }, \n          },\n        },\n      },\n    }),\n  ],\n});\n\nFor inferring the additional fields, you can use the inferOrgAdditionalFields function. This function will infer the additional fields from the auth object type.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport {\n  inferOrgAdditionalFields,\n  organizationClient,\n} from \"better-auth/client/plugins\";\nimport type { auth } from \"@/auth\"; // import the auth object type only\nconst client = createAuthClient({\n  plugins: [\n    organizationClient({\n      schema: inferOrgAdditionalFields<typeof auth>(),\n    }),\n  ],\n});\n\nif you can't import the auth object type, you can use the inferOrgAdditionalFields function without the generic. This function will infer the additional fields from the schema object.\n\nauth-client.ts\nconst client = createAuthClient({\n  plugins: [\n    organizationClient({\n      schema: inferOrgAdditionalFields({\n        organization: {\n          additionalFields: {\n            newField: {\n              type: \"string\", \n            }, \n          },\n        },\n      }),\n    }),\n  ],\n});\n//example usage\nawait client.organization.create({\n  name: \"Test\",\n  slug: \"test\",\n  newField: \"123\", //this should be allowed\n  //@ts-expect-error - this field is not available\n  unavalibleField: \"123\", //this should be not allowed\n});\nOptions\n\nallowUserToCreateOrganization: boolean | ((user: User) => Promise<boolean> | boolean) - A function that determines whether a user can create an organization. By default, it's true. You can set it to false to restrict users from creating organizations.\n\norganizationLimit: number | ((user: User) => Promise<boolean> | boolean) - The maximum number of organizations allowed for a user. By default, it's 5. You can set it to any number you want or a function that returns a boolean.\n\ncreatorRole: admin | owner - The role of the user who creates the organization. By default, it's owner. You can set it to admin.\n\nmembershipLimit: number - The maximum number of members allowed in an organization. By default, it's 100. You can set it to any number you want.\n\nsendInvitationEmail: async (data) => Promise<void> - A function that sends an invitation email to the user.\n\ninvitationExpiresIn : number - How long the invitation link is valid for in seconds. By default, it's 48 hours (2 days).\n\ncancelPendingInvitationsOnReInvite: boolean - Whether to cancel pending invitations if the user is already invited to the organization. By default, it's false.\n\ninvitationLimit: number | ((user: User) => Promise<boolean> | boolean) - The maximum number of invitations allowed for a user. By default, it's 100. You can set it to any number you want or a function that returns a boolean.\n\nrequireEmailVerificationOnInvitation: boolean - Whether to require email verification before accepting or rejecting invitations. By default, it's false. When enabled, users must have verified their email address before they can accept or reject organization invitations.\n\nEdit on GitHub\n\nPrevious Page\n\nMCP\n\nNext Page\n\nEnterprise"
  },
  {
    "title": "Single Sign-On (SSO) | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/sso",
    "html": "Single Sign-On (SSO)\nCopy Markdown\nOpen in\n\nOIDC OAuth2 SSO SAML\n\nSingle Sign-On (SSO) allows users to authenticate with multiple applications using a single set of credentials. This plugin supports OpenID Connect (OIDC), OAuth2 providers, and SAML 2.0.\n\nInstallation\nInstall the plugin\nnpm install @better-auth/sso\nAdd Plugin to the server\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { sso } from \"@better-auth/sso\";\nconst auth = betterAuth({\n    plugins: [ \n        sso() \n    ] \n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { ssoClient } from \"@better-auth/sso/client\"\nconst authClient = createAuthClient({\n    plugins: [ \n        ssoClient() \n    ] \n})\nUsage\nRegister an OIDC Provider\n\nTo register an OIDC provider, use the registerSSOProvider endpoint and provide the necessary configuration details for the provider.\n\nA redirect URL will be automatically generated using the provider ID. For instance, if the provider ID is hydra, the redirect URL would be {baseURL}/api/auth/sso/callback/hydra. Note that /api/auth may vary depending on your base path configuration.\n\nExample\nclient\nserver\nregister-oidc-provider.ts\nimport { authClient } from \"@/lib/auth-client\";\n// Register with OIDC configuration\nawait authClient.sso.register({\n    providerId: \"example-provider\",\n    issuer: \"https://idp.example.com\",\n    domain: \"example.com\",\n    oidcConfig: {\n        clientId: \"client-id\",\n        clientSecret: \"client-secret\",\n        authorizationEndpoint: \"https://idp.example.com/authorize\",\n        tokenEndpoint: \"https://idp.example.com/token\",\n        jwksEndpoint: \"https://idp.example.com/jwks\",\n        discoveryEndpoint: \"https://idp.example.com/.well-known/openid-configuration\",\n        scopes: [\"openid\", \"email\", \"profile\"],\n        pkce: true,\n        mapping: {\n            id: \"sub\",\n            email: \"email\",\n            emailVerified: \"email_verified\",\n            name: \"name\",\n            image: \"picture\",\n            extraFields: {\n                department: \"department\",\n                role: \"role\"\n            }\n        }\n    }\n});\nRegister a SAML Provider\n\nTo register a SAML provider, use the registerSSOProvider endpoint with SAML configuration details. The provider will act as a Service Provider (SP) and integrate with your Identity Provider (IdP).\n\nclient\nserver\nregister-saml-provider.ts\nimport { authClient } from \"@/lib/auth-client\";\nawait authClient.sso.register({\n    providerId: \"saml-provider\",\n    issuer: \"https://idp.example.com\",\n    domain: \"example.com\",\n    samlConfig: {\n        entryPoint: \"https://idp.example.com/sso\",\n        cert: \"-----BEGIN CERTIFICATE-----\\n...\\n-----END CERTIFICATE-----\",\n        callbackUrl: \"https://yourapp.com/api/auth/sso/saml2/callback/saml-provider\",\n        audience: \"https://yourapp.com\",\n        wantAssertionsSigned: true,\n        signatureAlgorithm: \"sha256\",\n        digestAlgorithm: \"sha256\",\n        identifierFormat: \"urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddress\",\n        idpMetadata: {\n            metadata: \"<!-- IdP Metadata XML -->\",\n            privateKey: \"-----BEGIN RSA PRIVATE KEY-----\\n...\\n-----END RSA PRIVATE KEY-----\",\n            privateKeyPass: \"your-private-key-password\",\n            isAssertionEncrypted: true,\n            encPrivateKey: \"-----BEGIN RSA PRIVATE KEY-----\\n...\\n-----END RSA PRIVATE KEY-----\",\n            encPrivateKeyPass: \"your-encryption-key-password\"\n        },\n        spMetadata: {\n            metadata: \"<!-- SP Metadata XML -->\",\n            binding: \"post\",\n            privateKey: \"-----BEGIN RSA PRIVATE KEY-----\\n...\\n-----END RSA PRIVATE KEY-----\",\n            privateKeyPass: \"your-sp-private-key-password\",\n            isAssertionEncrypted: true,\n            encPrivateKey: \"-----BEGIN RSA PRIVATE KEY-----\\n...\\n-----END RSA PRIVATE KEY-----\",\n            encPrivateKeyPass: \"your-sp-encryption-key-password\"\n        },\n        mapping: {\n            id: \"nameID\",\n            email: \"email\",\n            name: \"displayName\",\n            firstName: \"givenName\",\n            lastName: \"surname\",\n            emailVerified: \"email_verified\",\n            extraFields: {\n                department: \"department\",\n                role: \"role\"\n            }\n        }\n    }\n});\nGet Service Provider Metadata\n\nFor SAML providers, you can retrieve the Service Provider metadata XML that needs to be configured in your Identity Provider:\n\nget-sp-metadata.ts\nconst response = await auth.api.spMetadata({\n    query: {\n        providerId: \"saml-provider\",\n        format: \"xml\" // or \"json\"\n    }\n});\nconst metadataXML = await response.text();\nconsole.log(metadataXML);\nSign In with SSO\n\nTo sign in with an SSO provider, you can call signIn.sso\n\nYou can sign in using the email with domain matching:\n\nsign-in.ts\nconst res = await authClient.signIn.sso({\n    email: \"user@example.com\",\n    callbackURL: \"/dashboard\",\n});\n\nor you can specify the domain:\n\nsign-in-domain.ts\nconst res = await authClient.signIn.sso({\n    domain: \"example.com\",\n    callbackURL: \"/dashboard\",\n});\n\nYou can also sign in using the organization slug if a provider is associated with an organization:\n\nsign-in-org.ts\nconst res = await authClient.signIn.sso({\n    organizationSlug: \"example-org\",\n    callbackURL: \"/dashboard\",\n});\n\nAlternatively, you can sign in using the provider's ID:\n\nsign-in-provider-id.ts\nconst res = await authClient.signIn.sso({\n    providerId: \"example-provider-id\",\n    callbackURL: \"/dashboard\",\n});\n\nTo use the server API you can use signInSSO\n\nsign-in-org.ts\nconst res = await auth.api.signInSSO({\n    body: {\n        organizationSlug: \"example-org\",\n        callbackURL: \"/dashboard\",\n    }\n});\nFull method\nClient\nServer\nPOST\n/sign-in/sso\nconst { data, error } = await authClient.signIn.sso({\n    email: \"john@example.com\",\n    organizationSlug: \"example-org\",\n    providerId: \"example-provider\",\n    domain: \"example.com\",\n    callbackURL: \"https://example.com/callback\", // required\n    errorCallbackURL: \"https://example.com/callback\",\n    newUserCallbackURL: \"https://example.com/new-user\",\n    scopes: [\"openid\", \"email\", \"profile\", \"offline_access\"],\n    requestSignUp: true,\n});\nProp\tDescription\tType\nemail?\t\nThe email address to sign in with. This is used to identify the issuer to sign in with. It's optional if the issuer is provided.\n\tstring\norganizationSlug?\t\nThe slug of the organization to sign in with.\n\tstring\nproviderId?\t\nThe ID of the provider to sign in with. This can be provided instead of email or issuer.\n\tstring\ndomain?\t\nThe domain of the provider.\n\tstring\ncallbackURL\t\nThe URL to redirect to after login.\n\tstring\nerrorCallbackURL?\t\nThe URL to redirect to after login.\n\tstring\nnewUserCallbackURL?\t\nThe URL to redirect to after login if the user is new.\n\tstring\nscopes?\t\nScopes to request from the provider.\n\tstring[]\nrequestSignUp?\t\nExplicitly request sign-up. Useful when disableImplicitSignUp is true for this provider.\n\tboolean\n\nWhen a user is authenticated, if the user does not exist, the user will be provisioned using the provisionUser function. If the organization provisioning is enabled and a provider is associated with an organization, the user will be added to the organization.\n\nauth.ts\nconst auth = betterAuth({\n    plugins: [\n        sso({\n            provisionUser: async (user) => {\n                // provision user\n            },\n            organizationProvisioning: {\n                disabled: false,\n                defaultRole: \"member\",\n                getRole: async (user) => {\n                    // get role if needed\n                },\n            },\n        }),\n    ],\n});\nProvisioning\n\nThe SSO plugin provides powerful provisioning capabilities to automatically set up users and manage their organization memberships when they sign in through SSO providers.\n\nUser Provisioning\n\nUser provisioning allows you to run custom logic whenever a user signs in through an SSO provider. This is useful for:\n\nSetting up user profiles with additional data from the SSO provider\nSynchronizing user attributes with external systems\nCreating user-specific resources\nLogging SSO sign-ins\nUpdating user information from the SSO provider\nauth.ts\nconst auth = betterAuth({\n    plugins: [\n        sso({\n            provisionUser: async ({ user, userInfo, token, provider }) => {\n                // Update user profile with SSO data\n                await updateUserProfile(user.id, {\n                    department: userInfo.attributes?.department,\n                    jobTitle: userInfo.attributes?.jobTitle,\n                    manager: userInfo.attributes?.manager,\n                    lastSSOLogin: new Date(),\n                });\n                // Create user-specific resources\n                await createUserWorkspace(user.id);\n                // Sync with external systems\n                await syncUserWithCRM(user.id, userInfo);\n                // Log the SSO sign-in\n                await auditLog.create({\n                    userId: user.id,\n                    action: 'sso_signin',\n                    provider: provider.providerId,\n                    metadata: {\n                        email: userInfo.email,\n                        ssoProvider: provider.issuer,\n                    },\n                });\n            },\n        }),\n    ],\n});\n\nThe provisionUser function receives:\n\nuser: The user object from the database\nuserInfo: User information from the SSO provider (includes attributes, email, name, etc.)\ntoken: OAuth2 tokens (for OIDC providers) - may be undefined for SAML\nprovider: The SSO provider configuration\nOrganization Provisioning\n\nOrganization provisioning automatically manages user memberships in organizations when SSO providers are linked to specific organizations. This is particularly useful for:\n\nEnterprise SSO where each company/domain maps to an organization\nAutomatic role assignment based on SSO attributes\nManaging team memberships through SSO\nBasic Organization Provisioning\nauth.ts\nconst auth = betterAuth({\n    plugins: [\n        sso({\n            organizationProvisioning: {\n                disabled: false,           // Enable org provisioning\n                defaultRole: \"member\",     // Default role for new members\n            },\n        }),\n    ],\n});\nAdvanced Organization Provisioning with Custom Roles\nauth.ts\nconst auth = betterAuth({\n    plugins: [\n        sso({\n            organizationProvisioning: {\n                disabled: false,\n                defaultRole: \"member\",\n                getRole: async ({ user, userInfo, provider }) => {\n                    // Assign roles based on SSO attributes\n                    const department = userInfo.attributes?.department;\n                    const jobTitle = userInfo.attributes?.jobTitle;\n                    \n                    // Admins based on job title\n                    if (jobTitle?.toLowerCase().includes('manager') || \n                        jobTitle?.toLowerCase().includes('director') ||\n                        jobTitle?.toLowerCase().includes('vp')) {\n                        return \"admin\";\n                    }\n                    \n                    // Special roles for IT department\n                    if (department?.toLowerCase() === 'it') {\n                        return \"admin\";\n                    }\n                    \n                    // Default to member for everyone else\n                    return \"member\";\n                },\n            },\n        }),\n    ],\n});\nLinking SSO Providers to Organizations\n\nWhen registering an SSO provider, you can link it to a specific organization:\n\nregister-org-provider.ts\nawait auth.api.registerSSOProvider({\n    body: {\n        providerId: \"acme-corp-saml\",\n        issuer: \"https://acme-corp.okta.com\",\n        domain: \"acmecorp.com\",\n        organizationId: \"org_acme_corp_id\", // Link to organization\n        samlConfig: {\n            // SAML configuration...\n        },\n    },\n    headers,\n});\n\nNow when users from acmecorp.com sign in through this provider, they'll automatically be added to the \"Acme Corp\" organization with the appropriate role.\n\nMultiple Organizations Example\n\nYou can set up multiple SSO providers for different organizations:\n\nmulti-org-setup.ts\n// Acme Corp SAML provider\nawait auth.api.registerSSOProvider({\n    body: {\n        providerId: \"acme-corp\",\n        issuer: \"https://acme.okta.com\",\n        domain: \"acmecorp.com\",\n        organizationId: \"org_acme_id\",\n        samlConfig: { /* ... */ },\n    },\n    headers,\n});\n// TechStart OIDC provider\nawait auth.api.registerSSOProvider({\n    body: {\n        providerId: \"techstart-google\",\n        issuer: \"https://accounts.google.com\",\n        domain: \"techstart.io\",\n        organizationId: \"org_techstart_id\",\n        oidcConfig: { /* ... */ },\n    },\n    headers,\n});\nOrganization Provisioning Flow\nUser signs in through an SSO provider linked to an organization\nUser is authenticated and either found or created in the database\nOrganization membership is checked - if the user isn't already a member of the linked organization\nRole is determined using either the defaultRole or getRole function\nUser is added to the organization with the determined role\nUser provisioning runs (if configured) for additional setup\nProvisioning Best Practices\n1. Idempotent Operations\n\nMake sure your provisioning functions can be safely run multiple times:\n\nprovisionUser: async ({ user, userInfo }) => {\n    // Check if already provisioned\n    const existingProfile = await getUserProfile(user.id);\n    if (!existingProfile.ssoProvisioned) {\n        await createUserResources(user.id);\n        await markAsProvisioned(user.id);\n    }\n    \n    // Always update attributes (they might change)\n    await updateUserAttributes(user.id, userInfo.attributes);\n},\n2. Error Handling\n\nHandle errors gracefully to avoid blocking user sign-in:\n\nprovisionUser: async ({ user, userInfo }) => {\n    try {\n        await syncWithExternalSystem(user, userInfo);\n    } catch (error) {\n        // Log error but don't throw - user can still sign in\n        console.error('Failed to sync user with external system:', error);\n        await logProvisioningError(user.id, error);\n    }\n},\n3. Conditional Provisioning\n\nOnly run certain provisioning steps when needed:\n\norganizationProvisioning: {\n    disabled: false,\n    getRole: async ({ user, userInfo, provider }) => {\n        // Only process role assignment for certain providers\n        if (provider.providerId.includes('enterprise')) {\n            return determineEnterpriseRole(userInfo);\n        }\n        return \"member\";\n    },\n},\nSAML Configuration\nDefault SSO Provider\nauth.ts\nconst auth = betterAuth({\n    plugins: [\n        sso({\n            defaultSSO: {\n                providerId: \"default-saml\", // Provider ID for the default provider\n                samlConfig: {\n                    issuer: \"https://your-app.com\",\n                    entryPoint: \"https://idp.example.com/sso\",\n                    cert: \"-----BEGIN CERTIFICATE-----\\n...\\n-----END CERTIFICATE-----\",\n                    callbackUrl: \"http://localhost:3000/api/auth/sso/saml2/sp/acs\",\n                    spMetadata: {\n                        entityID: \"http://localhost:3000/api/auth/sso/saml2/sp/metadata\",\n                        metadata: \"<!-- Your SP Metadata XML -->\",\n                    }\n                }\n            }\n        })\n    ]\n});\n\nThe defaultSSO provider will be used when:\n\nNo matching provider is found in the database\n\nThis allows you to test SAML authentication without setting up providers in the database. The defaultSSO provider supports all the same configuration options as regular SAML providers.\n\nService Provider Configuration\n\nWhen registering a SAML provider, you need to provide Service Provider (SP) metadata configuration:\n\nmetadata: XML metadata for the Service Provider\nbinding: The binding method, typically \"post\" or \"redirect\"\nprivateKey: Private key for signing (optional)\nprivateKeyPass: Password for the private key (if encrypted)\nisAssertionEncrypted: Whether assertions should be encrypted\nencPrivateKey: Private key for decryption (if encryption is enabled)\nencPrivateKeyPass: Password for the encryption private key\nIdentity Provider Configuration\n\nYou also need to provide Identity Provider (IdP) configuration:\n\nmetadata: XML metadata from your Identity Provider\nprivateKey: Private key for the IdP communication (optional)\nprivateKeyPass: Password for the IdP private key (if encrypted)\nisAssertionEncrypted: Whether assertions from IdP are encrypted\nencPrivateKey: Private key for IdP assertion decryption\nencPrivateKeyPass: Password for the IdP decryption key\nSAML Attribute Mapping\n\nConfigure how SAML attributes map to user fields:\n\nmapping: {\n    id: \"nameID\",           // Default: \"nameID\"\n    email: \"email\",         // Default: \"email\" or \"nameID\"\n    name: \"displayName\",    // Default: \"displayName\"\n    firstName: \"givenName\", // Default: \"givenName\"\n    lastName: \"surname\",    // Default: \"surname\"\n    extraFields: {\n        department: \"department\",\n        role: \"jobTitle\",\n        phone: \"telephoneNumber\"\n    }\n}\nSAML Endpoints\n\nThe plugin automatically creates the following SAML endpoints:\n\nSP Metadata: /api/auth/sso/saml2/sp/metadata?providerId={providerId}\nSAML Callback: /api/auth/sso/saml2/callback/{providerId}\nSchema\n\nThe plugin requires additional fields in the ssoProvider table to store the provider's configuration.\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tA database identifier\nissuer\tstring\t-\tThe issuer identifier\ndomain\tstring\t-\tThe domain of the provider\noidcConfig\tstring\t-\tThe OIDC configuration (JSON string)\nsamlConfig\tstring\t-\tThe SAML configuration (JSON string)\nuserId\tstring\t-\tThe user ID\nproviderId\tstring\t-\tThe provider ID. Used to identify a provider and to generate a redirect URL.\norganizationId\tstring\t-\tThe organization Id. If provider is linked to an organization.\n\nFor a detailed guide on setting up SAML SSO with examples for Okta and testing with DummyIDP, see our SAML SSO with Okta.\n\nOptions\nServer\n\nprovisionUser: A custom function to provision a user when they sign in with an SSO provider.\n\norganizationProvisioning: Options for provisioning users to an organization.\n\ndefaultOverrideUserInfo: Override user info with the provider info by default.\n\ndisableImplicitSignUp: Disable implicit sign up for new users.\n\ntrustEmailVerified: Trust the email verified flag from the provider.\n\nProp\n\nType\n\nprovisionUser?\nfunction\norganizationProvisioning?\nobject\ndefaultOverrideUserInfo?\nboolean\ndisableImplicitSignUp?\nboolean\nprovidersLimit?\nnumber | function\ndefaultSSO?\nobject\nEdit on GitHub\n\nPrevious Page\n\nOIDC Provider\n\nNext Page\n\nUtility"
  },
  {
    "title": "Bearer Token Authentication | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/bearer",
    "html": "Bearer Token Authentication\nCopy Markdown\nOpen in\n\nThe Bearer plugin enables authentication using Bearer tokens as an alternative to browser cookies. It intercepts requests, adding the Bearer token to the Authorization header before forwarding them to your API.\n\nUse this cautiously; it is intended only for APIs that don't support cookies or require Bearer tokens for authentication. Improper implementation could easily lead to security vulnerabilities.\n\nInstalling the Bearer Plugin\n\nAdd the Bearer plugin to your authentication setup:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { bearer } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [bearer()]\n});\nHow to Use Bearer Tokens\n1. Obtain the Bearer Token\n\nAfter a successful sign-in, you'll receive a session token in the response headers. Store this token securely (e.g., in localStorage):\n\nauth-client.ts\nconst { data } = await authClient.signIn.email({\n    email: \"user@example.com\",\n    password: \"securepassword\"\n}, {\n  onSuccess: (ctx)=>{\n    const authToken = ctx.response.headers.get(\"set-auth-token\") // get the token from the response headers\n    // Store the token securely (e.g., in localStorage)\n    localStorage.setItem(\"bearer_token\", authToken);\n  }\n});\n\nYou can also set this up globally in your auth client:\n\nauth-client.ts\nexport const authClient = createAuthClient({\n    fetchOptions: {\n        onSuccess: (ctx) => {\n            const authToken = ctx.response.headers.get(\"set-auth-token\") // get the token from the response headers\n            // Store the token securely (e.g., in localStorage)\n            if(authToken){\n              localStorage.setItem(\"bearer_token\", authToken);\n            }\n        }\n    }\n});\n\nYou may want to clear the token based on the response status code or other conditions:\n\n2. Configure the Auth Client\n\nSet up your auth client to include the Bearer token in all requests:\n\nauth-client.ts\nexport const authClient = createAuthClient({\n    fetchOptions: {\n        auth: {\n           type:\"Bearer\",\n           token: () => localStorage.getItem(\"bearer_token\") || \"\" // get the token from localStorage\n        }\n    }\n});\n3. Make Authenticated Requests\n\nNow you can make authenticated API calls:\n\nauth-client.ts\n// This request is automatically authenticated\nconst { data } = await authClient.listSessions();\n4. Per-Request Token (Optional)\n\nYou can also provide the token for individual requests:\n\nauth-client.ts\nconst { data } = await authClient.listSessions({\n    fetchOptions: {\n        headers: {\n            Authorization: `Bearer ${token}`\n        }\n    }\n});\n5. Using Bearer Tokens Outside the Auth Client\n\nThe Bearer token can be used to authenticate any request to your API, even when not using the auth client:\n\napi-call.ts\nconst token = localStorage.getItem(\"bearer_token\");\nconst response = await fetch(\"https://api.example.com/data\", {\n  headers: {\n    Authorization: `Bearer ${token}`\n  }\n});\nconst data = await response.json();\n\nAnd in the server, you can use the auth.api.getSession function to authenticate requests:\n\nserver.ts\nimport { auth } from \"@/auth\";\nexport async function handler(req, res) {\n  const session = await auth.api.getSession({\n    headers: req.headers\n  });\n  \n  if (!session) {\n    return res.status(401).json({ error: \"Unauthorized\" });\n  }\n  \n  // Process authenticated request\n  // ...\n}\nOptions\n\nrequireSignature (boolean): Require the token to be signed. Default: false.\n\nEdit on GitHub\n\nPrevious Page\n\nUtility\n\nNext Page\n\nDevice Authorization"
  },
  {
    "title": "Device Authorization | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/device-authorization",
    "html": "Device Authorization\nCopy Markdown\nOpen in\n\nRFC 8628 CLI Smart TV IoT\n\nThe Device Authorization plugin implements the OAuth 2.0 Device Authorization Grant (RFC 8628), enabling authentication for devices with limited input capabilities such as smart TVs, CLI applications, IoT devices, and gaming consoles.\n\nTry It Out\n\nYou can test the device authorization flow right now using the Better Auth CLI:\n\nnpx @better-auth/cli login\n\nThis will demonstrate the complete device authorization flow by:\n\nRequesting a device code from the Better Auth demo server\nDisplaying a user code for you to enter\nOpening your browser to the verification page\nPolling for authorization completion\n\nThe CLI login command is a demo feature that connects to the Better Auth demo server to showcase the device authorization flow in action.\n\nInstallation\nAdd the plugin to your auth config\n\nAdd the device authorization plugin to your server configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { deviceAuthorization } from \"better-auth/plugins\"; \nexport const auth = betterAuth({\n  // ... other config\n  plugins: [ \n    deviceAuthorization({ \n      // Optional configuration\n      expiresIn: \"30m\", // Device code expiration time\n      interval: \"5s\",    // Minimum polling interval\n    }), \n  ], \n});\nMigrate the database\n\nRun the migration or generate the schema to add the necessary tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nAdd the client plugin\n\nAdd the device authorization plugin to your client.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { deviceAuthorizationClient } from \"better-auth/client/plugins\"; \nexport const authClient = createAuthClient({\n  plugins: [ \n    deviceAuthorizationClient(), \n  ], \n});\nHow It Works\n\nThe device flow follows these steps:\n\nDevice requests codes: The device requests a device code and user code from the authorization server\nUser authorizes: The user visits a verification URL and enters the user code\nDevice polls for token: The device polls the server until the user completes authorization\nAccess granted: Once authorized, the device receives an access token\nBasic Usage\nRequesting Device Authorization\n\nTo initiate device authorization, call device.code with the client ID:\n\nClient\nServer\nPOST\n/device/code\nconst { data, error } = await authClient.device.code({\n    client_id, // required\n    scope,\n});\nProp\tDescription\tType\nclient_id\t\nThe OAuth client identifier\n\tstring;\nscope?\t\nSpace-separated list of requested scopes (optional)\n\tstring;\n\nExample usage:\n\nconst { data } = await authClient.device.code({\n  client_id: \"your-client-id\",\n  scope: \"openid profile email\",\n});\nif (data) {\n  console.log(`Please visit: ${data.verification_uri}`);\n  console.log(`And enter code: ${data.user_code}`);\n}\nPolling for Token\n\nAfter displaying the user code, poll for the access token:\n\nClient\nServer\nPOST\n/device/token\nconst { data, error } = await authClient.device.token({\n    grant_type, // required\n    device_code, // required\n    client_id, // required\n});\nProp\tDescription\tType\ngrant_type\t\nMust be \"urn:ietf:params:oauth:grant-type:device_code\"\n\tstring;\ndevice_code\t\nThe device code from the initial request\n\tstring;\nclient_id\t\nThe OAuth client identifier\n\tstring;\n\nExample polling implementation:\n\nlet pollingInterval = 5; // Start with 5 seconds\nconst pollForToken = async () => {\n  const { data, error } = await authClient.device.token({\n    grant_type: \"urn:ietf:params:oauth:grant-type:device_code\",\n    device_code,\n    client_id: yourClientId,\n    fetchOptions: {\n      headers: {\n        \"user-agent\": `My CLI`,\n      },\n    },\n  });\n  if (data?.access_token) {\n    console.log(\"Authorization successful!\");\n  } else if (error) {\n    switch (error.error) {\n      case \"authorization_pending\":\n        // Continue polling\n        break;\n      case \"slow_down\":\n        pollingInterval += 5;\n        break;\n      case \"access_denied\":\n        console.error(\"Access was denied by the user\");\n        return;\n      case \"expired_token\":\n        console.error(\"The device code has expired. Please try again.\");\n        return;\n      default:\n        console.error(`Error: ${error.error_description}`);\n        return;\n    }\n    setTimeout(pollForToken, pollingInterval * 1000);\n  }\n};\npollForToken();\nUser Authorization Flow\n\nThe user authorization flow requires two steps:\n\nCode Verification: Check if the entered user code is valid\nAuthorization: User must be authenticated to approve/deny the device\n\nUsers must be authenticated before they can approve or deny device authorization requests. If not authenticated, redirect them to the login page with a return URL.\n\nCreate a page where users can enter their code:\n\napp/device/page.tsx\nexport default function DeviceAuthorizationPage() {\n  const [userCode, setUserCode] = useState(\"\");\n  const [error, setError] = useState(null);\n  \n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    \n    try {\n      // Format the code: remove dashes and convert to uppercase\n      const formattedCode = userCode.trim().replace(/-/g, \"\").toUpperCase();\n      // Check if the code is valid using GET /device endpoint\n      const response = await authClient.device({\n        query: { user_code: formattedCode },\n      });\n      \n      if (response.data) {\n        // Redirect to approval page\n        window.location.href = `/device/approve?user_code=${formattedCode}`;\n      }\n    } catch (err) {\n      setError(\"Invalid or expired code\");\n    }\n  };\n  \n  return (\n    <form onSubmit={handleSubmit}>\n      <input\n        type=\"text\"\n        value={userCode}\n        onChange={(e) => setUserCode(e.target.value)}\n        placeholder=\"Enter device code (e.g., ABCD-1234)\"\n        maxLength={12}\n      />\n      <button type=\"submit\">Continue</button>\n      {error && <p>{error}</p>}\n    </form>\n  );\n}\nApproving or Denying Device\n\nUsers must be authenticated to approve or deny device authorization requests:\n\nApprove Device\nClient\nServer\nPOST\n/device/approve\nconst { data, error } = await authClient.device.approve({\n    userCode, // required\n});\nProp\tDescription\tType\nuserCode\t\nThe user code to approve\n\tstring;\nDeny Device\nClient\nServer\nPOST\n/device/deny\nconst { data, error } = await authClient.device.deny({\n    userCode, // required\n});\nProp\tDescription\tType\nuserCode\t\nThe user code to deny\n\tstring;\nExample Approval Page\napp/device/approve/page.tsx\nexport default function DeviceApprovalPage() {\n  const { user } = useAuth(); // Must be authenticated\n  const searchParams = useSearchParams();\n  const userCode = searchParams.get(\"userCode\");\n  const [isProcessing, setIsProcessing] = useState(false);\n  \n  const handleApprove = async () => {\n    setIsProcessing(true);\n    try {\n      await authClient.device.approve({\n        userCode: userCode,\n      });\n      // Show success message\n      alert(\"Device approved successfully!\");\n      window.location.href = \"/\";\n    } catch (error) {\n      alert(\"Failed to approve device\");\n    }\n    setIsProcessing(false);\n  };\n  \n  const handleDeny = async () => {\n    setIsProcessing(true);\n    try {\n      await authClient.device.deny({\n        userCode: userCode,\n      });\n      alert(\"Device denied\");\n      window.location.href = \"/\";\n    } catch (error) {\n      alert(\"Failed to deny device\");\n    }\n    setIsProcessing(false);\n  };\n  if (!user) {\n    // Redirect to login if not authenticated\n    window.location.href = `/login?redirect=/device/approve?user_code=${userCode}`;\n    return null;\n  }\n  \n  return (\n    <div>\n      <h2>Device Authorization Request</h2>\n      <p>A device is requesting access to your account.</p>\n      <p>Code: {userCode}</p>\n      \n      <button onClick={handleApprove} disabled={isProcessing}>\n        Approve\n      </button>\n      <button onClick={handleDeny} disabled={isProcessing}>\n        Deny\n      </button>\n    </div>\n  );\n}\nAdvanced Configuration\nClient Validation\n\nYou can validate client IDs to ensure only authorized applications can use the device flow:\n\ndeviceAuthorization({\n  validateClient: async (clientId) => {\n    // Check if client is authorized\n    const client = await db.oauth_clients.findOne({ id: clientId });\n    return client && client.allowDeviceFlow;\n  },\n  \n  onDeviceAuthRequest: async (clientId, scope) => {\n    // Log device authorization requests\n    await logDeviceAuthRequest(clientId, scope);\n  },\n})\nCustom Code Generation\n\nCustomize how device and user codes are generated:\n\ndeviceAuthorization({\n  generateDeviceCode: async () => {\n    // Custom device code generation\n    return crypto.randomBytes(32).toString(\"hex\");\n  },\n  \n  generateUserCode: async () => {\n    // Custom user code generation\n    // Default uses: ABCDEFGHJKLMNPQRSTUVWXYZ23456789\n    // (excludes 0, O, 1, I to avoid confusion)\n    const charset = \"ABCDEFGHJKLMNPQRSTUVWXYZ23456789\";\n    let code = \"\";\n    for (let i = 0; i < 8; i++) {\n      code += charset[Math.floor(Math.random() * charset.length)];\n    }\n    return code;\n  },\n})\nError Handling\n\nThe device flow defines specific error codes:\n\nError Code\tDescription\nauthorization_pending\tUser hasn't approved yet (continue polling)\nslow_down\tPolling too frequently (increase interval)\nexpired_token\tDevice code has expired\naccess_denied\tUser denied the authorization\ninvalid_grant\tInvalid device code or client ID\nExample: CLI Application\n\nHere's a complete example for a CLI application based on the actual demo:\n\ncli-auth.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { deviceAuthorizationClient } from \"better-auth/client/plugins\";\nimport open from \"open\";\nconst authClient = createAuthClient({\n  baseURL: \"http://localhost:3000\",\n  plugins: [deviceAuthorizationClient()],\n});\nasync function authenticateCLI() {\n  console.log(\"🔐 Better Auth Device Authorization Demo\");\n  console.log(\"⏳ Requesting device authorization...\");\n  \n  try {\n    // Request device code\n    const { data, error } = await authClient.device.code({\n      client_id: \"demo-cli\",\n      scope: \"openid profile email\",\n    });\n    \n    if (error || !data) {\n      console.error(\"❌ Error:\", error?.error_description);\n      process.exit(1);\n    }\n    \n    const {\n      device_code,\n      user_code,\n      verification_uri,\n      verification_uri_complete,\n      interval = 5,\n    } = data;\n    \n    console.log(\"\\n📱 Device Authorization in Progress\");\n    console.log(`Please visit: ${verification_uri}`);\n    console.log(`Enter code: ${user_code}\\n`);\n    \n    // Open browser with the complete URL\n    const urlToOpen = verification_uri_complete || verification_uri;\n    if (urlToOpen) {\n      console.log(\"🌐 Opening browser...\");\n      await open(urlToOpen);\n    }\n    \n    console.log(`⏳ Waiting for authorization... (polling every ${interval}s)`);\n    \n    // Poll for token\n    await pollForToken(device_code, interval);\n  } catch (err) {\n    console.error(\"❌ Error:\", err.message);\n    process.exit(1);\n  }\n}\nasync function pollForToken(deviceCode: string, interval: number) {\n  let pollingInterval = interval;\n  \n  return new Promise<void>((resolve) => {\n    const poll = async () => {\n      try {\n        const { data, error } = await authClient.device.token({\n          grant_type: \"urn:ietf:params:oauth:grant-type:device_code\",\n          device_code: deviceCode,\n          client_id: \"demo-cli\",\n        });\n        \n        if (data?.access_token) {\n          console.log(\"\\nAuthorization Successful!\");\n          console.log(\"Access token received!\");\n          \n          // Get user session\n          const { data: session } = await authClient.getSession({\n            fetchOptions: {\n              headers: {\n                Authorization: `Bearer ${data.access_token}`,\n              },\n            },\n          });\n          \n          console.log(`Hello, ${session?.user?.name || \"User\"}!`);\n          resolve();\n          process.exit(0);\n        } else if (error) {\n          switch (error.error) {\n            case \"authorization_pending\":\n              // Continue polling silently\n              break;\n            case \"slow_down\":\n              pollingInterval += 5;\n              console.log(`⚠️  Slowing down polling to ${pollingInterval}s`);\n              break;\n            case \"access_denied\":\n              console.error(\"❌ Access was denied by the user\");\n              process.exit(1);\n              break;\n            case \"expired_token\":\n              console.error(\"❌ The device code has expired. Please try again.\");\n              process.exit(1);\n              break;\n            default:\n              console.error(\"❌ Error:\", error.error_description);\n              process.exit(1);\n          }\n        }\n      } catch (err) {\n        console.error(\"❌ Network error:\", err.message);\n        process.exit(1);\n      }\n      \n      // Schedule next poll\n      setTimeout(poll, pollingInterval * 1000);\n    };\n    \n    // Start polling\n    setTimeout(poll, pollingInterval * 1000);\n  });\n}\n// Run the authentication flow\nauthenticateCLI().catch((err) => {\n  console.error(\"❌ Fatal error:\", err);\n  process.exit(1);\n});\nSecurity Considerations\nRate Limiting: The plugin enforces polling intervals to prevent abuse\nCode Expiration: Device and user codes expire after the configured time (default: 30 minutes)\nClient Validation: Always validate client IDs in production to prevent unauthorized access\nHTTPS Only: Always use HTTPS in production for device authorization\nUser Code Format: User codes use a limited character set (excluding similar-looking characters like 0/O, 1/I) to reduce typing errors\nAuthentication Required: Users must be authenticated before they can approve or deny device requests\nOptions\nServer\n\nexpiresIn: The expiration time for device codes. Default: \"30m\" (30 minutes).\n\ninterval: The minimum polling interval. Default: \"5s\" (5 seconds).\n\nuserCodeLength: The length of the user code. Default: 8.\n\ndeviceCodeLength: The length of the device code. Default: 40.\n\ngenerateDeviceCode: Custom function to generate device codes. Returns a string or Promise<string>.\n\ngenerateUserCode: Custom function to generate user codes. Returns a string or Promise<string>.\n\nvalidateClient: Function to validate client IDs. Takes a clientId and returns boolean or Promise<boolean>.\n\nonDeviceAuthRequest: Hook called when device authorization is requested. Takes clientId and optional scope.\n\nClient\n\nNo client-specific configuration options. The plugin adds the following methods:\n\ndevice(): Verify user code validity\ndevice.code(): Request device and user codes\ndevice.token(): Poll for access token\ndevice.approve(): Approve device (requires authentication)\ndevice.deny(): Deny device (requires authentication)\nSchema\n\nThe plugin requires a new table to store device authorization data.\n\nTable Name: deviceCode\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for the device authorization request\ndeviceCode\tstring\t-\tThe device verification code\nuserCode\tstring\t-\tThe user-friendly code for verification\nuserId\tstring\t\nFK?\tThe ID of the user who approved/denied\nclientId\tstring\t?\tThe OAuth client identifier\nscope\tstring\t?\tRequested OAuth scopes\nstatus\tstring\t-\tCurrent status: pending, approved, or denied\nexpiresAt\tDate\t-\tWhen the device code expires\nlastPolledAt\tDate\t?\tLast time the device polled for status\npollingInterval\tnumber\t?\tMinimum seconds between polls\ncreatedAt\tDate\t-\tWhen the request was created\nupdatedAt\tDate\t-\tWhen the request was last updated\nEdit on GitHub\n\nPrevious Page\n\nBearer\n\nNext Page\n\nCaptcha"
  },
  {
    "title": "Captcha | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/captcha",
    "html": "Captcha\nCopy Markdown\nOpen in\n\nThe Captcha Plugin integrates bot protection into your Better Auth system by adding captcha verification for key endpoints. This plugin ensures that only human users can perform actions like signing up, signing in, or resetting passwords. The following providers are currently supported:\n\nGoogle reCAPTCHA\nCloudflare Turnstile\nhCaptcha\nCaptchaFox\n\nThis plugin works out of the box with Email & Password authentication. To use it with other authentication methods, you will need to configure the endpoints array in the plugin options.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { captcha } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    plugins: [ \n        captcha({ \n            provider: \"cloudflare-turnstile\", // or google-recaptcha, hcaptcha, captchafox\n            secretKey: process.env.TURNSTILE_SECRET_KEY!, \n        }), \n    ], \n});\nAdd the captcha token to your request headers\n\nAdd the captcha token to your request headers for all protected endpoints. This example shows how to include it in a signIn request:\n\nawait authClient.signIn.email({\n    email: \"user@example.com\",\n    password: \"secure-password\",\n    fetchOptions: { \n        headers: { \n            \"x-captcha-response\": turnstileToken, \n            \"x-captcha-user-remote-ip\": userIp, // optional: forwards the user's IP address to the captcha service\n        }, \n    }, \n});\nTo implement Cloudflare Turnstile on the client side, follow the official Cloudflare Turnstile documentation or use a library like react-turnstile.\nTo implement Google reCAPTCHA on the client side, follow the official Google reCAPTCHA documentation or use libraries like react-google-recaptcha (v2) and react-google-recaptcha-v3 (v3).\nTo implement hCaptcha on the client side, follow the official hCaptcha documentation or use libraries like @hcaptcha/react-hcaptcha\nTo implement CaptchaFox on the client side, follow the official CaptchaFox documentation or use libraries like @captchafox/react\nHow it works\n\nThe plugin acts as a middleware: it intercepts all POST requests to configured endpoints (see endpoints in the Plugin Options section).\n\nit validates the captcha token on the server, by calling the captcha provider's /siteverify.\n\nif the token is missing, gets rejected by the captcha provider, or if the /siteverify endpoint is unavailable, the plugin returns an error and interrupts the request.\nif the token is accepted by the captcha provider, the middleware returns undefined, meaning the request is allowed to proceed.\nPlugin Options\nprovider (required): your captcha provider.\nsecretKey (required): your provider's secret key used for the server-side validation.\nendpoints (optional): overrides the default array of paths where captcha validation is enforced. Default is: [\"/sign-up/email\", \"/sign-in/email\", \"/forget-password\",].\nminScore (optional - only Google ReCAPTCHA v3): minimum score threshold. Default is 0.5.\nsiteKey (optional - only hCaptcha and CaptchaFox): prevents tokens issued on one sitekey from being redeemed elsewhere.\nsiteVerifyURLOverride (optional): overrides endpoint URL for the captcha verification request.\nEdit on GitHub\n\nPrevious Page\n\nDevice Authorization\n\nNext Page\n\nHave I Been Pwned"
  },
  {
    "title": "Have I Been Pwned | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/have-i-been-pwned",
    "html": "Have I Been Pwned\nCopy Markdown\nOpen in\n\nThe Have I Been Pwned plugin helps protect user accounts by preventing the use of passwords that have been exposed in known data breaches. It uses the Have I Been Pwned API to check if a password has been compromised.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { haveIBeenPwned } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [\n        haveIBeenPwned()\n    ]\n})\nUsage\n\nWhen a user attempts to create an account or update their password with a compromised password, they'll receive the following default error:\n\n{\n  \"code\": \"PASSWORD_COMPROMISED\",\n  \"message\": \"Password is compromised\"\n}\nConfig\n\nYou can customize the error message:\n\nhaveIBeenPwned({\n    customPasswordCompromisedMessage: \"Please choose a more secure password.\"\n})\nSecurity Notes\nOnly the first 5 characters of the password hash are sent to the API\nThe full password is never transmitted\nProvides an additional layer of account security\nEdit on GitHub\n\nPrevious Page\n\nCaptcha\n\nNext Page\n\nLast Login Method"
  },
  {
    "title": "Multi Session | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/multi-session",
    "html": "Multi Session\nCopy Markdown\nOpen in\n\nThe multi-session plugin allows users to maintain multiple active sessions across different accounts in the same browser. This plugin is useful for applications that require users to switch between multiple accounts without logging out.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { multiSession } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [ \n        multiSession(), \n    ] \n})\nAdd the client Plugin\n\nAdd the client plugin and Specify where the user should be redirected if they need to verify 2nd factor\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { multiSessionClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        multiSessionClient()\n    ]\n})\nUsage\n\nWhenever a user logs in, the plugin will add additional cookie to the browser. This cookie will be used to maintain multiple sessions across different accounts.\n\nList all device sessions\n\nTo list all active sessions for the current user, you can call the listDeviceSessions method.\n\nClient\nServer\nGET\n/multi-session/list-device-sessions\nconst { data, error } = await authClient.multiSession.listDeviceSessions();\nSet active session\n\nTo set the active session, you can call the setActive method.\n\nClient\nServer\nPOST\n/multi-session/set-active\nconst { data, error } = await authClient.multiSession.setActive({\n    sessionToken: \"some-session-token\", // required\n});\nProp\tDescription\tType\nsessionToken\t\nThe session token to set as active.\n\tstring\nRevoke a session\n\nTo revoke a session, you can call the revoke method.\n\nClient\nServer\nPOST\n/multi-session/revoke\nconst { data, error } = await authClient.multiSession.revoke({\n    sessionToken: \"some-session-token\", // required\n});\nProp\tDescription\tType\nsessionToken\t\nThe session token to revoke.\n\tstring\nSignout and Revoke all sessions\n\nWhen a user logs out, the plugin will revoke all active sessions for the user. You can do this by calling the existing signOut method, which handles revoking all sessions automatically.\n\nMax Sessions\n\nYou can specify the maximum number of sessions a user can have by passing the maximumSessions option to the plugin. By default, the plugin allows 5 sessions per device.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    plugins: [\n        multiSession({\n            maximumSessions: 3\n        })\n    ]\n})\nEdit on GitHub\n\nPrevious Page\n\nLast Login Method\n\nNext Page\n\nOAuth Proxy"
  },
  {
    "title": "Last Login Method | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/last-login-method",
    "html": "Last Login Method\nCopy Markdown\nOpen in\n\nThe last login method plugin tracks the most recent authentication method used by users (email, OAuth providers, etc.). This enables you to display helpful indicators on login pages, such as \"Last signed in with Google\" or prioritize certain login methods based on user preferences.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { lastLoginMethod } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    // ... other config options\n    plugins: [\n        lastLoginMethod() \n    ]\n})\nAdd the client plugin to your auth client\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { lastLoginMethodClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        lastLoginMethodClient() \n    ]\n})\nUsage\n\nOnce installed, the plugin automatically tracks the last authentication method used by users. You can then retrieve and display this information in your application.\n\nGetting the Last Used Method\n\nThe client plugin provides several methods to work with the last login method:\n\napp.tsx\nimport { authClient } from \"@/lib/auth-client\"\n// Get the last used login method\nconst lastMethod = authClient.getLastUsedLoginMethod()\nconsole.log(lastMethod) // \"google\", \"email\", \"github\", etc.\n// Check if a specific method was last used\nconst wasGoogle = authClient.isLastUsedLoginMethod(\"google\")\n// Clear the stored method\nauthClient.clearLastUsedLoginMethod()\nUI Integration Example\n\nHere's how to use the plugin to enhance your login page:\n\nsign-in.tsx\nimport { authClient } from \"@/lib/auth-client\"\nimport { Button } from \"@/components/ui/button\"\nimport { Badge } from \"@/components/ui/badge\"\nexport function SignInPage() {\n    const lastMethod = authClient.getLastUsedLoginMethod()\n    \n    return (\n        <div className=\"space-y-4\">\n            <h1>Sign In</h1>\n            \n            {/* Email sign in */}\n            <div className=\"relative\">\n                <Button \n                    onClick={() => authClient.signIn.email({...})}\n                    variant={lastMethod === \"email\" ? \"default\" : \"outline\"}\n                    className=\"w-full\"\n                >\n                    Sign in with Email\n                    {lastMethod === \"email\" && (\n                        <Badge className=\"ml-2\">Last used</Badge>\n                    )}\n                </Button>\n            </div>\n            \n            {/* OAuth providers */}\n            <div className=\"relative\">\n                <Button \n                    onClick={() => authClient.signIn.social({ provider: \"google\" })}\n                    variant={lastMethod === \"google\" ? \"default\" : \"outline\"}\n                    className=\"w-full\"\n                >\n                    Continue with Google\n                    {lastMethod === \"google\" && (\n                        <Badge className=\"ml-2\">Last used</Badge>\n                    )}\n                </Button>\n            </div>\n            \n            <div className=\"relative\">\n                <Button \n                    onClick={() => authClient.signIn.social({ provider: \"github\" })}\n                    variant={lastMethod === \"github\" ? \"default\" : \"outline\"}\n                    className=\"w-full\"\n                >\n                    Continue with GitHub\n                    {lastMethod === \"github\" && (\n                        <Badge className=\"ml-2\">Last used</Badge>\n                    )}\n                </Button>\n            </div>\n        </div>\n    )\n}\nDatabase Persistence\n\nBy default, the last login method is stored only in cookies. For more persistent tracking and analytics, you can enable database storage.\n\nEnable database storage\n\nSet storeInDatabase to true in your plugin configuration:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { lastLoginMethod } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [\n        lastLoginMethod({\n            storeInDatabase: true\n        })\n    ]\n})\nRun database migration\n\nThe plugin will automatically add a lastLoginMethod field to your user table. Run the migration to apply the changes:\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\nAccess database field\n\nWhen database storage is enabled, the lastLoginMethod field becomes available in user objects:\n\nuser-profile.tsx\nimport { auth } from \"@/lib/auth\"\n// Server-side access\nconst session = await auth.api.getSession({ headers })\nconsole.log(session?.user.lastLoginMethod) // \"google\", \"email\", etc.\n// Client-side access via session\nconst { data: session } = authClient.useSession()\nconsole.log(session?.user.lastLoginMethod)\nDatabase Schema\n\nWhen storeInDatabase is enabled, the plugin adds the following field to the user table:\n\nTable: user\n\nField Name\tType\tKey\tDescription\nlastLoginMethod\tstring\t?\tThe last authentication method used by the user\nCustom Schema Configuration\n\nYou can customize the database field name:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { lastLoginMethod } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [\n        lastLoginMethod({\n            storeInDatabase: true,\n            schema: {\n                user: {\n                    lastLoginMethod: \"last_auth_method\" // Custom field name\n                }\n            }\n        })\n    ]\n})\nConfiguration Options\n\nThe last login method plugin accepts the following options:\n\nServer Options\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { lastLoginMethod } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [\n        lastLoginMethod({\n            // Cookie configuration\n            cookieName: \"better-auth.last_used_login_method\", // Default: \"better-auth.last_used_login_method\"\n            maxAge: 60 * 60 * 24 * 30, // Default: 30 days in seconds\n            \n            // Database persistence\n            storeInDatabase: false, // Default: false\n            \n            // Custom method resolution\n            customResolveMethod: (ctx) => {\n                // Custom logic to determine the login method\n                if (ctx.path === \"/oauth/callback/custom-provider\") {\n                    return \"custom-provider\"\n                }\n                // Return null to use default resolution\n                return null\n            },\n            \n            // Schema customization (when storeInDatabase is true)\n            schema: {\n                user: {\n                    lastLoginMethod: \"custom_field_name\"\n                }\n            }\n        })\n    ]\n})\n\ncookieName: string\n\nThe name of the cookie used to store the last login method\nDefault: \"better-auth.last_used_login_method\"\nNote: This cookie is httpOnly: false to allow client-side JavaScript access for UI features\n\nmaxAge: number\n\nCookie expiration time in seconds\nDefault: 2592000 (30 days)\n\nstoreInDatabase: boolean\n\nWhether to store the last login method in the database\nDefault: false\nWhen enabled, adds a lastLoginMethod field to the user table\n\ncustomResolveMethod: (ctx: GenericEndpointContext) => string | null\n\nCustom function to determine the login method from the request context\nReturn null to use the default resolution logic\nUseful for custom OAuth providers or authentication flows\n\nschema: object\n\nCustomize database field names when storeInDatabase is enabled\nAllows mapping the lastLoginMethod field to a custom column name\nClient Options\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { lastLoginMethodClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        lastLoginMethodClient({\n            cookieName: \"better-auth.last_used_login_method\" // Default: \"better-auth.last_used_login_method\"\n        })\n    ]\n})\n\ncookieName: string\n\nThe name of the cookie to read the last login method from\nMust match the server-side cookieName configuration\nDefault: \"better-auth.last_used_login_method\"\nDefault Method Resolution\n\nBy default, the plugin tracks these authentication methods:\n\nEmail authentication: \"email\"\nOAuth providers: Provider ID (e.g., \"google\", \"github\", \"discord\")\nOAuth2 callbacks: Provider ID from URL path\nSign up methods: Tracked the same as sign in methods\n\nThe plugin automatically detects the method from these endpoints:\n\n/callback/:id - OAuth callback with provider ID\n/oauth2/callback/:id - OAuth2 callback with provider ID\n/sign-in/email - Email sign in\n/sign-up/email - Email sign up\nCross-Domain Support\n\nThe plugin automatically inherits cookie settings from Better Auth's centralized cookie system. This solves the problem where the last login method wouldn't persist across:\n\nCross-subdomain setups: auth.example.com → app.example.com\nCross-origin setups: api.company.com → app.different.com\n\nWhen you enable crossSubDomainCookies or crossOriginCookies in your Better Auth config, the plugin will automatically use the same domain, secure, and sameSite settings as your session cookies, ensuring consistent behavior across your application.\n\nAdvanced Examples\nCustom Provider Tracking\n\nIf you have custom OAuth providers or authentication methods, you can use the customResolveMethod option:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { lastLoginMethod } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [\n        lastLoginMethod({\n            customResolveMethod: (ctx) => {\n                // Track custom SAML provider\n                if (ctx.path === \"/saml/callback\") {\n                    return \"saml\"\n                }\n                \n                // Track magic link authentication\n                if (ctx.path === \"/magic-link/verify\") {\n                    return \"magic-link\"\n                }\n                \n                // Track phone authentication\n                if (ctx.path === \"/sign-in/phone\") {\n                    return \"phone\"\n                }\n                \n                // Return null to use default logic\n                return null\n            }\n        })\n    ]\n})\nEdit on GitHub\n\nPrevious Page\n\nHave I Been Pwned\n\nNext Page\n\nMulti Session"
  },
  {
    "title": "OAuth Proxy | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/oauth-proxy",
    "html": "OAuth Proxy\nCopy Markdown\nOpen in\n\nA proxy plugin, that allows you to proxy OAuth requests. Useful for development and preview deployments where the redirect URL can't be known in advance to add to the OAuth provider.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { oAuthProxy } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [ \n        oAuthProxy({ \n            productionURL: \"https://my-main-app.com\", // Optional - if the URL isn't inferred correctly\n            currentURL: \"http://localhost:3000\", // Optional - if the URL isn't inferred correctly\n        }), \n    ] \n})\nAdd redirect URL to your OAuth provider\n\nFor the proxy server to work properly, you’ll need to pass the redirect URL of your main production app registered with the OAuth provider in your social provider config. This needs to be done for each social provider you want to proxy requests for.\n\nexport const auth = betterAuth({\n   plugins: [\n       oAuthProxy(),\n   ], \n   socialProviders: {\n        github: {\n            clientId: \"your-client-id\",\n            clientSecret: \"your-client-secret\",\n            redirectURI: \"https://my-main-app.com/api/auth/callback/github\"\n        }\n   }\n})\nHow it works\n\nThe plugin adds an endpoint to your server that proxies OAuth requests. When you initiate a social sign-in, it sets the redirect URL to this proxy endpoint. After the OAuth provider redirects back to your server, the plugin then forwards the user to the original callback URL.\n\nawait authClient.signIn.social({\n    provider: \"github\",\n    callbackURL: \"/dashboard\" // the plugin will override this to something like \"http://localhost:3000/api/auth/oauth-proxy?callbackURL=/dashboard\"\n})\n\nWhen the OAuth provider returns the user to your server, the plugin automatically redirects them to the intended callback URL.\n\nTo share cookies between the proxy server and your main server it uses URL query parameters to pass the cookies encrypted in the URL. This is secure as the cookies are encrypted and can only be decrypted by the server.\n\nThis plugin requires skipping the state cookie check. This has security implications and should only be used in dev or staging environments. If baseURL and productionURL are the same, the plugin will not proxy the request.\n\nOptions\n\ncurrentURL: The application's current URL is automatically determined by the plugin. It first checks for the request URL if invoked by a client, then it checks the base URL from popular hosting providers, and finally falls back to the baseURL in your auth config. If the URL isn’t inferred correctly, you can specify it manually here.\n\nproductionURL: If this value matches the baseURL in your auth config, requests will not be proxied. Defaults to the BETTER_AUTH_URL environment variable.\n\nEdit on GitHub\n\nPrevious Page\n\nMulti Session\n\nNext Page\n\nOne-Time Token"
  },
  {
    "title": "One-Time Token Plugin | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/one-time-token",
    "html": "One-Time Token Plugin\nCopy Markdown\nOpen in\n\nThe One-Time Token (OTT) plugin provides functionality to generate and verify secure, single-use session tokens. These are commonly used for across domains authentication.\n\nInstallation\nAdd the plugin to your auth config\n\nTo use the One-Time Token plugin, add it to your auth config.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { oneTimeToken } from \"better-auth/plugins/one-time-token\";\nexport const auth = betterAuth({\n    plugins: [\n      oneTimeToken()\n    ]\n    // ... other auth config\n});\nAdd the client plugin\n\nNext, include the one-time-token client plugin in your authentication client instance.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { oneTimeTokenClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n    plugins: [\n        oneTimeTokenClient()\n    ]\n})\nUsage\n1. Generate a Token\n\nGenerate a token using auth.api.generateOneTimeToken or authClient.oneTimeToken.generate\n\nClient\nServer\nGET\n/one-time-token/generate\nconst { data, error } = await authClient.oneTimeToken.generate();\n\nThis will return a token that is attached to the current session which can be used to verify the one-time token. By default, the token will expire in 3 minutes.\n\n2. Verify the Token\n\nWhen the user clicks the link or submits the token, use the auth.api.verifyOneTimeToken or authClient.oneTimeToken.verify method in another API route to validate it.\n\nClient\nServer\nPOST\n/one-time-token/verify\nconst { data, error } = await authClient.oneTimeToken.verify({\n    token: \"some-token\", // required\n});\nProp\tDescription\tType\ntoken\t\nThe token to verify.\n\tstring\n\nThis will return the session that was attached to the token.\n\nOptions\n\nThese options can be configured when adding the oneTimeToken plugin:\n\ndisableClientRequest (boolean): Optional. If true, the token will only be generated on the server side. Default: false.\nexpiresIn (number): Optional. The duration for which the token is valid in minutes. Default: 3.\noneTimeToken({\n    expiresIn: 10 // 10 minutes\n})\n\ngenerateToken: A custom token generator function that takes session object and a ctx as parameters.\n\nstoreToken: Optional. This option allows you to configure how the token is stored in your database.\n\nplain: The token is stored in plain text. (Default)\nhashed: The token is hashed using the default hasher.\ncustom-hasher: A custom hasher function that takes a token and returns a hashed token.\n\nNote: It will not affect the token that's sent, it will only affect the token stored in your database.\n\nExamples:\n\nNo hashing (default)\noneTimeToken({\n    storeToken: \"plain\"\n})\nbuilt-in hasher\noneTimeToken({\n    storeToken: \"hashed\"\n})\ncustom hasher\noneTimeToken({\n    storeToken: {\n        type: \"custom-hasher\",\n        hash: async (token) => {\n            return myCustomHasher(token);\n        }\n    }\n})\nEdit on GitHub\n\nPrevious Page\n\nOAuth Proxy\n\nNext Page\n\nOpen API"
  },
  {
    "title": "Open API | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/open-api",
    "html": "Open API\nCopy Markdown\nOpen in\n\nThis is a plugin that provides an Open API reference for Better Auth. It shows all endpoints added by plugins and the core. It also provides a way to test the endpoints. It uses Scalar to display the Open API reference.\n\nThis plugin is still in the early stages of development. We are working on adding more features to it and filling in the gaps.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { openAPI } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [ \n        openAPI(), \n    ] \n})\nNavigate to /api/auth/reference to view the Open API reference\n\nEach plugin endpoints are grouped by the plugin name. The core endpoints are grouped under the Default group. And Model schemas are grouped under the Models group.\n\nUsage\n\nThe Open API reference is generated using the OpenAPI 3.0 specification. You can use the reference to generate client libraries, documentation, and more.\n\nThe reference is generated using the Scalar library. Scalar provides a way to view and test the endpoints. You can test the endpoints by clicking on the Try it out button and providing the required parameters.\n\nGenerated Schema\n\nTo get the generated Open API schema directly as JSON, you can do auth.api.generateOpenAPISchema(). This will return the Open API schema as a JSON object.\n\nimport { auth } from \"~/lib/auth\"\nconst openAPISchema = await auth.api.generateOpenAPISchema()\nconsole.log(openAPISchema)\nUsing Scalar with Multiple Sources\n\nIf you're using Scalar for your API documentation, you can add Better Auth as an additional source alongside your main API:\n\nWhen using Hono with Scalar for OpenAPI documentation, you can integrate Better Auth by adding it as a source:\n\napp.get(\"/docs\", Scalar({\n  pageTitle: \"API Documentation\", \n  sources: [\n    { url: \"/api/open-api\", title: \"API\" },\n    // Better Auth schema generation endpoint\n    { url: \"/api/auth/open-api/generate-schema\", title: \"Auth\" },\n  ],\n}));\nConfiguration\n\npath - The path where the Open API reference is served. Default is /api/auth/reference. You can change it to any path you like, but keep in mind that it will be appended to the base path of your auth server.\n\ndisableDefaultReference - If set to true, the default Open API reference UI by Scalar will be disabled. Default is false.\n\nThis allows you to display both your application's API and Better Auth's authentication endpoints in a unified documentation interface.\n\ntheme - Allows you to change the theme of the OpenAPI reference page. Default is default.\n\nEdit on GitHub\n\nPrevious Page\n\nOne-Time Token\n\nNext Page\n\nJWT"
  },
  {
    "title": "JWT | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/jwt",
    "html": "JWT\nCopy Markdown\nOpen in\n\nThe JWT plugin provides endpoints to retrieve a JWT token and a JWKS endpoint to verify the token.\n\nThis plugin is not meant as a replacement for the session. It's meant to be used for services that require JWT tokens. If you're looking to use JWT tokens for authentication, check out the Bearer Plugin.\n\nInstallation\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { jwt } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    plugins: [ \n        jwt(), \n    ] \n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary fields and tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the fields manually.\n\nUsage\n\nOnce you've installed the plugin, you can start using the JWT & JWKS plugin to get the token and the JWKS through their respective endpoints.\n\nJWT\nRetrieve the token\n\nThere are multiple ways to retrieve JWT tokens:\n\nUsing the client plugin (recommended)\n\nAdd the jwtClient plugin to your auth client configuration:\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { jwtClient } from \"better-auth/client/plugins\"\nexport const authClient = createAuthClient({\n  plugins: [\n    jwtClient() \n  ]\n})\n\nThen use the client to get JWT tokens:\n\nconst { data, error } = await authClient.token()\nif (error) {\n  // handle error\n}\nif (data) {\n  const jwtToken = data.token\n  // Use this token for authenticated requests to external services\n}\n\nThis is the recommended approach for client applications that need JWT tokens for external API authentication.\n\nUsing your session token\n\nTo get the token, call the /token endpoint. This will return the following:\n\n  { \n    \"token\": \"ey...\"\n  }\n\nMake sure to include the token in the Authorization header of your requests if the bearer plugin is added in your auth configuration.\n\nawait fetch(\"/api/auth/token\", {\n  headers: {\n    \"Authorization\": `Bearer ${token}`\n  },\n})\nFrom set-auth-jwt header\n\nWhen you call getSession method, a JWT is returned in the set-auth-jwt header, which you can use to send to your services directly.\n\nawait authClient.getSession({\n  fetchOptions: {\n    onSuccess: (ctx)=>{\n      const jwt = ctx.response.headers.get(\"set-auth-jwt\")\n    }\n  }\n})\nVerifying the token\n\nThe token can be verified in your own service, without the need for an additional verify call or database check. For this JWKS is used. The public key can be fetched from the /api/auth/jwks endpoint.\n\nSince this key is not subject to frequent changes, it can be cached indefinitely. The key ID (kid) that was used to sign a JWT is included in the header of the token. In case a JWT with a different kid is received, it is recommended to fetch the JWKS again.\n\n  {\n    \"keys\": [\n        {\n            \"crv\": \"Ed25519\",\n            \"x\": \"bDHiLTt7u-VIU7rfmcltcFhaHKLVvWFy-_csKZARUEU\",\n            \"kty\": \"OKP\",\n            \"kid\": \"c5c7995d-0037-4553-8aee-b5b620b89b23\"\n        }\n    ]\n  }\nOAuth Provider Mode\n\nIf you are making your system oAuth compliant (such as when utilizing the OIDC or MCP plugins), you MUST disable the /token endpoint (oAuth equivalent /oauth2/token) and disable setting the jwt header (oAuth equivalent /oauth2/userinfo).\n\nauth.ts\nbetterAuth({\n  disabledPaths: [\n    \"/token\",\n  ],\n  plugins: [jwt({\n    disableSettingJwtHeader: true,\n  })]\n})\nExample using jose with remote JWKS\nimport { jwtVerify, createRemoteJWKSet } from 'jose'\nasync function validateToken(token: string) {\n  try {\n    const JWKS = createRemoteJWKSet(\n      new URL('http://localhost:3000/api/auth/jwks')\n    )\n    const { payload } = await jwtVerify(token, JWKS, {\n      issuer: 'http://localhost:3000', // Should match your JWT issuer, which is the BASE_URL\n      audience: 'http://localhost:3000', // Should match your JWT audience, which is the BASE_URL by default\n    })\n    return payload\n  } catch (error) {\n    console.error('Token validation failed:', error)\n    throw error\n  }\n}\n// Usage example\nconst token = 'your.jwt.token' // this is the token you get from the /api/auth/token endpoint\nconst payload = await validateToken(token)\nExample with local JWKS\nimport { jwtVerify, createLocalJWKSet } from 'jose'\nasync function validateToken(token: string) {\n  try {\n    /**\n     * This is the JWKS that you get from the /api/auth/\n     * jwks endpoint\n     */\n    const storedJWKS = {\n      keys: [{\n        //...\n      }]\n    };\n    const JWKS = createLocalJWKSet({\n      keys: storedJWKS.data?.keys!,\n    })\n    const { payload } = await jwtVerify(token, JWKS, {\n      issuer: 'http://localhost:3000', // Should match your JWT issuer, which is the BASE_URL\n      audience: 'http://localhost:3000', // Should match your JWT audience, which is the BASE_URL by default\n    })\n    return payload\n  } catch (error) {\n    console.error('Token validation failed:', error)\n    throw error\n  }\n}\n// Usage example\nconst token = 'your.jwt.token' // this is the token you get from the /api/auth/token endpoint\nconst payload = await validateToken(token)\nRemote JWKS Url\n\nDisables the /jwks endpoint and uses this endpoint in any discovery such as OIDC.\n\nUseful if your JWKS are not managed at /jwks or if your jwks are signed with a certificate and placed on your CDN.\n\nNOTE: you MUST specify which asymmetric algorithm is used for signing.\n\nauth.ts\njwt({\n  jwks: {\n    remoteUrl: \"https://example.com/.well-known/jwks.json\",\n    keyPairConfig: {\n      alg: 'ES256',\n    },\n  }\n})\nCustom Signing\n\nThis is an advanced feature. Configuration outside of this plugin MUST be provided.\n\nImplementers:\n\nremoteUrl must be defined if using the sign function. This shall store all active keys, not just the current one.\nIf using localized approach, ensure server uses the latest private key when rotated. Depending on deployment, the server may need to be restarted.\nWhen using remote approach, verify the payload is unchanged after transit. Use integrity validation like CRC32 or SHA256 checks if available.\nLocalized Signing\nauth.ts\njwt({\n  jwks: {\n    remoteUrl: \"https://example.com/.well-known/jwks.json\",\n    keyPairConfig: {\n      alg: 'EdDSA',\n    },\n  },\n  jwt: {\n    sign: async (jwtPayload: JWTPayload) => {\n      // this is pseudocode\n      return await new SignJWT(jwtPayload)\n        .setProtectedHeader({\n          alg: \"EdDSA\",\n          kid: process.env.currentKid,\n          typ: \"JWT\",\n        })\n        .sign(process.env.clientPrivateKey);\n    },\n  },\n})\nRemote Signing\n\nUseful if you are using a remote Key Management Service such as Google KMS, Amazon KMS, or Azure Key Vault.\n\nauth.ts\njwt({\n  jwks: {\n    remoteUrl: \"https://example.com/.well-known/jwks.json\",\n    keyPairConfig: {\n      alg: 'ES256',\n    },\n  },\n  jwt: {\n    sign: async (jwtPayload: JWTPayload) => {\n      // this is pseudocode\n      const headers = JSON.stringify({ kid: '123', alg: 'ES256', typ: 'JWT' })\n      const payload = JSON.stringify(jwtPayload)\n      const encodedHeaders = Buffer.from(headers).toString('base64url')\n      const encodedPayload = Buffer.from(payload).toString('base64url')\n      const hash = createHash('sha256')\n      const data = `${encodedHeaders}.${encodedPayload}`\n      hash.update(Buffer.from(data))\n      const digest = hash.digest()\n      const sig = await remoteSign(digest)\n      // integrityCheck(sig)\n      const jwt = `${data}.${sig}`\n      // verifyJwt(jwt)\n      return jwt\n    },\n  },\n})\nSchema\n\nThe JWT plugin adds the following tables to the database:\n\nJWKS\n\nTable Name: jwks\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each web key\npublicKey\tstring\t-\tThe public part of the web key\nprivateKey\tstring\t-\tThe private part of the web key\ncreatedAt\tDate\t-\tTimestamp of when the web key was created\n\nYou can customize the table name and fields for the jwks table. See the Database concept documentation for more information on how to customize plugin schema.\n\nOptions\nAlgorithm of the Key Pair\n\nThe algorithm used for the generation of the key pair. The default is EdDSA with the Ed25519 curve. Below are the available options:\n\nauth.ts\njwt({\n  jwks: {\n    keyPairConfig: {\n      alg: \"EdDSA\",\n      crv: \"Ed25519\"\n    }\n  }\n})\nEdDSA\nDefault Curve: Ed25519\nOptional Property: crv\nAvailable options: Ed25519, Ed448\nDefault: Ed25519\nES256\nNo additional properties\nRSA256\nOptional Property: modulusLength\nExpects a number\nDefault: 2048\nPS256\nOptional Property: modulusLength\nExpects a number\nDefault: 2048\nECDH-ES\nOptional Property: crv\nAvailable options: P-256, P-384, P-521\nDefault: P-256\nES512\nNo additional properties\nDisable private key encryption\n\nBy default, the private key is encrypted using AES256 GCM. You can disable this by setting the disablePrivateKeyEncryption option to true.\n\nFor security reasons, it's recommended to keep the private key encrypted.\n\nauth.ts\njwt({\n  jwks: {\n    disablePrivateKeyEncryption: true\n  }\n})\nModify JWT payload\n\nBy default the entire user object is added to the JWT payload. You can modify the payload by providing a function to the definePayload option.\n\nauth.ts\njwt({\n  jwt: {\n    definePayload: ({user}) => {\n      return {\n        id: user.id,\n        email: user.email,\n        role: user.role\n      }\n    }\n  }\n})\nModify Issuer, Audience, Subject or Expiration time\n\nIf none is given, the BASE_URL is used as the issuer and the audience is set to the BASE_URL. The expiration time is set to 15 minutes.\n\nauth.ts\njwt({\n  jwt: {\n    issuer: \"https://example.com\",\n    audience: \"https://example.com\",\n    expirationTime: \"1h\",\n    getSubject: (session) => {\n      // by default the subject is the user id\n      return session.user.email\n    }\n  }\n})\nEdit on GitHub\n\nPrevious Page\n\nOpen API\n\nNext Page\n\n3rd party"
  },
  {
    "title": "Polar | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/polar",
    "html": "Polar\nCopy Markdown\nOpen in\n\nPolar is a developer first payment infrastructure. Out of the box it provides a lot of developer first integrations for payments, checkouts and more. This plugin helps you integrate Polar with Better Auth to make your auth + payments flow seamless.\n\nThis plugin is maintained by Polar team. For bugs, issues or feature requests, please visit the Polar GitHub repo.\n\nFeatures\nCheckout Integration\nCustomer Portal\nAutomatic Customer creation on signup\nEvent Ingestion & Customer Meters for flexible Usage Based Billing\nHandle Polar Webhooks securely with signature verification\nReference System to associate purchases with organizations\nInstallation\npnpm add better-auth @polar-sh/better-auth @polar-sh/sdk\nPreparation\n\nGo to your Polar Organization Settings, and create an Organization Access Token. Add it to your environment.\n\n# .env\nPOLAR_ACCESS_TOKEN=...\nConfiguring BetterAuth Server\n\nThe Polar plugin comes with a handful additional plugins which adds functionality to your stack.\n\nCheckout - Enables a seamless checkout integration\nPortal - Makes it possible for your customers to manage their orders, subscriptions & granted benefits\nUsage - Simple extension for listing customer meters & ingesting events for Usage Based Billing\nWebhooks - Listen for relevant Polar webhooks\nimport { betterAuth } from \"better-auth\";\nimport { polar, checkout, portal, usage, webhooks } from \"@polar-sh/better-auth\";\nimport { Polar } from \"@polar-sh/sdk\";\nconst polarClient = new Polar({\n    accessToken: process.env.POLAR_ACCESS_TOKEN,\n    // Use 'sandbox' if you're using the Polar Sandbox environment\n    // Remember that access tokens, products, etc. are completely separated between environments.\n    // Access tokens obtained in Production are for instance not usable in the Sandbox environment.\n    server: 'sandbox'\n});\nconst auth = betterAuth({\n    // ... Better Auth config\n    plugins: [\n        polar({\n            client: polarClient,\n            createCustomerOnSignUp: true,\n            use: [\n                checkout({\n                    products: [\n                        {\n                            productId: \"123-456-789\", // ID of Product from Polar Dashboard\n                            slug: \"pro\" // Custom slug for easy reference in Checkout URL, e.g. /checkout/pro\n                        }\n                    ],\n                    successUrl: \"/success?checkout_id={CHECKOUT_ID}\",\n                    authenticatedUsersOnly: true\n                }),\n                portal(),\n                usage(),\n                webhooks({\n                    secret: process.env.POLAR_WEBHOOK_SECRET,\n                    onCustomerStateChanged: (payload) => // Triggered when anything regarding a customer changes\n                    onOrderPaid: (payload) => // Triggered when an order was paid (purchase, subscription renewal, etc.)\n                    ...  // Over 25 granular webhook handlers\n                    onPayload: (payload) => // Catch-all for all events\n                })\n            ],\n        })\n    ]\n});\nConfiguring BetterAuth Client\n\nYou will be using the BetterAuth Client to interact with the Polar functionalities.\n\nimport { createAuthClient } from \"better-auth/react\";\nimport { polarClient } from \"@polar-sh/better-auth\";\n// This is all that is needed\n// All Polar plugins, etc. should be attached to the server-side BetterAuth config\nexport const authClient = createAuthClient({\n  plugins: [polarClient()],\n});\nConfiguration Options\nimport { betterAuth } from \"better-auth\";\nimport {\n  polar,\n  checkout,\n  portal,\n  usage,\n  webhooks,\n} from \"@polar-sh/better-auth\";\nimport { Polar } from \"@polar-sh/sdk\";\nconst polarClient = new Polar({\n  accessToken: process.env.POLAR_ACCESS_TOKEN,\n  // Use 'sandbox' if you're using the Polar Sandbox environment\n  // Remember that access tokens, products, etc. are completely separated between environments.\n  // Access tokens obtained in Production are for instance not usable in the Sandbox environment.\n  server: \"sandbox\",\n});\nconst auth = betterAuth({\n  // ... Better Auth config\n  plugins: [\n    polar({\n      client: polarClient,\n      createCustomerOnSignUp: true,\n      getCustomerCreateParams: ({ user }, request) => ({\n        metadata: {\n          myCustomProperty: 123,\n        },\n      }),\n      use: [\n        // This is where you add Polar plugins\n      ],\n    }),\n  ],\n});\nRequired Options\nclient: Polar SDK client instance\nOptional Options\ncreateCustomerOnSignUp: Automatically create a Polar customer when a user signs up\ngetCustomerCreateParams: Custom function to provide additional customer creation metadata\nCustomers\n\nWhen createCustomerOnSignUp is enabled, a new Polar Customer is automatically created when a new User is added in the Better-Auth Database.\n\nAll new customers are created with an associated externalId, which is the ID of your User in the Database. This allows us to skip any Polar to User mapping in your Database.\n\nCheckout Plugin\n\nTo support checkouts in your app, simply pass the Checkout plugin to the use-property.\n\nimport { polar, checkout } from \"@polar-sh/better-auth\";\nconst auth = betterAuth({\n    // ... Better Auth config\n    plugins: [\n        polar({\n            ...\n            use: [\n                checkout({\n                    // Optional field - will make it possible to pass a slug to checkout instead of Product ID\n                    products: [ { productId: \"123-456-789\", slug: \"pro\" } ],\n                    // Relative URL to return to when checkout is successfully completed\n                    successUrl: \"/success?checkout_id={CHECKOUT_ID}\",\n                    // Whether you want to allow unauthenticated checkout sessions or not\n                    authenticatedUsersOnly: true\n                })\n            ],\n        })\n    ]\n});\n\nWhen checkouts are enabled, you're able to initialize Checkout Sessions using the checkout-method on the BetterAuth Client. This will redirect the user to the Product Checkout.\n\nawait authClient.checkout({\n  // Any Polar Product ID can be passed here\n  products: [\"e651f46d-ac20-4f26-b769-ad088b123df2\"],\n  // Or, if you setup \"products\" in the Checkout Config, you can pass the slug\n  slug: \"pro\",\n});\n\nCheckouts will automatically carry the authenticated User as the customer to the checkout. Email-address will be \"locked-in\".\n\nIf authenticatedUsersOnly is false - then it will be possible to trigger checkout sessions without any associated customer.\n\nOrganization Support\n\nThis plugin supports the Organization plugin. If you pass the organization ID to the Checkout referenceId, you will be able to keep track of purchases made from organization members.\n\nconst organizationId = (await authClient.organization.list())?.data?.[0]?.id,\nawait authClient.checkout({\n    // Any Polar Product ID can be passed here\n    products: [\"e651f46d-ac20-4f26-b769-ad088b123df2\"],\n    // Or, if you setup \"products\" in the Checkout Config, you can pass the slug\n    slug: 'pro',\n    // Reference ID will be saved as `referenceId` in the metadata of the checkout, order & subscription object\n    referenceId: organizationId\n});\nPortal Plugin\n\nA plugin which enables customer management of their purchases, orders and subscriptions.\n\nimport { polar, checkout, portal } from \"@polar-sh/better-auth\";\nconst auth = betterAuth({\n    // ... Better Auth config\n    plugins: [\n        polar({\n            ...\n            use: [\n                checkout(...),\n                portal()\n            ],\n        })\n    ]\n});\n\nThe portal-plugin gives the BetterAuth Client a set of customer management methods, scoped under authClient.customer.\n\nCustomer Portal Management\n\nThe following method will redirect the user to the Polar Customer Portal, where they can see orders, purchases, subscriptions, benefits, etc.\n\nawait authClient.customer.portal();\nCustomer State\n\nThe portal plugin also adds a convenient state-method for retrieving the general Customer State.\n\nconst { data: customerState } = await authClient.customer.state();\n\nThe customer state object contains:\n\nAll the data about the customer.\nThe list of their active subscriptions\nNote: This does not include subscriptions done by a parent organization. See the subscription list-method below for more information.\nThe list of their granted benefits.\nThe list of their active meters, with their current balance.\n\nThus, with that single object, you have all the required information to check if you should provision access to your service or not.\n\nYou can learn more about the Polar Customer State in the Polar Docs.\n\nBenefits, Orders & Subscriptions\n\nThe portal plugin adds 3 convenient methods for listing benefits, orders & subscriptions relevant to the authenticated user/customer.\n\nAll of these methods use the Polar CustomerPortal APIs\n\nBenefits\n\nThis method only lists granted benefits for the authenticated user/customer.\n\nconst { data: benefits } = await authClient.customer.benefits.list({\n  query: {\n    page: 1,\n    limit: 10,\n  },\n});\nOrders\n\nThis method lists orders like purchases and subscription renewals for the authenticated user/customer.\n\nconst { data: orders } = await authClient.customer.orders.list({\n  query: {\n    page: 1,\n    limit: 10,\n    productBillingType: \"one_time\", // or 'recurring'\n  },\n});\nSubscriptions\n\nThis method lists the subscriptions associated with authenticated user/customer.\n\nconst { data: subscriptions } = await authClient.customer.subscriptions.list({\n  query: {\n    page: 1,\n    limit: 10,\n    active: true,\n  },\n});\n\nImportant - Organization Support\n\nThis will not return subscriptions made by a parent organization to the authenticated user.\n\nHowever, you can pass a referenceId to this method. This will return all subscriptions associated with that referenceId instead of subscriptions associated with the user.\n\nSo in order to figure out if a user should have access, pass the user's organization ID to see if there is an active subscription for that organization.\n\nconst organizationId = (await authClient.organization.list())?.data?.[0]?.id,\nconst { data: subscriptions } = await authClient.customer.orders.list({\n    query: {\n\t    page: 1,\n\t\tlimit: 10,\n\t\tactive: true,\n        referenceId: organizationId\n    },\n});\nconst userShouldHaveAccess = subscriptions.some(\n    sub => // Your logic to check subscription product or whatever.\n)\nUsage Plugin\n\nA simple plugin for Usage Based Billing.\n\nimport { polar, checkout, portal, usage } from \"@polar-sh/better-auth\";\nconst auth = betterAuth({\n    // ... Better Auth config\n    plugins: [\n        polar({\n            ...\n            use: [\n                checkout(...),\n                portal(),\n                usage()\n            ],\n        })\n    ]\n});\nEvent Ingestion\n\nPolar's Usage Based Billing builds entirely on event ingestion. Ingest events from your application, create Meters to represent that usage, and add metered prices to Products to charge for it.\n\nLearn more about Usage Based Billing in the Polar Docs.\n\nconst { data: ingested } = await authClient.usage.ingest({\n  event: \"file-uploads\",\n  metadata: {\n    uploadedFiles: 12,\n  },\n});\n\nThe authenticated user is automatically associated with the ingested event.\n\nCustomer Meters\n\nA simple method for listing the authenticated user's Usage Meters, or as we call them, Customer Meters.\n\nCustomer Meter's contains all information about their consumption on your defined meters.\n\nCustomer Information\nMeter Information\nCustomer Meter Information\nConsumed Units\nCredited Units\nBalance\nconst { data: customerMeters } = await authClient.usage.meters.list({\n  query: {\n    page: 1,\n    limit: 10,\n  },\n});\nWebhooks Plugin\n\nThe Webhooks plugin can be used to capture incoming events from your Polar organization.\n\nimport { polar, webhooks } from \"@polar-sh/better-auth\";\nconst auth = betterAuth({\n    // ... Better Auth config\n    plugins: [\n        polar({\n            ...\n            use: [\n                webhooks({\n                    secret: process.env.POLAR_WEBHOOK_SECRET,\n                    onCustomerStateChanged: (payload) => // Triggered when anything regarding a customer changes\n                    onOrderPaid: (payload) => // Triggered when an order was paid (purchase, subscription renewal, etc.)\n                    ...  // Over 25 granular webhook handlers\n                    onPayload: (payload) => // Catch-all for all events\n                })\n            ],\n        })\n    ]\n});\n\nConfigure a Webhook endpoint in your Polar Organization Settings page. Webhook endpoint is configured at /polar/webhooks.\n\nAdd the secret to your environment.\n\n# .env\nPOLAR_WEBHOOK_SECRET=...\n\nThe plugin supports handlers for all Polar webhook events:\n\nonPayload - Catch-all handler for any incoming Webhook event\nonCheckoutCreated - Triggered when a checkout is created\nonCheckoutUpdated - Triggered when a checkout is updated\nonOrderCreated - Triggered when an order is created\nonOrderPaid - Triggered when an order is paid\nonOrderRefunded - Triggered when an order is refunded\nonRefundCreated - Triggered when a refund is created\nonRefundUpdated - Triggered when a refund is updated\nonSubscriptionCreated - Triggered when a subscription is created\nonSubscriptionUpdated - Triggered when a subscription is updated\nonSubscriptionActive - Triggered when a subscription becomes active\nonSubscriptionCanceled - Triggered when a subscription is canceled\nonSubscriptionRevoked - Triggered when a subscription is revoked\nonSubscriptionUncanceled - Triggered when a subscription cancellation is reversed\nonProductCreated - Triggered when a product is created\nonProductUpdated - Triggered when a product is updated\nonOrganizationUpdated - Triggered when an organization is updated\nonBenefitCreated - Triggered when a benefit is created\nonBenefitUpdated - Triggered when a benefit is updated\nonBenefitGrantCreated - Triggered when a benefit grant is created\nonBenefitGrantUpdated - Triggered when a benefit grant is updated\nonBenefitGrantRevoked - Triggered when a benefit grant is revoked\nonCustomerCreated - Triggered when a customer is created\nonCustomerUpdated - Triggered when a customer is updated\nonCustomerDeleted - Triggered when a customer is deleted\nonCustomerStateChanged - Triggered when a customer is created\nEdit on GitHub\n\nPrevious Page\n\nStripe\n\nNext Page\n\nAutumn Billing"
  },
  {
    "title": "Stripe | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/stripe",
    "html": "Stripe\nCopy Markdown\nOpen in\n\nThe Stripe plugin integrates Stripe's payment and subscription functionality with Better Auth. Since payment and authentication are often tightly coupled, this plugin simplifies the integration of Stripe into your application, handling customer creation, subscription management, and webhook processing.\n\nFeatures\nCreate Stripe Customers automatically when users sign up\nManage subscription plans and pricing\nProcess subscription lifecycle events (creation, updates, cancellations)\nHandle Stripe webhooks securely with signature verification\nExpose subscription data to your application\nSupport for trial periods and subscription upgrades\nAutomatic trial abuse prevention - Users can only get one trial per account across all plans\nFlexible reference system to associate subscriptions with users or organizations\nTeam subscription support with seats management\nInstallation\nInstall the plugin\n\nFirst, install the plugin:\n\nnpm\npnpm\nyarn\nbun\nnpm install @better-auth/stripe\n\nIf you're using a separate client and server setup, make sure to install the plugin in both parts of your project.\n\nInstall the Stripe SDK\n\nNext, install the Stripe SDK on your server:\n\nnpm\npnpm\nyarn\nbun\nnpm install stripe@^19.1.0\nAdd the plugin to your auth config\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { stripe } from \"@better-auth/stripe\"\nimport Stripe from \"stripe\"\nconst stripeClient = new Stripe(process.env.STRIPE_SECRET_KEY!, {\n    apiVersion: \"2025-09-30.clover\", // Latest API version as of Stripe SDK v19\n})\nexport const auth = betterAuth({\n    // ... your existing config\n    plugins: [\n        stripe({\n            stripeClient,\n            stripeWebhookSecret: process.env.STRIPE_WEBHOOK_SECRET!,\n            createCustomerOnSignUp: true,\n        })\n    ]\n})\n\nUpgrading from Stripe v18? Version 19 uses async webhook signature verification (constructEventAsync) which is handled internally by the plugin. No code changes required on your end!\n\nAdd the client plugin\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { stripeClient } from \"@better-auth/stripe/client\"\nexport const client = createAuthClient({\n    // ... your existing config\n    plugins: [\n        stripeClient({\n            subscription: true //if you want to enable subscription management\n        })\n    ]\n})\nMigrate the database\n\nRun the migration or generate the schema to add the necessary tables to the database.\n\nmigrate\ngenerate\nnpx @better-auth/cli migrate\n\nSee the Schema section to add the tables manually.\n\nSet up Stripe webhooks\n\nCreate a webhook endpoint in your Stripe dashboard pointing to:\n\nhttps://your-domain.com/api/auth/stripe/webhook\n\n/api/auth is the default path for the auth server.\n\nMake sure to select at least these events:\n\ncheckout.session.completed\ncustomer.subscription.updated\ncustomer.subscription.deleted\n\nSave the webhook signing secret provided by Stripe and add it to your environment variables as STRIPE_WEBHOOK_SECRET.\n\nUsage\nCustomer Management\n\nYou can use this plugin solely for customer management without enabling subscriptions. This is useful if you just want to link Stripe customers to your users.\n\nBy default, when a user signs up, a Stripe customer is automatically created if you set createCustomerOnSignUp: true. This customer is linked to the user in your database. You can customize the customer creation process:\n\nauth.ts\nstripe({\n    // ... other options\n    createCustomerOnSignUp: true,\n    onCustomerCreate: async ({ customer, stripeCustomer, user }, request) => {\n        // Do something with the newly created customer\n        console.log(`Customer ${customer.id} created for user ${user.id}`);\n    },\n    getCustomerCreateParams: async ({ user, session }, request) => {\n        // Customize the Stripe customer creation parameters\n        return {\n            metadata: {\n                referralSource: user.metadata?.referralSource\n            }\n        };\n    }\n})\nSubscription Management\nDefining Plans\n\nYou can define your subscription plans either statically or dynamically:\n\nauth.ts\n// Static plans\nsubscription: {\n    enabled: true,\n    plans: [\n        {\n            name: \"basic\", // the name of the plan, it'll be automatically lower cased when stored in the database\n            priceId: \"price_1234567890\", // the price ID from stripe\n            annualDiscountPriceId: \"price_1234567890\", // (optional) the price ID for annual billing with a discount\n            limits: {\n                projects: 5,\n                storage: 10\n            }\n        },\n        {\n            name: \"pro\",\n            priceId: \"price_0987654321\",\n            limits: {\n                projects: 20,\n                storage: 50\n            },\n            freeTrial: {\n                days: 14,\n            }\n        }\n    ]\n}\n// Dynamic plans (fetched from database or API)\nsubscription: {\n    enabled: true,\n    plans: async () => {\n        const plans = await db.query(\"SELECT * FROM plans\");\n        return plans.map(plan => ({\n            name: plan.name,\n            priceId: plan.stripe_price_id,\n            limits: JSON.parse(plan.limits)\n        }));\n    }\n}\n\nsee plan configuration for more.\n\nCreating a Subscription\n\nTo create a subscription, use the subscription.upgrade method:\n\nClient\nServer\nPOST\n/subscription/upgrade\nconst { data, error } = await authClient.subscription.upgrade({\n    plan: \"pro\", // required\n    annual: true,\n    referenceId: \"123\",\n    subscriptionId: \"sub_123\",\n    metadata,\n    seats: 1,\n    successUrl, // required\n    cancelUrl, // required\n    returnUrl,\n    disableRedirect: true, // required\n});\nProp\tDescription\tType\nplan\t\nThe name of the plan to upgrade to.\n\tstring\nannual?\t\nWhether to upgrade to an annual plan.\n\tboolean\nreferenceId?\t\nReference id of the subscription to upgrade.\n\tstring\nsubscriptionId?\t\nThe id of the subscription to upgrade.\n\tstring\nmetadata?\t\n\tRecord<string, any>\nseats?\t\nNumber of seats to upgrade to (if applicable).\n\tnumber\nsuccessUrl\t\nCallback URL to redirect back after successful subscription.\n\tstring\ncancelUrl\t\nIf set, checkout shows a back button and customers will be directed here if they cancel payment.\n\tstring\nreturnUrl?\t\nURL to take customers to when they click on the billing portal’s link to return to your website.\n\tstring\ndisableRedirect\t\nDisable redirect after successful subscription.\n\tboolean\n\nSimple Example:\n\nclient.ts\nawait client.subscription.upgrade({\n    plan: \"pro\",\n    successUrl: \"/dashboard\",\n    cancelUrl: \"/pricing\",\n    annual: true, // Optional: upgrade to an annual plan\n    referenceId: \"org_123\", // Optional: defaults to the current logged in user ID\n    seats: 5 // Optional: for team plans\n});\n\nThis will create a Checkout Session and redirect the user to the Stripe Checkout page.\n\nIf the user already has an active subscription, you must provide the subscriptionId parameter. Otherwise, the user will be subscribed to (and pay for) both plans.\n\nImportant: The successUrl parameter will be internally modified to handle race conditions between checkout completion and webhook processing. The plugin creates an intermediate redirect that ensures subscription status is properly updated before redirecting to your success page.\n\nconst { error } = await client.subscription.upgrade({\n    plan: \"pro\",\n    successUrl: \"/dashboard\",\n    cancelUrl: \"/pricing\",\n});\nif(error) {\n    alert(error.message);\n}\n\nFor each reference ID (user or organization), only one active or trialing subscription is supported at a time. The plugin doesn't currently support multiple concurrent active subscriptions for the same reference ID.\n\nSwitching Plans\n\nTo switch a subscription to a different plan, use the subscription.upgrade method:\n\nclient.ts\nawait client.subscription.upgrade({\n    plan: \"pro\",\n    successUrl: \"/dashboard\",\n    cancelUrl: \"/pricing\",\n    subscriptionId: \"sub_123\", // the Stripe subscription ID of the user's current plan\n});\n\nThis ensures that the user only pays for the new plan, and not both.\n\nListing Active Subscriptions\n\nTo get the user's active subscriptions:\n\nClient\nServer\nGET\n/subscription/list\nconst { data: subscriptions, error } = await authClient.subscription.list({\n    query: {\n        referenceId: '123',\n    },\n});\n// get the active subscription\nconst activeSubscription = subscriptions.find(\n    sub => sub.status === \"active\" || sub.status === \"trialing\"\n);\n// Check subscription limits\nconst projectLimit = subscriptions?.limits?.projects || 0;\nProp\tDescription\tType\nreferenceId?\t\nReference id of the subscription to list.\n\tstring\nCanceling a Subscription\n\nTo cancel a subscription:\n\nClient\nServer\nPOST\n/subscription/cancel\nconst { data, error } = await authClient.subscription.cancel({\n    referenceId: 'org_123',\n    subscriptionId: 'sub_123',\n    returnUrl: '/account', // required\n});\nProp\tDescription\tType\nreferenceId?\t\nReference id of the subscription to cancel. Defaults to the userId.\n\tstring\nsubscriptionId?\t\nThe id of the subscription to cancel.\n\tstring\nreturnUrl\t\nURL to take customers to when they click on the billing portal’s link to return to your website.\n\tstring\n\nThis will redirect the user to the Stripe Billing Portal where they can cancel their subscription.\n\nRestoring a Canceled Subscription\n\nIf a user changes their mind after canceling a subscription (but before the subscription period ends), you can restore the subscription:\n\nClient\nServer\nPOST\n/subscription/restore\nconst { data, error } = await authClient.subscription.restore({\n    referenceId: '123',\n    subscriptionId: 'sub_123',\n});\nProp\tDescription\tType\nreferenceId?\t\nReference id of the subscription to restore. Defaults to the userId.\n\tstring\nsubscriptionId?\t\nThe id of the subscription to restore.\n\tstring\n\nThis will reactivate a subscription that was previously set to cancel at the end of the billing period (cancelAtPeriodEnd: true). The subscription will continue to renew automatically.\n\nNote: This only works for subscriptions that are still active but marked to cancel at the end of the period. It cannot restore subscriptions that have already ended.\n\nCreating Billing Portal Sessions\n\nTo create a Stripe billing portal session where customers can manage their subscriptions, update payment methods, and view billing history:\n\nClient\nServer\nPOST\n/subscription/billing-portal\nconst { data, error } = await authClient.subscription.billingPortal({\n    locale,\n    referenceId: \"123\",\n    returnUrl,\n});\nProp\tDescription\tType\nlocale?\t\nThe IETF language tag of the locale customer portal is displayed in. If blank or auto, browser's locale is used.\n\tstring\nreferenceId?\t\nReference id of the subscription to upgrade.\n\tstring\nreturnUrl?\t\nReturn URL to redirect back after successful subscription.\n\tstring\n\nFor supported locales, see the IETF language tag documentation.\n\nThis endpoint creates a Stripe billing portal session and returns a URL in the response as data.url. You can redirect users to this URL to allow them to manage their subscription, payment methods, and billing history.\n\nReference System\n\nBy default, subscriptions are associated with the user ID. However, you can use a custom reference ID to associate subscriptions with other entities, such as organizations:\n\nclient.ts\n// Create a subscription for an organization\nawait client.subscription.upgrade({\n    plan: \"pro\",\n    referenceId: \"org_123456\",\n    successUrl: \"/dashboard\",\n    cancelUrl: \"/pricing\",\n    seats: 5 // Number of seats for team plans\n});\n// List subscriptions for an organization\nconst { data: subscriptions } = await client.subscription.list({\n    query: {\n        referenceId: \"org_123456\"\n    }\n});\nTeam Subscriptions with Seats\n\nFor team or organization plans, you can specify the number of seats:\n\nawait client.subscription.upgrade({\n    plan: \"team\",\n    referenceId: \"org_123456\",\n    seats: 10, // 10 team members\n    successUrl: \"/org/billing/success\",\n    cancelUrl: \"/org/billing\"\n});\n\nThe seats parameter is passed to Stripe as the quantity for the subscription item. You can use this value in your application logic to limit the number of members in a team or organization.\n\nTo authorize reference IDs, implement the authorizeReference function:\n\nauth.ts\nsubscription: {\n    // ... other options\n    authorizeReference: async ({ user, session, referenceId, action }) => {\n        // Check if the user has permission to manage subscriptions for this reference\n        if (action === \"upgrade-subscription\" || action === \"cancel-subscription\" || action === \"restore-subscription\") {\n            const org = await db.member.findFirst({\n                where: {\n                    organizationId: referenceId,\n                    userId: user.id\n                }   \n            });\n            return org?.role === \"owner\"\n        }\n        return true;\n    }\n}\nWebhook Handling\n\nThe plugin automatically handles common webhook events:\n\ncheckout.session.completed: Updates subscription status after checkout\ncustomer.subscription.updated: Updates subscription details when changed\ncustomer.subscription.deleted: Marks subscription as canceled\n\nYou can also handle custom events:\n\nauth.ts\nstripe({\n    // ... other options\n    onEvent: async (event) => {\n        // Handle any Stripe event\n        switch (event.type) {\n            case \"invoice.paid\":\n                // Handle paid invoice\n                break;\n            case \"payment_intent.succeeded\":\n                // Handle successful payment\n                break;\n        }\n    }\n})\nSubscription Lifecycle Hooks\n\nYou can hook into various subscription lifecycle events:\n\nauth.ts\nsubscription: {\n    // ... other options\n    onSubscriptionComplete: async ({ event, subscription, stripeSubscription, plan }) => {\n        // Called when a subscription is successfully created\n        await sendWelcomeEmail(subscription.referenceId, plan.name);\n    },\n    onSubscriptionUpdate: async ({ event, subscription }) => {\n        // Called when a subscription is updated\n        console.log(`Subscription ${subscription.id} updated`);\n    },\n    onSubscriptionCancel: async ({ event, subscription, stripeSubscription, cancellationDetails }) => {\n        // Called when a subscription is canceled\n        await sendCancellationEmail(subscription.referenceId);\n    },\n    onSubscriptionDeleted: async ({ event, subscription, stripeSubscription }) => {\n        // Called when a subscription is deleted\n        console.log(`Subscription ${subscription.id} deleted`);\n    }\n}\nTrial Periods\n\nYou can configure trial periods for your plans:\n\nauth.ts\n{\n    name: \"pro\",\n    priceId: \"price_0987654321\",\n    freeTrial: {\n        days: 14,\n        onTrialStart: async (subscription) => {\n            // Called when a trial starts\n            await sendTrialStartEmail(subscription.referenceId);\n        },\n        onTrialEnd: async ({ subscription, user }, request) => {\n            // Called when a trial ends\n            await sendTrialEndEmail(user.email);\n        },\n        onTrialExpired: async (subscription) => {\n            // Called when a trial expires without conversion\n            await sendTrialExpiredEmail(subscription.referenceId);\n        }\n    }\n}\nSchema\n\nThe Stripe plugin adds the following tables to your database:\n\nUser\n\nTable Name: user\n\nField Name\tType\tKey\tDescription\nstripeCustomerId\tstring\t?\tThe Stripe customer ID\nSubscription\n\nTable Name: subscription\n\nField Name\tType\tKey\tDescription\nid\tstring\t\nPK\tUnique identifier for each subscription\nplan\tstring\t-\tThe name of the subscription plan\nreferenceId\tstring\t-\tThe ID this subscription is associated with (user ID by default)\nstripeCustomerId\tstring\t?\tThe Stripe customer ID\nstripeSubscriptionId\tstring\t?\tThe Stripe subscription ID\nstatus\tstring\t-\tThe status of the subscription (active, canceled, etc.)\nperiodStart\tDate\t?\tStart date of the current billing period\nperiodEnd\tDate\t?\tEnd date of the current billing period\ncancelAtPeriodEnd\tboolean\t?\tWhether the subscription will be canceled at the end of the period\nseats\tnumber\t?\tNumber of seats for team plans\ntrialStart\tDate\t?\tStart date of the trial period\ntrialEnd\tDate\t?\tEnd date of the trial period\nCustomizing the Schema\n\nTo change the schema table names or fields, you can pass a schema option to the Stripe plugin:\n\nauth.ts\nstripe({\n    // ... other options\n    schema: {\n        subscription: {\n            modelName: \"stripeSubscriptions\", // map the subscription table to stripeSubscriptions\n            fields: {\n                plan: \"planName\" // map the plan field to planName\n            }\n        }\n    }\n})\nOptions\nMain Options\n\nstripeClient: Stripe - The Stripe client instance. Required.\n\nstripeWebhookSecret: string - The webhook signing secret from Stripe. Required.\n\ncreateCustomerOnSignUp: boolean - Whether to automatically create a Stripe customer when a user signs up. Default: false.\n\nonCustomerCreate: (data: { customer: Customer, stripeCustomer: Stripe.Customer, user: User }, request?: Request) => Promise<void> - A function called after a customer is created.\n\ngetCustomerCreateParams: (data: { user: User, session: Session }, request?: Request) => Promise<{}> - A function to customize the Stripe customer creation parameters.\n\nonEvent: (event: Stripe.Event) => Promise<void> - A function called for any Stripe webhook event.\n\nSubscription Options\n\nenabled: boolean - Whether to enable subscription functionality. Required.\n\nplans: Plan[] | (() => Promise<Plan[]>) - An array of subscription plans or a function that returns plans. Required if subscriptions are enabled.\n\nrequireEmailVerification: boolean - Whether to require email verification before allowing subscription upgrades. Default: false.\n\nauthorizeReference: (data: { user: User, session: Session, referenceId: string, action: \"upgrade-subscription\" | \"list-subscription\" | \"cancel-subscription\" | \"restore-subscription\"}, request?: Request) => Promise<boolean> - A function to authorize reference IDs.\n\nPlan Configuration\n\nEach plan can have the following properties:\n\nname: string - The name of the plan. Required.\n\npriceId: string - The Stripe price ID. Required unless using lookupKey.\n\nlookupKey: string - The Stripe price lookup key. Alternative to priceId.\n\nannualDiscountPriceId: string - A price ID for annual billing.\n\nannualDiscountLookupKey: string - The Stripe price lookup key for annual billing. Alternative to annualDiscountPriceId.\n\nlimits: Record<string, number> - Limits associated with the plan (e.g., { projects: 10, storage: 5 }).\n\ngroup: string - A group name for the plan, useful for categorizing plans.\n\nfreeTrial: Object containing trial configuration:\n\ndays: number - Number of trial days.\nonTrialStart: (subscription: Subscription) => Promise<void> - Called when a trial starts.\nonTrialEnd: (data: { subscription: Subscription, user: User }, request?: Request) => Promise<void> - Called when a trial ends.\nonTrialExpired: (subscription: Subscription) => Promise<void> - Called when a trial expires without conversion.\nAdvanced Usage\nUsing with Organizations\n\nThe Stripe plugin works well with the organization plugin. You can associate subscriptions with organizations instead of individual users:\n\nclient.ts\n// Get the active organization\nconst { data: activeOrg } = client.useActiveOrganization();\n// Create a subscription for the organization\nawait client.subscription.upgrade({\n    plan: \"team\",\n    referenceId: activeOrg.id,\n    seats: 10,\n    annual: true, // upgrade to an annual plan (optional)\n    successUrl: \"/org/billing/success\",\n    cancelUrl: \"/org/billing\"\n});\n\nMake sure to implement the authorizeReference function to verify that the user has permission to manage subscriptions for the organization:\n\nauth.ts\nauthorizeReference: async ({ user, referenceId, action }) => {\n    const member = await db.members.findFirst({\n        where: {\n            userId: user.id,\n            organizationId: referenceId\n        }\n    });\n    \n    return member?.role === \"owner\" || member?.role === \"admin\";\n}\nCustom Checkout Session Parameters\n\nYou can customize the Stripe Checkout session with additional parameters:\n\nauth.ts\ngetCheckoutSessionParams: async ({ user, session, plan, subscription }, request) => {\n    return {\n        params: {\n            allow_promotion_codes: true,\n            tax_id_collection: {\n                enabled: true\n            },\n            billing_address_collection: \"required\",\n            custom_text: {\n                submit: {\n                    message: \"We'll start your subscription right away\"\n                }\n            },\n            metadata: {\n                planType: \"business\",\n                referralCode: user.metadata?.referralCode\n            }\n        },\n        options: {\n            idempotencyKey: `sub_${user.id}_${plan.name}_${Date.now()}`\n        }\n    };\n}\nTax Collection\n\nTo collect tax IDs from the customer, set tax_id_collection to true:\n\nauth.ts\nsubscription: {\n    // ... other options\n    getCheckoutSessionParams: async ({ user, session, plan, subscription }, request) => {\n        return {\n            params: {\n                tax_id_collection: {\n                    enabled: true\n                }\n            }\n        };\n    }\n}\nAutomatic Tax Calculation\n\nTo enable automatic tax calculation using the customer's location, set automatic_tax to true. Enabling this parameter causes Checkout to collect any billing address information necessary for tax calculation. You need to have tax registration setup and configured in the Stripe dashboard first for this to work.\n\nauth.ts\nsubscription: {\n    // ... other options\n    getCheckoutSessionParams: async ({ user, session, plan, subscription }, request) => {\n        return {\n            params: {\n                automatic_tax: {\n                    enabled: true\n                }\n            }\n        };\n    }\n}\nTrial Period Management\n\nThe Stripe plugin automatically prevents users from getting multiple free trials. Once a user has used a trial period (regardless of which plan), they will not be eligible for additional trials on any plan.\n\nHow it works:\n\nThe system tracks trial usage across all plans for each user\nWhen a user subscribes to a plan with a trial, the system checks their subscription history\nIf the user has ever had a trial (indicated by trialStart/trialEnd fields or trialing status), no new trial will be offered\nThis prevents abuse where users cancel subscriptions and resubscribe to get multiple free trials\n\nExample scenario:\n\nUser subscribes to \"Starter\" plan with 7-day trial\nUser cancels the subscription after the trial\nUser tries to subscribe to \"Premium\" plan - no trial will be offered\nUser will be charged immediately for the Premium plan\n\nThis behavior is automatic and requires no additional configuration. The trial eligibility is determined at the time of subscription creation and cannot be overridden through configuration.\n\nTroubleshooting\nWebhook Issues\n\nIf webhooks aren't being processed correctly:\n\nCheck that your webhook URL is correctly configured in the Stripe dashboard\nVerify that the webhook signing secret is correct\nEnsure you've selected all the necessary events in the Stripe dashboard\nCheck your server logs for any errors during webhook processing\nSubscription Status Issues\n\nIf subscription statuses aren't updating correctly:\n\nMake sure the webhook events are being received and processed\nCheck that the stripeCustomerId and stripeSubscriptionId fields are correctly populated\nVerify that the reference IDs match between your application and Stripe\nTesting Webhooks Locally\n\nFor local development, you can use the Stripe CLI to forward webhooks to your local environment:\n\nstripe listen --forward-to localhost:3000/api/auth/stripe/webhook\n\nThis will provide you with a webhook signing secret that you can use in your local environment.\n\nEdit on GitHub\n\nPrevious Page\n\n3rd party\n\nNext Page\n\nPolar"
  },
  {
    "title": "Dodo Payments | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/dodopayments",
    "html": "Dodo Payments\nCopy Markdown\nOpen in\n\nDodo Payments is a global Merchant-of-Record platform that lets AI, SaaS and digital businesses sell in 150+ countries without touching tax, fraud, or compliance. A single, developer-friendly API powers checkout, billing, and payouts so you can launch worldwide in minutes.\n\nGet support on Dodo Payments' Discord\n\nThis plugin is maintained by the Dodo Payments team.\nHave questions? Our team is available on Discord to assist you anytime.\n\nFeatures\nAutomatic customer creation on sign-up\nType-safe checkout flows with product slug mapping\nSelf-service customer portal\nReal-time webhook event processing with signature verification\nGet started with Dodo Payments\n\nYou need a Dodo Payments account and API keys to use this integration.\n\nInstallation\n\nRun the following command in your project root:\n\nnpm install @dodopayments/better-auth dodopayments better-auth zod\n\nAdd these to your .env file:\n\nDODO_PAYMENTS_API_KEY=your_api_key_here\nDODO_PAYMENTS_WEBHOOK_SECRET=your_webhook_secret_here\n\nCreate or update src/lib/auth.ts:\n\nimport { betterAuth } from \"better-auth\";\nimport {\n  dodopayments,\n  checkout,\n  portal,\n  webhooks,\n} from \"@dodopayments/better-auth\";\nimport DodoPayments from \"dodopayments\";\nexport const dodoPayments = new DodoPayments({\n  bearerToken: process.env.DODO_PAYMENTS_API_KEY!,\n  environment: \"test_mode\"\n});\nexport const auth = betterAuth({\n  plugins: [\n    dodopayments({\n      client: dodoPayments,\n      createCustomerOnSignUp: true,\n      use: [\n        checkout({\n          products: [\n            {\n              productId: \"pdt_xxxxxxxxxxxxxxxxxxxxx\",\n              slug: \"premium-plan\",\n            },\n          ],\n          successUrl: \"/dashboard/success\",\n          authenticatedUsersOnly: true,\n        }),\n        portal(),\n        webhooks({\n          webhookKey: process.env.DODO_PAYMENTS_WEBHOOK_SECRET!,\n          onPayload: async (payload) => {\n            console.log(\"Received webhook:\", payload.event_type);\n          },\n        }),\n      ],\n    }),\n  ],\n});\n\nSet environment to live_mode for production.\n\nCreate or update src/lib/auth-client.ts:\n\nimport { dodopaymentsClient } from \"@dodopayments/better-auth\";\nexport const authClient = createAuthClient({\n  baseURL: process.env.BETTER_AUTH_URL || \"http://localhost:3000\",\n  plugins: [dodopaymentsClient()],\n});\nUsage\nCreating a Checkout Session\nconst { data: checkout, error } = await authClient.dodopayments.checkout({\n  slug: \"premium-plan\",\n  customer: {\n    email: \"customer@example.com\",\n    name: \"John Doe\",\n  },\n  billing: {\n    city: \"San Francisco\",\n    country: \"US\",\n    state: \"CA\",\n    street: \"123 Market St\",\n    zipcode: \"94103\",\n  },\n  referenceId: \"order_123\",\n});\nif (checkout) {\n  window.location.href = checkout.url;\n}\nAccessing the Customer Portal\nconst { data: customerPortal, error } = await authClient.dodopayments.customer.portal();\nif (customerPortal && customerPortal.redirect) {\n  window.location.href = customerPortal.url;\n}\nListing Customer Data\n// Get subscriptions\nconst { data: subscriptions, error } =\n  await authClient.dodopayments.customer.subscriptions.list({\n    query: {\n      limit: 10,\n      page: 1,\n      active: true,\n    },\n  });\n// Get payment history\nconst { data: payments, error } = await authClient.dodopayments.customer.payments.list({\n  query: {\n    limit: 10,\n    page: 1,\n    status: \"succeeded\",\n  },\n});\nWebhooks\n\nThe webhooks plugin processes real-time payment events from Dodo Payments with secure signature verification. The default endpoint is /api/auth/dodopayments/webhooks.\n\nGenerate a webhook secret for your endpoint URL (e.g., https://your-domain.com/api/auth/dodopayments/webhooks) in the Dodo Payments Dashboard and set it in your .env file:\n\nDODO_PAYMENTS_WEBHOOK_SECRET=your_webhook_secret_here\n\nExample handler:\n\nwebhooks({\n  webhookKey: process.env.DODO_PAYMENTS_WEBHOOK_SECRET!,\n  onPayload: async (payload) => {\n    console.log(\"Received webhook:\", payload.event_type);\n  },\n});\nConfiguration Reference\nPlugin Options\nclient (required): DodoPayments client instance\ncreateCustomerOnSignUp (optional): Auto-create customers on user signup\nuse (required): Array of plugins to enable (checkout, portal, webhooks)\nCheckout Plugin Options\nproducts: Array of products or async function returning products\nsuccessUrl: URL to redirect after successful payment\nauthenticatedUsersOnly: Require user authentication (default: false)\n\nIf you encounter any issues, please refer to the Dodo Payments documentation for troubleshooting steps.\n\nEdit on GitHub\n\nPrevious Page\n\nAutumn Billing\n\nNext Page\n\nDub"
  },
  {
    "title": "Autumn Billing | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/autumn",
    "html": "Autumn Billing\nCopy Markdown\nOpen in\n\nAutumn is open source infrastructure to run SaaS pricing plans. It sits between your app and Stripe, and acts as the database for your customers' subscription status, usage metering and feature permissions.\n\nGet help on Autumn's Discord\n\nWe're online to help you with any questions you have.\n\nFeatures\nOne function for all checkout, subscription and payment flows\nNo webhooks required: query Autumn for the data you need\nManages your application's free and paid plans\nUsage tracking for usage billing and periodic limits\nCustom plans and pricing changes through Autumn's dashboard\nSetup Autumn Account\n\nFirst, create your pricing plans in Autumn's dashboard, where you define what each plan and product gets access to and how it should be billed. In this example, we're handling the free and pro plans for an AI chatbot, which comes with a number of messages per month.\n\nInstall Autumn SDK\nnpm\npnpm\nyarn\nbun\nnpm install autumn-js\n\nIf you're using a separate client and server setup, make sure to install the plugin in both parts of your project.\n\nAdd AUTUMN_SECRET_KEY to your environment variables\n\nYou can find it in Autumn's dashboard under \"Developer\".\n\n.env\nAUTUMN_SECRET_KEY=am_sk_xxxxxxxxxx\nAdd the Autumn plugin to your auth config\nUser\nOrganization\nUser & Organization\nCustom\nauth.ts\nimport { autumn } from \"autumn-js/better-auth\";\nexport const auth = betterAuth({\n  // ...\n  plugins: [autumn()],\n});\n\nAutumn will auto-create your customers when they sign up, and assign them any default plans you created (eg your Free plan). You can choose who becomes a customer: individual users, organizations, both, or something custom like workspaces.\n\nAdd <AutumnProvider />\n\nClient side, wrap your application with the AutumnProvider component, and pass in the baseUrl that you define within better-auth's authClient.\n\napp/layout.tsx\nimport { AutumnProvider } from \"autumn-js/react\";\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <html>\n      <body>\n        {/* or meta.env.BETTER_AUTH_URL for vite */}\n        <AutumnProvider betterAuthUrl={process.env.NEXT_PUBLIC_BETTER_AUTH_URL}>\n          {children}\n        </AutumnProvider>\n      </body>\n    </html>\n  );\n}\nUsage\nHandle payments\n\nCall attach to redirect the customer to a Stripe checkout page when they want to purchase the Pro plan.\n\nIf their payment method is already on file, AttachDialog will open instead to let the customer confirm their new subscription or purchase, and handle the payment.\n\nMake sure you've pasted in your Stripe test secret key in the Autumn dashboard.\n\nimport { useCustomer, AttachDialog } from \"autumn-js/react\";\nexport default function PurchaseButton() {\n  const { attach } = useCustomer();\n  return (\n    <button\n      onClick={async () => {\n        await attach({\n          productId: \"pro\",\n          dialog: AttachDialog,\n        });\n      }}\n    >\n      Upgrade to Pro\n    </button>\n  );\n}\n\nThe AttachDialog component can be used directly from the autumn-js/react library (as shown in the example above), or downloaded as a shadcn/ui component to customize.\n\nIntegrate Pricing Logic\n\nIntegrate your client and server pricing tiers logic with the following functions:\n\ncheck to see if the customer is allowed to send a message.\ntrack a usage event in Autumn (typically done server-side)\ncustomer to display any relevant billing data in your UI (subscriptions, feature balances)\n\nServer-side, you can access Autumn's functions through the auth object.\n\nClient\nServer\nimport { useCustomer } from \"autumn-js/react\";\nexport default function SendChatMessage() {\n  const { customer, allowed, refetch } = useCustomer();\n  return (\n    <>\n      <button\n        onClick={async () => {\n          if (allowed({ featureId: \"messages\" })) {\n            //... send chatbot message server-side, then\n            await refetch(); // refetch customer usage data\n            alert(\n              \"Remaining messages: \" + customer?.features.messages?.balance\n            );\n          } else {\n            alert(\"You're out of messages\");\n          }\n        }}\n      >\n        Send Message\n      </button>\n    </>\n  );\n}\nAdditional Functions\nopenBillingPortal()\n\nOpens a billing portal where the customer can update their payment method or cancel their plan.\n\nimport { useCustomer } from \"autumn-js/react\";\nexport default function BillingSettings() {\n  const { openBillingPortal } = useCustomer();\n  return (\n    <button\n      onClick={async () => {\n        await openBillingPortal({\n          returnUrl: \"/settings/billing\",\n        });\n      }}\n    >\n      Manage Billing\n    </button>\n  );\n}\ncancel()\n\nCancel a product or subscription.\n\nimport { useCustomer } from \"autumn-js/react\";\nexport default function CancelSubscription() {\n  const { cancel } = useCustomer();\n  return (\n    <button\n      onClick={async () => {\n        await cancel({ productId: \"pro\" });\n      }}\n    >\n      Cancel Subscription\n    </button>\n  );\n}\nGet invoice history\n\nPass in an expand param into useCustomer to get additional information. You can expand invoices, trials_used, payment_method, or rewards.\n\nimport { useCustomer } from \"autumn-js/react\";\nexport default function CustomerProfile() {\n  const { customer } = useCustomer({ expand: [\"invoices\"] });\n  return (\n    <div>\n      <h2>Customer Profile</h2>\n      <p>Name: {customer?.name}</p>\n      <p>Email: {customer?.email}</p>\n      <p>Balance: {customer?.features.chat_messages?.balance}</p>\n    </div>\n  );\n}\nEdit on GitHub\n\nPrevious Page\n\nPolar\n\nNext Page\n\nDodo Payments"
  },
  {
    "title": "Dub | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/dub",
    "html": "Dub\nCopy Markdown\nOpen in\n\nDub is an open source modern link management platform for entrepreneurs, creators, and growth teams.\n\nThis plugins allows you to track leads when a user signs up using a Dub link. It also adds OAuth linking support to allow you to build integrations extending Dub's linking management infrastructure.\n\nInstallation\nInstall the plugin\n\nFirst, install the plugin:\n\nnpm\npnpm\nyarn\nbun\nnpm install @dub/better-auth\nInstall the Dub SDK\n\nNext, install the Dub SDK on your server:\n\nnpm\npnpm\nyarn\nbun\nnpm install dub\nConfigure the plugin\n\nAdd the plugin to your auth config:\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { dubAnalytics } from \"@dub/better-auth\"\nimport { dub } from \"dub\"\nexport const auth = betterAuth({\n    plugins: [\n        dubAnalytics({\n            dubClient: new Dub()\n        })\n    ]\n})\nUsage\nLead Tracking\n\nBy default, the plugin will track sign up events as leads. You can disable this by setting disableLeadTracking to true.\n\nimport { dubAnalytics } from \"@dub/better-auth\";\nimport { betterAuth } from \"better-auth\";\nimport { Dub } from \"dub\";\nconst dub = new Dub();\nconst betterAuth = betterAuth({\n  plugins: [\n    dubAnalytics({\n      dubClient: dub,\n      disableLeadTracking: true, // Disable lead tracking\n    }),\n  ],\n});\nOAuth Linking\n\nThe plugin supports OAuth for account linking.\n\nFirst, you need to setup OAuth app in Dub. Dub supports OAuth 2.0 authentication, which is recommended if you build integrations extending Dub’s functionality Learn more about OAuth.\n\nOnce you get the client ID and client secret, you can configure the plugin.\n\ndubAnalytics({\n  dubClient: dub,\n  oauth: {\n    clientId: \"your-client-id\",\n    clientSecret: \"your-client-secret\",\n  },\n});\n\nAnd in the client, you need to use the dubAnalyticsClient plugin.\n\nimport { createAuthClient } from \"better-auth/client\";\nimport { dubAnalyticsClient } from \"@dub/better-auth/client\";\nconst authClient = createAuthClient({\n  plugins: [dubAnalyticsClient()],\n});\n\nTo link account with Dub, you need to use the dub.link.\n\nClient\nServer\nPOST\n/dub/link\nconst { data, error } = await authClient.dub.link({\n    callbackURL: \"/dashboard\", // required\n});\nProp\tDescription\tType\ncallbackURL\t\nURL to redirect to after linking\n\tstring\nOptions\n\nYou can pass the following options to the plugin:\n\ndubClient\n\nThe Dub client instance.\n\ndisableLeadTracking\n\nDisable lead tracking for sign up events.\n\nleadEventName\n\nEvent name for sign up leads.\n\ncustomLeadTrack\n\nCustom lead track function.\n\noauth\n\nDub OAuth configuration.\n\noauth.clientId\n\nClient ID for Dub OAuth.\n\noauth.clientSecret\n\nClient secret for Dub OAuth.\n\noauth.pkce\n\nEnable PKCE for Dub OAuth.\n\nEdit on GitHub\n\nPrevious Page\n\nDodo Payments\n\nNext Page\n\nCommunity Plugins"
  },
  {
    "title": "Community Plugins | Better Auth",
    "url": "https://www.better-auth.com/docs/plugins/community-plugins",
    "html": "Community Plugins\nCopy Markdown\nOpen in\n\nThis page showcases a list of recommended community made plugins.\n\nWe encourage you to create custom plugins and maybe get added to the list!\n\nTo create your own custom plugin, get started by reading our plugins documentation. And if you want to share your plugin with the community, please open a pull request to add it to this list.\n\nPlugin\n\tDescription\t\nAuthor\n\n@dymo-api/better-auth\tSign Up Protection and validation of disposable emails (the world's largest database with nearly 14 million entries).\t TPEOficial\nbetter-auth-harmony\tEmail & phone normalization and additional validation, blocking over 55,000 temporary email domains.\t GeKorm\nvalidation-better-auth\tValidate API request using any validation library (e.g., Zod, Yup)\t Daanish2003\nbetter-auth-localization\tLocalize and customize better-auth messages with easy translation and message override support.\t marcellosso\nbetter-auth-attio-plugin\tSync your products Better Auth users & workspaces with Attio\t tobimori\nbetter-auth-cloudflare\tSeamlessly integrate with Cloudflare Workers, D1, Hyperdrive, KV, R2, and geolocation services. Includes CLI for project generation, automated resource provisioning on Cloudflare, and database migrations. Supports Next.js, Hono, and more!\t zpg6\nexpo-better-auth-passkey\tBetter-auth client plugin for using passkeys on mobile platforms in expo apps. Supports iOS, macOS, Android (and web!) by wrapping the existing better-auth passkey client plugin.\t kevcube\nbetter-auth-credentials-plugin\tLDAP authentication plugin for Better Auth.\t erickweil\nbetter-auth-opaque\tProvides database-breach resistant authentication using the zero-knowledge OPAQUE protocol.\t TheUntraceable\nEdit on GitHub\n\nPrevious Page\n\nDub\n\nNext Page\n\nGuides"
  },
  {
    "title": "Astro Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/astro",
    "html": "Astro Integration\nCopy Markdown\nOpen in\n\nBetter Auth comes with first class support for Astro. This guide will show you how to integrate Better Auth with Astro.\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nMount the handler\n\nTo enable Better Auth to handle requests, we need to mount the handler to a catch all API route. Create a file inside /pages/api/auth called [...all].ts and add the following code:\n\npages/api/auth/[...all].ts\nimport { auth } from \"~/auth\";\nimport type { APIRoute } from \"astro\";\nexport const ALL: APIRoute = async (ctx) => {\n\t// If you want to use rate limiting, make sure to set the 'x-forwarded-for' header to the request headers from the context\n\t// ctx.request.headers.set(\"x-forwarded-for\", ctx.clientAddress);\n\treturn auth.handler(ctx.request);\n};\n\nYou can change the path on your better-auth configuration but it's recommended to keep it as /api/auth/[...all]\n\nCreate a client\n\nAstro supports multiple frontend frameworks, so you can easily import your client based on the framework you're using.\n\nIf you're not using a frontend framework, you can still import the vanilla client.\n\nvanilla\nreact\nvue\nsvelte\nsolid\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\"\nexport const authClient =  createAuthClient()\nAuth Middleware\nAstro Locals types\n\nTo have types for your Astro locals, you need to set it inside the env.d.ts file.\n\nenv.d.ts\n/// <reference path=\"../.astro/types.d.ts\" />\ndeclare namespace App {\n    // Note: 'import {} from \"\"' syntax does not work in .d.ts files.\n    interface Locals {\n        user: import(\"better-auth\").User | null;\n        session: import(\"better-auth\").Session | null;\n    }\n}\nMiddleware\n\nTo protect your routes, you can check if the user is authenticated using the getSession method in middleware and set the user and session data using the Astro locals with the types we set before. Start by creating a middleware.ts file in the root of your project and follow the example below:\n\nmiddleware.ts\nimport { auth } from \"@/auth\";\nimport { defineMiddleware } from \"astro:middleware\";\nexport const onRequest = defineMiddleware(async (context, next) => {\n    const isAuthed = await auth.api\n        .getSession({\n            headers: context.request.headers,\n        })\n    if (isAuthed) {\n        context.locals.user = isAuthed.user;\n        context.locals.session = isAuthed.session;\n    } else {\n        context.locals.user = null;\n        context.locals.session = null;\n    }\n    return next();\n});\nGetting session on the server inside .astro file\n\nYou can use Astro.locals to check if the user has session and get the user data from the server side. Here is an example of how you can get the session inside an .astro file:\n\n---\nimport { UserCard } from \"@/components/user-card\";\nconst session = () => {\n    if (Astro.locals.session) {\n        return Astro.locals.session;\n    } else {\n        // Redirect to login page if the user is not authenticated\n        return Astro.redirect(\"/login\");\n    }\n}\n---\n<UserCard initialSession={session} />\nEdit on GitHub\n\nPrevious Page\n\nFull Stack\n\nNext Page\n\nRemix"
  },
  {
    "title": "Remix Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/remix",
    "html": "Remix Integration\nCopy Markdown\nOpen in\n\nBetter Auth can be easily integrated with Remix. This guide will show you how to integrate Better Auth with Remix.\n\nYou can follow the steps from installation to get started or you can follow this guide to make it the Remix-way.\n\nIf you have followed the installation steps, you can skip the first step.\n\nCreate auth instance\n\nCreate a file named auth.server.ts in one of these locations:\n\nProject root\nlib/ folder\nutils/ folder\n\nYou can also nest any of these folders under app/ folder. (e.g. app/lib/auth.server.ts)\n\nAnd in this file, import Better Auth and create your instance.\n\nMake sure to export the auth instance with the variable name auth or as a default export.\n\napp/lib/auth.server.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    database: {\n        provider: \"postgres\", //change this to your database provider\n        url: process.env.DATABASE_URL, // path to your database or connection string\n    }\n})\nCreate API Route\n\nWe need to mount the handler to a API route. Create a resource route file api.auth.$.ts inside app/routes/ directory. And add the following code:\n\napp/routes/api.auth.$.ts\nimport { auth } from '~/lib/auth.server' // Adjust the path as necessary\nimport type { LoaderFunctionArgs, ActionFunctionArgs } from \"@remix-run/node\"\nexport async function loader({ request }: LoaderFunctionArgs) {\n    return auth.handler(request)\n}\nexport async function action({ request }: ActionFunctionArgs) {\n    return auth.handler(request)\n}\n\nYou can change the path on your better-auth configuration but it's recommended to keep it as routes/api.auth.$.ts\n\nCreate a client\n\nCreate a client instance. Here we are creating auth-client.ts file inside the lib/ directory.\n\napp/lib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\" // make sure to import from better-auth/react\nexport const authClient = createAuthClient({\n    //you can pass client configuration here\n})\n\nOnce you have created the client, you can use it to sign up, sign in, and perform other actions.\n\nExample usage\nSign Up\napp/routes/signup.tsx\nimport { Form } from \"@remix-run/react\"\nimport { useState } from \"react\"\nimport { authClient } from \"~/lib/auth-client\"\nexport default function SignUp() {\n  const [email, setEmail] = useState(\"\")\n  const [name, setName] = useState(\"\")\n  const [password, setPassword] = useState(\"\")\n  const signUp = async () => {\n    await authClient.signUp.email(\n      {\n        email,\n        password,\n        name,\n      },\n      {\n        onRequest: (ctx) => {\n          // show loading state\n        },\n        onSuccess: (ctx) => {\n          // redirect to home\n        },\n        onError: (ctx) => {\n          alert(ctx.error)\n        },\n      },\n    )\n  }\n  return (\n    <div>\n      <h2>\n        Sign Up\n      </h2>\n      <Form\n        onSubmit={signUp}\n      >\n        <input\n          type=\"text\"\n          value={name}\n          onChange={(e) => setName(e.target.value)}\n          placeholder=\"Name\"\n        />\n        <input\n          type=\"email\"\n          value={email}\n          onChange={(e) => setEmail(e.target.value)}\n          placeholder=\"Email\"\n        />\n        <input\n          type=\"password\"\n          value={password}\n          onChange={(e) => setPassword(e.target.value)}\n          placeholder=\"Password\"\n        />\n        <button\n          type=\"submit\"\n        >\n          Sign Up\n        </button>\n      </Form>\n    </div>\n  )\n}\nSign In\napp/routes/signin.tsx\nimport { Form } from \"@remix-run/react\"\nimport { useState } from \"react\"\nimport { authClient } from \"~/services/auth-client\"\nexport default function SignIn() {\n  const [email, setEmail] = useState(\"\")\n  const [password, setPassword] = useState(\"\")\n  const signIn = async () => {\n    await authClient.signIn.email(\n      {\n        email,\n        password,\n      },\n      {\n        onRequest: (ctx) => {\n          // show loading state\n        },\n        onSuccess: (ctx) => {\n          // redirect to home\n        },\n        onError: (ctx) => {\n          alert(ctx.error)\n        },\n      },\n    )\n  }\n  return (\n    <div>\n      <h2>\n        Sign In\n      </h2>\n      <Form onSubmit={signIn}>\n        <input\n          type=\"email\"\n          value={email}\n          onChange={(e) => setEmail(e.target.value)}\n        />\n        <input\n          type=\"password\"\n          value={password}\n          onChange={(e) => setPassword(e.target.value)}\n        />\n        <button\n          type=\"submit\"\n        >\n          Sign In\n        </button>\n      </Form>\n    </div>\n  )\n}\nEdit on GitHub\n\nPrevious Page\n\nAstro\n\nNext Page\n\nNext"
  },
  {
    "title": "Nuxt Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/nuxt",
    "html": "Nuxt Integration\nCopy Markdown\nOpen in\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nCreate API Route\n\nWe need to mount the handler to an API route. Create a file inside /server/api/auth called [...all].ts and add the following code:\n\nserver/api/auth/[...all].ts\nimport { auth } from \"~/lib/auth\"; // import your auth config\nexport default defineEventHandler((event) => {\n\treturn auth.handler(toWebRequest(event));\n});\n\nYou can change the path on your better-auth configuration but it's recommended to keep it as /api/auth/[...all]\n\nMigrate the database\n\nRun the following command to create the necessary tables in your database:\n\nnpx @better-auth/cli migrate\nCreate a client\n\nCreate a client instance. You can name the file anything you want. Here we are creating client.ts file inside the lib/ directory.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/vue\" // make sure to import from better-auth/vue\nexport const authClient = createAuthClient({\n    //you can pass client configuration here\n})\n\nOnce you have created the client, you can use it to sign up, sign in, and perform other actions. Some of the actions are reactive.\n\nExample usage\nindex.vue\n<script setup lang=\"ts\">\nimport { authClient } from \"~/lib/client\"\nconst session = authClient.useSession()\n</script>\n<template>\n    <div>\n        <button v-if=\"!session?.data\" @click=\"() => authClient.signIn.social({\n            provider: 'github'\n        })\">\n            Continue with GitHub\n        </button>\n        <div>\n            <pre>{{ session.data }}</pre>\n            <button v-if=\"session.data\" @click=\"authClient.signOut()\">\n                Sign out\n            </button>\n        </div>\n    </div>\n</template>\nServer Usage\n\nThe api object exported from the auth instance contains all the actions that you can perform on the server. Every endpoint made inside Better Auth is a invocable as a function. Including plugins endpoints.\n\nExample: Getting Session on a server API route\n\nserver/api/example.ts\nimport { auth } from \"~/lib/auth\";\nexport default defineEventHandler((event) => {\n    const session = await auth.api.getSession({\n      headers: event.headers\n    });\n   if(session) {\n     // access the session.session && session.user\n   }\n});\nSSR Usage\n\nIf you are using Nuxt with SSR, you can use the useSession function in the setup function of your page component and pass useFetch to make it work with SSR.\n\nindex.vue\n<script setup lang=\"ts\">\nimport { authClient } from \"~/lib/auth-client\";\nconst { data: session } = await authClient.useSession(useFetch);\n</script>\n<template>\n    <p>\n        {{ session }}\n    </p>\n</template>\nMiddleware\n\nTo add middleware to your Nuxt project, you can use the useSession method from the client.\n\nmiddleware/auth.global.ts\nimport { authClient } from \"~/lib/auth-client\";\nexport default defineNuxtRouteMiddleware(async (to, from) => {\n\tconst { data: session } = await authClient.useSession(useFetch); \n\tif (!session.value) {\n\t\tif (to.path === \"/dashboard\") {\n\t\t\treturn navigateTo(\"/\");\n\t\t}\n\t}\n});\nResources & Examples\nNuxt and Nuxt Hub example on GitHub.\nNuxtZzle is Nuxt,Drizzle ORM example on GitHub preview\nNuxt example on StackBlitz.\nNuxSaaS (Github) is a full-stack SaaS Starter Kit that leverages Better Auth for secure and efficient user authentication. Demo\nNuxtOne (Github) is a Nuxt-based starter template for building AIaaS (AI-as-a-Service) applications preview\nEdit on GitHub\n\nPrevious Page\n\nNext\n\nNext Page\n\nSvelteKit"
  },
  {
    "title": "SvelteKit Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/svelte-kit",
    "html": "SvelteKit Integration\nCopy Markdown\nOpen in\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nMount the handler\n\nWe need to mount the handler to SvelteKit server hook.\n\nhooks.server.ts\nimport { auth } from \"$lib/auth\";\nimport { svelteKitHandler } from \"better-auth/svelte-kit\";\nimport { building } from \"$app/environment\";\nexport async function handle({ event, resolve }) {\n  return svelteKitHandler({ event, resolve, auth, building });\n}\nPopulate session data in the event (event.locals)\n\nThe svelteKitHandler does not automatically populate event.locals.user or event.locals.session. If you want to access the current session in your server code (e.g., in +layout.server.ts, actions, or endpoints), populate event.locals in your handle hook:\n\nhooks.server.ts\nimport { auth } from \"$lib/auth\";\nimport { svelteKitHandler } from \"better-auth/svelte-kit\";\nimport { building } from \"$app/environment\";\nexport async function handle({ event, resolve }) {\n  // Fetch current session from Better Auth\n  const session = await auth.api.getSession({\n    headers: event.request.headers,\n  });\n  // Make session and user available on server\n  if (session) {\n    event.locals.session = session.session;\n    event.locals.user = session.user;\n  }\n  return svelteKitHandler({ event, resolve, auth, building });\n}\nServer Action Cookies\n\nTo ensure cookies are properly set when you call functions like signInEmail or signUpEmail in a server action, you should use the sveltekitCookies plugin. This plugin will automatically handle setting cookies for you in SvelteKit.\n\nYou need to add it as a plugin to your Better Auth instance.\n\nThe getRequestEvent function is available in SvelteKit 2.20.0 and later. Make sure you are using a compatible version.\n\nlib/auth.ts\nimport { betterAuth } from \"better-auth\";\nimport { sveltekitCookies } from \"better-auth/svelte-kit\";\nimport { getRequestEvent } from \"$app/server\";\nexport const auth = betterAuth({\n  // ... your config\n  plugins: [sveltekitCookies(getRequestEvent)], // make sure this is the last plugin in the array\n});\nCreate a client\n\nCreate a client instance. You can name the file anything you want. Here we are creating client.ts file inside the lib/ directory.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/svelte\"; // make sure to import from better-auth/svelte\nexport const authClient = createAuthClient({\n  // you can pass client configuration here\n});\n\nOnce you have created the client, you can use it to sign up, sign in, and perform other actions. Some of the actions are reactive. The client use nano-store to store the state and reflect changes when there is a change like a user signing in or out affecting the session state.\n\nExample usage\n<script lang=\"ts\">\n  import { authClient } from \"$lib/client\";\n  const session = authClient.useSession();\n</script>\n    <div>\n      {#if $session.data}\n        <div>\n          <p>\n            {$session.data.user.name}\n          </p>\n          <button\n            on:click={async () => {\n              await authClient.signOut();\n            }}\n          >\n            Sign Out\n          </button>\n        </div>\n      {:else}\n        <button\n          on:click={async () => {\n            await authClient.signIn.social({\n              provider: \"github\",\n            });\n          }}\n        >\n          Continue with GitHub\n        </button>\n      {/if}\n    </div>\nEdit on GitHub\n\nPrevious Page\n\nNuxt\n\nNext Page\n\nSolidStart"
  },
  {
    "title": "SolidStart Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/solid-start",
    "html": "SolidStart Integration\nCopy Markdown\nOpen in\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nMount the handler\n\nWe need to mount the handler to SolidStart server. Put the following code in your *auth.ts file inside /routes/api/auth folder.\n\n*auth.ts\nimport { auth } from \"~/lib/auth\";\nimport { toSolidStartHandler } from \"better-auth/solid-start\";\nexport const { GET, POST } = toSolidStartHandler(auth);\nEdit on GitHub\n\nPrevious Page\n\nSvelteKit\n\nNext Page\n\nTanStack Start"
  },
  {
    "title": "TanStack Start Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/tanstack",
    "html": "TanStack Start Integration\nCopy Markdown\nOpen in\n\nThis integration guide is assuming you are using TanStack Start.\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nMount the handler\n\nWe need to mount the handler to a TanStack API endpoint/Server Route. Create a new file: /src/routes/api/auth/$.ts\n\nsrc/routes/api/auth/$.ts\nimport { auth } from '@/lib/auth'\nimport { createFileRoute } from '@tanstack/react-router'\nexport const Route = createFileRoute('/api/auth/$')({\n  server: {\n    handlers: {\n      GET: ({ request }) => {\n        return auth.handler(request)\n      },\n      POST: ({ request }) => {\n        return auth.handler(request)\n      },\n    },\n  },\n})\nUsage tips\nWe recommend using the client SDK or authClient to handle authentication, rather than server actions with auth.api.\nWhen you call functions that need to set cookies (like signInEmail or signUpEmail), you'll need to handle cookie setting for TanStack Start. Better Auth provides a reactStartCookies plugin to automatically handle this for you.\nsrc/lib/auth.ts\nimport { betterAuth } from \"better-auth\";\nimport { reactStartCookies } from \"better-auth/react-start\";\nexport const auth = betterAuth({\n    //...your config\n    plugins: [reactStartCookies()] // make sure this is the last plugin in the array\n})\n\nNow, when you call functions that set cookies, they will be automatically set using TanStack Start's cookie handling system.\n\nimport { auth } from \"@/lib/auth\"\nconst signIn = async () => {\n    await auth.api.signInEmail({\n        body: {\n            email: \"user@email.com\",\n            password: \"password\",\n        }\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nSolidStart\n\nNext Page\n\nBackend"
  },
  {
    "title": "Hono Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/hono",
    "html": "Hono Integration\nCopy Markdown\nOpen in\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nMount the handler\n\nWe need to mount the handler to Hono endpoint.\n\nimport { Hono } from \"hono\";\nimport { auth } from \"./auth\";\nimport { serve } from \"@hono/node-server\";\nconst app = new Hono();\napp.on([\"POST\", \"GET\"], \"/api/auth/*\", (c) => {\n\treturn auth.handler(c.req.raw);\n});\nserve(app);\nCors\n\nTo configure cors, you need to use the cors plugin from hono/cors.\n\nimport { Hono } from \"hono\";\nimport { auth } from \"./auth\";\nimport { serve } from \"@hono/node-server\";\nimport { cors } from \"hono/cors\";\n \nconst app = new Hono();\napp.use(\n\t\"/api/auth/*\", // or replace with \"*\" to enable cors for all routes\n\tcors({\n\t\torigin: \"http://localhost:3001\", // replace with your origin\n\t\tallowHeaders: [\"Content-Type\", \"Authorization\"],\n\t\tallowMethods: [\"POST\", \"GET\", \"OPTIONS\"],\n\t\texposeHeaders: [\"Content-Length\"],\n\t\tmaxAge: 600,\n\t\tcredentials: true,\n\t}),\n);\napp.on([\"POST\", \"GET\"], \"/api/auth/*\", (c) => {\n\treturn auth.handler(c.req.raw);\n});\nserve(app);\n\nImportant: CORS middleware must be registered before your routes. This ensures that cross-origin requests are properly handled before they reach your authentication endpoints.\n\nMiddleware\n\nYou can add a middleware to save the session and user in a context and also add validations for every route.\n\nimport { Hono } from \"hono\";\nimport { auth } from \"./auth\";\nimport { serve } from \"@hono/node-server\";\nimport { cors } from \"hono/cors\";\n \nconst app = new Hono<{\n\tVariables: {\n\t\tuser: typeof auth.$Infer.Session.user | null;\n\t\tsession: typeof auth.$Infer.Session.session | null\n\t}\n}>();\napp.use(\"*\", async (c, next) => {\n\tconst session = await auth.api.getSession({ headers: c.req.raw.headers });\n  \tif (!session) {\n    \tc.set(\"user\", null);\n    \tc.set(\"session\", null);\n    \tawait next();\n        return;\n  \t}\n  \tc.set(\"user\", session.user);\n  \tc.set(\"session\", session.session);\n  \tawait next();\n});\napp.on([\"POST\", \"GET\"], \"/api/auth/*\", (c) => {\n\treturn auth.handler(c.req.raw);\n});\nserve(app);\n\nThis will allow you to access the user and session object in all of your routes.\n\napp.get(\"/session\", (c) => {\n\tconst session = c.get(\"session\")\n\tconst user = c.get(\"user\")\n\t\n\tif(!user) return c.body(null, 401);\n  \treturn c.json({\n\t  session,\n\t  user\n\t});\n});\nCross-Domain Cookies\n\nBy default, all Better Auth cookies are set with SameSite=Lax. If you need to use cookies across different domains, you’ll need to set SameSite=None and Secure=true. However, we recommend using subdomains whenever possible, as this allows you to keep SameSite=Lax. To enable cross-subdomain cookies, simply turn on crossSubDomainCookies in your auth config.\n\nauth.ts\nexport const auth = createAuth({\n  advanced: {\n    crossSubDomainCookies: {\n      enabled: true\n    }\n  }\n})\n\nIf you still need to set SameSite=None and Secure=true, you can adjust these attributes globally through cookieOptions in the createAuth configuration.\n\nauth.ts\nexport const auth = createAuth({\n  advanced: {\n    defaultCookieAttributes: {\n      sameSite: \"none\",\n      secure: true,\n      partitioned: true // New browser standards will mandate this for foreign cookies\n    }\n  }\n})\n\nYou can also customize cookie attributes individually by setting them within cookies in your auth config.\n\nauth.ts\nexport const auth = createAuth({\n  advanced: {\n    cookies: {\n      sessionToken: {\n        attributes: {\n          sameSite: \"none\",\n          secure: true,\n          partitioned: true // New browser standards will mandate this for foreign cookies\n        }\n      }\n    }\n  }\n})\nClient-Side Configuration\n\nWhen using the Hono client (@hono/client) to make requests to your Better Auth-protected endpoints, you need to configure it to send credentials (cookies) with cross-origin requests.\n\napi.ts\nimport { hc } from \"hono/client\";\nimport type { AppType } from \"./server\"; // Your Hono app type\nconst client = hc<AppType>(\"http://localhost:8787/\", {\n  init: {\n    credentials: \"include\", // Required for sending cookies cross-origin\n  },\n});\n// Now your client requests will include credentials\nconst response = await client.someProtectedEndpoint.$get();\n\nThis configuration is necessary when:\n\nYour client and server are on different domains/ports during development\nYou're making cross-origin requests in production\nYou need to send authentication cookies with your requests\n\nThe credentials: \"include\" option tells the fetch client to send cookies even for cross-origin requests. This works in conjunction with the CORS configuration on your server that has credentials: true.\n\nNote: Make sure your CORS configuration on the server matches your client's domain, and that credentials: true is set in both the server's CORS config and the client's fetch config.\n\nEdit on GitHub\n\nPrevious Page\n\nBackend\n\nNext Page\n\nFastify"
  },
  {
    "title": "Express Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/express",
    "html": "Express Integration\nCopy Markdown\nOpen in\n\nThis guide will show you how to integrate Better Auth with express.js.\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nNote that CommonJS (cjs) isn't supported. Use ECMAScript Modules (ESM) by setting \"type\": \"module\" in your package.json or configuring your tsconfig.json to use ES modules.\n\nMount the handler\n\nTo enable Better Auth to handle requests, we need to mount the handler to an API route. Create a catch-all route to manage all requests to /api/auth/* in case of ExpressJS v4 or /api/auth/*splat in case of ExpressJS v5 (or any other path specified in your Better Auth options).\n\nDon’t use express.json() before the Better Auth handler. Use it only for other routes, or the client API will get stuck on \"pending\".\n\nserver.ts\nimport express from \"express\";\nimport { toNodeHandler } from \"better-auth/node\";\nimport { auth } from \"./auth\";\nconst app = express();\nconst port = 3005;\napp.all(\"/api/auth/*\", toNodeHandler(auth)); // For ExpressJS v4\n// app.all(\"/api/auth/*splat\", toNodeHandler(auth)); For ExpressJS v5 \n// Mount express json middleware after Better Auth handler\n// or only apply it to routes that don't interact with Better Auth\napp.use(express.json());\napp.listen(port, () => {\n\tconsole.log(`Example app listening on port ${port}`);\n});\n\nAfter completing the setup, start your server. Better Auth will be ready to use. You can send a GET request to the /ok endpoint (/api/auth/ok) to verify that the server is running.\n\nCors Configuration\n\nTo add CORS (Cross-Origin Resource Sharing) support to your Express server when integrating Better Auth, you can use the cors middleware. Below is an updated example showing how to configure CORS for your server:\n\nimport express from \"express\";\nimport cors from \"cors\"; // Import the CORS middleware\nimport { toNodeHandler, fromNodeHeaders } from \"better-auth/node\";\nimport { auth } from \"./auth\";\nconst app = express();\nconst port = 3005;\n// Configure CORS middleware\napp.use(\n  cors({\n    origin: \"http://your-frontend-domain.com\", // Replace with your frontend's origin\n    methods: [\"GET\", \"POST\", \"PUT\", \"DELETE\"], // Specify allowed HTTP methods\n    credentials: true, // Allow credentials (cookies, authorization headers, etc.)\n  })\n);\nGetting the User Session\n\nTo retrieve the user's session, you can use the getSession method provided by the auth object. This method requires the request headers to be passed in a specific format. To simplify this process, Better Auth provides a fromNodeHeaders helper function that converts Node.js request headers to the format expected by Better Auth (a Headers object).\n\nHere's an example of how to use getSession in an Express route:\n\nserver.ts\nimport { fromNodeHeaders } from \"better-auth/node\";\nimport { auth } from \"./auth\"; // Your Better Auth instance\napp.get(\"/api/me\", async (req, res) => {\n \tconst session = await auth.api.getSession({\n      headers: fromNodeHeaders(req.headers),\n    });\n\treturn res.json(session);\n});\nEdit on GitHub\n\nPrevious Page\n\nFastify\n\nNext Page\n\nElysia"
  },
  {
    "title": "Elysia Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/elysia",
    "html": "Elysia Integration\nCopy Markdown\nOpen in\n\nThis integration guide is assuming you are using Elysia with bun server.\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nMount the handler\n\nWe need to mount the handler to Elysia endpoint.\n\nimport { Elysia } from \"elysia\";\nimport { auth } from \"./auth\";\nconst app = new Elysia().mount(auth.handler).listen(3000);\nconsole.log(\n  `🦊 Elysia is running at ${app.server?.hostname}:${app.server?.port}`,\n);\nCORS\n\nTo configure cors, you can use the cors plugin from @elysiajs/cors.\n\nimport { Elysia } from \"elysia\";\nimport { cors } from \"@elysiajs/cors\";\nimport { auth } from \"./auth\";\nconst app = new Elysia()\n  .use(\n    cors({\n      origin: \"http://localhost:3001\",\n      methods: [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"],\n      credentials: true,\n      allowedHeaders: [\"Content-Type\", \"Authorization\"],\n    }),\n  )\n  .mount(auth.handler)\n  .listen(3000);\nconsole.log(\n  `🦊 Elysia is running at ${app.server?.hostname}:${app.server?.port}`,\n);\nMacro\n\nYou can use macro with resolve to provide session and user information before pass to view.\n\nimport { Elysia } from \"elysia\";\nimport { auth } from \"./auth\";\n// user middleware (compute user and session and pass to routes)\nconst betterAuth = new Elysia({ name: \"better-auth\" })\n  .mount(auth.handler)\n  .macro({\n    auth: {\n      async resolve({ status, request: { headers } }) {\n        const session = await auth.api.getSession({\n          headers,\n        });\n        if (!session) return status(401);\n        return {\n          user: session.user,\n          session: session.session,\n        };\n      },\n    },\n  });\nconst app = new Elysia()\n  .use(betterAuth)\n  .get(\"/user\", ({ user }) => user, {\n    auth: true,\n  })\n  .listen(3000);\nconsole.log(\n  `🦊 Elysia is running at ${app.server?.hostname}:${app.server?.port}`,\n);\n\nThis will allow you to access the user and session object in all of your routes.\n\nEdit on GitHub\n\nPrevious Page\n\nExpress\n\nNext Page\n\nNitro"
  },
  {
    "title": "NestJS Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/nestjs",
    "html": "NestJS Integration\nCopy Markdown\nOpen in\n\nThis guide will show you how to integrate Better Auth with NestJS.\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nThe NestJS integration is community maintained. If you encounter any issues, please open them at nestjs-better-auth.\n\nInstallation\n\nInstall the NestJS integration library:\n\nnpm\npnpm\nyarn\nbun\nnpm install @thallesp/nestjs-better-auth\nBasic Setup\n\nCurrently the library has beta support for Fastify, if you experience any issues with it, please open an issue at nestjs-better-auth.\n\n1. Disable Body Parser\n\nDisable NestJS's built-in body parser to allow Better Auth to handle the raw request body:\n\nmain.ts\nimport { NestFactory } from \"@nestjs/core\";\nimport { AppModule } from \"./app.module\";\nasync function bootstrap() {\n  const app = await NestFactory.create(AppModule, {\n    bodyParser: false, // Required for Better Auth\n  });\n  await app.listen(process.env.PORT ?? 3000);\n}\nbootstrap();\n2. Import AuthModule\n\nImport the AuthModule in your root module:\n\napp.module.ts\nimport { Module } from '@nestjs/common';\nimport { AuthModule } from '@thallesp/nestjs-better-auth';\nimport { auth } from \"./auth\"; // Your Better Auth instance\n@Module({\n  imports: [\n    AuthModule.forRoot({ auth }),\n  ],\n})\nexport class AppModule {}\n3. Route Protection\n\nGlobal by default: An AuthGuard is registered globally by this module. All routes are protected unless you explicitly allow access.\n\nUse the Session decorator to access the user session:\n\nuser.controller.ts\nimport { Controller, Get } from '@nestjs/common';\nimport { Session, UserSession, AllowAnonymous, OptionalAuth } from '@thallesp/nestjs-better-auth';\n@Controller('users')\nexport class UserController {\n  @Get('me')\n  async getProfile(@Session() session: UserSession) {\n    return { user: session.user };\n  }\n  @Get('public')\n  @AllowAnonymous() // Allow anonymous access\n  async getPublic() {\n    return { message: 'Public route' };\n  }\n  @Get('optional')\n  @OptionalAuth() // Authentication is optional\n  async getOptional(@Session() session: UserSession) {\n    return { authenticated: !!session };\n  }\n}\nFull Documentation\n\nFor comprehensive documentation including decorators, hooks, global guards, and advanced configuration, visit the NestJS Better Auth repository.\n\nEdit on GitHub\n\nPrevious Page\n\nNitro\n\nNext Page\n\nConvex"
  },
  {
    "title": "Nitro Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/nitro",
    "html": "Nitro Integration\nCopy Markdown\nOpen in\n\nBetter Auth can be integrated with your Nitro Application (an open source framework to build web servers).\n\nThis guide aims to help you integrate Better Auth with your Nitro application in a few simple steps.\n\nCreate a new Nitro Application\n\nStart by scaffolding a new Nitro application using the following command:\n\nTerminal\nnpx giget@latest nitro nitro-app --install\n\nThis will create the nitro-app directory and install all the dependencies. You can now open the nitro-app directory in your code editor.\n\nPrisma Adapter Setup\n\nThis guide assumes that you have a basic understanding of Prisma. If you are new to Prisma, you can check out the Prisma documentation.\n\nThe sqlite database used in this guide will not work in a production environment. You should replace it with a production-ready database like PostgreSQL.\n\nFor this guide, we will be using the Prisma adapter. You can install prisma client by running the following command:\n\nnpm\npnpm\nyarn\nbun\nnpm install @prisma/client\n\nprisma can be installed as a dev dependency using the following command:\n\nnpm\npnpm\nyarn\nbun\nnpm install -D prisma\n\nGenerate a schema.prisma file in the prisma directory by running the following command:\n\nTerminal\nnpx prisma init\n\nYou can now replace the contents of the schema.prisma file with the following:\n\nprisma/schema.prisma\ngenerator client {\n  provider = \"prisma-client-js\"\n}\ndatasource db {\n  provider = \"sqlite\"\n  url      = env(\"DATABASE_URL\")\n}\n// Will be deleted. Just need it to generate the prisma client\nmodel Test {\n  id   Int    @id @default(autoincrement())\n  name String\n}\n\nEnsure that you update the DATABASE_URL in your .env file to point to the location of your database.\n\n.env\nDATABASE_URL=\"file:./dev.db\"\n\nRun the following command to generate the Prisma client & sync the database:\n\nTerminal\nnpx prisma db push\nInstall & Configure Better Auth\n\nFollow steps 1 & 2 from the installation guide to install Better Auth in your Nitro application & set up the environment variables.\n\nOnce that is done, create your Better Auth instance within the server/utils/auth.ts file.\n\nserver/utils/auth.ts\nimport { betterAuth } from \"better-auth\";\nimport { prismaAdapter } from \"better-auth/adapters/prisma\";\nimport { PrismaClient } from \"@prisma/client\";\nconst prisma = new PrismaClient();\nexport const auth = betterAuth({\n  database: prismaAdapter(prisma, { provider: \"sqlite\" }),\n  emailAndPassword: { enabled: true },\n});\nUpdate Prisma Schema\n\nUse the Better Auth CLI to update your Prisma schema with the required models by running the following command:\n\nTerminal\nnpx @better-auth/cli generate --config server/utils/auth.ts\n\nThe --config flag is used to specify the path to the file where you have created your Better Auth instance.\n\nHead over to the prisma/schema.prisma file & save the file to trigger the format on save.\n\nAfter saving the file, you can run the npx prisma db push command to update the database schema.\n\nMount The Handler\n\nYou can now mount the Better Auth handler in your Nitro application. You can do this by adding the following code to your server/routes/api/auth/[...all].ts file:\n\nserver/routes/api/auth/[...all].ts\nexport default defineEventHandler((event) => {\n  return auth.handler(toWebRequest(event));\n});\n\nThis is a catch-all route that will handle all requests to /api/auth/*.\n\nCORS\n\nYou can configure CORS for your Nitro app by creating a plugin.\n\nStart by installing the cors package:\n\nnpm\npnpm\nyarn\nbun\nnpm install cors\n\nYou can now create a new file server/plugins/cors.ts and add the following code:\n\nserver/plugins/cors.ts\nimport cors from \"cors\";\nexport default defineNitroPlugin((plugin) => {\n  plugin.h3App.use(\n    fromNodeMiddleware(\n      cors({\n        origin: \"*\",\n      }),\n    ),\n  );\n});\n\nThis will enable CORS for all routes. You can customize the origin property to allow requests from specific domains. Ensure that the config is in sync with your frontend application.\n\nAuth Guard/Middleware\n\nYou can add an auth guard to your Nitro application to protect routes that require authentication. You can do this by creating a new file server/utils/require-auth.ts and adding the following code:\n\nserver/utils/require-auth.ts\nimport { EventHandler, H3Event } from \"h3\";\nimport { fromNodeHeaders } from \"better-auth/node\";\n/**\n * Middleware used to require authentication for a route.\n *\n * Can be extended to check for specific roles or permissions.\n */\nexport const requireAuth: EventHandler = async (event: H3Event) => {\n  const headers = event.headers;\n  const session = await auth.api.getSession({\n    headers: headers,\n  });\n  if (!session)\n    throw createError({\n      statusCode: 401,\n      statusMessage: \"Unauthorized\",\n    });\n  // You can save the session to the event context for later use\n  event.context.auth = session;\n};\n\nYou can now use this event handler/middleware in your routes to protect them:\n\nserver/routes/api/secret.get.ts\n// Object syntax of the route handler\nexport default defineEventHandler({\n  // The user has to be logged in to access this route\n  onRequest: [requireAuth],\n  handler: async (event) => {\n    setResponseStatus(event, 201, \"Secret data\");\n    return { message: \"Secret data\" };\n  },\n});\nExample\n\nYou can find an example of a Nitro application integrated with Better Auth & Prisma here.\n\nEdit on GitHub\n\nPrevious Page\n\nElysia\n\nNext Page\n\nNestJS"
  },
  {
    "title": "Convex Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/convex",
    "html": "Convex Integration\nCopy Markdown\nOpen in\n\nThis documentation comes from the Convex documentation, for more information, please refer to their documentation.\n\nPrerequisites\nCreate a Convex project\n\nTo use Convex + Better Auth, you'll first need a Convex project. If you don't have one, run the following command to get started.\n\nnpm\npnpm\nyarn\nbun\nnpm create convex@latest\n\nCheck out the Convex docs to learn more about Convex.\n\nRun convex dev\n\nRunning the CLI during setup will initialize your Convex deployment if it doesn't already exist, and keeps generated types current through the process. Keep it running.\n\nnpm\npnpm\nyarn\nbun\nnpx convex dev\nInstallation of Convex + Better Auth\n\nThe following documentation assumes you're using Next.js.\n\nIf you're not using Next.js, support for other frameworks is documented in the installation guide by Convex.\n\nFor a complete example, check out Convex + Better Auth example with Next.js on GitHub.\n\nInstallation\nInstall packages\n\nInstall the component, a pinned version of Better Auth, and ensure the latest version of Convex.\n\nThis component requires Convex 1.25.0 or later.\n\nnpm\npnpm\nyarn\nbun\nnpm install better-auth@1.3.27 --save-exact\nnpm install convex@latest @convex-dev/better-auth\nRegister the component\n\nRegister the Better Auth component in your Convex project.\n\nconvex/convex.config.ts\nimport { defineApp } from \"convex/server\";\nimport betterAuth from \"@convex-dev/better-auth/convex.config\";\nconst app = defineApp();\napp.use(betterAuth);\nexport default app;\nAdd Convex auth config\n\nAdd a convex/auth.config.ts file to configure Better Auth as an authentication provider.\n\nconvex/auth.config.ts\nexport default {\n    providers: [\n        {\n            domain: process.env.CONVEX_SITE_URL,\n            applicationID: \"convex\",\n        },\n    ],\n};\nSet environment variables\n\nGenerate a secret for encryption and generating hashes. Use the command below if you have openssl installed, or generate your own however you like.\n\nnpm\npnpm\nyarn\nbun\nnpx convex env set BETTER_AUTH_SECRET=$(openssl rand -base64 32)\n\nAdd your site URL to your Convex deployment.\n\nnpm\npnpm\nyarn\nbun\nnpx convex env set SITE_URL http://localhost:3000\n\nAdd environment variables to the .env.local file created by npx convex dev. It will be picked up by your framework dev server.\n\nCloud\nSelf hosted\n.env.local\n# Deployment used by \\`npx convex dev\\`\nCONVEX_DEPLOYMENT=dev:adjective-animal-123 # team: team-name, project: project-name\nNEXT_PUBLIC_CONVEX_URL=https://adjective-animal-123.convex.cloud\n# Same as NEXT_PUBLIC_CONVEX_URL but ends in .site\nNEXT_PUBLIC_CONVEX_SITE_URL=https://adjective-animal-123.convex.site\n# Your local site URL\nSITE_URL=http://localhost:3000\nCreate a Better Auth instance\n\nCreate a Better Auth instance and initialize the component.\n\nSome TypeScript errors will show until you save the file.\nconvex/auth.ts\nimport { createClient, type GenericCtx } from \"@convex-dev/better-auth\";\nimport { convex } from \"@convex-dev/better-auth/plugins\";\nimport { components } from \"./_generated/api\";\nimport { DataModel } from \"./_generated/dataModel\";\nimport { query } from \"./_generated/server\";\nimport { betterAuth } from \"better-auth\";\nconst siteUrl = process.env.SITE_URL!;\n// The component client has methods needed for integrating Convex with Better Auth,\n// as well as helper methods for general use.\nexport const authComponent = createClient<DataModel>(components.betterAuth);\nexport const createAuth = (\n    ctx: GenericCtx<DataModel>,\n    { optionsOnly } = { optionsOnly: false },\n) => {\n    return betterAuth({\n        // disable logging when createAuth is called just to generate options.\n        // this is not required, but there's a lot of noise in logs without it.\n        logger: {\n            disabled: optionsOnly,\n        },\n        baseURL: siteUrl,\n        database: authComponent.adapter(ctx),\n        // Configure simple, non-verified email/password to get started\n        emailAndPassword: {\n            enabled: true,\n            requireEmailVerification: false,\n        },\n        plugins: [\n            // The Convex plugin is required for Convex compatibility\n            convex(),\n        ],\n    });\n};\n// Example function for getting the current user\n// Feel free to edit, omit, etc.\nexport const getCurrentUser = query({\n    args: {},\n    handler: async (ctx) => {\n        return authComponent.getAuthUser(ctx);\n    },\n});\nCreate a Better Auth client instance\n\nCreate a Better Auth client instance for interacting with the Better Auth server from your client.\n\nsrc/lib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\";\nimport { convexClient } from \"@convex-dev/better-auth/client/plugins\";\nexport const authClient = createAuthClient({\n    plugins: [convexClient()],\n});\nMount handlers\n\nRegister Better Auth route handlers on your Convex deployment.\n\nconvex/http.ts\nimport { httpRouter } from \"convex/server\";\nimport { authComponent, createAuth } from \"./auth\";\nconst http = httpRouter();\nauthComponent.registerRoutes(http, createAuth);\nexport default http;\n\nSet up route handlers to proxy auth requests from your framework server to your Convex deployment.\n\napp/api/auth/[...all]/route.ts\nimport { nextJsHandler } from \"@convex-dev/better-auth/nextjs\";\nexport const { GET, POST } = nextJsHandler();\nSet up Convex client provider\n\nWrap your app with the ConvexBetterAuthProvider component.\n\napp/ConvexClientProvider.tsx\n\"use client\";\nimport { ReactNode } from \"react\";\nimport { ConvexReactClient } from \"convex/react\";\nimport { authClient } from \"@/lib/auth-client\"; \nimport { ConvexBetterAuthProvider } from \"@convex-dev/better-auth/react\"; \nconst convex = new ConvexReactClient(process.env.NEXT_PUBLIC_CONVEX_URL!, {\n  // Optionally pause queries until the user is authenticated\n  expectAuth: true, \n});\nexport function ConvexClientProvider({ children }: { children: ReactNode }) {\n  return (\n    <ConvexBetterAuthProvider client={convex} authClient={authClient}>\n      {children}\n    </ConvexBetterAuthProvider>\n  );\n}\nYou're done!\n\nYou're now ready to start using Better Auth with Convex.\n\nUsage\nUsing Better Auth from the server\n\nTo use Better Auth's server methods in server rendering, server functions, or any other Next.js server code, use Convex functions and call the function from your server code.\n\nFirst, a token helper for calling Convex functions from your server code.\n\nsrc/lib/auth-server.ts\nimport { createAuth } from \"@/convex/auth\";\nimport { getToken as getTokenNextjs } from \"@convex-dev/better-auth/nextjs\";\nexport const getToken = () => {\n  return getTokenNextjs(createAuth);\n};\n\nHere's an example Convex function that uses Better Auth's server methods, and a server action that calls the Convex function.\n\nconvex/users.ts\nimport { mutation } from \"./_generated/server\";\nimport { v } from \"convex/values\";\nimport { createAuth, authComponent } from \"./auth\";\nexport const updateUserPassword = mutation({\n  args: {\n    currentPassword: v.string(),\n    newPassword: v.string(),\n  },\n  handler: async (ctx, args) => {\n    const { auth, headers } = await authComponent.getAuth(createAuth, ctx);\n    await auth.api.changePassword({\n      body: {\n        currentPassword: args.currentPassword,\n        newPassword: args.newPassword,\n      },\n      headers,\n    });\n  },\n});\napp/actions.ts\n\"use server\";\nimport { fetchMutation } from \"convex/nextjs\";\nimport { api } from \"../convex/_generated/api\";\nimport { getToken } from \"../lib/auth-server\";\n// Authenticated mutation via server function\nexport async function updatePassword({\n  currentPassword,\n  newPassword,\n}: {\n  currentPassword: string;\n  newPassword: string;\n}) {\n  const token = await getToken();\n  await fetchMutation(\n    api.users.updatePassword,\n    { currentPassword, newPassword },\n    { token }\n  );\n}\n\nThis documentation comes from the Convex documentation, for more information, please refer to their documentation.\n\nEdit on GitHub\n\nPrevious Page\n\nNestJS\n\nNext Page\n\nMobile & Desktop"
  },
  {
    "title": "Expo Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/expo",
    "html": "Expo Integration\nCopy Markdown\nOpen in\n\nExpo is a popular framework for building cross-platform apps with React Native. Better Auth supports both Expo native and web apps.\n\nInstallation\nConfigure A Better Auth Backend\n\nBefore using Better Auth with Expo, make sure you have a Better Auth backend set up. You can either use a separate server or leverage Expo's new API Routes feature to host your Better Auth instance.\n\nTo get started, check out our installation guide for setting up Better Auth on your server. If you prefer to check out the full example, you can find it here.\n\nTo use the new API routes feature in Expo to host your Better Auth instance you can create a new API route in your Expo app and mount the Better Auth handler.\n\napp/api/auth/[...auth]+api.ts\nimport { auth } from \"@/lib/auth\"; // import Better Auth handler\nconst handler = auth.handler;\nexport { handler as GET, handler as POST }; // export handler for both GET and POST requests\nInstall Server Dependencies\n\nInstall both the Better Auth package and Expo plugin into your server application.\n\nnpm\npnpm\nyarn\nbun\nnpm install better-auth @better-auth/expo\nInstall Client Dependencies\n\nYou also need to install both the Better Auth package and Expo plugin into your Expo application.\n\nnpm\npnpm\nyarn\nbun\nnpm install better-auth @better-auth/expo \n\nIf you plan on using our social integrations (Google, Apple etc.) then there are a few more dependencies that are required in your Expo app. In the default Expo template these are already installed so you may be able to skip this step if you have these dependencies already.\n\nnpm\npnpm\nyarn\nbun\nnpm install expo-linking expo-web-browser expo-constants\nAdd the Expo Plugin on Your Server\n\nAdd the Expo plugin to your Better Auth server.\n\nlib/auth.ts\nimport { betterAuth } from \"better-auth\";\nimport { expo } from \"@better-auth/expo\";\nexport const auth = betterAuth({\n    plugins: [expo()],\n    emailAndPassword: { \n        enabled: true, // Enable authentication using email and password.\n      }, \n});\nInitialize Better Auth Client\n\nTo initialize Better Auth in your Expo app, you need to call createAuthClient with the base URL of your Better Auth backend. Make sure to import the client from /react.\n\nMake sure you install the expo-secure-store package into your Expo app. This is used to store the session data and cookies securely.\n\nnpm\npnpm\nyarn\nbun\nnpm install expo-secure-store\n\nYou need to also import client plugin from @better-auth/expo/client and pass it to the plugins array when initializing the auth client.\n\nThis is important because:\n\nSocial Authentication Support: enables social auth flows by handling authorization URLs and callbacks within the Expo web browser.\nSecure Cookie Management: stores cookies securely and automatically adds them to the headers of your auth requests.\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\";\nimport { expoClient } from \"@better-auth/expo/client\";\nimport * as SecureStore from \"expo-secure-store\";\nexport const authClient = createAuthClient({\n    baseURL: \"http://localhost:8081\", // Base URL of your Better Auth backend.\n    plugins: [\n        expoClient({\n            scheme: \"myapp\",\n            storagePrefix: \"myapp\",\n            storage: SecureStore,\n        })\n    ]\n});\n\nBe sure to include the full URL, including the path, if you've changed the default path from /api/auth.\n\nScheme and Trusted Origins\n\nBetter Auth uses deep links to redirect users back to your app after authentication. To enable this, you need to add your app's scheme to the trustedOrigins list in your Better Auth config.\n\nFirst, make sure you have a scheme defined in your app.json file.\n\napp.json\n{\n    \"expo\": {\n        \"scheme\": \"myapp\"\n    }\n}\n\nThen, update your Better Auth config to include the scheme in the trustedOrigins list.\n\nauth.ts\nexport const auth = betterAuth({\n    trustedOrigins: [\"myapp://\"]\n})\n\nIf you have multiple schemes or need to support deep linking with various paths, you can use specific patterns or wildcards:\n\nauth.ts\nexport const auth = betterAuth({\n    trustedOrigins: [\n        // Basic scheme\n        \"myapp://\", \n        \n        // Production & staging schemes\n        \"myapp-prod://\",\n        \"myapp-staging://\",\n        \n        // Wildcard support for all paths following the scheme\n        \"myapp://*\"\n    ]\n})\n\nThe wildcard pattern can be particularly useful if your app uses different URL formats for deep linking based on features or screens.\n\nConfigure Metro Bundler\n\nTo resolve Better Auth exports you'll need to enable unstable_enablePackageExports in your metro config.\n\nmetro.config.js\nconst { getDefaultConfig } = require(\"expo/metro-config\");\nconst config = getDefaultConfig(__dirname)\nconfig.resolver.unstable_enablePackageExports = true; \nmodule.exports = config;\nIn case you don't have a metro.config.js file in your project run npx expo customize metro.config.js.\n\nIf you can't enable unstable_enablePackageExports option, you can use babel-plugin-module-resolver to manually resolve the paths.\n\nbabel.config.js\nmodule.exports = function (api) {\n    api.cache(true);\n    return {\n        presets: [\"babel-preset-expo\"],\n        plugins: [\n            [\n                \"module-resolver\",\n                {\n                    alias: {\n                        \"better-auth/react\": \"./node_modules/better-auth/dist/client/react/index.cjs\",\n                        \"better-auth/client/plugins\": \"./node_modules/better-auth/dist/client/plugins/index.cjs\",\n                        \"@better-auth/expo/client\": \"./node_modules/@better-auth/expo/dist/client.cjs\",\n                    },\n                },\n            ],\n        ],\n    }\n}\nIn case you don't have a babel.config.js file in your project run npx expo customize babel.config.js.\n\nDon't forget to clear the cache after making changes.\n\nnpx expo start --clear\nUsage\nAuthenticating Users\n\nWith Better Auth initialized, you can now use the authClient to authenticate users in your Expo app.\n\nsign-in\nsign-up\napp/sign-in.tsx\nimport { useState } from \"react\"; \nimport { View, TextInput, Button } from \"react-native\";\nimport { authClient } from \"@/lib/auth-client\";\nexport default function SignIn() {\n    const [email, setEmail] = useState(\"\");\n    const [password, setPassword] = useState(\"\");\n    const handleLogin = async () => {\n        await authClient.signIn.email({\n            email,\n            password,\n        })\n    };\n    return (\n        <View>\n            <TextInput\n                placeholder=\"Email\"\n                value={email}\n                onChangeText={setEmail}\n            />\n            <TextInput\n                placeholder=\"Password\"\n                value={password}\n                onChangeText={setPassword}\n            />\n            <Button title=\"Login\" onPress={handleLogin} />\n        </View>\n    );\n}\nSocial Sign-In\n\nFor social sign-in, you can use the authClient.signIn.social method with the provider name and a callback URL.\n\napp/social-sign-in.tsx\nimport { Button } from \"react-native\";\nexport default function SocialSignIn() {\n    const handleLogin = async () => {\n        await authClient.signIn.social({\n            provider: \"google\",\n            callbackURL: \"/dashboard\" // this will be converted to a deep link (eg. `myapp://dashboard`) on native\n        })\n    };\n    return <Button title=\"Login with Google\" onPress={handleLogin} />;\n}\nIdToken Sign-In\n\nIf you want to make provider request on the mobile device and then verify the ID token on the server, you can use the authClient.signIn.social method with the idToken option.\n\napp/social-sign-in.tsx\nimport { Button } from \"react-native\";\nexport default function SocialSignIn() {\n    const handleLogin = async () => {\n        await authClient.signIn.social({\n            provider: \"google\", // only google, apple and facebook are supported for idToken signIn\n            idToken: {\n                token: \"...\", // ID token from provider\n                nonce: \"...\", // nonce from provider (optional)\n            }\n            callbackURL: \"/dashboard\" // this will be converted to a deep link (eg. `myapp://dashboard`) on native\n        })\n    };\n    return <Button title=\"Login with Google\" onPress={handleLogin} />;\n}\nSession\n\nBetter Auth provides a useSession hook to access the current user's session in your app.\n\napp/index.tsx\nimport { Text } from \"react-native\";\nimport { authClient } from \"@/lib/auth-client\";\nexport default function Index() {\n    const { data: session } = authClient.useSession();\n    return <Text>Welcome, {session?.user.name}</Text>;\n}\n\nOn native, the session data will be cached in SecureStore. This will allow you to remove the need for a loading spinner when the app is reloaded. You can disable this behavior by passing the disableCache option to the client.\n\nMaking Authenticated Requests to Your Server\n\nTo make authenticated requests to your server that require the user's session, you have to retrieve the session cookie from SecureStore and manually add it to your request headers.\n\nimport { authClient } from \"@/lib/auth-client\";\nconst makeAuthenticatedRequest = async () => {\n  const cookies = authClient.getCookie(); \n  const headers = {\n    \"Cookie\": cookies, \n  };\n  const response = await fetch(\"http://localhost:8081/api/secure-endpoint\", { \n    headers,\n    // 'include' can interfere with the cookies we just set manually in the headers\n    credentials: \"omit\"\n  });\n  const data = await response.json();\n  return data;\n};\n\nExample: Usage With TRPC\n\nlib/trpc-provider.tsx\n//...other imports\nimport { authClient } from \"@/lib/auth-client\"; \nexport const api = createTRPCReact<AppRouter>();\nexport function TRPCProvider(props: { children: React.ReactNode }) {\n  const [queryClient] = useState(() => new QueryClient());\n  const [trpcClient] = useState(() =>\n    api.createClient({\n      links: [\n        httpBatchLink({\n          //...your other options\n          headers() {\n            const headers = new Map<string, string>(); \n            const cookies = authClient.getCookie(); \n            if (cookies) { \n              headers.set(\"Cookie\", cookies); \n            } \n            return Object.fromEntries(headers); \n          },\n        }),\n      ],\n    }),\n  );\n  return (\n    <api.Provider client={trpcClient} queryClient={queryClient}>\n      <QueryClientProvider client={queryClient}>\n        {props.children}\n      </QueryClientProvider>\n    </api.Provider>\n  );\n}\nOptions\nExpo Client\n\nstorage: the storage mechanism used to cache the session data and cookies.\n\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\";\nimport SecureStorage from \"expo-secure-store\";\nconst authClient = createAuthClient({\n    baseURL: \"http://localhost:8081\",\n    storage: SecureStorage\n});\n\nscheme: scheme is used to deep link back to your app after a user has authenticated using oAuth providers. By default, Better Auth tries to read the scheme from the app.json file. If you need to override this, you can pass the scheme option to the client.\n\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\";\nconst authClient = createAuthClient({\n    baseURL: \"http://localhost:8081\",\n    scheme: \"myapp\"\n});\n\ndisableCache: By default, the client will cache the session data in SecureStore. You can disable this behavior by passing the disableCache option to the client.\n\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/react\";\nconst authClient = createAuthClient({\n    baseURL: \"http://localhost:8081\",\n    disableCache: true\n});\nExpo Servers\n\nServer plugin options:\n\noverrideOrigin: Override the origin for Expo API routes (default: false). Enable this if you're facing cors origin issues with Expo API routes.\n\nEdit on GitHub\n\nPrevious Page\n\nMobile & Desktop\n\nNext Page\n\nLynx"
  },
  {
    "title": "Lynx Integration | Better Auth",
    "url": "https://www.better-auth.com/docs/integrations/lynx",
    "html": "Lynx Integration\nCopy Markdown\nOpen in\n\nThis integration guide is for using Better Auth with Lynx, a cross-platform rendering framework that enables developers to build applications for Android, iOS, and Web platforms with native rendering performance.\n\nBefore you start, make sure you have a Better Auth instance configured. If you haven't done that yet, check out the installation.\n\nInstallation\n\nInstall Better Auth and the Lynx React dependency:\n\nnpm\npnpm\nyarn\nbun\nnpm install better-auth @lynx-js/react\nCreate Client Instance\n\nImport createAuthClient from better-auth/lynx to create your client instance:\n\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/lynx\"\nexport const authClient = createAuthClient({\n    baseURL: \"http://localhost:3000\" // The base URL of your auth server\n})\nUsage\n\nThe Lynx client provides the same API as other Better Auth clients, with optimized integration for Lynx's reactive system.\n\nAuthentication Methods\nimport { authClient } from \"./lib/auth-client\"\n// Sign in with email and password\nawait authClient.signIn.email({\n    email: \"test@user.com\",\n    password: \"password1234\"\n})\n// Sign up\nawait authClient.signUp.email({\n    email: \"test@user.com\", \n    password: \"password1234\",\n    name: \"John Doe\"\n})\n// Sign out\nawait authClient.signOut()\nHooks\n\nThe Lynx client includes reactive hooks that integrate seamlessly with Lynx's component system:\n\nuseSession\ncomponents/user.tsx\nimport { authClient } from \"../lib/auth-client\"\nexport function User() {\n    const {\n        data: session,\n        isPending, // loading state\n        error // error object \n    } = authClient.useSession()\n    if (isPending) return <div>Loading...</div>\n    if (error) return <div>Error: {error.message}</div>\n    return (\n        <div>\n            {session ? (\n                <div>\n                    <p>Welcome, {session.user.name}!</p>\n                    <button onClick={() => authClient.signOut()}>\n                        Sign Out\n                    </button>\n                </div>\n            ) : (\n                <button onClick={() => authClient.signIn.social({\n                    provider: 'github'\n                })}>\n                    Sign In with GitHub\n                </button>\n            )}\n        </div>\n    )\n}\nStore Integration\n\nThe Lynx client uses nanostores for state management and provides a useStore hook for accessing reactive state:\n\ncomponents/session-info.tsx\nimport { useStore } from \"better-auth/lynx\"\nimport { authClient } from \"../lib/auth-client\"\nexport function SessionInfo() {\n    // Access the session store directly\n    const session = useStore(authClient.$store.session)\n    \n    return (\n        <div>\n            {session && (\n                <pre>{JSON.stringify(session, null, 2)}</pre>\n            )}\n        </div>\n    )\n}\nAdvanced Store Usage\n\nYou can use the store with selective key watching for optimized re-renders:\n\ncomponents/optimized-user.tsx\nimport { useStore } from \"better-auth/lynx\"\nimport { authClient } from \"../lib/auth-client\"\nexport function OptimizedUser() {\n    // Only re-render when specific keys change\n    const session = useStore(authClient.$store.session, {\n        keys: ['user.name', 'user.email'] // Only watch these specific keys\n    })\n    \n    return (\n        <div>\n            {session?.user && (\n                <div>\n                    <h2>{session.user.name}</h2>\n                    <p>{session.user.email}</p>\n                </div>\n            )}\n        </div>\n    )\n}\nPlugin Support\n\nThe Lynx client supports all Better Auth plugins:\n\nlib/auth-client.ts\nimport { createAuthClient } from \"better-auth/lynx\"\nimport { magicLinkClient } from \"better-auth/client/plugins\"\nconst authClient = createAuthClient({\n    plugins: [\n        magicLinkClient()\n    ]\n})\n// Use plugin methods\nawait authClient.signIn.magicLink({\n    email: \"test@email.com\"\n})\nError Handling\n\nError handling works the same as other Better Auth clients:\n\ncomponents/login-form.tsx\nimport { authClient } from \"../lib/auth-client\"\nexport function LoginForm() {\n    const signIn = async (email: string, password: string) => {\n        const { data, error } = await authClient.signIn.email({\n            email,\n            password\n        })\n        \n        if (error) {\n            console.error('Login failed:', error.message)\n            return\n        }\n        \n        console.log('Login successful:', data)\n    }\n    \n    return (\n        <form onSubmit={(e) => {\n            e.preventDefault()\n            const formData = new FormData(e.target)\n            signIn(formData.get('email'), formData.get('password'))\n        }}>\n            <input name=\"email\" type=\"email\" placeholder=\"Email\" />\n            <input name=\"password\" type=\"password\" placeholder=\"Password\" />\n            <button type=\"submit\">Sign In</button>\n        </form>\n    )\n}\nFeatures\n\nThe Lynx client provides:\n\nCross-Platform Support: Works across Android, iOS, and Web platforms\nOptimized Performance: Built specifically for Lynx's reactive system\nNanostores Integration: Uses nanostores for efficient state management\nSelective Re-rendering: Watch specific store keys to minimize unnecessary updates\nFull API Compatibility: All Better Auth methods and plugins work seamlessly\nTypeScript Support: Full type safety with TypeScript inference\n\nThe Lynx integration maintains all the features and benefits of Better Auth while providing optimal performance and developer experience within Lynx's cross-platform ecosystem.\n\nEdit on GitHub\n\nPrevious Page\n\nExpo\n\nNext Page\n\nAuthentication"
  },
  {
    "title": "Optimizing for Performance | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/optimizing-for-performance",
    "html": "Optimizing for Performance\nCopy Markdown\nOpen in\n\nIn this guide, we’ll go over some of the ways you can optimize your application for a more performant Better Auth app.\n\nCaching\n\nCaching is a powerful technique that can significantly improve the performance of your Better Auth application by reducing the number of database queries and speeding up response times.\n\nCookie Cache\n\nCalling your database every time useSession or getSession is invoked isn’t ideal, especially if sessions don’t change frequently. Cookie caching handles this by storing session data in a short-lived, signed cookie similar to how JWT access tokens are used with refresh tokens.\n\nTo turn on cookie caching, just set session.cookieCache in your auth config:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  session: {\n    cookieCache: {\n      enabled: true,\n      maxAge: 5 * 60, // Cache duration in seconds\n    },\n  },\n});\n\nRead more about cookie caching.\n\nFramework Caching\n\nHere are examples of how you can do caching in different frameworks and environments:\n\nNext\nRemix\nSolidStart\nReact Query\n\nSince Next v15, we can use the \"use cache\" directive to cache the response of a server function.\n\nexport async function getUsers() {\n    'use cache'\n    const { users } = await auth.api.listUsers();\n    return users\n}\n\nLearn more about NextJS use cache directive here.\n\nSSR Optimizations\n\nIf you're using a framework that supports server-side rendering, it's usually best to pre-fetch the user session on the server and use it as a fallback on the client.\n\nconst session = await auth.api.getSession({\n  headers: await headers(),\n});\n//then pass the session to the client\nDatabase optimizations\n\nOptimizing database performance is essential to get the best out of Better Auth.\n\nRecommended fields to index\nTable\tFields\tPlugin\nusers\temail\t\naccounts\tuserId\t\nsessions\tuserId, token\t\nverifications\tidentifier\t\ninvitations\temail, organizationId\torganization\nmembers\tuserId, organizationId\torganization\norganizations\tslug\torganization\npasskey\tuserId\tpasskey\ntwoFactor\tsecret\ttwoFactor\n\nWe intend to add indexing support in our schema generation tool in the future.\n\nEdit on GitHub\n\nPrevious Page\n\nSAML SSO with Okta\n\nNext Page\n\nOptions"
  },
  {
    "title": "Other Social Providers | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/other-social-providers",
    "html": "Other Social Providers\nCopy Markdown\nOpen in\n\nBetter Auth provides out of the box support for a Generic OAuth Plugin which allows you to use any social provider that implements the OAuth2 protocol or OpenID Connect (OIDC) flows.\n\nTo use a provider that is not supported out of the box, you can use the Generic OAuth Plugin.\n\nInstallation\nAdd the plugin to your auth config\n\nTo use the Generic OAuth plugin, add it to your auth config.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { genericOAuth } from \"better-auth/plugins\"\nexport const auth = betterAuth({\n    // ... other config options\n    plugins: [\n        genericOAuth({ \n            config: [ \n                { \n                    providerId: \"provider-id\", \n                    clientId: \"test-client-id\", \n                    clientSecret: \"test-client-secret\", \n                    discoveryUrl: \"https://auth.example.com/.well-known/openid-configuration\", \n                    // ... other config options\n                }, \n                // Add more providers as needed\n            ] \n        }) \n    ]\n})\nAdd the client plugin\n\nInclude the Generic OAuth client plugin in your authentication client instance.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nimport { genericOAuthClient } from \"better-auth/client/plugins\"\nconst authClient = createAuthClient({\n    plugins: [\n        genericOAuthClient()\n    ]\n})\n\nRead more about installation and usage of the Generic Oauth plugin here.\n\nExample usage\nInstagram Example\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { genericOAuth } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  // ... other config options\n  plugins: [\n    genericOAuth({\n      config: [\n        {\n          providerId: \"instagram\",\n          clientId: process.env.INSTAGRAM_CLIENT_ID as string,\n          clientSecret: process.env.INSTAGRAM_CLIENT_SECRET as string,\n          authorizationUrl: \"https://api.instagram.com/oauth/authorize\",\n          tokenUrl: \"https://api.instagram.com/oauth/access_token\",\n          scopes: [\"user_profile\", \"user_media\"],\n        },\n      ],\n    }),\n  ],\n});\nsign-in.ts\nconst response = await authClient.signIn.oauth2({\n  providerId: \"instagram\",\n  callbackURL: \"/dashboard\", // the path to redirect to after the user is authenticated\n});\nCoinbase Example\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { genericOAuth } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n  // ... other config options\n  plugins: [\n    genericOAuth({\n      config: [\n        {\n          providerId: \"coinbase\",\n          clientId: process.env.COINBASE_CLIENT_ID as string,\n          clientSecret: process.env.COINBASE_CLIENT_SECRET as string,\n          authorizationUrl: \"https://www.coinbase.com/oauth/authorize\",\n          tokenUrl: \"https://api.coinbase.com/oauth/token\",\n          scopes: [\"wallet:user:read\"], // and more...\n        },\n      ],\n    }),\n  ],\n});\nsign-in.ts\nconst response = await authClient.signIn.oauth2({\n  providerId: \"coinbase\",\n  callbackURL: \"/dashboard\", // the path to redirect to after the user is authenticated\n});\nEdit on GitHub\n\nPrevious Page\n\nOthers\n\nNext Page\n\nMySQL"
  },
  {
    "title": "Email & Password | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/email-password#forget-password",
    "html": "Email & Password\nCopy Markdown\nOpen in\n\nEmail and password authentication is a common method used by many applications. Better Auth provides a built-in email and password authenticator that you can easily integrate into your project.\n\nIf you prefer username-based authentication, check out the username plugin. It extends the email and password authenticator with username support.\n\nEnable Email and Password\n\nTo enable email and password authentication, you need to set the emailAndPassword.enabled option to true in the auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  emailAndPassword: { \n    enabled: true, \n  }, \n});\n\nIf it's not enabled, it'll not allow you to sign in or sign up with email and password.\n\nUsage\nSign Up\n\nTo sign a user up, you can use the signUp.email function provided by the client.\n\nClient\nServer\nPOST\n/sign-up/email\nconst { data, error } = await authClient.signUp.email({\n    name: \"John Doe\", // required\n    email: \"john.doe@example.com\", // required\n    password: \"password1234\", // required\n    image: \"https://example.com/image.png\",\n    callbackURL: \"https://example.com/callback\",\n});\nProp\tDescription\tType\nname\t\nThe name of the user.\n\tstring\nemail\t\nThe email address of the user.\n\tstring\npassword\t\nThe password of the user. It should be at least 8 characters long and max 128 by default.\n\tstring\nimage?\t\nAn optional profile image of the user.\n\tstring\ncallbackURL?\t\nAn optional URL to redirect to after the user signs up.\n\tstring\n\nThese are the default properties for the sign up email endpoint, however it's possible that with additional fields or special plugins you can pass more properties to the endpoint.\n\nSign In\n\nTo sign a user in, you can use the signIn.email function provided by the client.\n\nClient\nServer\nPOST\n/sign-in/email\nconst { data, error } = await authClient.signIn.email({\n    email: \"john.doe@example.com\", // required\n    password: \"password1234\", // required\n    rememberMe: true,\n    callbackURL: \"https://example.com/callback\",\n});\nProp\tDescription\tType\nemail\t\nThe email address of the user.\n\tstring\npassword\t\nThe password of the user. It should be at least 8 characters long and max 128 by default.\n\tstring\nrememberMe?\t\nIf false, the user will be signed out when the browser is closed. (optional) (default: true)\n\tboolean\ncallbackURL?\t\nAn optional URL to redirect to after the user signs in. (optional)\n\tstring\n\nThese are the default properties for the sign in email endpoint, however it's possible that with additional fields or special plugins you can pass different properties to the endpoint.\n\nSign Out\n\nTo sign a user out, you can use the signOut function provided by the client.\n\nClient\nServer\nPOST\n/sign-out\nawait authClient.signOut();\n\nyou can pass fetchOptions to redirect onSuccess\n\nauth-client.ts\nawait authClient.signOut({\n  fetchOptions: {\n    onSuccess: () => {\n      router.push(\"/login\"); // redirect to login page\n    },\n  },\n});\nEmail Verification\n\nTo enable email verification, you need to pass a function that sends a verification email with a link. The sendVerificationEmail function takes a data object with the following properties:\n\nuser: The user object.\nurl: The URL to send to the user which contains the token.\ntoken: A verification token used to complete the email verification.\n\nand a request object as the second parameter.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { sendEmail } from \"./email\"; // your email sending function\nexport const auth = betterAuth({\n  emailVerification: {\n    sendVerificationEmail: async ( { user, url, token }, request) => {\n      await sendEmail({\n        to: user.email,\n        subject: \"Verify your email address\",\n        text: `Click the link to verify your email: ${url}`,\n      });\n    },\n  },\n});\n\nOn the client side you can use sendVerificationEmail function to send verification link to user. This will trigger the sendVerificationEmail function you provided in the auth configuration.\n\nOnce the user clicks on the link in the email, if the token is valid, the user will be redirected to the URL provided in the callbackURL parameter. If the token is invalid, the user will be redirected to the URL provided in the callbackURL parameter with an error message in the query string ?error=invalid_token.\n\nRequire Email Verification\n\nIf you enable require email verification, users must verify their email before they can log in. And every time a user tries to sign in, sendVerificationEmail is called.\n\nThis only works if you have sendVerificationEmail implemented and if the user is trying to sign in with email and password.\n\nauth.ts\nexport const auth = betterAuth({\n  emailAndPassword: {\n    requireEmailVerification: true,\n  },\n});\n\nIf a user tries to sign in without verifying their email, you can handle the error and show a message to the user.\n\nauth-client.ts\nawait authClient.signIn.email(\n  {\n    email: \"email@example.com\",\n    password: \"password\",\n  },\n  {\n    onError: (ctx) => {\n      // Handle the error\n      if (ctx.error.status === 403) {\n        alert(\"Please verify your email address\");\n      }\n      //you can also show the original error message\n      alert(ctx.error.message);\n    },\n  }\n);\nTriggering manually Email Verification\n\nYou can trigger the email verification manually by calling the sendVerificationEmail function.\n\nawait authClient.sendVerificationEmail({\n  email: \"user@email.com\",\n  callbackURL: \"/\", // The redirect URL after verification\n});\nRequest Password Reset\n\nTo allow users to reset a password first you need to provide sendResetPassword function to the email and password authenticator. The sendResetPassword function takes a data object with the following properties:\n\nuser: The user object.\nurl: The URL to send to the user which contains the token.\ntoken: A verification token used to complete the password reset.\n\nand a request object as the second parameter.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport { sendEmail } from \"./email\"; // your email sending function\nexport const auth = betterAuth({\n  emailAndPassword: {\n    enabled: true,\n    sendResetPassword: async ({user, url, token}, request) => {\n      await sendEmail({\n        to: user.email,\n        subject: \"Reset your password\",\n        text: `Click the link to reset your password: ${url}`,\n      });\n    },\n    onPasswordReset: async ({ user }, request) => {\n      // your logic here\n      console.log(`Password for user ${user.email} has been reset.`);\n    },\n  },\n});\n\nAdditionally, you can provide an onPasswordReset callback to execute logic after a password has been successfully reset.\n\nOnce you configured your server you can call requestPasswordReset function to send reset password link to user. If the user exists, it will trigger the sendResetPassword function you provided in the auth config.\n\nClient\nServer\nPOST\n/request-password-reset\nconst { data, error } = await authClient.requestPasswordReset({\n    email: \"john.doe@example.com\", // required\n    redirectTo: \"https://example.com/reset-password\",\n});\nProp\tDescription\tType\nemail\t\nThe email address of the user to send a password reset email to\n\tstring\nredirectTo?\t\nThe URL to redirect the user to reset their password. If the token isn't valid or expired, it'll be redirected with a query parameter ?error=INVALID_TOKEN. If the token is valid, it'll be redirected with a query parameter `?token=VALID_TOKEN\n\tstring\n\nWhen a user clicks on the link in the email, they will be redirected to the reset password page. You can add the reset password page to your app. Then you can use resetPassword function to reset the password. It takes an object with the following properties:\n\nnewPassword: The new password of the user.\nauth-client.ts\nconst { data, error } = await authClient.resetPassword({\n  newPassword: \"password1234\",\n  token,\n});\nClient\nServer\nPOST\n/reset-password\nconst token = new URLSearchParams(window.location.search).get(\"token\");\nif (!token) {\n  // Handle the error\n}\nconst { data, error } = await authClient.resetPassword({\n    newPassword: \"password1234\", // required\n    token, // required\n});\nProp\tDescription\tType\nnewPassword\t\nThe new password to set\n\tstring\ntoken\t\nThe token to reset the password\n\tstring\nUpdate password\n\nA user's password isn't stored in the user table. Instead, it's stored in the account table. To change the password of a user, you can use one of the following approaches:\n\nClient\nServer\nPOST\n/change-password\nconst { data, error } = await authClient.changePassword({\n    newPassword: \"newpassword1234\", // required\n    currentPassword: \"oldpassword1234\", // required\n    revokeOtherSessions: true,\n});\nProp\tDescription\tType\nnewPassword\t\nThe new password to set\n\tstring\ncurrentPassword\t\nThe current user password\n\tstring\nrevokeOtherSessions?\t\nWhen set to true, all other active sessions for this user will be invalidated\n\tboolean\nConfiguration\n\nPassword\n\nBetter Auth stores passwords inside the account table with providerId set to credential.\n\nPassword Hashing: Better Auth uses scrypt to hash passwords. The scrypt algorithm is designed to be slow and memory-intensive to make it difficult for attackers to brute force passwords. OWASP recommends using scrypt if argon2id is not available. We decided to use scrypt because it's natively supported by Node.js.\n\nYou can pass custom password hashing algorithm by setting passwordHasher option in the auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nimport { scrypt } from \"scrypt\"\nexport const auth = betterAuth({\n    //...rest of the options\n    emailAndPassword: {\n        password: {\n            hash: // your custom password hashing function\n            verify: // your custom password verification function\n        }\n    }\n})\n\nProp\n\nType\n\nenabled?\nboolean\ndisableSignUp?\nboolean\nminPasswordLength?\nnumber\nmaxPasswordLength?\nnumber\nsendResetPassword?\nfunction\nonPasswordReset?\nfunction\nresetPasswordTokenExpiresIn?\nnumber\npassword?\nobject\nEdit on GitHub\n\nPrevious Page\n\nUsers & Accounts\n\nNext Page\n\nSocial Sign-On"
  },
  {
    "title": "SAML SSO with Okta | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/saml-sso-with-okta",
    "html": "SAML SSO with Okta\nCopy Markdown\nOpen in\n\nThis guide walks you through setting up SAML Single Sign-On (SSO) with your Identity Provider (IdP), using Okta as an example. For advanced configuration details and the full API reference, check out the SSO Plugin Documentation.\n\nWhat is SAML?\n\nSAML (Security Assertion Markup Language) is an XML-based standard for exchanging authentication and authorization data between an Identity Provider (IdP) (e.g., Okta, Azure AD, OneLogin) and a Service Provider (SP) (in this case, Better Auth).\n\nIn this setup:\n\nIdP (Okta): Authenticates users and sends assertions about their identity.\nSP (Better Auth): Validates assertions and logs the user in.up.\nStep 1: Create a SAML Application in Okta\n\nLog in to your Okta Admin Console\n\nNavigate to Applications > Applications\n\nClick \"Create App Integration\"\n\nSelect \"SAML 2.0\" as the Sign-in method\n\nConfigure the following settings:\n\nSingle Sign-on URL: Your Better Auth ACS endpoint (e.g., http://localhost:3000/api/auth/sso/saml2/sp/acs/sso). while sso being your providerId\nAudience URI (SP Entity ID): Your Better Auth metadata URL (e.g., http://localhost:3000/api/auth/sso/saml2/sp/metadata)\nName ID format: Email Address or any of your choice.\n\nDownload the IdP metadata XML file and certificate\n\nStep 2: Configure Better Auth\n\nHere’s an example configuration for Okta in a dev environment:\n\nconst ssoConfig = {\n  defaultSSO: [{\n    domain: \"localhost:3000\", // Your domain\n    providerId: \"sso\",\n    samlConfig: {\n      // SP Configuration\n      issuer: \"http://localhost:3000/api/auth/sso/saml2/sp/metadata\",\n      entryPoint: \"https://trial-1076874.okta.com/app/trial-1076874_samltest_1/exktofb0a62hqLAUL697/sso/saml\",\n      callbackUrl: \"/dashboard\", // Redirect after successful authentication\n      \n      // IdP Configuration\n      idpMetadata: {\n        entityID: \"https://trial-1076874.okta.com/app/exktofb0a62hqLAUL697/sso/saml/metadata\",\n        singleSignOnService: [{\n          Binding: \"urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect\",\n          Location: \"https://trial-1076874.okta.com/app/trial-1076874_samltest_1/exktofb0a62hqLAUL697/sso/saml\"\n        }],\n        cert: `-----BEGIN CERTIFICATE-----\nMIIDqjCCApKgAwIBAgIGAZhVGMeUMA0GCSqGSIb3DQEBCwUAMIGVMQswCQYDVQQGEwJVUzETMBEG\n...\n[Your Okta Certificate]\n...\n-----END CERTIFICATE-----`\n      },\n      \n      // SP Metadata\n      spMetadata: {\n        metadata: `<md:EntityDescriptor xmlns:md=\"urn:oasis:names:tc:SAML:2.0:metadata\" \n          entityID=\"http://localhost:3000/api/sso/saml2/sp/metadata\">\n          ...\n          [Your SP Metadata XML]\n          ...\n        </md:EntityDescriptor>`\n      }\n    }\n  }]\n}\nStep 3: Multiple Default Providers (Optional)\n\nYou can configure multiple SAML providers for different domains:\n\nconst ssoConfig = {\n  defaultSSO: [\n    {\n      domain: \"company.com\",\n      providerId: \"company-okta\",\n      samlConfig: {\n        // Okta SAML configuration for company.com\n      }\n    },\n    {\n      domain: \"partner.com\", \n      providerId: \"partner-adfs\",\n      samlConfig: {\n        // ADFS SAML configuration for partner.com\n      }\n    },\n    {\n      domain: \"contractor.org\",\n      providerId: \"contractor-azure\",\n      samlConfig: {\n        // Azure AD SAML configuration for contractor.org\n      }\n    }\n  ]\n}\n\nExplicit: Pass providerId directly when signing in. Domain fallback: Matches based on the user’s email domain. e.g. user@company.com → matches company-okta provider.\n\nStep 4: Initiating Sign-In\n\nYou can start an SSO flow in three ways:\n\n1. Explicitly by providerId (recommended):\n\n// Explicitly specify which provider to use\nawait authClient.signIn.sso({\n  providerId: \"company-okta\",\n  callbackURL: \"/dashboard\"\n});\n\n2. By email domain matching:\n\n// Automatically matches provider based on email domain\nawait authClient.signIn.sso({\n  email: \"user@company.com\",\n  callbackURL: \"/dashboard\"\n});\n\n3. By specifying domain:\n\n// Explicitly specify domain for matching\nawait authClient.signIn.sso({\n  domain: \"partner.com\",\n  callbackURL: \"/dashboard\"\n});\n\nImportant Notes:\n\nDummyIDP should ONLY be used for development and testing\nNever use these certificates in production\nThe example uses localhost:3000 - adjust URLs for your environment\nFor production, always use proper IdP providers like Okta, Azure AD, or OneLogin\nStep 5: Dynamically Registering SAML Providers\n\nFor dynamic registration, you should register SAML providers using the API. See the SSO Plugin Documentation for detailed registration instructions.\n\nExample registration:\n\nawait authClient.sso.register({\n  providerId: \"okta-prod\",\n  issuer: \"https://your-domain.com\",\n  domain: \"your-domain.com\",\n  samlConfig: {\n    // Your production SAML configuration\n  }\n});\nAdditional Resources\nSSO Plugin Documentation\nOkta SAML Documentation\nSAML 2.0 Specification\nEdit on GitHub\n\nPrevious Page\n\nBrowser Extension Guide\n\nNext Page\n\nOptimize for Performance"
  },
  {
    "title": "Migrating from NextAuth.js to Better Auth | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/next-auth-migration-guide",
    "html": "Migrating from NextAuth.js to Better Auth\nCopy Markdown\nOpen in\n\nIn this guide, we’ll walk through the steps to migrate a project from NextAuth.js to Better Auth, ensuring no loss of data or functionality. While this guide focuses on Next.js, it can be adapted for other frameworks as well.\n\nBefore You Begin\n\nBefore starting the migration process, set up Better Auth in your project. Follow the installation guide to get started.\n\nMapping Existing Columns\n\nInstead of altering your existing database column names, you can map them to match Better Auth's expected structure. This allows you to retain your current database schema.\n\nUser Schema\n\nMap the following fields in the user schema:\n\n(next-auth v4) emailVerified: datetime → boolean\nSession Schema\n\nMap the following fields in the session schema:\n\nexpires → expiresAt\nsessionToken → token\n(next-auth v4) add createdAt with datetime type\n(next-auth v4) add updatedAt with datetime type\nauth.ts\nexport const auth = betterAuth({\n    // Other configs\n    session: {\n        fields: {\n            expiresAt: \"expires\", // Map your existing `expires` field to Better Auth's `expiresAt`\n            token: \"sessionToken\" // Map your existing `sessionToken` field to Better Auth's `token`\n        }\n    },\n});\n\nMake sure to have createdAt and updatedAt fields on your session schema.\n\nAccount Schema\n\nMap these fields in the account schema:\n\n(next-auth v4) provider → providerId\nproviderAccountId → accountId\nrefresh_token → refreshToken\naccess_token → accessToken\n(next-auth v3) access_token_expires → accessTokenExpiresAt and int → datetime\n(next-auth v4) expires_at → accessTokenExpiresAt and int → datetime\nid_token → idToken\n(next-auth v4) add createdAt with datetime type\n(next-auth v4) add updatedAt with datetime type\n\nRemove the session_state, type, and token_type fields, as they are not required by Better Auth.\n\nauth.ts\nexport const auth = betterAuth({\n    // Other configs\n    account: {\n        fields: {\n            accountId: \"providerAccountId\",\n            refreshToken: \"refresh_token\",\n            accessToken: \"access_token\",\n            accessTokenExpiresAt: \"access_token_expires\",\n            idToken: \"id_token\",\n        }\n    },\n});\n\nNote: If you use ORM adapters, you can map these fields in your schema file.\n\nExample with Prisma:\n\nschema.prisma\nmodel Session {\n    id          String   @id @default(cuid())\n    expiresAt   DateTime @map(\"expires\") // Map your existing `expires` field to Better Auth's `expiresAt`\n    token       String   @map(\"sessionToken\") // Map your existing `sessionToken` field to Better Auth's `token`\n    userId      String\n    user        User     @relation(fields: [userId], references: [id])\n}\n\nMake sure to have createdAt and updatedAt fields on your account schema.\n\nUpdate the Route Handler\n\nIn the app/api/auth folder, rename the [...nextauth] file to [...all] to avoid confusion. Then, update the route.ts file as follows:\n\napp/api/auth/[...all]/route.ts\nimport { toNextJsHandler } from \"better-auth/next-js\";\nimport { auth } from \"~/server/auth\";\nexport const { POST, GET } = toNextJsHandler(auth);\nUpdate the Client\n\nCreate a file named auth-client.ts in the lib folder. Add the following code:\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/react\";\nexport const authClient = createAuthClient({\n    baseURL: process.env.BASE_URL! // Optional if the API base URL matches the frontend\n});\nexport const { signIn, signOut, useSession } = authClient;\nSocial Login Functions\n\nUpdate your social login functions to use Better Auth. For example, for Discord:\n\nimport { signIn } from \"~/lib/auth-client\";\nexport const signInDiscord = async () => {\n    const data = await signIn.social({\n        provider: \"discord\"\n    });\n    return data;\n};\nUpdate useSession Calls\n\nReplace useSession calls with Better Auth’s version. Example:\n\nProfile.tsx\nimport { useSession } from \"~/lib/auth-client\";\nexport const Profile = () => {\n    const { data } = useSession();\n    return (\n        <div>\n            <pre>\n                {JSON.stringify(data, null, 2)}\n            </pre>\n        </div>\n    );\n};\nServer-Side Session Handling\n\nUse the auth instance to get session data on the server:\n\nactions.ts\n\"use server\";\nimport { auth } from \"~/server/auth\";\nimport { headers } from \"next/headers\";\nexport const protectedAction = async () => {\n    const session = await auth.api.getSession({\n        headers: await headers(),\n    });\n};\nMiddleware\n\nTo protect routes with middleware, refer to the Next.js middleware guide.\n\nWrapping Up\n\nCongratulations! You’ve successfully migrated from NextAuth.js to Better Auth. For a complete implementation with multiple authentication methods, check out the demo repository.\n\nBetter Auth offers greater flexibility and more features—be sure to explore the documentation to unlock its full potential.\n\nEdit on GitHub\n\nPrevious Page\n\nGuides\n\nNext Page\n\nSupabase Migration Guide"
  },
  {
    "title": "Migrating from Supabase Auth to Better Auth | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/supabase-migration-guide",
    "html": "Migrating from Supabase Auth to Better Auth\nCopy Markdown\nOpen in\n\nIn this guide, we'll walk through the steps to migrate a project from Supabase Auth to Better Auth.\n\nThis migration will invalidate all active sessions. While this guide doesn't currently cover migrating two-factor (2FA) or Row Level Security (RLS) configurations, both should be possible with additional steps.\n\nBefore You Begin\n\nBefore starting the migration process, set up Better Auth in your project. Follow the installation guide to get started.\n\nConnect to your database\n\nYou'll need to connect to your database to migrate the users and accounts. Copy your DATABASE_URL from your Supabase project and use it to connect to your database. And for this example, we'll need to install pg to connect to the database.\n\nnpm\npnpm\nyarn\nbun\nnpm install pg\n\nAnd then you can use the following code to connect to your database.\n\nauth.ts\nimport { Pool } from \"pg\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n})\nEnable Email and Password (Optional)\n\nEnable the email and password in your auth config.\n\nauth.ts\nimport { admin, anonymous } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n\temailVerification: {\n\t\tsendEmailVerification: async(user)=>{\n\t\t\t// send email verification email\n\t\t\t// implement your own logic here\n\t\t}\n\t},\n    emailAndPassword: { \n        enabled: true, \n    } \n})\nSetup Social Providers (Optional)\n\nAdd social providers you have enabled in your Supabase project in your auth config.\n\nauth.ts\nimport { admin, anonymous } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true,\n    },\n    socialProviders: { \n        github: { \n            clientId: process.env.GITHUB_CLIENT_ID, \n            clientSecret: process.env.GITHUB_CLIENT_SECRET, \n        } \n    } \n})\nAdd admin and anonymous plugins (Optional)\n\nAdd the admin and anonymous plugins to your auth config.\n\nauth.ts\nimport { admin, anonymous } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true,\n    },\n    socialProviders: {\n        github: {\n            clientId: process.env.GITHUB_CLIENT_ID!,\n            clientSecret: process.env.GITHUB_CLIENT_SECRET!,\n        }\n    },\n    plugins: [admin(), anonymous()], \n})\nRun the migration\n\nRun the migration to create the necessary tables in your database.\n\nTerminal\nnpx @better-auth/cli migrate\n\nThis will create the following tables in your database:\n\nuser\naccount\nsession\nverification\n\nThis tables will be created on the public schema.\n\nCopy the migration script\n\nNow that we have the necessary tables in our database, we can run the migration script to migrate the users and accounts from Supabase to Better Auth.\n\nStart by creating a .ts file in your project.\n\nTerminal\ntouch migration.ts\n\nAnd then copy and paste the following code into the file.\n\nmigration.ts\nimport { Pool } from \"pg\";\nimport { auth } from \"./auth\";\nimport { User as SupabaseUser } from \"@supabase/supabase-js\";\ntype User = SupabaseUser & {\n\tis_super_admin: boolean;\n\traw_user_meta_data: {\n\t\tavatar_url: string;\n\t};\n\tencrypted_password: string;\n\temail_confirmed_at: string;\n\tcreated_at: string;\n\tupdated_at: string;\n\tis_anonymous: boolean;\n\tidentities: {\n\t\tprovider: string;\n\t\tidentity_data: {\n\t\t\tsub: string;\n\t\t\temail: string;\n\t\t};\n\t\tcreated_at: string;\n\t\tupdated_at: string;\n\t};\n};\nconst migrateFromSupabase = async () => {\n\tconst ctx = await auth.$context;\n\tconst db = ctx.options.database as Pool;\n\tconst users = await db\n\t\t.query(`\n\t\t\tSELECT \n\t\t\t\tu.*,\n\t\t\t\tCOALESCE(\n\t\t\t\t\tjson_agg(\n\t\t\t\t\t\ti.* ORDER BY i.id\n\t\t\t\t\t) FILTER (WHERE i.id IS NOT NULL),\n\t\t\t\t\t'[]'::json\n\t\t\t\t) as identities\n\t\t\tFROM auth.users u\n\t\t\tLEFT JOIN auth.identities i ON u.id = i.user_id\n\t\t\tGROUP BY u.id\n\t\t`)\n\t\t.then((res) => res.rows as User[]);\n\tfor (const user of users) {\n\t\tif (!user.email) {\n\t\t\tcontinue;\n\t\t}\n\t\tawait ctx.adapter\n\t\t\t.create({\n\t\t\t\tmodel: \"user\",\n\t\t\t\tdata: {\n\t\t\t\t\tid: user.id,\n\t\t\t\t\temail: user.email,\n\t\t\t\t\tname: user.email,\n\t\t\t\t\trole: user.is_super_admin ? \"admin\" : user.role,\n\t\t\t\t\temailVerified: !!user.email_confirmed_at,\n\t\t\t\t\timage: user.raw_user_meta_data.avatar_url,\n\t\t\t\t\tcreatedAt: new Date(user.created_at),\n\t\t\t\t\tupdatedAt: new Date(user.updated_at),\n\t\t\t\t\tisAnonymous: user.is_anonymous,\n\t\t\t\t},\n\t\t\t})\n\t\t\t.catch(() => {});\n\t\tfor (const identity of user.identities) {\n\t\t\tconst existingAccounts = await ctx.internalAdapter.findAccounts(user.id);\n\t\t\tif (identity.provider === \"email\") {\n\t\t\t\tconst hasCredential = existingAccounts.find(\n\t\t\t\t\t(account) => account.providerId === \"credential\",\n\t\t\t\t);\n\t\t\t\tif (!hasCredential) {\n\t\t\t\t\tawait ctx.adapter\n\t\t\t\t\t\t.create({\n\t\t\t\t\t\t\tmodel: \"account\",\n\t\t\t\t\t\t\tdata: {\n\t\t\t\t\t\t\t\tuserId: user.id,\n\t\t\t\t\t\t\t\tproviderId: \"credential\",\n\t\t\t\t\t\t\t\taccountId: user.id,\n\t\t\t\t\t\t\t\tpassword: user.encrypted_password,\n\t\t\t\t\t\t\t\tcreatedAt: new Date(user.created_at),\n\t\t\t\t\t\t\t\tupdatedAt: new Date(user.updated_at),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t})\n\t\t\t\t\t\t.catch(() => {});\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst supportedProviders = Object.keys(ctx.options.socialProviders || {})\n\t\t\tif (supportedProviders.includes(identity.provider)) {\n\t\t\t\tconst hasAccount = existingAccounts.find(\n\t\t\t\t\t(account) => account.providerId === identity.provider,\n\t\t\t\t);\n\t\t\t\tif (!hasAccount) {\n\t\t\t\t\tawait ctx.adapter.create({\n\t\t\t\t\t\tmodel: \"account\",\n\t\t\t\t\t\tdata: {\n\t\t\t\t\t\t\tuserId: user.id,\n\t\t\t\t\t\t\tproviderId: identity.provider,\n\t\t\t\t\t\t\taccountId: identity.identity_data?.sub,\n\t\t\t\t\t\t\tcreatedAt: new Date(identity.created_at ?? user.created_at),\n\t\t\t\t\t\t\tupdatedAt: new Date(identity.updated_at ?? user.updated_at),\n\t\t\t\t\t\t},\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n};\nmigrateFromSupabase();\nCustomize the migration script (Optional)\nname: the migration script will use the user's email as the name. You might want to customize it if you have the user display name in your database.\nsocialProviderList: the migration script will use the social providers you have enabled in your auth config. You might want to customize it if you have additional social providers that you haven't enabled in your auth config.\nrole: remove role if you're not using the admin plugin\nisAnonymous: remove isAnonymous if you're not using the anonymous plugin.\nupdate other tables that reference the users table to use the id field.\nRun the migration script\n\nRun the migration script to migrate the users and accounts from Supabase to Better Auth.\n\nTerminal\nbun migration.ts # or use node, ts-node, etc.\nChange password hashing algorithm\n\nBy default, Better Auth uses the scrypt algorithm to hash passwords. Since Supabase uses bcrypt, you'll need to configure Better Auth to use bcrypt for password verification.\n\nFirst, install bcrypt:\n\nnpm install bcrypt\nnpm install -D @types/bcrypt\n\nThen update your auth configuration:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport bcrypt from \"bcrypt\";\nexport const auth = betterAuth({\n   emailAndPassword: {\n       password: {\n           hash: async (password) => {\n               return await bcrypt.hash(password, 10);\n           },\n           verify: async ({ hash, password }) => {\n               return await bcrypt.compare(password, hash);\n           }\n       }\n   }\n})\nUpdate your code\n\nUpdate your codebase from Supabase auth calls to Better Auth API.\n\nHere's a list of the Supabase auth API calls and their Better Auth counterparts.\n\nsupabase.auth.signUp -> authClient.signUp.email\nsupabase.auth.signInWithPassword -> authClient.signIn.email\nsupabase.auth.signInWithOAuth -> authClient.signIn.social\nsupabase.auth.signInAnonymously -> authClient.signIn.anonymous\nsupabase.auth.signOut -> authClient.signOut\nsupabase.auth.getSession -> authClient.getSession - you can also use authClient.useSession for reactive state\n\nLearn more:\n\nBasic Usage: Learn how to use the auth client to sign up, sign in, and sign out.\nEmail and Password: Learn how to add email and password authentication to your project.\nAnonymous: Learn how to add anonymous authentication to your project.\nAdmin: Learn how to add admin authentication to your project.\nEmail OTP: Learn how to add email OTP authentication to your project.\nHooks: Learn how to use the hooks to listen for events.\nNext.js: Learn how to use the auth client in a Next.js project.\nMiddleware\n\nTo protect routes with middleware, refer to the Next.js middleware guide or your framework's documentation.\n\nWrapping Up\n\nCongratulations! You've successfully migrated from Supabase Auth to Better Auth.\n\nBetter Auth offers greater flexibility and more features—be sure to explore the documentation to unlock its full potential.\n\nEdit on GitHub\n\nPrevious Page\n\nNext Auth Migration Guide\n\nNext Page\n\nClerk Migration Guide"
  },
  {
    "title": "Migrating from Clerk to Better Auth | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/clerk-migration-guide",
    "html": "Migrating from Clerk to Better Auth\nCopy Markdown\nOpen in\n\nIn this guide, we'll walk through the steps to migrate a project from Clerk to Better Auth — including email/password with proper hashing, social/external accounts, phone number, two-factor data, and more.\n\nThis migration will invalidate all active sessions. This guide doesn't currently show you how to migrate Organization but it should be possible with additional steps and the Organization Plugin.\n\nBefore You Begin\n\nBefore starting the migration process, set up Better Auth in your project. Follow the installation guide to get started. And go to\n\nConnect to your database\n\nYou'll need to connect to your database to migrate the users and accounts. You can use any database you want, but for this example, we'll use PostgreSQL.\n\nnpm\npnpm\nyarn\nbun\nnpm install pg\n\nAnd then you can use the following code to connect to your database.\n\nauth.ts\nimport { Pool } from \"pg\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n})\nEnable Email and Password (Optional)\n\nEnable the email and password in your auth config and implement your own logic for sending verification emails, reset password emails, etc.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true, \n    }, \n    emailVerification: {\n      sendVerificationEmail: async({ user, url })=>{\n        // implement your logic here to send email verification\n      }\n\t},\n})\n\nSee Email and Password for more configuration options.\n\nSetup Social Providers (Optional)\n\nAdd social providers you have enabled in your Clerk project in your auth config.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true,\n    },\n    socialProviders: { \n        github: { \n            clientId: process.env.GITHUB_CLIENT_ID, \n            clientSecret: process.env.GITHUB_CLIENT_SECRET, \n        } \n    } \n})\nAdd Plugins (Optional)\n\nYou can add the following plugins to your auth config based on your needs.\n\nAdmin Plugin will allow you to manage users, user impersonations and app level roles and permissions.\n\nTwo Factor Plugin will allow you to add two-factor authentication to your application.\n\nPhone Number Plugin will allow you to add phone number authentication to your application.\n\nUsername Plugin will allow you to add username authentication to your application.\n\nauth.ts\nimport { Pool } from \"pg\";\nimport { betterAuth } from \"better-auth\";\nimport { admin, twoFactor, phoneNumber, username } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true,\n    },\n    socialProviders: {\n        github: {\n            clientId: process.env.GITHUB_CLIENT_ID!,\n            clientSecret: process.env.GITHUB_CLIENT_SECRET!,\n        }\n    },\n    plugins: [admin(), twoFactor(), phoneNumber(), username()], \n})\nGenerate Schema\n\nIf you're using a custom database adapter, generate the schema:\n\nnpx @better-auth/cli generate\n\nor if you're using the default adapter, you can use the following command:\n\nnpx @better-auth/cli migrate\nExport Clerk Users\n\nGo to the Clerk dashboard and export the users. Check how to do it here. It will download a CSV file with the users data. You need to save it as exported_users.csv and put it in the root of your project.\n\nCreate the migration script\n\nCreate a new file called migrate-clerk.ts in the scripts folder and add the following code:\n\nscripts/migrate-clerk.ts\nimport { generateRandomString, symmetricEncrypt } from \"better-auth/crypto\";\nimport { auth } from \"@/lib/auth\"; // import your auth instance\nfunction getCSVData(csv: string) {\n  const lines = csv.split('\\n').filter(line => line.trim());\n  const headers = lines[0]?.split(',').map(header => header.trim()) || [];\n  const jsonData = lines.slice(1).map(line => {\n      const values = line.split(',').map(value => value.trim());\n      return headers.reduce((obj, header, index) => {\n          obj[header] = values[index] || '';\n          return obj;\n      }, {} as Record<string, string>);\n  });\n  return jsonData as Array<{\n      id: string;\n      first_name: string;\n      last_name: string;\n      username: string;\n      primary_email_address: string;\n      primary_phone_number: string;\n      verified_email_addresses: string;\n      unverified_email_addresses: string;\n      verified_phone_numbers: string;\n      unverified_phone_numbers: string;\n      totp_secret: string;\n      password_digest: string;\n      password_hasher: string;\n  }>;\n}\nconst exportedUserCSV = await Bun.file(\"exported_users.csv\").text(); // this is the file you downloaded from Clerk\nasync function getClerkUsers(totalUsers: number) {\n  const clerkUsers: {\n      id: string;\n      first_name: string;\n      last_name: string;\n      username: string;\n      image_url: string;\n      password_enabled: boolean;\n      two_factor_enabled: boolean;\n      totp_enabled: boolean;\n      backup_code_enabled: boolean;\n      banned: boolean;\n      locked: boolean;\n      lockout_expires_in_seconds: number;\n      created_at: number;\n      updated_at: number;\n      external_accounts: {\n          id: string;\n          provider: string;\n          identification_id: string;\n          provider_user_id: string;\n          approved_scopes: string;\n          email_address: string;\n          first_name: string;\n          last_name: string;\n          image_url: string;\n          created_at: number;\n          updated_at: number;\n      }[]\n  }[] = [];\n  for (let i = 0; i < totalUsers; i += 500) {\n      const response = await fetch(`https://api.clerk.com/v1/users?offset=${i}&limit=${500}`, {\n          headers: {\n              'Authorization': `Bearer ${process.env.CLERK_SECRET_KEY}`\n          }\n      });\n      if (!response.ok) {\n          throw new Error(`Failed to fetch users: ${response.statusText}`);\n      }\n      const clerkUsersData = await response.json();\n      // biome-ignore lint/suspicious/noExplicitAny: <explanation>\n      clerkUsers.push(...clerkUsersData as any);\n  }\n  return clerkUsers;\n}\nexport async function generateBackupCodes(\n  secret: string,\n) {\n  const key = secret;\n  const backupCodes = Array.from({ length: 10 })\n      .fill(null)\n      .map(() => generateRandomString(10, \"a-z\", \"0-9\", \"A-Z\"))\n      .map((code) => `${code.slice(0, 5)}-${code.slice(5)}`);\n  const encCodes = await symmetricEncrypt({\n      data: JSON.stringify(backupCodes),\n      key: key,\n  });\n  return encCodes\n}\n// Helper function to safely convert timestamp to Date\nfunction safeDateConversion(timestamp?: number): Date {\n  if (!timestamp) return new Date();\n  // Convert seconds to milliseconds\n  const date = new Date(timestamp * 1000);\n  // Check if the date is valid\n  if (isNaN(date.getTime())) {\n      console.warn(`Invalid timestamp: ${timestamp}, falling back to current date`);\n      return new Date();\n  }\n  // Check for unreasonable dates (before 2000 or after 2100)\n  const year = date.getFullYear();\n  if (year < 2000 || year > 2100) {\n      console.warn(`Suspicious date year: ${year}, falling back to current date`);\n      return new Date();\n  }\n  return date;\n}\nasync function migrateFromClerk() {\n  const jsonData = getCSVData(exportedUserCSV);\n  const clerkUsers = await getClerkUsers(jsonData.length);\n  const ctx = await auth.$context\n  const isAdminEnabled = ctx.options?.plugins?.find(plugin => plugin.id === \"admin\");\n  const isTwoFactorEnabled = ctx.options?.plugins?.find(plugin => plugin.id === \"two-factor\");\n  const isUsernameEnabled = ctx.options?.plugins?.find(plugin => plugin.id === \"username\");\n  const isPhoneNumberEnabled = ctx.options?.plugins?.find(plugin => plugin.id === \"phone-number\");\n  for (const user of jsonData) {\n      const { id, first_name, last_name, username, primary_email_address, primary_phone_number, verified_email_addresses, unverified_email_addresses, verified_phone_numbers, unverified_phone_numbers, totp_secret, password_digest, password_hasher } = user;\n      const clerkUser = clerkUsers.find(clerkUser => clerkUser?.id === id);\n      // create user\n      const createdUser = await ctx.adapter.create<{\n          id: string;\n      }>({\n          model: \"user\",\n          data: {\n              id,\n              email: primary_email_address,\n              emailVerified: verified_email_addresses.length > 0,\n              name: `${first_name} ${last_name}`,\n              image: clerkUser?.image_url,\n              createdAt: safeDateConversion(clerkUser?.created_at),\n              updatedAt: safeDateConversion(clerkUser?.updated_at),\n              // # Two Factor (if you enabled two factor plugin)\n              ...(isTwoFactorEnabled ? {\n                  twoFactorEnabled: clerkUser?.two_factor_enabled\n              } : {}),\n              // # Admin (if you enabled admin plugin)\n              ...(isAdminEnabled ? {\n                  banned: clerkUser?.banned,\n                  banExpiresAt: clerkUser?.lockout_expires_in_seconds,\n                  role: \"user\"\n              } : {}),\n              // # Username (if you enabled username plugin)\n              ...(isUsernameEnabled ? {\n                  username: username,\n              } : {}),\n              // # Phone Number (if you enabled phone number plugin)  \n              ...(isPhoneNumberEnabled ? {\n                  phoneNumber: primary_phone_number,\n                  phoneNumberVerified: verified_phone_numbers.length > 0,\n              } : {}),\n          },\n          forceAllowId: true\n      }).catch(async e => {\n          return await ctx.adapter.findOne<{\n              id: string;\n          }>({\n              model: \"user\",\n              where: [{\n                  field: \"id\",\n                  value: id\n              }]\n          })\n      })\n      // create external account\n      const externalAccounts = clerkUser?.external_accounts;\n      if (externalAccounts) {\n          for (const externalAccount of externalAccounts) {\n              const { id, provider, identification_id, provider_user_id, approved_scopes, email_address, first_name, last_name, image_url, created_at, updated_at } = externalAccount;\n              if (externalAccount.provider === \"credential\") {\n                  await ctx.adapter.create({\n                      model: \"account\",\n                      data: {\n                          id,\n                          providerId: provider,\n                          accountId: externalAccount.provider_user_id,\n                          scope: approved_scopes,\n                          userId: createdUser?.id,\n                          createdAt: safeDateConversion(created_at),\n                          updatedAt: safeDateConversion(updated_at),\n                          password: password_digest,\n                      }\n                  })\n              } else {\n                  await ctx.adapter.create({\n                      model: \"account\",\n                      data: {\n                          id,\n                          providerId: provider.replace(\"oauth_\", \"\"),\n                          accountId: externalAccount.provider_user_id,\n                          scope: approved_scopes,\n                          userId: createdUser?.id,\n                          createdAt: safeDateConversion(created_at),\n                          updatedAt: safeDateConversion(updated_at),\n                      },\n                      forceAllowId: true\n                  })\n              }\n          }\n      }\n      //two factor\n      if (isTwoFactorEnabled) {\n          await ctx.adapter.create({\n              model: \"twoFactor\",\n              data: {\n                  userId: createdUser?.id,\n                  secret: totp_secret,\n                  backupCodes: await generateBackupCodes(totp_secret)\n              }\n          })\n      }\n  }\n}\nmigrateFromClerk()\n  .then(() => {\n      console.log('Migration completed');\n      process.exit(0);\n  })\n  .catch((error) => {\n      console.error('Migration failed:', error);\n      process.exit(1);\n  });\n\nMake sure to replace the process.env.CLERK_SECRET_KEY with your own Clerk secret key. Feel free to customize the script to your needs.\n\nRun the migration\n\nRun the migration:\n\nbun run script/migrate-clerk.ts # you can use any thing you like to run the script\n\nMake sure to:\n\nTest the migration in a development environment first\nMonitor the migration process for any errors\nVerify the migrated data in Better Auth before proceeding\nKeep Clerk installed and configured until the migration is complete\nVerify the migration\n\nAfter running the migration, verify that all users have been properly migrated by checking the database.\n\nUpdate your components\n\nNow that the data is migrated, you can start updating your components to use Better Auth. Here's an example for the sign-in component:\n\ncomponents/auth/sign-in.tsx\nimport { authClient } from \"better-auth/client\";\nexport const SignIn = () => {\n  const handleSignIn = async () => {\n    const { data, error } = await authClient.signIn.email({\n      email: \"user@example.com\",\n      password: \"password\",\n    });\n    \n    if (error) {\n      console.error(error);\n      return;\n    }\n    // Handle successful sign in\n  };\n  return (\n    <form onSubmit={handleSignIn}>\n      <button type=\"submit\">Sign in</button>\n    </form>\n  );\n};\nUpdate the middleware\n\nReplace your Clerk middleware with Better Auth's middleware:\n\nmiddleware.ts\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { getSessionCookie } from \"better-auth/cookies\";\nexport async function middleware(request: NextRequest) {\n  const sessionCookie = getSessionCookie(request);\n  const { pathname } = request.nextUrl;\n  if (sessionCookie && [\"/login\", \"/signup\"].includes(pathname)) {\n    return NextResponse.redirect(new URL(\"/dashboard\", request.url));\n  }\n  if (!sessionCookie && pathname.startsWith(\"/dashboard\")) {\n    return NextResponse.redirect(new URL(\"/login\", request.url));\n  }\n  return NextResponse.next();\n}\nexport const config = {\n  matcher: [\"/dashboard\", \"/login\", \"/signup\"],\n};\nRemove Clerk Dependencies\n\nOnce you've verified that everything is working correctly with Better Auth, you can remove Clerk:\n\nRemove Clerk\npnpm remove @clerk/nextjs @clerk/themes @clerk/types\nAdditional Resources\n\nGoodbye Clerk, Hello Better Auth – Full Migration Guide!\n\nWrapping Up\n\nCongratulations! You've successfully migrated from Clerk to Better Auth.\n\nBetter Auth offers greater flexibility and more features—be sure to explore the documentation to unlock its full potential.\n\nEdit on GitHub\n\nPrevious Page\n\nSupabase Migration Guide\n\nNext Page\n\nAuth0 Migration Guide"
  },
  {
    "title": "Migrating from Auth0 to Better Auth | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/auth0-migration-guide",
    "html": "Migrating from Auth0 to Better Auth\nCopy Markdown\nOpen in\n\nIn this guide, we'll walk through the steps to migrate a project from Auth0 to Better Auth — including email/password with proper hashing, social/external accounts, two-factor authentication, and more.\n\nThis migration will invalidate all active sessions. This guide doesn't currently show you how to migrate Organizations but it should be possible with additional steps and the Organization Plugin.\n\nBefore You Begin\n\nBefore starting the migration process, set up Better Auth in your project. Follow the installation guide to get started.\n\nConnect to your database\n\nYou'll need to connect to your database to migrate the users and accounts. You can use any database you want, but for this example, we'll use PostgreSQL.\n\nnpm\npnpm\nyarn\nbun\nnpm install pg\n\nAnd then you can use the following code to connect to your database.\n\nauth.ts\nimport { Pool } from \"pg\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n})\nEnable Email and Password (Optional)\n\nEnable the email and password in your auth config and implement your own logic for sending verification emails, reset password emails, etc.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true, \n    }, \n    emailVerification: {\n      sendVerificationEmail: async({ user, url })=>{\n        // implement your logic here to send email verification\n      }\n    },\n})\n\nSee Email and Password for more configuration options.\n\nSetup Social Providers (Optional)\n\nAdd social providers you have enabled in your Auth0 project in your auth config.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true,\n    },\n    socialProviders: { \n        google: { \n            clientId: process.env.GOOGLE_CLIENT_ID, \n            clientSecret: process.env.GOOGLE_CLIENT_SECRET, \n        }, \n        github: { \n            clientId: process.env.GITHUB_CLIENT_ID, \n            clientSecret: process.env.GITHUB_CLIENT_SECRET, \n        } \n    } \n})\nAdd Plugins (Optional)\n\nYou can add the following plugins to your auth config based on your needs.\n\nAdmin Plugin will allow you to manage users, user impersonations and app level roles and permissions.\n\nTwo Factor Plugin will allow you to add two-factor authentication to your application.\n\nUsername Plugin will allow you to add username authentication to your application.\n\nauth.ts\nimport { Pool } from \"pg\";\nimport { betterAuth } from \"better-auth\";\nimport { admin, twoFactor, username } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n    database: new Pool({ \n        connectionString: process.env.DATABASE_URL \n    }),\n    emailAndPassword: { \n        enabled: true,\n        password: {\n            verify: (data) => {\n                // this for an edgecase that you might run in to on verifying the password\n            }\n        }\n    },\n    socialProviders: {\n        google: {\n            clientId: process.env.GOOGLE_CLIENT_ID!,\n            clientSecret: process.env.GOOGLE_CLIENT_SECRET!,\n        },\n        github: {\n            clientId: process.env.GITHUB_CLIENT_ID!,\n            clientSecret: process.env.GITHUB_CLIENT_SECRET!,\n        }\n    },\n    plugins: [admin(), twoFactor(), username()], \n})\nGenerate Schema\n\nIf you're using a custom database adapter, generate the schema:\n\nnpx @better-auth/cli generate\n\nor if you're using the default adapter, you can use the following command:\n\nnpx @better-auth/cli migrate\nInstall Dependencies\n\nInstall the required dependencies for the migration:\n\nnpm install auth0\nCreate the migration script\n\nCreate a new file called migrate-auth0.ts in the scripts folder and add the following code:\n\nInstead of using the Management API, you can use Auth0's bulk user export functionality and pass the exported JSON data directly to the auth0Users array. This is especially useful if you need to migrate password hashes and complete user data, which are not available through the Management API.\n\nImportant Notes:\n\nPassword hashes export is only available for Auth0 Enterprise users\nFree plan users cannot export password hashes and will need to request a support ticket\nFor detailed information about bulk user exports, see the Auth0 Bulk User Export Documentation\nFor password hash export details, refer to Exporting Password Hashes\n\nExample:\n\n// Replace this with your exported users JSON data\nconst auth0Users = [\n  {\n    \"email\": \"helloworld@gmail.com\",\n    \"email_verified\": false,\n    \"name\": \"Hello world\",\n    // Note: password_hash is only available for Enterprise users\n    \"password_hash\": \"$2b$10$w4kfaZVjrcQ6ZOMiG.M8JeNvnVQkPKZV03pbDUHbxy9Ug0h/McDXi\",\n    // ... other user data\n  }\n];\nscripts/migrate-auth0.ts\nimport { ManagementClient } from 'auth0';\nimport { generateRandomString, symmetricEncrypt } from \"better-auth/crypto\";\nimport { auth } from '@/lib/auth';\nconst auth0Client = new ManagementClient({\n    domain: process.env.AUTH0_DOMAIN!,\n    clientId: process.env.AUTH0_CLIENT_ID!,\n    clientSecret: process.env.AUTH0_SECRET!,\n});\nfunction safeDateConversion(timestamp?: string | number): Date {\n    if (!timestamp) return new Date();\n    const numericTimestamp = typeof timestamp === 'string' ? Date.parse(timestamp) : timestamp;\n    const milliseconds = numericTimestamp < 1000000000000 ? numericTimestamp * 1000 : numericTimestamp;\n    const date = new Date(milliseconds);\n    if (isNaN(date.getTime())) {\n        console.warn(`Invalid timestamp: ${timestamp}, falling back to current date`);\n        return new Date();\n    }\n    // Check for unreasonable dates (before 2000 or after 2100)\n    const year = date.getFullYear();\n    if (year < 2000 || year > 2100) {\n        console.warn(`Suspicious date year: ${year}, falling back to current date`);\n        return new Date();\n    }\n    return date;\n}\n// Helper function to generate backup codes for 2FA\nasync function generateBackupCodes(secret: string) {\n    const key = secret;\n    const backupCodes = Array.from({ length: 10 })\n        .fill(null)\n        .map(() => generateRandomString(10, \"a-z\", \"0-9\", \"A-Z\"))\n        .map((code) => `${code.slice(0, 5)}-${code.slice(5)}`);\n    const encCodes = await symmetricEncrypt({\n        data: JSON.stringify(backupCodes),\n        key: key,\n    });\n    return encCodes;\n}\nfunction mapAuth0RoleToBetterAuthRole(auth0Roles: string[]) {\n    if (typeof auth0Roles === 'string') return auth0Roles;\n    if (Array.isArray(auth0Roles)) return auth0Roles.join(',');\n}\n// helper function to migrate password from auth0 to better auth for custom hashes and algs\nasync function migratePassword(auth0User: any) {\n    if (auth0User.password_hash) {\n        if (auth0User.password_hash.startsWith('$2a$') || auth0User.password_hash.startsWith('$2b$')) {\n            return auth0User.password_hash;\n        }\n    }\n    if (auth0User.custom_password_hash) {\n        const customHash = auth0User.custom_password_hash;\n        if (customHash.algorithm === 'bcrypt') {\n            const hash = customHash.hash.value;\n            if (hash.startsWith('$2a$') || hash.startsWith('$2b$')) {\n                return hash;\n            }\n        }\n        return JSON.stringify({\n            algorithm: customHash.algorithm,\n            hash: {\n                value: customHash.hash.value,\n                encoding: customHash.hash.encoding || 'utf8',\n                ...(customHash.hash.digest && { digest: customHash.hash.digest }),\n                ...(customHash.hash.key && {\n                    key: {\n                        value: customHash.hash.key.value,\n                        encoding: customHash.hash.key.encoding || 'utf8'\n                    }\n                })\n            },\n            ...(customHash.salt && {\n                salt: {\n                    value: customHash.salt.value,\n                    encoding: customHash.salt.encoding || 'utf8',\n                    position: customHash.salt.position || 'prefix'\n                }\n            }),\n            ...(customHash.password && {\n                password: {\n                    encoding: customHash.password.encoding || 'utf8'\n                }\n            }),\n            ...(customHash.algorithm === 'scrypt' && {\n                keylen: customHash.keylen,\n                cost: customHash.cost || 16384,\n                blockSize: customHash.blockSize || 8,\n                parallelization: customHash.parallelization || 1\n            })\n        });\n    }\n    return null;\n}\nasync function migrateMFAFactors(auth0User: any, userId: string | undefined, ctx: any) {\n    if (!userId || !auth0User.mfa_factors || !Array.isArray(auth0User.mfa_factors)) {\n        return;\n    }\n    for (const factor of auth0User.mfa_factors) {\n        try {\n            if (factor.totp && factor.totp.secret) {\n                await ctx.adapter.create({\n                    model: \"twoFactor\",\n                    data: {\n                        userId: userId,\n                        secret: factor.totp.secret,\n                        backupCodes: await generateBackupCodes(factor.totp.secret)\n                    }\n                });\n            }\n        } catch (error) {\n            console.error(`Failed to migrate MFA factor for user ${userId}:`, error);\n        }\n    }\n}\nasync function migrateOAuthAccounts(auth0User: any, userId: string | undefined, ctx: any) {\n    if (!userId || !auth0User.identities || !Array.isArray(auth0User.identities)) {\n        return;\n    }\n    for (const identity of auth0User.identities) {\n        try {\n            const providerId = identity.provider === 'auth0' ? \"credential\" : identity.provider.split(\"-\")[0];\n            await ctx.adapter.create({\n                model: \"account\",\n                data: {\n                    id: `${auth0User.user_id}|${identity.provider}|${identity.user_id}`,\n                    userId: userId,\n                    password: await migratePassword(auth0User),\n                    providerId: providerId || identity.provider,\n                    accountId: identity.user_id,\n                    accessToken: identity.access_token,\n                    tokenType: identity.token_type,\n                    refreshToken: identity.refresh_token,\n                    accessTokenExpiresAt: identity.expires_in ? new Date(Date.now() + identity.expires_in * 1000) : undefined,\n                    // if you are enterprise user, you can get the refresh tokens or all the tokensets - auth0Client.users.getAllTokensets \n                    refreshTokenExpiresAt: identity.refresh_token_expires_in ? new Date(Date.now() + identity.refresh_token_expires_in * 1000) : undefined,\n                    scope: identity.scope,\n                    idToken: identity.id_token,\n                    createdAt: safeDateConversion(auth0User.created_at),\n                    updatedAt: safeDateConversion(auth0User.updated_at)\n                },\n                forceAllowId: true\n            }).catch((error: Error) => {\n                console.error(`Failed to create OAuth account for user ${userId} with provider ${providerId}:`, error);\n                return ctx.adapter.create({\n                    // Try creating without optional fields if the first attempt failed\n                    model: \"account\",\n                    data: {\n                        id: `${auth0User.user_id}|${identity.provider}|${identity.user_id}`,\n                        userId: userId,\n                        password: migratePassword(auth0User),\n                        providerId: providerId,\n                        accountId: identity.user_id,\n                        accessToken: identity.access_token,\n                        tokenType: identity.token_type,\n                        refreshToken: identity.refresh_token,\n                        accessTokenExpiresAt: identity.expires_in ? new Date(Date.now() + identity.expires_in * 1000) : undefined,\n                        refreshTokenExpiresAt: identity.refresh_token_expires_in ? new Date(Date.now() + identity.refresh_token_expires_in * 1000) : undefined,\n                        scope: identity.scope,\n                        idToken: identity.id_token,\n                        createdAt: safeDateConversion(auth0User.created_at),\n                        updatedAt: safeDateConversion(auth0User.updated_at)\n                    },\n                    forceAllowId: true\n                });\n            });\n            console.log(`Successfully migrated OAuth account for user ${userId} with provider ${providerId}`);\n        } catch (error) {\n            console.error(`Failed to migrate OAuth account for user ${userId}:`, error);\n        }\n    }\n}\nasync function migrateOrganizations(ctx: any) {\n    try {\n        const organizations = await auth0Client.organizations.getAll();\n        for (const org of organizations.data || []) {\n            try {\n                await ctx.adapter.create({\n                    model: \"organization\",\n                    data: {\n                        id: org.id,\n                        name: org.display_name || org.id,\n                        slug: (org.display_name || org.id).toLowerCase().replace(/[^a-z0-9]/g, '-'),\n                        logo: org.branding?.logo_url,\n                        metadata: JSON.stringify(org.metadata || {}),\n                        createdAt: safeDateConversion(org.created_at),\n                    },\n                    forceAllowId: true\n                });\n                const members = await auth0Client.organizations.getMembers({ id: org.id });\n                for (const member of members.data || []) {\n                    try {\n                        const userRoles = await auth0Client.organizations.getMemberRoles({\n                            id: org.id,\n                            user_id: member.user_id\n                        });\n                        const role = mapAuth0RoleToBetterAuthRole(userRoles.data?.map(r => r.name) || []);\n                        await ctx.adapter.create({\n                            model: \"member\",\n                            data: {\n                                id: `${org.id}|${member.user_id}`,\n                                organizationId: org.id,\n                                userId: member.user_id,\n                                role: role,\n                                createdAt: new Date()\n                            },\n                            forceAllowId: true\n                        });\n                        console.log(`Successfully migrated member ${member.user_id} for organization ${org.display_name || org.id}`);\n                    } catch (error) {\n                        console.error(`Failed to migrate member ${member.user_id} for organization ${org.display_name || org.id}:`, error);\n                    }\n                }\n                console.log(`Successfully migrated organization: ${org.display_name || org.id}`);\n            } catch (error) {\n                console.error(`Failed to migrate organization ${org.display_name || org.id}:`, error);\n            }\n        }\n        console.log('Organization migration completed');\n    } catch (error) {\n        console.error('Failed to migrate organizations:', error);\n    }\n}\nasync function migrateFromAuth0() {\n    try {\n        const ctx = await auth.$context;\n        const isAdminEnabled = ctx.options?.plugins?.find(plugin => plugin.id === \"admin\");\n        const isUsernameEnabled = ctx.options?.plugins?.find(plugin => plugin.id === \"username\");\n        const isOrganizationEnabled = ctx.options?.plugins?.find(plugin => plugin.id === \"organization\");\n        const perPage = 100;\n        const auth0Users: any[] = [];\n        let pageNumber = 0;\n        while (true) {\n            try {\n                const params = {\n                    per_page: perPage,\n                    page: pageNumber,\n                    include_totals: true,\n                };\n                const response = (await auth0Client.users.getAll(params)).data as any;\n                const users = response.users || [];\n                if (users.length === 0) break;\n                auth0Users.push(...users);\n                pageNumber++;\n                if (users.length < perPage) break;\n            } catch (error) {\n                console.error('Error fetching users:', error);\n                break;\n            }\n        }\n        console.log(`Found ${auth0Users.length} users to migrate`);\n        for (const auth0User of auth0Users) {\n            try {\n                // Determine if this is a password-based or OAuth user\n                const isOAuthUser = auth0User.identities?.some((identity: any) => identity.provider !== 'auth0');\n                // Base user data that's common for both types\n                const baseUserData = {\n                    id: auth0User.user_id,\n                    email: auth0User.email,\n                    emailVerified: auth0User.email_verified || false,\n                    name: auth0User.name || auth0User.nickname,\n                    image: auth0User.picture,\n                    createdAt: safeDateConversion(auth0User.created_at),\n                    updatedAt: safeDateConversion(auth0User.updated_at),\n                    ...(isAdminEnabled ? {\n                        banned: auth0User.blocked || false,\n                        role: mapAuth0RoleToBetterAuthRole(auth0User.roles || []),\n                    } : {}),\n                    ...(isUsernameEnabled ? {\n                        username: auth0User.username || auth0User.nickname,\n                    } : {}),\n                };\n                const createdUser = await ctx.adapter.create({\n                    model: \"user\",\n                    data: {\n                        ...baseUserData,\n                    },\n                    forceAllowId: true\n                });\n                if (!createdUser?.id) {\n                    throw new Error('Failed to create user');\n                }\n                await migrateOAuthAccounts(auth0User, createdUser.id, ctx)\n                console.log(`Successfully migrated user: ${auth0User.email}`);\n            } catch (error) {\n                console.error(`Failed to migrate user ${auth0User.email}:`, error);\n            }\n        }\n        if (isOrganizationEnabled) {\n            await migrateOrganizations(ctx);\n        }\n        // the reset of migration will be here.\n        console.log('Migration completed successfully');\n    } catch (error) {\n        console.error('Migration failed:', error);\n        throw error;\n    }\n}\nmigrateFromAuth0()\n    .then(() => {\n        console.log('Migration completed');\n        process.exit(0);\n    })\n    .catch((error) => {\n        console.error('Migration failed:', error);\n        process.exit(1);\n    }); \n\nMake sure to replace the Auth0 environment variables with your own values:\n\nAUTH0_DOMAIN\nAUTH0_CLIENT_ID\nAUTH0_SECRET\nRun the migration\n\nRun the migration script:\n\nbun run scripts/migrate-auth0.ts # or use your preferred runtime\n\nImportant considerations:\n\nTest the migration in a development environment first\nMonitor the migration process for any errors\nVerify the migrated data in Better Auth before proceeding\nKeep Auth0 installed and configured until the migration is complete\nThe script handles bcrypt password hashes by default. For custom password hashing algorithms, you'll need to modify the migratePassword function\nChange password hashing algorithm\n\nBy default, Better Auth uses the scrypt algorithm to hash passwords. Since Auth0 uses bcrypt, you'll need to configure Better Auth to use bcrypt for password verification.\n\nFirst, install bcrypt:\n\nnpm install bcrypt\nnpm install -D @types/bcrypt\n\nThen update your auth configuration:\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nimport bcrypt from \"bcrypt\";\nexport const auth = betterAuth({\n   emailAndPassword: {\n       password: {\n           hash: async (password) => {\n               return await bcrypt.hash(password, 10);\n           },\n           verify: async ({ hash, password }) => {\n               return await bcrypt.compare(password, hash);\n           }\n       }\n   }\n})\nVerify the migration\n\nAfter running the migration, verify that:\n\nAll users have been properly migrated\nSocial connections are working\nPassword-based authentication is working\nTwo-factor authentication settings are preserved (if enabled)\nUser roles and permissions are correctly mapped\nUpdate your components\n\nNow that the data is migrated, update your components to use Better Auth. Here's an example for the sign-in component:\n\ncomponents/auth/sign-in.tsx\nimport { authClient } from \"better-auth/client\";\nexport const SignIn = () => {\n  const handleSignIn = async () => {\n    const { data, error } = await authClient.signIn.email({\n      email: \"helloworld@gmail.com\",\n      password: \"helloworld\",\n    });\n    \n    if (error) {\n      console.error(error);\n      return;\n    }\n    // Handle successful sign in\n  };\n  return (\n    <form onSubmit={handleSignIn}>\n      <button type=\"submit\">Sign in</button>\n    </form>\n  );\n};\nUpdate the middleware\n\nReplace your Auth0 middleware with Better Auth's middleware:\n\nmiddleware.ts\nimport { NextRequest, NextResponse } from \"next/server\";\nimport { getSessionCookie } from \"better-auth/cookies\";\nexport async function middleware(request: NextRequest) {\n  const sessionCookie = getSessionCookie(request);\n  const { pathname } = request.nextUrl;\n  if (sessionCookie && [\"/login\", \"/signup\"].includes(pathname)) {\n    return NextResponse.redirect(new URL(\"/dashboard\", request.url));\n  }\n  if (!sessionCookie && pathname.startsWith(\"/dashboard\")) {\n    return NextResponse.redirect(new URL(\"/login\", request.url));\n  }\n  return NextResponse.next();\n}\nexport const config = {\n  matcher: [\"/dashboard\", \"/login\", \"/signup\"],\n};\nRemove Auth0 Dependencies\n\nOnce you've verified everything is working correctly with Better Auth, remove Auth0:\n\nnpm remove @auth0/auth0-react @auth0/auth0-spa-js @auth0/nextjs-auth0\nAdditional Considerations\nPassword Migration\n\nThe migration script handles bcrypt password hashes by default. If you're using custom password hashing algorithms in Auth0, you'll need to modify the migratePassword function in the migration script to handle your specific case.\n\nRole Mapping\n\nThe script includes a basic role mapping function (mapAuth0RoleToBetterAuthRole). Customize this function based on your Auth0 roles and Better Auth role requirements.\n\nRate Limiting\n\nThe migration script includes pagination to handle large numbers of users. Adjust the perPage value based on your needs and Auth0's rate limits.\n\nWrapping Up\n\nNow! You've successfully migrated from Auth0 to Better Auth.\n\nBetter Auth offers greater flexibility and more features—be sure to explore the documentation to unlock its full potential.\n\nEdit on GitHub\n\nPrevious Page\n\nClerk Migration Guide\n\nNext Page\n\nCreate Your First Plugin"
  },
  {
    "title": "Create your first plugin | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/your-first-plugin",
    "html": "Create your first plugin\nCopy Markdown\nOpen in\n\nIn this guide, we’ll walk you through the steps of creating your first Better Auth plugin.\n\nThis guide assumes you have setup the basics of Better Auth and are ready to create your first plugin.\n\nPlan your idea\n\nBefore beginning, you must know what plugin you intend to create.\n\nIn this guide, we’ll create a birthday plugin to keep track of user birth dates.\n\nServer plugin first\n\nBetter Auth plugins operate as a pair: a server plugin and a client plugin. The server plugin forms the foundation of your authentication system, while the client plugin provides convenient frontend APIs to interact with your server implementation.\n\nYou can read more about server/client plugins in our documentation.\n\nCreating the server plugin\n\nGo ahead and find a suitable location to create your birthday plugin folder, with an index.ts file within.\n\nbirthday-plugin\nindex.ts\n\nIn the index.ts file, we’ll export a function that represents our server plugin. This will be what we will later add to our plugin list in the auth.ts file.\n\nindex.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport type { BetterAuthPlugin } from \"better-auth\";\nexport const birthdayPlugin = () =>\n  ({\n    id: \"birthdayPlugin\",\n  } satisfies BetterAuthPlugin);\n\nAlthough this does nothing, you have technically just made yourself your first plugin, congratulations! 🎉\n\nDefining a schema\n\nIn order to save each user’s birthday data, we must create a schema on top of the user model.\n\nBy creating a schema here, this also allows Better Auth’s CLI to generate the schemas required to update your database.\n\nYou can learn more about plugin schemas here.\n\nindex.ts\n//...\nexport const birthdayPlugin = () =>\n  ({\n    id: \"birthdayPlugin\",\n    schema: {\n      user: {\n        fields: {\n          birthday: {\n            type: \"date\", // string, number, boolean, date\n            required: true, // if the field should be required on a new record. (default: false)\n            unique: false, // if the field should be unique. (default: false)\n            references: null // if the field is a reference to another table. (default: null)\n          },\n        },\n      },\n    },\n  } satisfies BetterAuthPlugin);\nAuthorization logic\n\nFor this example guide, we’ll set up authentication logic to check and ensure that the user who signs-up is older than 5. But the same concept could be applied for something like verifying users agreeing to the TOS or anything alike.\n\nTo do this, we’ll utilize Hooks, which allows us to run code before or after an action is performed.\n\nindex.ts\nexport const birthdayPlugin = () => ({\n    //...\n    // In our case, we want to write authorization logic,\n    // meaning we want to intercept it `before` hand.\n    hooks: {\n      before: [\n        {\n          matcher: (context) => /* ... */,\n          handler: createAuthMiddleware(async (ctx) => {\n            //...\n          }),\n        },\n      ],\n    },\n} satisfies BetterAuthPlugin)\n\nIn our case we want to match any requests going to the signup path:\n\nBefore hook\n{\n  matcher: (context) => context.path.startsWith(\"/sign-up/email\"),\n  //...\n}\n\nAnd for our logic, we’ll write the following code to check the if user’s birthday makes them above 5 years old.\n\nImports\nimport { APIError } from \"better-auth/api\";\nimport { createAuthMiddleware } from \"better-auth/plugins\";\nBefore hook\n{\n  //...\n  handler: createAuthMiddleware(async (ctx) => {\n    const { birthday } = ctx.body;\n    if(!(birthday instanceof Date)) {\n      throw new APIError(\"BAD_REQUEST\", { message: \"Birthday must be of type Date.\" });\n    }\n    const today = new Date();\n    const fiveYearsAgo = new Date(today.setFullYear(today.getFullYear() - 5));\n    if(birthday >= fiveYearsAgo) {\n      throw new APIError(\"BAD_REQUEST\", { message: \"User must be above 5 years old.\" });\n    }\n    return { context: ctx };\n  }),\n}\n\nAuthorized! 🔒\n\nWe’ve now successfully written code to ensure authorization for users above 5!\n\nClient Plugin\n\nWe’re close to the finish line! 🏁\n\nNow that we have created our server plugin, the next step is to develop our client plugin. Since there isn’t much frontend APIs going on for this plugin, there isn’t much to do!\n\nFirst, let’s create our client.ts file first:\n\nbirthday-plugin\nindex.ts\nclient.ts\n\nThen, add the following code:\n\nclient.ts\nimport { BetterAuthClientPlugin } from \"better-auth\";\nimport type { birthdayPlugin } from \"./index\"; // make sure to import the server plugin as a type\ntype BirthdayPlugin = typeof birthdayPlugin;\nexport const birthdayClientPlugin = () => {\n  return {\n    id: \"birthdayPlugin\",\n    $InferServerPlugin: {} as ReturnType<BirthdayPlugin>,\n  } satisfies BetterAuthClientPlugin;\n};\n\nWhat we’ve done is allow the client plugin to infer the types defined by our schema from the server plugin.\n\nAnd that’s it! This is all it takes for the birthday client plugin. 🎂\n\nInitiate your plugin!\n\nBoth the client and server plugins are now ready, the last step is to import them to both your auth-client.ts and your server.ts files respectively to initiate the plugin.\n\nServer initiation\nserver.ts\nimport { betterAuth } from \"better-auth\";\nimport { birthdayPlugin } from \"./birthday-plugin\";\n \nexport const auth = betterAuth({\n    plugins: [\n      birthdayPlugin(),\n    ]\n});\nClient initiation\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nimport { birthdayClientPlugin } from \"./birthday-plugin/client\";\n \nconst authClient = createAuthClient({\n    plugins: [\n      birthdayClientPlugin()\n    ]\n});\nOh yeah, the schemas!\n\nDon’t forget to add your birthday field to your user table model!\n\nOr, use the generate CLI command:\n\nnpx @better-auth/cli@latest generate\nWrapping Up\n\nCongratulations! You’ve successfully created your first ever Better Auth plugin. We highly recommend you visit our plugins documentation to learn more information.\n\nIf you have a plugin you’d like to share with the community, feel free to let us know through our Discord server, or through a pull-request and we may add it to the community-plugins list!\n\nEdit on GitHub\n\nPrevious Page\n\nAuth0 Migration Guide\n\nNext Page\n\nCreate a Database Adapter"
  },
  {
    "title": "Create a Database Adapter | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/create-a-db-adapter",
    "html": "Create a Database Adapter\nCopy Markdown\nOpen in\n\nLearn how to create a custom database adapter for Better-Auth using createAdapter.\n\nOur createAdapter function is designed to be very flexible, and we've done our best to make it easy to understand and use. Our hope is to allow you to focus on writing database logic, and not have to worry about how the adapter is working with Better-Auth.\n\nAnything from custom schema configurations, custom ID generation, safe JSON parsing, and more is handled by the createAdapter function. All you need to do is provide the database logic, and the createAdapter function will handle the rest.\n\nQuick Start\nGet things ready\nImport createAdapter.\nCreate CustomAdapterConfig interface that represents your adapter config options.\nCreate the adapter!\nimport { createAdapter, type DBAdapterDebugLogOption } from \"better-auth/adapters\";\n// Your custom adapter config options\ninterface CustomAdapterConfig {\n  /**\n   * Helps you debug issues with the adapter.\n   */\n  debugLogs?: DBAdapterDebugLogOption;\n  /**\n   * If the table names in the schema are plural.\n   */\n  usePlural?: boolean;\n}\nexport const myAdapter = (config: CustomAdapterConfig = {}) =>\n  createAdapter({\n    // ...\n  });\nConfigure the adapter\n\nThe config object is mostly used to provide information about the adapter to Better-Auth. We try to minimize the amount of code you need to write in your adapter functions, and these config options are used to help us do that.\n\n// ...\nexport const myAdapter = (config: CustomAdapterConfig = {}) =>\n  createAdapter({\n    config: {\n      adapterId: \"custom-adapter\", // A unique identifier for the adapter.\n      adapterName: \"Custom Adapter\", // The name of the adapter.\n      usePlural: config.usePlural ?? false, // Whether the table names in the schema are plural.\n      debugLogs: config.debugLogs ?? false, // Whether to enable debug logs.\n      supportsJSON: false, // Whether the database supports JSON. (Default: false)\n      supportsDates: true, // Whether the database supports dates. (Default: true)\n      supportsBooleans: true, // Whether the database supports booleans. (Default: true)\n      supportsNumericIds: true, // Whether the database supports auto-incrementing numeric IDs. (Default: true)\n    },\n    // ...\n  });\nCreate the adapter\n\nThe adapter function is where you write the code that interacts with your database.\n\n// ...\nexport const myAdapter = (config: CustomAdapterConfig = {}) =>\n  createAdapter({\n    config: {\n      // ...\n    },\n    adapter: ({}) => {\n      return {\n        create: async ({ data, model, select }) => {\n          // ...\n        },\n        update: async ({ data, model, select }) => {\n          // ...\n        },\n        updateMany: async ({ data, model, select }) => {\n          // ...\n        },\n        delete: async ({ data, model, select }) => {\n          // ...\n        },\n        // ...\n      };\n    },\n  });\n\nLearn more about the adapter here here.\n\nAdapter\n\nThe adapter function is where you write the code that interacts with your database.\n\nIf you haven't already, check out the options object in the config section, as it can be useful for your adapter.\n\nBefore we get into the adapter function, let's go over the parameters that are available to you.\n\noptions: The Better Auth options.\nschema: The schema from the user's Better Auth instance.\ndebugLog: The debug log function.\ngetField: The get field function.\ngetDefaultModelName: The get default model name function.\ngetDefaultFieldName: The get default field name function.\ngetFieldAttributes: The get field attributes function.\nExample\nadapter: ({\n  options,\n  schema,\n  debugLog,\n  getField,\n  getDefaultModelName,\n  getDefaultFieldName,\n}) => {\n  return {\n    // ...\n  };\n};\nAdapter Methods\nAll model values are already transformed into the correct model name for the database based on the end-user's schema configuration.\nThis also means that if you need access to the schema version of a given model, you can't use this exact model value, you'll need to use the getDefaultModelName function provided in the options to convert the model to the schema version.\nWe will automatically fill in any missing fields you return based on the user's schema configuration.\nAny method that includes a select parameter, is only for the purpose of getting data from your database more efficiently. You do not need to worry about only returning what the select parameter states, as we will handle that for you.\ncreate method\n\nThe create method is used to create a new record in the database.\n\nNote: If the user has enabled the useNumberId option, or if generateId is false in the user's Better Auth config, then it's expected that the id is provided in the data object. Otherwise, the id will be automatically generated.\n\nAdditionally, it's possible to pass forceAllowId as a parameter to the create method, which allows id to be provided in the data object. We handle forceAllowId internally, so you don't need to worry about it.\n\nparameters:\n\nmodel: The model/table name that new data will be inserted into.\ndata: The data to insert into the database.\nselect: An array of fields to return from the database.\n\nMake sure to return the data that is inserted into the database.\n\nExample\ncreate: async ({ model, data, select }) => {\n  // Example of inserting data into the database.\n  return await db.insert(model).values(data);\n};\nupdate method\n\nThe update method is used to update a record in the database.\n\nparameters:\n\nmodel: The model/table name that the record will be updated in.\nwhere: The where clause to update the record by.\nupdate: The data to update the record with.\n\nMake sure to return the data in the row which is updated. This includes any fields that were not updated.\n\nExample\nupdate: async ({ model, where, update }) => {\n  // Example of updating data in the database.\n  return await db.update(model).set(update).where(where);\n};\nupdateMany method\n\nThe updateMany method is used to update multiple records in the database.\n\nparameters:\n\nmodel: The model/table name that the records will be updated in.\nwhere: The where clause to update the records by.\nupdate: The data to update the records with.\nMake sure to return the number of records that were updated.\nExample\nupdateMany: async ({ model, where, update }) => {\n  // Example of updating multiple records in the database.\n  return await db.update(model).set(update).where(where);\n};\ndelete method\n\nThe delete method is used to delete a record from the database.\n\nparameters:\n\nmodel: The model/table name that the record will be deleted from.\nwhere: The where clause to delete the record by.\nExample\ndelete: async ({ model, where }) => {\n  // Example of deleting a record from the database.\n  await db.delete(model).where(where);\n}\ndeleteMany method\n\nThe deleteMany method is used to delete multiple records from the database.\n\nparameters:\n\nmodel: The model/table name that the records will be deleted from.\nwhere: The where clause to delete the records by.\nMake sure to return the number of records that were deleted.\nExample\ndeleteMany: async ({ model, where }) => {\n  // Example of deleting multiple records from the database.\n  return await db.delete(model).where(where);\n};\nfindOne method\n\nThe findOne method is used to find a single record in the database.\n\nparameters:\n\nmodel: The model/table name that the record will be found in.\nwhere: The where clause to find the record by.\nselect: The select clause to return.\nMake sure to return the data that is found in the database.\nExample\nfindOne: async ({ model, where, select }) => {\n  // Example of finding a single record in the database.\n  return await db.select().from(model).where(where).limit(1);\n};\nfindMany method\n\nThe findMany method is used to find multiple records in the database.\n\nparameters:\n\nmodel: The model/table name that the records will be found in.\nwhere: The where clause to find the records by.\nlimit: The limit of records to return.\nsortBy: The sortBy clause to sort the records by.\noffset: The offset of records to return.\n\nMake sure to return the array of data that is found in the database.\n\nExample\nfindMany: async ({ model, where, limit, sortBy, offset }) => {\n  // Example of finding multiple records in the database.\n  return await db\n    .select()\n    .from(model)\n    .where(where)\n    .limit(limit)\n    .offset(offset)\n    .orderBy(sortBy);\n};\ncount method\n\nThe count method is used to count the number of records in the database.\n\nparameters:\n\nmodel: The model/table name that the records will be counted in.\nwhere: The where clause to count the records by.\nMake sure to return the number of records that were counted.\nExample\ncount: async ({ model, where }) => {\n  // Example of counting the number of records in the database.\n  return await db.select().from(model).where(where).count();\n};\noptions (optional)\n\nThe options object is for any potential config that you got from your custom adapter options.\n\nExample\nconst myAdapter = (config: CustomAdapterConfig) =>\n  createAdapter({\n    config: {\n      // ...\n    },\n    adapter: ({ options }) => {\n      return {\n        options: config,\n      };\n    },\n  });\ncreateSchema (optional)\n\nThe createSchema method allows the Better Auth CLI to generate a schema for the database.\n\nparameters:\n\ntables: The tables from the user's Better-Auth instance schema; which is expected to be generated into the schema file.\nfile: The file the user may have passed in to the generate command as the expected schema file output path.\nExample\ncreateSchema: async ({ file, tables }) => {\n  // ... Custom logic to create a schema for the database.\n};\nTest your adapter\n\nWe've provided a test suite that you can use to test your adapter. It requires you to use vitest.\n\nmy-adapter.test.ts\nimport { expect, test, describe } from \"vitest\";\nimport { runAdapterTest } from \"better-auth/adapters/test\";\nimport { myAdapter } from \"./my-adapter\";\ndescribe(\"My Adapter Tests\", async () => {\n  afterAll(async () => {\n    // Run DB cleanup here...\n  });\n  const adapter = myAdapter({\n    debugLogs: {\n      // If your adapter config allows passing in debug logs, then pass this here.\n      isRunningAdapterTests: true, // This is our super secret flag to let us know to only log debug logs if a test fails.\n    },\n  });\n  await runAdapterTest({\n    getAdapter: async (betterAuthOptions = {}) => {\n      return adapter(betterAuthOptions);\n    },\n  });\n});\nNumeric ID tests\n\nIf your database supports numeric IDs, then you should run this test as well:\n\nmy-adapter.number-id.test.ts\nimport { expect, test, describe } from \"vitest\";\nimport { runNumberIdAdapterTest } from \"better-auth/adapters/test\";\nimport { myAdapter } from \"./my-adapter\";\ndescribe(\"My Adapter Numeric ID Tests\", async () => {\n  afterAll(async () => {\n    // Run DB cleanup here...\n  });\n  const adapter = myAdapter({\n    debugLogs: {\n      // If your adapter config allows passing in debug logs, then pass this here.\n      isRunningAdapterTests: true, // This is our super secret flag to let us know to only log debug logs if a test fails.\n    },\n  });\n  await runNumberIdAdapterTest({\n    getAdapter: async (betterAuthOptions = {}) => {\n      return adapter(betterAuthOptions);\n    },\n  });\n});\nConfig\n\nThe config object is used to provide information about the adapter to Better-Auth.\n\nWe highly recommend going through and reading each provided option below, as it will help you understand how to properly configure your adapter.\n\nRequired Config\nadapterId\n\nA unique identifier for the adapter.\n\nadapterName\n\nThe name of the adapter.\n\nOptional Config\nsupportsNumericIds\n\nWhether the database supports numeric IDs. If this is set to false and the user's config has enabled useNumberId, then we will throw an error.\n\nsupportsJSON\n\nWhether the database supports JSON. If the database doesn't support JSON, we will use a string to save the JSON data.And when we retrieve the data, we will safely parse the string back into a JSON object.\n\nsupportsDates\n\nWhether the database supports dates. If the database doesn't support dates, we will use a string to save the date. (ISO string) When we retrieve the data, we will safely parse the string back into a Date object.\n\nsupportsBooleans\n\nWhether the database supports booleans. If the database doesn't support booleans, we will use a 0 or 1 to save the boolean value. When we retrieve the data, we will safely parse the 0 or 1 back into a boolean value.\n\nusePlural\n\nWhether the table names in the schema are plural. This is often defined by the user, and passed down through your custom adapter options. If you do not intend to allow the user to customize the table names, you can ignore this option, or set this to false.\n\nExample\nconst adapter = myAdapter({\n  // This value then gets passed into the `usePlural`\n  // option in the createAdapter `config` object.\n  usePlural: true,\n});\ntransaction\n\nWhether the adapter supports transactions. If false, operations run sequentially; otherwise provide a function that executes a callback with a TransactionAdapter.\n\nIf your database does not support transactions, the error handling and rollback will not be as robust. We recommend using a database that supports transactions for better data integrity.\n\ndebugLogs\n\nUsed to enable debug logs for the adapter. You can pass in a boolean, or an object with the following keys: create, update, updateMany, findOne, findMany, delete, deleteMany, count. If any of the keys are true, the debug logs will be enabled for that method.\n\nExample\n// Will log debug logs for all methods.\nconst adapter = myAdapter({\n  debugLogs: true,\n});\nExample\n// Will only log debug logs for the `create` and `update` methods.\nconst adapter = myAdapter({\n  debugLogs: {\n    create: true,\n    update: true,\n  },\n});\ndisableIdGeneration\n\nWhether to disable ID generation. If this is set to true, then the user's generateId option will be ignored.\n\ncustomIdGenerator\n\nIf your database only supports a specific custom ID generation, then you can use this option to generate your own IDs.\n\nmapKeysTransformInput\n\nIf your database uses a different key name for a given situation, you can use this option to map the keys. This is useful for databases that expect a different key name for a given situation. For example, MongoDB uses _id while in Better-Auth we use id.\n\nEach key in the returned object represents the old key to replace. The value represents the new key.\n\nThis can be a partial object that only transforms some keys.\n\nExample\nmapKeysTransformInput: () => {\n  return {\n    id: \"_id\", // We want to replace `id` to `_id` to save into MongoDB\n  };\n},\nmapKeysTransformOutput\n\nIf your database uses a different key name for a given situation, you can use this option to map the keys. This is useful for databases that use a different key name for a given situation. For example, MongoDB uses _id while in Better-Auth we use id.\n\nEach key in the returned object represents the old key to replace. The value represents the new key.\n\nThis can be a partial object that only transforms some keys.\n\nExample\nmapKeysTransformOutput: () => {\n  return {\n    _id: \"id\", // We want to replace `_id` (from MongoDB) to `id` (for Better-Auth)\n  };\n},\ncustomTransformInput\n\nIf you need to transform the input data before it is saved to the database, you can use this option to transform the data.\n\nIf you're using supportsJSON, supportsDates, or supportsBooleans, then the transformations will be applied before your customTransformInput function is called.\n\nThe customTransformInput function receives the following arguments:\n\ndata: The data to transform.\nfield: The field that is being transformed.\nfieldAttributes: The field attributes of the field that is being transformed.\nselect: The select values which the query expects to return.\nmodel: The model that is being transformed.\nschema: The schema that is being transformed.\noptions: Better Auth options.\n\nThe customTransformInput function runs at every key in the data object of a given action.\n\nExample\ncustomTransformInput: ({ field, data }) => {\n  if (field === \"id\") {\n    return \"123\"; // Force the ID to be \"123\"\n  }\n  return data;\n};\ncustomTransformOutput\n\nIf you need to transform the output data before it is returned to the user, you can use this option to transform the data. The customTransformOutput function is used to transform the output data. Similar to the customTransformInput function, it runs at every key in the data object of a given action, but it runs after the data is retrieved from the database.\n\nExample\ncustomTransformOutput: ({ field, data }) => {\n  if (field === \"name\") {\n    return \"Bob\"; // Force the name to be \"Bob\"\n  }\n  return data;\n};\nconst some_data = await adapter.create({\n  model: \"user\",\n  data: {\n    name: \"John\",\n  },\n});\n// The name will be \"Bob\"\nconsole.log(some_data.name);\nEdit on GitHub\n\nPrevious Page\n\nCreate Your First Plugin\n\nNext Page\n\nBrowser Extension Guide"
  },
  {
    "title": "Browser Extension Guide | Better Auth",
    "url": "https://www.better-auth.com/docs/guides/browser-extension-guide",
    "html": "Browser Extension Guide\nCopy Markdown\nOpen in\n\nIn this guide, we'll walk you through the steps of creating a browser extension using Plasmo with Better Auth for authentication.\n\nIf you would like to view a completed example, you can check out the browser extension example.\n\nThe Plasmo framework does not provide a backend for the browser extension. This guide assumes you have a backend setup of Better Auth and are ready to create a browser extension to connect to it.\n\nSetup & Installations\n\nInitialize a new Plasmo project with TailwindCSS and a src directory.\n\npnpm create plasmo --with-tailwindcss --with-src\n\nThen, install the Better Auth package.\n\npnpm add better-auth\n\nTo start the Plasmo development server, run the following command.\n\npnpm dev\nConfigure tsconfig\n\nConfigure the tsconfig.json file to include strict mode.\n\nFor this demo, we have also changed the import alias from ~ to @ and set it to the src directory.\n\ntsconfig.json\n{\n    \"compilerOptions\": {\n        \"paths\": {\n            \"@/_\": [\n                \"./src/_\"\n            ]\n        },\n        \"strict\": true,\n        \"baseUrl\": \".\"\n    }\n}\nCreate the client auth instance\n\nCreate a new file at src/auth/auth-client.ts and add the following code.\n\nsrc\nauth\nauth-client.ts\nauth-client.ts\nimport { createAuthClient } from \"better-auth/react\"\nexport const authClient = createAuthClient({\n    baseURL: \"http://localhost:3000\" /* Base URL of your Better Auth backend. */,\n    plugins: [],\n});\nConfigure the manifest\n\nWe must ensure the extension knows the URL to the Better Auth backend.\n\nHead to your package.json file, and add the following code.\n\npackage.json\n{\n    //...\n    \"manifest\": {\n        \"host_permissions\": [\n            \"https://URL_TO_YOUR_BACKEND\" // localhost works too (e.g. http://localhost:3000)\n        ]\n    }\n}\nYou're now ready!\n\nYou have now set up Better Auth for your browser extension.\n\nAdd your desired UI and create your dream extension!\n\nTo learn more about the client Better Auth API, check out the client documentation.\n\nHere's a quick example 😎\n\nsrc/popup.tsx\nimport { authClient } from \"./auth/auth-client\"\nfunction IndexPopup() {\n    const {data, isPending, error} = authClient.useSession();\n    if(isPending){\n        return <>Loading...</>\n    }\n    if(error){\n        return <>Error: {error.message}</>\n    }\n    if(data){\n        return <>Signed in as {data.user.name}</>\n    }\n}\nexport default IndexPopup;\nBundle your extension\n\nTo get a production build, run the following command.\n\npnpm build\n\nHead over to chrome://extensions and enable developer mode.\n\nClick on \"Load Unpacked\" and navigate to your extension's build/chrome-mv3-dev (or build/chrome-mv3-prod) directory.\n\nTo see your popup, click on the puzzle piece icon on the Chrome toolbar, and click on your extension.\n\nLearn more about bundling your extension here.\n\nConfigure the server auth instance\n\nFirst, we will need your extension URL.\n\nAn extension URL formed like this: chrome-extension://YOUR_EXTENSION_ID.\n\nYou can find your extension ID at chrome://extensions.\n\nHead to your server's auth file, and make sure that your extension's URL is added to the trustedOrigins list.\n\nserver.ts\nimport { betterAuth } from \"better-auth\"\nimport { auth } from \"@/auth/auth\"\nexport const auth = betterAuth({\n    trustedOrigins: [\"chrome-extension://YOUR_EXTENSION_ID\"],\n})\n\nIf you're developing multiple extensions or need to support different browser extensions with different IDs, you can use wildcard patterns:\n\nserver.ts\nexport const auth = betterAuth({\n    trustedOrigins: [\n        // Support a specific extension ID\n        \"chrome-extension://YOUR_EXTENSION_ID\",\n        \n        // Or support multiple extensions with wildcard (less secure)\n        \"chrome-extension://*\"\n    ],\n})\n\nUsing wildcards for extension origins (chrome-extension://*) reduces security by trusting all extensions. It's safer to explicitly list each extension ID you trust. Only use wildcards for development and testing.\n\nThat's it!\n\nEverything is set up! You can now start developing your extension. 🎉\n\nWrapping Up\n\nCongratulations! You've successfully created a browser extension using Better Auth and Plasmo. We highly recommend you visit the Plasmo documentation to learn more about the framework.\n\nIf you would like to view a completed example, you can check out the browser extension example.\n\nIf you have any questions, feel free to open an issue on our GitHub repo, or join our Discord server for support.\n\nEdit on GitHub\n\nPrevious Page\n\nCreate a Database Adapter\n\nNext Page\n\nSAML SSO with Okta"
  },
  {
    "title": "Options | Better Auth",
    "url": "https://www.better-auth.com/docs/reference/options",
    "html": "Options\nCopy Markdown\nOpen in\n\nList of all the available options for configuring Better Auth. See Better Auth Options.\n\nappName\n\nThe name of the application.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tappName: \"My App\",\n})\nbaseURL\n\nBase URL for Better Auth. This is typically the root URL where your application server is hosted. Note: If you include a path in the baseURL, it will take precedence over the default path.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tbaseURL: \"https://example.com\",\n})\n\nIf not explicitly set, the system will check for the environment variable process.env.BETTER_AUTH_URL\n\nbasePath\n\nBase path for Better Auth. This is typically the path where the Better Auth routes are mounted. It will be overridden if there is a path component within baseURL.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tbasePath: \"/api/auth\",\n})\n\nDefault: /api/auth\n\ntrustedOrigins\n\nList of trusted origins. You can provide a static array of origins, a function that returns origins dynamically, or use wildcard patterns to match multiple domains.\n\nStatic Origins\n\nYou can provide a static array of origins:\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\ttrustedOrigins: [\"http://localhost:3000\", \"https://example.com\"],\n})\nDynamic Origins\n\nYou can provide a function that returns origins dynamically:\n\nexport const auth = betterAuth({\n\ttrustedOrigins: async (request: Request) => {\n\t\t// Return an array of trusted origins based on the request\n\t\treturn [\"https://dynamic-origin.com\"];\n\t}\n})\nWildcard Support\n\nYou can use wildcard patterns in trusted origins:\n\nexport const auth = betterAuth({\n\ttrustedOrigins: [\n\t\t\"*.example.com\",             // Trust all subdomains of example.com\n\t\t\"https://*.example.com\",     // Trust only HTTPS subdomains\n\t\t\"http://*.dev.example.com\"   // Trust HTTP subdomains of dev.example.com\n\t]\n})\nsecret\n\nThe secret used for encryption, signing, and hashing.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tsecret: \"your-secret-key\",\n})\n\nBy default, Better Auth will look for the following environment variables:\n\nprocess.env.BETTER_AUTH_SECRET\nprocess.env.AUTH_SECRET\n\nIf none of these environment variables are set, it will default to \"better-auth-secret-123456789\". In production, if it's not set, it will throw an error.\n\nYou can generate a good secret using the following command:\n\nopenssl rand -base64 32\ndatabase\n\nDatabase configuration for Better Auth.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tdatabase: {\n\t\tdialect: \"postgres\",\n\t\ttype: \"postgres\",\n\t\tcasing: \"camel\"\n\t},\n})\n\nBetter Auth supports various database configurations including PostgreSQL, MySQL, and SQLite.\n\nRead more about databases here.\n\nsecondaryStorage\n\nSecondary storage configuration used to store session and rate limit data.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\t// ... other options\n    secondaryStorage: {\n    \t// Your implementation here\n    },\n})\n\nRead more about secondary storage here.\n\nemailVerification\n\nEmail verification configuration.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\temailVerification: {\n\t\tsendVerificationEmail: async ({ user, url, token }) => {\n\t\t\t// Send verification email to user\n\t\t},\n\t\tsendOnSignUp: true,\n\t\tautoSignInAfterVerification: true,\n\t\texpiresIn: 3600 // 1 hour\n\t},\n})\nsendVerificationEmail: Function to send verification email\nsendOnSignUp: Send verification email automatically after sign up (default: false)\nsendOnSignIn: Send verification email automatically on sign in when the user's email is not verified (default: false)\nautoSignInAfterVerification: Auto sign in the user after they verify their email\nexpiresIn: Number of seconds the verification token is valid for (default: 3600 seconds)\nemailAndPassword\n\nEmail and password authentication configuration.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\temailAndPassword: {\n\t\tenabled: true,\n\t\tdisableSignUp: false,\n\t\trequireEmailVerification: true,\n\t\tminPasswordLength: 8,\n\t\tmaxPasswordLength: 128,\n\t\tautoSignIn: true,\n\t\tsendResetPassword: async ({ user, url, token }) => {\n\t\t\t// Send reset password email\n\t\t},\n\t\tresetPasswordTokenExpiresIn: 3600, // 1 hour\n\t\tpassword: {\n\t\t\thash: async (password) => {\n\t\t\t\t// Custom password hashing\n\t\t\t\treturn hashedPassword;\n\t\t\t},\n\t\t\tverify: async ({ hash, password }) => {\n\t\t\t\t// Custom password verification\n\t\t\t\treturn isValid;\n\t\t\t}\n\t\t}\n\t},\n})\nenabled: Enable email and password authentication (default: false)\ndisableSignUp: Disable email and password sign up (default: false)\nrequireEmailVerification: Require email verification before a session can be created\nminPasswordLength: Minimum password length (default: 8)\nmaxPasswordLength: Maximum password length (default: 128)\nautoSignIn: Automatically sign in the user after sign up\nsendResetPassword: Function to send reset password email\nresetPasswordTokenExpiresIn: Number of seconds the reset password token is valid for (default: 3600 seconds)\npassword: Custom password hashing and verification functions\nsocialProviders\n\nConfigure social login providers.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tsocialProviders: {\n\t\tgoogle: {\n\t\t\tclientId: \"your-client-id\",\n\t\t\tclientSecret: \"your-client-secret\",\n\t\t\tredirectURI: \"https://example.com/api/auth/callback/google\"\n\t\t},\n\t\tgithub: {\n\t\t\tclientId: \"your-client-id\",\n\t\t\tclientSecret: \"your-client-secret\",\n\t\t\tredirectURI: \"https://example.com/api/auth/callback/github\"\n\t\t}\n\t},\n})\nplugins\n\nList of Better Auth plugins.\n\nimport { betterAuth } from \"better-auth\";\nimport { emailOTP } from \"better-auth/plugins\";\nexport const auth = betterAuth({\n\tplugins: [\n\t\temailOTP({\n\t\t\tsendVerificationOTP: async ({ email, otp, type }) => {\n\t\t\t\t// Send OTP to user's email\n\t\t\t}\n\t\t})\n\t],\n})\nuser\n\nUser configuration options.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tuser: {\n\t\tmodelName: \"users\",\n\t\tfields: {\n\t\t\temail: \"emailAddress\",\n\t\t\tname: \"fullName\"\n\t\t},\n\t\tadditionalFields: {\n\t\t\tcustomField: {\n\t\t\t\ttype: \"string\",\n\t\t\t}\n\t\t},\n\t\tchangeEmail: {\n\t\t\tenabled: true,\n\t\t\tsendChangeEmailVerification: async ({ user, newEmail, url, token }) => {\n\t\t\t\t// Send change email verification\n\t\t\t}\n\t\t},\n\t\tdeleteUser: {\n\t\t\tenabled: true,\n\t\t\tsendDeleteAccountVerification: async ({ user, url, token }) => {\n\t\t\t\t// Send delete account verification\n\t\t\t},\n\t\t\tbeforeDelete: async (user) => {\n\t\t\t\t// Perform actions before user deletion\n\t\t\t},\n\t\t\tafterDelete: async (user) => {\n\t\t\t\t// Perform cleanup after user deletion\n\t\t\t}\n\t\t}\n\t},\n})\nmodelName: The model name for the user (default: \"user\")\nfields: Map fields to different column names\nadditionalFields: Additional fields for the user table\nchangeEmail: Configuration for changing email\ndeleteUser: Configuration for user deletion\nsession\n\nSession configuration options.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tsession: {\n\t\tmodelName: \"sessions\",\n\t\tfields: {\n\t\t\tuserId: \"user_id\"\n\t\t},\n\t\texpiresIn: 604800, // 7 days\n\t\tupdateAge: 86400, // 1 day\n\t\tdisableSessionRefresh: true, // Disable session refresh so that the session is not updated regardless of the `updateAge` option. (default: `false`)\n\t\tadditionalFields: { // Additional fields for the session table\n\t\t\tcustomField: {\n\t\t\t\ttype: \"string\",\n\t\t\t}\n\t\t},\n\t\tstoreSessionInDatabase: true, // Store session in database when secondary storage is provided (default: `false`)\n\t\tpreserveSessionInDatabase: false, // Preserve session records in database when deleted from secondary storage (default: `false`)\n\t\tcookieCache: {\n\t\t\tenabled: true, // Enable caching session in cookie (default: `false`)\t\n\t\t\tmaxAge: 300 // 5 minutes\n\t\t}\n\t},\n})\nmodelName: The model name for the session (default: \"session\")\nfields: Map fields to different column names\nexpiresIn: Expiration time for the session token in seconds (default: 604800 - 7 days)\nupdateAge: How often the session should be refreshed in seconds (default: 86400 - 1 day)\nadditionalFields: Additional fields for the session table\nstoreSessionInDatabase: Store session in database when secondary storage is provided (default: false)\npreserveSessionInDatabase: Preserve session records in database when deleted from secondary storage (default: false)\ncookieCache: Enable caching session in cookie\naccount\n\nAccount configuration options.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\taccount: {\n\t\tmodelName: \"accounts\",\n\t\tfields: {\n\t\t\tuserId: \"user_id\"\n\t\t},\n\t\tencryptOAuthTokens: true, // Encrypt OAuth tokens before storing them in the database\n\t\taccountLinking: {\n\t\t\tenabled: true,\n\t\t\ttrustedProviders: [\"google\", \"github\", \"email-password\"],\n\t\t\tallowDifferentEmails: false\n\t\t}\n\t},\n})\nmodelName: The model name for the account\nfields: Map fields to different column names\nencryptOAuthTokens\n\nEncrypt OAuth tokens before storing them in the database. Default: false.\n\nupdateAccountOnSignIn\n\nIf enabled (true), the user account data (accessToken, idToken, refreshToken, etc.) will be updated on sign in with the latest data from the provider.\n\naccountLinking\n\nConfiguration for account linking.\n\nenabled: Enable account linking (default: false)\ntrustedProviders: List of trusted providers\nallowDifferentEmails: Allow users to link accounts with different email addresses\nallowUnlinkingAll: Allow users to unlink all accounts\nverification\n\nVerification configuration options.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tverification: {\n\t\tmodelName: \"verifications\",\n\t\tfields: {\n\t\t\tuserId: \"user_id\"\n\t\t},\n\t\tdisableCleanup: false\n\t},\n})\nmodelName: The model name for the verification table\nfields: Map fields to different column names\ndisableCleanup: Disable cleaning up expired values when a verification value is fetched\nrateLimit\n\nRate limiting configuration.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\trateLimit: {\n\t\tenabled: true,\n\t\twindow: 10,\n\t\tmax: 100,\n\t\tcustomRules: {\n\t\t\t\"/example/path\": {\n\t\t\t\twindow: 10,\n\t\t\t\tmax: 100\n\t\t\t}\n\t\t},\n\t\tstorage: \"memory\",\n\t\tmodelName: \"rateLimit\"\n\t}\n})\nenabled: Enable rate limiting (defaults: true in production, false in development)\nwindow: Time window to use for rate limiting. The value should be in seconds. (default: 10)\nmax: The default maximum number of requests allowed within the window. (default: 100)\ncustomRules: Custom rate limit rules to apply to specific paths.\nstorage: Storage configuration. If you passed a secondary storage, rate limiting will be stored in the secondary storage. (options: \"memory\", \"database\", \"secondary-storage\", default: \"memory\")\nmodelName: The name of the table to use for rate limiting if database is used as storage. (default: \"rateLimit\")\nadvanced\n\nAdvanced configuration options.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tadvanced: {\n\t\tipAddress: {\n\t\t\tipAddressHeaders: [\"x-client-ip\", \"x-forwarded-for\"],\n\t\t\tdisableIpTracking: false\n\t\t},\n\t\tuseSecureCookies: true,\n\t\tdisableCSRFCheck: false,\n\t\tcrossSubDomainCookies: {\n\t\t\tenabled: true,\n\t\t\tadditionalCookies: [\"custom_cookie\"],\n\t\t\tdomain: \"example.com\"\n\t\t},\n\t\tcookies: {\n\t\t\tsession_token: {\n\t\t\t\tname: \"custom_session_token\",\n\t\t\t\tattributes: {\n\t\t\t\t\thttpOnly: true,\n\t\t\t\t\tsecure: true\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\tdefaultCookieAttributes: {\n\t\t\thttpOnly: true,\n\t\t\tsecure: true\n\t\t},\n\t\tcookiePrefix: \"myapp\",\n\t\tdatabase: {\n\t\t\t// If your DB is using auto-incrementing IDs, set this to true.\n\t\t\tuseNumberId: false,\n\t\t\t// Use your own custom ID generator, or disable generating IDs as a whole.\n\t\t\tgenerateId: (((options: {\n\t\t\t\tmodel: LiteralUnion<Models, string>;\n\t\t\t\tsize?: number;\n\t\t\t}) => {\n\t\t\t\treturn \"my-super-unique-id\";\n\t\t\t})) | false,\n\t\t\tdefaultFindManyLimit: 100,\n\t\t}\n\t},\n})\nipAddress: IP address configuration for rate limiting and session tracking\nuseSecureCookies: Use secure cookies (default: false)\ndisableCSRFCheck: Disable trusted origins check (⚠️ security risk)\ncrossSubDomainCookies: Configure cookies to be shared across subdomains\ncookies: Customize cookie names and attributes\ndefaultCookieAttributes: Default attributes for all cookies\ncookiePrefix: Prefix for cookies\ngenerateId: Function to generate a unique ID for a model\nlogger\n\nLogger configuration for Better Auth.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tlogger: {\n\t\tdisabled: false,\n\t\tdisableColors: false,\n\t\tlevel: \"error\",\n\t\tlog: (level, message, ...args) => {\n\t\t\t// Custom logging implementation\n\t\t\tconsole.log(`[${level}] ${message}`, ...args);\n\t\t}\n\t}\n})\n\nThe logger configuration allows you to customize how Better Auth handles logging. It supports the following options:\n\ndisabled: Disable all logging when set to true (default: false)\ndisableColors: Disable colors in the default logger implementation (default: determined by the terminal's color support)\nlevel: Set the minimum log level to display. Available levels are:\n\"info\": Show all logs\n\"warn\": Show warnings and errors\n\"error\": Show only errors\n\"debug\": Show all logs including debug information\nlog: Custom logging function that receives:\nlevel: The log level (\"info\", \"warn\", \"error\", or \"debug\")\nmessage: The log message\n...args: Additional arguments passed to the logger\n\nExample with custom logging:\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tlogger: {\n\t\tlevel: \"info\",\n\t\tlog: (level, message, ...args) => {\n\t\t\t// Send logs to a custom logging service\n\t\t\tmyLoggingService.log({\n\t\t\t\tlevel,\n\t\t\t\tmessage,\n\t\t\t\tmetadata: args,\n\t\t\t\ttimestamp: new Date().toISOString()\n\t\t\t});\n\t\t}\n\t}\n})\ndatabaseHooks\n\nDatabase lifecycle hooks for core operations.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tdatabaseHooks: {\n\t\tuser: {\n\t\t\tcreate: {\n\t\t\t\tbefore: async (user) => {\n\t\t\t\t\t// Modify user data before creation\n\t\t\t\t\treturn { data: { ...user, customField: \"value\" } };\n\t\t\t\t},\n\t\t\t\tafter: async (user) => {\n\t\t\t\t\t// Perform actions after user creation\n\t\t\t\t}\n\t\t\t},\n\t\t\tupdate: {\n\t\t\t\tbefore: async (userData) => {\n\t\t\t\t\t// Modify user data before update\n\t\t\t\t\treturn { data: { ...userData, updatedAt: new Date() } };\n\t\t\t\t},\n\t\t\t\tafter: async (user) => {\n\t\t\t\t\t// Perform actions after user update\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\tsession: {\n\t\t\t// Session hooks\n\t\t},\n\t\taccount: {\n\t\t\t// Account hooks\n\t\t},\n\t\tverification: {\n\t\t\t// Verification hooks\n\t\t}\n\t},\n})\nonAPIError\n\nAPI error handling configuration.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tonAPIError: {\n\t\tthrow: true,\n\t\tonError: (error, ctx) => {\n\t\t\t// Custom error handling\n\t\t\tconsole.error(\"Auth error:\", error);\n\t\t},\n\t\terrorURL: \"/auth/error\"\n\t},\n})\nthrow: Throw an error on API error (default: false)\nonError: Custom error handler\nerrorURL: URL to redirect to on error (default: /api/auth/error)\nhooks\n\nRequest lifecycle hooks.\n\nimport { betterAuth } from \"better-auth\";\nimport { createAuthMiddleware } from \"better-auth/api\";\nexport const auth = betterAuth({\n\thooks: {\n\t\tbefore: createAuthMiddleware(async (ctx) => {\n\t\t\t// Execute before processing the request\n\t\t\tconsole.log(\"Request path:\", ctx.path);\n\t\t}),\n\t\tafter: createAuthMiddleware(async (ctx) => {\n\t\t\t// Execute after processing the request\n\t\t\tconsole.log(\"Response:\", ctx.context.returned);\n\t\t})\n\t},\n})\n\nFor more details and examples, see the Hooks documentation.\n\ndisabledPaths\n\nDisable specific auth paths.\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n\tdisabledPaths: [\"/sign-up/email\", \"/sign-in/email\"],\n})\ntelemetry\n\nEnable or disable Better Auth's telemetry collection. (default: false)\n\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  telemetry: {\n    enabled: false,\n  }\n})\nEdit on GitHub\n\nPrevious Page\n\nOptimize for Performance\n\nNext Page\n\nContributing"
  },
  {
    "title": "Atlassian | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/atlassian",
    "html": "Atlassian\nCopy Markdown\nOpen in\nGet your Credentials\nSign in to your Atlassian account and go to the Atlassian Developer Console\nClick \"Create new app\"\nFill out the app details\nConfigure your redirect URI (e.g., https://yourdomain.com/api/auth/callback/atlassian)\nNote your Client ID and Client Secret\nThe default scope is read:jira-user and offline_access. For additional scopes, refer to the Atlassian OAuth documentation.\n\nMake sure to set the redirect URI to match your application's callback URL. If you change the base path of the auth routes, you should update the redirect URI accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        atlassian: { \n            clientId: process.env.ATLASSIAN_CLIENT_ID as string, \n            clientSecret: process.env.ATLASSIAN_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with Atlassian\n\nTo sign in with Atlassian, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to atlassian.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"atlassian\"\n    })\n}\n\nFor more information about Atlassian's OAuth scopes and API capabilities, refer to the official Atlassian OAuth 2.0 (3LO) apps documentation.\n\nEdit on GitHub\n\nPrevious Page\n\nApple\n\nNext Page\n\nCognito"
  },
  {
    "title": "Apple | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/apple",
    "html": "Apple\nCopy Markdown\nOpen in\nGet your OAuth credentials\n\nTo use Apple sign in, you need a client ID and client secret. You can get them from the Apple Developer Portal.\n\nYou will need an active Apple Developer account to access the developer portal and generate these credentials.\n\nFollow these steps to set up your App ID, Service ID, and generate the key needed for your client secret:\n\nNavigate to Certificates, Identifiers & Profiles: In the Apple Developer Portal, go to the \"Certificates, Identifiers & Profiles\" section.\n\nCreate an App ID:\n\nGo to the Identifiers tab.\nClick the + icon next to Identifiers.\nSelect App IDs, then click Continue.\nSelect App as the type, then click Continue.\nDescription: Enter a name for your app (e.g., \"My Awesome App\"). This name may be displayed to users when they sign in.\nBundle ID: Set a bundle ID. The recommended format is a reverse domain name (e.g., com.yourcompany.yourapp). Using a suffix like .ai (for app identifier) can help with organization but is not required (e.g., com.yourcompany.yourapp.ai).\nScroll down to Capabilities. Select the checkbox for Sign In with Apple.\nClick Continue, then Register.\n\nCreate a Service ID:\n\nGo back to the Identifiers tab.\nClick the + icon.\nSelect Service IDs, then click Continue.\nDescription: Enter a description for this service (e.g., your app name again).\nIdentifier: Set a unique identifier for the service. Use a reverse domain format, distinct from your App ID (e.g., com.yourcompany.yourapp.si, where .si indicates service identifier - this is for your organization and not required). This Service ID will be your clientId.\nClick Continue, then Register.\n\nConfigure the Service ID:\n\nFind the Service ID you just created in the Identifiers list and click on it.\nCheck the Sign In with Apple capability, then click Configure.\nUnder Primary App ID, select the App ID you created earlier (e.g., com.yourcompany.yourapp.ai).\nUnder Domains and Subdomains, list all the root domains you will use for Sign In with Apple (e.g., example.com, anotherdomain.com).\nUnder Return URLs, enter the callback URL. https://yourdomain.com/api/auth/callback/apple. Add all necessary return URLs.\nClick Next, then Done.\nClick Continue, then Save.\n\nCreate a Client Secret Key:\n\nGo to the Keys tab.\nClick the + icon to create a new key.\nKey Name: Enter a name for the key (e.g., \"Sign In with Apple Key\").\nScroll down and select the checkbox for Sign In with Apple.\nClick the Configure button next to Sign In with Apple.\nSelect the Primary App ID you created earlier.\nClick Save, then Continue, then Register.\nDownload the Key: Immediately download the .p8 key file. This file is only available for download once. Note the Key ID (available on the Keys page after creation) and your Team ID (available in your Apple Developer Account settings).\n\nGenerate the Client Secret (JWT): Apple requires a JSON Web Token (JWT) to be generated dynamically using the downloaded .p8 key, the Key ID, and your Team ID. This JWT serves as your clientSecret.\n\nYou can use the guide below from Apple's documentation to understand how to generate this client secret. You can also use our built in generator below to generate the client secret JWT required for 'Sign in with Apple'.\n\nNote: Apple allows a maximum expiration of 6 months (180 days) for the client secret JWT. You will need to regenerate the client secret before it expires to maintain uninterrupted authentication.\n\nConfigure the provider\n\nTo configure the provider, you need to add it to the socialProviders option of the auth instance.\n\nYou also need to add https://appleid.apple.com to the trustedOrigins array in your auth instance configuration to allow communication with Apple's authentication servers.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        apple: { \n            clientId: process.env.APPLE_CLIENT_ID as string, \n            clientSecret: process.env.APPLE_CLIENT_SECRET as string, \n            // Optional\n            appBundleIdentifier: process.env.APPLE_APP_BUNDLE_IDENTIFIER as string, \n        }, \n    },\n    // Add appleid.apple.com to trustedOrigins for Sign In with Apple flows\n    trustedOrigins: [\"https://appleid.apple.com\"], \n})\n\nOn native iOS, it doesn't use the service ID but the app ID (bundle ID) as client ID, so if using the service ID as clientId in signIn.social with idToken, it throws an error: JWTClaimValidationFailed: unexpected \"aud\" claim value. So you need to provide the appBundleIdentifier when you want to sign in with Apple using the ID Token.\n\nUsage\nSign In with Apple\n\nTo sign in with Apple, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to apple.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"apple\"\n    })\n}\nSign In with Apple With ID Token\n\nTo sign in with Apple using the ID Token, you can use the signIn.social function to pass the ID Token.\n\nThis is useful when you have the ID Token from Apple on the client-side and want to use it to sign in on the server.\n\nIf ID token is provided no redirection will happen, and the user will be signed in directly.\n\nauth-client.ts\nawait authClient.signIn.social({\n    provider: \"apple\",\n    idToken: {\n        token: // Apple ID Token,\n        nonce: // Nonce (optional)\n        accessToken: // Access Token (optional)\n    }\n})\nGenerate Apple Client Secret (JWT)\nApple Team ID\nClient ID (Service ID)\n\nThe identifier for the service you created in Apple Developer.\n\nKey ID\n\nThe ID associated with your private key (.p8 file).\n\nPrivate Key Content (.p8 file content)\n\nPaste the entire content of your .p8 private key file here. Ensure it's in PKCS#8 format.\n\nGenerate Apple Client Secret (JWT)\nEdit on GitHub\n\nPrevious Page\n\nSocial Sign-On\n\nNext Page\n\nAtlassian"
  },
  {
    "title": "Cognito | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/cognito",
    "html": "Cognito\nCopy Markdown\nOpen in\nGet your Cognito Credentials\n\nTo integrate with Cognito, you need to set up a User Pool and an App client in the Amazon Cognito Console.\n\nFollow these steps:\n\nGo to the Cognito Console and create a User Pool.\nUnder App clients, create a new App client (note the Client ID and Client Secret if enabled).\nGo to Domain and set a Cognito Hosted UI domain (e.g., your-app.auth.us-east-1.amazoncognito.com).\nIn App client settings, enable:\nAllowed OAuth flows: Authorization code grant\nAllowed OAuth scopes: openid, profile, email\nAdd your callback URL (e.g., http://localhost:3000/api/auth/callback/cognito).\nUser Pool is required for Cognito authentication.\nMake sure the callback URL matches exactly what you configure in Cognito.\nConfigure the provider\n\nConfigure the cognito key in socialProviders key of your auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  socialProviders: {\n    cognito: {\n      clientId: process.env.COGNITO_CLIENT_ID as string, \n      clientSecret: process.env.COGNITO_CLIENT_SECRET as string, \n      domain: process.env.COGNITO_DOMAIN as string, // e.g. \"your-app.auth.us-east-1.amazoncognito.com\"\n      region: process.env.COGNITO_REGION as string, // e.g. \"us-east-1\"\n      userPoolId: process.env.COGNITO_USERPOOL_ID as string, \n    },\n  },\n})\nSign In with Cognito\n\nTo sign in with Cognito, use the signIn.social function from the client.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient = createAuthClient()\nconst signIn = async () => {\n  const data = await authClient.signIn.social({\n    provider: \"cognito\"\n  })\n}\nAdditional Options:\nscope: Additional OAuth2 scopes to request (combined with default permissions).\nDefault: \"openid\" \"profile\" \"email\"\nCommon Cognito scopes:\nopenid: Required for OpenID Connect authentication\nprofile: Access to basic profile info\nemail: Access to user’s email\nphone: Access to user’s phone number\naws.cognito.signin.user.admin: Grants access to Cognito-specific APIs\nNote: You must configure the scopes in your Cognito App Client settings. available scopes\ngetUserInfo: Custom function to retrieve user information from the Cognito UserInfo endpoint.\n\nFor more information about Amazon Cognito's scopes and API capabilities, refer to the official documentation.\n\nEdit on GitHub\n\nPrevious Page\n\nAtlassian\n\nNext Page\n\nDiscord"
  },
  {
    "title": "Discord | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/discord",
    "html": "Discord\nCopy Markdown\nOpen in\nGet your Discord credentials\n\nTo use Discord sign in, you need a client ID and client secret. You can get them from the Discord Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/discord for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({ \n    socialProviders: {\n        discord: { \n            clientId: process.env.DISCORD_CLIENT_ID as string, \n            clientSecret: process.env.DISCORD_CLIENT_SECRET as string, \n        }, \n    },\n})\nUsage\nSign In with Discord\n\nTo sign in with Discord, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to discord.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"discord\"\n    })\n}\nOptions\n\nFor the full list of options supported by all social providers, check the Provider Options.\n\nBot Permissions (Optional)\n\nIf you're using the bot scope with Discord OAuth, you can specify bot permissions using the permissions option. It can either be a bitwise value (e.g 2048 | 16384 for Send Messages and Embed Links) or a specific permission value (e.g 16384 for Embed Links).\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({ \n    socialProviders: {\n        discord: {\n            clientId: process.env.DISCORD_CLIENT_ID as string,\n            clientSecret: process.env.DISCORD_CLIENT_SECRET as string,\n            permissions: 2048 | 16384, // Send Messages + Embed Links\n        }, \n    },\n})\n\nNote: The permissions parameter only works when the bot scope is included in your OAuth2 scopes. Read more about Discord bot permissions.\n\nEdit on GitHub\n\nPrevious Page\n\nCognito\n\nNext Page\n\nFacebook"
  },
  {
    "title": "Figma | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/figma",
    "html": "Figma\nCopy Markdown\nOpen in\nGet your Credentials\nSign in to your Figma account and go to the Developer Apps page\nClick \"Create new app\"\nFill out the app details (name, description, etc.)\nConfigure your redirect URI (e.g., https://yourdomain.com/api/auth/callback/figma)\nNote your Client ID and Client Secret\nThe default scope is file_read. For additional scopes like file_write, refer to the Figma OAuth documentation.\n\nMake sure to set the redirect URI to match your application's callback URL. If you change the base path of the auth routes, you should update the redirect URI accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        figma: { \n            clientId: process.env.FIGMA_CLIENT_ID as string, \n            clientSecret: process.env.FIGMA_CLIENT_SECRET as string, \n            clientKey: process.env.FIGMA_CLIENT_KEY as string, \n        }, \n    },\n})\nSign In with Figma\n\nTo sign in with Figma, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to figma.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"figma\"\n    })\n}\n\nFor more information about Figma's OAuth scopes and API capabilities, refer to the official Figma API documentation.\n\nEdit on GitHub\n\nPrevious Page\n\nFacebook\n\nNext Page\n\nGitHub"
  },
  {
    "title": "Facebook | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/facebook",
    "html": "Facebook\nCopy Markdown\nOpen in\nGet your Facebook credentials\n\nTo use Facebook sign in, you need a client ID and client Secret. You can get them from the Facebook Developer Portal. Select your app, navigate to App Settings > Basic, locate the following:\n\nApp ID: This is your clientId\nApp Secret: This is your clientSecret.\n\nAvoid exposing the clientSecret in client-side code (e.g., frontend apps) because it’s sensitive information.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/facebook for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        facebook: { \n            clientId: process.env.FACEBOOK_CLIENT_ID as string, \n            clientSecret: process.env.FACEBOOK_CLIENT_SECRET as string, \n        }, \n    },\n})\n\nBetterAuth also supports Facebook Login for Business, all you need to do is provide the configId as listed in Facebook Login For Business > Configurations alongside your clientId and clientSecret. Note that the app must be a Business app and, since BetterAuth expects to have an email address and account id, the configuration must be of the \"User access token\" type. \"System-user access token\" is not supported.\n\nSign In with Facebook\n\nTo sign in with Facebook, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to facebook.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/auth-client\"\nconst authClient = createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"facebook\"\n    })\n}\nAdditional Configuration\nScopes\n\nBy default, Facebook provides basic user information. If you need additional permissions, you can specify scopes in your auth configuration:\n\nauth.ts\nexport const auth = betterAuth({\n    socialProviders: {\n        facebook: {\n            clientId: process.env.FACEBOOK_CLIENT_ID as string,\n            clientSecret: process.env.FACEBOOK_CLIENT_SECRET as string,\n            scopes: [\"email\", \"public_profile\", \"user_friends\"], // Overwrites permissions\n            fields: [\"user_friends\"], // Extending list of fields\n        },\n    },\n})\n\nAdditional options:\n\nscopes: Access basic account information (overwrites).\nDefault: \"email\", \"public_profile\"\nfields: Extend list of fields to retrieve from the Facebook user profile (assignment).\nDefault: \"id\", \"name\", \"email\", \"picture\"\nSign In with Facebook With ID or Access Token\n\nTo sign in with Facebook using the ID Token, you can use the signIn.social function to pass the ID Token.\n\nThis is useful when you have the ID Token from Facebook on the client-side and want to use it to sign in on the server.\n\nIf ID token is provided no redirection will happen, and the user will be signed in directly.\n\nFor limited login, you need to pass idToken.token, for only accessToken you need to pass idToken.accessToken and idToken.token together because of (#1183)[https://github.com/better-auth/better-auth/issues/1183].\n\nauth-client.ts\nconst data = await authClient.signIn.social({\n    provider: \"facebook\",\n    idToken: {  \n        ...(platform === 'ios' ?\n            { token: idToken }  \n            : { token: accessToken, accessToken: accessToken }), \n    },\n})\n\nFor a complete list of available permissions, refer to the Permissions Reference.\n\nEdit on GitHub\n\nPrevious Page\n\nDiscord\n\nNext Page\n\nFigma"
  },
  {
    "title": "GitHub | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/github",
    "html": "GitHub\nCopy Markdown\nOpen in\nGet your GitHub credentials\n\nTo use GitHub sign in, you need a client ID and client secret. You can get them from the GitHub Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/github for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nImportant: You MUST include the user:email scope in your GitHub app. See details below.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        github: { \n            clientId: process.env.GITHUB_CLIENT_ID as string, \n            clientSecret: process.env.GITHUB_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with GitHub\n\nTo sign in with GitHub, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to github.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"github\"\n    })\n}\nUsage\nSetting up your Github app\n\nGithub has two types of apps: Github apps and OAuth apps.\n\nFor OAuth apps, you don't have to do anything special (just follow the steps above). For Github apps, you DO have to add one more thing, which is enable it to read the user's email:\n\nAfter creating your app, go to Permissions and Events > Account Permissions > Email Addresses and select \"Read-Only\"\n\nSave changes.\n\nThat's all! Now you can copy the Client ID and Client Secret of your app!\n\nIf you get \"email_not_found\" error, it's because you selected a Github app & did not configure this part!\n\nWhy don't I have a refresh token?\n\nGithub doesn't issue refresh tokens for OAuth apps. For regular OAuth apps, GitHub issues access tokens that remain valid indefinitely unless the user revokes them, the app revokes them, or they go unused for a year. There's no need for a refresh token because the access token doesn't expire on a short interval like Google or Discord.\n\nEdit on GitHub\n\nPrevious Page\n\nFigma\n\nNext Page\n\nGoogle"
  },
  {
    "title": "Google | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/google",
    "html": "Google\nCopy Markdown\nOpen in\nGet your Google credentials\n\nTo use Google as a social provider, you need to get your Google credentials. You can get them by creating a new project in the Google Cloud Console.\n\nIn the Google Cloud Console > Credentials > Authorized redirect URIs, make sure to set the redirect URL to http://localhost:3000/api/auth/callback/google for local development. For production, make sure to set the redirect URL as your application domain, e.g. https://example.com/api/auth/callback/google. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to pass the clientId and clientSecret to socialProviders.google in your auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        google: { \n            clientId: process.env.GOOGLE_CLIENT_ID as string, \n            clientSecret: process.env.GOOGLE_CLIENT_SECRET as string, \n        }, \n    },\n})\nUsage\nSign In with Google\n\nTo sign in with Google, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to google.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nconst authClient = createAuthClient();\nconst signIn = async () => {\n  const data = await authClient.signIn.social({\n    provider: \"google\",\n  });\n};\nSign In with Google With ID Token\n\nTo sign in with Google using the ID Token, you can use the signIn.social function to pass the ID Token.\n\nThis is useful when you have the ID Token from Google on the client-side and want to use it to sign in on the server.\n\nIf ID token is provided no redirection will happen, and the user will be signed in directly.\n\nauth-client.ts\nconst data = await authClient.signIn.social({\n    provider: \"google\",\n    idToken: {\n        token: // Google ID Token,\n        accessToken: // Google Access Token\n    }\n})\n\nIf you want to use google one tap, you can use the One Tap Plugin guide.\n\nAlways ask to select an account\n\nIf you want to always ask the user to select an account, you pass the prompt parameter to the provider, setting it to select_account.\n\nsocialProviders: {\n    google: {\n        prompt: \"select_account\", \n        clientId: process.env.GOOGLE_CLIENT_ID as string,\n        clientSecret: process.env.GOOGLE_CLIENT_SECRET as string,\n    },\n}\nRequesting Additional Google Scopes\n\nIf your application needs additional Google scopes after the user has already signed up (e.g., for Google Drive, Gmail, or other Google services), you can request them using the linkSocial method with the same Google provider.\n\nauth-client.ts\nconst requestGoogleDriveAccess = async () => {\n  await authClient.linkSocial({\n    provider: \"google\",\n    scopes: [\"https://www.googleapis.com/auth/drive.file\"],\n  });\n};\n// Example usage in a React component\nreturn (\n  <button onClick={requestGoogleDriveAccess}>\n    Add Google Drive Permissions\n  </button>\n);\n\nThis will trigger a new OAuth flow that requests the additional scopes. After completion, your account will have the new scope in the database, and the access token will give you access to the requested Google APIs.\n\nEnsure you're using Better Auth version 1.2.7 or later to avoid \"Social account already linked\" errors when requesting additional scopes from the same provider.\n\nAlways get refresh token\n\nGoogle only issues a refresh token the first time a user consents to your app. If the user has already authorized your app, subsequent OAuth flows will only return an access token, not a refresh token.\n\nTo always get a refresh token, you can set the accessType to offline, and prompt to select_account consent in the provider options.\n\nsocialProviders: {\n    google: {\n        clientId: process.env.GOOGLE_CLIENT_ID as string,\n        clientSecret: process.env.GOOGLE_CLIENT_SECRET as string,\n        accessType: \"offline\", \n        prompt: \"select_account consent\", \n    },\n}\n\nRevoking Access: If you want to get a new refresh token for a user who has already authorized your app, you must have them revoke your app's access in their Google account settings, then re-authorize.\n\nEdit on GitHub\n\nPrevious Page\n\nGitHub\n\nNext Page\n\nLINE"
  },
  {
    "title": "LINE | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/line",
    "html": "LINE\nCopy Markdown\nOpen in\nGet your LINE credentials\nCreate a channel in the LINE Developers Console.\nNote your Channel ID (client_id) and Channel secret (client_secret).\nIn the channel settings, add your Redirect URI, e.g. http://localhost:3000/api/auth/callback/line for local development.\nEnable required scopes (at least openid; add profile, email if you need name, avatar, email).\n\nSee LINE Login v2.1 reference for details: [https://developers.line.biz/en/reference/line-login/#issue-access-token]\n\nConfigure the provider\n\nAdd your LINE credentials to socialProviders.line in your auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  socialProviders: {\n    line: {\n      clientId: process.env.LINE_CLIENT_ID as string,\n      clientSecret: process.env.LINE_CLIENT_SECRET as string,\n      // Optional: override redirect if needed\n      // redirectURI: \"https://your.app/api/auth/callback/line\",\n      // scopes are prefilled: [\"openid\",\"profile\",\"email\"]. Append if needed\n    },\n  },\n});\nUsage\nSign In with LINE\n\nUse the client signIn.social with provider: \"line\".\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nconst authClient = createAuthClient();\nasync function signInWithLINE() {\n  const res = await authClient.signIn.social({ provider: \"line\" });\n}\nSign In with LINE using ID Token (optional)\n\nIf you obtain the LINE ID token on the client, you can sign in directly without redirection.\n\nauth-client.ts\nawait authClient.signIn.social({\n  provider: \"line\",\n  idToken: {\n    token: \"<LINE_ID_TOKEN>\",\n    accessToken: \"<LINE_ACCESS_TOKEN>\",\n  },\n});\nNotes\nDefault scopes include openid profile email. Adjust as needed via provider options.\nVerify redirect URI exactly matches the value configured in LINE Developers Console.\nLINE ID token verification uses the official endpoint and checks audience and optional nonce per spec.\n\nDesigning a login button? Follow LINE's button guidelines.\n\nEdit on GitHub\n\nPrevious Page\n\nGoogle\n\nNext Page\n\nHugging Face"
  },
  {
    "title": "Hugging Face | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/huggingface",
    "html": "Hugging Face\nCopy Markdown\nOpen in\nGet your Hugging Face credentials\n\nTo use Hugging Face sign in, you need a client ID and client secret. Hugging Face OAuth documentation. Make sure the created oauth app on Hugging Face has the \"email\" scope.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/huggingface for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        huggingface: { \n            clientId: process.env.HUGGINGFACE_CLIENT_ID as string, \n            clientSecret: process.env.HUGGINGFACE_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with Hugging Face\n\nTo sign in with Hugging Face, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to huggingface.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"huggingface\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nLINE\n\nNext Page\n\nKakao"
  },
  {
    "title": "Kakao | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/kakao",
    "html": "Kakao\nCopy Markdown\nOpen in\nGet your Kakao Credentials\n\nTo use Kakao sign in, you need a client ID and client secret. You can get them from the Kakao Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/kakao for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        kakao: { \n            clientId: process.env.KAKAO_CLIENT_ID as string, \n            clientSecret: process.env.KAKAO_CLIENT_SECRET as string, \n        }, \n    }\n})\nSign In with Kakao\n\nTo sign in with Kakao, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to kakao.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"kakao\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nHugging Face\n\nNext Page\n\nKick"
  },
  {
    "title": "Kick | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/kick",
    "html": "Kick\nCopy Markdown\nOpen in\nGet your Kick Credentials\n\nTo use Kick sign in, you need a client ID and client secret. You can get them from the Kick Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/kick for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        kick: { \n            clientId: process.env.KICK_CLIENT_ID as string, \n            clientSecret: process.env.KICK_CLIENT_SECRET as string, \n        }, \n    }\n})\nSign In with Kick\n\nTo sign in with Kick, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to kick.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"kick\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nKakao\n\nNext Page\n\nMicrosoft"
  },
  {
    "title": "Microsoft | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/microsoft",
    "html": "Microsoft\nCopy Markdown\nOpen in\n\nEnabling OAuth with Microsoft Azure Entra ID (formerly Active Directory) allows your users to sign in and sign up to your application with their Microsoft account.\n\nGet your Microsoft credentials\n\nTo use Microsoft as a social provider, you need to get your Microsoft credentials. Which involves generating your own Client ID and Client Secret using your Microsoft Entra ID dashboard account.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/microsoft for local development. For production, you should change it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nsee the Microsoft Entra ID documentation for more information.\n\nConfigure the provider\n\nTo configure the provider, you need to pass the clientId and clientSecret to socialProviders.microsoft in your auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        microsoft: { \n            clientId: process.env.MICROSOFT_CLIENT_ID as string, \n            clientSecret: process.env.MICROSOFT_CLIENT_SECRET as string, \n            // Optional\n            tenantId: 'common', \n            authority: \"https://login.microsoftonline.com\", // Authentication authority URL\n            prompt: \"select_account\", // Forces account selection\n        }, \n    },\n})\n\nAuthority URL: Use the default https://login.microsoftonline.com for standard Entra ID scenarios or https://<tenant-id>.ciamlogin.com for CIAM (Customer Identity and Access Management) scenarios.\n\nSign In with Microsoft\n\nTo sign in with Microsoft, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to microsoft.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nconst authClient = createAuthClient();\nconst signIn = async () => {\n  const data = await authClient.signIn.social({\n    provider: \"microsoft\",\n    callbackURL: \"/dashboard\", // The URL to redirect to after the sign in\n  });\n};\nEdit on GitHub\n\nPrevious Page\n\nKick\n\nNext Page\n\nPayPal"
  },
  {
    "title": "PayPal | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/paypal",
    "html": "PayPal\nCopy Markdown\nOpen in\nGet your PayPal Credentials\n\nTo integrate with PayPal, you need to obtain API credentials by creating an application in the PayPal Developer Portal.\n\nFollow these steps:\n\nCreate an account on the PayPal Developer Portal\nCreate a new application, official docs\nConfigure Log in with PayPal under \"Other features\"\nSet up your Return URL (redirect URL)\nConfigure user information permissions\nNote your Client ID and Client Secret\nPayPal has two environments: Sandbox (for testing) and Live (for production)\nFor testing, create sandbox test accounts in the Developer Dashboard under \"Sandbox\" → \"Accounts\"\nYou cannot use your real PayPal account to test in sandbox mode - you must use the generated test accounts\nThe Return URL in your PayPal app settings must exactly match your redirect URI\nThe PayPal API does not work with localhost. You need to use a public domain for the redirect URL and HTTPS for local testing. You can use NGROK or another similar tool for this.\n\nMake sure to configure \"Log in with PayPal\" in your app settings:\n\nGo to your app in the Developer Dashboard\nUnder \"Other features\", check \"Log in with PayPal\"\nClick \"Advanced Settings\"\nEnter your Return URL\nSelect the user information you want to access (email, name, etc.)\nEnter Privacy Policy and User Agreement URLs\nPayPal doesn't use traditional OAuth2 scopes in the authorization URL. Instead, you configure permissions directly in the Developer Dashboard\nFor live apps, PayPal must review and approve your application before it can go live, which typically takes a few weeks\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        paypal: { \n            clientId: process.env.PAYPAL_CLIENT_ID as string, \n            clientSecret: process.env.PAYPAL_CLIENT_SECRET as string, \n            environment: \"sandbox\", // or \"live\" for production //,\n        }, \n    },\n})\nOptions\n\nThe PayPal provider accepts the following options:\n\nenvironment: 'sandbox' | 'live' - PayPal environment to use (default: 'sandbox')\nrequestShippingAddress: boolean - Whether to request shipping address information (default: false)\nauth.ts\nexport const auth = betterAuth({\n    socialProviders: {\n        paypal: {\n            clientId: process.env.PAYPAL_CLIENT_ID as string,\n            clientSecret: process.env.PAYPAL_CLIENT_SECRET as string,\n            environment: \"live\", // Use \"live\" for production\n            requestShippingAddress: true, // Request address info\n        },\n    },\n})\nSign In with PayPal\n\nTo sign in with PayPal, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to paypal.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"paypal\"\n    })\n}\nAdditional Options:\nenvironment: PayPal environment to use.\nDefault: \"sandbox\"\nOptions: \"sandbox\" | \"live\"\nrequestShippingAddress: Whether to request shipping address information.\nDefault: false\nscope: Additional scopes to request (combined with default permissions).\nDefault: Configured in PayPal Developer Dashboard\nNote: PayPal doesn't use traditional OAuth2 scopes - permissions are set in the Dashboard For more details refer to the Scopes Reference\nmapProfileToUser: Custom function to map PayPal profile data to user object.\ngetUserInfo: Custom function to retrieve user information. For more details refer to the User Reference\nverifyIdToken: Custom ID token verification function.\nEdit on GitHub\n\nPrevious Page\n\nMicrosoft\n\nNext Page\n\nSalesforce"
  },
  {
    "title": "Salesforce | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/salesforce",
    "html": "Salesforce\nCopy Markdown\nOpen in\nGet your Salesforce Credentials\nLog into your Salesforce org (Production or Developer Edition)\nNavigate to Setup > App Manager\nClick New Connected App\nFill in the basic information:\nConnected App Name: Your app name\nAPI Name: Auto-generated from app name\nContact Email: Your email address\nEnable OAuth Settings:\nCheck Enable OAuth Settings\nSet Callback URL to your redirect URI (e.g., http://localhost:3000/api/auth/callback/salesforce for development)\nSelect Required OAuth Scopes:\nAccess your basic information (id)\nAccess your identity URL service (openid)\nAccess your email address (email)\nPerform requests on your behalf at any time (refresh_token, offline_access)\nEnable Require Proof Key for Code Exchange (PKCE) (required)\nSave and note your Consumer Key (Client ID) and Consumer Secret (Client Secret)\nFor development, you can use http://localhost:3000 URLs, but production requires HTTPS\nThe callback URL must exactly match what's configured in Better Auth\nPKCE (Proof Key for Code Exchange) is required by Salesforce and is automatically handled by the provider\n\nFor sandbox testing, you can create the Connected App in your sandbox org, or use the same Connected App but specify environment: \"sandbox\" in the provider configuration.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        salesforce: { \n            clientId: process.env.SALESFORCE_CLIENT_ID as string, \n            clientSecret: process.env.SALESFORCE_CLIENT_SECRET as string, \n            environment: \"production\", // or \"sandbox\"\n        }, \n    },\n})\nConfiguration Options\nclientId: Your Connected App's Consumer Key\nclientSecret: Your Connected App's Consumer Secret\nenvironment: \"production\" (default) or \"sandbox\"\nloginUrl: Custom My Domain URL (without https://) - overrides environment setting\nredirectURI: Override the auto-generated redirect URI if needed\nAdvanced Configuration\nauth.ts\nexport const auth = betterAuth({\n    socialProviders: {\n        salesforce: {\n            clientId: process.env.SALESFORCE_CLIENT_ID as string,\n            clientSecret: process.env.SALESFORCE_CLIENT_SECRET as string,\n            environment: \"sandbox\", \n            loginUrl: \"mycompany.my.salesforce.com\", // Custom My Domain\n            redirectURI: \"http://localhost:3000/api/auth/callback/salesforce\", // Override if needed\n        },\n    },\n})\nUse environment: \"sandbox\" for testing with Salesforce sandbox orgs\nThe loginUrl option is useful for organizations with My Domain enabled\nThe redirectURI option helps resolve redirect URI mismatch errors\nEnvironment Variables\n\nAdd the following environment variables to your .env.local file:\n\n.env.local\nSALESFORCE_CLIENT_ID=your_consumer_key_here\nSALESFORCE_CLIENT_SECRET=your_consumer_secret_here\nBETTER_AUTH_URL=http://localhost:3000 # Important for redirect URI generation\n\nFor production:\n\n.env\nSALESFORCE_CLIENT_ID=your_consumer_key_here\nSALESFORCE_CLIENT_SECRET=your_consumer_secret_here\nBETTER_AUTH_URL=https://yourdomain.com\nSign In with Salesforce\n\nTo sign in with Salesforce, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to salesforce.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient = createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"salesforce\"\n    })\n}\nTroubleshooting\nRedirect URI Mismatch Error\n\nIf you encounter a redirect_uri_mismatch error:\n\nCheck Callback URL: Ensure the Callback URL in your Salesforce Connected App exactly matches your Better Auth callback URL\nProtocol: Make sure you're using the same protocol (http:// vs https://)\nPort: Verify the port number matches (e.g., :3000)\nOverride if needed: Use the redirectURI option to explicitly set the redirect URI\nsalesforce: {\n    clientId: process.env.SALESFORCE_CLIENT_ID as string,\n    clientSecret: process.env.SALESFORCE_CLIENT_SECRET as string,\n    redirectURI: \"http://localhost:3000/api/auth/callback/salesforce\", \n}\nEnvironment Issues\nProduction: Use environment: \"production\" (default) with login.salesforce.com\nSandbox: Use environment: \"sandbox\" with test.salesforce.com\nMy Domain: Use loginUrl: \"yourcompany.my.salesforce.com\" for custom domains\nPKCE Requirements\n\nSalesforce requires PKCE (Proof Key for Code Exchange) which is automatically handled by this provider. Make sure PKCE is enabled in your Connected App settings.\n\nThe default scopes requested are openid, email, and profile. The provider will automatically include the id scope for accessing basic user information.\n\nEdit on GitHub\n\nPrevious Page\n\nPayPal\n\nNext Page\n\nSlack"
  },
  {
    "title": "Slack | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/slack",
    "html": "Slack\nCopy Markdown\nOpen in\nGet your Slack credentials\n\nTo use Slack as a social provider, you need to create a Slack app and get your credentials.\n\nGo to Your Apps on Slack API and click \"Create New App\"\nChoose \"From scratch\" and give your app a name and select a development workspace\nIn your app settings, navigate to \"OAuth & Permissions\"\nUnder \"Redirect URLs\", add your redirect URL:\nFor local development: http://localhost:3000/api/auth/callback/slack\nFor production: https://yourdomain.com/api/auth/callback/slack\nCopy your Client ID and Client Secret from the \"Basic Information\" page\n\nSlack requires HTTPS for redirect URLs in production. For local development, you can use tools like ngrok to create a secure tunnel.\n\nConfigure the provider\n\nTo configure the provider, you need to pass the clientId and clientSecret to socialProviders.slack in your auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        slack: { \n            clientId: process.env.SLACK_CLIENT_ID as string, \n            clientSecret: process.env.SLACK_CLIENT_SECRET as string, \n        }, \n    },\n})\nUsage\nSign In with Slack\n\nTo sign in with Slack, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to slack.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nconst authClient = createAuthClient();\nconst signIn = async () => {\n  const data = await authClient.signIn.social({ provider: \"slack\" });\n};\nRequesting Additional Scopes\n\nBy default, Slack uses OpenID Connect scopes: openid, profile, and email. You can request additional Slack scopes during sign-in:\n\nauth-client.ts\nconst signInWithSlack = async () => {\n  await authClient.signIn.social({\n    provider: \"slack\",\n    scopes: [\"channels:read\", \"chat:write\"], // Additional Slack API scopes\n  });\n};\nWorkspace-Specific Sign In\n\nIf you want to restrict sign-in to a specific Slack workspace, you can pass the team parameter:\n\nauth.ts\nsocialProviders: {\n    slack: {\n        clientId: process.env.SLACK_CLIENT_ID as string,\n        clientSecret: process.env.SLACK_CLIENT_SECRET as string,\n        team: \"T1234567890\", // Your Slack workspace ID\n    },\n}\nUsing Slack API After Sign In\n\nAfter successful authentication, you can access the user's Slack information through the session. The access token can be used to make requests to the Slack API:\n\nconst session = await authClient.getSession();\nif (session?.user) {\n  // Access Slack-specific data\n  const slackUserId = session.user.id; // This is the Slack user ID\n  // The access token is stored securely on the server\n}\n\nThe Slack provider uses OpenID Connect by default, which provides basic user information. If you need to access other Slack APIs, make sure to request the appropriate scopes during sign-in.\n\nEdit on GitHub\n\nPrevious Page\n\nSalesforce\n\nNext Page\n\nNotion"
  },
  {
    "title": "Notion | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/notion",
    "html": "Notion\nCopy Markdown\nOpen in\nGet your Notion credentials\n\nTo use Notion as a social provider, you need to get your Notion OAuth credentials. You can get them by creating a new integration in the Notion Developers Portal.\n\nIn the Notion integration settings > OAuth Domain & URIs, make sure to set the redirect URL to http://localhost:3000/api/auth/callback/notion for local development. For production, make sure to set the redirect URL as your application domain, e.g. https://example.com/api/auth/callback/notion. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nMake sure your Notion integration has the appropriate capabilities enabled. For user authentication, you'll need the \"Read user information including email addresses\" capability.\n\nConfigure the provider\n\nTo configure the provider, you need to pass the clientId and clientSecret to socialProviders.notion in your auth configuration.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        notion: { \n            clientId: process.env.NOTION_CLIENT_ID as string, \n            clientSecret: process.env.NOTION_CLIENT_SECRET as string, \n        }, \n    },\n})\nUsage\nSign In with Notion\n\nTo sign in with Notion, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to notion.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"notion\"\n    })\n}\nNotion Integration Types\n\nNotion supports different integration types. When creating your integration, you can choose between:\n\nPublic integrations: Can be installed by any Notion workspace\nInternal integrations: Limited to your own workspace\n\nFor most authentication use cases, you'll want to create a public integration to allow users from different workspaces to sign in.\n\nRequesting Additional Notion Scopes\n\nIf your application needs additional Notion capabilities after the user has already signed up, you can request them using the linkSocial method with the same Notion provider and additional scopes.\n\nauth-client.ts\nconst requestNotionAccess = async () => {\n    await authClient.linkSocial({\n        provider: \"notion\",\n        // Notion automatically provides access based on integration capabilities\n    });\n};\n// Example usage in a React component\nreturn <button onClick={requestNotionAccess}>Connect Notion Workspace</button>;\n\nAfter authentication, you can use the access token to interact with the Notion API to read and write pages, databases, and other content that the user has granted access to.\n\nEdit on GitHub\n\nPrevious Page\n\nSlack\n\nNext Page\n\nNaver"
  },
  {
    "title": "Naver | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/naver",
    "html": "Naver\nCopy Markdown\nOpen in\nGet your Naver Credentials\n\nTo use Naver sign in, you need a client ID and client secret. You can get them from the Naver Developers.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/naver for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        naver: { \n            clientId: process.env.NAVER_CLIENT_ID as string, \n            clientSecret: process.env.NAVER_CLIENT_SECRET as string, \n        }, \n    }\n})\nSign In with Naver\n\nTo sign in with Naver, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to naver.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"naver\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nNotion\n\nNext Page\n\nTiktok"
  },
  {
    "title": "TikTok | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/tiktok",
    "html": "TikTok\nCopy Markdown\nOpen in\nGet your TikTok Credentials\n\nTo integrate with TikTok, you need to obtain API credentials by creating an application in the TikTok Developer Portal.\n\nFollow these steps:\n\nCreate an account on the TikTok Developer Portal\nCreate a new application\nSet up a sandbox environment for testing\nConfigure your redirect URL (must be HTTPS)\nNote your Client Secret and Client Key\nThe TikTok API does not work with localhost. You need to use a public domain for the redirect URL and HTTPS for local testing. You can use NGROK or another similar tool for this.\nFor testing, you will need to use the Sandbox mode, which you can enable in the TikTok Developer Portal.\nThe default scope is user.info.profile. For additional scopes, refer to the Available Scopes documentation.\n\nMake sure to set the redirect URL to a valid HTTPS domain for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nThe TikTok API does not provide email addresses. As a workaround, this implementation uses the user's username value for the email field, which is why it requires the user.info.profile scope instead of just user.info.basic.\nFor production use, you will need to request approval from TikTok for the scopes you intend to use.\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        tiktok: { \n            clientSecret: process.env.TIKTOK_CLIENT_SECRET as string, \n            clientKey: process.env.TIKTOK_CLIENT_KEY as string, \n        }, \n    },\n})\nSign In with TikTok\n\nTo sign in with TikTok, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to tiktok.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"tiktok\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nNaver\n\nNext Page\n\nTwitch"
  },
  {
    "title": "Twitch | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/twitch",
    "html": "Twitch\nCopy Markdown\nOpen in\nGet your Twitch Credentials\n\nTo use Twitch sign in, you need a client ID and client secret. You can get them from the Twitch Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/twitch for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        twitch: { \n            clientId: process.env.TWITCH_CLIENT_ID as string, \n            clientSecret: process.env.TWITCH_CLIENT_SECRET as string, \n        }, \n    }\n})\nSign In with Twitch\n\nTo sign in with Twitch, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to twitch.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"twitch\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nTiktok\n\nNext Page\n\nTwitter (X)"
  },
  {
    "title": "Twitter (X) | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/twitter",
    "html": "Twitter (X)\nCopy Markdown\nOpen in\nGet your Twitter Credentials\n\nGet your Twitter credentials from the Twitter Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/twitter for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nTwitter API v2 now supports email address retrieval. Make sure to request the user.email scope when configuring your Twitter app to enable this feature.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\" \nexport const auth = betterAuth({\n    socialProviders: {\n        twitter: { \n            clientId: process.env.TWITTER_CLIENT_ID as string, \n            clientSecret: process.env.TWITTER_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with Twitter\n\nTo sign in with Twitter, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to twitter.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"twitter\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nTwitch\n\nNext Page\n\nDropbox"
  },
  {
    "title": "Dropbox | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/dropbox",
    "html": "Dropbox\nCopy Markdown\nOpen in\nGet your Dropbox credentials\n\nTo use Dropbox sign in, you need a client ID and client secret. You can get them from the Dropbox Developer Portal. You can Allow \"Implicit Grant & PKCE\" for the application in the App Console.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/dropbox for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nIf you need deeper dive into Dropbox Authentication, you can check out the official documentation.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        dropbox: { \n            clientId: process.env.DROPBOX_CLIENT_ID as string, \n            clientSecret: process.env.DROPBOX_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with Dropbox\n\nTo sign in with Dropbox, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to dropbox.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"dropbox\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nTwitter (X)\n\nNext Page\n\nLinear"
  },
  {
    "title": "Linear | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/linear",
    "html": "Linear\nCopy Markdown\nOpen in\nGet your Linear credentials\n\nTo use Linear sign in, you need a client ID and client secret. You can get them from the Linear Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/linear for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nWhen creating your OAuth application in Linear, you'll need to specify the required scopes. The default scope is read, but you can also request additional scopes like write if needed.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        linear: { \n            clientId: process.env.LINEAR_CLIENT_ID as string, \n            clientSecret: process.env.LINEAR_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with Linear\n\nTo sign in with Linear, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to linear.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient = createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"linear\"\n    })\n}\nAvailable scopes\n\nLinear OAuth supports the following scopes:\n\nread (default): Read access for the user's account\nwrite: Write access for the user's account\nissues:create: Allows creating new issues and their attachments\ncomments:create: Allows creating new issue comments\ntimeSchedule:write: Allows creating and modifying time schedules\nadmin: Full access to admin level endpoints (use with caution)\n\nYou can specify additional scopes when configuring the provider:\n\nauth.ts\nexport const auth = betterAuth({\n    socialProviders: {\n        linear: {\n            clientId: process.env.LINEAR_CLIENT_ID as string,\n            clientSecret: process.env.LINEAR_CLIENT_SECRET as string,\n            scope: [\"read\", \"write\"] \n        },\n    },\n})\nEdit on GitHub\n\nPrevious Page\n\nDropbox\n\nNext Page\n\nLinkedIn"
  },
  {
    "title": "LinkedIn | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/linkedin",
    "html": "LinkedIn\nCopy Markdown\nOpen in\nGet your LinkedIn credentials\n\nTo use LinkedIn sign in, you need a client ID and client secret. You can get them from the LinkedIn Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/linkedin for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nIn the LinkedIn portal under products you need the Sign In with LinkedIn using OpenID Connect product.\n\nThere are some different Guides here: Authorization Code Flow (3-legged OAuth) (Outdated) Sign In with LinkedIn using OpenID Connect\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        linkedin: { \n            clientId: process.env.LINKEDIN_CLIENT_ID as string, \n            clientSecret: process.env.LINKEDIN_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with LinkedIn\n\nTo sign in with LinkedIn, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to linkedin.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"linkedin\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nLinear\n\nNext Page\n\nGitLab"
  },
  {
    "title": "GitLab | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/gitlab",
    "html": "GitLab\nCopy Markdown\nOpen in\nGet your GitLab credentials\n\nTo use GitLab sign in, you need a client ID and client secret. GitLab OAuth documentation.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/gitlab for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        gitlab: { \n            clientId: process.env.GITLAB_CLIENT_ID as string, \n            clientSecret: process.env.GITLAB_CLIENT_SECRET as string, \n            issuer: process.env.GITLAB_ISSUER as string, \n        }, \n    },\n})\nConfiguration Options\nclientId: Your GitLab application's Client ID\nclientSecret: Your GitLab application's Client Secret\nissuer: (Optional) The URL of your GitLab instance. Use this for self-hosted GitLab servers.\nDefault: \"https://gitlab.com\" (GitLab.com)\nExample: \"https://gitlab.company.com\"\n\nThe issuer option is useful when using a self-hosted GitLab instance. If you're using GitLab.com, you can omit this option as it defaults to https://gitlab.com.\n\nExample with self-hosted GitLab\nauth.ts\nexport const auth = betterAuth({\n    socialProviders: {\n        gitlab: {\n            clientId: process.env.GITLAB_CLIENT_ID as string,\n            clientSecret: process.env.GITLAB_CLIENT_SECRET as string,\n            issuer: \"https://gitlab.company.com\", // Your self-hosted GitLab URL\n        },\n    },\n})\nSign In with GitLab\n\nTo sign in with GitLab, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to gitlab.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"gitlab\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nLinkedIn\n\nNext Page\n\nReddit"
  },
  {
    "title": "Reddit | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/reddit",
    "html": "Reddit\nCopy Markdown\nOpen in\nGet your Reddit Credentials\n\nTo use Reddit sign in, you need a client ID and client secret. You can get them from the Reddit Developer Portal.\n\nClick \"Create App\" or \"Create Another App\"\nSelect \"web app\" as the application type\nSet the redirect URL to http://localhost:3000/api/auth/callback/reddit for local development\nFor production, set it to your application's domain (e.g. https://example.com/api/auth/callback/reddit)\nAfter creating the app, you'll get the client ID (under the app name) and client secret\n\nIf you change the base path of the auth routes, make sure to update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n    socialProviders: {\n        reddit: {\n            clientId: process.env.REDDIT_CLIENT_ID as string,\n            clientSecret: process.env.REDDIT_CLIENT_SECRET as string,\n        },\n    },\n})\nSign In with Reddit\n\nTo sign in with Reddit, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to reddit.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient = createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"reddit\"\n    })\n}\nAdditional Configuration\nScopes\n\nBy default, Reddit provides basic user information. If you need additional permissions, you can specify scopes in your auth configuration:\n\nauth.ts\nexport const auth = betterAuth({\n    socialProviders: {\n        reddit: {\n            clientId: process.env.REDDIT_CLIENT_ID as string,\n            clientSecret: process.env.REDDIT_CLIENT_SECRET as string,\n            duration: \"permanent\",\n            scope: [\"read\", \"submit\"] // Add required scopes\n        },\n    },\n})\n\nCommon Reddit scopes include:\n\nidentity: Access basic account information\nread: Access posts and comments\nsubmit: Submit posts and comments\nsubscribe: Manage subreddit subscriptions\nhistory: Access voting history\n\nFor a complete list of available scopes, refer to the Reddit OAuth2 documentation.\n\nEdit on GitHub\n\nPrevious Page\n\nGitLab\n\nNext Page\n\nRoblox"
  },
  {
    "title": "Spotify | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/spotify",
    "html": "Spotify\nCopy Markdown\nOpen in\nGet your Spotify Credentials\n\nTo use Spotify sign in, you need a client ID and client secret. You can get them from the Spotify Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/spotify for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n   \n    socialProviders: {\n        spotify: { \n            clientId: process.env.SPOTIFY_CLIENT_ID as string, \n            clientSecret: process.env.SPOTIFY_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with Spotify\n\nTo sign in with Spotify, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to spotify.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"spotify\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nRoblox\n\nNext Page\n\nVK"
  },
  {
    "title": "Roblox | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/roblox",
    "html": "Roblox\nCopy Markdown\nOpen in\nGet your Roblox Credentials\n\nGet your Roblox credentials from the Roblox Creator Hub.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/roblox for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nThe Roblox API does not provide email addresses. As a workaround, the user's email field uses the preferred_username value instead.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\" \nexport const auth = betterAuth({\n    socialProviders: {\n        roblox: { \n            clientId: process.env.ROBLOX_CLIENT_ID as string, \n            clientSecret: process.env.ROBLOX_CLIENT_SECRET as string, \n        }, \n    },\n})\nSign In with Roblox\n\nTo sign in with Roblox, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to roblox.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n    const data = await authClient.signIn.social({\n        provider: \"roblox\"\n    })\n}\nEdit on GitHub\n\nPrevious Page\n\nReddit\n\nNext Page\n\nSpotify"
  },
  {
    "title": "Zoom | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/zoom",
    "html": "Zoom\nCopy Markdown\nOpen in\nCreate a Zoom App from Marketplace\n\nVisit Zoom Marketplace.\n\nHover on the Develop button and select Build App\n\nSelect General App and click Create\n\nConfigure your Zoom App\n\nEnsure that you are in the Basic Information of your app settings.\n\nUnder Select how the app is managed, choose User-managed\n\nUnder App Credentials, copy your Client ID and Client Secret and store them in a safe location\n\nUnder OAuth Information -> OAuth Redirect URL, add your Callback URL. For example,\n\nhttp://localhost:3000/api/auth/callback/zoom\n\nFor production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nSkip to the Scopes section, then\n\nClick the Add Scopes button\nSearch for user:read:user (View a user) and select it\nAdd any other scopes your applications needs and click Done\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\"\nexport const auth = betterAuth({\n  socialProviders: {\n    zoom: { \n      clientId: process.env.ZOOM_CLIENT_ID as string, \n      clientSecret: process.env.ZOOM_CLIENT_SECRET as string, \n    }, \n  },\n})\nSign In with Zoom\n\nTo sign in with Zoom, you can use the signIn.social function provided by the client. You will need to specify zoom as the provider.\n\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\"\nconst authClient =  createAuthClient()\nconst signIn = async () => {\n  const data = await authClient.signIn.social({\n    provider: \"zoom\"\n  })\n}\nEdit on GitHub\n\nPrevious Page\n\nVK\n\nNext Page\n\nOthers"
  },
  {
    "title": "VK | Better Auth",
    "url": "https://www.better-auth.com/docs/authentication/vk",
    "html": "VK\nCopy Markdown\nOpen in\nGet your VK ID credentials\n\nTo use VK ID sign in, you need a client ID and client secret. You can get them from the VK ID Developer Portal.\n\nMake sure to set the redirect URL to http://localhost:3000/api/auth/callback/vk for local development. For production, you should set it to the URL of your application. If you change the base path of the auth routes, you should update the redirect URL accordingly.\n\nConfigure the provider\n\nTo configure the provider, you need to import the provider and pass it to the socialProviders option of the auth instance.\n\nauth.ts\nimport { betterAuth } from \"better-auth\";\nexport const auth = betterAuth({\n  socialProviders: {\n    vk: { \n      clientId: process.env.VK_CLIENT_ID as string, \n      clientSecret: process.env.VK_CLIENT_SECRET as string, \n    },\n  },\n});\nSign In with VK\n\nTo sign in with VK, you can use the signIn.social function provided by the client. The signIn function takes an object with the following properties:\n\nprovider: The provider to use. It should be set to vk.\nauth-client.ts\nimport { createAuthClient } from \"better-auth/client\";\nconst authClient = createAuthClient();\nconst signIn = async () => {\n  const data = await authClient.signIn.social({\n    provider: \"vk\",\n  });\n};\nEdit on GitHub\n\nPrevious Page\n\nSpotify\n\nNext Page\n\nZoom"
  },
  {
    "title": "Contributing to BetterAuth | Better Auth",
    "url": "https://www.better-auth.com/docs/reference/contributing",
    "html": "Contributing to BetterAuth\nCopy Markdown\nOpen in\n\nThank you for your interest in contributing to Better Auth! This guide is a concise guide to contributing to Better Auth.\n\nGetting Started\n\nBefore diving in, here are a few important resources:\n\nTake a look at our existing issues and pull requests\nJoin our community discussions in Discord\nDevelopment Setup\n\nTo get started with development:\n\nMake sure you have Node.JS installed, preferably on LTS.\n\n1. Fork the repository\n\nVisit https://github.com/better-auth/better-auth\n\nClick the \"Fork\" button in the top right.\n\n2. Clone your fork\n# Replace YOUR-USERNAME with your GitHub username\ngit clone https://github.com/YOUR-USERNAME/better-auth.git\ncd better-auth\n3. Install dependencies\n\nMake sure you have pnpm installed!\n\npnpm install\n4. Prepare ENV files\n\nCopy the example env file to create your new .env file.\n\ncp -n ./docs/.env.example ./docs/.env\nMaking changes\n\nOnce you have an idea of what you want to contribute, you can start making changes. Here are some steps to get started:\n\n1. Create a new branch\n# Make sure you're on main\ngit checkout main\n# Pull latest changes\ngit pull upstream main\n# Create and switch to a new branch\ngit checkout -b feature/your-feature-name\n2. Start development server\n\nStart the development server:\n\npnpm dev\n\nTo start the docs server:\n\npnpm -F docs dev\n3. Make Your Changes\n\nMake your changes to the codebase.\n\nWrite tests if needed. (Read more about testing here)\n\nUpdate documentation. (Read more about documenting here)\n\nIssues and Bug Fixes\nCheck our GitHub issues for tasks labeled good first issue\nWhen reporting bugs, include steps to reproduce and expected behavior\nComment on issues you'd like to work on to avoid duplicate efforts\nFramework Integrations\n\nWe welcome contributions to support more frameworks:\n\nFocus on framework-agnostic solutions where possible\nKeep integrations minimal and maintainable\nAll integrations currently live in the main package\nPlugin Development\nFor core plugins: Open an issue first to discuss your idea\nFor community plugins: Feel free to develop independently\nFollow our plugin architecture guidelines\nDocumentation\nFix typos and errors\nAdd examples and clarify existing content\nEnsure documentation is up to date with code changes\nTesting\n\nWe use Vitest for testing. Place test files next to the source files they test:\n\nimport { describe, it, expect } from \"vitest\";\nimport { getTestInstance } from \"./test-utils/test-instance\";\ndescribe(\"Feature\", () => {\n    it(\"should work as expected\", async () => {\n        const { client } = await getTestInstance();\n        // Test code here\n        expect(result).toBeDefined();\n    });\n});\nUsing the Test Instance Helper\n\nThe test instance helper now includes improved async context support for managing user sessions:\n\nconst { client, runWithUser, signInWithTestUser } = await getTestInstance();\n// Run tests with a specific user context\nawait runWithUser(\"user@example.com\", \"password\", async (headers) => {\n    // All client calls within this block will use the user's session\n    const response = await client.getSession();\n    // headers are automatically applied\n});\n// Or use the test user with async context\nconst { runWithDefaultUser } = await signInWithTestUser();\nawait runWithDefaultUser(async (headers) => {\n    // Code here runs with the test user's session context\n});\nTesting Best Practices\nWrite clear commit messages\nUpdate documentation to reflect your changes\nAdd tests for new features\nFollow our coding standards\nKeep pull requests focused on a single change\nNeed Help?\n\nDon't hesitate to ask for help! You can:\n\nOpen an issue with questions\nJoin our community discussions\nReach out to project maintainers\n\nThank you for contributing to Better Auth!\n\nEdit on GitHub\n\nPrevious Page\n\nOptions\n\nNext Page\n\nResources"
  },
  {
    "title": "Resources | Better Auth",
    "url": "https://www.better-auth.com/docs/reference/resources",
    "html": "Resources\nCopy Markdown\nOpen in\n\nA curated collection of resources to help you learn and master Better Auth. From blog posts to video tutorials, find everything you need to get started.\n\nVideo tutorials\nAll\ntrends\nshowcase\nreview\nimplementation\nnextjs\ncomparison\ntutorial\ntanstack\nmigration\nclerk\nThe State of Authentication\n\nTheo(t3.gg) explores the current landscape of authentication, discussing trends, challenges, and where the industry is heading.\n\ntrends\nshowcase\nreview\nLast Authentication You Will Ever Need\n\nA comprehensive tutorial demonstrating why Better Auth could be the final authentication solution you'll need for your projects.\n\nimplementation\nshowcase\nThis Might Be My New Favourite Auth Library\n\ndevelopedbyed explores the features and capabilities of Better Auth, explaining why it stands out among authentication libraries.\n\nreview\nshowcase\n8 Reasons To Try Better Auth\n\nCJ presents 8 compelling reasons why Better Auth is the BEST auth framework he's ever used, demonstrating its superior features and ease of implementation.\n\nreview\nshowcase\nimplementation\nBetter Auth is so good that I almost switched programming languages\n\nDreams of Code reviews Better Auth's features that nearly made them switch languages.\n\nreview\nshowcase\nimplementation\nBest authentication framework for next.js\n\nA detailed comparison of authentication frameworks for Next.js, highlighting why Better Auth might be your best choice.\n\nnextjs\ncomparison\nBetter-Auth: A First Look\n\nAn introductory overview and demonstration of Better Auth's core features and capabilities.\n\nimplementation\nshowcase\nStripe was never so easy (with better auth)\n\nA tutorial on how to integrate Stripe with Better Auth.\n\nimplementation\nNextjs 15 Authentication Made EASY with Better Auth\n\nA practical guide showing how to seamlessly integrate Better Auth with Next.js 15 for robust authentication.\n\nnextjs\nimplementation\ntutorial\nBetter Auth: Headless Authentication for Your TanStack Start App\n\nJack demonstrates how to implement headless authentication in your TanStack Start application using Better Auth, providing a modern approach to auth.\n\ntanstack\nimplementation\nGoodbye Clerk, Hello Better Auth – Full Migration Guide!\n\nA comprehensive guide showing how to migrate your authentication from Clerk to Better Auth, with step-by-step instructions and best practices.\n\nmigration\nclerk\ntutorial\nBlog posts\nAll\ntypescript\nreact\nbun\nvite\norganizations\nintegration\npayments\nastro\ntutorial\nmulti-tenant\nzenstack\narchitecture\nBetter Auth with Hono, Bun, TypeScript, React and Vite\n\nYou'll learn how to implement authentication with Better Auth in a client - server architecture, where the frontend is separate from the backend.\n\ntypescript\nreact\nbun\nvite\nPolar.sh + BetterAuth for Organizations\n\nPolar.sh is a platform for building payment integrations. This article will show you how to use Better Auth to authenticate your users.\n\norganizations\nintegration\npayments\nAuthenticating users in Astro with Better Auth\n\nStep by step guide on how to authenticate users in Astro with Better Auth.\n\nastro\nintegration\ntutorial\nBuilding Multi-Tenant Apps With Better-Auth and ZenStack\n\nLearn how to build multi-tenant apps with Better-Auth and ZenStack.\n\nmulti-tenant\nzenstack\narchitecture\nEdit on GitHub\n\nPrevious Page\n\nContributing\n\nNext Page\n\nSecurity"
  },
  {
    "title": "Security | Better Auth",
    "url": "https://www.better-auth.com/docs/reference/security",
    "html": "Security\nCopy Markdown\nOpen in\n\nThis page contains information about security features of Better Auth.\n\nPassword Hashing\n\nBetter Auth uses the scrypt algorithm to hash passwords by default. This algorithm is designed to be memory-hard and CPU-intensive, making it resistant to brute-force attacks. You can customize the password hashing function by setting the password option in the configuration. This option should include a hash function to hash passwords and a verify function to verify them.\n\nSession Management\nSession Expiration\n\nBetter Auth uses secure session management to protect user data. Sessions are stored in the database or a secondary storage, if configured, to prevent unauthorized access. By default, sessions expire after 7 days, but you can customize this value in the configuration. Additionally, each time a session is used, if it reaches the updateAge threshold, the expiration date is extended, which by default is set to 1 day.\n\nSession Revocation\n\nBetter Auth allows you to revoke sessions to enhance security. When a session is revoked, the user is logged out and can no longer access the application. A logged in user can also revoke their own sessions to log out from different devices or browsers.\n\nSee the session management for more details.\n\nCSRF Protection\n\nBetter Auth includes multiple safeguards to prevent Cross-Site Request Forgery (CSRF) attacks:\n\nNon-Simple Headers POST requests must either have a non-simple header or a Content-Type header of application/json. Non-simple headers are headers that are not included in the simple headers list.\n\nOrigin Validation Each request’s Origin header is verified to confirm it comes from your application or another explicitly trusted source. Requests from untrusted origins are rejected. By default, Better Auth trusts the base URL of your app, but you can specify additional trusted origins via the trustedOrigins configuration option.\n\nSecure Cookie Settings Session cookies use the SameSite=Lax attribute by default, preventing browsers from sending cookies with most cross-site requests. You can override this behavior using the defaultCookieAttributes option.\n\nNo Mutations on GET Requests (with additional safeguards) GET requests are assumed to be read-only and should not alter the application’s state. In cases where a GET request must perform a mutation—such as during OAuth callbacks - Better Auth applies extra security measures, including validating nonce and state parameters to ensure the request’s authenticity.\n\nYou can skip the CSRF check for all requests by setting the disableCSRFCheck option to true in the configuration.\n\n{\n  advanced: {\n    disableCSRFCheck: true\n  }\n}\n\nYou can skip the origin check for all requests by setting the disableOriginCheck option to true in the configuration.\n\n{\n  advanced: {\n    disableOriginCheck: true\n  }\n}\n\nSkipping csrf check will open your application to CSRF attacks. And skipping origin check may open up your application to other security vulnerabilities including open redirects.\n\nOAuth State and PKCE\n\nTo secure OAuth flows, Better Auth stores the OAuth state and PKCE (Proof Key for Code Exchange) in the database. The state helps prevent CSRF attacks, while PKCE protects against code injection threats. Once the OAuth process completes, these values are removed from the database.\n\nCookies\n\nBetter Auth assigns secure cookies by default when the base URL uses https. These secure cookies are encrypted and only sent over secure connections, adding an extra layer of protection. They are also set with the sameSite attribute to lax by default to prevent cross-site request forgery attacks. And the httpOnly attribute is enabled to prevent client-side JavaScript from accessing the cookie.\n\nFor Cross-Subdomain Cookies, you can set the crossSubDomainCookies option in the configuration. This option allows cookies to be shared across subdomains, enabling seamless authentication across multiple subdomains.\n\nCustomizing Cookies\n\nYou can customize cookie names to minimize the risk of fingerprinting attacks and set specific cookie options as needed for additional control. For more information, refer to the cookie options.\n\nPlugins can also set custom cookie options to align with specific security needs. If you're using Better Auth in non-browser environments, plugins offer ways to manage cookies securely in those contexts as well.\n\nRate Limiting\n\nBetter Auth includes built-in rate limiting to safeguard against brute-force attacks. Rate limits are applied across all routes by default, with specific routes subject to stricter limits based on potential risk.\n\nIP Address Headers\n\nBetter Auth uses client IP addresses for rate limiting and security monitoring. By default, it reads the IP address from the standard X-Forwarded-For header. However, you can configure a specific trusted header to ensure accurate IP address detection and prevent IP spoofing attacks.\n\nYou can configure the IP address header in your Better Auth configuration:\n\n{\n  advanced: {\n    ipAddress: {\n      ipAddressHeaders: ['cf-connecting-ip'] // or any other custom header\n    }\n  }\n}\n\nThis ensures that Better Auth only accepts IP addresses from your trusted proxy's header, making it more difficult for attackers to bypass rate limiting or other IP-based security measures by spoofing headers.\n\nImportant: When setting a custom IP address header, ensure that your proxy or load balancer is properly configured to set this header, and that it cannot be set by end users directly.\n\nTrusted Origins\n\nTrusted origins prevent CSRF attacks and block open redirects. You can set a list of trusted origins in the trustedOrigins configuration option. Requests from origins not on this list are automatically blocked.\n\nBasic Usage\n\nThe most basic usage is to specify exact origins:\n\n{\n  trustedOrigins: [\n    \"https://example.com\",\n    \"https://app.example.com\",\n    \"http://localhost:3000\"\n  ]\n}\nWildcard Domains\n\nBetter Auth supports wildcard patterns in trusted origins, which allows you to trust multiple subdomains with a single entry:\n\n{\n  trustedOrigins: [\n    \"*.example.com\",             // Trust all subdomains of example.com (any protocol)\n    \"https://*.example.com\",     // Trust only HTTPS subdomains of example.com\n    \"http://*.dev.example.com\"   // Trust all HTTP subdomains of dev.example.com\n  ]\n}\nProtocol-specific wildcards\n\nWhen using a wildcard pattern with a protocol prefix (like https://):\n\nThe protocol must match exactly\nThe domain can have any subdomain in place of the *\nRequests using a different protocol will be rejected, even if the domain matches\nProtocol-agnostic wildcards\n\nWhen using a wildcard pattern without a protocol prefix (like *.example.com):\n\nAny protocol (http, https, etc.) will be accepted\nThe domain must match the wildcard pattern\nCustom Schemes\n\nTrusted origins also support custom schemes for mobile apps and browser extensions:\n\n{\n  trustedOrigins: [\n    \"myapp://\",                               // Mobile app scheme\n    \"chrome-extension://YOUR_EXTENSION_ID\"    // Browser extension\n  ]\n}\nReporting Vulnerabilities\n\nIf you discover a security vulnerability in Better Auth, please report it to us at security@better-auth.com. We address all reports promptly, and credits will be given for validated discoveries.\n\nEdit on GitHub\n\nPrevious Page\n\nResources\n\nNext Page\n\nTelemetry"
  },
  {
    "title": "Telemetry | Better Auth",
    "url": "https://www.better-auth.com/docs/reference/telemetry",
    "html": "Telemetry\nCopy Markdown\nOpen in\n\nBetter Auth collects anonymous usage data to help us improve the project. This is optional, transparent, and disabled by default.\n\nWhy is telemetry collected?\n\nSince v1.3.5, Better Auth collects anonymous telemetry data about general usage if enabled.\n\nTelemetry data helps us understand how Better Auth is being used across different environments so we can improve performance, prioritize features, and fix issues more effectively. It guides our decisions on performance optimizations, feature development, and bug fixes. All data is collected completely anonymously and with privacy in mind, and users can opt out at any time. We strive to keep what we collect as transparent as possible.\n\nWhat is being collected?\n\nThe following data points may be reported. Everything is anonymous and intended for aggregate insights only.\n\nAnonymous identifier: A non-reversible hash derived from your project (package.json name and optionally baseURL). This lets us de‑duplicate events per project without knowing who you are.\nRuntime: { name: \"node\" | \"bun\" | \"deno\", version }.\nEnvironment: one of development, production, test, or ci.\nFramework (if detected): { name, version } for frameworks like Next.js, Nuxt, Remix, Astro, SvelteKit, etc.\nDatabase (if detected): { name, version } for integrations like PostgreSQL, MySQL, SQLite, Prisma, Drizzle, MongoDB, etc.\nSystem info: platform, OS release, architecture, CPU count/model/speed, total memory, and flags like isDocker, isWSL, isTTY.\nPackage manager: { name, version } derived from the npm user agent.\nRedacted auth config snapshot: A minimized, privacy‑preserving view of your betterAuth options produced by getTelemetryAuthConfig.\n\nWe also collect anonymous telemetry from the CLI:\n\nCLI generate (cli_generate): outcome generated | overwritten | appended | no_changes | aborted plus redacted config.\nCLI migrate (cli_migrate): outcome migrated | no_changes | aborted | unsupported_adapter plus adapter id (when relevant) and redacted config.\n\nYou can audit telemetry locally by setting the BETTER_AUTH_TELEMETRY_DEBUG=1 environment variable when running your project or by setting telemetry: { debug: true } in your auth config. In this debug mode, telemetry events are logged only to the console.\n\nauth.ts\nexport const auth = betterAuth({\n  telemetry: { \n    debug: true\n  } \n});\nHow is my data protected?\n\nAll collected data is fully anonymous and only useful in aggregate. It cannot be traced back to any individual source and is accessible only to a small group of core Better Auth maintainers to guide roadmap decisions.\n\nNo PII or secrets: We do not collect emails, usernames, tokens, secrets, client IDs, client secrets, or database URLs.\nNo full config: We never send your full betterAuth configuration. Instead we send a reduced, redacted snapshot of non‑sensitive toggles and counts.\nRedaction by design: See detect-auth-config.ts in the Better Auth source for the exact shape of what is included. It purposely converts sensitive values to booleans, counts, or generic identifiers.\nHow can I enable it?\n\nYou can enable telemetry collection in your auth config or by setting an environment variable.\n\nVia your auth config.\n\nauth.ts\nexport const auth = betterAuth({\n  telemetry: { \n    enabled: true\n  } \n});\n\nVia an environment variable.\n\n.env\n# Enable telemetry\nBETTER_AUTH_TELEMETRY=1\n# Disable telemetry\nBETTER_AUTH_TELEMETRY=0\nWhen is telemetry sent?\nOn betterAuth initialization (type: \"init\").\nOn CLI actions: generate and migrate as described above.\n\nTelemetry is disabled automatically in tests (NODE_ENV=test) unless explicitly overridden by internal tooling.\n\nEdit on GitHub\n\nPrevious Page\n\nSecurity\n\nNext Page\n\nFAQ"
  },
  {
    "title": "FAQ | Better Auth",
    "url": "https://www.better-auth.com/docs/reference/faq",
    "html": "FAQ\nCopy Markdown\nOpen in\n\nThis page contains frequently asked questions, common issues, and other helpful information about Better Auth.\n\nAuth client not working\ngetSession not working\nAdding custom fields to the users table\nDifference between getSession and useSession\nCommon TypeScript Errors\nCan I remove `name`, `image`, or `email` fields from the user table?\nEdit on GitHub\n\nPrevious Page\n\nTelemetry"
  }
]
</file>

<file path="output/jobs/prisma.json">
[
  {
    "title": "Reference | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference",
    "html": "ORM\nReference\n\nThe reference section of the documentation is a collection of reference pages that describe the Prisma ORM APIs and database implementations.\n\nIn this section​\nPrisma Client API\n\nIf Prisma ORM's Rust engine binaries cause large bundle sizes, slow builds, or deployment issues (for example, in serverless or edge environments), you can use it without them using this configuration of your generator block:\n\nPrisma Schema\n\ndatasource\n\nPrisma CLI\n\nThis document describes the Prisma CLI commands, arguments, and options.\n\nErrors\n\nFor more information about how to work with exceptions and error codes, see Handling exceptions and errors.\n\nEnvironment variables\n\nThis document describes different environment variables and their use cases.\n\nPrisma Config\n\nOverview\n\nDatabase features matrix\n\nThis page gives an overview of the features which are provided by the databases that Prisma ORM supports. Additionally, it explains how each of these features can be used in Prisma ORM with pointers to further documentation.\n\nSupported databases\n\nPrisma ORM currently supports the following databases.\n\nConnection URLs\n\nPrisma ORM needs a connection URL to be able to connect to your database, e.g. when sending queries with Prisma Client or when changing the database schema with Prisma Migrate.\n\nSystem requirements\n\nThis page provides an overview of the system requirements for Prisma ORM.\n\nPreview features"
  },
  {
    "title": "Prisma Client API | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-client-reference",
    "html": "ORMReference\nPrisma Client API reference\nUSE PRISMA ORM WITHOUT RUST BINARIES\n\nIf Prisma ORM's Rust engine binaries cause large bundle sizes, slow builds, or deployment issues (for example, in serverless or edge environments), you can use it without them using this configuration of your generator block:\n\ngenerator client {\n\n  provider   = \"prisma-client-js\" // or \"prisma-client\"\n\n  engineType = \"client\"\n\n}\n\n\nPrisma ORM without Rust binaries has been Generally Available since v6.16.0\n.\n\nNote that you need to use a driver adapter in this case.\n\nWhen using this architecture:\n\nNo Rust query engine binary is downloaded or shipped.\nThe database connection pool is maintained by the native JS database driver you install (e.g., @prisma/adapter-pg for PostgreSQL).\n\nThis setup can simplify deployments in serverless or edge runtimes. Learn more in the docs here.\n\nCurious why we moved away from the Rust engine? Take a look at why we transitioned from Rust binary engines to an all-TypeScript approach for a faster, lighter Prisma ORM in this blog post.\n\nThe Prisma Client API reference documentation is based on the following schema:\n\nmodel User {\n\n  id           Int              @id @default(autoincrement())\n\n  name         String?\n\n  email        String           @unique\n\n  profileViews Int              @default(0)\n\n  role         Role             @default(USER)\n\n  coinflips    Boolean[]\n\n  posts        Post[]\n\n  city         String\n\n  country      String\n\n  profile      ExtendedProfile?\n\n  pets         Json\n\n}\n\n\n\nmodel ExtendedProfile {\n\n  id     Int     @id @default(autoincrement())\n\n  userId Int?    @unique\n\n  bio    String?\n\n  User   User?   @relation(fields: [userId], references: [id])\n\n}\n\n\n\nmodel Post {\n\n  id        Int     @id @default(autoincrement())\n\n  title     String\n\n  published Boolean @default(true)\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int\n\n  comments  Json\n\n  views     Int     @default(0)\n\n  likes     Int     @default(0)\n\n}\n\n\n\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\n\nAll example generated types (such as UserSelect and UserWhereUniqueInput) are based on the User model.\n\nPrismaClient​\n\nThis section describes the PrismaClient constructor and its parameters.\n\nRemarks​\nParameters are validated at runtime.\ndatasources​\n\nProgrammatically overrides properties of the datasource block in the schema.prisma file - for example, as part of an integration test. See also: Data sources\n\nFrom version 5.2.0 and upwards, you can also use the datasourceUrl property to programmatically override the database connection string.\n\nProperties​\nExample property\tExample value\tDescription\ndb\t{ url: 'file:./dev_qa.db' }\tThe database connection URL.\nRemarks​\nYou must re-generate Prisma Client each time you add or rename a data source. Datasource names are included in the generated client.\nIf you named your datasource block something else in the schema, replace db with the name of your datasource block.\nExamples​\nProgrammatically override a datasource url​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  datasources: {\n\n    db: {\n\n      url: 'file:./dev_qa.db',\n\n    },\n\n  },\n\n});\n\n\nBased on the following datasource block:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\ndatasourceUrl​\n\nProgrammatically overrides the datasource block in the schema.prisma file.\n\nProperty​\nOption\tExample value\tDescription\nDatabase connection string\t'file:./dev_qa.db'\tThe database connection URL.\nExamples​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  datasourceUrl: 'postgresql://johndoe:randompassword@localhost:5432/mydb',\n\n});\n\nlog​\n\nDetermines the type and level of logging. See also: Logging\n\nOptions​\nOption\tExample\nArray of log levels\t[ \"info\", \"query\" ]\nArray of log definitions\t[ { level: \"info\", emit: \"event\" }, { level: \"warn\", emit: \"stdout\" }]\nLog levels​\nName\tExample\nquery\tLogs all queries run by Prisma.\n\nFor relational databases this logs all SQL queries. Example:\nprisma:query SELECT \"public\".\"User\".\"id\", \"public\".\"User\".\"email\" FROM \"public\".\"User\" WHERE (\"public\".\"User\".\"id\") IN (SELECT \"t0\".\"id\" FROM \"public\".\"User\" AS \"t0\" INNER JOIN \"public\".\"Post\" AS \"j0\" ON (\"j0\".\"authorId\") = (\"t0\".\"id\") WHERE (\"j0\".\"views\" > $1 AND \"t0\".\"id\" IS NOT NULL)) OFFSET $2\n\nFor MongoDB this logs queries using the \nmongosh\nshell\n format. Example:\nprisma:query db.User.deleteMany({ _id: ( $in: [ “6221ce49f756b0721fc00542”, ], }, })\ninfo\tExample:\nprisma:info Started http server on http://127.0.0.1:58471\nwarn\tWarnings.\nerror\tErrors.\nEmit formats​\nName\tDescription\nstdout\tSee: stdout\n\nevent\tRaises an event that you can subscribe to.\nEvent types​\n\nThe query event type:\n\nindex.d.ts\nexport type QueryEvent = {\n\n  timestamp: Date;\n\n  query: string; // Query sent to the database\n\n  params: string; // Query parameters\n\n  duration: number; // Time elapsed (in milliseconds) between client issuing query and database responding - not only time taken to run query\n\n  target: string;\n\n};\n\n\nNote that for MongoDB, the params and duration fields will be undefined.\n\nAll other log level event types:\n\nindex.d.ts\nexport type LogEvent = {\n\n  timestamp: Date;\n\n  message: string;\n\n  target: string;\n\n};\n\nExamples​\nLog query and info to stdout​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({ log: ['query', 'info'] });\n\n\n\nasync function main() {\n\n  const countUsers = await prisma.user.count({});\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nLog a query event to console​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  log: [{ level: 'query', emit: 'event' }],\n\n});\n\n\n\nprisma.$on('query', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nasync function main() {\n\n  const countUsers = await prisma.user.count({});\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nLog info, warn, and error events to console​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  log: [\n\n    { level: 'warn', emit: 'event' },\n\n    { level: 'info', emit: 'event' },\n\n    { level: 'error', emit: 'event' },\n\n  ],\n\n});\n\n\n\nprisma.$on('warn', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nprisma.$on('info', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nprisma.$on('error', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nasync function main() {\n\n  const countUsers = await prisma.user.count({});\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nerrorFormat​\n\nDetermines the level and formatting of errors returned by Prisma Client.\n\nError formats​\nName\tDescription\nundefined\tIf it's not defined, the default is colorless.\npretty\tEnables pretty error formatting.\ncolorless (default)\tEnables colorless error formatting.\nminimal\tEnables minimal error formatting.\nExamples​\nNo error formatting​\nconst prisma = new PrismaClient({\n\n  // Defaults to colorless\n\n});\n\npretty error formatting​\nconst prisma = new PrismaClient({\n\n  errorFormat: 'pretty',\n\n});\n\ncolorless error formatting​\nconst prisma = new PrismaClient({\n\n  errorFormat: 'colorless',\n\n});\n\nminimal error formatting​\nconst prisma = new PrismaClient({\n\n  errorFormat: 'minimal',\n\n});\n\nadapter​\n\nDefines an instance of a driver adapter. See also Database drivers .\n\nINFO\n\nThis is available from version 5.4.0 and newer as a Preview feature behind the driverAdapters feature flag. It has been Generally Available since 6.16.0.\n\nExample​\n\nThe example below uses the Neon driver adapter\n\nimport { PrismaNeon } from '@prisma/adapter-neon';\n\nimport { PrismaClient } from '@prisma/client';\n\nimport dotenv from 'dotenv';\n\n\n\ndotenv.config();\n\nconst connectionString = `${process.env.DATABASE_URL}`;\n\n\n\nconst adapter = new PrismaNeon({ connectionString });\n\nconst prisma = new PrismaClient({ adapter });\n\nrejectOnNotFound​\nINFO\n\nNote: rejectOnNotFound was removed in v5.0.0.\n\nDeprecated: rejectOnNotFound is deprecated in v4.0.0. From v4.0.0, use the queries findUniqueOrThrow or findFirstOrThrow.\n\nUse the rejectOnNotFound parameter to configure findUnique() and/or findFirst to throw an error if the record was not found. By default, both operations return null if the record is not found.\n\nRemarks​\nYou can configure rejectOnNotFound on a per-request level for both findUnique() and findFirst\nOptions​\nOption\tDescription\nRejectOnNotFound\tEnable globally (true / false) or throw a custom error.\nRejectPerOperation\tEnable per operation (true / false) or throw a custom error per operation, per model.\nExamples​\nEnable globally for findUnique() and findFirst​\nconst prisma = new PrismaClient({\n\n  rejectOnNotFound: true,\n\n});\n\nEnable globally for a specific operation​\nconst prisma = new PrismaClient({\n\n  rejectOnNotFound: {\n\n    findUnique: true,\n\n  },\n\n});\n\nThrow a custom error per model and operation if record is not found​\nconst prisma = new PrismaClient({\n\n  rejectOnNotFound: {\n\n    findFirst: {\n\n      User: (err) => new Error('User error'),\n\n      Post: (err) => new Error('Post error!'),\n\n    },\n\n    findUnique: {\n\n      User: (err) => new Error('User error'),\n\n      Post: (err) => new Error('Post error!'),\n\n    },\n\n  },\n\n});\n\ntransactionOptions​\nINFO\n\nNote: transactionOptions was introduced in v5.10.0.\n\nAllows to set transaction options globally on the constructor level.\n\nRemarks​\nThe transaction levels can be overridden on a per-transaction level.\nOptions​\nOption\tDescription\nmaxWait\tThe maximum amount of time Prisma Client will wait to acquire a transaction from the database. The default value is 2 seconds.\ntimeout\tThe maximum amount of time the interactive transaction can run before being canceled and rolled back. The default value is 5 seconds.\nisolationLevel\tSets the transaction isolation level. By default this is set to the value currently configured in your database. The available can vary depending on the database you use.\nExample​\nconst prisma = new PrismaClient({\n\n  transactionOptions: {\n\n    isolationLevel: Prisma.TransactionIsolationLevel.Serializable,\n\n    maxWait: 5000, // default: 2000\n\n    timeout: 10000, // default: 5000\n\n  },\n\n});\n\nModel queries​\n\nUse model queries to perform CRUD operations on your models. See also: CRUD\n\nNote: It's a best practice to always validate and sanitize any untrusted user data before passing it into Prisma queries. Failure to do so can lead to SQL injection or other injection vulnerabilities if the type checks are bypassed. Make sure user-supplied values cannot inadvertently bypass critical checks. We strongly recommend performing type checking and input validation at the application layer. For more details, see Custom Validation section.\n\nfindUnique()​\n\nfindUnique() query lets you retrieve a single database record:\n\nBy ID\nBy a unique attribute\n\nfindUnique() replaced findOne in version 2.12.0\n.\n\nRemarks​\nPrisma Client's dataloader automatically batches findUnique() queries with the same select and where parameters.\nIf you want the query to throw an error if the record is not found, then consider using findUniqueOrThrow instead.\nYou cannot use filter conditions (e.g. equals, contains, not) to filter fields of the JSON data type. Using filter conditions will likely result in a null response for that field.\nOptions​\nName\tExample type (User)\tRequired\tDescription\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ title: \"Hello world\" }\tUse select and include to determine which fields to return.\nnull\tnull\tRecord not found\nExamples​\nGet the User record with an id of 42​\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    id: 42,\n\n  },\n\n});\n\nGet the User record with an email of alice@prisma.io​\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    email: 'alice@prisma.io',\n\n  },\n\n});\n\nGet the User record with firstName of Alice and lastName of Smith (@@unique)​\nExpand for example User model with a @@unique block\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    fullname: {\n\n      // name property of @@unique attribute - default is firstname_lastname\n\n      firstName: 'Alice',\n\n      lastName: 'Smith',\n\n    },\n\n  },\n\n});\n\nGet the User record with firstName of Alice and lastName of Smith (@@id)​\nExpand for example User model with an @@id block\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    firstName_lastName: {\n\n      firstName: 'Alice',\n\n      lastName: 'Smith',\n\n    },\n\n  },\n\n});\n\nfindUniqueOrThrow()​\n\nfindUniqueOrThrow() retrieves a single record in the same way as findUnique(). However, if the query does not find the requested record, it throws a PrismaClientKnownRequestError.\n\nNote that before Prisma v6, it would throw a NotFoundError: No User found error.\n\nHere’s an example of its usage:\n\nawait prisma.user.findUniqueOrThrow({\n\n  where: { id: 1 },\n\n});\n\n\nfindUniqueOrThrow() differs from findUnique() as follows:\n\nIts return type is non-nullable. For example, post.findUnique() can return post or null, but post.findUniqueOrThrow() always returns post.\n\nIt is not compatible with sequential operations in the $transaction API. If the query throws a PrismaClientKnownRequestError, then the API will not roll back any operations in the array of calls. As a workaround, you can use interactive transactions with the $transaction API, as follows:\n\n $transaction(async (prisma) => {\n\n   await prisma.model.create({ data: { ... });\n\n   await prisma.model.findUniqueOrThrow();\n\n })\n\nfindFirst()​\n\nfindFirst returns the first record in a list that matches your criteria.\n\nRemarks​\nIf you want the query to throw an error if the record is not found, then consider using findFirstOrThrow instead.\nOptions​\nName\tExample type (User)\tRequired\tDescription\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0.\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<UserOrderByInput>, UserOrderByInput>\tNo\tLets you order the returned list by any property.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\tSpecifies which properties to include on the returned object.\nJavaScript object (plain)\t{ title: \"Hello world\" }\tUse select and include to determine which fields to return.\nnull\tnull\tRecord not found\nRemarks​\nfindFirst calls findMany behind the scenes and accepts the same query options.\nPassing in a negative take value when you use a findFirst query reverses the order of the list.\nExamples​\n\nSee Filter conditions and operators for examples of how to filter results.\n\nGet the first User record where the name is Alice​\nconst user = await prisma.user.findFirst({\n\n  where: { name: 'Alice' },\n\n});\n\nGet the first Post record where the title starts with A test, reverse the list with take​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({});\n\n\n\nasync function main() {\n\n  const a = await prisma.post.create({\n\n    data: {\n\n      title: 'A test 1',\n\n    },\n\n  });\n\n\n\n  const b = await prisma.post.create({\n\n    data: {\n\n      title: 'A test 2',\n\n    },\n\n  });\n\n\n\n  const c = await prisma.post.findFirst({\n\n    where: {\n\n      title: {\n\n        startsWith: 'A test',\n\n      },\n\n    },\n\n    orderBy: {\n\n      title: 'asc',\n\n    },\n\n    take: -1, // Reverse the list\n\n  });\n\n}\n\n\n\nmain();\n\nfindFirstOrThrow()​\n\nfindFirstOrThrow() retrieves a single data record in the same way as findFirst(). However, if the query does not find a record, it throws a PrismaClientKnownRequestError.\n\nNote that before Prisma v6, it would throw a NotFoundError: No User found error.\n\nfindFirstOrThrow() differs from findFirst() as follows:\n\nIts return type is non-nullable. For example, post.findFirst() can return post or null, but post.findFirstOrThrow always returns post.\n\nIt is not compatible with sequential operations in the $transaction API. If the query returns PrismaClientKnownRequestError, then the API will not roll back any operations in the array of calls. As a workaround, you can use interactive transactions with the $transaction API, as follows:\n\nprisma.$transaction(async (tx) => {\n\n  await tx.model.create({ data: { ... });\n\n  await tx.model.findFirstOrThrow();\n\n})\n\nfindMany()​\n\nfindMany returns a list of records.\n\nOptions​\nName\tType\tRequired\tDescription\nselect\tXOR<PostSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<PostInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<PostOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<PostOrder\nByInput>, PostOrderByInput>\tNo\tLets you order the returned list by any property.\ncursor\tUserWhereUniqueInput\tNo\tSpecifies the position for the list (the value typically specifies an id or another unique value).\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\ndistinct\tEnumerable<UserDistinctFieldEnum>\tNo\tLets you filter out duplicate rows by a specific field - for example, return only distinct Post titles.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript array object (typed)\tUser[]\t\nJavaScript array object (plain)\t[{ title: \"Hello world\" }]\tUse select and include to determine which fields to return.\nEmpty array\t[]\tNo matching records found.\nExamples​\n\nSee Filter conditions and operators for examples of how to filter results.\n\nGet all User records where the name is Alice​\nconst user = await prisma.user.findMany({\n\n  where: { name: 'Alice' },\n\n});\n\ncreate()​\n\ncreate creates a new database record.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserCreateInput,\nUserUncheckedCreateInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. It also includes relation fields which lets you perform (transactional) nested inserts. Fields that are marked as optional or have default values in the datamodel are optional.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tUse select and include to determine which fields to return.\nRemarks​\nYou can also perform a nested create - for example, add a User and two Post records at the same time.\nExamples​\nCreate a single new record with the only required field email​\nconst user = await prisma.user.create({\n\n  data: { email: 'alice@prisma.io' },\n\n});\n\nCreate multiple new records​\n\nIn most cases, you can carry out batch inserts with the createMany() or createManyAndReturn() queries. However, there are scenarios where create() is the best option to insert multiple records.\n\nThe following example results in two INSERT statements:\n\nimport { Prisma, PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({ log: ['query'] });\n\n\n\nasync function main() {\n\n  let users: Prisma.UserCreateInput[] = [\n\n    {\n\n      email: 'ariana@prisma.io',\n\n      name: 'Ari',\n\n      profileViews: 20,\n\n      coinflips: [true, false, false],\n\n      role: 'ADMIN',\n\n    },\n\n    {\n\n      email: 'elsa@prisma.io',\n\n      name: 'Elsa',\n\n      profileViews: 20,\n\n      coinflips: [true, false, false],\n\n      role: 'ADMIN',\n\n    },\n\n  ];\n\n\n\n  await Promise.all(\n\n    users.map(async (user) => {\n\n      await prisma.user.create({\n\n        data: user,\n\n      });\n\n    })\n\n  );\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nprisma:query BEGIN\n\nprisma:query INSERT INTO \"public\".\"User\" (\"name\",\"email\",\"profileViews\",\"role\",\"coinflips\") VALUES ($1,$2,$3,$4,$5) RETURNING \"public\".\"User\".\"id\"\n\nprisma:query SELECT \"public\".\"User\".\"id\", \"public\".\"User\".\"name\", \"public\".\"User\".\"email\", \"public\".\"User\".\"profileViews\", \"public\".\"User\".\"role\", \"public\".\"User\".\"coinflips\" FROM \"public\".\"User\" WHERE \"public\".\"User\".\"id\" = $1 LIMIT $2 OFFSET $3\n\nprisma:query INSERT INTO \"public\".\"User\" (\"name\",\"email\",\"profileViews\",\"role\",\"coinflips\") VALUES ($1,$2,$3,$4,$5) RETURNING \"public\".\"User\".\"id\"\n\nprisma:query COMMIT\n\nprisma:query SELECT \"public\".\"User\".\"id\", \"public\".\"User\".\"name\", \"public\".\"User\".\"email\", \"public\".\"User\".\"profileViews\", \"public\".\"User\".\"role\", \"public\".\"User\".\"coinflips\" FROM \"public\".\"User\" WHERE \"public\".\"User\".\"id\" = $1 LIMIT $2 OFFSET $3\n\nprisma:query COMMIT\n\nupdate()​\n\nupdate updates an existing database record.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserUpdateInput\nUserUncheckedUpdateInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional.\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0.\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tUse select and include to determine which fields to return.\nPrismaClientKnownRequestError (code P2025)\t\tThrown if the record to update does not exist. See Error reference\nRemarks​\nTo perform arithmetic operations on update (add, subtract, multiply, divide), use atomic updates to prevent race conditions.\nYou can also perform a nested update - for example, update a user and that user's posts at the same time.\nExamples​\nUpdate the email of the User record with id of 1 to alice@prisma.io​\nconst user = await prisma.user.update({\n\n  where: { id: 1 },\n\n  data: { email: 'alice@prisma.io' },\n\n});\n\nupsert()​\nINFO\n\nThis section covers the usage of the upsert() operation. To learn about using nested upsert queries within update(), reference the linked documentation.\n\nupsert does the following:\n\nIf an existing database record satisfies the where condition, it updates that record\nIf no database record satisfies the where condition, it creates a new database record\nOptions​\nName\tType\tRequired\tDescription\ncreate\tXOR<UserCreateInput,\nUserUncheckedCreateInput>\tYes\tWraps all the fields of the model so that they can be provided when creating new records. It also includes relation fields which lets you perform (transactional) nested inserts. Fields that are marked as optional or have default values in the datamodel are optional.\nupdate\tXOR<UserUpdateInput,\nUserUncheckedUpdateInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional.\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tUse select and include to determine which fields to return.\nRemarks​\nTo perform arithmetic operations on update (add, subtract, multiply, divide), use atomic updates to prevent race conditions.\nIf two or more upsert operations happen at the same time and the record doesn't already exist, then a race condition might happen. As a result, one or more of the upsert operations might throw a unique key constraint error. Your application code can catch this error and retry the operation. Learn more.\nFrom version 4.6.0, Prisma ORM hands over upsert queries to the database where possible. Learn more.\nExamples​\nUpdate (if exists) or create a new User record with an email of alice@prisma.io​\nconst user = await prisma.user.upsert({\n\n  where: { id: 1 },\n\n  update: { email: 'alice@prisma.io' },\n\n  create: { email: 'alice@prisma.io' },\n\n});\n\nUnique key constraint errors on upserts​\nProblem​\n\nIf multiple upsert operations happen at the same time and the record doesn't already exist, then one or more of the operations might return a unique key constraint error.\n\nCause​\n\nWhen Prisma Client does an upsert, it first checks whether that record already exists in the database. To make this check, Prisma Client performs a read operation with the where clause from the upsert operation. This has two possible outcomes, as follows:\n\nIf the record does not exist, then Prisma Client creates that record.\nIf the record exists, then Prisma Client updates it.\n\nWhen your application tries to perform two or more concurrent upsert operations, then a race condition might happen where two or more operations do not find the record and therefore try to create that record. In this situation, one of the operations successfully creates the new record but the other operations fail and return a unique key constraint error.\n\nSolution​\n\nHandle the P2002 error in your application code. When it occurs, retry the upsert operation to update the row.\n\nDatabase upserts​\n\nWhere possible, Prisma Client hands over an upsert query to the database. This is called a database upsert.\n\nDatabase upserts have the following advantages:\n\nThey are faster than upserts handled by Prisma Client\nUnique key constraint errors cannot happen\n\nPrisma Client uses a database upsert automatically when specific criteria are met. When these criteria are not met, Prisma Client handles the upsert.\n\nTo use a database upsert, Prisma Client sends the SQL construction INSERT ... ON CONFLICT SET .. WHERE to the database.\n\nDatabase upsert prerequisites​\n\nPrisma Client can use database upserts if your stack meets the following criteria:\n\nYou use Prisma ORM version 4.6.0 or later\nYour application uses a CockroachDB, PostgreSQL, or SQLite data source\nDatabase upsert query criteria​\n\nPrisma Client uses a database upsert for an upsert query when the query meets the following criteria:\n\nThere are no nested queries in the upsert's create and update options\nThe query does not include a selection that uses a nested read\nThe query modifies only one model\nThere is only one unique field in the upsert's where option\nThe unique field in the where option and the unique field in the create option have the same value\n\nIf your query does not meet these criteria, then Prisma Client handles the upsert itself.\n\nDatabase upsert examples​\n\nThe following examples use this schema:\n\nmodel User {\n\n  id           Int    @id\n\n  profileViews Int\n\n  userName     String @unique\n\n  email        String\n\n\n\n  @@unique([id, profileViews])\n\n}\n\n\nThe following upsert query meets all of the criteria, so Prisma Client uses a database upsert.\n\nprisma.user.upsert({\n\n  where: {\n\n    userName: 'Alice',\n\n  },\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'Alice',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\n\nIn this situation, Prisma uses the following SQL query:\n\nINSERT INTO \"public\".\"User\" (\"id\",\"profileViews\",\"userName\",\"email\") VALUES ($1,$2,$3,$4)\n\nON CONFLICT (\"userName\") DO UPDATE\n\nSET \"email\" = $5 WHERE (\"public\".\"User\".\"userName\" = $6 AND 1=1) RETURNING \"public\".\"User\".\"id\", \"public\".\"User\".\"profileViews\", \"public\".\"User\".\"userName\", \"public\".\"User\".\"email\"\n\n\nThe following query has multiple unique values in the where clause, so Prisma Client does not use a database upsert:\n\nprisma.User.upsert({\n\n  where: {\n\n    userName: 'Alice',\n\n    profileViews: 1,\n\n    id: 1,\n\n  },\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'Alice',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\n\nIn the following query, the values for userName in the where and create options are different, so Prisma Client does not use a database upsert.\n\nprisma.User.upsert({\n\n  where: {\n\n    userName: 'Alice',\n\n  },\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'AliceS',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\n\nIn the following query, the selection on the title field in posts is a nested read, so Prisma Client does not use a database upsert.\n\nprisma.user.upsert({\n\n  select: {\n\n    email: true,\n\n    id: true,\n\n    posts: {\n\n      select: {\n\n        title: true,\n\n      },\n\n    },\n\n  },\n\n  where: {\n\n    userName: 'Alice',\n\n  },\n\n\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'Alice',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\ndelete()​\n\ndelete deletes an existing database record. You can delete a record:\n\nBy ID\nBy a unique attribute\n\nTo delete records that match a certain criteria, use deleteMany with a filter.\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\tThe User record that was deleted.\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tData from the User record that was deleted. Use select and include to determine which fields to return.\nPrismaClientKnownRequestError (code P2025)\t\tThrown if the record to delete does not exist. See Error reference\nRemarks​\nTo delete multiple records based on some criteria (for example, all User records with a prisma.io email address, use deleteMany)\nExamples​\nDelete the User record with an id of 1​\nconst user = await prisma.user.delete({\n\n  where: { id: 1 },\n\n});\n\nDelete the User record where email equals elsa@prisma.io​\n\nThe following query deletes a specific user record and uses select to return the name and email of the deleted user:\n\nconst deleteUser = await prisma.user.delete({\n\n  where: {\n\n    email: 'elsa@prisma.io',\n\n  },\n\n  select: {\n\n    email: true,\n\n    name: true,\n\n  },\n\n});\n\nShow CLI results\n{ \"email\": \"elsa@prisma.io\", \"name\": \"Elsa\" }\n\ncreateMany()​\n\ncreateMany creates multiple records in a transaction.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tEnumerable<UserCreateManyInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. Fields that are marked as optional or have default values in the datamodel are optional.\nskipDuplicates?\tboolean\tNo\tDo not insert records with unique fields or ID fields that already exist. Only supported by databases that support \nON CONFLICT DO NOTHING\n. This excludes MongoDB and SQLServer\nReturn type​\nReturn type\tExample\tDescription\nBatchPayload\t{ count: 3 }\tA count of the number of records created.\nRemarks​\nAs of Prisma ORM version 5.12.0, createMany() is now supported by SQLite.\nThe skipDuplicates option is not supported by MongoDB, SQLServer, or SQLite.\nYou cannot create or connect relations by using nested create, createMany, connect, connectOrCreate queries inside a top-level createMany() query. See here for a workaround.\nYou can use a nested createMany query inside an update() or create() query - for example, add a User and two Post records with a nested createMany at the same time.\nExamples​\nCreate several new users​\nconst users = await prisma.user.createMany({\n\n  data: [\n\n    { name: 'Sonali', email: 'sonali@prisma.io' },\n\n    { name: 'Alex', email: 'alex@prisma.io' },\n\n  ],\n\n});\n\ncreateManyAndReturn()​\n\ncreateManyAndReturn creates multiple records and returns the resulting objects.\n\nINFO\n\nThis feature is available in Prisma ORM version 5.14.0 and later for PostgreSQL, CockroachDB and SQLite.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tEnumerable<UserCreateManyInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. Fields that are marked as optional or have default values in the datamodel are optional.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned objects.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned objects. In Preview since 5.13.0. Mutually exclusive with select.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned objects.\nskipDuplicates?\tboolean\tNo\tDo not insert records with unique fields or ID fields that already exist. Only supported by databases that support \nON CONFLICT DO NOTHING\n. This excludes MongoDB and SQLServer\nRemarks​\nThe skipDuplicates option is not supported by SQLite.\nNote that the order of elements returned by createManyAndReturn is not guaranteed.\nYou cannot create or connect relations by using nested create, createMany, connect, connectOrCreate queries inside a top-level createManyAndReturn() query. See here for a workaround.\nWhen relations are included via include, a separate query is generated per relation.\nrelationLoadStrategy: join is not supported.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript array object (typed)\tUser[]\t\nJavaScript array object (plain)\t[{ name: \"Sonali\" }]\tUse select, omit and include to determine which fields to return.\nExamples​\nCreate and return several new users​\nconst users = await prisma.user.createManyAndReturn({\n\n  data: [\n\n    { name: 'Sonali', email: 'sonali@prisma.io' },\n\n    { name: 'Alex', email: 'alex@prisma.io' },\n\n  ],\n\n})\n\nShow CLI results\n[\n\n  { \"id\": 0, \"name\": \"Sonali\", \"email\": \"sonali@prisma.io\", \"profileViews\": 0 },\n\n  { \"id\": 1, \"name\": \"Alex\", \"email\": \"alex@prisma.io\", \"profileViews\": 0  }\n\n]\n\nupdateMany()​\n\nupdateMany updates a batch of existing database records in bulk and returns the number of updated records.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserUpdateManyMutationInput,\nUserUncheckedUpdateManyInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional on data.\nwhere\tUserWhereInput\tNo\tWraps all fields of a model so that the list can be filtered by any property. If you do not filter the list, all records will be updated.\nlimit\tnumber\tNo\tLimits the number of records to update.\nReturn type​\nReturn type\tExample\tDescription\nBatchPayload\t{ count: 4 }\tThe count of updated records.\nexport type BatchPayload = {\n\n  count: number;\n\n};\n\nExamples​\nUpdate all User records where the name is Alice to ALICE​\nconst updatedUserCount = await prisma.user.updateMany({\n\n  where: { name: 'Alice' },\n\n  data: { name: 'ALICE' },\n\n});\n\nUpdate all User records where the email contains prisma.io and at least one related Post has more than 10 likes​\nconst updatedUserCount = await prisma.user.updateMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n    posts: {\n\n      some: {\n\n        likes: {\n\n          gt: 10,\n\n        },\n\n      },\n\n    },\n\n  },\n\n  data: {\n\n    role: 'USER',\n\n  },\n\n});\n\nUpdate User records where the email contains prisma.io, but limit to 5 records updated.​\nconst updatedUserCount = await prisma.user.updateMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n  },\n\n  data: {\n\n    role: 'USER',\n\n  },\n\n  limit: 5,\n\n});\n\nupdateManyAndReturn()​\nINFO\n\nThis feature is available in Prisma ORM version 6.2.0 and later for PostgreSQL, CockroachDB and SQLite.\n\nupdateManyAndReturn updates multiple records and returns the resulting objects.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserUpdateManyMutationInput,\nUserUncheckedUpdateManyInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional on data.\nwhere\tUserWhereInput\tNo\tWraps all fields of a model so that the list can be filtered by any property. If you do not filter the list, all records will be updated.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript array object (typed)\tUser[]\t\nJavaScript array object (plain)\t[{ name: \"Sonali\" }]\tUse select, omit and include to determine which fields to return.\nExamples​\nUpdate and return multiple users​\nconst users = await prisma.user.updateManyAndReturn({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    }\n\n  },\n\n  data: {\n\n    role: 'ADMIN'\n\n  },\n\n})\n\nShow CLI results\n[\n\n  { \"id\": 0, \"name\": \"Sonali\", \"email\": \"sonali@prisma.io\", \"role\": \"ADMIN\", \"profileViews\": 0 },\n\n  { \"id\": 1, \"name\": \"Alex\", \"email\": \"alex@prisma.io\", \"role\": \"ADMIN\", \"profileViews\": 0  }\n\n]\n\ndeleteMany()​\n\ndeleteMany deletes multiple records in a transaction.\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all fields of a model so that the list can be filtered by any field.\nlimit\tInt\tNo\tLimits the number of records deleted.\nReturn type​\nReturn type\tExample\tDescription\nBatchPayload\t{ count: 4 }\tThe count of deleted records.\nexport type BatchPayload = {\n\n  count: number;\n\n};\n\nExamples​\nDelete all User records​\nconst deletedUserCount = await prisma.user.deleteMany({});\n\nDelete all User records where the name is Alice​\nconst deletedUserCount = await prisma.user.deleteMany({\n\n  where: { name: 'Alice' },\n\n});\n\nDelete all User records where the email contains prisma.io, but limit to 5 records deleted.​\nconst deletedUserCount = await prisma.user.deleteMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n  },\n\n  limit: 5,\n\n});\n\n\nSee Filter conditions and operators for examples of how to filter the records to delete.\n\ncount()​\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<PostOrder\nByInput>, PostOrderByInput>\tNo\tLets you order the returned list by any property.\ncursor\tUserWhereUniqueInput\tNo\tSpecifies the position for the list (the value typically specifies an id or another unique value).\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\nReturn type​\nReturn type\tExample\tDescription\nnumber\t29\tThe count of records.\nUserCountAggregateOutputType\t{ _all: 27, name: 10 }\tReturned if select is used.\nExamples​\nCount all User records​\nconst result = await prisma.user.count();\n\nCount all User records with at least one published Post​\nconst result = await prisma.user.count({\n\n  where: {\n\n    post: {\n\n      some: {\n\n        published: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nUse select to perform three separate counts​\n\nThe following query returns:\n\nA count of all records (_all)\nA count of all records with non-null name fields\nA count of all records with non-null city fields\nconst c = await prisma.user.count({\n\n  select: {\n\n    _all: true,\n\n    city: true,\n\n    name: true,\n\n  },\n\n});\n\naggregate()​\n\nSee also: Aggregation, grouping, and summarizing\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<UserOrderByInput>,\nUserOrderByInput>\tNo\tLets you order the returned list by any property.\ncursor\tUserWhereUniqueInput\tNo\tSpecifies the position for the list (the value typically specifies an id or another unique value).\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\n_count\ttrue\tNo\tReturns a count of matching records or non-null fields.\n_avg\tUserAvgAggregateInputType\tNo\tReturns an average of all values of the specified field.\n_sum\tUserSumAggregateInputType\tNo\tReturns the sum of all values of the specified field.\n_min\tUserMinAggregateInputType\tNo\tReturns the smallest available value of the specified field.\n_max\tUserMaxAggregateInputType\tNo\tReturns the largest available value of the specified field.\nExamples​\nReturn _min, _max, and _count of profileViews of all User records​\nconst minMaxAge = await prisma.user.aggregate({\n\n  _count: {\n\n    _all: true,\n\n  },\n\n  _max: {\n\n    profileViews: true,\n\n  },\n\n  _min: {\n\n    profileViews: true,\n\n  },\n\n});\n\nShow CLI results\nReturn _sum of all profileViews for all User records​\nconst setValue = await prisma.user.aggregate({\n\n  _sum: {\n\n    profileViews: true,\n\n  },\n\n});\n\nShow CLI results\ngroupBy()​\n\nSee also: Aggregation, grouping, and summarizing\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<UserOrderByInput>,\nUserOrderByInput>\tNo\tLets you order the returned list by any property that is also present in by.\nby\tArray<UserScalarFieldEnum> | string\tNo\tSpecifies the field or combination of fields to group records by.\nhaving\tUserScalarWhereWithAggregatesInput\tNo\tAllows you to filter groups by an aggregate value - for example, only return groups having an average age less than 50.\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\n_count\ttrue | UserCountAggregateInputType\tNo\tReturns a count of matching records or non-null fields.\n_avg\tUserAvgAggregateInputType\tNo\tReturns an average of all values of the specified field.\n_sum\tUserSumAggregateInputType\tNo\tReturns the sum of all values of the specified field.\n_min\tUserMinAggregateInputType\tNo\tReturns the smallest available value of the specified field.\n_max\tUserMaxAggregateInputType\tNo\tReturns the largest available value of the specified field.\nExamples​\nGroup by country/city where the average profileViews is greater than 200, and return the _sum of profileViews for each group​\n\nThe query also returns a count of _all records in each group, and all records with non-null city field values in each group.\n\nconst groupUsers = await prisma.user.groupBy({\n\n  by: ['country', 'city'],\n\n  _count: {\n\n    _all: true,\n\n    city: true,\n\n  },\n\n  _sum: {\n\n    profileViews: true,\n\n  },\n\n  orderBy: {\n\n    country: 'desc',\n\n  },\n\n  having: {\n\n    profileViews: {\n\n      _avg: {\n\n        gt: 200,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\n[\n\n  {\n\n    country: 'Denmark',\n\n    city: 'Copenhagen',\n\n    _sum: { profileViews: 490 },\n\n    _count: {\n\n      _all: 70,\n\n      city: 8,\n\n    },\n\n  },\n\n  {\n\n    country: 'Sweden',\n\n    city: 'Stockholm',\n\n    _sum: { profileViews: 500 },\n\n    _count: {\n\n      _all: 50,\n\n      city: 3,\n\n    },\n\n  },\n\n];\n\nfindRaw()​\n\nSee: Using Raw SQL (findRaw()).\n\naggregateRaw()​\n\nSee: Using Raw SQL (aggregateRaw()).\n\nModel query options​\nselect​\n\nselect defines which fields are included in the object that Prisma Client returns. See: Select fields and include relations .\n\nRemarks​\nYou cannot combine select and include on the same level.\nIn 3.0.1\n and later, you can select a _count of relations.\nExamples​\nSelect the name and profileViews fields of a single User record​\nconst result = await prisma.user.findUnique({\n\n  where: { id: 1 },\n\n  select: {\n\n    name: true,\n\n    profileViews: true,\n\n  },\n\n});\n\nShow CLI results\nSelect the email and role fields of a multiple User records​\nconst result = await prisma.user.findMany({\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n});\n\nShow CLI results\nSelect a _count of relations​\nconst usersWithCount = await prisma.user.findMany({\n\n  select: {\n\n    _count: {\n\n      select: { posts: true },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nSelect the 'id' and 'title' fields of related Post records​\nconst result = await prisma.user.findMany({\n\n  select: {\n\n    id: true,\n\n    name: true,\n\n    posts: {\n\n      select: {\n\n        id: true,\n\n        title: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\ninclude inside select​\nconst result = await prisma.user.findMany({\n\n  select: {\n\n    id: true,\n\n    name: true,\n\n    posts: {\n\n      include: {\n\n        author: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nGenerated types for select​\n\nThe following example demonstrates how to use the validator with select:\n\nconst selectNameEmailNotPosts = Prisma.validator<Prisma.UserSelect>()({\n\n  name: true,\n\n  email: true,\n\n  posts: false,\n\n});\n\ninclude​\n\ninclude defines which relations are included in the result that Prisma Client returns. See: Select fields and include relations .\n\nRemarks​\nIn 3.0.1\n and later, you can include a _count of relations\nExamples​\nInclude the posts and profile relation when loading User records​\nconst users = await prisma.user.findMany({\n\n  include: {\n\n    posts: true, // Returns all fields for all posts\n\n    profile: true, // Returns all Profile fields\n\n  },\n\n});\n\nInclude the posts relation on the returned objects when creating a new User record with two Post records​\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    posts: {\n\n      create: [{ title: 'This is my first post' }, { title: 'Here comes a second post' }],\n\n    },\n\n  },\n\n  include: { posts: true }, // Returns all fields for all posts\n\n});\n\nGenerated types for include​\n\nThe following example demonstrates how to use the validator with include:\n\nconst includePosts = Prisma.validator<Prisma.UserInclude>()({\n\n  posts: true,\n\n});\n\nInclude a _count of relations​\nconst usersWithCount = await prisma.user.findMany({\n\n  include: {\n\n    _count: {\n\n      select: { posts: true },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nomit​\n\nomit defines which fields are excluded in the object that Prisma Client returns.\n\nRemarks​\nYou cannot combine omit and select since they serve opposite purposes\nomit was released into General Availability with Prisma ORM 6.2.0. It was available via the omitApi Preview feature in Prisma ORM versions 5.13.0 through 6.1.0.\nExamples​\nOmit the password field from all User records​\nconst result = await prisma.user.findMany({\n\n  omit: {\n\n    password: true,\n\n  },\n\n});\n\nShow CLI results\nOmit the title fields from all User's posts relation​\nconst results = await prisma.user.findMany({\n\n  omit: {\n\n    password: true,\n\n  },\n\n  include: {\n\n    posts: {\n\n      omit: {\n\n        title: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nGenerated types for omit​\n\nThe following example demonstrates how to use the validator with omit:\n\nconst omitPassword = Prisma.validator<Prisma.UserOmit>()({\n\n  password: true,\n\n});\n\nrelationLoadStrategy (Preview)​\n\nrelationLoadStrategy specifies how a relation should be loaded from the database. It has two possible values:\n\njoin (default): Uses a database-level LATERAL JOIN (PostgreSQL) or correlated subqueries (MySQL) and fetches all data with a single query to the database.\nquery: Sends multiple queries to the database (one per table) and joins them on the application level.\n\nNote: Once relationLoadStrategy moves from Preview into General Availability, join will universally become the default for all relation queries.\n\nYou can learn more about join strategies here.\n\nBecause the relationLoadStrategy option is currently in Preview, you need to enable it via the relationJoins preview feature flag in your Prisma schema file:\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"relationJoins\"]\n\n}\n\n\nAfter adding this flag, you need to run prisma generate again to re-generate Prisma Client. The relationJoins feature is currently available on PostgreSQL, CockroachDB and MySQL.\n\nRemarks​\nIn most situations, the default join strategy will be more effective. Use query if you want to save resources on your database server or if you profiling shows that the application-level join is more performant.\nYou can only specify the relationLoadStrategy on the top-level in your query. The top-level choice will affect all nested sub-queries.\nExamples​\nLoad the posts relation via a database-level JOIN when using include​\nconst users = await prisma.user.findMany({\n\n  relationLoadStrategy: 'join',\n\n  include: {\n\n    posts: true,\n\n  },\n\n});\n\nLoad the posts relation via a database-level JOIN when using select​\nconst users = await prisma.user.findMany({\n\n  relationLoadStrategy: 'join',\n\n  select: {\n\n    posts: true,\n\n  },\n\n});\n\nwhere​\n\nwhere defines one or more filters, and can be used to filter on record properties (like a user's email address) or related record properties (like a user's top 10 most recent post titles).\n\nExamples​\nconst results = await prisma.user.findMany({\n\n  where: {\n\n    email: {\n\n      endsWith: 'prisma.io',\n\n    },\n\n  },\n\n});\n\nGenerated types for where​\n\nThe following examples demonstrate how to use the validator with where:\n\nUserWhereInput\n\n// UserWhereInput\n\nconst whereNameIs = Prisma.validator<Prisma.UserWhereInput>()({\n\n  name: 'Rich',\n\n});\n\n\n\n// It can be combined with conditional operators too\n\nconst whereNameIs = Prisma.validator<Prisma.UserWhereInput>()({\n\n  name: 'Rich',\n\n  AND: [\n\n    {\n\n      email: {\n\n        contains: 'rich@boop.com',\n\n      },\n\n    },\n\n  ],\n\n});\n\n\nUserWhereUniqueInput This type works by exposing any unique fields on the model. A field assigned @id is considered unique, as is one assigned @unique.\n\nFrom version 4.5.0, this type exposes all fields on the model. This means that when you filter for a single record based on a unique field, you can check additional non-unique and unique fields at the same time. Learn more.\n\n// UserWhereUniqueInput\n\nconst whereEmailIsUnique = Prisma.validator<Prisma.UserWhereUniqueInput>()({\n\n  email: 'rich@boop.com',\n\n})\n\n\nPostScalarWhereInput\n\nconst whereScalarTitleIs = Prisma.validator<Prisma.PostScalarWhereInput>()({\n\n  title: 'boop',\n\n});\n\n\nPostUpdateWithWhereUniqueWithoutAuthorInput - This type accepts a unique where field (an @id or another assigned @unique) and updates any field on the Post model except the Author. The Author is the scalar field on the Post model.\n\nconst updatePostByIdWithoutAuthor =\n\n  Prisma.validator<Prisma.PostUpdateWithWhereUniqueWithoutAuthorInput>()({\n\n    where: {\n\n      id: 1,\n\n    },\n\n    data: {\n\n      content: 'This is some updated content',\n\n      published: true,\n\n      title: 'This is a new title',\n\n    },\n\n  });\n\n\nPostUpsertWithWhereUniqueWithoutAuthorInput - This type will update the Post records title field where the id matches, if it doesn't exist it will create it instead.\n\nconst updatePostTitleOrCreateIfNotExist =\n\n  Prisma.validator<Prisma.PostUpsertWithWhereUniqueWithoutAuthorInput>()({\n\n    where: {\n\n      id: 1,\n\n    },\n\n    update: {\n\n      title: 'This is a new title',\n\n    },\n\n    create: {\n\n      id: 1,\n\n      title: 'If the title doesnt exist, then create one with this text',\n\n    },\n\n  });\n\n\nPostUpdateManyWithWhereWithoutAuthorInput - This type will update all Post records where published is set to false.\n\nconst publishAllPosts = Prisma.validator<Prisma.PostUpdateManyWithWhereWithoutAuthorInput>()({\n\n  where: {\n\n    published: {\n\n      equals: false,\n\n    },\n\n  },\n\n  data: {\n\n    published: true,\n\n  },\n\n});\n\norderBy​\n\nSorts a list of records. See also: Sorting\n\nRemarks​\n\nIn 2.16.0\n and later, you can order by relation fields - for example, order posts by the author's name.\n\nIn 3.5.0\n and later, in PostgreSQL you can order by relevance. For details, see Sort by relevance.\n\nIn 4.1.0\n and later, you can sort null records first or last. For details, see Sort with nulls first or last.\n\nInputs for sort argument​\nName\tDescription\nasc\tSort ascending (A → Z)\ndesc\tSort descending (Z → A)\nInputs for nulls argument​\n\nNote:\n\nThis argument is optional.\nIt is for use on optional scalar fields only. If you try to sort by nulls on a required or relation field, Prisma Client throws a P2009 error.\nIt is available in version 4.1.0 and later, as a preview feature. See sort with nulls first or last for details of how to enable the feature.\nName\tDescription\nfirst\tSort with null values first.\nlast\tSort with null values last.\nExamples​\nSort User by email field​\n\nThe following example returns all User records sorted by email ascending:\n\nconst users = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'asc',\n\n  },\n\n});\n\n\nThe following example returns all User records sorted by email descending:\n\nconst users = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'desc',\n\n  },\n\n});\n\nSort Post by the related User record's name​\n\nThe following query orders posts by user name:\n\nconst posts = await prisma.post.findMany({\n\n  orderBy: {\n\n    author: {\n\n      name: 'asc',\n\n    },\n\n  },\n\n});\n\nSort Post by the related User record's name, with null records first​\n\nThe following query orders posts by user name, with null records first:\n\nconst posts = await prisma.post.findMany({\n\n  orderBy: {\n\n    author: {\n\n      name: { sort: 'asc', nulls: 'first' },\n\n    },\n\n  },\n\n});\n\nSort Post by relevance of the title​\nINFO\n\nFor PostgreSQL, this feature is still in Preview. Enable the fullTextSearchPostgres feature flag in order to use it.\n\nThe following query orders posts by relevance of the search term 'database' to the title:\n\nconst posts = await prisma.post.findMany({\n\n  orderBy: {\n\n    _relevance: {\n\n      fields: ['title'],\n\n      search: 'database',\n\n      sort: 'asc'\n\n    },\n\n})\n\nSort User by the posts count​\n\nThe following query orders users by post count:\n\nconst getActiveusers = await prisma.user.findMany({\n\n  orderBy: {\n\n    posts: {\n\n      count: 'desc',\n\n    },\n\n  },\n\n});\n\nSort User by multiple fields - email and role​\n\nThe following example sorts users by two fields - first email, then role:\n\nconst users = await prisma.user.findMany({\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n  orderBy: [\n\n    {\n\n      email: 'desc',\n\n    },\n\n    {\n\n      role: 'desc',\n\n    },\n\n  ],\n\n});\n\nShow CLI results\n\nThe order of sorting parameters matters - the following query sorts by role, then email. Note the difference in the results:\n\nconst users = await prisma.user.findMany({\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n  orderBy: [\n\n    {\n\n      role: 'desc',\n\n    },\n\n    {\n\n      email: 'desc',\n\n    },\n\n  ],\n\n});\n\nShow CLI results\nSort User by email, select name and email​\n\nThe following example returns all the name and email fields of all User records, sorted by email:\n\nconst users3 = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'asc',\n\n  },\n\n  select: {\n\n    name: true,\n\n    email: true,\n\n  },\n\n});\n\nShow CLI results\nSort User records by email and sort nested Post records by title​\n\nThe following example:\n\nReturns all User records sorted by email\nFor each User record, returns the title field of all nested Post records sorted by title\nconst usersWithPosts = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'asc',\n\n  },\n\n  include: {\n\n    posts: {\n\n      select: {\n\n        title: true,\n\n      },\n\n      orderBy: {\n\n        title: 'asc',\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nSort one user's nested list of Post records​\n\nThe following example retrieves a single User record by ID, as well as a list of nested Post records sorted by title:\n\nconst userWithPosts = await prisma.user.findUnique({\n\n  where: {\n\n    id: 1,\n\n  },\n\n  include: {\n\n    posts: {\n\n      orderBy: {\n\n        title: 'desc',\n\n      },\n\n      select: {\n\n        title: true,\n\n        published: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nSort by enum​\n\nThe following sorts all User records by role (an enum):\n\nconst sort = await prisma.user.findMany({\n\n  orderBy: {\n\n    role: 'desc',\n\n  },\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n});\n\nShow CLI results\nGenerated types for orderBy​\n\nThe following examples demonstrate how to use the validator with orderBy:\n\nUserOrderByInput\nconst orderEmailsByDescending = Prisma.validator<Prisma.UserOrderByInput>()({\n\n  email: 'desc',\n\n});\n\ndistinct​\n\nDeduplicate a list of records from findMany or findFirst. See also: Aggregation, grouping, and summarizing\n\nExamples​\nSelect distinct on a single field​\n\nThe following example returns all distinct city fields, and selects only the city and country fields:\n\nconst distinctCities = await prisma.user.findMany({\n\n  select: {\n\n    city: true,\n\n    country: true,\n\n  },\n\n  distinct: ['city'],\n\n});\n\nShow CLI results\n[\n\n  { city: 'Paris', country: 'France' },\n\n  { city: 'Lyon', country: 'France' },\n\n];\n\nSelect distinct on multiple fields​\n\nThe following example returns all distinct city and country field combinations, and selects only the city and country fields:\n\nconst distinctCitiesAndCountries = await prisma.user.findMany({\n\n  select: {\n\n    city: true,\n\n    country: true,\n\n  },\n\n  distinct: ['city', 'country'],\n\n});\n\nShow CLI results\n[\n\n  { city: 'Paris', country: 'France' },\n\n  { city: 'Paris', country: 'Denmark' },\n\n  { city: 'Lyon', country: 'France' },\n\n];\n\n\nNote that there is now a \"Paris, Denmark\" in addition to \"Paris, France\":\n\nSelect distinct in combination with a filter​\n\nThe following example returns all distinct city and country field combinations where the user's email contains \"prisma.io\", and selects only the city and country fields:\n\nconst distinctCitiesAndCountries = await prisma.user.findMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n  },\n\n  select: {\n\n    city: true,\n\n    country: true,\n\n  },\n\n  distinct: ['city', 'country'],\n\n});\n\nShow CLI results\nnativeDistinct​\n\nEnabling nativeDistinct in your Prisma schema pushes the distinct operation to the database layer (where supported). This can significantly improve performance. However, note that:\n\nSome databases may not fully support DISTINCT on certain field combinations.\nBehavior can differ among providers.\n\nTo enable nativeDistinct:\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"nativeDistinct\"]\n\n}\n\n\nSee Preview Features for more details.\n\nNested queries​\ncreate​\n\nA nested create query adds a new related record or set of records to a parent record. See: Working with relations\n\nRemarks​\ncreate is available as a nested query when you create() (prisma.user.create(...)) a new parent record or update() (prisma.user.update(...)) an existing parent record.\nYou can use a nested create or a nested createMany to create multiple related records. If you require the skipDuplicates query option you should use createMany.\nExamples​\nCreate a new User record with a new Profile record​\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    profile: {\n\n      create: { bio: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nCreate a new Profile record with a new User record​\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    user: {\n\n      create: { email: 'alice@prisma.io' },\n\n    },\n\n  },\n\n})\n\nCreate a new User record with a new Post record​\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    posts: {\n\n      create: { title: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nCreate a new User record with two new Post records​\n\nBecause it's a one-to-many relation, you can also create multiple Post records at once by passing an array to create:\n\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    posts: {\n\n      create: [\n\n        {\n\n          title: 'This is my first post',\n\n        },\n\n        {\n\n          title: 'Here comes a second post',\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\n\nNote: You can also use a nested createMany to achieve the same result.\n\nUpdate an existing User record by creating a new Profile record​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      create: { bio: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by creating a new Post record​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      create: { title: 'Hello World' },\n\n    },\n\n  },\n\n})\n\ncreateMany​\n\nA nested createMany query adds a new set of records to a parent record. See: Working with relations\n\nRemarks​\ncreateMany is available as a nested query when you create() (prisma.user.create(...)) a new parent record or update() (prisma.user.update(...)) an existing parent record.\nAvailable in the context of a one-to-many relation — for example, you can prisma.user.create(...) a user and use a nested createMany to create multiple posts (posts have one user).\nNot available in the context of a many-to-many relation — for example, you cannot prisma.post.create(...) a post and use a nested createMany to create categories (many posts have many categories).\nYou cannot nest an additional create or createMany.\nAllows setting foreign keys directly — for example, setting the categoryId on a post.\nAs of Prisma ORM version 5.12.0, nested createMany is supported by SQLite.\nYou can use a nested create or a nested createMany to create multiple related records - if you do not need the skipDuplicates query option, you should probably use create.\nOptions​\nName\tType\tRequired\tDescription\ndata\tEnumerable<UserCreateManyInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. Fields that are marked as optional or have default values in the datamodel are optional.\nskipDuplicates?\tboolean\tNo\tDo not insert records with unique fields or ID fields that already exist. Only supported by databases that support \nON CONFLICT DO NOTHING\n. This excludes MongoDB and SQLServer\nExamples​\nUpdate a User and multiple new related Post records​\nconst user = await prisma.user.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    name: 'Elliott',\n\n    posts: {\n\n      createMany: {\n\n        data: [{ title: 'My first post' }, { title: 'My second post' }],\n\n      },\n\n    },\n\n  },\n\n});\n\nset​\n\nset overwrites the value of a relation - for example, replacing a list of Post records with a different list. See: Working with relations\n\nExamples​\nUpdate an existing User record by disconnecting any previous Post records and connecting two other existing ones​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      set: [{ id: 32 }, { id: 42 }],\n\n    },\n\n  },\n\n});\n\nconnect​\n\nA nested connect query connects a record to an existing related record by specifying an ID or unique identifier. See: Working with relations\n\nRemarks​\n\nconnect is available as a nested query when you create a new parent record or update an existing parent record.\n\nIf the related record does not exist, Prisma Client throws an exception:\n\nThe required connected records were not found. Expected 1 records to be connected, found 0.\n\n\nWhen using set and connect together, the order in which they are applied significantly impacts the result. If set is used before connect, the connected records will only reflect the final state established by the connect operation, as set clears all existing connections before connect establishes new ones. Conversely, if connect is applied before set, the set operation will override the connect action by clearing all connected records and replacing them with its own specified state.\n\nExamples​\nCreate a new Profile record and connect it to an existing User record via unique field​\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    user: {\n\n      connect: { email: 'alice@prisma.io' },\n\n    },\n\n  },\n\n});\n\nCreate a new Profile record and connect it to an existing User record via an ID field​\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    user: {\n\n      connect: { id: 42 }, // sets userId of Profile record\n\n    },\n\n  },\n\n});\n\n\nIn 2.11.0\n and later, you can set the foreign key directly:\n\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    userId: 42,\n\n  },\n\n});\n\n\nHowever, you can't use both the direct approach and the connect approach in the same query. See this issue comment\n for details.\n\nCreate a new Post record and connect it to an existing User record​\nconst user = await prisma.post.create({\n\n  data: {\n\n    title: 'Hello World',\n\n    author: {\n\n      connect: { email: 'alice@prisma.io' },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connecting it to an existing Profile record​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      connect: { id: 24 },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connecting it to two existing Post records​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      connect: [{ id: 24 }, { id: 42 }],\n\n    },\n\n  },\n\n});\n\nconnectOrCreate​\n\nconnectOrCreate either connects a record to an existing related record by ID or unique identifier or creates a new related record if the record does not exist. See: Working with relations\n\nRemarks​\n\nMultiple connectOrCreate queries that run as concurrent transactions can result in a race condition. Consider the following example, where two queries attempt to connectOrCreate a blog post tag named computing at the same time (tag names must be unique):\n\nQuery A\nQuery B\nconst createPost = await prisma.post.create({\n\n  data: {\n\n    title: 'How to create a compiler',\n\n    content: '...',\n\n    author: {\n\n      connect: {\n\n        id: 9,\n\n      },\n\n    },\n\n    tags: {\n\n      connectOrCreate: {\n\n        create: {\n\n          name: 'computing',\n\n        },\n\n        where: {\n\n          name: 'computing',\n\n        },\n\n      },\n\n    },\n\n  },\n\n})\n\n\nIf query A and query B overlap in the following way, query A results in an exception:\n\nQuery A (Fail ❌)\tQuery B (Success ✅)\nQuery hits server, starts transaction A\tQuery hits server, starts transaction B\n\tFind record where tagName equals computing, record not found\nFind record where tagName equals computing, record not found\t\n\tCreate record where tagName equals computing and connect\nCreate record where tagName equals computing\t\nUnique violation, record already created by transaction B\t\n\nTo work around this scenario, we recommend catching the unique violation exception (PrismaClientKnownRequestError, error P2002) and retrying failed queries.\n\nExamples​\nCreate a new Profile record, then connect it to an existing User record or create a new User​\n\nThe following example:\n\nCreates a Profile\nAttempts to connect the profile to a User where the email address is alice@prisma.io\nCreates a new user if a matching user does not exist\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'The coolest Alice on the planet',\n\n    user: {\n\n      connectOrCreate: {\n\n        where:  { email: 'alice@prisma.io' },\n\n        create: { email: 'alice@prisma.io'}\n\n    },\n\n  },\n\n})\n\nCreate a new Post record and connect it to an existing User record, or create a new User​\nconst user = await prisma.post.create({\n\n  data: {\n\n    title: 'Hello World',\n\n    author: {\n\n      connectOrCreate: {\n\n        where: { email: 'alice@prisma.io' },\n\n        create: { email: 'alice@prisma.io' },\n\n      },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connecting it to an existing Profile record, or creating a new Profile record​\n\nThe following example:\n\nAttempts to connect the user to a Profile with an id of 20\nCreates a new profile if a matching profile does not exist\nconst updateUser = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      connectOrCreate: {\n\n        where: { id: 20 },\n\n        create: {\n\n          bio: 'The coolest Alice in town',\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connect it to two existing Post records, or creating two new Post records​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      connectOrCreate: [\n\n        {\n\n          where: { id: 32 },\n\n          create: { title: 'This is my first post' },\n\n        },\n\n        {\n\n          where: { id: 19 },\n\n          create: { title: 'This is my second post' },\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\ndisconnect​\n\nA nested disconnect query breaks the connection between a parent record and a related record, but does not delete either record. See: Working with relations\n\nRemarks​\n\ndisconnect is only available if the relation is optional.\n\nIf the relationship you are attempting to disconnect does not exist:\n\n(In 2.21.0 and later\n), the operation does nothing\n\n(Before 2.21.0\n) Prisma Client throws an exception if the provided ID or unique identifier is not connected:\n\nThe records for relation `PostToUser` between the `User` and `Post` models are not connected.\n\nExamples​\nUpdate an existing User record by disconnecting the Profile record it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'bob@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      disconnect: true,\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by disconnecting two Post records it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      disconnect: [{ id: 44 }, { id: 46 }],\n\n    },\n\n  },\n\n});\n\nupdate​\n\nA nested update query updates one or more related records where the parent record's ID is n. See: Working with relations\n\nRemarks​\n\nNested update queries are only available in the context of a top-level update query (for example, prisma.user.update(...)).\n\nIf the parent record does not exist, Prisma Client throws an exception:\n\nAssertionError(\"Expected a valid parent ID to be present for nested update to-one case.\")\n\n\nIf the related record that you want to update does not exist, Prisma Client throws an exception:\n\nAssertionError(\"Expected a valid parent ID to be present for nested update to-one case.\")\n\nExamples​\nUpdate an existing User record by updating the Profile record it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      update: { bio: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by updating two Post records it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      update: [\n\n        {\n\n          data: { published: true },\n\n          where: { id: 32 },\n\n        },\n\n        {\n\n          data: { published: true },\n\n          where: { id: 23 },\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\nupsert​\nINFO\n\nThis section covers the usage of nested upsert within update(). To learn about the upsert() operation, reference the linked documentation.\n\nA nested upsert query updates a related record if it exists, or creates a new related record.\n\nExamples​\nUpdate an existing User record by updating the Profile record it's connected to or creating a new one (upsert)​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      upsert: {\n\n        create: { bio: 'Hello World' },\n\n        update: { bio: 'Hello World' },\n\n      },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by updating two Post record it's connected to or creating new ones (upsert)​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      upsert: [\n\n        {\n\n          create: { title: 'This is my first post' },\n\n          update: { title: 'This is my first post' },\n\n          where: { id: 32 },\n\n        },\n\n        {\n\n          create: { title: 'This is my second post' },\n\n          update: { title: 'This is my second post' },\n\n          where: { id: 23 },\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\ndelete​\n\nA nested delete query deletes a related record. The parent record is not deleted.\n\nRemarks​\ndelete is only available if the relation is optional.\nExamples​\nUpdate an existing User record by deleting the Profile record it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      delete: true,\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by deleting two Post records it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      delete: [{ id: 34 }, { id: 36 }],\n\n    },\n\n  },\n\n});\n\nupdateMany​\n\nA nested updateMany updates a list of related records and supports filtering - for example, you can update a user's unpublished posts.\n\nExamples​\nUpdate all unpublished posts belonging to a specific user​\nconst result = await prisma.user.update({\n\n  where: {\n\n    id: 2,\n\n  },\n\n  data: {\n\n    posts: {\n\n      updateMany: {\n\n        where: {\n\n          published: false,\n\n        },\n\n        data: {\n\n          likes: 0,\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\ndeleteMany​\n\nA nested deleteMany deletes related records and supports filtering. For example, you can delete a user's posts while updating other properties of that user.\n\nExamples​\nDelete all posts belonging to a specific user as part of an update​\nconst result = await prisma.user.update({\n\n  where: {\n\n    id: 2,\n\n  },\n\n  data: {\n\n    name: 'Updated name',\n\n    posts: {\n\n      deleteMany: {},\n\n    },\n\n  },\n\n});\n\nFilter conditions and operators​\nequals​\n\nValue equals n.\n\nExamples​\n\nReturn all users where name equals \"Eleanor\"\n\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    name: {\n\n      equals: 'Eleanor',\n\n    },\n\n  },\n\n});\n\n\nYou can also exclude the equals:\n\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    name: 'Eleanor',\n\n  },\n\n});\n\n\nReturn all products with a quantity lower than the \"warn quantity\" threshold\n\nThis example compares fields of the same model which is available as of version 4.3.0.\n\nconst productsWithLowQuantity = await prisma.product.findMany({\n\n  where: {\n\n    quantity: {\n\n      lte: prisma.product.fields.warnQuantity\n\n    },\n\n  },\n\n});\n\n\nReturn all users that have blue and green as their favorite colors\n\nThis example finds users that have set their favoriteColors field to ['blue', 'green'].\n\nNote that when using equals, order of elements matters. That is to say ['blue', 'green'] is not equal to ['green', 'blue']\n\nconst favoriteColorFriends = await prisma.user.findMany({\n\n  where: {\n\n    favoriteColors: {\n\n      equals: ['blue', 'green'],\n\n    },\n\n  },\n\n});\n\nnot​\n\nValue does not equal n.\n\nExamples​\nReturn all users where name does not equal \"Eleanor\"​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    name: {\n\n      not: 'Eleanor',\n\n    },\n\n  },\n\n});\n\nWARNING\n\nnot will return all items that do not match a given value. However, if the column is nullable, NULL values will not be returned. If you require null values to be returned, use an OR operator to include NULL values.\n\nReturn all users where name does not equal \"Eleanor\" including users where name is NULL​\nawait prisma.user.findMany({\n\n  where: {\n\n    OR: [\n\n      { name: { not: 'Eleanor' } },\n\n      { name: null }\n\n    ]\n\n  }\n\n})\n\nin​\n\nValue n exists in list.\n\nNOTE\n\nnull values are not returned. For example, if you combine in and NOT to return a user whose name is not in the list, users with null value names are not returned.\n\nExamples​\nGet User records where the id can be found in the following list: [22, 91, 14, 2, 5]​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    id: { in: [22, 91, 14, 2, 5] },\n\n  },\n\n});\n\nGet User records where the name can be found in the following list: ['Saqui', 'Clementine', 'Bob']​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    name: { in: ['Saqui', 'Clementine', 'Bob'] },\n\n  },\n\n});\n\nGet User records where name is not present in the list​\n\nThe following example combines in and NOT. You can also use notIn.\n\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    NOT: {\n\n      name: { in: ['Saqui', 'Clementine', 'Bob'] },\n\n    },\n\n  },\n\n});\n\nGet a User record where at least one Post has at least one specified Category​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    // Find users where..\n\n    posts: {\n\n      some: {\n\n        // ..at least one (some) posts..\n\n        categories: {\n\n          some: {\n\n            // .. have at least one category ..\n\n            name: {\n\n              in: ['Food', 'Introductions'], // .. with a name that matches one of the following.\n\n            },\n\n          },\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\nnotIn​\n\nValue n does not exist in list.\n\nRemarks​\nnull values are not returned.\nExamples​\nGet User records where the id can not be found in the following list: [22, 91, 14, 2, 5]​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    id: { notIn: [22, 91, 14, 2, 5] },\n\n  },\n\n});\n\nlt​\n\nValue n is less than x.\n\nExamples​\nGet all Post records where likes is less than 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      lt: 9,\n\n    },\n\n  },\n\n});\n\nlte​\n\nValue n is less than or equal to x.\n\nExamples​\nGet all Post records where likes is less or equal to 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      lte: 9,\n\n    },\n\n  },\n\n});\n\ngt​\n\nValue n is greater than x.\n\nExamples​\nGet all Post records where likes is greater than 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      gt: 9,\n\n    },\n\n  },\n\n});\n\ngte​\n\nValue n is greater than or equal to x.\n\nExamples​\nGet all Post records where likes is greater than or equal to 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      gte: 9,\n\n    },\n\n  },\n\n});\n\nExamples​\nGet all Post records where date_created is greater than March 19th, 2020​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    date_created: {\n\n      gte: new Date('2020-03-19T14:21:00+0200') /* Includes time offset for UTC */,\n\n    },\n\n  },\n\n});\n\ncontains​\n\nValue n contains x.\n\nExamples​\nCount all Post records where content contains databases​\nconst result = await prisma.post.count({\n\n  where: {\n\n    content: {\n\n      contains: 'databases',\n\n    },\n\n  },\n\n});\n\nCount all Post records where content does not contain databases​\nconst result = await prisma.post.count({\n\n  where: {\n\n    NOT: {\n\n      content: {\n\n        contains: 'databases',\n\n      },\n\n    },\n\n  },\n\n});\n\nsearch​\n\nUse Full-Text Search to search within a String field.\n\nINFO\n\nFor PostgreSQL, this feature is still in Preview. Enable the fullTextSearchPostgres feature flag in order to use it.\n\nExamples​\nFind all posts with a title that contains cat or dog.​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      search: 'cat | dog',\n\n    },\n\n  },\n\n});\n\nFind all posts with a title that contains cat and dog.​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      search: 'cat & dog',\n\n    },\n\n  },\n\n});\n\nFind all posts with a title that doesn't contain cat.​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      search: '!cat',\n\n    },\n\n  },\n\n});\n\nmode​\nRemarks​\nSupported by the PostgreSQL and MongoDB connectors only\nExamples​\nGet all Post records where title contains prisma, in a case insensitive way​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      contains: 'prisma',\n\n      mode: 'insensitive',\n\n    },\n\n  },\n\n});\n\nstartsWith​\nExamples​\nGet all Post records where title starts with Pr (such as Prisma)​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      startsWith: 'Pr',\n\n    },\n\n  },\n\n});\n\nendsWith​\nGet all User records where email ends with prisma.io​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    email: {\n\n      endsWith: 'prisma.io',\n\n    },\n\n  },\n\n});\n\nAND​\n\nAll conditions must return true. Alternatively, pass a list of objects into the where clause - the AND operator is not required.\n\nExamples​\nGet all Post records where the content field contains Prisma and published is false​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    AND: [\n\n      {\n\n        content: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        published: {\n\n          equals: false,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\nGet all Post records where the content field contains Prisma and published is false (no AND)​\n\nThe following format returns the same results as the previous example without the AND operator:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    content: {\n\n      contains: 'Prisma',\n\n    },\n\n    published: {\n\n      equals: false,\n\n    },\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, and published is false​\n\nThe following example combines OR and AND:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    AND: {\n\n      published: false,\n\n    },\n\n  },\n\n});\n\nOR​\n\nOne or more conditions must return true.\n\nExamples​\nGet all Post records where the title field contains Prisma or databases​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, but not SQL​\n\nThe following example combines OR and NOT:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    NOT: {\n\n      title: {\n\n        contains: 'SQL',\n\n      },\n\n    },\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, and published is false​\n\nThe following example combines OR and AND:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    AND: {\n\n      published: false,\n\n    },\n\n  },\n\n});\n\nNOT​\n\nAll conditions must return false.\n\nExamples​\nGet all Post records where the title does not contain SQL​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    NOT: {\n\n      title: {\n\n        contains: 'SQL',\n\n      },\n\n    },\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, but not SQL, and the related User record' email address does not contain sarah​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    NOT: {\n\n      title: {\n\n        contains: 'SQL',\n\n      },\n\n    },\n\n    user: {\n\n      NOT: {\n\n        email: {\n\n          contains: 'sarah',\n\n        },\n\n      },\n\n    },\n\n  },\n\n  include: {\n\n    user: true,\n\n  },\n\n});\n\nRelation filters​\nsome​\n\nReturns all records where one or more (\"some\") related records match filtering criteria.\n\nRemarks​\nYou can use some without parameters to return all records with at least one relation\nExamples​\nGet all User records where some posts mention Prisma​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n      some: {\n\n        content: {\n\n          contains: \"Prisma\"\n\n        }\n\n      }\n\n    }\n\n  }\n\n}\n\nevery​\n\nReturns all records where all (\"every\") related records match filtering criteria.\n\nExamples​\nGet all User records where all posts are published​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n      every: {\n\n        published: true\n\n      },\n\n    }\n\n  }\n\n}\n\nnone​\n\nReturns all records where zero related records match filtering criteria.\n\nRemarks​\nYou can use none without parameters to return all records with no relations\nExamples​\nGet all User records with zero posts​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n        none: {} // User has no posts\n\n    }\n\n  }\n\n}\n\nGet all User records with zero published posts​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n        none: {\n\n          published: true\n\n        }\n\n    }\n\n  }\n\n}\n\nis​\n\nReturns all records where related record matches filtering criteria (for example, user's name is Bob).\n\nExamples​\nGet all Post records where user's name is \"Bob\"​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    user: {\n\n        is: {\n\n          name: \"Bob\"\n\n        },\n\n    }\n\n  }\n\n}\n\nisNot​\n\nReturns all records where the related record does not match the filtering criteria (for example, user's name isNot Bob).\n\nExamples​\nGet all Post records where user's name is NOT \"Bob\"​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    user: {\n\n        isNot: {\n\n          name: \"Bob\"\n\n        },\n\n    }\n\n  }\n\n}\n\nScalar list methods​\nset​\n\nUse set to overwrite the value of a scalar list field.\n\nRemarks​\n\nset is optional - you can set the value directly:\n\ntags: ['computers', 'books'];\n\nExamples​\nSet the value of tags to a list of string values​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      set: ['computing', 'books'],\n\n    },\n\n  },\n\n});\n\nSet tags to a list of values without using the set keyword​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: ['computing', 'books'],\n\n  },\n\n});\n\nSet the value of tags to a single string value​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      set: 'computing',\n\n    },\n\n  },\n\n});\n\npush​\n\npush is available in version 2.20.0\n and later. Use push to add one value or multiple values to a scalar list field.\n\nRemarks​\nAvailable for PostgreSQL and MongoDB only.\nYou can push a list of values or only a single value.\nExamples​\nAdd a computing item to the tags list​\nconst addTag = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      push: 'computing',\n\n    },\n\n  },\n\n});\n\nconst addTag = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      push: ['computing', 'genetics'],\n\n    },\n\n  },\n\n});\n\nunset​\nWARNING\n\nThis method is available on MongoDB only in versions 3.11.1\n and later.\n\nUse unset to unset the value of a scalar list. Unlike set: null, unset removes the list entirely.\n\nExamples​\nUnset the value of tags​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      unset: true,\n\n    },\n\n  },\n\n});\n\nScalar list filters​\n\nScalar list filters allow you to filter by the contents of a list / array field.\n\nWARNING\n\nAvailable for:\n\nPostgreSQL in versions 2.15.0\n and later\nCockroachDB in versions 3.9.0\n and later\nMongoDB in versions 3.11.0\n and later\nRemarks​\nScalar list / array filters ignore NULL values . Using isEmpty or NOT does not return records with NULL value lists / arrays, and { equals: null } results in an error.\nhas​\n\nThe given value exists in the list.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes \"databases\":\n\nconst posts = await client.post.findMany({\n\n  where: {\n\n    tags: {\n\n      has: 'databases',\n\n    },\n\n  },\n\n});\n\n\nThe following query returns all Post records where the tags list does not include \"databases\":\n\nconst posts = await client.post.findMany({\n\n  where: {\n\n    NOT: {\n\n      tags: {\n\n        has: 'databases',\n\n      },\n\n    },\n\n  },\n\n});\n\nhasEvery​\n\nEvery value exists in the list.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes at least \"databases\" and \"typescript\":\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      hasEvery: ['databases', 'typescript'],\n\n    },\n\n  },\n\n});\n\nhasSome​\n\nAt least one value exists in the list.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes \"databases\" or \"typescript\":\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      hasSome: ['databases', 'typescript'],\n\n    },\n\n  },\n\n});\n\nisEmpty​\n\nThe list is empty.\n\nExamples​\n\nThe following query returns all Post records that have no tags:\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      isEmpty: true,\n\n    },\n\n  },\n\n});\n\nisSet​\nWARNING\n\nThis filter is available on MongoDB only in versions 3.11.1\n and later.\n\nFilter lists to include only results that have been set (either set to a value, or explicitly set to null). Setting this filter to true will exclude undefined results that are not set at all.\n\nExamples​\n\nThe following query returns all Post records where the tags have been set to either null or a value:\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      isSet: true,\n\n    },\n\n  },\n\n});\n\nequals​\n\nThe list matches the given value exactly.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes \"databases\" and \"typescript\" only:\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      equals: ['databases', 'typescript'],\n\n    },\n\n  },\n\n});\n\nComposite type methods​\nWARNING\n\nAvailable for MongoDB only in Prisma 3.10.0 and later.\n\nComposite type methods allow you to create, update and delete composite types.\n\nset​\n\nUse set to overwrite the value of a composite type.\n\nRemarks​\nThe set keyword is optional - you can set the value directly:\nphotos: [\n\n  { height: 100, width: 200, url: '1.jpg' },\n\n  { height: 100, width: 200, url: '2.jpg' },\n\n];\n\nExamples​\nSet the shippingAddress composite type within a new order​\nconst order = await prisma.order.create({\n\n  data: {\n\n    // Normal relation\n\n    product: { connect: { id: 'some-object-id' } },\n\n    color: 'Red',\n\n    size: 'Large',\n\n    // Composite type\n\n    shippingAddress: {\n\n      set: {\n\n        street: '1084 Candycane Lane',\n\n        city: 'Silverlake',\n\n        zip: '84323',\n\n      },\n\n    },\n\n  },\n\n});\n\nSet an optional composite type to null​\nconst order = await prisma.order.create({\n\n  data: {\n\n    // Embedded optional type, set to null\n\n    billingAddress: {\n\n      set: null,\n\n    },\n\n  },\n\n});\n\nunset​\n\nUse unset to unset the value of a composite type. Unlike set: null, this removes the field entirely from the MongoDB document.\n\nExamples​\nRemove the billingAddress from an order​\nconst order = await prisma.order.update({\n\n  where: {\n\n    id: 'some-object-id',\n\n  },\n\n  data: {\n\n    billingAddress: {\n\n      // Unset the billing address\n\n      // Removes \"billingAddress\" field from order\n\n      unset: true,\n\n    },\n\n  },\n\n});\n\nupdate​\n\nUse update to update fields within a required composite type.\n\nRemarks​\n\nThe update method cannot be used on optional types. Instead, use upsert\n\nExamples​\nUpdate the zip field of a shippingAddress composite type​\nconst order = await prisma.order.update({\n\n  where: {\n\n    id: 'some-object-id',\n\n  },\n\n  data: {\n\n    shippingAddress: {\n\n      // Update just the zip field\n\n      update: {\n\n        zip: '41232',\n\n      },\n\n    },\n\n  },\n\n});\n\nupsert​\n\nUse upsert to update an existing optional composite type if it exists, and otherwise set the composite type.\n\nRemarks​\n\nThe upsert method cannot be used on required types. Instead, use update\n\nExamples​\nCreate a new billingAddress if it doesn't exist, and otherwise update it​\nconst order = await prisma.order.update({\n\n  where: {\n\n    id: 'some-object-id',\n\n  },\n\n  data: {\n\n    billingAddress: {\n\n      // Create the address if it doesn't exist,\n\n      // otherwise update it\n\n      upsert: {\n\n        set: {\n\n          street: '1084 Candycane Lane',\n\n          city: 'Silverlake',\n\n          zip: '84323',\n\n        },\n\n        update: {\n\n          zip: '84323',\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\npush​\n\nUse push to push values to the end of a list of composite types.\n\nExamples​\nAdd a new photo to the photos list​\nconst product = prisma.product.update({\n\n  where: {\n\n    id: 10,\n\n  },\n\n  data: {\n\n    photos: {\n\n      // Push a photo to the end of the photos list\n\n      push: [{ height: 100, width: 200, url: '1.jpg' }],\n\n    },\n\n  },\n\n});\n\nComposite type filters​\nWARNING\n\nAvailable for MongoDB only in Prisma 3.11.0 and later.\n\nComposite type filters allow you to filter the contents of composite types.\n\nequals​\n\nUse equals to filter results by matching a composite type or a list of composite types. Requires all required fields of the composite type to match.\n\nRemarks​\n\nWhen matching optional fields, you need to distinguish between undefined (missing) fields of the document, and fields that have been explicitly set to null:\n\nIf you omit an optional field, it will match undefined fields, but not fields that have been set to null\nIf you filter for null values of an optional field with equals: { ... exampleField: null ... }, then it will match only documents where the field has been set to null, and not undefined fields\n\nThe ordering of fields and lists matters when using equals:\n\nFor fields, { \"a\": \"1\", \"b\": \"2\" } and { \"b\": \"2\", \"a\": \"1\" } are not considered equal\nFor lists, [ { \"a\": 1 }, { \"a\": 2 } ] and [ { \"a\": 2 }, { \"a\": 1 } ] are not considered equal\nExamples​\nFind orders that exactly match the given shippingAddress​\nconst orders = await prisma.order.findMany({\n\n  where: {\n\n    shippingAddress: {\n\n      equals: {\n\n        street: '555 Candy Cane Lane',\n\n        city: 'Wonderland',\n\n        zip: '52337',\n\n      },\n\n    },\n\n  },\n\n});\n\nFind products with photos that match all of a list of urls​\nconst product = prisma.product.findMany({\n\n  where: {\n\n    equals: {\n\n      photos: [{ url: '1.jpg' }, { url: '2.jpg' }],\n\n    },\n\n  },\n\n});\n\nis​\n\nUse is to filter results by matching specific fields within composite types.\n\nExamples​\nFind orders with a shippingAddress that matches the given street name​\nconst orders = await prisma.order.findMany({\n\n  where: {\n\n    shippingAddress: {\n\n      is: {\n\n        street: '555 Candy Cane Lane',\n\n      },\n\n    },\n\n  },\n\n});\n\nisNot​\n\nUse isNot to filter results for composite type fields that do not match.\n\nExamples​\nFind orders with a shippingAddress that does not match the given zip code​\nconst orders = await prisma.order.findMany({\n\n  where: {\n\n    shippingAddress: {\n\n      isNot: {\n\n        zip: '52337',\n\n      },\n\n    },\n\n  },\n\n});\n\nisEmpty​\n\nUse isEmpty to filter results for an empty list of composite types.\n\nExamples​\nFind products with no photos​\nconst product = prisma.product.findMany({\n\n  where: {\n\n    photos: {\n\n      isEmpty: true,\n\n    },\n\n  },\n\n});\n\nevery​\n\nUse every to filter for lists of composite types where every item in the list matches the condition\n\nExamples​\nFind the first product where every photo has a height of 200​\nconst product = await prisma.product.findFirst({\n\n  where: {\n\n    photos: {\n\n      every: {\n\n        height: 200,\n\n      }\n\n    }\n\n  },\n\n})\n\nsome​\n\nUse some to filter for lists of composite types where one or more items in the list match the condition.\n\nExamples​\nFind the first product where one or more photos have a url of 2.jpg​\nconst product = await prisma.product.findFirst({\n\n  where: {\n\n    photos: {\n\n      some: {\n\n         url: \"2.jpg\",\n\n      }\n\n    }\n\n  },\n\n})\n\nnone​\n\nUse none to filter for lists of composite types where no items in the list match the condition.\n\nExamples​\nFind the first product where no photos have a url of 2.jpg​\nconst product = await prisma.product.findFirst({\n\n  where: {\n\n    photos: {\n\n      none: {\n\n         url: \"2.jpg\",\n\n      }\n\n    }\n\n  },\n\n})\n\nAtomic number operations​\n\nAtomic operations on update is available for number field types (Float and Int). This feature allows you to update a field based on its current value (such as subtracting or dividing) without risking a race condition.\n\nOverview: Race conditions\nOperators​\nOption\tDescription\nincrement\tAdds n to the current value.\ndecrement\tSubtacts n from the current value.\nmultiply\tMultiplies the current value by n.\ndivide\tDivides the current value by n.\nset\tSets the current field value. Identical to { myField : n }.\nRemarks​\nYou can only perform one atomic update per field, per query.\nIf a field is null, it will not be updated by increment, decrement, multiply, or divide.\nExamples​\nIncrement all view and likes fields of all Post records by 1​\nconst updatePosts = await prisma.post.updateMany({\n\n  data: {\n\n    views: {\n\n      increment: 1,\n\n    },\n\n    likes: {\n\n      increment: 1,\n\n    },\n\n  },\n\n});\n\nSet all views fields of all Post records to 0​\nconst updatePosts = await prisma.post.updateMany({\n\n  data: {\n\n    views: {\n\n      set: 0,\n\n    },\n\n  },\n\n});\n\n\nCan also be written as:\n\nconst updatePosts = await prisma.post.updateMany({\n\n  data: {\n\n    views: 0,\n\n  },\n\n});\n\nJson filters​\n\nFor use cases and advanced examples, see: Working with Json fields.\n\nWARNING\n\nSupported by PostgreSQL and MySQL with different syntaxes for the path option. PostgreSQL does not support filtering on object key values in arrays.\n\nThe examples in this section assumes that the value of the pet field is:\n\n{\n\n  \"favorites\": {\n\n    \"catBreed\": \"Turkish van\",\n\n    \"dogBreed\": \"Rottweiler\",\n\n    \"sanctuaries\": [\"RSPCA\", \"Alley Cat Allies\"],\n\n    \"treats\": [\n\n      { \"name\": \"Dreamies\", \"manufacturer\": \"Mars Inc\" },\n\n      { \"name\": \"Treatos\", \"manufacturer\": \"The Dog People\" }\n\n    ]\n\n  },\n\n  \"fostered\": {\n\n    \"cats\": [\"Bob\", \"Alice\", \"Svetlana the Magnificent\", \"Queenie\"]\n\n  },\n\n  \"owned\": {\n\n    \"cats\": [\"Elliott\"]\n\n  }\n\n}\n\nRemarks​\nThe implementation of Json filtering differs between database connectors\nFiltering is case sensitive in PostgreSQL and does not yet support mode\npath​\n\npath represents the location of a specific key. The following query returns all users where the nested favourites > dogBreed key equals \"Rottweiler\".\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'dogBreed'],\n\n      equals: 'Rottweiler',\n\n    },\n\n  },\n\n});\n\n\nThe following query returns all users where the nested owned > cats array contains \"Elliott\".\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['owned', 'cats'],\n\n      array_contains: ['Elliott'],\n\n    },\n\n  },\n\n});\n\nWARNING\n\nFiltering by the key values of objects inside an array (below) is only supported by the MySQL connector.\n\nThe following query returns all users where the nested favorites > treats array contains an object where the name value is \"Dreamies\":\n\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: '$.favorites.treats[*].name',\n\n      array_contains: 'Dreamies',\n\n    },\n\n  },\n\n});\n\nstring_contains​\n\nThe following query returns all users where the nested favorites > catBreed key value contains \"Van\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_contains: 'Van',\n\n    },\n\n  },\n\n});\n\nstring_starts_with​\n\nThe following query returns all users where the nested favorites > catBreed key value starts with \"Turkish\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_starts_with: 'Turkish',\n\n    },\n\n  },\n\n});\n\nstring_ends_with​\n\nThe following query returns all users where the nested favorites > catBreed key value ends with \"Van\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_ends_with: 'Van',\n\n    },\n\n  },\n\n});\n\nmode​\n\nSpecify whether the the string filtering should be case sensitive (default) or case insensitive.\n\nThe following query returns all users where the nested favorites > catBreed key value contains \"Van\" or \"van\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_contains: 'Van',\n\n      mode: \"insensitive\",\n\n    },\n\n  },\n\n});\n\narray_contains​\n\nThe following query returns all users where the sanctuaries array contains the value \"RSPCA\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_contains: ['RSPCA'],\n\n    },\n\n  },\n\n});\n\nINFO\n\nNote: In PostgreSQL, the value of array_contains must be an array and not a string, even if the array only contains a single value.\n\nThe following query returns all users where the sanctuaries array contains all the values in the given array:\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_contains: ['RSPCA', 'Alley Cat Allies'],\n\n    },\n\n  },\n\n});\n\narray_starts_with​\n\nThe following query returns all users where the sanctuaries array starts with the value \"RSPCA\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_starts_with: 'RSPCA',\n\n    },\n\n  },\n\n});\n\narray_ends_with​\n\nThe following query returns all users where the sanctuaries array ends with the value \"Alley Cat Allies\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_ends_with: 'Alley Cat Allies',\n\n    },\n\n  },\n\n});\n\nClient methods​\n\nNote: Client-level methods are prefixed by $.\n\nRemarks​\n$on and $use client methods do not exist on extended client instances which are extended using $extends\nWARNING\n\nIn extended clients, Client methods do not necessarily exist. If you are extending your client, make sure to check for existence before using Client methods like $transaction or $connect.\n\nIn addition, if you are using $on or $use, you will need to use these client methods before extending your client as these methods do not exist on extended clients. For $use specifically we recommend transitioning to use query extensions.\n\n$disconnect()​\n\nThe $disconnect() method closes the database connections that were established when $connect was called and stops the process that was running Prisma ORM's query engine. See Connection management for an overview of $connect() and $disconnect().\n\nRemarks​\n$disconnect() returns a Promise, so you should call it inside an async function with the await keyword.\n$connect()​\n\nThe $connect() method establishes a physical connection to the database via Prisma ORM's query engine. See Connection management for an overview of $connect() and $disconnect().\n\nRemarks​\n$connect() returns a Promise, so you should call it inside an async function with the await keyword.\n$on()​\nWARNING\n\n$on is not available in extended clients. Please either migrate to client extensions or use the $on method prior to extending your client.\n\nThe $on() method allows you to subscribe to logging events or the exit hook.\n\n$use()​\nWARNING\n\n$use is not available in extended clients. Please either migrate to query extensions or use the $use method prior to extending your client.\n\nThe $use() method adds middleware :\n\nprisma.$use(async (params, next) => {\n\n  console.log('This is middleware!');\n\n  // Modify or interrogate params here\n\n\n\n  return next(params);\n\n});\n\nnext​\n\nnext represents the \"next level\" in the middleware stack, which could be the next middleware or the Prisma Query, depending on where in the stack you are.\n\nparams​\n\nparams is an object with information to use in your middleware.\n\nParameter\tDescription\naction\tThe query type - for example, create or findMany.\nargs\tArguments that were passed into the query - for example, where, data, or orderBy\ndataPath\tPopulated if you use the fluent API.\nmodel\tThe model type - for example, Post or User.\nrunInTransaction\tReturns true if the query ran in the context of a transaction.\nTIP\n\nIf you need the model property as a string, use: String(params.model)\n\nExample parameter values:\n\n{\n\n  args: { where: { id: 15 } },\n\n  dataPath: [ 'select', 'author', 'select', 'posts' ],\n\n  runInTransaction: false,\n\n  action: 'findMany',\n\n  model: 'Post'\n\n}\n\nExamples​\n\nSee middleware examples.\n\n$queryRawTyped​\n\nSee: Using Raw SQL ($queryRawTyped).\n\n$queryRaw​\n\nSee: Using Raw SQL ($queryRaw).\n\n$queryRawUnsafe()​\n\nSee: Using Raw SQL ($queryRawUnsafe()).\n\n$executeRaw​\n\nSee: Using Raw SQL ($executeRaw).\n\n$executeRawUnsafe()​\n\nSee: Using Raw SQL ($executeRawUnsafe()).\n\n$runCommandRaw()​\n\nSee: Using Raw SQL ($runCommandRaw()).\n\n$transaction()​\n\nSee: Transactions.\n\n$metrics​\n\nPrisma Client metrics give you a detailed insight into how Prisma Client interacts with your database. You can use this insight to help diagnose performance issues with your application. Learn more: Metrics.\n\nPrisma Client metrics has the following methods:\n\n$metrics.json(): Retrieves Prisma Client metrics in JSON format.\n$metrics.prometheus(): Retrieves Prisma Client metrics in Prometheus format.\n$extends​\n\nWith $extends, you can create and use Prisma Client extensions to add functionality to Prisma Client in the following ways:\n\nmodel: add custom methods to your models\nclient: add custom methods to your client\nquery: create custom Prisma Client queries\nresult: add custom fields to your query results\n\nLearn more: Prisma Client extensions.\n\nUtility types​\n\nUtility types are helper functions and types that live on the Prisma namespace. They are useful for keeping your application type safe.\n\nPrisma.validator​\n\nThe validator helps you create re-usable query parameters based on your schema models while making sure that the objects you create are valid. See also: Using Prisma.validator\n\nThere are two ways you can use the validator:\n\nUsing generated Prisma Client types​\n\nUsing types provides a type-level approach to validate data:\n\nPrisma.validator<GeneratedType>({ args });\n\nUsing a \"selector\"​\n\nWhen using the selector pattern, you use an existing Prisma Client instance to create a validator. This pattern allows you to select the model, operation, and query option to validate against.\n\nYou can also use an instance of Prisma Client that has been extended using a Prisma Client extension.\n\nPrisma.validator(PrismaClientInstance, '<model>', '<operation>', '<query option>')({ args });\n\nExamples​\n\nThe following example shows how you can extract and validate the input for the create operation you can reuse within your app:\n\nimport { Prisma } from '@prisma/client';\n\n\n\nconst validateUserAndPostInput = (name, email, postTitle) => {\n\n  return Prisma.validator<Prisma.UserCreateInput>()({\n\n    name,\n\n    email,\n\n    posts: {\n\n      create: {\n\n        title: postTitle,\n\n      },\n\n    },\n\n  });\n\n};\n\n\nHere is an alternative syntax for the same operation:\n\nimport { Prisma } from '@prisma/client';\n\nimport prisma from './prisma';\n\n\n\nconst validateUserAndPostInput = (name, email, postTitle) => {\n\n  return Prisma.validator(\n\n    prisma,\n\n    'user',\n\n    'create',\n\n    'data'\n\n  )({\n\n    name,\n\n    email,\n\n    posts: {\n\n      create: {\n\n        title: postTitle,\n\n      },\n\n    },\n\n  });\n\n};\n\nCompare columns in the same table​\n\nYou can compare columns in the same table directly, for non-unique filters.\n\nThis feature was moved to general availability in version 5.0.0 and was available via the fieldReference Preview feature from Prisma ORM versions 4.3.0 to 4.16.2.\n\nINFO\n\nIn the following situations, you must use raw queries to compare columns in the same table:\n\nIf you use a version earlier than 4.3.0\nIf you want to use a unique filter, such as findUnique or findUniqueOrThrow\nIf you want to compare a field with a unique constraint\nIf you want to use one of the following operators to compare a JSON field in MySQL or MariaDB with another field: gt, gte, lt, or lte. Note that you can use these operators to compare the JSON field with a scalar value. This limitation applies only if you try to compare a JSON field with another field.\n\nTo compare columns in the same table, use the <model>.fields property. In the following example, the query returns all records where the value in the prisma.product.quantity field is less than or equal to the value in the prisma.product.warnQuantity field.\n\nprisma.product.findMany({\n\n  where: { quantity: { lte: prisma.product.fields.warnQuantity } },\n\n});\n\nINFO\n\nfields is a special property of every model. It contains the list of fields for that model.\n\nConsiderations​\nFields must be of the same type​\n\nYou can only make comparisons on fields of the same type. For example, the following causes an error:\n\nawait prisma.order.findMany({\n\n  where: {\n\n    id: { equals: prisma.order.fields.due },\n\n    // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    // Type error: id is a string, while amountDue is an integer\n\n  },\n\n});\n\nFields must be in the same model​\n\nYou can only make comparisons with the fields property on fields in the same model. The following example does not work:\n\nawait prisma.order.findMany({\n\n  where: {\n\n    id: { equals: prisma.user.fields.name },\n\n    // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    // Type error: name is a field on the User model, not Order\n\n  },\n\n});\n\n\nHowever, you can compare fields in separate models with standard queries.\n\nIn groupBy model queries, put your referenced fields in the by argument​\n\nIf you use the groupBy model query with the having option, then you must put your referenced fields in the by argument.\n\nThe following example works:\n\nprisma.user.groupBy({\n\n  by: ['id', 'name'],\n\n  having: { id: { equals: prisma.user.fields.name } },\n\n});\n\n\nThe following example does not work, because name is not in the by argument:\n\nprisma.user.groupBy({\n\n  by: ['id'],\n\n  having: { id: { equals: prisma.user.fields.name } },\n\n  // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  // name is not in the 'by' argument\n\n});\n\nSearch for fields in scalar lists​\n\nIf your data source supports scalar lists (for example in PostgreSQL), then you can search for all records where a specific field is in a list of fields. To do so, reference the scalar list with the in and notIn filters. For example:\n\nawait prisma.user.findMany({\n\n  where: {\n\n    // find all users where 'name' is in a list of tags\n\n    name: { in: prisma.user.fields.tags },\n\n  },\n\n});\n\nFilter on non-unique fields with UserWhereUniqueInput​\n\nFrom version 5.0.0, the generated type UserWhereUniqueInput on where exposes all fields on the model, not just unique fields. This was available under the extendedWhereUnique Preview flag between versions 4.5.0 to 4.16.2\n\nYou must specify at least one unique field in your where statement outside of boolean operators, and you can specify any number of additional unique and non-unique fields. You can use this to add filters to any operation that returns a single record. For example, you can use this feature for the following:\n\nOptimistic concurrency control on updates\nPermission checks\nSoft deletes\n\nFrom version 4.6.0, you can use this feature to filter on optional one-to-one nested reads.\n\nOptimistic concurrency control on updates​\n\nYou can filter on non-unique fields to perform optimistic concurrency control on update operations.\n\nTo perform optimistic concurrency control, we recommend that you use a version field to check whether the data in a record or related record has changed while your code executes. Before version 4.5.0, you could not evaluate the version field in an update operation, because the field is non-unique. From version 4.5.0, you can evaluate the version field.\n\nIn the following example, updateOne and updateTwo first read the same record and then attempt to update it. The database only executes these updates if the value in version is the same as the value when it did the initial read. When the database executes the first of these updates (which might be updateOne or updateTwo, depending on timing), it increments the value in version. This means that the database does not execute the second update because the value in version has changed.\n\nmodel User {\n\n  id      Int    @id @default(autoincrement())\n\n  email   String @unique\n\n  city    String\n\n  version Int\n\n}\n\nfunction updateOne() {\n\n  const user = await prisma.user.findUnique({ id: 1 });\n\n\n\n  await prisma.user.update({\n\n    where: { id: user.id, version: user.version },\n\n    data: { city: 'Berlin', version: { increment: 1 } },\n\n  });\n\n}\n\n\n\nfunction updateTwo() {\n\n  const user = await prisma.user.findUnique({ id: 1 });\n\n\n\n  await prisma.user.update({\n\n    where: { id: user.id, version: user.version },\n\n    data: { city: 'New York', version: { increment: 1 } },\n\n  });\n\n}\n\n\n\nfunction main() {\n\n  await Promise.allSettled([updateOne(), updateTwo()]);\n\n}\n\nPermission checks​\n\nYou can filter on non-unique fields to check permissions during an update.\n\nIn the following example, a user wants to update a post title. The where statement checks the value in authorId to confirm that the user is the author of the post. The application only updates the post title if the user is the post author.\n\nawait prisma.post.update({\n\n  where: { id: 1, authorId: 1 },\n\n  data: { title: 'Updated post title' },\n\n});\n\nSoft deletes​\n\nYou can filter on non-unique fields to handle soft deletes.\n\nIn the following example, we do not want to return a post if it is soft-deleted. The operation only returns the post if the value in isDeleted is false.\n\nprisma.Post.findUnique({ where: { id: postId, isDeleted: false } });\n\nUserWhereUniqueInput considerations​\nBoolean operators with UserWhereUniqueInput​\n\nWith UserWhereUniqueInput, you must specify at least one unique field outside of the boolean operators AND, OR, NOT. You can still use these boolean operators in conjunction with any other unique fields or non-unique fields in your filter.\n\nIn the following example, we test id, a unique field, in conjunction with email. This is valid.\n\nawait prisma.user.update({\n\n  where: { id: 1, OR: [{ email: \"bob@prisma.io\" }, { email: \"alice@prisma.io\" }] },\n\n        // ^^^ Valid: the expression specifies a unique field (`id`) outside of any boolean operators\n\n  data: { ... }\n\n})\n\n\n\n// SQL equivalent:\n\n// WHERE id = 1 AND (email = \"bob@prisma.io\" OR email = \"alice@prisma.io\")\n\n\nThe following example is not valid, because there is no unique field outside of any boolean operators:\n\nawait prisma.user.update({\n\n  where: { OR: [{ email: \"bob@prisma.io\" }, { email: \"alice@prisma.io\" }] },\n\n        // ^^^ Invalid: the expressions does not contain a unique field outside of boolean operators\n\n  data: { ... }\n\n})\n\nOne-to-one relations​\n\nFrom version 4.5.0, you can filter on non-unique fields in the following operations on one-to-one relations:\n\nNested update\nNested upsert\nNested disconnect\nNested delete\n\nPrisma Client automatically uses a unique filter to select the appropriate related record. As a result, you do not need to specify a unique filter in your where statement with a WhereUniqueInput generated type. Instead, the where statement has a WhereInput generated type. You can use this to filter without the restrictions of WhereUniqueInput.\n\nNested update example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      // Before Prisma version 4.5.0\n\n      update: { field: \"updated\" }\n\n      // From Prisma version 4.5.0, you can also do the following:\n\n      update: { where: { /*WhereInput*/ }, data: { field: \"updated\" } } }\n\n    }\n\n  }\n\n})\n\nNested upsert example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      upsert: {\n\n        where: { /* WhereInput */ } // new argument from Prisma 4.5.0\n\n        create: { /* CreateInput */ },\n\n        update: { /* CreateInput */ },\n\n      }\n\n    }\n\n  }\n\n})\n\nNested disconnect example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      // Before Prisma version 4.5.0\n\n      disconnect: true\n\n      // From Prisma version 4.5.0, you can also do the following:\n\n      disconnect: { /* WhereInput */ }\n\n    }\n\n  }\n\n})\n\nNested delete example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      // Before Prisma version 4.5.0\n\n      delete: true\n\n      // From Prisma version 4.5.0, you can also do the following:\n\n      delete: { /* WhereInput */ }\n\n    }\n\n  }\n\n})\n\nPrismaPromise behavior​\n\nAll Prisma Client queries return an instance of PrismaPromise. This is a \"thenable\"\n, meaning a PrismaPromise only executes when you call await or .then() or .catch(). This behavior is different from a regular JavaScript \nPromise\n, which starts executing immediately.\n\nFor example:\n\nconst findPostOperation = prisma.post.findMany({}); // Query not yet executed\n\n\n\nfindPostOperation.then(); // Prisma Client now executes the query\n\n// or\n\nawait findPostOperation; // Prisma Client now executes the query\n\n\nWhen using the $transaction API, this behavior makes it possible for Prisma Client to pass all the queries on to the query engine as a single transaction."
  },
  {
    "title": "Prisma Schema API | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-schema-reference",
    "html": "ORMReference\nPrisma schema reference\ndatasource​\n\nDefines a data source in the Prisma schema.\n\nFields​\n\nA datasource block accepts the following fields:\n\nName\tRequired\tType\tDescription\nprovider\tYes\tString (postgresql, mysql, sqlite, sqlserver, mongodb, cockroachdb)\tDescribes which data source connectors to use.\nurl\tYes\tString (URL)\tConnection URL including authentication info. Most connectors use the syntax provided by the database.\nshadowDatabaseUrl\tNo\tString (URL)\tConnection URL to the shadow database used by Prisma Migrate. Allows you to use a cloud-hosted database as the shadow database.\ndirectUrl\tNo\tString (URL)\tConnection URL for direct connection to the database.\n\nIf you use a connection pooler URL in the url argument (for example, if you use Prisma Accelerate or pgBouncer), Prisma CLI commands that require a direct connection to the database use the URL in the directUrl argument.\n\nThe directUrl property is supported by Prisma Studio from version 5.1.0 upwards.\n\nThe directUrl property is not needed when using Prisma Postgres database.\nrelationMode\tNo\tString (foreignKeys, prisma)\tSets whether referential integrity is enforced by foreign keys in the database or emulated in the Prisma Client.\n\nIn preview in versions 3.1.1 and later. The field is named relationMode in versions 4.5.0 and later, and was previously named referentialIntegrity.\nextensions\tNo\tList of strings (PostgreSQL extension names)\tAllows you to represent PostgreSQL extensions in your schema. Available in preview for PostgreSQL only in Prisma ORM versions 4.5.0 and later.\n\nThe following providers are available:\n\nsqlite\npostgresql\nmysql\nsqlserver\nmongodb\ncockroachdb\nRemarks​\nYou can only have one datasource block in a schema.\ndatasource db is convention - however, you can give your data source any name - for example, datasource mysql or datasource data.\nExamples​\nSpecify a PostgreSQL data source​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 5432\nDatabase name: mydb\nSchema name: public\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"postgresql://johndoe:mypassword@localhost:5432/mydb?schema=public\"\n\n}\n\n\nLearn more about PostgreSQL connection strings here.\n\nSpecify a PostgreSQL data source via an environment variable​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 5432\nDatabase name: mydb\nSchema name: public\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\nWhen running a Prisma CLI command that needs the database connection URL (e.g. prisma generate), you need to make sure that the DATABASE_URL environment variable is set.\n\nOne way to do so is by creating a \n.env\n file with the following contents. Note that the file must be in the same directory as your schema.prisma file to automatically picked up the Prisma CLI.\n\nDATABASE_URL=postgresql://johndoe:mypassword@localhost:5432/mydb?schema=public\n\nSpecify a MySQL data source​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 3306\nDatabase name: mydb\ndatasource db {\n\n  provider = \"mysql\"\n\n  url      = \"mysql://johndoe:mypassword@localhost:3306/mydb\"\n\n}\n\n\nLearn more about MySQL connection strings here.\n\nSpecify a MongoDB data source​\nUser: root\nPassword: password\nHost: cluster1.test1.mongodb.net\nPort: N/A\nDatabase name: testing\ndatasource db {\n\n  provider = \"mongodb\"\n\n  url      = \"mongodb+srv://root:password@cluster1.test1.mongodb.net/testing?retryWrites=true&w=majority\"\n\n}\n\n\nLearn more about MongoDB connection strings here.\n\nSpecify a SQLite data source​\n\nIn this example, the target database is located in a file called dev.db:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:./dev.db\"\n\n}\n\n\nLearn more about SQLite connection strings here.\n\nSpecify a CockroachDB data source​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 26257\nDatabase name: mydb\nSchema name: public\ndatasource db {\n\n  provider = \"cockroachdb\"\n\n  url      = \"postgresql://johndoe:mypassword@localhost:26257/mydb?schema=public\"\n\n}\n\n\nThe format for connection strings is the same as for PostgreSQL. Learn more about PostgreSQL connection strings here.\n\ngenerator​\n\nDefines a generator in the Prisma schema.\n\nFields for prisma-client-js provider​\n\nThis is the default generator for Prisma ORM 6.x and earlier versions. Learn more about generators.\n\nA generator block accepts the following fields:\n\nName\tRequired\tType\tDescription\nprovider\tYes\tprisma-client-js\tDescribes which generator to use. This can point to a file that implements a generator or specify a built-in generator directly.\noutput\tNo\tString (file path)\tDetermines the location for the generated client, learn more. Default: node_modules/.prisma/client\npreviewFeatures\tNo\tList of Enums\tUse intellisense to see list of currently available Preview features (Ctrl+Space in Visual Studio Code) Default: none\nengineType\tNo\tEnum (library or binary)\tDefines the query engine type to download and use. Default: library\nbinaryTargets\tNo\tList of Enums (see below)\tSpecify the OS on which the Prisma Client will run to ensure compatibility of the query engine. Default: native\nmoduleFormat\tNo\tEnum (cjs or esm)\tDefines the module format of the generated Prisma Client. This field is available only with prisma-client generator.\nIMPORTANT\n\nWe recommend defining a custom output path, adding the path to .gitignore, and then making sure to run prisma generate via a custom build script or postinstall hook.\n\nFields for prisma-client provider​\n\nThe ESM-first client generator that offers greater control and flexibility across different JavaScript environments. It generates plain TypeScript code into a custom directory, providing full visibility over the generated code. Learn more about the new prisma-client generator.\n\nNOTE\n\nThe prisma-client generator will be the default generator in Prisma ORM 7.0 and we recommend migrating to it as soon as possible. It has been Generally Available since v6.16.0\n.\n\nA generator block accepts the following fields:\n\nName\tRequired\tType\tDescription\nprovider\tYes\tprisma-client\tDescribes which generator to use. This can point to a file that implements a generator or specify a built-in generator directly.\noutput\tYes\tString (file path)\tDetermines the location for the generated client, learn more.\npreviewFeatures\tNo\tList of Enums\tUse intellisense to see list of currently available Preview features (Ctrl+Space in Visual Studio Code) Default: none\nruntime\tNo\tEnum (nodejs, deno, bun, workerd (alias cloudflare), vercel-edge (alias edge-light), react-native)\tTarget runtime environment. Default: nodejs\nmoduleFormat\tNo\tEnum (esm or cjs)\tDetermines whether the generated code supports ESM (uses import) or CommonJS (uses require(...)) modules. We always recommend esm unless you have a good reason to use cjs. Default: Inferred from environment.\ngeneratedFileExtension\tNo\tEnum (ts or mts or cts)\tFile extension for generated TypeScript files. Default: ts\nimportFileExtension\tNo\tEnum (ts,mts,cts,js,mjs,cjs, empty (for bare imports))\tFile extension used in import statements Default: Inferred from environment.\nbinaryTargets options​\n\nThe following tables list all supported operating systems with the name of platform to specify in binaryTargets.\n\nUnless specified otherwise, the default supported CPU architecture is x86_64.\n\nmacOS​\nBuild OS\tPrisma engine build name\nmacOS Intel x86_64\tdarwin\nmacOS ARM64\tdarwin-arm64\nWindows​\nBuild OS\tPrisma engine build name\nWindows\twindows\nLinux (Alpine on x86_64 architectures)​\nBuild OS\tPrisma engine build name\tOpenSSL\nAlpine (3.17 and newer)\tlinux-musl-openssl-3.0.x*\t3.0.x\nAlpine (3.16 and older)\tlinux-musl\t1.1.x\n\n* Available in Prisma ORM versions 4.8.0 and later.\n\nLinux (Alpine on ARM64 architectures)​\nBuild OS\tPrisma engine build name\tOpenSSL\nAlpine (3.17 and newer)\tlinux-musl-arm64-openssl-3.0.x*\t3.0.x\nAlpine (3.16 and older)\tlinux-musl-arm64-openssl-1.1.x*\t1.1.x\n\n* Available in Prisma ORM versions 4.10.0 and later.\n\nLinux (Debian), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nDebian 8 (Jessie)\tdebian-openssl-1.0.x\t1.0.x\nDebian 9 (Stretch)\tdebian-openssl-1.1.x\t1.1.x\nDebian 10 (Buster)\tdebian-openssl-1.1.x\t1.1.x\nDebian 11 (Bullseye)\tdebian-openssl-1.1.x\t1.1.x\nDebian 12 (Bookworm)\tdebian-openssl-3.0.x\t3.0.x\nLinux (Ubuntu), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nUbuntu 14.04 (trusty)\tdebian-openssl-1.0.x\t1.0.x\nUbuntu 16.04 (xenial)\tdebian-openssl-1.0.x\t1.0.x\nUbuntu 18.04 (bionic)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 19.04 (disco)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 20.04 (focal)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 21.04 (hirsute)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 22.04 (jammy)\tdebian-openssl-3.0.x\t3.0.x\nUbuntu 23.04 (lunar)\tdebian-openssl-3.0.x\t3.0.x\nLinux (CentOS), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nCentOS 7\trhel-openssl-1.0.x\t1.0.x\nCentOS 8\trhel-openssl-1.1.x\t1.1.x\nLinux (Fedora), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nFedora 28\trhel-openssl-1.1.x\t1.1.x\nFedora 29\trhel-openssl-1.1.x\t1.1.x\nFedora 30\trhel-openssl-1.1.x\t1.1.x\nFedora 36\trhel-openssl-3.0.x\t3.0.x\nFedora 37\trhel-openssl-3.0.x\t3.0.x\nFedora 38\trhel-openssl-3.0.x\t3.0.x\nLinux (Linux Mint), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nLinux Mint 18\tdebian-openssl-1.0.x\t1.0.x\nLinux Mint 19\tdebian-openssl-1.1.x\t1.1.x\nLinux Mint 20\tdebian-openssl-1.1.x\t1.1.x\nLinux Mint 21\tdebian-openssl-3.0.x\t3.0.x\nLinux (Arch Linux), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nArch Linux 2019.09.01\tdebian-openssl-1.1.x\t1.1.x\nArch Linux 2023.04.23\tdebian-openssl-3.0.x\t3.0.x\nLinux ARM64 (all major distros but Alpine)​\nBuild OS\tPrisma engine build name\tOpenSSL\nLinux ARM64 glibc-based distro\tlinux-arm64-openssl-1.0.x\t1.0.x\nLinux ARM64 glibc-based distro\tlinux-arm64-openssl-1.1.x\t1.1.x\nLinux ARM64 glibc-based distro\tlinux-arm64-openssl-3.0.x\t3.0.x\nExamples​\nSpecify the prisma-client-js generator with the default output, previewFeatures, engineType and binaryTargets​\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\n\nNote that the above generator definition is equivalent to the following because it uses the default values for output, engineType and binaryTargets (and implicitly previewFeatures):\n\ngenerator client {\n\n  provider      = \"prisma-client-js\"\n\n  output        = \"node_modules/.prisma/client\"\n\n  engineType    = \"library\"\n\n  binaryTargets = [\"native\"]\n\n}\n\nSpecify a custom output location for Prisma Client​\n\nThis example shows how to define a custom output location of the generated asset to override the default one.\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output   = \"../src/generated/client\"\n\n}\n\nSpecify custom binaryTargets to ensure compatibility with the OS​\n\nThis example shows how to configure Prisma Client to run on Ubuntu 19.04 (disco) based on the table above.\n\ngenerator client {\n\n  provider      = \"prisma-client-js\"\n\n  binaryTargets = [\"debian-openssl-1.1.x\"]\n\n}\n\nSpecify a provider pointing to some custom generator implementation​\n\nThis example shows how to use a custom generator that's located in a directory called my-generator.\n\ngenerator client {\n\n  provider = \"./my-generator\"\n\n}\n\nmodel​\n\nDefines a Prisma model .\n\nRemarks​\nEvery record of a model must be uniquely identifiable. You must define at least one of the following attributes per model:\n@unique\n@@unique\n@id\n@@id\nNaming conventions​\nModel names must adhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\nModel names must start with a letter and are typically spelled in PascalCase\nModel names should use the singular form (for example, User instead of user, users or Users)\nPrisma ORM has a number of reserved words that are being used by Prisma ORM internally and therefore cannot be used as a model name. You can find the reserved words here\n and here\n.\n\nNote: You can use the @@map attribute to map a model (for example, User) to a table with a different name that does not match model naming conventions (for example, users).\n\nOrder of fields​\nIn version 2.3.0 and later, introspection lists model fields in the same order as the corresponding columns in the database. Relation fields are listed after scalar fields.\nExamples​\nA model named User with two scalar fields​\nRelational databases\nMongoDB\nmodel User {\n\n  email String  @unique // `email` can not be optional because it's the only unique field on the model\n\n  name  String?\n\n}\n\nmodel fields​\n\nFields are properties of models.\n\nRemarks​\nNaming conventions​\nMust start with a letter\nTypically spelled in camelCase\nMust adhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\n\nNote: You can use the @map attribute to map a field name to a column with a different name that does not match field naming conventions: e.g. myField @map(\"my_field\").\n\nmodel field scalar types​\n\nThe data source connector determines what native database type each of Prisma ORM scalar type maps to. Similarly, the generator determines what type in the target programming language each of these types map to.\n\nPrisma models also have model field types that define relations between models.\n\nString​\n\nVariable length text.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\ttext\nSQL Server\tnvarchar(1000)\nMySQL\tvarchar(191)\nMongoDB\tString\nSQLite\tTEXT\nCockroachDB\tSTRING\nPostgreSQL​\nNative database type\tNative database type attribute\tNotes\ntext\t@db.Text\t\nchar(x)\t@db.Char(x)\t\nvarchar(x)\t@db.VarChar(x)\t\nbit(x)\t@db.Bit(x)\t\nvarbit\t@db.VarBit\t\nuuid\t@db.Uuid\t\nxml\t@db.Xml\t\ninet\t@db.Inet\t\ncitext\t@db.Citext\tOnly available if Citext extension is enabled.\nMySQL​\nNative database type\tNative database type attribute\nVARCHAR(x)\t@db.VarChar(x)\nTEXT\t@db.Text\nCHAR(x)\t@db.Char(x)\nTINYTEXT\t@db.TinyText\nMEDIUMTEXT\t@db.MediumText\nLONGTEXT\t@db.LongText\n\nYou can use Prisma Migrate to map @db.Bit(1) to String:\n\nmodel Model {\n\n  /* ... */\n\n  myField String @db.Bit(1)\n\n}\n\nMongoDB​\n\nString\n\nNative database type attribute\tNotes\n@db.String\t\n@db.ObjectId\tRequired if the underlying BSON type is OBJECT_ID (ID fields, relation scalars)\nMicrosoft SQL Server​\nNative database type\tNative database type attribute\nchar(x)\t@db.Char(x)\nnchar(x)\t@db.NChar(x)\nvarchar(x)\t@db.VarChar(x)\nnvarchar(x)\t@db.NVarChar(x)\ntext\t@db.Text\nntext\t@db.NText\nxml\t@db.Xml\nuniqueidentifier\t@db.UniqueIdentifier\nSQLite​\n\nTEXT\n\nCockroachDB​\nNative database type\tNative database type attribute\tNotes\nSTRING(x) | TEXT(x) | VARCHAR(x)\t@db.String(x)\t\nCHAR(x)\t@db.Char(x)\t\n\"char\"\t@db.CatalogSingleChar\t\nBIT(x)\t@db.Bit(x)\t\nVARBIT\t@db.VarBit\t\nUUID\t@db.Uuid\t\nINET\t@db.Inet\t\n\nNote that the xml and citext types supported in PostgreSQL are not currently supported in CockroachDB.\n\nClients​\nPrisma Client JS\nstring\nBoolean​\n\nTrue or false value.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tboolean\nSQL Server\tbit\nMySQL\tTINYINT(1)\nMongoDB\tBool\nSQLite\tINTEGER\nCockroachDB\tBOOL\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\nboolean\t@db.Boolean\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nTINYINT(1)\t@db.TinyInt(1)\tTINYINT maps to Int if the max length is greater than 1 (for example, TINYINT(2)) or the default value is anything other than 1, 0, or NULL\nBIT(1)\t@db.Bit\t\nMongoDB​\n\nBool\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nbit\t@db.Bit\t\nSQLite​\n\nINTEGER\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nBOOL\t@db.Bool\t\nClients​\nPrisma Client JS\nboolean\nInt​\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tinteger\nSQL Server\tint\nMySQL\tINT\nMongoDB\tInt\nSQLite\tINTEGER\nCockroachDB\tINT\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ninteger | int, int4\t@db.Integer\t\nsmallint | int2\t@db.SmallInt\t\nsmallserial | serial2\t@db.SmallInt @default(autoincrement())\t\nserial | serial4\t@db.Int @default(autoincrement())\t\noid\t@db.Oid\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nINT\t@db.Int\t\nINT UNSIGNED\t@db.UnsignedInt\t\nSMALLINT\t@db.SmallInt\t\nSMALLINT UNSIGNED\t@db.UnsignedSmallInt\t\nMEDIUMINT\t@db.MediumInt\t\nMEDIUMINT UNSIGNED\t@db.UnsignedMediumInt\t\nTINYINT\t@db.TinyInt\tTINYINT maps to Int if the max length is greater than 1 (for example, TINYINT(2)) or the default value is anything other than 1, 0, or NULL. TINYINT(1) maps to Boolean.\nTINYINT UNSIGNED\t@db.UnsignedTinyInt\tTINYINT(1) UNSIGNED maps to Int, not Boolean\nYEAR\t@db.Year\t\nMongoDB​\n\nInt\n\nNative database type attribute\tNotes\n@db.Int\t\n@db.Long\t\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nint\t@db.Int\t\nsmallint\t@db.SmallInt\t\ntinyint\t@db.TinyInt\t\nbit\t@db.Bit\t\nSQLite​\n\nINTEGER\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nINTEGER | INT | INT8\t@db.Int8\tNote that this differs from PostgreSQL, where integer and int are aliases for int4 and map to @db.Integer\nINT4\t@db.Int4\t\nINT2 | SMALLINT\t@db.Int2\t\nSMALLSERIAL | SERIAL2\t@db.Int2 @default(autoincrement())\t\nSERIAL | SERIAL4\t@db.Int4 @default(autoincrement())\t\nSERIAL8 | BIGSERIAL\t@db.Int8 @default(autoincrement())\t\nClients​\nPrisma Client JS\nnumber\nBigInt​\n\nBigInt is available in version 2.17.0\n and later.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tbigint\nSQL Server\tint\nMySQL\tBIGINT\nMongoDB\tLong\nSQLite\tINTEGER\nCockroachDB\tINTEGER\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\nbigint | int8\t@db.BigInt\t\nbigserial | serial8\t@db.BigInt @default(autoincrement())\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nBIGINT\t@db.BigInt\t\nSERIAL\t@db.UnsignedBigInt @default(autoincrement())\t\nMongoDB​\n\nLong\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nbigint\t@db.BigInt\t\nSQLite​\n\nINTEGER\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nBIGINT | INT | INT8\t@db.Int8\tNote that this differs from PostgreSQL, where int is an alias for int4\nbigserial | serial8\t@db.Int8 @default(autoincrement())\t\nClients​\nClient\tType\tDescription\nPrisma Client JS\t\nBigInt\n\tSee examples of working with BigInt\nFloat​\n\nFloating point number.\n\nFloat maps to Double in 2.17.0\n and later - see release notes\n and Video: Changes to the default mapping of Float in Prisma ORM 2.17.0\n for more information about this change.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tdouble precision\nSQL Server\tfloat(53)\nMySQL\tDOUBLE\nMongoDB\tDouble\nSQLite\tREAL\nCockroachDB\tDOUBLE PRECISION\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ndouble precision\t@db.DoublePrecision\t\nreal\t@db.Real\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nFLOAT\t@db.Float\t\nDOUBLE\t@db.Double\t\nMongoDB​\n\nDouble\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\nfloat\t@db.Float\nmoney\t@db.Money\nsmallmoney\t@db.SmallMoney\nreal\t@db.Real\nSQLite connector​\n\nREAL\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nDOUBLE PRECISION | FLOAT8\t@db.Float8\t\nREAL | FLOAT4 | FLOAT\t@db.Float4\t\nClients​\nPrisma Client JS\nnumber\nDecimal​\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tdecimal(65,30)\nSQL Server\tdecimal(32,16)\nMySQL\tDECIMAL(65,30)\nMongoDB\tNot supported\n\nSQLite\tDECIMAL\nCockroachDB\tDECIMAL\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ndecimal | numeric\t@db.Decimal(p, s)†\t\nmoney\t@db.Money\t\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nMySQL​\nNative database types\tNative database type attribute\tNotes\nDECIMAL | NUMERIC\t@db.Decimal(p, s)†\t\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nMongoDB​\n\nNot supported\n.\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\ndecimal | numeric\t@db.Decimal(p, s)†\t\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nSQLite​\n\nDECIMAL (changed from REAL in 2.17.0)\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nDECIMAL | DEC | NUMERIC\t@db.Decimal(p, s)†\t\nmoney\tNot yet\tPostgreSQL's money type is not yet supported by CockroachDB\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nClients​\nClient\tType\tDescription\nPrisma Client JS\t\nDecimal\n\tSee examples of working with Decimal\nDateTime​\nRemarks​\nPrisma Client returns all DateTime as native \nDate\n objects.\nCurrently, Prisma ORM does not support\n zero dates\n (0000-00-00 00:00:00, 0000-00-00, 00:00:00) in MySQL.\nThere currently is a bug\n that doesn't allow you to pass in DateTime values as strings and produces a runtime error when you do. DateTime values need to be passed as \nDate\n objects (i.e. new Date('2024-12-04') instead of '2024-12-04').\n\nYou can find more info and examples in this section: Working with DateTime.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\ttimestamp(3)\nSQL Server\tdatetime2\nMySQL\tDATETIME(3)\nMongoDB\tTimestamp\nSQLite\tNUMERIC\nCockroachDB\tTIMESTAMP\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ntimestamp(x)\t@db.Timestamp(x)\t\ntimestamptz(x)\t@db.Timestamptz(x)\t\ndate\t@db.Date\t\ntime(x)\t@db.Time(x)\t\ntimetz(x)\t@db.Timetz(x)\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nDATETIME(x)\t@db.DateTime(x)\t\nDATE(x)\t@db.Date(x)\t\nTIME(x)\t@db.Time(x)\t\nTIMESTAMP(x)\t@db.Timestamp(x)\t\n\nYou can also use MySQL's YEAR type with Int:\n\nyearField     Int    @db.Year\n\nMongoDB​\n\nTimestamp\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\ndate\t@db.Date\t\ntime\t@db.Time\t\ndatetime\t@db.DateTime\t\ndatetime2\t@db.DateTime2\t\nsmalldatetime\t@db.SmallDateTime\t\ndatetimeoffset\t@db.DateTimeOffset\t\nSQLite​\n\nNUMERIC or STRING. If the underlying data type is STRING, you must use one of the following formats:\n\nRFC 3339\n (1996-12-19T16:39:57-08:00)\nRFC 2822\n (Tue, 1 Jul 2003 10:52:37 +0200)\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nTIMESTAMP(x)\t@db.Timestamp(x)\t\nTIMESTAMPTZ(x)\t@db.Timestamptz(x)\t\nDATE\t@db.Date\t\nTIME(x)\t@db.Time(x)\t\nTIMETZ(x)\t@db.Timetz(x)\t\nClients​\nPrisma Client JS\nDate\nJson​\n\nA JSON object.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tjsonb\nSQL Server\tNot supported\n\nMySQL\tJSON\nMongoDB\tA valid\nBSON\nobject (Relaxed mode)\n\nSQLite\tJSONB\nCockroachDB\tJSONB\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\njson\t@db.Json\t\njsonb\t@db.JsonB\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nJSON\t@db.Json\t\nMongoDB​\n\nA valid\nBSON\nobject (Relaxed mode)\n\nMicrosoft SQL Server​\n\nMicrosoft SQL Server does not have a specific data type for JSON. However, there are a number of built-in functions for reading and modifying JSON\n.\n\nSQLite​\n\nNot supported\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nJSON | JSONB\t@db.JsonB\t\nClients​\nPrisma Client JS\nobject\nBytes​\n\nBytes is available in version 2.17.0\n and later.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tbytea\nSQL Server\tvarbinary\nMySQL\tLONGBLOB\nMongoDB\tBinData\nSQLite\tBLOB\nCockroachDB\tBYTES\nPostgreSQL​\nNative database types\tNative database type attribute\nbytea\t@db.ByteA\nMySQL​\nNative database types\tNative database type attribute\tNotes\nLONGBLOB\t@db.LongBlob\t\nBINARY\t@db.Binary\t\nVARBINARY\t@db.VarBinary\t\nTINYBLOB\t@db.TinyBlob\t\nBLOB\t@db.Blob\t\nMEDIUMBLOB\t@db.MediumBlob\t\nBIT\t@db.Bit\t\nMongoDB​\n\nBinData\n\nNative database type attribute\tNotes\n@db.ObjectId\tRequired if the underlying BSON type is OBJECT_ID (ID fields, relation scalars)\n@db.BinData\t\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nbinary\t@db.Binary\t\nvarbinary\t@db.VarBinary\t\nimage\t@db.Image\t\nSQLite​\n\nBLOB\n\nCockroachDB​\nNative database types\tNative database type attribute\nBYTES | BYTEA | BLOB\t@db.Bytes\nClients​\nClient\tType\tDescription\nPrisma Client JS\t\nUint8Array\n\tSee examples of working with Bytes\nPrisma Client JS (before v6)\t\nBuffer\n\tSee examples of working with Bytes\nUnsupported​\nWARNING\n\nNot supported by MongoDB\nThe MongoDB connector does not support the Unsupported type.\n\nThe Unsupported type was introduced in 2.17.0\n and allows you to represent data types in the Prisma schema that are not supported by Prisma Client. Fields of type Unsupported can be created during Introspection with prisma db pull or written by hand, and created in the database with Prisma Migrate or db push.\n\nRemarks​\n\nFields with Unsupported types are not available in the generated client.\n\nIf a model contains a required Unsupported type, prisma.model.create(..), prisma.model.update(...) and prisma.model.upsert(...) are not available in Prisma Client.\n\nWhen you introspect a database that contains unsupported types, Prisma ORM will provide the following warning:\n\n*** WARNING ***\n\n\n\nThese fields are not supported by Prisma Client, because Prisma does not currently support their types.\n\n* Model \"Post\", field: \"circle\", original data type: \"circle\"\n\nExamples​\nmodel Star {\n\n  id       Int                    @id @default(autoincrement())\n\n  position Unsupported(\"circle\")?\n\n  example1 Unsupported(\"circle\")\n\n  circle   Unsupported(\"circle\")? @default(dbgenerated(\"'<(10,4),11>'::circle\"))\n\n}\n\nmodel field type modifiers​\n[] modifier​\n\nMakes a field a list.\n\nRemarks​\nCannot be optional (for example Post[]?).\nRelational databases​\nScalar lists (arrays) are only supported in the data model if your database natively supports them. Currently, scalar lists are therefore only supported when using PostgreSQL or CockroachDB (since MySQL and SQLite don't natively support scalar lists).\nMongoDB​\nScalar lists are supported\nExamples​\nDefine a scalar list​\nRelational databases\nMongoDB\nmodel User {\n\n  id             Int      @id @default(autoincrement())\n\n  favoriteColors String[]\n\n}\n\nDefine a scalar list with a default value​\n\nAvailable in version 4.0.0 and later.\n\nRelational databases\nMongoDB\nmodel User {\n\n  id             Int      @id @default(autoincrement())\n\n  favoriteColors String[] @default([\"red\", \"blue\", \"green\"])\n\n}\n\n? modifier​\n\nMakes a field optional.\n\nRemarks​\nCannot be used with a list field (for example, Posts[])\nExamples​\nOptional name field​\nmodel User {\n\n  id   Int     @id @default(autoincrement())\n\n  name String?\n\n}\n\nAttributes​\n\nAttributes modify the behavior of a field or block (e.g. models). There are two ways to add attributes to your data model:\n\nField attributes are prefixed with @\nBlock attributes are prefixed with @@\n\nSome attributes take arguments. Arguments in attributes are always named, but in most cases the argument name can be omitted.\n\nNote: The leading underscore in a signature means the argument name can be omitted.\n\n@id​\n\nDefines a single-field ID on the model.\n\nRemarks​\nGeneral​\nCannot be defined on a relation field\nCannot be optional\nRelational databases​\n\nCorresponding database construct: PRIMARY KEY\n\nCan be annotated with a @default attribute that uses functions to auto-generate an ID:\n\nautoincrement()\ncuid()\nuuid()\nulid()\n\nCan be defined on any scalar field (String, Int, enum)\n\nMongoDB​\n\nCorresponding database construct: Any valid BSON type, except arrays\n\nEvery model must define an @id field\n\nThe underlying ID field name is always\n_id\n, and must be mapped with @map(\"_id\")\n\nCan be defined on any scalar field (String, Int, enum) unless you want to use ObjectId in your database\n\nTo use an \nObjectId\n as your ID, you must:\n\nUse the String or Bytes field type\n\nAnnotate your field with @db.ObjectId:\n\nid   String  @db.ObjectId  @map(\"_id\")\n\n\nOptionally, annotate your field with a @default attribute that uses the auto() function to auto-generate an ObjectId\n\nid   String  @db.ObjectId  @map(\"_id\") @default(auto())\n\n\ncuid(), uuid() and ulid() are supported but do not generate a valid ObjectId - use auto() instead for @id\n\nautoincrement() is not supported\n\nArguments​\nName\tRequired\tType\tDescription\nmap\tNo\tString\tThe name of the underlying primary key constraint in the database.\n\nNot supported for MySQL or MongoDB.\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the ID are stored in the database. The available options are Asc and Desc.\n\nSQL Server only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the ID is clustered or non-clustered. Defaults to true.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\nSignature​\n@id(map: String?, length: number?, sort: String?, clustered: Boolean?)\n\n\nNote: Before version 4.0.0, or 3.5.0 with the extendedIndexes Preview feature enabled, the signature was:\n\n@id(map: String?)\n\n\nNote: Before version 3.0.0, the signature was:\n\n@id\n\nExamples​\n\nIn most cases, you want your database to create the ID. To do this, annotate the ID field with the @default attribute and initialize the field with a function.\n\nGenerate autoincrementing integers as IDs (Relational databases only)​\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n}\n\nGenerate ObjectId as IDs (MongoDB only)​\nmodel User {\n\n  id   String @id @default(auto()) @map(\"_id\") @db.ObjectId\n\n  name String\n\n}\n\nGenerate cuid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(cuid())\n\n  name String\n\n}\n\nGenerate uuid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(uuid())\n\n  name String\n\n}\n\nGenerate ulid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(ulid())\n\n  name String\n\n}\n\nSingle-field IDs without default values​\n\nIn the following example, id does not have a default value:\n\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id\n\n  name String\n\n}\n\n\nNote that in the above case, you must provide your own ID values when creating new records for the User model using Prisma Client, e.g.:\n\nconst newUser = await prisma.user.create({\n\n  data: {\n\n    id: 1,\n\n    name: \"Alice\",\n\n  },\n\n});\n\nSpecify an ID on relation scalar field without a default value​\n\nIn the following example, authorId is a both a relation scalar and the ID of Profile:\n\nRelational databases\nMongoDB\nmodel Profile {\n\n  authorId Int    @id\n\n  author   User   @relation(fields: [authorId], references: [id])\n\n  bio      String\n\n}\n\n\n\nmodel User {\n\n  id      Int      @id\n\n  email   String   @unique\n\n  name    String?\n\n  profile Profile?\n\n}\n\n\nIn this scenario, you cannot create a Profile only - you must use Prisma Client's nested writes create a User or connect the profile to an existing user.\n\nThe following example creates a user and a profile:\n\nconst userWithProfile = await prisma.user.create({\n\n  data: {\n\n    id: 3,\n\n    email: \"bob@prisma.io\",\n\n    name: \"Bob Prismo\",\n\n    profile: {\n\n      create: {\n\n        bio: \"Hello, I'm Bob Prismo and I love apples, blue nail varnish, and the sound of buzzing mosquitoes.\",\n\n      },\n\n    },\n\n  },\n\n});\n\n\nThe following example connects a new profile to a user:\n\nconst profileWithUser = await prisma.profile.create({\n\n  data: {\n\n    bio: \"Hello, I'm Bob and I like nothing at all. Just nothing.\",\n\n    author: {\n\n      connect: {\n\n        id: 22,\n\n      },\n\n    },\n\n  },\n\n});\n\n@@id​\nWARNING\n\nNot supported by MongoDB\nThe MongoDB connector does not support composite IDs.\n\nDefines a multi-field ID (composite ID) on the model.\n\nRemarks​\nCorresponding database type: PRIMARY KEY\nCan be annotated with a @default attribute that uses functions to auto-generate an ID\nCannot be optional\nCan be defined on any scalar field (String, Int, enum)\nCannot be defined on a relation field\nThe name of the composite ID field in Prisma Client has the following pattern: field1_field2_field3\nArguments​\nName\tRequired\tType\tDescription\nfields\tYes\tFieldReference[]\tA list of field names - for example, [\"firstname\", \"lastname\"]\nname\tNo\tString\tThe name that Prisma Client will expose for the argument covering all fields, e.g. fullName in fullName: { firstName: \"First\", lastName: \"Last\"}\nmap\tNo\tString\tThe name of the underlying primary key constraint in the database.\n\nNot supported for MySQL.\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the ID are stored in the database. The available options are Asc and Desc.\n\nSQL Server only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the ID is clustered or non-clustered. Defaults to true.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\n\nThe name of the fields argument on the @@id attribute can be omitted:\n\n@@id(fields: [title, author])\n\n@@id([title, author])\n\nSignature​\n@@id(_ fields: FieldReference[], name: String?, map: String?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@@id(_ fields: FieldReference[])\n\nExamples​\nSpecify a multi-field ID on two String fields (Relational databases only)​\nmodel User {\n\n  firstName String\n\n  lastName  String\n\n  email     String  @unique\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@id([firstName, lastName])\n\n}\n\n\nWhen you create a user, you must provide a unique combination of firstName and lastName:\n\nconst user = await prisma.user.create({\n\n  data: {\n\n    firstName: \"Alice\",\n\n    lastName: \"Smith\",\n\n  },\n\n});\n\n\nTo retrieve a user, use the generated composite ID field (firstName_lastName):\n\nconst user = await prisma.user.findUnique({\n\n  where: {\n\n    firstName_lastName: {\n\n      firstName: \"Alice\",\n\n      lastName: \"Smith\",\n\n    },\n\n  },\n\n});\n\nSpecify a multi-field ID on two String fields and one Boolean field (Relational databases only)​\nmodel User {\n\n  firstName String\n\n  lastName  String\n\n  email     String  @unique\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@id([firstName, lastName, isAdmin])\n\n}\n\n\nWhen creating new User records, you now must provide a unique combination of values for firstName, lastName and isAdmin:\n\nconst user = await prisma.user.create({\n\n  data: {\n\n    firstName: \"Alice\",\n\n    lastName: \"Smith\",\n\n    isAdmin: true,\n\n  },\n\n});\n\nSpecify a multi-field ID that includes a relation field (Relational databases only)​\nmodel Post {\n\n  title     String\n\n  published Boolean @default(false)\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int\n\n\n\n  @@id([authorId, title])\n\n}\n\n\n\nmodel User {\n\n  id    Int     @default(autoincrement())\n\n  email String  @unique\n\n  name  String?\n\n  posts Post[]\n\n}\n\n\nWhen creating new Post records, you now must provide a unique combination of values for authorId (foreign key) and title:\n\nconst post = await prisma.post.create({\n\n  data: {\n\n    title: \"Hello World\",\n\n    author: {\n\n      connect: {\n\n        email: \"alice@prisma.io\",\n\n      },\n\n    },\n\n  },\n\n});\n\n@default​\n\nDefines a default value for a field.\n\nRemarks​\nDefault values that cannot yet be represented in the Prisma schema are represented by the dbgenerated() function when you use introspection.\nDefault values are not allowed on relation fields in the Prisma schema. Note however that you can still define default values on the fields backing a relation (the ones listed in the fields argument in the @relation attribute). A default value on the field backing a relation will mean that relation is populated automatically for you.\nDefault values can be used with scalar lists in databases that natively support them.\nRelational databases​\nCorresponding database construct: DEFAULT\nDefault values can be a static value (4, \"hello\") or one of the following functions:\nautoincrement()\nsequence() (CockroachDB only)\ndbgenerated(...)\ncuid()\ncuid(2)\nuuid()\nuuid(4)\nuuid(7)\nulid()\nnanoid()\nnow()\nDefault values that cannot yet be represented in the Prisma schema are represented by the dbgenerated(...) function when you use introspection.\nDefault values are not allowed on relation fields in the Prisma schema. Note however that you can still define default values on the fields backing a relation (the ones listed in the fields argument in the @relation attribute). A default value on the field backing a relation will mean that relation is populated automatically for you.\nDefault values can be used with scalar lists in databases that natively support them.\nJSON data. Note that JSON needs to be enclosed with double-quotes inside the @default attribute, e.g.: @default(\"[]\"). If you want to provide a JSON object, you need to enclose it with double-quotes and then escape any internal double quotes using a backslash, e.g.: @default(\"{ \\\"hello\\\": \\\"world\\\" }\").\nMongoDB​\nDefault values can be a static value (4, \"hello\") or one of the following functions:\nauto() (can only be used with @db.ObjectId to generate an ObjectId in MongoDB)\ncuid()\nuuid()\nulid()\nnow()\nArguments​\nName\tRequired\tType\tDescription\nvalue\tYes\tAn expression (e.g. 5, true, now())\t\nmap\tNo\tString\tSQL Server only.\n\nThe name of the value argument on the @default attribute can be omitted:\n\nid Int @id @default(value: autoincrement())\n\nid Int @id @default(autoincrement())\n\nSignature​\n@default(_ value: Expression, map: String?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@default(_ value: Expression)\n\nExamples​\nDefault value for an Int​\nRelational databases\nMongoDB\nmodel User {\n\n  email        String @unique\n\n  profileViews Int    @default(0)\n\n}\n\nDefault value for a Float​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String @unique\n\n  number Float  @default(1.1)\n\n}\n\nDefault value for Decimal​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String  @unique\n\n  number Decimal @default(22.99)\n\n}\n\nDefault value for BigInt​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String @unique\n\n  number BigInt @default(34534535435353)\n\n}\n\nDefault value for a String​\nRelational databases\nMongoDB\nmodel User {\n\n  email String @unique\n\n  name  String @default(\"\")\n\n}\n\nDefault value for a Boolean​\nRelational databases\nMongoDB\nmodel User {\n\n  email   String  @unique\n\n  isAdmin Boolean @default(false)\n\n}\n\nDefault value for a DateTime​\n\nNote that static default values for DateTime are based on the ISO 8601\n standard.\n\nRelational databases\nMongoDB\nmodel User {\n\n  email String   @unique\n\n  data  DateTime @default(\"2020-03-19T14:21:00+02:00\")\n\n}\n\nDefault value for a Bytes​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String @unique\n\n  secret Bytes  @default(\"SGVsbG8gd29ybGQ=\")\n\n}\n\nDefault value for an enum​\nRelational databases\nMongoDB\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\nmodel User {\n\n  id      Int      @id @default(autoincrement())\n\n  email   String   @unique\n\n  name    String?\n\n  role    Role     @default(USER)\n\n  posts   Post[]\n\n  profile Profile?\n\n}\n\nDefault values for scalar lists​\nRelational databases\nMongoDB\nmodel User {\n\n  id             Int      @id @default(autoincrement())\n\n  posts          Post[]\n\n  favoriteColors String[] @default([\"red\", \"yellow\", \"purple\"])\n\n  roles          Role[]   @default([USER, DEVELOPER])\n\n}\n\n\n\nenum Role {\n\n  USER\n\n  DEVELOPER\n\n  ADMIN\n\n}\n\n@unique​\n\nDefines a unique constraint for this field.\n\nRemarks​\nGeneral​\nA field annotated with @unique can be optional or required\nA field annotated with @unique must be required if it represents the only unique constraint on a model without an @id / @@id\nA model can have any number of unique constraints\nCan be defined on any scalar field\nCannot be defined on a relation field\nRelational databases​\nCorresponding database construct: UNIQUE\nNULL values are considered to be distinct (multiple rows with NULL values in the same column are allowed)\nAdding a unique constraint automatically adds a corresponding unique index to the specified column(s).\nMongoDB​\nEnforced by a unique index in MongoDB\nArguments​\nName\tRequired\tType\tDescription\nmap\tNo\tString\t\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the constraint are stored in the database. The available options are Asc and Desc.\n\nIn preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the constraint is clustered or non-clustered. Defaults to false.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\n¹ Can be required by some of the index and field types.\nSignature​\n@unique(map: String?, length: number?, sort: String?)\n\n\nNote: Before version 4.0.0, or 3.5.0 with the extendedIndexes Preview feature enabled, the signature was:\n\n@unique(map: String?)\n\n\nNote: Before version 3.0.0, the signature was:\n\n@unique\n\nExamples​\nSpecify a unique attribute on a required String field​\nRelational databases\nMongoDB\nmodel User {\n\n  email String @unique\n\n  name  String\n\n}\n\nSpecify a unique attribute on an optional String field​\nRelational databases\nMongoDB\nmodel User {\n\n  id    Int     @id @default(autoincrement())\n\n  email String? @unique\n\n  name  String\n\n}\n\nSpecify a unique attribute on relation scalar field authorId​\nRelational databases\nMongoDB\nmodel Post {\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int     @unique\n\n  title     String\n\n  published Boolean @default(false)\n\n}\n\n\n\nmodel User {\n\n  id    Int     @id @default(autoincrement())\n\n  email String? @unique\n\n  name  String\n\n  Post  Post[]\n\n}\n\nSpecify a unique attribute with cuid() values as default values​\nRelational databases\nMongoDB\nmodel User {\n\n  token String @unique @default(cuid())\n\n  name  String\n\n}\n\n@@unique​\n\nDefines a compound unique constraint for the specified fields.\n\nRemarks​\nGeneral​\n\nAll fields that make up the unique constraint must be mandatory fields. The following model is not valid because id could be null:\n\nmodel User {\n\n  firstname Int\n\n  lastname  Int\n\n  id        Int?\n\n\n\n  @@unique([firstname, lastname, id])\n\n}\n\n\nThe reason for this behavior is that all connectors consider null values to be distinct, which means that two rows that look identical are considered unique:\n\n firstname  | lastname | id\n\n -----------+----------+------\n\n John       | Smith    | null\n\n John       | Smith    | null\n\n\nA model can have any number of @@unique blocks\n\nRelational databases​\nCorresponding database construct: UNIQUE\nA @@unique block is required if it represents the only unique constraint on a model without an @id / @@id\nAdding a unique constraint automatically adds a corresponding unique index to the specified column(s)\nMongoDB​\nEnforced by a compound index in MongoDB\nA @@unique block cannot be used as the only unique identifier for a model - MongoDB requires an @id field\nArguments​\nName\tRequired\tType\tDescription\nfields\tYes\tFieldReference[]\tA list of field names - for example, [\"firstname\", \"lastname\"]. Fields must be mandatory - see remarks.\nname\tNo\tString\tThe name of the unique combination of fields - defaults to fieldName1_fieldName2_fieldName3\nmap\tNo\tString\t\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the constraint are stored in the database. The available options are Asc and Desc.\n\nIn preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the constraint is clustered or non-clustered. Defaults to false.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\n\nThe name of the fields argument on the @@unique attribute can be omitted:\n\n@@unique(fields: [title, author])\n\n@@unique([title, author])\n\n@@unique(fields: [title, author], name: \"titleAuthor\")\n\n\nThe length and sort arguments are added to the relevant field names:\n\n@@unique(fields: [title(length:10), author])\n\n@@unique([title(sort: Desc), author(sort: Asc)])\n\nSignature​\n@@unique(_ fields: FieldReference[], name: String?, map: String?)\n\n\nNote: Before version 4.0.0, or before version 3.5.0 with the extendedIndexes Preview feature enabled, the signature was:\n\n@@unique(_ fields: FieldReference[], name: String?, map: String?)\n\n\nNote: Before version 3.0.0, the signature was:\n\n@@unique(_ fields: FieldReference[], name: String?)\n\nExamples​\nSpecify a multi-field unique attribute on two String fields​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int     @default(autoincrement())\n\n  firstName String\n\n  lastName  String\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@unique([firstName, lastName])\n\n}\n\n\nTo retrieve a user, use the generated field name (firstname_lastname):\n\nconst user = await prisma.user.findUnique({\n\n  where: {\n\n    firstName_lastName: {\n\n      firstName: \"Alice\",\n\n      lastName: \"Smith\",\n\n      isAdmin: true,\n\n    },\n\n  },\n\n});\n\nSpecify a multi-field unique attribute on two String fields and one Boolean field​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int     @default(autoincrement())\n\n  firstName String\n\n  lastName  String\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@unique([firstName, lastName, isAdmin])\n\n}\n\nSpecify a multi-field unique attribute that includes a relation field​\nRelational databases\nMongoDB\nmodel Post {\n\n  id        Int     @default(autoincrement())\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int\n\n  title     String\n\n  published Boolean @default(false)\n\n\n\n  @@unique([authorId, title])\n\n}\n\n\n\nmodel User {\n\n  id    Int    @id @default(autoincrement())\n\n  email String @unique\n\n  posts Post[]\n\n}\n\nSpecify a custom name for a multi-field unique attribute​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int     @default(autoincrement())\n\n  firstName String\n\n  lastName  String\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@unique(fields: [firstName, lastName, isAdmin], name: \"admin_identifier\")\n\n}\n\n\nTo retrieve a user, use the custom field name (admin_identifier):\n\nconst user = await prisma.user.findUnique({\n\n  where: {\n\n    admin_identifier: {\n\n      firstName: \"Alice\",\n\n      lastName: \"Smith\",\n\n      isAdmin: true,\n\n    },\n\n  },\n\n});\n\n@@index​\n\nDefines an index in the database.\n\nRemarks​\nRelational databases​\nCorresponding database construct: INDEX\nThere are some additional index configuration options that cannot be provided via the Prisma schema yet. These include:\nPostgreSQL and CockroachDB:\nDefine index fields as expressions (e.g. CREATE INDEX title ON public.\"Post\"((lower(title)) text_ops);)\nDefine partial indexes with WHERE\nCreate indexes concurrently with CONCURRENTLY\nINFO\n\nWhile you cannot configure these option in your Prisma schema, you can still configure them on the database-level directly.\n\nMongoDB​\nIn version 3.12.0 and later, you can define an index on a field of a composite type using the syntax @@index([compositeType.field]). See Defining composite type indexes for more details.\nArguments​\nName\tRequired\tType\tDescription\nfields\tYes\tFieldReference[]\tA list of field names - for example, [\"firstname\", \"lastname\"]\nname\tNo\tString\tThe name that Prisma Client will expose for the argument covering all fields, e.g. fullName in fullName: { firstName: \"First\", lastName: \"Last\"}\nmap\tNo\tmap\tThe name of the index in the underlying database (Prisma generates an index name that respects identifier length limits if you do not specify a name. Prisma uses the following naming convention: tablename.field1_field2_field3_unique)\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the index or constraint are stored in the database. The available options are asc and desc.\n\nIn preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the index is clustered or non-clustered. Defaults to false.\n\nSQL Server only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\ntype\tNo\tidentifier\tAllows you to specify an index access method. Defaults to BTree.\n\nPostgreSQL and CockroachDB only. In preview with the Hash index access method in versions 3.6.0 and later, and with the Gist, Gin, SpGist and Brin methods added in 3.14.0. In general availability in versions 4.0.0 and later.\nops\tNo\tidentifier or a function\tAllows you to define the index operators for certain index types.\n\nPostgreSQL only. In preview in versions 3.14.0 and later, and in general availability in versions 4.0.0 and later.\n\nThe name of the fields argument on the @@index attribute can be omitted:\n\n@@index(fields: [title, author])\n\n@@index([title, author])\n\n\nThe length and sort arguments are added to the relevant field names:\n\n@@index(fields: [title(length:10), author])\n\n@@index([title(sort: Asc), author(sort: Desc)])\n\nSignature​\n@@index(_ fields: FieldReference[], map: String?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@@index(_ fields: FieldReference[], name: String?)\n\n\nThe old name argument will still be accepted to avoid a breaking change.\n\nExamples​\n\nAssume you want to add an index for the title field of the Post model\n\nDefine a single-column index (Relational databases only)​\nmodel Post {\n\n  id      Int     @id @default(autoincrement())\n\n  title   String\n\n  content String?\n\n\n\n  @@index([title])\n\n}\n\nDefine a multi-column index (Relational databases only)​\nmodel Post {\n\n  id      Int     @id @default(autoincrement())\n\n  title   String\n\n  content String?\n\n\n\n  @@index([title, content])\n\n}\n\nDefine an index with a name (Relational databases only)​\nmodel Post {\n\n  id      Int     @id @default(autoincrement())\n\n  title   String\n\n  content String?\n\n\n\n  @@index(fields: [title, content], name: \"main_index\")\n\n}\n\nDefine an index on a composite type field (Relational databases only)​\ntype Address {\n\n  street String\n\n  number Int\n\n}\n\n\n\nmodel User {\n\n  id      Int     @id\n\n  email   String\n\n  address Address\n\n\n\n  @@index([address.number])\n\n}\n\n@relation​\n\nDefines meta information about the relation. Learn more.\n\nRemarks​\nRelational databases​\nCorresponding database constructs: FOREIGN KEY / REFERENCES\nMongoDB​\nIf your model's primary key is of type ObjectId in the underlying database, both the primary key and the foreign key must have the @db.ObjectId attribute\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tSometimes (e.g. to disambiguate a relation)\tDefines the name of the relationship. In an m-n-relation, it also determines the name of the underlying relation table.\t\"CategoryOnPost\", \"MyRelation\"\nfields\tFieldReference[]\tOn annotated relation fields\tA list of fields of the current model\t[\"authorId\"], [\"authorFirstName, authorLastName\"]\nreferences\tFieldReference[]\tOn annotated relation fields\tA list of fields of the model on the other side of the relation\t[\"id\"], [\"firstName, lastName\"]\nmap\tString\tNo\tDefines a custom name for the foreign key in the database.\t[\"id\"], [\"firstName, lastName\"]\nonUpdate\tEnum. See Types of referential actions for values.\tNo\tDefines the referential action to perform when a referenced entry in the referenced model is being updated.\tCascade, NoAction\nonDelete\tEnum. See Types of referential actions for values.\tNo\tDefines the referential action to perform when a referenced entry in the referenced model is being deleted.\tCascade, NoAction\n\nThe name of the name argument on the @relation attribute can be omitted (references is required):\n\n@relation(name: \"UserOnPost\", references: [id])\n\n@relation(\"UserOnPost\", references: [id])\n\n\n\n// or\n\n\n\n@relation(name: \"UserOnPost\")\n\n@relation(\"UserOnPost\")\n\nSignature​\n@relation(_ name: String?, fields: FieldReference[]?, references: FieldReference[]?, onDelete: ReferentialAction?, onUpdate: ReferentialAction?, map: String?)\n\n\nWith SQLite, the signature changes to:\n\n@relation(_ name: String?, fields: FieldReference[]?, references: FieldReference[]?, onDelete: ReferentialAction?, onUpdate: ReferentialAction?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@relation(_ name: String?, fields: FieldReference[]?, references: FieldReference[]?)\n\nExamples​\n\nSee: The @relation attribute.\n\n@map​\n\nMaps a field name or enum value from the Prisma schema to a column or document field with a different name in the database. If you do not use @map, the Prisma field name matches the column name or document field name exactly.\n\nSee Using custom model and field names to see how @map and @@map changes the generated Prisma Client.\n\nRemarks​\nGeneral​\n@map does not rename the columns / fields in the database\n@map does change the field names in the generated client\nMongoDB​\n\nYour @id field must include @map(\"_id\"). For example:\n\nmodel User {\n\n  id String @default(auto()) @map(\"_id\") @db.ObjectId\n\n}\n\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tYes\tThe database column (relational databases) or document field (MongoDB) name.\t\"comments\", \"someFieldName\"\n\nThe name of the name argument on the @map attribute can be omitted:\n\n@map(name: \"is_admin\")\n\n@map(\"users\")\n\nSignature​\n@map(_ name: String)\n\nExamples​\nMap the firstName field to a column called first_name​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int    @id @default(autoincrement())\n\n  firstName String @map(\"first_name\")\n\n}\n\n\nThe generated client:\n\nawait prisma.user.create({\n\n  data: {\n\n    firstName: \"Yewande\", // first_name --> firstName\n\n  },\n\n});\n\nMap an enum named ADMIN to a database enum named admin​\nenum Role {\n\n  ADMIN    @map(\"admin\")\n\n  CUSTOMER\n\n}\n\n@@map​\n\nMaps the Prisma schema model name to a table (relational databases) or collection (MongoDB) with a different name, or an enum name to a different underlying enum in the database. If you do not use @@map, the model name matches the table (relational databases) or collection (MongoDB) name exactly.\n\nSee Using custom model and field names to see how @map and @@map changes the generated Prisma Client.\n\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tYes\tThe database table (relational databases) or collection (MongoDB) name.\t\"comments\", \"someTableOrCollectionName\"\n\nThe name of the name argument on the @@map attribute can be omitted\n\n@@map(name: \"users\")\n\n@@map(\"users\")\n\nSignature​\n@@map(_ name: String)\n\nExamples​\nMap the User model to a database table/collection named users​\nRelational databases\nMongoDB\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n\n\n  @@map(\"users\")\n\n}\n\n\nThe generated client:\n\nawait prisma.user.create({\n\n  // users --> user\n\n  data: {\n\n    name: \"Yewande\",\n\n  },\n\n});\n\nMap the Role enum to a native enum in the database named _Role its values to lowercase values in the database​\nenum Role {\n\n  ADMIN    @map(\"admin\")\n\n  CUSTOMER @map(\"customer\")\n\n\n\n  @@map(\"_Role\")\n\n}\n\n@updatedAt​\n\nAutomatically stores the time when a record was last updated. If you do not supply a time yourself, Prisma Client will automatically set the value for fields with this attribute.\n\nRemarks​\nCompatible with DateTime fields\nImplemented at Prisma ORM level\nWARNING\n\nIn versions before 4.4.0\n, if you're also using now(), the time might differ from the @updatedAt values if your database and app have different time zones. This happens because @updatedAt operates at the Prisma ORM level, while now() operates at the database level.\n\nNOTE\n\nIf you pass an empty update clause, the @updatedAt value will remain unchanged. For example:\n\nawait prisma.user.update({\n\n  where: {\n\n    id: 1,\n\n  },\n\n  data: {}, //<- Empty update clause\n\n});\n\nArguments​\n\nN/A\n\nSignature​\n@updatedAt\n\nExamples​\nRelational databases\nMongoDB\nmodel Post {\n\n  id        String   @id\n\n  updatedAt DateTime @updatedAt\n\n}\n\n@ignore​\n\nAdd @ignore to a field that you want to exclude from Prisma Client (for example, a field that you do not want Prisma Client users to update). Ignored fields are excluded from the generated Prisma Client. The model's create method is disabled when doing this for required fields with no @default (because the database cannot create an entry without that data).\n\nRemarks​\nIn 2.17.0\n and later, Prisma ORM automatically adds @ignore to fields that refer to invalid models when you introspect.\nExamples​\n\nThe following example demonstrates manually adding @ignore to exclude the email field from Prisma Client:\n\nschema.prisma\nmodel User {\n\n  id    Int    @id\n\n  name  String\n\n  email String @ignore // this field will be excluded\n\n}\n\n@@ignore​\n\nAdd @@ignore to a model that you want to exclude from Prisma Client (for example, a model that you do not want Prisma users to update). Ignored models are excluded from the generated Prisma Client.\n\nRemarks​\nIn 2.17.0\n and later, Prisma ORM adds @@ignore to an invalid model. (It also adds @ignore to relations pointing to such a model)\nExamples​\n\nIn the following example, the Post model is invalid because it does not have a unique identifier. Use @@ignore to exclude it from the generated Prisma Client API:\n\nschema.prisma\n/// The underlying table does not contain a valid unique identifier and can therefore currently not be handled by Prisma Client.\n\nmodel Post {\n\n  id       Int  @default(autoincrement()) // no unique identifier\n\n  author   User @relation(fields: [authorId], references: [id])\n\n  authorId Int\n\n\n\n  @@ignore\n\n}\n\n\nIn the following example, the Post model is invalid because it does not have a unique identifier, and the posts relation field on User is invalid because it refers to the invalid Post model. Use @@ignore on the Post model and @ignore on the posts relation field in User to exclude both the model and the relation field from the generated Prisma Client API:\n\nschema.prisma\n/// The underlying table does not contain a valid unique identifier and can therefore currently not be handled by Prisma Client.\n\nmodel Post {\n\n  id       Int  @default(autoincrement()) // no unique identifier\n\n  author   User @relation(fields: [authorId], references: [id])\n\n  authorId Int\n\n\n\n  @@ignore\n\n}\n\n\n\nmodel User {\n\n  id    Int     @id @default(autoincrement())\n\n  name  String?\n\n  posts Post[]  @ignore\n\n}\n\n@@schema​\n\nAdd @@schema to a model to specify which schema in your database should contain the table associated with that model. Learn more about adding multiple schema's here.\n\nNOTE\n\nMultiple database schema support is only available with the PostgreSQL, CockroachDB, and SQL Server connectors.\n\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tYes\tThe name of the database schema.\t\"base\", \"auth\"\n\nThe name of the name argument on the @@schema attribute can be omitted\n\n@@schema(name: \"auth\")\n\n@@schema(\"auth\")\n\nSignature​\n@@schema(_ name: String)\n\nExamples​\nMap the User model to a database schema named auth​\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n}\n\n\n\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n  schemas  = [\"auth\"]\n\n}\n\n\n\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n\n\n  @@schema(\"auth\")\n\n}\n\nINFO\n\nFor more information about using the multiSchema feature, refer to this guide.\n\n@shardKey​\nNOTE\n\nThis features requires the shardKeys Preview feature flag on your generator:\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output = \"../generated/prisma\"\n\n  previewFeatures = [\"shardKeys\"]\n\n}\n\n\nThe @shardKey attribute is only compatible with PlanetScale\n databases. It enables you define a shard key\n on a field of your model:\n\nmodel User {\n\n  id     String @default(uuid())\n\n  region String @shardKey\n\n}\n\n@@shardKey​\nNOTE\n\nThis features requires the shardKeys Preview feature flag on your generator:\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output = \"../generated/prisma\"\n\n  previewFeatures = [\"shardKeys\"]\n\n}\n\n\nThe @shardKey attribute is only compatible with PlanetScale\n databases. It enables you define a shard key\n on multiple fields of your model:\n\nmodel User {\n\n  id         String @default(uuid())\n\n  country    String\n\n  customerId String\n\n  @@shardKey([country, customerId])\n\n}\n\nAttribute functions​\nauto()​\nWARNING\nThis function is available on MongoDB only.\n\nRepresents default values that are automatically generated by the database.\n\nRemarks​\nMongoDB​\n\nUsed to generate an ObjectId for @id fields:\n\nid  String  @map(\"_id\") @db.ObjectId @default(auto())\n\nRelational databases​\n\nThe auto() function is not available on relational databases.\n\nExample​\nGenerate ObjectId (MongoDB only)​\nmodel User {\n\n  id   String  @id @default(auto()) @map(\"_id\") @db.ObjectId\n\n  name String?\n\n}\n\nautoincrement()​\nWARNING\n\nNot supported by MongoDB\nThe MongoDB connector does not support the autoincrement() function.\n\nCreate a sequence of integers in the underlying database and assign the incremented values to the ID values of the created records based on the sequence.\n\nRemarks​\n\nCompatible with Int on most databases (BigInt on CockroachDB)\n\nImplemented on the database-level, meaning that it manifests in the database schema and can be recognized through introspection. Database implementations:\n\nDatabase\tImplementation\nPostgreSQL\t\nSERIAL\n type\nMySQL\t\nAUTO_INCREMENT\n attribute\nSQLite\t\nAUTOINCREMENT\n keyword\nCockroachDB\t\nSERIAL\n type\nExamples​\nGenerate autoincrementing integers as IDs (Relational databases only)​\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n}\n\nsequence()​\nINFO\n\nOnly supported by CockroachDB\nThe sequence function is only supported by CockroachDB connector.\n\nCreate a sequence of integers in the underlying database and assign the incremented values to the values of the created records based on the sequence.\n\nOptional arguments​\nArgument\tExample\nvirtual\t@default(sequence(virtual))\nVirtual sequences are sequences that do not generate monotonically increasing values and instead produce values like those generated by the built-in function unique_rowid().\ncache\t@default(sequence(cache: 20))\nThe number of sequence values to cache in memory for reuse in the session. A cache size of 1 means that there is no cache, and cache sizes of less than 1 are not valid.\nincrement\t@default(sequence(increment: 4))\nThe new value by which the sequence is incremented. A negative number creates a descending sequence. A positive number creates an ascending sequence.\nminValue\t@default(sequence(minValue: 10))\nThe new minimum value of the sequence.\nmaxValue\t@default(sequence(maxValue: 3030303))\nThe new maximum value of the sequence.\nstart\t@default(sequence(start: 2))\nThe value the sequence starts at, if it's restarted or if the sequence hits the maxValue.\nExamples​\nGenerate sequencing integers as IDs​\nmodel User {\n\n  id   Int    @id @default(sequence(maxValue: 4294967295))\n\n  name String\n\n}\n\ncuid()​\n\nGenerate a globally unique identifier based on the \ncuid\n spec.\n\nIf you'd like to use \ncuid2\n values, you can pass 2 as an argument to the cuid function: cuid(2).\n\nRemarks​\nCompatible with String.\nImplemented by Prisma ORM and therefore not \"visible\" in the underlying database schema. You can still use cuid() when using introspection by manually changing your Prisma schema and generating Prisma Client, in that case the values will be generated by Prisma's query engine.\nSince the length of cuid() output is undefined per the cuid creator, a safe field size is 30 characters, in order to allow for enough characters for very large values. If you set the field size as less than 30, and then a larger value is generated by cuid(), you might see Prisma Client errors such as Error: The provided value for the column is too long for the column's type.\nFor MongoDB: cuid() does not generate a valid ObjectId. You can use @db.ObjectId syntax if you want to use ObjectId in the underlying database. However, you can still use cuid() if your _id field is not of type ObjectId.\nExamples​\nGenerate cuid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(cuid())\n\n  name String\n\n}\n\nGenerate cuid(2) values as IDs based on the cuid2 spec​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(cuid(2))\n\n  name String\n\n}\n\nuuid()​\n\nGenerate a globally unique identifier based on the UUID\n spec. Prisma ORM supports versions 4 (default) and 7.\n\nRemarks​\nCompatible with String.\nImplemented by Prisma ORM and therefore not \"visible\" in the underlying database schema. You can still use uuid() when using introspection by manually changing your Prisma schema and generating Prisma Client, in that case the values will be generated by Prisma ORM's query engine.\nFor relational databases: If you do not want to use Prisma ORM's uuid() function, you can use the native database function with dbgenerated.\nFor MongoDB: uuid() does not generate a valid ObjectId. You can use @db.ObjectId syntax if you want to use ObjectId in the underlying database. However, you can still use uuid() if your _id field is not of type ObjectId.\nExamples​\nGenerate uuid() values as IDs using UUID v4​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(uuid())\n\n  name String\n\n}\n\nGenerate uuid(7) values as IDs using UUID v7​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(uuid(7))\n\n  name String\n\n}\n\nulid()​\n\nGenerate a universally unique lexicographically sortable identifier based on the ULID\n spec.\n\nRemarks​\nulid() will produce 128-bit random identifier represented as a 26-character long alphanumeric string, e.g.: 01ARZ3NDEKTSV4RRFFQ69G5FAV\nExamples​\nGenerate ulid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(ulid())\n\n  name String\n\n}\n\nnanoid()​\n\nGenerated values based on the Nano ID\n spec. nanoid() accepts an integer value between 2 and 255 that specifies the length of the generate ID value, e.g. nanoid(16) will generated ID with 16 characters. If you don't provide a value to the nanoid() function, the default value is 21.\n\nINFO\n\nNano ID is quite comparable to UUID v4 (random-based). It has a similar number of random bits in the ID (126 in Nano ID and 122 in UUID), so it has a similar collision probability:\n\nFor there to be a one in a billion chance of duplication, 103 trillion version 4 IDs must be generated.\n\nThere are two main differences between Nano ID and UUID v4:\n\nNano ID uses a bigger alphabet, so a similar number of random bits are packed in just 21 symbols instead of 36.\nNano ID code is 4 times smaller than uuid/v4 package: 130 bytes instead of 423.\nRemarks​\nCompatible with String.\nImplemented by Prisma ORM and therefore not \"visible\" in the underlying database schema. You can still use uuid() when using introspection by manually changing your Prisma schema and generating Prisma Client, in that case the values will be generated by Prisma ORM's query engine.\nFor MongoDB: nanoid() does not generate a valid ObjectId. You can use @db.ObjectId syntax if you want to use ObjectId in the underlying database. However, you can still use nanoid() if your _id field is not of type ObjectId.\nExamples​\nGenerate nanoid() values with 21 characters as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(nanoid())\n\n  name String\n\n}\n\nGenerate nanoid() values with 16 characters as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(nanoid(16))\n\n  name String\n\n}\n\nnow()​\n\nSet a timestamp of the time when a record is created.\n\nRemarks​\nGeneral​\nCompatible with DateTime\nWARNING\n\nIn versions before 4.4.0\n, if you're also using @updatedAt, the time might differ from the now() values if your database and app have different time zones. This happens because @updatedAt operates at the Prisma ORM level, while now() operates at the database level.\n\nRelational databases​\n\nImplemented on the database-level, meaning that it manifests in the database schema and can be recognized through introspection. Database implementations:\n\nDatabase\tImplementation\nPostgreSQL\t\nCURRENT_TIMESTAMP\n and aliases like now()\nMySQL\t\nCURRENT_TIMESTAMP\n and aliases like now()\nSQLite\tCURRENT_TIMESTAMP and aliases like date('now')\nCockroachDB\t\nCURRENT_TIMESTAMP\n and aliases like now()\nMongoDB​\nImplemented at Prisma ORM level\nExamples​\nSet current timestamp value when a record is created​\nRelational databases\nMongoDB\nmodel User {\n\n  id        String   @id\n\n  createdAt DateTime @default(now())\n\n}\n\ndbgenerated(...)​\n\nRepresents default values that cannot be expressed in the Prisma schema (such as random()).\n\nRemarks​\nRelational databases​\n\nCompatible with any scalar type\n\nCan not be an empty string dbgenerated(\"\") in 2.21.0\n and later\n\nAccepts a String value in 2.17.0\n and later, which allows you to:\n\nSet default values for Unsupported types\nOverride default value behavior for supported types\n\nString values in dbgenerated(...) might not match what the DB returns as the default value, because values such as strings may be explicitly cast (e.g. 'hello'::STRING). When a mismatch is present, Prisma Migrate indicates a migration is still needed. You can use prisma db pull to infer the correct value to resolve the discrepancy. (Related issue\n)\n\nExamples​\nSet default value for Unsupported type​\ncircle     Unsupported(\"circle\")?   @default(dbgenerated(\"'<(10,4),11>'::circle\"))\n\nOverride default value behavior for supported types​\n\nYou can also use dbgenerated(...) to set the default value for supported types. For example, in PostgreSQL you can generate UUIDs at the database level rather than rely on Prisma ORM's uuid():\n\nmodel User {\n\n  id   String  @id @default(dbgenerated(\"gen_random_uuid()\")) @db.Uuid\n\n  id   String  @id @default(uuid()) @db.Uuid\n\n  test String?\n\n}\n\nINFO\n\nNote: \ngen_random_uuid()\nis a PostgreSQL function\n. To use it in PostgreSQL versions 12.13 and earlier, you must enable the pgcrypto extension.\n\nIn Prisma ORM versions 4.5.0 and later, you can declare the pgcrypto extension in your Prisma schema with the postgresqlExtensions preview feature.\n\nAttribute argument types​\nFieldReference[]​\n\nAn array of field names: [id], [firstName, lastName]\n\nString​\n\nA variable length text in double quotes: \"\", \"Hello World\", \"Alice\"\n\nExpression​\n\nAn expression that can be evaluated by Prisma ORM: 42.0, \"\", Bob, now(), cuid()\n\nenum​\nWARNING\n\nNot supported Microsoft SQL Server\nThe Microsoft SQL Server connector does not support the enum type.\n\nDefines an enum .\n\nRemarks​\nEnums are natively supported by PostgreSQL\n and MySQL\nEnums are implemented and enforced at Prisma ORM level in SQLite and MongoDB\nNaming conventions​\nEnum names must start with a letter (they are typically spelled in PascalCase\n)\nEnums must use the singular form (e.g. Role instead of role, roles or Roles).\nMust adhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\nExamples​\nSpecify an enum with two possible values​\nRelational databases\nMongoDB\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\n\n\nmodel User {\n\n  id   Int  @id @default(autoincrement())\n\n  role Role\n\n}\n\nSpecify an enum with two possible values and set a default value​\nRelational databases\nMongoDB\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\n\n\nmodel User {\n\n  id   Int  @id @default(autoincrement())\n\n  role Role @default(USER)\n\n}\n\ntype​\nWARNING\n\nComposite types are available for MongoDB only.\n\nINFO\n\nComposite types are available in versions 3.12.0 and later, and in versions 3.10.0 and later if you enable the mongodb Preview feature flag.\n\nDefines a composite type .\n\nNaming conventions​\n\nType names must:\n\nstart with a letter (they are typically spelled in PascalCase\n)\nadhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\nExamples​\nDefine a Product model with a list of Photo composite types​\nmodel Product {\n\n  id     String  @id @default(auto()) @map(\"_id\") @db.ObjectId\n\n  name   String\n\n  photos Photo[]\n\n}\n\n\n\ntype Photo {\n\n  height Int\n\n  width  Int\n\n  url    String\n\n}\n"
  },
  {
    "title": "Prisma CLI reference | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-cli-reference",
    "html": "ORMReference\nPrisma CLI reference\n\nThis document describes the Prisma CLI commands, arguments, and options.\n\nCommands​\nversion (-v)​\n\nThe version command outputs information about your current prisma version, platform, and engine binaries.\n\nOptions​\n\nThe version command recognizes the following options to modify its behavior:\n\nOption\tRequired\tDescription\n--json\tNo\tOutputs version information in JSON format.\nExamples​\nOutput version information​\nprisma version\n\nShow CLI results\nEnvironment variables loaded from .env\n\nprisma               : 2.21.0-dev.4\n\n@prisma/client       : 2.21.0-dev.4\n\nCurrent platform     : windows\n\nQuery Engine         : query-engine 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\query-engine-windows.exe)\n\nMigration Engine     : migration-engine-cli 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\migration-engine-windows.exe)\n\nFormat Binary        : prisma-fmt 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\n\nDefault Engines Hash : 60ba6551f29b17d7d6ce479e5733c70d9c00860e\n\nStudio               : 0.365.0\n\nOutput version information (-v)​\nprisma -v\n\nShow CLI results\nEnvironment variables loaded from .env\n\nprisma               : 2.21.0-dev.4\n\n@prisma/client       : 2.21.0-dev.4\n\nCurrent platform     : windows\n\nQuery Engine         : query-engine 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\query-engine-windows.exe)\n\nMigration Engine     : migration-engine-cli 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\migration-engine-windows.exe)\n\nFormat Binary        : prisma-fmt 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\n\nDefault Engines Hash : 60ba6551f29b17d7d6ce479e5733c70d9c00860e\n\nStudio               : 0.365.0\n\nOutput version information as JSON​\nprisma version --json\n\nShow CLI results\nEnvironment variables loaded from .env\n\n{\n\n  \"prisma\": \"2.21.0-dev.4\",\n\n  \"@prisma/client\": \"2.21.0-dev.4\",\n\n  \"current-platform\": \"windows\",\n\n  \"query-engine\": \"query-engine 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\\\@prisma\\\\engines\\\\query-engine-windows.exe)\",\n\n  \"migration-engine\": \"migration-engine-cli 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\\\@prisma\\\\engines\\\\migration-engine-windows.exe)\",\n\n  \"format-binary\": \"prisma-fmt 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\\\@prisma\\\\engines\\\\prisma-fmt-windows.exe)\",\n\n  \"default-engines-hash\": \"60ba6551f29b17d7d6ce479e5733c70d9c00860e\",\n\n  \"studio\": \"0.365.0\"\n\n}\n\ninit​\n\nBootstraps a fresh Prisma ORM project within the current directory.\n\nThe init command does not interpret any existing files. Instead, it creates a prisma directory containing a bare-bones schema.prisma file within your current directory.\n\nBy default, the project sets up a local Prisma Postgres instance but you can choose a different database using the --datasource-provider option.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--datasource-provider\tNo\tSpecifies the value for the provider field in the datasource block. Options are prisma+postgres, sqlite, postgresql, mysql, sqlserver, mongodb and cockroachdb.\tpostgresql\n--db\tNo\tShorthand syntax for --datasource-provider prisma+postgres; creates a new Prisma Postgres instance. Requires authentication in the PDP Console.\t\n--prompt (or --vibe)\tNo\tScaffolds a Prisma schema based on the prompt and deploys it to a fresh Prisma Postgres instance. Requires authentication in the PDP Console.\t\n--url\tNo\tDefine a custom datasource url.\t\n--generator-provider\tNo\tDefine the generator provider to use.\tprisma-client-js\n--preview-feature\tNo\tDefine the Preview features to use. To define multiple Preview features, you have to provide the flag multiple times for each Preview feature. See examples.\t\n--output\tNo\tSpecifies the output location for the generated client.\t../generated/prisma\n--with-model\tNo\tAdds a simple User model to the initial Prisma schema. Available since version 5.14.0.\t\nExamples​\n\nRun prisma init\n\nprisma init\n\nShow CLI results\n✔ Your Prisma schema was created at prisma/schema.prisma.\n\nYou can now open it in your favorite editor.\n\n\n\nNext steps:\n\n1. Set the DATABASE_URL in the .env file to point to your existing database. If your database has no tables yet, read https://pris.ly/d/getting-started\n\n2. Set the provider of the datasource block in schema.prisma to match your database: postgresql, mysql, sqlite, sqlserver, mongodb or cockroachdb.\n\n3. Run prisma db pull to turn your database schema into a Prisma schema.\n\n4. Run prisma generate to generate Prisma Client. You can then start querying your database.\n\n\n\nMore information in our documentation:\n\nhttps://pris.ly/d/getting-started\n\n\nNext, run the prisma dev command to interact with your local Prisma Postgres instance (e.g. to run migrations or execute queries).\n\nRun prisma init --datasource-provider sqlite\n\nprisma init --datasource-provider sqlite\n\n\nThe command output contains helpful information on how to use the generated files and begin using Prisma ORM with your project.\n\nRun prisma init --db\n\nprisma init --db\n\n\nThe command creates a new Prisma Postgres instance. Note that it requires you to be authenticated with the PDP Console, If you run it for the first time without being authenticated, the command will open the browser for you to log into Console.\n\nRun prisma init --prompt \"Simple habit tracker application\"\n\nprisma init --prompt \"Simple habit tracker application\"\n\n\nThe command scaffolds a Prisma schema and deploys it to a fresh Prisma Postgres instance. Note that it requires you to be authenticated with the PDP Console, If you run it for the first time without being authenticated, the command will open the browser for you to log into Console.\n\nRun prisma init --preview-feature\n\nprisma init --preview-feature metrics\n\nShow Prisma schema results\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"metrics\"]\n\n}\n\nprisma init --preview-feature view --preview-feature metrics\n\nShow Prisma schema results\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"views\", \"metrics\"]\n\n}\n\nGenerated Assets​\n\nprisma/schema.prisma\n\nAn initial schema.prisma file to define your schema in:\n\n// This is your Prisma schema file,\n\n// learn more about it in the docs: https://pris.ly/d/prisma-schema\n\n\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output   = \"../generated/prisma\"\n\n}\n\n\n\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n.env\n\nA file to define environment variables for your project:\n\n# Environment variables declared in this file are automatically made available to Prisma.\n\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server, MongoDB and CockroachDB.\n\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\n\n\nDATABASE_URL=\"file:./dev.db\"\n\n\n.gitignore\n\nA file to specify what folders/files git should ignore in your project.\n\nnode_modules\n\n# Keep environment variables out of version control\n\n.env\n\n\n\n/generated/prisma\n\n\nRun prisma init --url mysql://user:password@localhost:3306/mydb\n\nThe init command with the --url argument allows you to specify a custom datasource URL during Prisma initialization, instead of relying on a placeholder database URL:\n\nprisma init --url mysql://user:password@localhost:3306/mydb\n\nGenerated Assets​\n\nprisma/schema.prisma\n\nA minimal schema.prisma file to define your schema in:\n\n// This is your Prisma schema file,\n\n// learn more about it in the docs: https://pris.ly/d/prisma-schema\n\n\n\ndatasource db {\n\n  provider = \"mysql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\n\n.env\n\nA file to define environment variables for your project:\n\n# Environment variables declared in this file are automatically made available to Prisma.\n\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server, MongoDB and CockroachDB.\n\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\n\n\nDATABASE_URL=\"mysql://user:password@localhost:3306/mydb\"\n\ngenerate​\n\nThe generate command generates assets like Prisma Client based on the generator and data model blocks defined in your prisma/schema.prisma file.\n\nThe generate command is most often used to generate Prisma Client with the prisma-client-js generator. This does three things:\n\nSearches the current directory and parent directories to find the applicable npm project. It will create a package.json file in the current directory if it cannot find one.\nInstalls the @prisma/client into the npm project if it is not already present.\nInspects the current directory to find a Prisma Schema to process. It will then generate a customized Prisma Client\n for your project.\nPrerequisites​\n\nTo use the generate command, you must add a generator definition in your schema.prisma file. The prisma-client-js generator, used to generate Prisma Client, can be added by including the following in your schema.prisma file:\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--data-proxy\tNo\tThe generate command will generate Prisma Client for use with Prisma Accelerate prior to Prisma 5.0.0. Mutually exclusive with --accelerate and --no-engine.\t\n--accelerate\tNo\tThe generate command will generate Prisma Client for use with Prisma Accelerate. Mutually exclusive with --data-proxy and --no-engine. Available in Prisma 5.1.0 and later.\t\n--no-engine\tNo\tThe generate command will generate Prisma Client without an accompanied engine for use with Prisma Accelerate. Mutually exclusive with --data-proxy and --accelerate. Available in Prisma ORM 5.2.0 and later.\t\n--no-hints\tNo\tThe generate command will generate Prisma Client without usage hints, surveys or info banners being printed to the terminal. Available in Prisma ORM 5.16.0 and later.\t\n--allow-no-models\tNo\tThe generate command will generate Prisma Client without generating any models.\t\n--watch\tNo\tThe generate command will continue to watch the schema.prisma file and re-generate Prisma Client on file changes.\t\nWARNING\n\nDeprecation Warning\n\nAs of Prisma 5.2.0, --data-proxy and --accelerate are deprecated in favor of --no-engine as Prisma Client no longer requires an option to work with Prisma Accelerate. All options are available and work similarly, but we recommend --no-engine as it prevents an engine from being downloaded which will greatly impact the size of apps deployed to serverless and edge functions.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\t\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\t\n--generator\tNo\tSpecifies which generator to use to generate assets. This option may be provided multiple times to include multiple generators. By default, all generators in the target schema will be run.\t\t\nExamples​\nGenerate Prisma Client using the default schema.prisma path​\nprisma generate\n\nShow CLI results\n✔ Generated Prisma Client to ./node_modules/.prisma/client in 61ms\n\n\n\nYou can now start using Prisma Client in your code:\n\n\n\nimport { PrismaClient } from '@prisma/client'\n\n// or const { PrismaClient } = require('@prisma/client')\n\n\n\nconst prisma = new PrismaClient()\n\n\n\nExplore the full API: https://pris.ly/d/client\n\nGenerate Prisma Client using a non-default schema.prisma path​\nprisma generate --schema=./alternative/schema.prisma\n\nContinue watching the schema.prisma file for changes to automatically re-generate Prisma Client​\nprisma generate --watch\n\nShow CLI results\nWatching... /home/prismauser/prisma/prisma-play/prisma/schema.prisma\n\n\n\n✔ Generated Prisma Client to ./node_modules/.prisma/client in 45ms\n\nRun the generate command with only a specific generator​\nprisma generate --generator client\n\nRun the generate command with multiple specific generators​\nprisma generate --generator client --generator zod_schemas\n\nGenerated Assets​\n\nThe prisma-client-js generator creates a customized client for working with your database within the ./node_modules/.prisma/client directory by default - you can customize the output folder.\n\nvalidate​\n\nValidates the Prisma Schema Language of the Prisma schema file.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\nExamples​\nValidate a schema without errors​\nprisma validate\n\nShow CLI results\nValidate a schema with validation errors​\nprisma validate\n\nShow CLI results\nformat​\n\nFormats the Prisma schema file, which includes validating, formatting, and persisting the schema.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\n--check\tNo\tFails if any files are unformatted. This can be used in CI to detect if the schema is formatted correctly\t\nExamples​\nValidate a schema without errors​\nprisma format\n\nShow CLI results\nFormatting a schema with validation errors​\nprisma format\n\nShow CLI results\ndebug​\n\nPrints information for debugging and bug reports.\n\nINFO\n\nThis is available from version 5.6.0 and newer.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\n--help / --h\tNo\tDisplays the help message\t\nExample​\nprisma debug\n\nShow CLI results\n\nIf you're using an older version of Prisma, you can use this command by running:\n\nnpx prisma@latest debug\n\ndev​\n\nThe dev command starts a local Prisma Postgres database that you can run Prisma ORM commands against. It is useful for development and testing purposes and also allows you to switch to Prisma Postgres in production easily.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--name (or -n)\tNo\tEnables targeting a specific database instance. Learn more.\t\n--port (or -p)\tNo\tMain port number the local Prisma Postgres HTTP server will listen on.\t51213\n--db-port (or -P)\tNo\tPort number the local Prisma Postgres database server will listen on.\t51214\n--shadow-db-port\tNo\tPort number the shadow database server will listen on.\t51215\n--debug\tNo\tEnable debug logging.\tfalse\nExamples​\n\nRun prisma dev\n\nprisma dev\n\nShow CLI results\n$ npx prisma dev\n\nFetching latest updates for this subcommand...\n\n✔ Great Success! 😉👍\n\n\n\nYour prisma dev server default is ready and listening on ports 63567-63569.\n\n\n\n╭──────────────────────────────╮\n\n│[q]uit [h]ttp url [t]cp urls│\n\n╰──────────────────────────────╯\n\ndev stop​\n\nStops one or more local Prisma Postgres databases:\n\nnpx prisma dev stop <glob>\n\n\n<glob> is a placeholder for a glob pattern to specify which local Prisma Postgres instances should be stopped, for example:\n\nnpx prisma dev stop mydb # stops a DB called `mydb`\n\n\nTo stop all databases that begin with mydb (e.g. mydb-dev and mydb-prod), you can use a glob:\n\nnpx prisma dev stop mydb* # stops all DBs starting with `mydb`\n\ndev rm​\n\nRemoves the data of one or more local Prisma Postgres databases from your file system:\n\nnpx prisma dev rm <glob>\n\n\n<glob> is a placeholder for a glob pattern to specify which local Prisma Postgres instances should be removed, for example:\n\nnpx prisma dev stop mydb # stops a DB called `mydb`\n\n\nTo stop all databases that begin with mydb (e.g. mydb-dev and mydb-prod), you can use a glob:\n\nnpx prisma dev stop mydb* # stops all DBs starting with `mydb`\n\ndb​\ndb pull​\n\nThe db pull command connects to your database and adds Prisma models to your Prisma schema that reflect the current database schema.\n\nWARNING\n\nWarning: The command will overwrite the current schema.prisma file with the new schema. Some manual changes or customization can be lost. Be sure to back up your current schema.prisma file (or commit your current state to version control to be able to revert any changes) before running db pull if it contains important modifications.\n\nINFO\n\nIntrospection with the db pull command on the MongoDB connector samples the data instead of reading a schema.\n\nPrerequisites​\n\nBefore using the db pull command, you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--force\tNo\tForce overwrite of manual changes made to schema. The generated schema will be based on the introspected schema only.\t\n--print\tNo\tPrints the created schema.prisma to the screen instead of writing it to the filesystem.\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\nExamples​\nAnalyze the database and write its schema to the schema.prisma file​\nprisma db pull\n\nShow CLI results\nIntrospecting based on datasource defined in schema.prisma …\n\n\n\n✔ Introspected 2 models and wrote them into schema.prisma in 38ms\n\n\n\nRun prisma generate to generate Prisma Client.\n\nSpecify an alternative schema.prisma file to read and write to​\nprisma db pull --schema=./alternative/schema.prisma\n\nShow CLI results\nIntrospecting based on datasource defined in alternative/schema.prisma …\n\n\n\n✔ Introspected 2 models and wrote them into alternative/schema.prisma in 60ms\n\n\n\nRun prisma generate to generate Prisma Client.\n\nDisplay the generated schema.prisma file instead of writing it to the filesystem​\nprisma db pull --print\n\nShow CLI results\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\n\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:./hello-prisma.db\"\n\n}\n\n\n\nmodel User {\n\n  email   String    @unique\n\n  name    String?\n\n  user_id Int       @id @default(autoincrement())\n\n  post    Post[]\n\n  profile Profile[]\n\n}\n\n\n\nmodel Post {\n\n  content   String?\n\n  post_id   Int     @id @default(autoincrement())\n\n  title     String\n\n  author    User?   @relation(fields: [author_id], references: [user_id])\n\n  author_id Int?\n\n}\n\n\n\nmodel Profile {\n\n  bio        String?\n\n  profile_id Int     @id @default(autoincrement())\n\n  user       User    @relation(fields: [user_id], references: [user_id])\n\n  user_id    Int     @unique\n\n}\n\ndb push​\n\nThe db push command pushes the state of your Prisma schema to the database without using migrations. It creates the database if the database does not exist.\n\nThis command is a good choice when you do not need to version schema changes, such as during prototyping and local development.\n\nSee also:\n\nConceptual overview of db push and when to use it over Prisma Migrate\nSchema prototyping with db push\nPrerequisites​\n\nBefore using the db push command, you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\nOptions\tRequired\tDescription\n--skip-generate\tNo\tSkip generation of artifacts such as Prisma Client\n--force-reset\tNo\tResets the database and then updates the schema - useful if you need to start from scratch due to unexecutable migrations.\n--accept-data-loss\tNo\tIgnore data loss warnings. This option is required if as a result of making the schema changes, data may be lost.\n--help / --h\tNo\tDisplays the help message\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\n\nPush the schema:\n\nprisma db push\n\n\nPush the schema, accepting data loss:\n\nprisma db push --accept-data-loss\n\n\nPush the schema with a custom schema location:\n\nprisma db push --schema=/tmp/schema.prisma\n\ndb seed​\n\ndb seed changed from Preview to Generally Available (GA) in 3.0.1.\n\nSee Seeding your database\n\nOptions​\nOptions\tRequired\tDescription\n--help / --h\tNo\tDisplays the help message\n--\tNo\tAllows the use of custom arguments defined in a seed file\n\nThe -- argument/ delimiter\n/ double-dash is available from version 4.15.0 or later.\n\nExamples​\nprisma db seed\n\ndb execute​\nINFO\n\nThe db execute command is Generally Available in versions 3.13.0 and later. If you're using a version between 3.9.0 and 3.13.0, it is available behind a --preview-feature CLI flag.\n\nWARNING\n\nThis command is currently not supported on MongoDB.\n\nThis command applies a SQL script to the database without interacting with the Prisma migrations table. The script takes two inputs:\n\nthe SQL script, which can be provided either on standard input or in a file\nthe data source, which can either be the URL of the data source or the path to your Prisma schema file\n\nThe output of the command is connector-specific, and is not meant for returning data, but only to report success or failure.\n\nSee also:\n\nMigration troubleshooting in production\nPrerequisites​\n\nBefore using the db execute command, if you do not use the --url option you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\n\nOne of the following data source inputs is required:\n\nOptions\tDescription\n--url\tURL of the data source to run the command on\n--schema\tPath to a Prisma schema file, uses the URL in the datasource block\n\nOne of the following script inputs is required:\n\nOptions\tDescription\n--stdin\tUse the terminal standard input as the script to be executed\n--file\tPath to a file. The content will be sent as the script to be executed\n\nOther options:\n\nOptions\tRequired\tDescription\n--help\tNo\tDisplays the help message.\nExamples​\n\nTake the content of a SQL file located at ./script.sql and execute it on the database specified by the URL in the datasource block of your schema.prisma file:\n\nprisma db execute --file ./script.sql --schema schema.prisma\n\n\nTake the SQL script from standard input and execute it on the database specified by the data source URL given in the DATABASE_URL environment variable:\n\necho 'TRUNCATE TABLE dev;' | prisma db execute --stdin --url=\"$DATABASE_URL\"\n\nPrisma Migrate​\n\nPrisma Migrate changed from Preview to Generally Available (GA) in 2.19.0.\n\nINFO\n\nDoes not apply for MongoDB\nInstead of migrate dev and related commands, db push is used for MongoDB.\n\nmigrate dev​\n\nFor use in development environments only, requires shadow database\n\nThe migrate dev command:\n\nReruns the existing migration history in the shadow database in order to detect schema drift (edited or deleted migration file, or a manual changes to the database schema)\nApplies pending migrations to the shadow database (for example, new migrations created by colleagues)\nGenerates a new migration from any changes you made to the Prisma schema before running migrate dev\nApplies all unapplied migrations to the development database and updates the _prisma_migrations table\nTriggers the generation of artifacts (for example, Prisma Client)\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nSee also:\n\nConceptual overview of Prisma Migrate\nDeveloping with Prisma Migrate\nOptions​\nOption\tRequired\tDescription\tDefault\n--create-only\tNo\tCreates a new migration but does not apply it. This also works if you haven't made any changes to your schema (in that case, an empty migration is created). Run migrate dev to apply migration.\t\n--skip-seed\tNo\tSkip triggering seed\t\n--skip-generate\tNo\tSkip triggering generators (for example, Prisma Client)\t\n--name / -n\tNo\tName the migration (e.g. prisma migrate dev --name added_job_title)\t\n--help / -h\tNo\tDisplays the help message\t\nINFO\n\nIf a schema drift is detected while running prisma migrate dev using --create-only, you will be prompted to reset your database.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--name\tNo\tThe name of the migration. If no name is provided, the CLI will prompt you.\t\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\n\nApply all migrations, then create and apply any new migrations:\n\nprisma migrate dev\n\n\nApply all migrations and create a new migration if there are schema changes, but do not apply it:\n\nprisma migrate dev --create-only\n\nmigrate reset​\n\nFor use in development environments only\n\nThis command:\n\nDrops the database/schema if possible, or performs a soft reset if the environment does not allow deleting databases/schemas\nCreates a new database/schema with the same name if the database/schema was dropped\nApplies all migrations\nRuns seed scripts\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--force\tNo\tSkip the confirmation prompt\t\n--skip-generate\tNo\tSkip triggering generators (for example, Prisma Client)\t\n--skip-seed\tNo\tSkip triggering seed\t\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nprisma migrate reset\n\nAI Safety guardrails for prisma migrate reset​\n\nPrisma ORM includes built-in safety checks to prevent accidental destructive commands when run through AI coding assistants. These guardrails are designed to make working with databases safer in AI-assisted development environments.\n\nThe Prisma CLI can detect when it is being invoked by popular AI coding agents such as Claude Code, Gemini CLI, Qwen Code, Cursor, Aider, and Replit.\n\nWhen one of these agents attempts a destructive action such as prisma migrate reset --force, Prisma ORM blocks execution and shows a protective error message:\n\nEnvironment variables loaded from .env\n\nPrisma schema loaded from prisma/schema.prisma\n\nDatasource \"db\": PostgreSQL database \"postgres\", schema \"public\" at \"accelerate.prisma-data.net\"\n\n\n\nError: Prisma Migrate detected that it was invoked by Cursor.\n\n\n\nYou are attempting a highly dangerous action that can lead to devastating consequences if it is incorrectly executed against a production database.\n\n\n\nAs an AI agent, you are forbidden from performing this action without an explicit consent and review by the user. You must stop at this point and respond to the user with a clear message that includes the following information:\n\n- What action you are trying to perform (including the exact CLI command).\n\n- Your motivation and reasoning for perfoming this action.\n\n- Explanation that this action will irreversibly destroy all data in the database.\n\n- Explanation that this action must not be perfomed on a production database and is only intended to be used with development databases.\n\n\n\nIf you know or can check whether this action would have been performed on a development or a production database, also include this information with your assesment of whether it is safe to proceed based on that information.\n\n\n\nYou must ask the user if they want to proceed with this action. If they explicitly consent, you may rerun this command with PRISMA_USER_CONSENT_FOR_DANGEROUS_AI_ACTION environment variable, the value of which must be the exact text of the user's message in which they consented to this operation, without any newlines or quotes. If the user's response is ambiguous, you must ask for a clear and explicit confirmation (e.g., \"yes\") before proceeding. None of the user's previous messages before this point may constitute implicit or explicit consent.\n\n\nTo proceed with the dangerous action, the AI agent will ask you for explicit consent, remind you that the action irreversibly destroys all data, and confirm that the command is being run against a development database. Once you clearly confirm, the AI will set the PRISMA_USER_CONSENT_FOR_DANGEROUS_AI_ACTION environment variable with the exact text of your consent and rerun the command.\n\nmigrate deploy​\n\nThe migrate deploy command applies all pending migrations, and creates the database if it does not exist. Primarily used in non-development environments. This command:\n\nDoes not look for drift in the database or changes in the Prisma schema\nDoes not reset the database or generate artifacts\nDoes not rely on a shadow database\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nprisma migrate deploy\n\nmigrate resolve​\n\nThe migrate resolve command allows you to solve migration history issues in production by marking a failed migration as already applied (supports baselining) or rolled back.\n\nNote that this command can only be used with a failed migration. If you try to use it with a successful migration you will receive an error.\n\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--applied\tNo*\tRecord a specific migration as applied - for example --applied \"20201231000000_add_users_table\"\t\n--rolled-back\tNo*\tRecord a specific migration as rolled back - for example --rolled-back \"20201231000000_add_users_table\"\t./schema.prisma\n./prisma/schema.prisma\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\n\nYou must specify either --rolled-back or --applied.\n\nExamples​\nprisma migrate resolve --applied 20201231000000_add_users_table\n\nprisma migrate resolve --rolled-back 20201231000000_add_users_table\n\nmigrate status​\n\nThe prisma migrate status command looks up the migrations in ./prisma/migrations/* folder and the entries in the _prisma_migrations table and compiles information about the state of the migrations in your database.\n\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nFor example:\n\nStatus\n\n3 migrations found in prisma/migrations\n\n\n\nYour local migration history and the migrations table from your database are different:\n\n\n\nThe last common migration is: 20201127134938_new_migration\n\n\n\nThe migration have not yet been applied:\n\n20201208100950_test_migration\n\n\n\nThe migrations from the database are not found locally in prisma/migrations:\n\n20201208100950_new_migration\n\n\nIn versions 4.3.0 and later, prisma migrate status exits with exit code 1 in the following cases:\n\na database connection error occurs\nthere are migration files in the migrations directory that have not been applied to the database\nthe migration history in the migrations directory has diverged from the state of the database\nno migration table is found\nfailed migrations are found\nOptions​\nOption\tRequired\tDescription\tDefault\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nprisma migrate status\n\nmigrate diff​\nINFO\n\nThis command is only partially supported for MongoDB. See the command options below for details.\n\nThis command compares two database schema sources and outputs a description of a migration taking the first to the state of the second.\n\nThe output can be given either as a human-readable summary (the default) or an executable script.\n\nWARNING\n\nThe migrate diff command can only compare database features that are supported by Prisma. If two databases differ only in unsupported features, such as views or triggers, then migrate diff will not show any difference between them.\n\nThe format of the command is:\n\nprisma migrate diff --from-... <source1> --to-... <source2>\n\n\nwhere the --from-... and --to-... options are selected based on the type of database schema source. The supported types of sources are:\n\nlive databases\nmigration histories\nPrisma schema data models\nan empty schema\n\nBoth schema sources must use the same database provider. For example, a diff comparing a PostgreSQL data source with a SQLite data source is not supported.\n\nSee also:\n\nMigration troubleshooting in production\nPrerequisites​\n\nBefore using the migrate diff command, if you are using the --from-schema-datasource or --to-schema-datasource you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\n\nOne of the following --from-... options is required:\n\nOptions\tDescription\tNotes\n--from-url\tA data source URL\t\n--from-migrations\tPath to the Prisma Migrate migrations directory\tNot supported in MongoDB\n--from-schema-datamodel\tPath to a Prisma schema file, uses the data model for the diff\t\n--from-schema-datasource\tPath to a Prisma schema file, uses the URL in the datasource block for the diff\t\n--from-empty\tAssume that you the data model you are migrating from is empty\t\n--from-local-d1\tPath to a local D1 instance (learn more)\tAvailable since 5.12.0\n\nOne of the following --to-... options is required:\n\nOptions\tDescription\tNotes\n--to-url\tA data source URL\t\n--to-migrations\tPath to the Prisma Migrate migrations directory\tNot supported in MongoDB\n--to-schema-datamodel\tPath to a Prisma schema file, uses the data model for the diff\t\n--to-schema-datasource\tPath to a Prisma schema file, uses the URL in the datasource block for the diff\t\n--to-empty\tAssume that you the data model you are migrating to is empty\t\n--to-local-d1\tPath to a local D1 instance (learn more)\tAvailable since 5.12.0\n\nOther options:\n\nOptions\tRequired\tDescription\tNotes\n--shadow-database-url\tNo\tURL for the shadow database\tOnly required if using --to-migrations or --from-migrations\n--script\tNo\tOutputs a SQL script instead of the default human-readable summary\tNot supported in MongoDB\n-o, --output\tNo\tWrites to a file instead of stdout\tAvailable since 5.12.1\n\n--exit-code\tNo\tChange the exit code behavior to signal if the diff is empty or not (Empty: 0, Error: 1, Not empty: 2). Default behavior is Success: 0, Error: 1.\t\n--help\tNo\tDisplays the help message.\t\nExamples​\n\nCompare two databases specified by their data source URL, and output the default human-readable summary:\n\nprisma migrate diff \\\n\n  --from-url \"$DATABASE_URL\" \\\n\n  --to-url \"postgresql://login:password@localhost:5432/db2\"\n\n\nCompare the state of a database with a URL of $DATABASE_URL to the schema defined by the migrations in the ./prisma/migrations directory, and output the differences to a script script.sql:\n\nprisma migrate diff \\\n\n --from-url \"$DATABASE_URL\" \\\n\n --to-migrations ./prisma/migrations \\\n\n --shadow-database-url $SHADOW_DATABASE_URL \\\n\n --script > script.sql\n\nPrisma Data Platform​\nplatform (Early Access)​\n\nThe platform command provides access to the Prisma Data Platform through the Prisma CLI starting in version 5.10.0 or later.\n\nAuthentication:\nplatform auth login: Opens a browser window for login or account creation.\nplatform auth logout: Logs out of the platform.\nplatform auth show: Displays information about the currently authenticated user.\nWorkspace Management:\nplatform workspace show: Lists all workspaces available to your account.\nProject Management:\nplatform project show: Lists all projects within the specified workspace.\nplatform project create: Creates a new project within the specified workspace.\nplatform project delete: Deletes the specified project.\nEnvironment Management:\nplatform environment show: Lists all environments for the specified project.\nplatform environment create: Creates a new environment within the specified project.\nplatform environment delete: Deletes the specified environment.\nAPI Key Management:\nplatform apikey show: Lists all API keys for the specified environment.\nplatform apikey create: Creates a new API key for the specified environment.\nplatform apikey delete: Deletes the specified API key.\nPrisma Accelerate:\nplatform accelerate enable: Enables Prisma Accelerate for the specified environment.\nplatform accelerate disable: Disables Prisma Accelerate for the specified environment.\n\nYou can find the complete list of available commands with the arguments here.\n\nmcp​\n\nStarts the Prisma MCP server.\n\nStudio​\nstudio​\n\nThe studio command allows you to interact with and manage your data interactively. It does this by starting a local web server with a web app configured with your project's data schema and records.\n\nPrerequisites​\n\nBefore using the studio command, you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\n\nThe studio command recognizes the following options:\n\nOption\tRequired\tDescription\tDefault\n-b, --browser\tNo\tThe browser to auto-open Studio in.\t<your-default-browser>\n-h, --help\tNo\tShow all available options and exit\t\n-p, --port\tNo\tThe port number to start Studio on.\t5555\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nStart Studio on the default port and open a new browser tab to it​\nprisma studio\n\nStart Studio on a different port and open a new browser tab to it​\nprisma studio --port 7777\n\nStart Studio and open a Firefox tab to it​\nprisma studio --browser firefox\n\nStart Studio without opening a new browser tab to it​\nprisma studio --browser none\n\npackage.json entry options​\nschema​\n\nThe path to the desired schema.prisma file can be specified with the prisma.schema entry in the package.json file. The path defines the file the Prisma CLI should use when you run any of the CLI commands. Both absolute and relative paths are supported.\n\n\"package.json\"\n{\n\n  \"name\": \"my-project\",\n\n  \"version\": \"1.0.0\",\n\n  \"prisma\": {\n\n    \"schema\": \"./custom-path-to-schema/schema.prisma\"\n\n  }\n\n}\n\n\nThis is available from version 2.7.0 and later.\n\nseed​\n\nThe command used to populate the datasource is specified in the prisma.seed entry in the package.json file. It is used when prisma db seed is invoked or triggered.\n\nSee Seeding your database\n\n\"package.json\"\n{\n\n  \"name\": \"my-project\",\n\n  \"version\": \"1.0.0\",\n\n  \"prisma\": {\n\n    \"seed\": \"node ./prisma/seed.js\"\n\n  }\n\n}\n\n\nThis is available from version 3.0.1 and later.\n\nUsing a HTTP proxy for the CLI​\n\nPrisma CLI supports custom HTTP proxies\n. This is particularly relevant when being behind a corporate firewall.\n\nTo activate usage of the proxy, provide either of the following environment variables:\n\nHTTP_PROXY or http_proxy: Proxy URL for http traffic, for example http://localhost:8080\nHTTPS_PROXY or https_proxy: Proxy URL for https traffic, for example https://localhost:8080\nnpx create-db​\n\nThe create-db command provisions a temporary Prisma Postgres database with a single command. This is a standalone utility that can be invoked using npx. It's ideal for quickly testing, prototyping, or integrating with Prisma Postgres.\n\nYou can run the following variants:\n\nCommand\tDescription\nnpx create-db@latest\tCreates a temporary Prisma Postgres database.\nnpx create-pg@latest\tAlias for npx create-db.\nnpx create-postgres@latest\tAlias for npx create-db.\n\nEach database created with these commands:\n\nIs available for 24 hours by default.\nCan be claimed for free to make it permanent using the URL displayed in the CLI output.\n\nFor full usage details, options (such as --region and --interactive), and examples, see the documentation."
  },
  {
    "title": "Errors | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/error-reference",
    "html": "ORMReference\nError message reference\n\nFor more information about how to work with exceptions and error codes, see Handling exceptions and errors.\n\nPrisma Client error types​\n\nPrisma Client throws different kinds of errors. The following lists the exception types, and their documented data fields:\n\nPrismaClientKnownRequestError​\n\nPrisma Client throws a PrismaClientKnownRequestError exception if the query engine returns a known error related to the request - for example, a unique constraint violation.\n\nProperty\tDescription\ncode\tA Prisma-specific error code.\nmeta\tAdditional information about the error - for example, the field that caused the error: { target: [ 'email' ] }\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientUnknownRequestError​\n\nPrisma Client throws a PrismaClientUnknownRequestError exception if the query engine returns an error related to a request that does not have an error code.\n\nProperty\tDescription\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientRustPanicError​\n\nPrisma Client throws a PrismaClientRustPanicError exception if the underlying engine crashes and exits with a non-zero exit code. In this case, Prisma Client or the whole Node process must be restarted.\n\nProperty\tDescription\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientInitializationError​\n\nPrisma Client throws a PrismaClientInitializationError exception if something goes wrong when the query engine is started and the connection to the database is created. This happens either:\n\nWhen prisma.$connect() is called OR\nWhen the first query is executed\n\nErrors that can occur include:\n\nThe provided credentials for the database are invalid\nThere is no database server running under the provided hostname and port\nThe port that the query engine HTTP server wants to bind to is already taken\nA missing or inaccessible environment variable\nThe query engine binary for the current platform could not be found (generator block)\nProperty\tDescription\nerrorCode\tA Prisma-specific error code.\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientValidationError​\n\nPrisma Client throws a PrismaClientValidationError exception if validation fails - for example:\n\nMissing field - for example, an empty data: {} property when creating a new record\nIncorrect field type provided (for example, setting a Boolean field to \"Hello, I like cheese and gold!\")\nProperty\tDescription\nmessage\tError message.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nError codes​\nCommon​\nP1000​\n\n\"Authentication failed against database server at {database_host}, the provided database credentials for {database_user} are not valid. Please make sure to provide valid database credentials for the database server at {database_host}.\"\n\nP1001​\n\n\"Can't reach database server at {database_host}:{database_port} Please make sure your database server is running at {database_host}:{database_port}.\"\n\nP1002​\n\n\"The database server at {database_host}:{database_port} was reached but timed out. Please try again. Please make sure your database server is running at {database_host}:{database_port}. \"\n\nP1003​\n\n\"Database {database_file_name} does not exist at {database_file_path}\"\n\n\"Database {database_name}.{database_schema_name} does not exist on the database server at {database_host}:{database_port}.\"\n\n\"Database {database_name} does not exist on the database server at {database_host}:{database_port}.\"\n\nP1008​\n\n\"Operations timed out after {time}\"\n\nP1009​\n\n\"Database {database_name} already exists on the database server at {database_host}:{database_port}\"\n\nP1010​\n\n\"User {database_user} was denied access on the database {database_name}\"\n\nP1011​\n\n\"Error opening a TLS connection: {message}\"\n\nP1012​\n\nNote: If you get error code P1012 after you upgrade Prisma ORM to version 4.0.0 or later, see the version 4.0.0 upgrade guide. A schema that was valid before version 4.0.0 might be invalid in version 4.0.0 and later. The upgrade guide explains how to update your schema to make it valid.\n\n\"{full_error}\"\n\nPossible P1012 error messages:\n\n\"Argument {} is missing.\"\n\"Function {} takes arguments, but received .\"\n\"Argument {} is missing in attribute @{}.\"\n\"Argument {} is missing in data source block {}.\"\n\"Argument {} is missing in generator block {}.\"\n\"Error parsing attribute @{}: \"\n\"Attribute @{} is defined twice.\"\n\"The model with database name {} could not be defined because another model with this name exists: {}\"\n\"{} is a reserved scalar type name and can not be used.\"\n\"The {} cannot be defined because a with that name already exists.\"\n\"Key {} is already defined in .\"\n\"Argument {} is already specified as unnamed argument.\"\n\"Argument {} is already specified.\"\n\"No such argument.\"\"\n\"Field {} is already defined on model {}.\"\n\"Field {} in model {} can't be a list. The current connector does not support lists of primitive types.\"\n\"The index name {} is declared multiple times. With the current connector index names have to be globally unique.\"\n\"Value {} is already defined on enum {}.\"\n\"Attribute not known: @{}.\"\n\"Function not known: {}.\"\n\"Datasource provider not known: {}.\"\n\"shadowDatabaseUrl is the same as url for datasource {}. Please specify a different database as shadow database.\"\n\"The preview feature {} is not known. Expected one of: \"\n\"{} is not a valid value for .\"\n\"Type {} is neither a built-in type, nor refers to another model, custom type, or enum.\"\n\"Type {} is not a built-in type.\"\n\"Unexpected token. Expected one of: \"\n\"Environment variable not found: .\"\n\"Expected a value, but received value {}.\"\n\"Expected a value, but failed while parsing {}: .\"\n\"Error validating model {}: \"\n\"Error validating field {} in model {}: \"\n\"Error validating datasource {datasource}: {message}\"\n\"Error validating enum {}: \"\n\"Error validating: \"\nP1013​\n\n\"The provided database string is invalid. {details}\"\n\nP1014​\n\n\"The underlying {kind} for model {model} does not exist.\"\n\nP1015​\n\n\"Your Prisma schema is using features that are not supported for the version of the database.\nDatabase version: {database_version}\nErrors:\n{errors}\"\n\nP1016​\n\n\"Your raw query had an incorrect number of parameters. Expected: {expected}, actual: {actual}.\"\n\nP1017​\n\n\"Server has closed the connection.\"\n\nPrisma Client (Query Engine)​\nP2000​\n\n\"The provided value for the column is too long for the column's type. Column: {column_name}\"\n\nP2001​\n\n\"The record searched for in the where condition ({model_name}.{argument_name} = {argument_value}) does not exist\"\n\nP2002​\n\n\"Unique constraint failed on the {constraint}\"\n\nP2003​\n\n\"Foreign key constraint failed on the field: {field_name}\"\n\nP2004​\n\n\"A constraint failed on the database: {database_error}\"\n\nP2005​\n\n\"The value {field_value} stored in the database for the field {field_name} is invalid for the field's type\"\n\nP2006​\n\n\"The provided value {field_value} for {model_name} field {field_name} is not valid\"\n\nP2007​\n\n\"Data validation error {database_error}\"\n\nP2008​\n\n\"Failed to parse the query {query_parsing_error} at {query_position}\"\n\nP2009​\n\n\"Failed to validate the query: {query_validation_error} at {query_position}\"\n\nP2010​\n\n\"Raw query failed. Code: {code}. Message: {message}\"\n\nP2011​\n\n\"Null constraint violation on the {constraint}\"\n\nP2012​\n\n\"Missing a required value at {path}\"\n\nP2013​\n\n\"Missing the required argument {argument_name} for field {field_name} on {object_name}.\"\n\nP2014​\n\n\"The change you are trying to make would violate the required relation '{relation_name}' between the {model_a_name} and {model_b_name} models.\"\n\nP2015​\n\n\"A related record could not be found. {details}\"\n\nP2016​\n\n\"Query interpretation error. {details}\"\n\nP2017​\n\n\"The records for relation {relation_name} between the {parent_name} and {child_name} models are not connected.\"\n\nP2018​\n\n\"The required connected records were not found. {details}\"\n\nP2019​\n\n\"Input error. {details}\"\n\nP2020​\n\n\"Value out of range for the type. {details}\"\n\nP2021​\n\n\"The table {table} does not exist in the current database.\"\n\nP2022​\n\n\"The column {column} does not exist in the current database.\"\n\nP2023​\n\n\"Inconsistent column data: {message}\"\n\nP2024​\n\n\"Timed out fetching a new connection from the connection pool. (More info: http://pris.ly/d/connection-pool\n (Current connection pool timeout: {timeout}, connection limit: {connection_limit})\"\n\nP2025​\n\n\"An operation failed because it depends on one or more records that were required but not found. {cause}\"\n\nP2026​\n\n\"The current database provider doesn't support a feature that the query used: {feature}\"\n\nP2027​\n\n\"Multiple errors occurred on the database during query execution: {errors}\"\n\nP2028​\n\n\"Transaction API error: {error}\"\n\nP2029​\n\n\"Query parameter limit exceeded error: {message}\"\n\nP2030​\n\n\"Cannot find a fulltext index to use for the search, try adding a @@fulltext([Fields...]) to your schema\"\n\nP2031​\n\n\"Prisma needs to perform transactions, which requires your MongoDB server to be run as a replica set. See details: https://pris.ly/d/mongodb-replica-set\n\"\n\nP2033​\n\n\"A number used in the query does not fit into a 64 bit signed integer. Consider using BigInt as field type if you're trying to store large integers\"\n\nP2034​\n\n\"Transaction failed due to a write conflict or a deadlock. Please retry your transaction\"\n\nP2035​\n\n\"Assertion violation on the database: {database_error}\"\n\nP2036​\n\n\"Error in external connector (id {id})\"\n\nP2037​\n\n\"Too many database connections opened: {message}\"\n\nPrisma Migrate (Schema Engine)​\nWARNING\n\nThe Schema Engine was previously called Migration Engine. This change was introduced in version 5.0.0\n.\n\nP3000​\n\n\"Failed to create database: {database_error}\"\n\nP3001​\n\n\"Migration possible with destructive changes and possible data loss: {migration_engine_destructive_details}\"\n\nP3002​\n\n\"The attempted migration was rolled back: {database_error}\"\n\nP3003​\n\n\"The format of migrations changed, the saved migrations are no longer valid. To solve this problem, please follow the steps at: https://pris.ly/d/migrate\n\"\n\nP3004​\n\n\"The {database_name} database is a system database, it should not be altered with prisma migrate. Please connect to another database.\"\n\nP3005​\n\n\"The database schema is not empty. Read more about how to baseline an existing production database: https://pris.ly/d/migrate-baseline\n\"\n\nP3006​\n\n\"Migration {migration_name} failed to apply cleanly to the shadow database.\n{error_code}Error:\n{inner_error}\"\n\nP3007​\n\n\"Some of the requested preview features are not yet allowed in schema engine. Please remove them from your data model before using migrations. (blocked: {list_of_blocked_features})\"\n\nP3008​\n\n\"The migration {migration_name} is already recorded as applied in the database.\"\n\nP3009​\n\n\"migrate found failed migrations in the target database, new migrations will not be applied. Read more about how to resolve migration issues in a production database: https://pris.ly/d/migrate-resolve\n\n{details}\"\n\nP3010​\n\n\"The name of the migration is too long. It must not be longer than 200 characters (bytes).\"\n\nP3011​\n\n\"Migration {migration_name} cannot be rolled back because it was never applied to the database. Hint: did you pass in the whole migration name? (example: \"20201207184859_initial_migration\")\"\n\nP3012​\n\n\"Migration {migration_name} cannot be rolled back because it is not in a failed state.\"\n\nP3013​\n\n\"Datasource provider arrays are no longer supported in migrate. Please change your datasource to use a single provider. Read more at https://pris.ly/multi-provider-deprecation\n\"\n\nP3014​\n\n\"Prisma Migrate could not create the shadow database. Please make sure the database user has permission to create databases. Read more about the shadow database (and workarounds) at https://pris.ly/d/migrate-shadow\n.\n\nOriginal error: {error_code}\n{inner_error}\"\n\nP3015​\n\n\"Could not find the migration file at {migration_file_path}. Please delete the directory or restore the migration file.\"\n\nP3016​\n\n\"The fallback method for database resets failed, meaning Migrate could not clean up the database entirely. Original error: {error_code}\n{inner_error}\"\n\nP3017​\n\n\"The migration {migration_name} could not be found. Please make sure that the migration exists, and that you included the whole name of the directory. (example: \"20201207184859_initial_migration\")\"\n\nP3018​\n\n\"A migration failed to apply. New migrations cannot be applied before the error is recovered from. Read more about how to resolve migration issues in a production database: https://pris.ly/d/migrate-resolve\n\n\nMigration name: {migration_name}\n\nDatabase error code: {database_error_code}\n\nDatabase error:\n{database_error} \"\n\nP3019​\n\n\"The datasource provider {provider} specified in your schema does not match the one specified in the migration_lock.toml, {expected_provider}. Please remove your current migration directory and start a new migration history with prisma migrate dev. Read more: https://pris.ly/d/migrate-provider-switch\n\"\n\nP3020​\n\n\"The automatic creation of shadow databases is disabled on Azure SQL. Please set up a shadow database using the shadowDatabaseUrl datasource attribute.\nRead the docs page for more details: https://pris.ly/d/migrate-shadow\n\"\n\nP3021​\n\n\"Foreign keys cannot be created on this database. Learn more how to handle this: https://pris.ly/d/migrate-no-foreign-keys\n\"\n\nP3022​\n\n\"Direct execution of DDL (Data Definition Language) SQL statements is disabled on this database. Please read more here about how to handle this: https://pris.ly/d/migrate-no-direct-ddl\n\"\n\nP3023​\n\n\"For the current database, externalTables & externalEnums in your prisma config must contain only fully qualified identifiers (e.g. schema_name.table_name).\"\n\nP3024​\n\n\"For the current database, externalTables & externalEnums in your prisma config must contain only simple identifiers without a schema name.\"\n\nprisma db pull​\nP4000​\n\n\"Introspection operation failed to produce a schema file: {introspection_error}\"\n\nP4001​\n\n\"The introspected database was empty.\"\n\nP4002​\n\n\"The schema of the introspected database was inconsistent: {explanation}\"\n\nPrisma Accelerate​\n\nPrisma Accelerate-related errors start with P6xxx except for P5011.\n\nP6000 (ServerError)​\n\nGeneric error to catch all other errors.\n\nP6001 (InvalidDataSource)​\n\nThe URL is malformed; for instance, it does not use the prisma:// protocol.\n\nP6002 (Unauthorized)​\n\nThe API Key in the connection string is invalid.\n\nP6003 (PlanLimitReached)​\n\nThe included usage of the current plan has been exceeded. This can only occur on the free plan.\n\nP6004 (QueryTimeout)​\n\nThe global timeout of Accelerate has been exceeded. You can find the limit here.\n\nAlso see the troubleshooting guide for more information.\n\nP6005 (InvalidParameters)​\n\nThe user supplied invalid parameters. Currently only relevant for transaction methods. For example, setting a timeout that is too high. You can find the limit here.\n\nP6006 (VersionNotSupported)​\n\nThe chosen Prisma version is not compatible with Accelerate. This may occur when a user uses an unstable development version that we occasionally prune.\n\nP6008 (ConnectionError|EngineStartError)​\n\nThe engine failed to start. For example, it couldn't establish a connection to the database.\n\nAlso see the troubleshooting guide for more information.\n\nP6009 (ResponseSizeLimitExceeded)​\n\nThe global response size limit of Accelerate has been exceeded. You can find the limit here.\n\nAlso see the troubleshooting guide for more information.\n\nP6010 (ProjectDisabledError)​\n\nYour accelerate project is disabled. Please enable it again to use it.\n\nP5011 (Too Many Requests)​\n\nThis error indicates that the request volume exceeded. Implement a back-off strategy and try again later. For assistance with expected high workloads, contact support."
  },
  {
    "title": "Prisma environment variables | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/environment-variables-reference",
    "html": "ORMReference\nEnvironment variables reference\n\nThis document describes different environment variables and their use cases.\n\nPrisma Client​\nDEBUG​\n\nDEBUG is used to enable debugging output in Prisma Client.\n\nExample setting Prisma Client level debugging output:\n\n# enable only `prisma:client`-level debugging output\n\nexport DEBUG=\"prisma:client\"\n\n\nSee Debugging for more information.\n\nNO_COLOR​\n\nNO_COLOR if truthy\n will activate the colorless setting for error formatting and strip colors from error messages.\n\nSee Formatting via environment variables for more information.\n\nPrisma Studio​\nBROWSER​\n\nBROWSER is for Prisma Studio to force which browser it should be open in, if not set it will open in the default browser.\n\nBROWSER=firefox prisma studio --port 5555\n\n\nAlternatively you can set this when starting Studio from the CLI as well:\n\nprisma studio --browser firefox\n\n\nSee Studio documentation for more information.\n\nPrisma CLI​\nPRISMA_HIDE_PREVIEW_FLAG_WARNINGS​\n\nPRISMA_HIDE_PREVIEW_FLAG_WARNINGS hides the warning message that states that a preview feature flag can be removed. It is a truthy value.\n\nPRISMA_HIDE_UPDATE_MESSAGE​\n\nPRISMA_HIDE_UPDATE_MESSAGE is used to hide the update notification message that is shown when a newer Prisma CLI version is available. It's a truthy value.\n\nPRISMA_GENERATE_SKIP_AUTOINSTALL​\n\nPRISMA_GENERATE_SKIP_AUTOINSTALL can be set to a truthy value to skip the auto-install of prisma CLI and @prisma/client dependencies (if they are missing), if the prisma-client-js generator is defined in the Prisma Schema, when using the prisma generate command.\n\nPRISMA_SKIP_POSTINSTALL_GENERATE​\n\nPRISMA_SKIP_POSTINSTALL_GENERATE can be set to a truthy value to skip the auto-generation of Prisma Client when its postinstall hook is triggered by a package manager. The postinstall hook of the @prisma/client package is triggered when the package is installed, or its version is updated.\n\nPRISMA_DISABLE_WARNINGS​\n\nDisables all CLI warnings generated by logger.warn.\n\nPRISMA_GENERATE_NO_ENGINE​\nINFO\n\nThis environment variable is available since version 5.2.0\n\nPRISMA_GENERATE_NO_ENGINE can be set to a truthy value to generate a Prisma Client without an included query engine in order to reduce deployed application size when paired with Prisma Accelerate.\n\nPRISMA_SCHEMA_DISABLE_ADVISORY_LOCK​\nINFO\n\nThis environment variable is available since version 5.3.0\n\nPRISMA_SCHEMA_DISABLE_ADVISORY_LOCK can be set to a truthy value to disable the advisory locking used by Prisma Migrate. This might be needed, depending on the database configuration, for example, for a Percona-XtraDB-Cluster or MariaDB Galera Cluster.\n\nProxy environment variables​\n\nThe Prisma CLI supports custom HTTP(S) proxies to download the Prisma engines. These can be helpful to use when working behind a corporate firewall. See Using a HTTP proxy for the CLI for more information.\n\nNO_PROXY​\n\nNO_PROXY is a comma-separated list of hostnames or IP addresses that do not require a proxy.\n\nNO_PROXY=myhostname.com,10.11.12.0/16,172.30.0.0/16\n\nHTTP_PROXY​\n\nHTTP_PROXY is set with the hostname or IP address of a proxy server.\n\nHTTP_PROXY=http://proxy.example.com\n\nHTTPS_PROXY​\n\nHTTPS_PROXY is set with the hostname or IP address of a proxy server.\n\nHTTPS_PROXY=https://proxy.example.com\n\nEngine environment variables​\nConfiguring Query Engine Type​\nPRISMA_CLI_QUERY_ENGINE_TYPE​\n\nPRISMA_CLI_QUERY_ENGINE_TYPE is used to define the query engine type Prisma CLI downloads and uses. Defaults to library, but can be set to binary:\n\nPRISMA_CLI_QUERY_ENGINE_TYPE=binary\n\nPRISMA_CLIENT_ENGINE_TYPE​\n\nPRISMA_CLIENT_ENGINE_TYPE is used to define the query engine type Prisma Client downloads and uses. Defaults to library, but can be set to binary:\n\nPRISMA_CLIENT_ENGINE_TYPE=binary\n\n\nNote: You need to generate your Prisma Client after setting this variable for the configuration to take effect and the libraries to be downloaded. Otherwise, Prisma Client will be missing the appropriate query engine library and you will have to define their location using PRISMA_QUERY_ENGINE_LIBRARY.\n\nIt is the environment variable equivalent for the engineType property of the generator block which enables you to define the same setting in your Prisma Schema.\n\nDownloading Engines​\nPRISMA_ENGINES_MIRROR​\n\nPRISMA_ENGINES_MIRROR can be used to specify a custom CDN (or server) endpoint to download the engines files for the CLI/Client. The default value is https://binaries.prisma.sh, where Prisma hosts the engine files.\n\nPRISMA_ENGINES_MIRROR=https://example.org/custom-engines/\n\n\nSee Prisma engines for a conceptual overview of how to use this environment variable.\n\nNote: This environment variable used to be available as PRISMA_BINARIES_MIRROR, which was deprecated in Prisma ORM 3.0.1. It is discouraged to use anymore and will be removed in the future.\n\nPRISMA_ENGINES_CHECKSUM_IGNORE_MISSING​\nINFO\n\nThis environment variable is available since version 4.16.0\n\nPRISMA_ENGINES_CHECKSUM_IGNORE_MISSING can be can be set to a truthy value to ignore problems around downloading & verifying the integrity (via a checksum file) of the Prisma ORM engines. This is particularly useful when deploying to an offline system environment where the checksum file cannot be downloaded.\n\nPRISMA_ENGINES_CHECKSUM_IGNORE_MISSING=1\n\n\nNote: we might change the overall download behavior in a future release in a way that this environment variable will not be needed anymore in a offline environment case.\n\nCustom engine file locations​\n\nBy default, all engine files are downloaded when you install Prisma CLI, copied when generating Prisma Client, and put into known locations. There are however situations where you may want to use a custom engine file from custom locations:\n\nPRISMA_QUERY_ENGINE_BINARY​\n\nPRISMA_QUERY_ENGINE_BINARY is used to set a custom location for your own query engine binary.\n\nPRISMA_QUERY_ENGINE_BINARY=custom/query-engine-<target>\n\n# Example: ./prisma/binaries/query-engine-linux-arm64-openssl-1.0.x\n\n\nFor Prisma CLI it allows you to define the query engine file to be used.\nFor Prisma Client, on build time (during prisma generate), it defines where the query engine file will be copied from into Prisma Client. At run time (when using the generated Client) it can be used to define the specific query engine file to be used instead of the included one.\n\nNote: This can only have an effect if the engine type of CLI or Client are set to binary. If the engine type is library (the default), use PRISMA_QUERY_ENGINE_LIBARY instead.\n\nPRISMA_QUERY_ENGINE_LIBRARY​\n\nPRISMA_QUERY_ENGINE_LIBRARY is used to set a custom location for your own query engine library.\n\nPRISMA_QUERY_ENGINE_LIBRARY=custom/libquery_engine-<target>.so.node\n\n# Example: ./prisma/binaries/libquery_engine-linux-arm64-openssl-1.0.x.so.node\n\n\nFor Prisma CLI it allows you to define the query engine file to be used.\nFor Prisma Client, on build time (during prisma generate), it defines where the query engine file will be copied from into Prisma Client. At run time (when using the generated Client) it can be used to define the specific query engine file to be used instead of the included one.\n\nNote: This can only have an effect if the engine type of CLI or Client are set to library (the default)\n\nPRISMA_SCHEMA_ENGINE_BINARY​\n\nPRISMA_SCHEMA_ENGINE_BINARY is used to set a custom location for your Schema engine binary.\n\nPRISMA_SCHEMA_ENGINE_BINARY=custom/my-schema-engine-unix\n\nPRISMA_MIGRATION_ENGINE_BINARY​\nWARNING\n\nDeprecated: PRISMA_MIGRATION_ENGINE_BINARY variable is deprecated in 5.0.0\n because Migration engine was renamed to Schema Engine.\n\nPRISMA_MIGRATION_ENGINE_BINARY is used to set a custom location for your own migration engine binary.\n\nPRISMA_MIGRATION_ENGINE_BINARY=custom/my-migration-engine-unix\n\nPRISMA_INTROSPECTION_ENGINE_BINARY​\n\nPRISMA_INTROSPECTION_ENGINE_BINARY is used to set a custom location for your own introspection engine binary.\n\nPRISMA_INTROSPECTION_ENGINE_BINARY=custom/my-introspection-engine-unix\n\nWARNING\n\nThe Introspection Engine is served by the Migration Engine from 4.9.0\n. Therefore, the PRISMA_INTROSPECTION_ENGINE environment variable will not be used.\n\nPRISMA_FMT_BINARY​\nDANGER\n\nThis functionality has been removed in Prisma CLI version 4.10.0. It only works in earlier versions.\n\nPRISMA_FMT_BINARY is used to set a custom location for your own format engine binary.\n\nPRISMA_FMT_BINARY=custom/my-custom-format-engine-unix\n\nWARNING\n\nThe PRISMA_FMT_BINARY variable is used in versions 4.2.0\n or lower.\n\nCLI Binary Targets​\nPRISMA_CLI_BINARY_TARGETS​\n\nPRISMA_CLI_BINARY_TARGETS can be used to specify one or more binary targets that Prisma CLI will download during installation (so it must be provided during npm install of Prisma CLI and does not affect runtime of Prisma CLI or Prisma Client).\n\nUse PRISMA_CLI_BINARY_TARGETS if you 1) deploy to a specific platform via an upload of a local project that includes dependencies, and 2) your local environment is different from the target (e.g. AWS Lambda with Node.js 20+ is rhel-openssl-3.0.x, and your local environment might be macOS arm64 darwin-arm64). Using the PRISMA_CLI_BINARY_TARGETS environment variable ensures that the target engine files are also downloaded.\n\nPRISMA_CLI_BINARY_TARGETS=darwin-arm64,rhel-openssl-3.0.x npm install\n\n\nThis is the Prisma CLI equivalent for the binaryTargets property of the generator block, which enables you to define the same setting for Prisma Client.\n\nNote: For Node.js versions earlier than 20, the openssl version was 1.0.x instead of 3.0.x. This is most obvious in AWS Lambda deployments, where the binary target would be rhel-openssl-1.0.x instead of rhel-openssl-3.0.x."
  },
  {
    "title": "Reference documentation for the prisma config file | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-config-reference",
    "html": "ORMReference\nPrisma Config reference\nOverview​\n\nThe Prisma Config file configures the Prisma CLI, including subcommands like migrate and studio, using TypeScript.\n\nYou can define your config in either of two ways:\n\nUsing the defineConfig helper:\n\nimport path from \"node:path\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n  migrations: { \n\n    path: path.join(\"db\", \"migrations\"),\n\n  },\n\n  views: { \n\n    path: path.join(\"db\", \"views\"),\n\n  },\n\n  typedSql: { \n\n  path: path.join(\"db\", \"queries\"),\n\n  },\n\n  engine: \"classic\",\n\n  datasource: { \n\n    url: env(\"DATABASE_URL\") \n\n  }\n\n});\n\n\nUsing TypeScript's satisfies operator with the PrismaConfig type:\n\nimport path from \"node:path\";\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {\n\n  schema: path.join(\"db\", \"schema.prisma\"),\n\n  migrations: {\n\n    path: path.join(\"db\", \"migrations\"),\n\n  },\n\n  views: {\n\n    path: path.join(\"db\", \"views\"),\n\n  },\n\n  typedSql: {\n\n    path: path.join(\"db\", \"queries\"),\n\n  },\n\n  engine: \"classic\",\n\n  datasource: { \n\n    url: env(\"DATABASE_URL\") \n\n  }\n\n} satisfies PrismaConfig;\n\nConfiguration interface​\n\nHere is a simplified version of the PrismaConfig type:\n\nexport declare type PrismaConfig = {\n\n\n\n  // Whether features with an unstable API are enabled.\n\n  experimental: {\n\n    adapter: boolean;\n\n    externalTables: boolean;\n\n    studio: boolean;\n\n  },\n\n\n\n  // The path to the schema file, or path to a folder that shall be recursively searched for *.prisma files.\n\n  schema?: string;\n\n\n\n  // The Driver Adapter used for Prisma CLI.\n\n  adapter?: () => Promise<SqlMigrationAwareDriverAdapterFactory>;\n\n\n\n  // Configuration for Prisma Studio.\n\n  studio?: {\n\n    adapter: () => Promise<SqlMigrationAwareDriverAdapterFactory>;\n\n  };\n\n\n\n  // Configuration for Prisma migrations.\n\n  migrations?: {\n\n    path: string;\n\n    seed: string;\n\n    initShadowDb: string;\n\n  };\n\n\n\n  // Configuration for the database view entities.\n\n  views?: {\n\n    path: string;\n\n  };\n\n\n\n  // Configuration for the `typedSql` preview feature.\n\n  typedSql?: {\n\n    path: string;\n\n  };\n\n  // Depending on the choice, you must provide either a `datasource` object or driver adapter\n\n  engine: 'classic' | 'js'\n\n  \n\n  // If using the classic engine, datasource sets the database url, shadowDatabaseUrl, or directURL\n\n  datasource?: {\n\n    url: string;\n\n    directUrl?: string;\n\n    shadowDatabaseUrl?: string;\n\n  }\n\n  \n\n};\n\nSupported file extensions​\n\nPrisma Config files can be named as prisma.config.* or .config/prisma.* with the extensions js, ts, mjs, cjs, mts, or cts. Other extensions are supported to ensure compatibility with different TypeScript compiler settings.\n\nRECOMMENDATION\nUse prisma.config.ts for small TypeScript projects.\nUse .config/prisma.ts for larger TypeScript projects with multiple configuration files (following the \n.config\ndirectory proposal\n).\nOptions reference​\nschema​\n\nConfigures how Prisma ORM locates and loads your schema file(s). Can be a file or folder path. Relative paths are resolved relative to the prisma.config.ts file location. See here for more info about schema location options.\n\nProperty\tType\tRequired\tDefault\nschema\tstring\tNo\t./prisma/schema.prisma and ./schema.prisma\nadapter​\n\nA function that returns a Prisma driver adapter instance which is used by the Prisma CLI to run migrations. The function should return a Promise that resolves to a valid Prisma driver adapter.\n\nProperty\tType\tRequired\tDefault\nadapter\t() => Promise<SqlMigrationAwareDriverAdapterFactory>\tNo\tnone\n\nExample using the Prisma ORM D1 driver adapter:\n\nimport path from \"node:path\";\n\nimport type { PrismaConfig } from \"prisma\";\n\nimport { PrismaD1 } from \"@prisma/adapter-d1\";\n\n\n\nexport default {\n\n  experimental: {\n\n    adapter: true\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n  async adapter() {\n\n    return new PrismaD1({\n\n      CLOUDFLARE_D1_TOKEN: process.env.CLOUDFLARE_D1_TOKEN,\n\n      CLOUDFLARE_ACCOUNT_ID: process.env.CLOUDFLARE_ACCOUNT_ID,\n\n      CLOUDFLARE_DATABASE_ID: process.env.CLOUDFLARE_DATABASE_ID,\n\n    });\n\n  },\n\n} satisfies PrismaConfig;\n\nNOTE\n\nAs of Prisma ORM v6.11.0\n, the D1 adapter has been renamed from PrismaD1HTTP to PrismaD1.\n\nstudio​\n\nConfigures how Prisma Studio connects to your database. See sub-options below for details.\n\nProperty\tType\tRequired\tDefault\nstudio\tobject\tNo\tnone\nstudio.adapter​\n\nA function that returns a Prisma driver adapter instance. The function receives an env parameter containing environment variables and should return a Promise that resolves to a valid Prisma driver adapter.\n\nProperty\tType\tRequired\tDefault\nstudio.adapter\t(env: Env) => Promise<SqlMigrationAwareDriverAdapterFactory>\tNo\tnone\n\nExample using the Prisma ORM LibSQL driver adapter:\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {\n\n  experimental: {\n\n    studio: true\n\n  },\n\n  studio: {\n\n    adapter: async (env: Env) => {\n\n      const { PrismaLibSQL } = await import(\"@prisma/adapter-libsql\");\n\n      const { createClient } = await import(\"@libsql/client\");\n\n\n\n      const libsql = createClient({\n\n        url: env.DOTENV_PRISMA_STUDIO_LIBSQL_DATABASE_URL,\n\n      });\n\n      return new PrismaLibSQL(libsql);\n\n    },\n\n  },\n\n} satisfies PrismaConfig;\n\ntables.external and enums.external​\n\nThese options declare tables and enums in your database that are managed externally (not by Prisma Migrate). You can still query them with Prisma Client, but they will be ignored by migrations.\n\nProperty\tType\tRequired\tDefault\ntables.external\tstring[]\tNo\t[]\nenums.external\tstring[]\tNo\t[]\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  experimental: {\n\n    externalTables: true,\n\n  },\n\n  tables: {\n\n    external: [\"public.users\"],\n\n  },\n\n  enums: {\n\n    external: [\"public.role\"],\n\n  },\n\n});\n\n\nLearn more about the externalTables feature here.\n\nmigrations.path​\n\nThe path to the directory where Prisma should store migration files, and look for them.\n\nProperty\tType\tRequired\tDefault\nmigrations.path\tstring\tNo\tnone\nmigrations.seed​\n\nThis option allows you to define a script that Prisma runs to seed your database after running migrations or using the npx prisma db seed command. The string should be a command that can be executed in your terminal, such as with node, ts-node, or tsx.\n\nProperty\tType\tRequired\tDefault\nmigrations.seed\tstring\tNo\tnone\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  migrations: {\n\n    seed: `tsx db/seed.ts`,\n\n  },\n\n});\n\nmigrations.initShadowDb​\n\nThis option allows you to define SQL statements that Prisma runs on the shadow database before creating migrations. It is useful when working with external managed tables, as Prisma needs to know about the structure of these tables to correctly generate migrations.\n\nProperty\tType\tRequired\tDefault\nmigrations.initShadowDb\tstring\tNo\tnone\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  experimental: {\n\n    externalTables: true,\n\n  },\n\n  tables: {\n\n    external: [\"public.users\"],\n\n  },\n\n  migrations: {\n\n    initShadowDb: `\n\n      CREATE TABLE public.users (id SERIAL PRIMARY KEY);\n\n    `,\n\n  },\n\n});\n\n\nLearn more about the externalTables feature here.\n\nviews.path​\n\nThe path to the directory where Prisma should look for the SQL view definitions.\n\nProperty\tType\tRequired\tDefault\nviews.path\tstring\tNo\tnone\ntypedSql.path​\n\nThe path to the directory where Prisma should look for the SQL files used for generating typings via typedSql.\n\nProperty\tType\tRequired\tDefault\ntypedSql.path\tstring\tNo\tnone\nexperimental​\n\nEnables specific experimental features in the Prisma CLI.\n\nProperty\tType\tRequired\tDefault\nadapter\tboolean\tNo\tfalse\nexternalTables\tboolean\tNo\tfalse\nstudio\tboolean\tNo\tfalse\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  experimental: {\n\n    adapter: true,\n\n    externalTables: true,\n\n    studio: true,\n\n  },\n\n  schema: \"prisma/schema.prisma\",\n\n});\n\nNOTE\n\nIf you use features like adapter, studio or externalTables without enabling the corresponding experimental flag, Prisma will throw an error:\n\nFailed to load config file \"~\" as a TypeScript/JavaScript module. Error: Error: The `studio` configuration requires `experimental.studio` to be set to `true`.\n\nengine​\n\nConfigure the schema engine your project should use.\n\nProperty\tType\tRequired\tDefault\nengine\tclassic or js\tNo\tclassic\n\nBy default it is set to use the classic engine, which requires that datasource be set in your prisma.config.ts.\n\nimport path from \"node:path\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\nexport default defineConfig({\n\n  engine: \"classic\",\n\n  datasource: {\n\n      url: env('DATABASE_URL'),\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n});\n\ndatasource.url​\n\nConnection URL including authentication info. Most connectors use the syntax provided by the database.\n\nProperty\tType\tRequired\tDefault\ndatasource.url\tstring\tYes\t''\ndatasource.shadowDatabaseUrl​\n\nConnection URL to the shadow database used by Prisma Migrate. Allows you to use a cloud-hosted database as the shadow database\n\nProperty\tType\tRequired\tDefault\ndatasource.shadowDatabaseUrl\tstring\tNo\t''\ndatasource.directUrl​\n\nConnection URL for direct connection to the database.\n\nIf you use a connection pooler URL in the url argument (for example, if you use Prisma Accelerate or pgBouncer), Prisma CLI commands that require a direct connection to the database use the URL in the directUrl argument.\n\nThe directUrl property is supported by Prisma Studio from version 5.1.0 upwards.\n\nThe directUrl property is not needed when using Prisma Postgres database.\n\nProperty\tType\tRequired\tDefault\ndatasource.directUrl\tstring\tNo\t''\nCommon patterns​\nSetting up your project​\n\nTo get started with Prisma Config, create a prisma.config.ts file in your project root. You can use either of these approaches:\n\nUsing defineConfig:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({});\n\n\nUsing TypeScript types:\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {} satisfies PrismaConfig;\n\nUsing environment variables​\n\nWhen using prisma.config.ts, environment variables from .env files are not automatically loaded. Using tsx, you can pass a --env-file flag and that will automatically add those values to process.env\n\nIf using Node or Deno:\n\ntsx --env-file=.env src/index.ts\n\ntsx watch --env-file=.env --env-file=.local.env src/index.ts\n\ntsx --env-file=.env ./prisma/seed.ts\n\n\nFor Bun, .env files are automatically loaded.\n\nFor accessing environment variables within prisma.config.ts, use the env() helper function to provide a type-safe way of accessing that variable:\n\nimport path from \"node:path\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\n\n\ntype Env = {\n\n  DATABASE_URL: string\n\n}\n\nexport default defineConfig({\n\n  engine: \"classic\",\n\n  datasource: {\n\n      url: env<Env>('DATABASE_URL'),\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n});\n\n\nFor releases of Node before v20, you'll need to:\n\nInstall the dotenv package:\nnpm install dotenv\n\nImport dotenv/config in your config file:\nimport \"dotenv/config\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\n\n\ntype Env = {\n\n  DATABASE_URL: string\n\n}\n\nexport default defineConfig({\n\n  engine: \"classic\",\n\n  datasource: {\n\n      url: env<Env>('DATABASE_URL'),\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n});\n\nUsing multi-file schemas​\n\nIf you want to split your Prisma schema into multiple files, you need to specify the path to your Prisma schema folder via the schema property:\n\nimport path from \"node:path\";\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {\n\n  schema: path.join(\"prisma\", \"schema\"),\n\n} satisfies PrismaConfig;\n\n\nIn that case, your migrations directory must be located next to the .prisma file that defines the datasource block.\n\nFor example, assuming schema.prisma defines the datasource, here's how how need to place the migrations folder:\n\n# `migrations` and `schema.prisma` are on the same level\n\n.\n\n├── migrations\n\n├── models\n\n│   ├── posts.prisma\n\n│   └── users.prisma\n\n└── schema.prisma\n\nPath resolution​\n\nPrisma CLI commands such as prisma validate or prisma migrate use prisma.config.ts (or .config/prisma.ts) to locate your Prisma schema and other resources.\n\nKey rules:\n\nPaths defined in the config file (e.g., schema, migrations) are always resolved relative to the location of the config file, not where you run the CLI command from.\nThe CLI must first find the config file itself, which depends on how Prisma is installed and the package manager used.\nBehavior with pnpm prisma​\n\nWhen Prisma is installed locally and run via pnpm prisma, the config file is detected automatically whether you run the command from the project root or a subdirectory.\n\nExample project tree:\n\n.\n\n├── node_modules\n\n├── package.json\n\n├── prisma-custom\n\n│   └── schema.prisma\n\n├── prisma.config.ts\n\n└── src\n\n\nExample run from the project root:\n\npnpm prisma validate\n\n# → Loaded Prisma config from ./prisma.config.ts\n\n# → Prisma schema loaded from prisma-custom/schema.prisma\n\n\nExample run from a subdirectory:\n\ncd src\n\npnpm prisma validate\n\n# → Still finds prisma.config.ts and resolves schema correctly\n\nBehavior with npm exec prisma or bun prisma​\n\nWhen running via npm exec prisma or bun prisma, the CLI only detects the config file if the command is run from the project root (where package.json declares Prisma).\n\nExample run from the project root:\n\nnpm exec prisma validate\n\n# → Works as expected\n\n\nRun from a subdirectory (fails):\n\ncd src\n\nnpm exec prisma validate\n\n# → Error: Could not find Prisma Schema...\n\n\nTo fix this, you can use the --config flag:\n\nnpm exec prisma -- --config ../prisma.config.ts validate\n\nGlobal Prisma installations​\n\nIf Prisma is installed globally (npm i -g prisma), it may not find your prisma.config.ts or prisma/config module by default. To avoid issues:\n\nPrefer local Prisma installations in your project.\nOr use prisma/config locally and pass --config to point to your config file.\nMonorepos​\nIf Prisma is installed in the workspace root, pnpm prisma will detect the config file from subdirectories.\nIf Prisma is installed in a subpackage (e.g., ./packages/db), run commands from that package directory or deeper.\nCustom config location​\n\nYou can specify a custom location for your config file when running Prisma CLI commands:\n\nprisma validate --config ./path/to/myconfig.ts\n"
  },
  {
    "title": "Database features matrix | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/database-features",
    "html": "ORMReference\nDatabase features matrix\n\nThis page gives an overview of the features which are provided by the databases that Prisma ORM supports. Additionally, it explains how each of these features can be used in Prisma ORM with pointers to further documentation.\n\nRelational database features​\n\nThis section describes which database features exist on the relational databases that are currently supported by Prisma ORM. The Prisma schema column indicates how a certain feature can be represented in the Prisma schema and links to its documentation. Note that database features can be used in Prisma Client even though they might not yet be representable in the Prisma schema.\n\nNOTE\n\nThese features are only for relational databases. Supported features for NoSQL databases, like MongoDB, can be found below.\n\nConstraints​\nConstraint\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nPRIMARY KEY\t✔️\t@id and @@id\t✔️\t✔️\nFOREIGN KEY\t✔️\tRelation fields\t✔️\t✔️\nUNIQUE\t✔️*\t@unique and @@unique\t✔️\t✔️\nCHECK\t✔️†\tNot yet\t✔️\tNot yet\nNOT NULL\t✔️\t?\t✔️\t✔️\nDEFAULT\t✔️\t@default\t✔️\t✔️\nEXCLUDE\t✔️‡\tNot yet\t✔️\tNot yet\n\n* Caveats apply when using the UNIQUE constraint with Microsoft SQL Server † Only supported in MySQL in version 8 and higher\n. ‡ Only supported in PostgreSQL.\n\nReferential Actions (Delete and Update behaviors for foreign key references)​\nDeletion behavior\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nCASCADE\t✔️\t✔️\t✔️\t✔️\nRESTRICT\t✔️*\t✔️\t✔️\t✔️\nNO ACTION\t✔️\t✔️\t✔️\t✔️\nSET DEFAULT\t✔️\t✔️\t✔️\t✔️\nSET NULL\t✔️\t✔️\t✔️\t✔️\n\n* RESTRICT is not supported in Microsoft SQL Server.\n\nIndexes​\nIndex\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nUNIQUE\t✔️\t@unique and @@unique\t✔️\t✔️\nUSING\tPostgreSQL only\ttype\t✔️\t✔️\nWHERE\t✔️\tNot yet\t✔️\tNot yet\n(expression)\t✔️\tNot yet\t✔️\tNot yet\nINCLUDE\tPostgreSQL and Microsoft SQL Server only\tNot yet\t✔️\tNot yet\n\nAlgorithm specified via USING:\n\nIndex type (Algorithm)\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nB-tree\t✔️\t✔️†\t✔️\tNot yet\nHash\t✔️\t✔️†\t✔️\tNot yet\nGiST\t✔️*\t✔️†\t✔️*\tNot yet\nGIN\t✔️*\t✔️†\t✔️*\tNot yet\nBRIN\t✔️*\t✔️†\t✔️*\tNot yet\nSP-GiST\t✔️*\t✔️†\t✔️*\tNot yet\n* Not supported for MySQL and SQLite\n† Available with the PostgreSQL connector only in Prisma ORM versions 4.0.0 and later.\nMisc​\nFeature\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nAutoincrementing IDs\t✔️\tautoincrement()\t✔️\t✔️\nArrays\tPostgreSQL only\t[]\t✔️\t✔️\nEnums\t✔️*†\tenum\t✔️\t✔️\nNative database types\t✔️\t✔️\t✔️\tNot yet\nSQL Views\t✔️\tNot yet\tNot yet\tNot yet\nJSON support\t✔️†\t✔️\t✔️\t✔️\nFuzzy/Phrase full text search\t✔️‡\tNot yet\tNot yet\tNot yet\nTable inheritance\tPostgreSQL and Microsoft SQL Server only\tNot yet\t✔️\tNot yet\nAuthorization and user management\t✔️‡\tNot yet\tNot yet\tNot yet\n* Not supported by Microsoft SQL Server\n† JSON and Enum types are supported in SQLite as of Prisma ORM 6.2.0.\n‡ Not supported by SQLite\nNoSQL database features​\n\nThis section describes which database features exist on the NoSQL databases that are currently supported by Prisma ORM.\n\nMongoDB​\n\nThe following table lists common MongoDB features and describes the level of support offered by Prisma ORM:\n\nFeature\tSupported by Prisma ORM\tNotes\nEmbedded documents\t✔️\t\nTransactions\t✔️\t\nIndexes\t✔️ with caveats\tIndexes can only be introspected if the field they refer to includes at least some data.\nAutoincrementing IDs\tNo\t\nCompound IDs\tNo\tMongoDB does not support composite IDs (@@id)\nGenerated ObjectId\t✔️\tSee: Defining IDs for MongoDB\nArrays\t✔️\t\nEnums\t✔️\tImplemented at Prisma ORM level\nNative database types\t✔️\tSee: Field mapping reference\nJSON support\t✔️\tAdvanced Json field filtering is not yet supported.\nDBrefs\tNo\t\nChange streams\tNo\t\nDirect access to the aggregation pipeline\tNo\t"
  },
  {
    "title": "Databases supported by Prisma ORM | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/supported-databases",
    "html": "ORMReference\nSupported databases\n\nPrisma ORM currently supports the following databases.\n\nSee also: System requirements.\n\nAn asterisk (*) indicates that the version number is not relevant; either all versions are supported, there is not a public version number, etc.\n\nSelf-hosted databases​\nDatabase\tVersion\nCockroachDB\t21.2.4+\nMariaDB\t10.0+\nMariaDB\t11.0+\nMicrosoft SQL Server\t2017\nMicrosoft SQL Server\t2019\nMicrosoft SQL Server\t2022\nMongoDB\t4.2+\nMySQL\t5.6\nMySQL\t5.7\nMySQL\t8.0\nMySQL\t8.4\nPostgreSQL\t9.6\nPostgreSQL\t10\nPostgreSQL\t11\nPostgreSQL\t12\nPostgreSQL\t13\nPostgreSQL\t14\nPostgreSQL\t15\nPostgreSQL\t16\nPostgreSQL\t17\nSQLite\t*\n\nNote that a fixed version of SQLite is shipped with every Prisma ORM release.\n\nManaged databases​\nDatabase\tVersion\nAWS Aurora\t*\nAWS Aurora Serverless ¹\t*\nAzure SQL\t*\nCockroachDB-as-a-Service\t*\nMongoDB Atlas\t*\nNeon Serverless Postgres\t*\nPlanetScale\t*\nCloudflare D1 (Preview)\t*\nAiven (MySQL & Postgres)\t*\n¹ This does not include support for Data API for Aurora Serverless\n.\t"
  },
  {
    "title": "Connection URLs (Reference) | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/connection-urls",
    "html": "ORMReference\nConnection URLs\n\nPrisma ORM needs a connection URL to be able to connect to your database, e.g. when sending queries with Prisma Client or when changing the database schema with Prisma Migrate.\n\nThe connection URL is provided via the url field of a datasource block in your Prisma schema. It usually consists of the following components (except for SQLite and Prisma Postgres):\n\nUser: The name of your database user\nPassword: The password for your database user\nHost: The IP or domain name of the machine where your database server is running\nPort: The port on which your database server is running\nDatabase name: The name of the database you want to use\n\nMake sure you have this information at hand when getting started with Prisma ORM. If you don't have a database server running yet, you can either use a local SQLite database file (see the Quickstart) or setup a free PostgreSQL database with Prisma Postgres.\n\nFormat​\n\nThe format of the connection URL depends on the database connector you're using. Prisma ORM generally supports the standard formats for each database. You can find out more about the connection URL of your database on the dedicated docs page:\n\nPostgreSQL\nMySQL\nSQLite\nMongoDB\nMicrosoft SQL Server\nCockroachDB\nSpecial characters​\n\nFor MySQL, PostgreSQL and CockroachDB you must percentage-encode special characters\n in any part of your connection URL - including passwords. For example, p@$$w0rd becomes p%40%24%24w0rd.\n\nFor Microsoft SQL Server, you must escape special characters in any part of your connection string.\n\nExamples​\n\nHere are examples for the connection URLs of the databases Prisma ORM supports:\n\nPrisma Postgres​\n\nPrisma Postgres is a managed PostgreSQL service running on unikernels. There are several ways to connect to Prisma Postgres:\n\nvia direct TCP connections (lets you connect via any ORM or database tool)\nvia Prisma Accelerate (only supported with Prisma ORM)\nlocally\n\nThe connection string formats of these are covered below.\n\nDirect TCP​\n\nWhen you connect to Prisma Postgres via direct TCP, your connection string looks as follows:\n\nDATABASE_URL=\"postgres://USER:PASSWORD@db.prisma.io:5432/?sslmode=require\"\n\n\nThe USER and PASSWORD values are provided when you generate credentials for your Prisma Postgres instance in the Prisma Console. Here is an example with sample values:\n\nDATABASE_URL=\"postgres://2f9881cc7eef46f094ac913df34c1fb441502fe66cbe28cc48998d4e6b20336b:sk_QZ3u8fMPFfBzOID4ol-mV@db.prisma.io:5432/?sslmode=require\"\n\nVia Prisma Accelerate (HTTP)​\n\nWhen connecting via Prisma Accelerate, the connection string doesn't require a user/password like a conventional connection string does. Instead, authentication works via an API key:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"prisma+postgres://accelerate.prisma-data.net/?api_key=API_KEY\"\n\n} \n\n\nIn this snippet, API_KEY is a placeholder for the API key you are receiving when setting up a new Prismas Postgres instance via the Prisma Console. Here is an example for what a real connection URL to Prisma Postgres may look like:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"prisma+postgres://accelerate.prisma-data.net/?api_key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcGlfa2V5IjoiMGNkZTFlMjQtNzhiYi00NTY4LTkyM2EtNWUwOTEzZWUyNjU1IiwidGVuYW50X2lkIjoiNzEyZWRlZTc1Y2U2MDk2ZjI4NDg3YjE4NWMyYzA2OTNhNGMxNzJkMjhhOWFlNGUwZTYxNWE4NWIxZWY1YjBkMCIsImludGVybmFsX3NlY3JldCI6IjA4MzQ2Y2RlLWI5ZjktNDQ4Yy04NThmLTMxNjg4ODEzNmEzZCJ9.N1Za6q6NfInzHvRkud6Ojt_-RFg18a0601vdYWGKOrk\"\n\n}\n\nLocal Prisma Postgres​\n\nThe connection string for connecting to a local Prisma Postgres instance mirrors the structure of a remote instance via Accelerate:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"prisma+postgres://accelerate.prisma-data.net/?api_key=API_KEY\"\n\n} \n\n\nHowever, in this case the API_KEY doesn't provide authentication details. Instead, it encodes information about the local Prisma Postgres instance. You can obtain a local connection string via the prisma dev command.\n\nPostgreSQL​\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"postgresql://janedoe:mypassword@localhost:5432/mydb?schema=sample\"\n\n}\n\nMySQL​\nschema.prisma\ndatasource db {\n\n  provider = \"mysql\"\n\n  url      = \"mysql://janedoe:mypassword@localhost:3306/mydb\"\n\n}\n\nMicrosoft SQL Server​\nschema.prisma\ndatasource db {\n\n  provider = \"sqlserver\"\n\n  url      = \"sqlserver://localhost:1433;initial catalog=sample;user=sa;password=mypassword;\"\n\n}\n\nSQLite​\nschema.prisma\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:./dev.db\"\n\n}\n\nCockroachDB​\nschema.prisma\ndatasource db {\n\n  provider = \"cockroachdb\"\n\n  url      = \"postgresql://janedoe:mypassword@localhost:26257/mydb?schema=public\"\n\n}\n\nMongoDB​\nschema.prisma\ndatasource db {\n\n  provider = \"mongodb\"\n\n  url      = \"mongodb+srv://root:<password>@cluster0.ab1cd.mongodb.net/myDatabase?retryWrites=true&w=majority\"\n\n}\n\n.env​\n\nYou can also provide the connection URL as an environment variable:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\nYou can then either set the environment variable in your terminal or by providing a dotenv\n file named .env. This will automatically be picked up by the Prisma CLI.\n\nPrisma ORM reads the connection URL from the dotenv file in the following situations:\n\nWhen it updates the schema during build time\nWhen it connects to the database during run time\nDATABASE_URL=postgresql://janedoe:mypassword@localhost:5432/mydb\n"
  },
  {
    "title": "System requirements (Reference) | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/system-requirements",
    "html": "ORMReference\nSystem requirements\n\nThis page provides an overview of the system requirements for Prisma ORM.\n\nSystem requirements​\n\nThis section lists the software that Prisma ORM requires and the supported operating systems, along with runtime dependency requirements for specific operating systems.\n\nSoftware requirements​\n\nThe latest version of Prisma ORM requires the following software:\n\nTool\tMinimum required version\nNode.js\t18.8 / 20.9 / 22.11\nTypeScript (optional)\t5.1.X\nYarn (optional)\t1.19.2\nPrisma ORM supports and tests all Active LTS and Maintenance LTS Node.js releases. Releases that are not in these states like\nCurrent\n, and also odd-numbered versions\n probably also work, but are not recommended for production use.\nTypeScript is only required for TypeScript users.\nWhen using Yarn 1, 1.19.2 is the minimum version compatible with Prisma Client.\n\nSee also: Supported database versions\n\nExpand for earlier versions\nOperating systems​\n\nPrisma ORM is supported on macOS, Windows and most Linux distributions.\n\nLinux runtime dependencies​\n\nPrisma ORM requires the following system libraries to be installed to work:\n\nOpenSSL 1.0.x, 1.1.x or 3.x\nzlib (libz.so.1)\nlibgcc (libgcc_s.so.1)\nC standard library (glibc on most Linux distributions or musl libc on Alpine Linux)\n\nThe following two tables show the supported Linux distro families, OpenSSL versions and C standard libraries for each CPU architecture.\n\nOn AMD64 (x86_64) architecture:\n\nDistro family\tOpenSSL version\tlibc version\nAlpine\t1.1.x, 3.x\tmusl 1.2.x\nRHEL\t1.0.x, 1.1.x, 3.x\tglibc 2.17+\nDebian or others\t1.0.x\tglibc 2.19+\nDebian or others\t1.1.x, 3.x\tglibc 2.24+\n\nOn ARM64 (aarch64) architecture:\n\nDistro family\tOpenSSL version\tlibc version\nAlpine\t1.1.x, 3.x\tmusl 1.2.x\nRHEL\t1.0.x, 1.1.x, 3.x\tglibc 2.24+\nDebian or others\t1.0.x, 1.1.x, 3.x\tglibc 2.24+\n\nWhen Prisma ORM can not resolve the OpenSSL version on a system (e.g. because it is not installed), it will default to OpenSSL 1.1.x.\n\nSystems that can run the supported Node.js versions will most likely have zlib and libgcc available. One notable exception is Google's Distroless images, where libz.so.1 needs to be copied from a compatible Debian system.\n\nWindows runtime dependencies​\n\nOn Windows Microsoft Visual C++ Redistributable 2015\n or newer must be installed (which is by default the case on most modern installations).\n\nmacOS runtime dependencies​\n\nPrisma ORM supports macOS 10.15 or newer. There are no additional platform-specific requirements on macOS other than what is listed for all platforms in the Software requirements section.\n\nTroubleshooting​\n\nThere are some common problems caused by using outdated versions of the system requirements:\n\nUnable to build a TypeScript project with @prisma/client​\nProblem​\n\nYou see the following error when you try type-checking a project after you run prisma generate.\n\n./node_modules/.prisma/client/index.d.ts:10:33\n\nType error: Type expected.\n\n8 | export type PrismaPromise<A> = Promise<A> & {[prisma]: true}\n\n9 | type UnwrapTuple<Tuple extends readonly unknown[]> = {\n\n> 10 | [K in keyof Tuple]: K extends `${number}` ? Tuple[K] extends PrismaPromise<infer X> ? X : never : never\n\n| ^\n\n11 | };\n\n12 |\n\n13 |\n\nSolution​\n\nUpgrade the TypeScript dependency in your project to a version supported by Prisma ORM. npm install -D typescript.\n\nUnable to use groupBy preview feature​\nProblem​\n\nYou see the following console error when you attempt to run an app that uses the groupBy preview feature:\n\nserver.ts:6:25 - error TS2615: Type of property 'OR' circularly references itself in mapped type '{ [K in keyof { AND?: Enumerable<ProductScalarWhereWithAggregatesInput>; OR?: Enumerable<ProductScalarWhereWithAggregatesInput>; ... 4 more ...; category?: string | StringWithAggregatesFilter; }]: Or<...> extends 1 ? { ...; }[K] extends infer TK ? GetHavingFields<...> : never : {} extends FieldPaths<...> ? never : K...'.\n\n6 const grouped = await prisma.product.groupBy({\n\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n7 by: ['category']\n\n~~~~~~~~~~~~~~~~~~~~\n\n8 });\n\n~~~~\n\nserver.ts:6:48 - error TS2554: Expected 0 arguments, but got 1.\n\n6 const grouped = await prisma.product.groupBy({\n\n~\n\n7 by: ['category']\n\n~~~~~~~~~~~~~~~~~~~~\n\n8 });\n\n~~~\n\nSolution​\n\nUpgrade the TypeScript dependency in your project to a version supported by Prisma ORM. npm install -D typescript."
  },
  {
    "title": "Prisma Client & Prisma schema | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/preview-features/client-preview-features",
    "html": "ORMReferencePreview features\nPrisma Client & Prisma schema\n\nWhen we release a new Prisma Client or Prisma schema feature, it often starts in Preview so that you can test it and submit your feedback. After we improve the feature with your feedback and are satisfied with the internal test results, we promote the feature to general availability.\n\nFor more information, see ORM releases and maturity levels.\n\nCurrently active Preview features​\n\nThe following Preview feature flags are available for Prisma Client and Prisma schema:\n\nFeature\tReleased into Preview\tFeedback issue\nmetrics\t3.15.0\n\tSubmit feedback\n\nviews\t4.9.0\n\tSubmit feedback\n\nrelationJoins\t5.7.0\n\tSubmit feedback\n\nnativeDistinct\t5.7.0\n\tSubmit feedback\n\ntypedSql\t5.19.0\n\tSubmit feedback\n\nstrictUndefinedChecks\t5.20.0\n\tSubmit feedback\n\nfullTextSearchPostgres\t6.0.0\n\tSubmit feedback\n\nshardKeys\t6.10.0\n\tSubmit feedback\n\nTo enable a Preview feature, add the feature flag to the generator block in your schema.prisma file. Share your feedback on all Preview features on GitHub\n.\n\nEnabling a Prisma Client Preview feature​\n\nTo enable a Prisma Client Preview feature:\n\nAdd the Preview feature flag to the generator block:\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"relationJoins\"]\n\n}\n\n\nRe-generate Prisma Client:\n\nnpx prisma generate\n\n\nIf you are using Visual Studio Code and the Preview feature is not available in your .ts file after generating Prisma Client, run the TypeScript: Restart TS server command.\n\nPreview features promoted to General Availability​\n\nIn the list below, you can find a history of Prisma Client and Prisma schema features that were in Preview and are now in general availability. The features are sorted by the most recent version in which they were promoted to general availability.\n\nFeature\tReleased into Preview\tReleased into General Availability\ndriverAdapters\t5.4.0\n\t6.16.0\n\nqueryCompiler\t6.7.0\n\t6.16.0\n\nmultiSchema\t4.3.0\n\t6.13.0\n\nprismaSchemaFolder\t5.15.0\n\t6.7.0\n\nomitApi\t5.13.0\n\t6.2.0\n\njsonProtocol\t4.11.0\n\t5.0.0\n\nextendedWhereUnique\t4.5.0\n\t5.0.0\n\nfieldReference\t4.3.0\n\t5.0.0\n\nclientExtensions\t4.7.0\n\t4.16.0\n\nfilteredRelationCount\t4.3.0\n\t4.16.0\n\ntracing\t4.2.0\n\t6.1.0\n\norderByNulls\t4.1.0\n\t4.16.0\n\nreferentialIntegrity\t3.1.1\n\t4.7.0\n\ninteractiveTransactions\t2.29.0\n\t4.7.0\n\nwith Prisma Accelerate 5.1.1\n\nextendedIndexes\t3.5.0\n\t4.0.0\n\nfilterJson\t2.23.0\n\t4.0.0\n\nimprovedQueryRaw\t3.14.0\n\t4.0.0\n\ncockroachdb\t3.9.0\n\nmigrations in 3.11.0\n\t3.14.0\n\nmongodb\t2.27.0\n\nintrospection in 3.2.0\n\nembedded docs in 3.4.0\n\nraw queries in 3.9.0\n\nfilters/ordering in embedded docs in 3.11.0\n\t3.12.0\n\nmicrosoftSqlServer\t2.10.0\n\t3.0.1\n\nnamedConstraints\t2.29.0\n\t3.0.1\n\nreferentialActions\t2.26.0\n\t3.0.1\n\norderByAggregateGroup\t2.21.0\n\t3.0.1\n\norderByRelation\t2.16.0\n\naggregates in 2.19.0\n\t3.0.1\n\nselectRelationCount\t2.20.0\n\t3.0.1\n\nnapi\t2.20.0\n\t3.0.1\n\ngroupBy\t2.14.0\n\t2.20.0\n\ncreateMany\t2.16.0\n\t2.20.0\n\nnativeTypes\t2.11.0\n\t2.17.0\n\nuncheckedScalarInputs\t2.11.0\n\t2.15.0\n\ntransactionApi\t2.1.0\n\t2.11.0\n\nconnectOrCreate\t2.1.0\n\t2.11.0\n\natomicNumberOperations\t2.6.0\n\t2.10.0\n\ninsensitiveFilters (PostgreSQL)\t2.5.0\n\t2.8.0\n\nmiddlewares\t2.3.0\n\t2.5.0\n\naggregateApi\t2.2.0\n\t2.5.0\n\ndistinct\t2.3.0\n\t2.5.0"
  },
  {
    "title": "Preview features (Reference) | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/preview-features",
    "html": "ORMReference\nPreview features\n\nSome Prisma ORM features are released as Previews. Share your feedback on all Preview features on GitHub\n. For information about available preview features and how to enable them, see:\n\nPrisma Client and Prisma schema preview features\nPrisma CLI preview features\n\nFor information regarding upgrading Prisma ORM and enabling Preview features see Upgrading to use Preview features."
  },
  {
    "title": "Prisma CLI Preview features | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/preview-features/cli-preview-features",
    "html": "ORMReferencePreview features\nPrisma CLI Preview features\n\nWhen we release a new Prisma CLI feature, it often starts in Preview so that you can test it and submit your feedback. After we improve the feature with your feedback and are satisfied with the internal test results, we promote the feature to general availability.\n\nFor more information, see ORM releases and maturity levels.\n\nCurrently active Preview features​\n\nThere are currently no Preview features for Prisma CLI.\n\nPreview features promoted to general availability​\n\nIn the list below, you can find a history of Prisma CLI features that were in Preview and are now in general availability. The features are sorted by the most recent version in which they were promoted to general availability.\n\nFeatures\tReleased in Preview\tReleased in general availability\nprisma migrate diff\t3.9.0\n\t3.13.0\n\nprisma db execute\t3.9.0\n\t3.13.0\n\nprisma db push\t2.10.0\n\t2.22.0\n\nprisma migrate\t2.13.0\n\t2.19.0"
  }
]
</file>

<file path="output/jobs/trpc.json">
[
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/introduction",
    "html": "📄️ Define Routers\n\nTo begin building your tRPC-based API, you'll first need to define your router. Once you've mastered the fundamentals, you can customize your routers for more advanced use cases.\n\n📄️ Define Procedures\n\nA procedure is a function which is exposed to the client, it can be one of:\n\n📄️ Input & Output Validators\n\ntRPC procedures may define validation logic for their input and/or output, and validators are also used to infer the types of inputs and outputs (using the Standard Schema interface if available, or custom interfaces for supported validators if not). We have first class support for many popular validators, and you can integrate validators which we don't directly support.\n\n📄️ Non-JSON Inputs (FormData, File, Blob)\n\nIn addition to JSON-serializable data, tRPC can use FormData, File, and other Binary types as procedure inputs\n\n📄️ Merging Routers\n\nWriting all API-code in your code in the same file is not a great idea. It's easy to merge routers with other routers.\n\n📄️ Context\n\nYour context holds data that all of your tRPC procedures will have access to, and is a great place to put things like database connections or authentication information.\n\n📄️ Middlewares\n\nYou are able to add middleware(s) to a procedure with the t.procedure.use() method. The middleware(s) will wrap the invocation of the procedure and must pass through its return value.\n\n🗃️ Hosting tRPC with Adapters\n\n6 items\n\n📄️ Server Side Calls\n\nYou may need to call your procedure(s) directly from the same server they're hosted in, createCallerFactory() can be used to achieve this. This is useful for server-side calls and for integration testing of your tRPC procedures.\n\n📄️ Authorization\n\nThe createContext function is called for each incoming request, so here you can add contextual information about the calling user from the request object.\n\n📄️ Error Handling\n\nWhenever an error occurs in a procedure, tRPC responds to the client with an object that includes an \"error\" property. This property contains all the information that you need to handle the error in the client.\n\n📄️ Error Formatting\n\nThe error formatting in your router will be inferred all the way to your client (&&nbsp;React&nbsp;components)\n\n📄️ Data Transformers\n\nYou are able to serialize the response data & input args. The transformers need to be added both to the server and the client.\n\n📄️ Metadata\n\nProcedure metadata allows you to add an optional procedure specific meta property which will be available in all middleware function parameters.\n\n📄️ Response Caching\n\nThe below examples uses Vercel's edge caching to serve data to your users as fast as possible.\n\n📄️ Subscriptions\n\nIntroduction\n\n📄️ WebSockets\n\nYou can use WebSockets for all or some of the communication with your server, see wsLink for how to set it up on the client."
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs",
    "html": "Client Usage\nNext.js Integration\nVersion: 11.x\nNext.js Integration\ntRPC ❤️ Next.js​\n\nNext.js makes it easy to build a client and server together in one codebase. tRPC makes it easy to share types between them, ensuring typesafety for your application's data fetching.\n\nOur Next.js integration is built on top of our React Query Integration with some Next.js specific APIs, to handle both client and server side rendering.\n\nWhen using the Next.js integration, you'll get the following features:\n\nServer-side rendering - You can tell tRPC to render your pages on the server, and then hydrate them on the client. This way, you'll avoid an initial loading state, although time to first byte will be blocked by the server. Read more about Server-side rendering.\nStatic site generation - Prefetch queries on the server and generate static HTML files that are ready to be served. Read more about Static site generation.\nAutomatic Provider Wrapping - @trpc/next provides a higher-order component (HOC) that wraps your app with the necessary providers so you don't have to do it yourself.\nTIP\n\nIf you're using tRPC in a new project, consider using one of the example projects for reference: tRPC Example Projects\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/routers",
    "html": "Backend Usage\nDefine Routers\nVersion: 11.x\nDefine Routers\n\nTo begin building your tRPC-based API, you'll first need to define your router. Once you've mastered the fundamentals, you can customize your routers for more advanced use cases.\n\nInitialize tRPC​\n\nYou should initialize tRPC exactly once per application. Multiple instances of tRPC will cause issues.\n\nserver/trpc.ts\nimport { initTRPC } from '@trpc/server';\n \n// You can use any variable name you like.\n// We use t to keep things simple.\nconst t = initTRPC.create();\n \nexport const router = t.router;\nexport const publicProcedure = t.procedure;\nCopy\n\nYou'll notice we are exporting certain methods of the t variable here rather than t itself. This is to establish a certain set of procedures that we will use idiomatically in our codebase.\n\nDefining a router​\n\nNext, let's define a router with a procedure to use in our application. We have now created an API \"endpoint\".\n\nIn order for these endpoints to be exposed to the frontend, your Adapter should be configured with your appRouter instance.\n\nserver/_app.ts\nimport { publicProcedure, router } from './trpc';\n \nconst appRouter = router({\n  greeting: publicProcedure.query(() => 'hello tRPC v10!'),\n});\n \n// Export only the type of a router!\n// This prevents us from importing server code on the client.\nexport type AppRouter = typeof appRouter;\nCopy\nAdvanced usage​\n\nWhen initializing your router, tRPC allows you to:\n\nSetup request contexts\nAssign metadata to procedures\nFormat and handle errors\nTransform data as needed\nCustomize the runtime configuration\n\nYou can use method chaining to customize your t-object on initialization. For example:\n\nconst t = initTRPC.context<Context>().meta<Meta>().create({\n  /* [...] */\n});\nCopy\nRuntime Configuration​\nexport interface RootConfig<TTypes extends RootTypes> {\n  /**\n   * Use a data transformer\n   * @see https://trpc.io/docs/v11/data-transformers\n   */\n  transformer: TTypes['transformer'];\n  /**\n   * Use custom error formatting\n   * @see https://trpc.io/docs/v11/error-formatting\n   */\n  errorFormatter: ErrorFormatter<TTypes['ctx'], any>;\n  /**\n   * Allow `@trpc/server` to run in non-server environments\n   * @warning **Use with caution**, this should likely mainly be used within testing.\n   * @default false\n   */\n  allowOutsideOfServer: boolean;\n  /**\n   * Is this a server environment?\n   * @warning **Use with caution**, this should likely mainly be used within testing.\n   * @default typeof window === 'undefined' || 'Deno' in window || process.env.NODE_ENV === 'test'\n   */\n  isServer: boolean;\n  /**\n   * Is this development?\n   * Will be used to decide if the API should return stack traces\n   * @default process.env.NODE_ENV !== 'production'\n   */\n  isDev: boolean;\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/procedures",
    "html": "Backend Usage\nDefine Procedures\nVersion: 11.x\nDefine Procedures\n\nA procedure is a function which is exposed to the client, it can be one of:\n\na Query - used to fetch data, generally does not change any data\na Mutation - used to send data, often for create/update/delete purposes\na Subscription - you might not need this, and we have dedicated documentation\n\nProcedures in tRPC are very flexible primitives to create backend functions. They use an immutable builder pattern, which means you can create reusable base procedures that share functionality among multiple procedures.\n\nWriting procedures​\n\nThe t object you create during tRPC setup returns an initial t.procedure which all other procedures are built on:\n\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \nconst t = initTRPC.context<{ signGuestBook: () => Promise<void> }>().create();\n \nexport const router = t.router;\nexport const publicProcedure = t.procedure;\n \nconst appRouter = router({\n  // Queries are the best place to fetch data\n  hello: publicProcedure.query(() => {\n    return {\n      message: 'hello world',\n    };\n  }),\n \n  // Mutations are the best place to do things like updating a database\n  goodbye: publicProcedure.mutation(async (opts) => {\n    await opts.ctx.signGuestBook();\n \n    return {\n      message: 'goodbye!',\n    };\n  }),\n});\nCopy\nReusable \"Base Procedures\"​\n\nAs a general pattern we recommend you rename and export t.procedure as publicProcedure, which then makes room for you to create other named procedures for specific use cases and export those too. This pattern is called \"base procedures\" and is a key pattern for code and behaviour re-use in tRPC; every application is likely to need it.\n\nIn the below code, we're using reusable base procedures to build common use-cases for our app - we're making a reusable base procedures for logged in users (authedProcedure) & another base procedure that takes an organizationId and validates that a user is part of that organization.\n\nThis is a simplified example; in practice you may want to use some combination of Headers, Context, Middleware, and Metadata, to authenticate and authorize your users.\n\nimport { initTRPC, TRPCError } from '@trpc/server';\nimport { z } from 'zod';\n \ntype Organization = {\n  id: string;\n  name: string;\n};\ntype Membership = {\n  role: 'ADMIN' | 'MEMBER';\n  Organization: Organization;\n};\ntype User = {\n  id: string;\n  memberships: Membership[];\n};\ntype Context = {\n  /**\n   * User is nullable\n   */\n  user: User | null;\n};\n \nconst t = initTRPC.context<Context>().create();\n \nexport const publicProcedure = t.procedure;\n \n// procedure that asserts that the user is logged in\nexport const authedProcedure = t.procedure.use(async function isAuthed(opts) {\n  const { ctx } = opts;\n  // `ctx.user` is nullable\n  if (!ctx.user) {\n            \n(property) user: User | null\n    throw new TRPCError({ code: 'UNAUTHORIZED' });\n  }\n \n  return opts.next({\n    ctx: {\n      // ✅ user value is known to be non-null now\n      user: ctx.user,\n    },\n  });\n});\n \n// procedure that a user is a member of a specific organization\nexport const organizationProcedure = authedProcedure\n  .input(z.object({ organizationId: z.string() }))\n  .use(function isMemberOfOrganization(opts) {\n    const membership = opts.ctx.user.memberships.find(\n      (m) => m.Organization.id === opts.input.organizationId,\n    );\n    if (!membership) {\n      throw new TRPCError({\n        code: 'FORBIDDEN',\n      });\n    }\n    return opts.next({\n      ctx: {\n        Organization: membership.Organization,\n      },\n    });\n  });\n \nexport const appRouter = t.router({\n  whoami: authedProcedure.query(async (opts) => {\n    // user is non-nullable here\n    const { ctx } = opts;\n            \nconst ctx: {\n    user: User;\n}\n    return ctx.user;\n  }),\n  addMember: organizationProcedure\n    .input(\n      z.object({\n        email: z.string().email(),\n      }),\n    )\n    .mutation((opts) => {\n      // ctx contains the non-nullable user & the organization being queried\n      const { ctx } = opts;\n              \nconst ctx: {\n    user: User;\n    Organization: Organization;\n}\n \n      // input includes the validated email of the user being invited & the validated organizationId\n      const { input } = opts;\n               \nconst input: {\n    organizationId: string;\n    email: string;\n}\n \n      return '...';\n    }),\n});\nCopy\nInferring the options type of a \"Base Procedure\"​\n\nIn addition to being able to infer the input and output types of a procedure, you can also infer the options type of a specific procedure builder (or base procedure) using inferProcedureBuilderResolverOptions.\n\nThis type helper is useful for declaring a type to a function's parameters. Like for example, separating the procedure's handler (main execution code) from its definition at the router, or for creating a helper function that works with multiple procedures.\n\nasync function getMembersOfOrganization(\n  opts: inferProcedureBuilderResolverOptions<typeof organizationProcedure>,\n) {\n  // input and ctx are now correctly typed!\n  const { ctx, input } = opts;\n \n  return await prisma.user.findMany({\n    where: {\n      membership: {\n        organizationId: ctx.Organization.id,\n      },\n    },\n  });\n}\nexport const appRouter = t.router({\n  listMembers: organizationProcedure.query(async (opts) => {\n    // use helper function!\n    const members = await getMembersOfOrganization(opts);\n \n    return members;\n  }),\n});\nCopy\nSubscriptions​\n\nFor information on subscriptions, see our subscriptions guide.\n\nEdit this page"
  },
  {
    "title": "Input & Output Validators | tRPC",
    "url": "https://trpc.io/docs/server/validators",
    "html": "Backend Usage\nInput & Output Validators\nVersion: 11.x\nInput & Output Validators\n\ntRPC procedures may define validation logic for their input and/or output, and validators are also used to infer the types of inputs and outputs (using the Standard Schema interface if available, or custom interfaces for supported validators if not). We have first class support for many popular validators, and you can integrate validators which we don't directly support.\n\nInput Validators​\n\nBy defining an input validator, tRPC can check that a procedure call is correct and return a validation error if not.\n\nTo set up an input validator, use the procedure.input() method:\n\n// Our examples use Zod by default, but usage with other libraries is identical\nimport { z } from 'zod';\n \nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(\n      z.object({\n        name: z.string(),\n      }),\n    )\n    .query((opts) => {\n      const name = opts.input.name;\n             \nconst name: string\n      return {\n        greeting: `Hello ${opts.input.name}`,\n      };\n    }),\n});\nCopy\nInput Merging​\n\n.input() can be stacked to build more complex types, which is particularly useful when you want to utilise some common input to a collection of procedures in a middleware.\n\nconst baseProcedure = t.procedure\n  .input(z.object({ townName: z.string() }))\n  .use((opts) => {\n    const input = opts.input;\n           \nconst input: {\n    townName: string;\n}\n \n    console.log(`Handling request with user from: ${input.townName}`);\n \n    return opts.next();\n  });\n \nexport const appRouter = t.router({\n  hello: baseProcedure\n    .input(\n      z.object({\n        name: z.string(),\n      }),\n    )\n    .query((opts) => {\n      const input = opts.input;\n             \nconst input: {\n    townName: string;\n    name: string;\n}\n      return {\n        greeting: `Hello ${input.name}, my friend from ${input.townName}`,\n      };\n    }),\n});\nCopy\nOutput Validators​\n\nValidating outputs is not always as important as defining inputs, since tRPC gives you automatic type-safety by inferring the return type of your procedures. Some reasons to define an output validator include:\n\nChecking that data returned from untrusted sources is correct\nEnsure that you are not returning more data to the client than necessary\nINFO\n\nIf output validation fails, the server will respond with an INTERNAL_SERVER_ERROR.\n\nimport { z } from 'zod';\n \nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .output(\n      z.object({\n        greeting: z.string(),\n      }),\n    )\n    .query((opts) => {\n      return {\n        gre,\n           \ngreeting\n      };\n    }),\n});\nCopy\nOutput validation of subscriptions​\n\nSince subscriptions are async iterators, you can use the same validation techniques as above.\n\nHave a look at the subscriptions guide for more information.\n\nThe most basic validator: a function​\n\nYou can define a validator without any 3rd party dependencies, with a function.\n\nINFO\n\nWe don't recommend making a custom validator unless you have a specific need, but it's important to understand that there's no magic here - it's just typescript!\n\nIn most cases we recommend you use a validation library\n\nimport { initTRPC } from '@trpc/server';\n \nexport const t = initTRPC.create();\n \nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input((value): string => {\n      if (typeof value === 'string') {\n        return value;\n      }\n      throw new Error('Input is not a string');\n    })\n    .output((value): string => {\n      if (typeof value === 'string') {\n        return value;\n      }\n      throw new Error('Output is not a string');\n    })\n    .query((opts) => {\n      const { input } = opts;\n               \nconst input: string\n      return `hello ${input}`;\n    }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\nLibrary integrations​\n\ntRPC works out of the box with a number of popular validation and parsing libraries, including any library conforming to Standard Schema. The below are some examples of usage with validators which we officially maintain support for.\n\nWith Zod​\n\nZod is our default recommendation, it has a strong ecosystem which makes it a great choice to use in multiple parts of your codebase. If you have no opinion of your own and want a powerful library which won't limit future needs, Zod is a great choice.\n\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \nexport const t = initTRPC.create();\n \nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(\n      z.object({\n        name: z.string(),\n      }),\n    )\n    .output(\n      z.object({\n        greeting: z.string(),\n      }),\n    )\n    .query(({ input }) => {\n               \n(parameter) input: {\n    name: string;\n}\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\nWith Yup​\nimport { initTRPC } from '@trpc/server';\nimport * as yup from 'yup';\n \nexport const t = initTRPC.create();\n \nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(\n      yup.object({\n        name: yup.string().required(),\n      }),\n    )\n    .output(\n      yup.object({\n        greeting: yup.string().required(),\n      }),\n    )\n    .query(({ input }) => {\n               \n(parameter) input: {\n    name: string;\n}\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\nWith Superstruct​\nimport { initTRPC } from '@trpc/server';\nimport { object, string } from 'superstruct';\n \nexport const t = initTRPC.create();\n \nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(object({ name: string() }))\n    .output(object({ greeting: string() }))\n    .query(({ input }) => {\n               \n(parameter) input: {\n    name: string;\n}\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\nWith scale-ts​\nimport { initTRPC } from '@trpc/server';\nimport * as $ from 'scale-codec';\n \nexport const t = initTRPC.create();\n \nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input($.object($.field('name', $.str)))\n    .output($.object($.field('greeting', $.str)))\n    .query(({ input }) => {\n               \n(parameter) input: {\n    readonly name: string;\n}\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\nWith Typia​\nimport { initTRPC } from '@trpc/server';\nimport typia from 'typia';\nimport { v4 } from 'uuid';\nimport { IBbsArticle } from '../structures/IBbsArticle';\nconst t = initTRPC.create();\nconst publicProcedure = t.procedure;\nexport const appRouter = t.router({\n  store: publicProcedure\n    .input(typia.createAssert<IBbsArticle.IStore>())\n    .output(typia.createAssert<IBbsArticle>())\n    .query(({ input }) => {\n      return {\n        id: v4(),\n        writer: input.writer,\n        title: input.title,\n        body: input.body,\n        created_at: new Date().toString(),\n      };\n    }),\n});\nexport type AppRouter = typeof appRouter;\nCopy\nWith ArkType​\nimport { initTRPC } from '@trpc/server';\nimport { type } from 'arktype';\nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\nexport const appRouter = t.router({\n  hello: publicProcedure.input(type({ name: 'string' })).query((opts) => {\n    return {\n      greeting: `hello ${opts.input.name}`,\n    };\n  }),\n});\nexport type AppRouter = typeof appRouter;\nCopy\nWith effect​\nimport { initTRPC } from '@trpc/server';\nimport { Schema } from 'effect';\nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(Schema.standardSchemaV1(Schema.Struct({ name: Schema.String })))\n    .output(Schema.standardSchemaV1(Schema.Struct({ greeting: Schema.String })))\n    .query(({ input }) => {\n      //      ^?\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\nexport type AppRouter = typeof appRouter;\nCopy\nWith Valibot​\nimport { initTRPC } from '@trpc/server';\nimport * as v from 'valibot';\n \nexport const t = initTRPC.create();\n \nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(v.object({ name: v.string() }))\n    .output(v.object({ greeting: v.string() }))\n    .query(({ input }) => {\n               \n(parameter) input: {\n    name: string;\n}\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\nWith @robolex/sure​\n\nYou're able to define your own Error types and error throwing function if necessary. As a convenience @robolex/sure provides sure/src/err.ts:\n\n// sure/src/err.ts\nexport const err = (schema) => (input) => {\n  const [good, result] = schema(input);\n  if (good) return result;\n  throw result;\n};\nCopy\nimport { err, object, string } from '@robolex/sure';\nimport { initTRPC } from '@trpc/server';\nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(\n      err(\n        object({\n          name: string,\n        }),\n      ),\n    )\n    .output(\n      err(\n        object({\n          greeting: string,\n        }),\n      ),\n    )\n    .query(({ input }) => {\n      //      ^?\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\nexport type AppRouter = typeof appRouter;\nCopy\nWith TypeBox​\nimport { Type } from '@sinclair/typebox';\nimport { initTRPC } from '@trpc/server';\nimport { wrap } from '@typeschema/typebox';\nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\nexport const appRouter = t.router({\n  hello: publicProcedure\n    .input(wrap(Type.Object({ name: Type.String() })))\n    .output(wrap(Type.Object({ greeting: Type.String() })))\n    .query(({ input }) => {\n      return {\n        greeting: `hello ${input.name}`,\n      };\n    }),\n});\nexport type AppRouter = typeof appRouter;\nCopy\nContributing your own Validator Library​\n\nIf you work on a validator library which supports tRPC usage, please feel free to open a PR for this page with equivalent usage to the other examples here, and a link to your docs.\n\nIntegration with tRPC in most cases is as simple as meeting one of several existing type interfaces. Conforming to Standard Schema is recommended, but in some cases we may accept a PR to add a new supported interface. Feel free to open an issue for discussion. You can check the existing supported interfaces and functions for parsing/validation in code.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/non-json-content-types",
    "html": "Backend Usage\nNon-JSON Inputs (FormData, File, Blob)\nVersion: 11.x\nNon-JSON Content Types\n\nIn addition to JSON-serializable data, tRPC can use FormData, File, and other Binary types as procedure inputs\n\nClient Setup​\nINFO\n\nWhile tRPC natively supports several non-json serializable types, your client may need a little link configuration to support them depending on your setup.\n\nhttpLink supports non-json content types out the box, if you're only using this then your existing setup should work immediately\n\nimport { httpLink } from '@trpc/client';\ntrpc.createClient({\n  links: [\n    httpLink({\n      url: 'http://localhost:2022',\n    }),\n  ],\n});\nCopy\n\nHowever, not all links support these new content types, if you're using httpBatchLink or httpBatchStreamLink you will need to include a splitLink and check which link to use depending on the content\n\nimport {\n  httpBatchLink,\n  httpLink,\n  isNonJsonSerializable,\n  splitLink,\n} from '@trpc/client';\ntrpc.createClient({\n  links: [\n    splitLink({\n      condition: (op) => isNonJsonSerializable(op.input),\n      true: httpLink({\n        url,\n      }),\n      false: httpBatchLink({\n        url,\n      }),\n    }),\n  ],\n});\nCopy\n\nIf you are using transformer in your tRPC server, typescript requires that your tRPC client link defines transformer as well.\nUse this example as base:\n\nimport {\n  httpBatchLink,\n  httpLink,\n  isNonJsonSerializable,\n  splitLink,\n} from '@trpc/client';\nimport superjson from 'superjson';\ntrpc.createClient({\n  links: [\n    splitLink({\n      condition: (op) => isNonJsonSerializable(op.input),\n      true: httpLink({\n        url,\n        transformer: {\n          // request - convert data before sending to the tRPC server\n          serialize: (data) => data,\n          // response - convert the tRPC response before using it in client\n          deserialize: superjson.deserialize, // or your other transformer\n        },\n      }),\n      false: httpBatchLink({\n        url,\n        transformers: superjson, // or your other transformer\n      }),\n    }),\n  ],\n});\nCopy\nServer Usage​\nINFO\n\nWhen a request is handled by tRPC, it takes care of parsing the request body based on the Content-Type header of the request.\nIf you encounter errors like Failed to parse body as XXX, make sure that your server (e.g., Express, Next.js) isn't parsing the request body before tRPC handles it.\n\n// Example in express\n// incorrect\nconst app = express();\napp.use(express.json()); // this try to parse body before tRPC.\napp.post('/express/hello', (req,res) => {/* ... */ }); // normal express route handler\napp.use('/trpc', trpcExpress.createExpressMiddleware({ /* ... */}))// tRPC fails to parse body\n// correct\nconst app = express();\napp.use('/express', express.json()); // do it only in \"/express/*\" path\napp.post('/express/hello', (req,res) => {/* ... */ });\napp.use('/trpc', trpcExpress.createExpressMiddleware({ /* ... */}))// tRPC can parse body\nCopy\nFormData Input​\n\nFormData is natively supported, and for more advanced usage you could also combine this with a library like zod-form-data to validate inputs in a type-safe way.\n\nimport { z } from 'zod';\n \nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  hello: publicProcedure.input(z.instanceof(FormData)).mutation((opts) => {\n    const data = opts.input;\n           \nconst data: FormData\n    return {\n      greeting: `Hello ${data.get('name')}`,\n    };\n  }),\n});\nCopy\n\nFor a more advanced code sample you can see our example project here\n\nFile and other Binary Type Inputs​\n\ntRPC converts many octet content types to a ReadableStream which can be consumed in a procedure. Currently these are Blob Uint8Array and File.\n\nimport { octetInputParser } from '@trpc/server/http';\n \nexport const t = initTRPC.create();\nconst publicProcedure = t.procedure;\n \nexport const appRouter = t.router({\n  upload: publicProcedure.input(octetInputParser).mutation((opts) => {\n    const data = opts.input;\n           \nconst data: ReadableStream<any>\n    return {\n      valid: true,\n    };\n  }),\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/merging-routers",
    "html": "Backend Usage\nMerging Routers\nVersion: 11.x\nMerging Routers\n\nWriting all API-code in your code in the same file is not a great idea. It's easy to merge routers with other routers.\n\nDefining an inline sub-router​\n\nWhen you define an inline sub-router, you can represent your router as a plain object.\n\nIn the below example, nested1 and nested2 are equal:\n\nserver/_app.ts\nimport * as trpc from '@trpc/server';\nimport { publicProcedure, router } from './trpc';\n \nconst appRouter = router({\n  // Shorthand plain object for creating a sub-router\n  nested1: {\n    proc: publicProcedure.query(() => '...'),\n  },\n  // Equivalent of:\n  nested2: router({\n    proc : publicProcedure.query(() => '...'),\n  }),\n});\nCopy\nMerging with child routers​\nserver.ts\n// @filename: trpc.ts\nimport { initTRPC } from '@trpc/server';\nconst t = initTRPC.create();\n \n \n \nexport const router = t.router;\nexport const publicProcedure = t.procedure;\n \n// @filename: routers/_app.ts\nimport { router } from '../trpc';\nimport { z } from 'zod';\n \nimport { userRouter } from './user';\nimport { postRouter } from './post';\n \nconst appRouter = router({\n  user: userRouter, // put procedures under \"user\" namespace\n  post: postRouter, // put procedures under \"post\" namespace\n});\n \n// You can then access the merged route with\n// http://localhost:3000/trpc/<NAMESPACE>.<PROCEDURE>\n \nexport type AppRouter = typeof appRouter;\n \n \n// @filename: routers/post.ts\nimport { router, publicProcedure } from '../trpc';\nimport { z } from 'zod';\nexport const postRouter = router({\n  create: publicProcedure\n    .input(\n      z.object({\n        title: z.string(),\n      }),\n    )\n    .mutation((opts) => {\n      const { input } = opts;\n               \nconst input: {\n    title: string;\n}\n      // [...]\n    }),\n  list: publicProcedure.query(() => {\n    // ...\n    return [];\n  }),\n});\n \n// @filename: routers/user.ts\nimport { router, publicProcedure } from '../trpc';\nimport { z } from 'zod';\nexport const userRouter = router({\n  list: publicProcedure.query(() => {\n    // [..]\n    return [];\n  }),\n});\n \nCopy\nMerging with t.mergeRouters​\n\nIf you prefer having all procedures flat in one single namespace, you can instead use t.mergeRouters\n\nserver.ts\n// @filename: trpc.ts\nimport { initTRPC } from '@trpc/server';\nconst t = initTRPC.create();\n \n \nexport const router = t.router;\nexport const publicProcedure = t.procedure;\nexport const mergeRouters = t.mergeRouters;\n \n// @filename: routers/_app.ts\nimport { router, publicProcedure, mergeRouters } from '../trpc';\nimport { z } from 'zod';\n \nimport { userRouter } from './user';\nimport { postRouter } from './post';\n \nconst appRouter = mergeRouters(userRouter, postRouter)\n \nexport type AppRouter = typeof appRouter;\n \n// @filename: routers/post.ts\nimport { router, publicProcedure } from '../trpc';\nimport { z } from 'zod';\nexport const postRouter = router({\n  postCreate: publicProcedure\n    .input(\n      z.object({\n        title: z.string(),\n      }),\n    )\n    .mutation((opts) => {\n      const { input } = opts;\n               \nconst input: {\n    title: string;\n}\n      // [...]\n    }),\n  postList: publicProcedure.query(() => {\n    // ...\n    return [];\n  }),\n});\n \n \n// @filename: routers/user.ts\nimport { router, publicProcedure } from '../trpc';\nimport { z } from 'zod';\nexport const userRouter = router({\n  userList: publicProcedure.query(() => {\n    // [..]\n    return [];\n  }),\n});\n \nCopy\nDynamically load routers​\n\nYou can use the lazy function to dynamically load your routers. This can be useful to reduce cold starts of your application.\n\nThere's no difference in how you use the router after it's been lazy loaded vs. how you use a normal router.\n\nExample code of lazy loading a router:\n\n// @filename: routers/_app.ts\nimport { lazy } from '@trpc/server';\nimport { router } from '../trpc';\n \nexport const appRouter = router({\n  // Option 1: Short-hand lazy load the greeting router if you have exactly 1 export and it is the router\n  greeting: lazy(() => import('./greeting.js')),\n  // Option 2: Alternative way to lazy load if you have more than 1 export\n  user: lazy(() => import('./user.js').then((m) => m.userRouter)),\n});\nexport type AppRouter = typeof appRouter;\n \n// ----------------------------------------------------\n// @filename: routers/greeting.ts\nimport { router, publicProcedure } from '../trpc';\nexport const greetingRouter = router({\n  hello: publicProcedure.query(() => 'world'),\n});\n \n// ----------------------------------------------------\n// @filename: routers/user.ts\nimport { router, publicProcedure } from '../trpc';\n \nexport const userRouter = router({\n  list: publicProcedure.query(() => ['John', 'Jane', 'Jim']),\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/context",
    "html": "Backend Usage\nContext\nVersion: 11.x\nContext\n\nYour context holds data that all of your tRPC procedures will have access to, and is a great place to put things like database connections or authentication information.\n\nSetting up the context is done in 2 steps, defining the type during initialization and then creating the runtime context for each request.\n\nDefining the context type​\n\nWhen initializing tRPC using initTRPC, you should pipe .context<TContext>() to the initTRPC builder function before calling .create(). The type TContext can either be inferred from a function's return type or be explicitly defined.\n\nThis will make sure your context is properly typed in your procedures and middlewares.\n\nimport { initTRPC } from '@trpc/server';\nimport type { CreateNextContextOptions } from '@trpc/server/adapters/next';\nimport { getSession } from 'next-auth/react';\n \nexport const createContext = async (opts: CreateNextContextOptions) => {\n  const session = await getSession({ req: opts.req });\n \n  return {\n    session,\n  };\n};\n \nexport type Context = Awaited<ReturnType<typeof createContext>>;\nconst t = initTRPC.context<Context>().create();\n \nt.procedure.use((opts) => {\n  opts.ctx;\n       \n(property) ctx: {\n    session: Session | null;\n}\n \n  return opts.next();\n});\nCopy\nCreating the context​\n\nThe createContext() function must be passed to the handler that is mounting your appRouter, which may be via HTTP, a server-side call or our server-side helpers.\n\ncreateContext() is called for each invocation of tRPC, so batched requests will share a context.\n\n// 1. HTTP request\nimport { createHTTPHandler } from '@trpc/server/adapters/standalone';\nimport { createContext } from './context';\nimport { appRouter } from './router';\nconst handler = createHTTPHandler({\n  router: appRouter,\n  createContext,\n});\nCopy\n// 2. Server-side call\nimport { createContext } from './context';\nimport { createCaller } from './router';\nconst caller = createCaller(await createContext());\nCopy\n// 3. servers-side helpers\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport { createContext } from './context';\nimport { appRouter } from './router';\nconst helpers = createServerSideHelpers({\n  router: appRouter,\n  ctx: await createContext(),\n});\nCopy\nExample code​\n// -------------------------------------------------\n// @filename: context.ts\n// -------------------------------------------------\nimport type { CreateNextContextOptions } from '@trpc/server/adapters/next';\nimport { getSession } from 'next-auth/react';\n \n/**\n * Creates context for an incoming request\n * @see https://trpc.io/docs/v11/context\n */\nexport async function createContext(opts: CreateNextContextOptions) {\n  const session = await getSession({ req: opts.req });\n \n  return {\n    session,\n  };\n}\n \nexport type Context = Awaited<ReturnType<typeof createContext>>;\n \n// -------------------------------------------------\n// @filename: trpc.ts\n// -------------------------------------------------\nimport { initTRPC, TRPCError } from '@trpc/server';\nimport { Context } from './context';\n \nconst t = initTRPC.context<Context>().create();\n \n \nexport const router = t.router;\n \n/**\n * Unprotected procedure\n */\nexport const publicProcedure = t.procedure;\n \n/**\n * Protected procedure\n */\nexport const protectedProcedure = t.procedure.use(function isAuthed(opts) {\n  if (!opts.ctx.session?.user?.email) {\n    throw new TRPCError({\n      code: 'UNAUTHORIZED',\n    });\n  }\n  return opts.next({\n    ctx: {\n      // Infers the `session` as non-nullable\n      session: opts.ctx.session,\n    },\n  });\n});\nCopy\nInner and outer context​\n\nIn some scenarios it could make sense to split up your context into \"inner\" and \"outer\" functions.\n\nInner context is where you define context which doesn’t depend on the request, e.g. your database connection. You can use this function for integration testing or server-side helpers, where you don’t have a request object. Whatever is defined here will always be available in your procedures.\n\nOuter context is where you define context which depends on the request, e.g. for the user's session. Whatever is defined here is only available for procedures that are called via HTTP.\n\nExample for inner & outer context​\nimport type { CreateNextContextOptions } from '@trpc/server/adapters/next';\nimport { getSessionFromCookie, type Session } from './auth';\n/**\n * Defines your inner context shape.\n * Add fields here that the inner context brings.\n */\ninterface CreateInnerContextOptions extends Partial<CreateNextContextOptions> {\n  session: Session | null;\n}\n/**\n * Inner context. Will always be available in your procedures, in contrast to the outer context.\n *\n * Also useful for:\n * - testing, so you don't have to mock Next.js' `req`/`res`\n * - tRPC's `createServerSideHelpers` where we don't have `req`/`res`\n *\n * @see https://trpc.io/docs/v11/context#inner-and-outer-context\n */\nexport async function createContextInner(opts?: CreateInnerContextOptions) {\n  return {\n    prisma,\n    session: opts.session,\n  };\n}\n/**\n * Outer context. Used in the routers and will e.g. bring `req` & `res` to the context as \"not `undefined`\".\n *\n * @see https://trpc.io/docs/v11/context#inner-and-outer-context\n */\nexport async function createContext(opts: CreateNextContextOptions) {\n  const session = getSessionFromCookie(opts.req);\n  const contextInner = await createContextInner({ session });\n  return {\n    ...contextInner,\n    req: opts.req,\n    res: opts.res,\n  };\n}\nexport type Context = Awaited<ReturnType<typeof createContextInner>>;\n// The usage in your router is the same as the example above.\nCopy\n\nIt is important to infer your Context from the inner context, as only what is defined there is really always available in your procedures.\n\nIf you don't want to check req or res for undefined in your procedures all the time, you could build a small reusable procedure for that:\n\nexport const apiProcedure = publicProcedure.use((opts) => {\n  if (!opts.ctx.req || !opts.ctx.res) {\n    throw new Error('You are missing `req` or `res` in your call.');\n  }\n  return opts.next({\n    ctx: {\n      // We overwrite the context with the truthy `req` & `res`, which will also overwrite the types used in your procedure.\n      req: opts.ctx.req,\n      res: opts.ctx.res,\n    },\n  });\n});\nCopy\nLimiting Batch Size​\n\nYou can use the context to limit the number of requests that can be batched together.\n\nimport { TRPCError } from '@trpc/server';\nimport type { CreateHTTPContextOptions } from '@trpc/server/adapters/standalone';\n \nconst MAX_BATCH_SIZE = 10;\n \n// Create a context that checks batch size\nexport async function createContext(opts: CreateHTTPContextOptions) {\n  if (opts.info.calls.length > MAX_BATCH_SIZE) {\n    throw new TRPCError({\n      code: 'TOO_MANY_REQUESTS',\n      message: `Batch size limit of ${MAX_BATCH_SIZE} exceeded`,\n    });\n  }\n  return {};\n}\nCopy\n\nThis context will throw a TOO_MANY_REQUESTS error if a client tries to batch more than 10 requests together. You can adjust the MAX_BATCH_SIZE constant to match your needs.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/middlewares",
    "html": "Backend Usage\nMiddlewares\nVersion: 11.x\nMiddlewares\n\nYou are able to add middleware(s) to a procedure with the t.procedure.use() method. The middleware(s) will wrap the invocation of the procedure and must pass through its return value.\n\nAuthorization​\n\nIn the example below, any call to a adminProcedure will ensure that the user is an \"admin\" before executing.\n\nimport { TRPCError, initTRPC } from '@trpc/server';\n \ninterface Context {\n  user?: {\n    id: string;\n    isAdmin: boolean;\n    // [..]\n  };\n}\n \nconst t = initTRPC.context<Context>().create();\nexport const publicProcedure = t.procedure;\nexport const router = t.router;\n \nexport const adminProcedure = publicProcedure.use(async (opts) => {\n  const { ctx } = opts;\n  if (!ctx.user?.isAdmin) {\n    throw new TRPCError({ code: 'UNAUTHORIZED' });\n  }\n  return opts.next({\n    ctx: {\n      user: ctx.user,\n    },\n  });\n});\nCopy\nimport { adminProcedure, publicProcedure, router } from './trpc';\n \nconst adminRouter = router({\n  secretPlace: adminProcedure.query(() => 'a key'),\n});\n \nexport const appRouter = router({\n  foo: publicProcedure.query(() => 'bar'),\n  admin: adminRouter,\n});\nCopy\nTIP\n\nSee Error Handling to learn more about the TRPCError thrown in the above example.\n\nLogging​\n\nIn the example below timings for queries are logged automatically.\n\nexport const loggedProcedure = publicProcedure.use(async (opts) => {\n  const start = Date.now();\n \n  const result = await opts.next();\n \n  const durationMs = Date.now() - start;\n  const meta = { path: opts.path, type: opts.type, durationMs };\n \n  result.ok\n    ? console.log('OK request timing:', meta)\n    : console.error('Non-OK request timing', meta);\n \n  return result;\n});\nCopy\nimport { loggedProcedure, router } from './trpc';\n \nexport const appRouter = router({\n  foo: loggedProcedure.query(() => 'bar'),\n  abc: loggedProcedure.query(() => 'def'),\n});\nCopy\nContext Extension​\n\n\"Context Extension\" enables middlewares to dynamically add and override keys on a base procedure's context in a typesafe manner.\n\nBelow we have an example of a middleware that changes properties of a context, the changes are then available to all chained consumers, such as other middlewares and procedures:\n\ntype Context = {\n  // user is nullable\n  user?: {\n    id: string;\n  };\n};\n \nconst protectedProcedure = publicProcedure.use(async function isAuthed(opts) {\n  const { ctx } = opts;\n  // `ctx.user` is nullable\n  if (!ctx.user) {\n            \n(property) user: {\n    id: string;\n} | undefined\n    throw new TRPCError({ code: 'UNAUTHORIZED' });\n  }\n \n  return opts.next({\n    ctx: {\n      // ✅ user value is known to be non-null now\n      user: ctx.user,\n       \n(property) user: {\n    id: string;\n}\n    },\n  });\n});\n \nprotectedProcedure.query((opts) => {\n  const { ctx } = opts;\n  return ctx.user;\n         \nconst ctx: {\n    user: {\n        id: string;\n    };\n}\n});\nCopy\nUsing .concat() to create reusable middlewares and plugins​\nTIP\nCreating middlewares using t.middleware has the limitation that the Context type is tied to the Context type of the tRPC instance.\nCreating middlewares with experimental_standaloneMiddleware() has the limitation that you cannot define input parsers and similar tied to your module.\n\ntRPC has an API called .concat() which allows you to independently define a partial procedure that can be used with any tRPC instance that matches the context and metadata of the plugin.\n\nThis helper primarily targets creating plugins and libraries with tRPC.\n\n// ------------------------------------------------\n// 🧩🧩🧩 a library creating a reusable plugin 🧩🧩🧩\n// @filename: myPlugin.ts\n \nimport { initTRPC, TRPCError } from '@trpc/server';\n \nexport function createMyPlugin() {\n  // When creating a plugin for tRPC, you use the same API as creating any other tRPC-app\n  // this is the plugin's root `t`-object\n  const t = initTRPC\n    .context<{\n      // the procedure using the plugin will need to extend this context\n    }>()\n    .meta<{\n      // the base `initTRPC`-object of the application using this needs to extend this meta\n    }>()\n    .create();\n \n  return {\n    // you can also add `.input()` if you want your plugin to do input validation\n    pluginProc: t.procedure.use((opts) => {\n      return opts.next({\n        ctx: {\n          fromPlugin: 'hello from myPlugin' as const,\n        },\n      });\n    }),\n  };\n}\n// ------------------------------------\n// 🚀🚀🚀 the app using the plugin 🚀🚀🚀\n// @filename: app.ts\nimport { createMyPlugin } from './myPlugin';\nimport { initTRPC, TRPCError } from '@trpc/server';\n \n \n// the app's root `t`-object\nconst t = initTRPC\n  .context<{\n    // ...\n  }>()\n  .create();\n \n \nexport const publicProcedure = t.procedure;\nexport const router = t.router;\n \n// initialize the plugin (a real-world example would likely take options here)\nconst plugin = createMyPlugin();\n \n// create a base procedure using the plugin\nconst procedureWithPlugin = publicProcedure\n  .concat(\n    plugin.pluginProc,\n  )\n  .use(opts => {\n    const { ctx } = opts;\n            \nconst ctx: {\n    fromPlugin: \"hello from myPlugin\";\n}\n    return opts.next()\n  })\n \n \nexport const appRouter = router({\n  hello: procedureWithPlugin.query(opts => {\n    return opts.ctx.fromPlugin;\n  })\n})\nCopy\nExtending middlewares​\nINFO\n\nWe have prefixed this as unstable_ as it's a new API, but you're safe to use it! Read more.\n\nWe have a powerful feature called .pipe() which allows you to extend middlewares in a typesafe manner.\n\nBelow we have an example of a middleware that extends a base middleware(foo). Like the context extension example above, piping middlewares will change properties of the context, and procedures will receive the new context value.\n\nconst fooMiddleware = t.middleware((opts) => {\n  return opts.next({\n    ctx: {\n      foo: 'foo' as const,\n    },\n  });\n});\n \nconst barMiddleware = fooMiddleware.unstable_pipe((opts) => {\n  const { ctx } = opts;\n  ctx.foo;\n      \n(property) foo: \"foo\"\n  return opts.next({\n    ctx: {\n      bar: 'bar' as const,\n    },\n  });\n});\n \nconst barProcedure = publicProcedure.use(barMiddleware);\nbarProcedure.query((opts) => {\n  const { ctx } = opts;\n  return ctx.bar;\n         \nconst ctx: {\n    foo: \"foo\";\n    bar: \"bar\";\n}\n});\nCopy\n\nBeware that the order in which you pipe your middlewares matter and that the context must overlap. An example of a forbidden pipe is shown below. Here, the fooMiddleware overrides the ctx.a while barMiddleware still expects the root context from the initialization in initTRPC - so piping fooMiddleware with barMiddleware would not work, while piping barMiddleware with fooMiddleware does work.\n\nimport { initTRPC } from '@trpc/server';\n \nconst t = initTRPC\n  .context<{\n    a: {\n      b: 'a';\n    };\n  }>()\n  .create();\n \nconst fooMiddleware = t.middleware((opts) => {\n  const { ctx } = opts;\n  ctx.a; // 👈 fooMiddleware expects `ctx.a` to be an object\n     \n(property) a: {\n    b: \"a\";\n}\n  return opts.next({\n    ctx: {\n      a: 'a' as const, // 👈 `ctx.a` is no longer an object\n    },\n  });\n});\n \nconst barMiddleware = t.middleware((opts) => {\n  const { ctx } = opts;\n  ctx.a; // 👈 barMiddleware expects `ctx.a` to be an object\n     \n(property) a: {\n    b: \"a\";\n}\n  return opts.next({\n    ctx: {\n      foo: 'foo' as const,\n    },\n  });\n});\n \n// ❌ `ctx.a` does not overlap from `fooMiddleware` to `barMiddleware`\nfooMiddleware.unstable_pipe(barMiddleware);\n \n// ✅ `ctx.a` overlaps from `barMiddleware` and `fooMiddleware`\nbarMiddleware.unstable_pipe(fooMiddleware);\nCopy\nExperimental: standalone middlewares​\nINFO\n\nThis has been deprecated in favor of .concat()\n\ntRPC has an experimental API called experimental_standaloneMiddleware which allows you to independently define a middleware that can be used with any tRPC instance. Creating middlewares using t.middleware has the limitation that the Context type is tied to the Context type of the tRPC instance. This means that you cannot use the same middleware with multiple tRPC instances that have different Context types.\n\nUsing experimental_standaloneMiddleware you can create a middleware that explicitly defines its requirements, i.e. the Context, Input and Meta types:\n\nimport {\n  experimental_standaloneMiddleware,\n  initTRPC,\n  TRPCError,\n} from '@trpc/server';\nimport * as z from 'zod';\n \nconst projectAccessMiddleware = experimental_standaloneMiddleware<{\n  ctx: { allowedProjects: string[] }; // defaults to 'object' if not defined\n  input: { projectId: string }; // defaults to 'unknown' if not defined\n  // 'meta', not defined here, defaults to 'object | undefined'\n}>().create((opts) => {\n  if (!opts.ctx.allowedProjects.includes(opts.input.projectId)) {\n    throw new TRPCError({\n      code: 'FORBIDDEN',\n      message: 'Not allowed',\n    });\n  }\n \n  return opts.next();\n});\n \nconst t1 = initTRPC\n  .context<{\n    allowedProjects: string[];\n  }>()\n  .create();\n \n// ✅ `ctx.allowedProjects` satisfies \"string[]\" and `input.projectId` satisfies \"string\"\nconst accessControlledProcedure = t1.procedure\n  .input(z.object({ projectId: z.string() }))\n  .use(projectAccessMiddleware);\n \n// ❌ `ctx.allowedProjects` satisfies \"string[]\" but `input.projectId` does not satisfy \"string\"\nconst accessControlledProcedure2 = t1.procedure\n  .input(z.object({ projectId: z.number() }))\n  .use(projectAccessMiddleware);\n \n// ❌ `ctx.allowedProjects` does not satisfy \"string[]\" even though `input.projectId` satisfies \"string\"\nconst t2 = initTRPC\n  .context<{\n    allowedProjects: number[];\n  }>()\n  .create();\n \nconst accessControlledProcedure3 = t2.procedure\n  .input(z.object({ projectId: z.string() }))\n  .use(projectAccessMiddleware);\nCopy\n\nHere is an example with multiple standalone middlewares:\n\nimport { experimental_standaloneMiddleware, initTRPC } from '@trpc/server';\nimport * as z from 'zod';\n \nconst t = initTRPC.create();\nconst schemaA = z.object({ valueA: z.string() });\nconst schemaB = z.object({ valueB: z.string() });\n \nconst valueAUppercaserMiddleware = experimental_standaloneMiddleware<{\n  input: z.infer<typeof schemaA>;\n}>().create((opts) => {\n  return opts.next({\n    ctx: { valueAUppercase: opts.input.valueA.toUpperCase() },\n  });\n});\n \nconst valueBUppercaserMiddleware = experimental_standaloneMiddleware<{\n  input: z.infer<typeof schemaB>;\n}>().create((opts) => {\n  return opts.next({\n    ctx: { valueBUppercase: opts.input.valueB.toUpperCase() },\n  });\n});\n \nconst combinedInputThatSatisfiesBothMiddlewares = z.object({\n  valueA: z.string(),\n  valueB: z.string(),\n  extraProp: z.string(),\n});\n \nt.procedure\n  .input(combinedInputThatSatisfiesBothMiddlewares)\n  .use(valueAUppercaserMiddleware)\n  .use(valueBUppercaserMiddleware)\n  .query(\n    ({\n      input: { valueA, valueB, extraProp },\n      ctx: { valueAUppercase, valueBUppercase },\n    }) =>\n      `valueA: ${valueA}, valueB: ${valueB}, extraProp: ${extraProp}, valueAUppercase: ${valueAUppercase}, valueBUppercase: ${valueBUppercase}`,\n  );\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/adapters",
    "html": "Backend Usage\nHosting tRPC with Adapters\nVersion: 11.x\nAdapters\n\ntRPC is not a server on its own, and must therefore be served using other hosts, such as a simple Node.js HTTP Server, Express, or even Next.js. Most tRPC features are the same no matter which backend you choose. Adapters act as the glue between the host system and your tRPC API.\n\nAdapters typically follow some common conventions, allowing you to set up context creation via createContext, and globally handle errors via onError, but importantly allow you to choose an appropriate host for your application.\n\nWe support many modes of hosting an API, which you will find documented here.\n\nFor serverful APIs, you might want our Standalone adapter, or use the Express or Fastify adapters to hook into your existing APIs\nYou might want a serverless solution and choose AWS Lambda, or Fetch for edge runtimes\nYou might have a full-stack framework and want a full integration like Next.js, or you could use the Fetch adapter with Next.js, Astro, Remix, or SolidStart\nTIP\n\nFor local development or serverful infrastructure, the simplest Adapter to use is the Standalone Adapter, which can be used to run a standard Node.js HTTP Server. We recommend this when you need to get started quickly and have no existing HTTP Server to integrate with. Swapping out later is trivial if your needs change.\n\nEdit this page"
  },
  {
    "title": "Server Side Calls | tRPC",
    "url": "https://trpc.io/docs/server/server-side-calls",
    "html": "Backend Usage\nServer Side Calls\nVersion: 11.x\nServer Side Calls\n\nYou may need to call your procedure(s) directly from the same server they're hosted in, createCallerFactory() can be used to achieve this. This is useful for server-side calls and for integration testing of your tRPC procedures.\n\nINFO\n\ncreateCaller should not be used to call procedures from within other procedures. This creates overhead by (potentially) creating context again, executing all middlewares, and validating the input - all of which were already done by the current procedure. Instead, you should extract the shared logic into a separate function and call that from within the procedures, like so:\n\nCreate caller​\n\nWith the t.createCallerFactory-function you can create a server-side caller of any router. You first call createCallerFactory with an argument of the router you want to call, then this returns a function where you can pass in a Context for the following procedure calls.\n\nBasic example​\n\nWe create the router with a query to list posts and a mutation to add posts, and then we a call each method.\n\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \ntype Context = {\n  foo: string;\n};\n \nconst t = initTRPC.context<Context>().create();\n \nconst publicProcedure = t.procedure;\nconst { createCallerFactory, router } = t;\n \ninterface Post {\n  id: string;\n  title: string;\n}\nconst posts: Post[] = [\n  {\n    id: '1',\n    title: 'Hello world',\n  },\n];\nconst appRouter = router({\n  post: router({\n    add: publicProcedure\n      .input(\n        z.object({\n          title: z.string().min(2),\n        }),\n      )\n      .mutation((opts) => {\n        const post: Post = {\n          ...opts.input,\n          id: `${Math.random()}`,\n        };\n        posts.push(post);\n        return post;\n      }),\n    list: publicProcedure.query(() => posts),\n  }),\n});\n \n// 1. create a caller-function for your router\nconst createCaller = createCallerFactory(appRouter);\n \n// 2. create a caller using your `Context`\nconst caller = createCaller({\n  foo: 'bar',\n});\n \n// 3. use the caller to add and list posts\nconst addedPost = await caller.post.add({\n  title: 'How to make server-side call in tRPC',\n});\n \nconst postList = await caller.post.list();\n         \nconst postList: Post[]\nCopy\nExample usage in an integration test​\n\nTaken from https://github.com/trpc/examples-next-prisma-starter/blob/main/src/server/routers/post.test.ts\n\nimport { inferProcedureInput } from '@trpc/server';\nimport { createContextInner } from '../context';\nimport { AppRouter, createCaller } from './_app';\ntest('add and get post', async () => {\n  const ctx = await createContextInner({});\n  const caller = createCaller(ctx);\n  const input: inferProcedureInput<AppRouter['post']['add']> = {\n    text: 'hello test',\n    title: 'hello test',\n  };\n  const post = await caller.post.add(input);\n  const byId = await caller.post.byId({ id: post.id });\n  expect(byId).toMatchObject(input);\n});\nCopy\nrouter.createCaller()​\n\nWith the router.createCaller({}) function (first argument is Context) we retrieve an instance of RouterCaller.\n\nInput query example​\n\nWe create the router with an input query, and then we call the asynchronous greeting procedure to get the result.\n\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \nconst t = initTRPC.create();\n \nconst router = t.router({\n  // Create procedure at path 'greeting'\n  greeting: t.procedure\n    .input(z.object({ name: z.string() }))\n    .query((opts) => `Hello ${opts.input.name}`),\n});\n \nconst caller = router.createCaller({});\nconst result = await caller.greeting({ name: 'tRPC' });\n        \nconst result: string\nCopy\nMutation example​\n\nWe create the router with a mutation, and then we call the asynchronous post procedure to get the result.\n\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \nconst posts = ['One', 'Two', 'Three'];\n \nconst t = initTRPC.create();\nconst router = t.router({\n  post: t.router({\n    add: t.procedure.input(z.string()).mutation((opts) => {\n      posts.push(opts.input);\n      return posts;\n    }),\n  }),\n});\n \nconst caller = router.createCaller({});\nconst result = await caller.post.add('Four');\n        \nconst result: string[]\nCopy\nContext with middleware example​\n\nWe create a middleware to check the context before executing the secret procedure. Below are two examples: the former fails because the context doesn't fit the middleware logic, and the latter works correctly.\n\n\n\nINFO\n\nMiddlewares are performed before any procedure(s) are called.\n\n\n\nimport { initTRPC, TRPCError } from '@trpc/server';\n \ntype Context = {\n  user?: {\n    id: string;\n  };\n};\nconst t = initTRPC.context<Context>().create();\n \nconst protectedProcedure = t.procedure.use((opts) => {\n  const { ctx } = opts;\n  if (!ctx.user) {\n    throw new TRPCError({\n      code: 'UNAUTHORIZED',\n      message: 'You are not authorized',\n    });\n  }\n \n  return opts.next({\n    ctx: {\n      // Infers that the `user` is non-nullable\n      user: ctx.user,\n    },\n  });\n});\n \nconst router = t.router({\n  secret: protectedProcedure.query((opts) => opts.ctx.user),\n});\n \n{\n  // ❌ this will return an error because there isn't the right context param\n  const caller = router.createCaller({});\n \n  const result = await caller.secret();\n}\n \n{\n  // ✅ this will work because user property is present inside context param\n  const authorizedCaller = router.createCaller({\n    user: {\n      id: 'KATT',\n    },\n  });\n  const result = await authorizedCaller.secret();\n          \nconst result: {\n    id: string;\n}\n}\nCopy\nExample for a Next.js API endpoint​\nTIP\n\nThis example shows how to use the caller in a Next.js API endpoint. tRPC creates API endpoints for you already, so this file is only meant to show how to call a procedure from another, custom endpoint.\n\nimport { TRPCError } from '@trpc/server';\nimport { getHTTPStatusCodeFromError } from '@trpc/server/http';\nimport { appRouter } from '~/server/routers/_app';\nimport type { NextApiRequest, NextApiResponse } from 'next';\n \ntype ResponseData = {\n  data?: {\n    postTitle: string;\n  };\n  error?: {\n    message: string;\n  };\n};\n \nexport default async (\n  req: NextApiRequest,\n  res: NextApiResponse<ResponseData>,\n) => {\n  /** We want to simulate an error, so we pick a post ID that does not exist in the database. */\n  const postId = `this-id-does-not-exist-${Math.random()}`;\n \n  const caller = appRouter.createCaller({});\n \n  try {\n    // the server-side call\n    const postResult = await caller.post.byId({ id: postId });\n \n    res.status(200).json({ data: { postTitle: postResult.title } });\n  } catch (cause) {\n    // If this a tRPC error, we can extract additional information.\n    if (cause instanceof TRPCError) {\n      // We can get the specific HTTP status code coming from tRPC (e.g. 404 for `NOT_FOUND`).\n      const httpStatusCode = getHTTPStatusCodeFromError(cause);\n \n      res.status(httpStatusCode).json({ error: { message: cause.message } });\n      return;\n    }\n \n    // This is not a tRPC error, so we don't have specific information.\n    res.status(500).json({\n      error: { message: `Error while accessing post with ID ${postId}` },\n    });\n  }\n};\nCopy\nError handling​\n\nThe createFactoryCaller and the createCaller function can take an error handler through the onError option. This can be used to throw errors that are not wrapped in a TRPCError, or respond to errors in some other way. Any handler passed to createCallerFactory will be called before the handler passed to createCaller. The handler is called with the same arguments as an error formatter would be, except for the shape field:\n\n{\n  ctx: unknown; // The request context\n  error: TRPCError; // The TRPCError that was thrown\n  path: string | undefined; // The path of the procedure that threw the error\n  input: unknown; // The input that was passed to the procedure\n  type: 'query' | 'mutation' | 'subscription' | 'unknown'; // The type of the procedure that threw the error\n}\nCopy\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \nconst t = initTRPC\n  .context<{\n    foo?: 'bar';\n  }>()\n  .create();\n \nconst router = t.router({\n  greeting: t.procedure.input(z.object({ name: z.string() })).query((opts) => {\n    if (opts.input.name === 'invalid') {\n      throw new Error('Invalid name');\n    }\n \n    return `Hello ${opts.input.name}`;\n  }),\n});\n \nconst caller = router.createCaller(\n  {\n    /* context */\n  },\n  {\n    onError: (opts) => {\n      console.error('An error occurred:', opts.error);\n    },\n  },\n);\n \n// The following will log \"An error occurred: Error: Invalid name\", and then throw a plain error\n//  with the message \"This is a custom error\"\nawait caller.greeting({ name: 'invalid' });\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/authorization",
    "html": "Backend Usage\nAuthorization\nVersion: 11.x\nAuthorization\n\nThe createContext function is called for each incoming request, so here you can add contextual information about the calling user from the request object.\n\nCreate context from request headers​\nserver/context.ts\nimport * as trpcNext from '@trpc/server/adapters/next';\nimport { decodeAndVerifyJwtToken } from './somewhere/in/your/app/utils';\nexport async function createContext({\n  req,\n  res,\n}: trpcNext.CreateNextContextOptions) {\n  // Create your context based on the request object\n  // Will be available as `ctx` in all your resolvers\n  // This is just an example of something you might want to do in your ctx fn\n  async function getUserFromHeader() {\n    if (req.headers.authorization) {\n      const user = await decodeAndVerifyJwtToken(\n        req.headers.authorization.split(' ')[1],\n      );\n      return user;\n    }\n    return null;\n  }\n  const user = await getUserFromHeader();\n  return {\n    user,\n  };\n}\nexport type Context = Awaited<ReturnType<typeof createContext>>;\nCopy\nOption 1: Authorize using resolver​\nserver/routers/_app.ts\nimport { initTRPC, TRPCError } from '@trpc/server';\nimport type { Context } from '../context';\nexport const t = initTRPC.context<Context>().create();\nconst appRouter = t.router({\n  // open for anyone\n  hello: t.procedure\n    .input(z.string().nullish())\n    .query((opts) => `hello ${opts.input ?? opts.ctx.user?.name ?? 'world'}`),\n  // checked in resolver\n  secret: t.procedure.query((opts) => {\n    if (!opts.ctx.user) {\n      throw new TRPCError({ code: 'UNAUTHORIZED' });\n    }\n    return {\n      secret: 'sauce',\n    };\n  }),\n});\nCopy\nOption 2: Authorize using middleware​\nserver/routers/_app.ts\nimport { initTRPC, TRPCError } from '@trpc/server';\nimport type { Context } from '../context';\nexport const t = initTRPC.context<Context>().create();\n// you can reuse this for any procedure\nexport const protectedProcedure = t.procedure.use(\n  async function isAuthed(opts) {\n    const { ctx } = opts;\n    // `ctx.user` is nullable\n    if (!ctx.user) {\n      //     ^?\n      throw new TRPCError({ code: 'UNAUTHORIZED' });\n    }\n    return opts.next({\n      ctx: {\n        // ✅ user value is known to be non-null now\n        user: ctx.user,\n        // ^?\n      },\n    });\n  },\n);\nt.router({\n  // this is accessible for everyone\n  hello: t.procedure\n    .input(z.string().nullish())\n    .query((opts) => `hello ${opts.input ?? opts.ctx.user?.name ?? 'world'}`),\n  admin: t.router({\n    // this is accessible only to admins\n    secret: protectedProcedure.query((opts) => {\n      return {\n        secret: 'sauce',\n      };\n    }),\n  }),\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/error-handling",
    "html": "Backend Usage\nError Handling\nVersion: 11.x\nError Handling\n\nWhenever an error occurs in a procedure, tRPC responds to the client with an object that includes an \"error\" property. This property contains all the information that you need to handle the error in the client.\n\nHere's an example error response caused by a bad request input:\n\n{\n  \"id\": null,\n  \"error\": {\n    \"message\": \"\\\"password\\\" must be at least 4 characters\",\n    \"code\": -32600,\n    \"data\": {\n      \"code\": \"BAD_REQUEST\",\n      \"httpStatus\": 400,\n      \"stack\": \"...\",\n      \"path\": \"user.changepassword\"\n    }\n  }\n}\nCopy\n\nNote: the returned stack trace is only available in the development environment.\n\nError codes​\n\ntRPC defines a list of error codes that each represent a different type of error and response with a different HTTP code.\n\nCode\tDescription\tHTTP code\nBAD_REQUEST\tThe server cannot or will not process the request due to something that is perceived to be a client error.\t400\nUNAUTHORIZED\tThe client request has not been completed because it lacks valid authentication credentials for the requested resource.\t401\nPAYMENT_REQUIRED\tThe client request requires payment to access the requested resource.\t402\nFORBIDDEN\tThe server was unauthorized to access a required data source, such as a REST API.\t403\nNOT_FOUND\tThe server cannot find the requested resource.\t404\nMETHOD_NOT_SUPPORTED\tThe server knows the request method, but the target resource doesn't support this method.\t405\nTIMEOUT\tThe server would like to shut down this unused connection.\t408\nCONFLICT\tThe server request resource conflict with the current state of the target resource.\t409\nPRECONDITION_FAILED\tAccess to the target resource has been denied.\t412\nPAYLOAD_TOO_LARGE\tRequest entity is larger than limits defined by server.\t413\nUNSUPPORTED_MEDIA_TYPE\tThe server refuses to accept the request because the payload format is in an unsupported format.\t415\nUNPROCESSABLE_CONTENT\tThe server understands the request method, and the request entity is correct, but the server was unable to process it.\t422\nPRECONDITION_REQUIRED\tThe server cannot process the request because a required precondition header (such as If-Match) is missing. When a precondition header does not match the server-side state, the response should be 412 Precondition Failed.\t428\nTOO_MANY_REQUESTS\tThe rate limit has been exceeded or too many requests are being sent to the server.\t429\nCLIENT_CLOSED_REQUEST\tAccess to the resource has been denied.\t499\nINTERNAL_SERVER_ERROR\tAn unspecified error occurred.\t500\nNOT_IMPLEMENTED\tThe server does not support the functionality required to fulfill the request.\t501\nBAD_GATEWAY\tThe server received an invalid response from the upstream server.\t502\nSERVICE_UNAVAILABLE\tThe server is not ready to handle the request.\t503\nGATEWAY_TIMEOUT\tThe server did not get a response in time from the upstream server that it needed in order to complete the request.\t504\n\ntRPC exposes a helper function, getHTTPStatusCodeFromError, to help you extract the HTTP code from the error:\n\nimport { getHTTPStatusCodeFromError } from '@trpc/server/http';\n \n// Example error you might get if your input validation fails\nconst error: TRPCError = {\n  name: 'TRPCError',\n  code: 'BAD_REQUEST',\n  message: '\"password\" must be at least 4 characters',\n};\n \nif (error instanceof TRPCError) {\n  const httpCode = getHTTPStatusCodeFromError(error);\n  console.log(httpCode); // 400\n}\nCopy\nTIP\n\nThere's a full example of how this could be used in a Next.js API endpoint in the Server Side Calls docs.\n\nThrowing errors​\n\ntRPC provides an error subclass, TRPCError, which you can use to represent an error that occurred inside a procedure.\n\nFor example, throwing this error:\n\nserver.ts\nimport { initTRPC, TRPCError } from '@trpc/server';\nconst t = initTRPC.create();\nconst appRouter = t.router({\n  hello: t.procedure.query(() => {\n    throw new TRPCError({\n      code: 'INTERNAL_SERVER_ERROR',\n      message: 'An unexpected error occurred, please try again later.',\n      // optional: pass the original error to retain stack trace\n      cause: theError,\n    });\n  }),\n});\n// [...]\nCopy\n\nResults to the following response:\n\n{\n  \"id\": null,\n  \"error\": {\n    \"message\": \"An unexpected error occurred, please try again later.\",\n    \"code\": -32603,\n    \"data\": {\n      \"code\": \"INTERNAL_SERVER_ERROR\",\n      \"httpStatus\": 500,\n      \"stack\": \"...\",\n      \"path\": \"hello\"\n    }\n  }\n}\nCopy\nHandling errors​\n\nAll errors that occur in a procedure go through the onError method before being sent to the client. Here you can handle errors (To change errors see error formatting).\n\npages/api/trpc/[trpc].ts\nexport default trpcNext.createNextApiHandler({\n  // ...\n  onError(opts) {\n    const { error, type, path, input, ctx, req } = opts;\n    console.error('Error:', error);\n    if (error.code === 'INTERNAL_SERVER_ERROR') {\n      // send to bug reporting\n    }\n  },\n});\nCopy\n\nThe onError parameter is an object that contains all information about the error and the context it occurs in:\n\n{\n  error: TRPCError; // the original error\n  type: 'query' | 'mutation' | 'subscription' | 'unknown';\n  path: string | undefined; // path of the procedure that was triggered\n  input: unknown;\n  ctx: Context | undefined;\n  req: BaseRequest; // request object\n}\nCopy\nEdit this page"
  },
  {
    "title": "Error Formatting | tRPC",
    "url": "https://trpc.io/docs/server/error-formatting",
    "html": "Backend Usage\nError Formatting\nVersion: 11.x\nError Formatting\n\nThe error formatting in your router will be inferred all the way to your client (& React components)\n\nUsage example highlighted​\nAdding custom formatting​\nserver.ts\nimport { initTRPC } from '@trpc/server';\nexport const t = initTRPC.context<Context>().create({\n  errorFormatter(opts) {\n    const { shape, error } = opts;\n    return {\n      ...shape,\n      data: {\n        ...shape.data,\n        zodError:\n          error.code === 'BAD_REQUEST' && error.cause instanceof ZodError\n            ? error.cause.flatten()\n            : null,\n      },\n    };\n  },\n});\nCopy\nUsage in React​\ncomponents/MyComponent.tsx\nexport function MyComponent() {\n  const mutation = trpc.addPost.useMutation();\n  useEffect(() => {\n    mutation.mutate({ title: 'example' });\n  }, []);\n  if (mutation.error?.data?.zodError) {\n    // zodError will be inferred\n    return (\n      <pre>Error: {JSON.stringify(mutation.error.data.zodError, null, 2)}</pre>\n    );\n  }\n  return <>[...]</>;\n}\nCopy\nAll properties sent to errorFormatter()​\n\nSince v8.x tRPC is compliant with JSON-RPC 2.0\n\n{\n  error: TRPCError;\n  type: ProcedureType | 'unknown';\n  path: string | undefined;\n  input: unknown;\n  ctx: undefined | TContext;\n  shape: DefaultErrorShape; // the default error shape\n}\nCopy\n\nDefaultErrorShape:\n\ntype DefaultErrorData = {\n  code: TRPC_ERROR_CODE_KEY;\n  httpStatus: number;\n  /**\n   * Path to the procedure that threw the error\n   */\n  path?: string;\n  /**\n   * Stack trace of the error (only in development)\n   */\n  stack?: string;\n};\ninterface DefaultErrorShape {\n  message: string;\n  code: TRPC_ERROR_CODE_NUMBER;\n  data: DefaultErrorData;\n}\nCopy\nEdit this page"
  },
  {
    "title": "Data Transformers | tRPC",
    "url": "https://trpc.io/docs/server/data-transformers",
    "html": "Backend Usage\nData Transformers\nVersion: 11.x\nData Transformers\n\nYou are able to serialize the response data & input args. The transformers need to be added both to the server and the client.\n\nUsing superjson​\n\nSuperJSON allows us to transparently use, e.g., standard Date/Map/Sets over the wire between the server and client. That is, you can return any of these types from your API-resolver and use them in the client without having to recreate the objects from JSON.\n\nHow to​\n1. Install​\nyarn add superjson\nCopy\n2. Add to your initTRPC​\nrouters/router/_app.ts\nimport { initTRPC } from '@trpc/server';\nimport superjson from 'superjson';\nexport const t = initTRPC.create({\n  transformer: superjson,\n});\nCopy\n3. Add to httpLink(), wsLink(), etc​\n\nTypeScript will guide you to where you need to add transformer as soon as you've added it on the initTRPC-object\n\ncreateTRPCClient():\n\nsrc/app/_trpc/client.ts\nimport { createTRPCClient } from '@trpc/client';\nimport type { AppRouter } from '~/server/routers/_app';\nimport superjson from 'superjson';\nexport const client = createTRPCClient<AppRouter>({\n  links: [\n    httpLink({\n      url: 'http://localhost:3000',\n      transformer: superjson,\n    }),\n  ],\n});\nCopy\nUsing devalue​\n\nDevalue works like superjson, but focus in performance and compact payloads, but at the cost of a less human readable body.\n\nHow to​\n1. Install​\nyarn add superjson devalue\nCopy\n2. Add to utils/trpc.ts​\n\nHere we use parse and stringify as they mitigate XSS.\n\nutils/trpc.ts\nimport { parse, stringify } from 'devalue';\n// [...]\nexport const transformer = {\n  deserialize: (object: any) => parse(object),\n  serialize: (object: any) => stringify(object),\n};\nCopy\n3. Add to your initTRPC​\nserver/routers/_app.ts\nimport { initTRPC } from '@trpc/server';\nimport { transformer } from '../../utils/trpc';\nexport const t = initTRPC.create({\n  transformer,\n});\nCopy\n4. Add to httpLink(), wsLink(), etc​\n\nTypeScript will guide you to where you need to add transformer as soon as you've added it on the initTRPC-object\n\ncreateTRPCClient():\n\nsrc/app/_trpc/client.ts\nimport { createTRPCClient } from '@trpc/client';\nimport type { AppRouter } from '~/server/routers/_app';\nimport { transformer } from '../../utils/trpc';\nexport const client = createTRPCClient<AppRouter>({\n  links: [\n    httpLink({\n      url: 'http://localhost:3000',\n      transformer,\n    }),\n  ],\n});\nCopy\nDifferent transformers for upload and download​\n\nIf a transformer should only be used for one direction or different transformers should be used for upload and download (e.g., for performance reasons), you can provide individual transformers for upload and download. Make sure you use the same combined transformer everywhere.\n\nDataTransformer interface​\nexport interface DataTransformer {\n  serialize(object: any): any;\n  deserialize(object: any): any;\n}\ninterface InputDataTransformer extends DataTransformer {\n  /**\n   * This function runs **on the client** before sending the data to the server.\n   */\n  serialize(object: any): any;\n  /**\n   * This function runs **on the server** to transform the data before it is passed to the resolver\n   */\n  deserialize(object: any): any;\n}\ninterface OutputDataTransformer extends DataTransformer {\n  /**\n   * This function runs **on the server** before sending the data to the client.\n   */\n  serialize(object: any): any;\n  /**\n   * This function runs **only on the client** to transform the data sent from the server.\n   */\n  deserialize(object: any): any;\n}\nexport interface CombinedDataTransformer {\n  /**\n   * Specify how the data sent from the client to the server should be transformed.\n   */\n  input: InputDataTransformer;\n  /**\n   * Specify how the data sent from the server to the client should be transformed.\n   */\n  output: OutputDataTransformer;\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/metadata",
    "html": "Backend Usage\nMetadata\nVersion: 11.x\nMetadata\n\nProcedure metadata allows you to add an optional procedure specific meta property which will be available in all middleware function parameters.\n\nTIP\n\nUse metadata together with trpc-openapi if you want to expose REST-compatible endpoints for your application.\n\nCreate router with typed metadata​\nimport { initTRPC } from '@trpc/server';\n// [...]\ninterface Meta {\n  authRequired: boolean;\n}\nexport const t = initTRPC.context<Context>().meta<Meta>().create();\nexport const appRouter = t.router({\n  // [...]\n});\nCopy\nExample with per route authentication settings​\nserver.ts\nimport { initTRPC } from '@trpc/server';\n// [...]\ninterface Meta {\n  authRequired: boolean;\n}\nexport const t = initTRPC.context<Context>().meta<Meta>().create();\nexport const authedProcedure = t.procedure.use(async (opts) => {\n  const { meta, next, ctx } = opts;\n  // only check authorization if enabled\n  if (meta?.authRequired && !ctx.user) {\n    throw new TRPCError({ code: 'UNAUTHORIZED' });\n  }\n  return next();\n});\nexport const appRouter = t.router({\n  hello: authedProcedure.meta({ authRequired: false }).query(() => {\n    return {\n      greeting: 'hello world',\n    };\n  }),\n  protectedHello: authedProcedure.meta({ authRequired: true }).query(() => {\n    return {\n      greeting: 'hello-world',\n    };\n  }),\n});\nCopy\nDefault meta, chaining, and shallow merging​\n\nYou can set default values for your meta type, and if you chain meta on top of a base procedure it will be shallow merged.\n\nimport { initTRPC } from '@trpc/server';\ninterface Meta {\n  authRequired: boolean;\n  role?: 'user' | 'admin'\n}\nexport const t = initTRPC\n  .context<Context>()\n  .meta<Meta>()\n  .create({\n    // Set a default value\n    defaultMeta: { authRequired: false }\n  });\nconst publicProcedure = t.procedure\n// ^ Default Meta: { authRequired: false }\nconst authProcedure = publicProcedure\n  .use(authMiddleware)\n  .meta({\n    authRequired: true;\n    role: 'user'\n  });\n// ^ Meta: { authRequired: true, role: 'user' }\nconst adminProcedure = authProcedure\n  .meta({\n    role: 'admin'\n  });\n// ^ Meta: { authRequired: true, role: 'admin' }\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/caching",
    "html": "Backend Usage\nResponse Caching\nVersion: 11.x\nResponse Caching\n\nThe below examples uses Vercel's edge caching to serve data to your users as fast as possible.\n\nINFO\n\nAlways be careful with caching - especially if you handle personal information.\n\n \nSince batching is enabled by default, it's recommended to set your cache headers in the responseMeta function and make sure that there are not any concurrent calls that may include personal data - or to omit cache headers completely if there is an auth header or cookie.\n\n \nYou can also use a splitLink to split your public requests and those that should be private and uncached.\n\nApp Caching​\n\nIf you turn on SSR in your app, you might discover that your app loads slowly on, for instance, Vercel, but you can actually statically render your whole app without using SSG; read this Twitter thread for more insights.\n\nExample code​\nutils/trpc.tsx\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport type { AppRouter } from '../server/routers/_app';\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    if (typeof window !== 'undefined') {\n      return {\n        links: [\n          httpBatchLink({\n            url: '/api/trpc',\n          }),\n        ],\n      };\n    }\n    const url = process.env.VERCEL_URL\n      ? `https://${process.env.VERCEL_URL}/api/trpc`\n      : 'http://localhost:3000/api/trpc';\n    return {\n      links: {\n        http: httpBatchLink({\n          url,\n        }),\n      },\n    };\n  },\n  ssr: true,\n  responseMeta(opts) {\n    const { clientErrors } = opts;\n    if (clientErrors.length) {\n      // propagate http first error from API calls\n      return {\n        status: clientErrors[0].data?.httpStatus ?? 500,\n      };\n    }\n    // cache request for 1 day + revalidate once every second\n    const ONE_DAY_IN_SECONDS = 60 * 60 * 24;\n    return {\n      headers: new Headers([\n        [\n          'cache-control',\n          `s-maxage=1, stale-while-revalidate=${ONE_DAY_IN_SECONDS}`,\n        ],\n      ]),\n    };\n  },\n});\nCopy\nAPI Response caching​\n\nSince all queries are normal HTTP GETs, we can use normal HTTP headers to cache responses, make the responses snappy, give your database a rest, and easily scale your API to gazillions of users.\n\nUsing responseMeta to cache responses​\n\nAssuming you're deploying your API somewhere that can handle stale-while-revalidate cache headers like Vercel.\n\nserver.ts\nimport { initTRPC } from '@trpc/server';\nimport * as trpcNext from '@trpc/server/adapters/next';\nexport const createContext = async ({\n  req,\n  res,\n}: trpcNext.CreateNextContextOptions) => {\n  return {\n    req,\n    res,\n    prisma,\n  };\n};\ntype Context = Awaited<ReturnType<typeof createContext>>;\nexport const t = initTRPC.context<Context>().create();\nconst waitFor = async (ms: number) =>\n  new Promise((resolve) => setTimeout(resolve, ms));\nexport const appRouter = t.router({\n  public: t.router({\n    slowQueryCached: t.procedure.query(async (opts) => {\n      await waitFor(5000); // wait for 5s\n      return {\n        lastUpdated: new Date().toJSON(),\n      };\n    }),\n  }),\n});\n// Exporting type _type_ AppRouter only exposes types that can be used for inference\n// https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-8.html#type-only-imports-and-export\nexport type AppRouter = typeof appRouter;\n// export API handler\nexport default trpcNext.createNextApiHandler({\n  router: appRouter,\n  createContext,\n  responseMeta(opts) {\n    const { ctx, paths, errors, type } = opts;\n    // assuming you have all your public routes with the keyword `public` in them\n    const allPublic = paths && paths.every((path) => path.includes('public'));\n    // checking that no procedures errored\n    const allOk = errors.length === 0;\n    // checking we're doing a query request\n    const isQuery = type === 'query';\n    if (ctx?.res && allPublic && allOk && isQuery) {\n      // cache request for 1 day + revalidate once every second\n      const ONE_DAY_IN_SECONDS = 60 * 60 * 24;\n      return {\n        headers: new Headers([\n          [\n            'cache-control',\n            `s-maxage=1, stale-while-revalidate=${ONE_DAY_IN_SECONDS}`,\n          ],\n        ]),\n      };\n    }\n    return {};\n  },\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/subscriptions",
    "html": "Backend Usage\nSubscriptions\nVersion: 11.x\nSubscriptions\nIntroduction​\n\nSubscriptions are a type of real-time event stream between the client and server. Use subscriptions when you need to push real-time updates to the client.\n\nWith tRPC's subscriptions, the client establishes and maintains a persistent connection to the server plus automatically attempts to reconnect and recover gracefully if disconnected with the help of tracked() events.\n\nWebSockets or Server-sent Events?​\n\nYou can either use WebSockets or Server-sent Events (SSE) to setup real-time subscriptions in tRPC.\n\nFor WebSockets, see the WebSockets page\nFor SSE, see the httpSubscriptionLink\n\nIf you are unsure which one to use, we recommend using SSE for subscriptions as it's easier to setup and don't require setting up a WebSocket server.\n\nReference projects​\nType\tExample Type\tLink\nWebSockets\tBare-minimum Node.js WebSockets example\t/examples/standalone-server\nSSE\tFull-stack SSE implementation\tgithub.com/trpc/examples-next-sse-chat\nWebSockets\tFull-stack WebSockets implementation\tgithub.com/trpc/examples-next-prisma-websockets-starter\nBasic example​\nTIP\n\nFor a full example, see our full-stack SSE example.\n\nserver.ts\nimport { initTRPC } from '@trpc/server';\nconst t = initTRPC.create();\nconst ee = new EventEmitter();\nexport const appRouter = router({\n  onPostAdd: publicProcedure.subscription(async function* (opts) {\n    // listen for new events\n    for await (const [data] of on(ee, 'add', {\n      // Passing the AbortSignal from the request automatically cancels the event emitter when the request is aborted\n      signal: opts.signal,\n    })) {\n      const post = data as Post;\n      yield post;\n    }\n  }),\n});\nCopy\nAutomatic tracking of id using tracked() (recommended)​\n\nIf you yield an event using our tracked()-helper and include an id, the client will automatically reconnect when it gets disconnected and send the last known ID.\n\nYou can send an initial lastEventId when initializing the subscription and it will be automatically updated as the browser receives data.\n\nFor SSE, this is part of the EventSource-spec and will be propagated through lastEventId in your .input().\nFor WebSockets, our wsLink will automatically send the last known ID and update it as the browser receives data.\nTIP\n\nIf you're fetching data based on the lastEventId, and capturing all events is critical, make sure you setup the event listener before fetching events from your database as is done in our full-stack SSE example, this can prevent newly emitted events being ignored while yield'ing the original batch based on lastEventId.\n\nimport EventEmitter, { on } from 'events';\nimport type { Post } from '@prisma/client';\nimport { tracked } from '@trpc/server';\nimport { z } from 'zod';\nimport { publicProcedure, router } from '../trpc';\nconst ee = new EventEmitter();\nexport const subRouter = router({\n  onPostAdd: publicProcedure\n    .input(\n      z\n        .object({\n          // lastEventId is the last event id that the client has received\n          // On the first call, it will be whatever was passed in the initial setup\n          // If the client reconnects, it will be the last event id that the client received\n          lastEventId: z.string().nullish(),\n        })\n        .optional(),\n    )\n    .subscription(async function* (opts) {\n      // We start by subscribing to the ee so that we don't miss any new events while fetching\n      const iterable = ee.toIterable('add', {\n        // Passing the AbortSignal from the request automatically cancels the event emitter when the request is aborted\n        signal: opts.signal,\n      });\n      if (opts.input.lastEventId) {\n        // [...] get the posts since the last event id and yield them\n        // const items = await db.post.findMany({ ... })\n        // for (const item of items) {\n        //   yield tracked(item.id, item);\n        // }\n      }\n      // listen for new events\n      for await (const [data] of on(ee, 'add', {\n        signal: opts.signal,\n      })) {\n        const post = data as Post;\n        // tracking the post id ensures the client can reconnect at any time and get the latest events this id\n        yield tracked(post.id, post);\n      }\n    }),\n});\nCopy\nPull data in a loop​\n\nThis recipe is useful when you want to periodically check for new data from a source like a database and push it to the client.\n\nserver.ts\nimport type { Post } from '@prisma/client';\nimport { tracked } from '@trpc/server';\nimport { z } from 'zod';\nimport { publicProcedure, router } from '../trpc';\nexport const subRouter = router({\n  onPostAdd: publicProcedure\n    .input(\n      z.object({\n        // lastEventId is the last event id that the client has received\n        // On the first call, it will be whatever was passed in the initial setup\n        // If the client reconnects, it will be the last event id that the client received\n        // The id is the createdAt of the post\n        lastEventId: z.coerce.date().nullish(),\n      }),\n    )\n    .subscription(async function* (opts) {\n      // `opts.signal` is an AbortSignal that will be aborted when the client disconnects.\n      let lastEventId = opts.input?.lastEventId ?? null;\n      // We use a `while` loop that checks `!opts.signal.aborted`\n      while (!opts.signal!.aborted) {\n        const posts = await db.post.findMany({\n          // If we have a `lastEventId`, we only fetch posts created after it.\n          where: lastEventId\n            ? {\n                createdAt: {\n                  gt: lastEventId,\n                },\n              }\n            : undefined,\n          orderBy: {\n            createdAt: 'asc',\n          },\n        });\n        for (const post of posts) {\n          // `tracked` is a helper that sends an `id` with each event.\n          // This allows the client to resume from the last received event upon reconnection.\n          yield tracked(post.createdAt.toJSON(), post);\n          lastEventId = post.createdAt;\n        }\n        // Wait for a bit before polling again to avoid hammering the database.\n        await sleep(1_000);\n      }\n    }),\n});\nCopy\nStopping a subscription from the server​\n\nIf you need to stop a subscription from the server, simply return in the generator function.\n\nimport { publicProcedure, router } from '../trpc';\nexport const subRouter = router({\n  onPostAdd: publicProcedure\n    .input(\n      z.object({\n        lastEventId: z.string().coerce.number().min(0).optional(),\n      }),\n    )\n    .subscription(async function* (opts) {\n      let index = opts.input.lastEventId ?? 0;\n      while (!opts.signal!.aborted) {\n        const idx = index++;\n        if (idx > 100) {\n          // With this, the subscription will stop and the client will disconnect\n          return;\n        }\n        await new Promise((resolve) => setTimeout(resolve, 10));\n      }\n    }\n  }),\n});\nCopy\n\nOn the client, you just .unsubscribe() the subscription.\n\nCleanup of side effects​\n\nIf you need to clean up any side-effects of your subscription you can use the try...finally pattern, as trpc invokes the .return() of the Generator Instance when the subscription stops for any reason.\n\nimport EventEmitter, { on } from 'events';\nimport type { Post } from '@prisma/client';\nimport { z } from 'zod';\nimport { publicProcedure, router } from '../trpc';\nconst ee = new EventEmitter();\nexport const subRouter = router({\n  onPostAdd: publicProcedure.subscription(async function* (opts) {\n    let timeout;\n    try {\n      for await (const [data] of on(ee, 'add', {\n        signal: opts.signal,\n      })) {\n        timeout = setTimeout(() => console.log('Pretend like this is useful'));\n        const post = data as Post;\n        yield post;\n      }\n    } finally {\n      if (timeout) clearTimeout(timeout);\n    }\n  }),\n});\nCopy\nError handling​\n\nThrowing an error in a generator function propagates to trpc's onError() on the backend.\n\nIf the error thrown is a 5xx error, the client will automatically attempt to reconnect based on the last event id that is tracked using tracked(). For other errors, the subscription will be cancelled and propagate to the onError() callback.\n\nOutput validation​\n\nSince subscriptions are async iterators, you have to go through the iterator to validate the output.\n\nExample with zod​\nzAsyncIterable.ts\nimport type { TrackedEnvelope } from '@trpc/server';\nimport { isTrackedEnvelope, tracked } from '@trpc/server';\nimport { z } from 'zod';\nfunction isAsyncIterable<TValue, TReturn = unknown>(\n  value: unknown,\n): value is AsyncIterable<TValue, TReturn> {\n  return !!value && typeof value === 'object' && Symbol.asyncIterator in value;\n}\nconst trackedEnvelopeSchema =\n  z.custom<TrackedEnvelope<unknown>>(isTrackedEnvelope);\n/**\n * A Zod schema helper designed specifically for validating async iterables. This schema ensures that:\n * 1. The value being validated is an async iterable.\n * 2. Each item yielded by the async iterable conforms to a specified type.\n * 3. The return value of the async iterable, if any, also conforms to a specified type.\n */\nexport function zAsyncIterable<\n  TYieldIn,\n  TYieldOut,\n  TReturnIn = void,\n  TReturnOut = void,\n  Tracked extends boolean = false,\n>(opts: {\n  /**\n   * Validate the value yielded by the async generator\n   */\n  yield: z.ZodType<TYieldIn, any, TYieldOut>;\n  /**\n   * Validate the return value of the async generator\n   * @remark not applicable for subscriptions\n   */\n  return?: z.ZodType<TReturnIn, any, TReturnOut>;\n  /**\n   * Whether if the yielded values are tracked\n   * @remark only applicable for subscriptions\n   */\n  tracked?: Tracked;\n}) {\n  return z\n    .custom<\n      AsyncIterable<\n        Tracked extends true ? TrackedEnvelope<TYieldIn> : TYieldIn,\n        TReturnIn\n      >\n    >((val) => isAsyncIterable(val))\n    .transform(async function* (iter) {\n      const iterator = iter[Symbol.asyncIterator]();\n      try {\n        let next;\n        while ((next = await iterator.next()) && !next.done) {\n          if (opts.tracked) {\n            const [id, data] = trackedEnvelopeSchema.parse(next.value);\n            yield tracked(id, await opts.yield.parseAsync(data));\n            continue;\n          }\n          yield opts.yield.parseAsync(next.value);\n        }\n        if (opts.return) {\n          return await opts.return.parseAsync(next.value);\n        }\n        return;\n      } finally {\n        await iterator.return?.();\n      }\n    }) as z.ZodType<\n    AsyncIterable<\n      Tracked extends true ? TrackedEnvelope<TYieldIn> : TYieldIn,\n      TReturnIn,\n      unknown\n    >,\n    any,\n    AsyncIterable<\n      Tracked extends true ? TrackedEnvelope<TYieldOut> : TYieldOut,\n      TReturnOut,\n      unknown\n    >\n  >;\n}\nCopy\n\nNow you can use this helper to validate the output of your subscription procedures:\n\n_app.ts\nimport { publicProcedure, router } from '../trpc';\nimport { zAsyncIterable } from './zAsyncIterable';\nexport const appRouter = router({\n  mySubscription: publicProcedure\n    .input(\n      z.object({\n        lastEventId: z.coerce.number().min(0).optional(),\n      }),\n    )\n    .output(\n      zAsyncIterable({\n        yield: z.object({\n          count: z.number(),\n        }),\n        tracked: true,\n      }),\n    )\n    .subscription(async function* (opts) {\n      let index = opts.input.lastEventId ?? 0;\n      while (true) {\n        index++;\n        yield tracked(index, {\n          count: index,\n        });\n        await new Promise((resolve) => setTimeout(resolve, 1000));\n      }\n    }),\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/websockets",
    "html": "Backend Usage\nWebSockets\nVersion: 11.x\nWebSockets\n\nYou can use WebSockets for all or some of the communication with your server, see wsLink for how to set it up on the client.\n\nTIP\n\nThe document here outlines the specific details of using WebSockets. For general usage of subscriptions, see our subscriptions guide.\n\nCreating a WebSocket-server​\nyarn add ws\nCopy\nserver/wsServer.ts\nimport { applyWSSHandler } from '@trpc/server/adapters/ws';\nimport ws from 'ws';\nimport { appRouter } from './routers/app';\nimport { createContext } from './trpc';\nconst wss = new ws.Server({\n  port: 3001,\n});\nconst handler = applyWSSHandler({\n  wss,\n  router: appRouter,\n  createContext,\n  // Enable heartbeat messages to keep connection open (disabled by default)\n  keepAlive: {\n    enabled: true,\n    // server ping message interval in milliseconds\n    pingMs: 30000,\n    // connection is terminated if pong message is not received in this many milliseconds\n    pongWaitMs: 5000,\n  },\n});\nwss.on('connection', (ws) => {\n  console.log(`➕➕ Connection (${wss.clients.size})`);\n  ws.once('close', () => {\n    console.log(`➖➖ Connection (${wss.clients.size})`);\n  });\n});\nconsole.log('✅ WebSocket Server listening on ws://localhost:3001');\nprocess.on('SIGTERM', () => {\n  console.log('SIGTERM');\n  handler.broadcastReconnectNotification();\n  wss.close();\n});\nCopy\nSetting TRPCClient to use WebSockets​\nTIP\n\nYou can use Links to route queries and/or mutations to HTTP transport and subscriptions over WebSockets.\n\nclient.ts\nimport { createTRPCClient, createWSClient, wsLink } from '@trpc/client';\nimport type { AppRouter } from '../path/to/server/trpc';\n// create persistent WebSocket connection\nconst wsClient = createWSClient({\n  url: `ws://localhost:3001`,\n});\n// configure TRPCClient to use WebSockets transport\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    wsLink({\n      client: wsClient,\n    }),\n  ],\n});\nCopy\nAuthentication / connection params​\nTIP\n\nIf you're doing a web application, you can ignore this section as the cookies are sent as part of the request.\n\nIn order to authenticate with WebSockets, you can define connectionParams to createWSClient. This will be sent as the first message when the client establishes a WebSocket connection.\n\nserver/context.ts\nimport type { CreateWSSContextFnOptions } from '@trpc/server/adapters/ws';\n \nexport const createContext = async (opts: CreateWSSContextFnOptions) => {\n  const token = opts.info.connectionParams?.token;\n         \nconst token: string | undefined\n \n  // [... authenticate]\n \n  return {};\n};\n \nexport type Context = Awaited<ReturnType<typeof createContext>>;\nCopy\nclient/trpc.ts\nimport { createTRPCClient, createWSClient, wsLink } from '@trpc/client';\nimport type { AppRouter } from '~/server/routers/_app';\nconst wsClient = createWSClient({\n  url: `ws://localhost:3000`,\n  connectionParams: async () => {\n    return {\n      token: 'supersecret',\n    };\n  },\n});\nexport const trpc = createTRPCClient<AppRouter>({\n  links: [wsLink({ client: wsClient, transformer: superjson })],\n});\nCopy\nAutomatic tracking of id using tracked() (recommended)​\n\nIf you yield an event using our tracked()-helper and include an id, the client will automatically reconnect when it gets disconnected and send the last known ID when reconnecting as part of the lastEventId-input.\n\nYou can send an initial lastEventId when initializing the subscription and it will be automatically updated as the browser receives data.\n\nINFO\n\nIf you're fetching data based on the lastEventId, and capturing all events is critical, you may want to use ReadableStream's or a similar pattern as an intermediary as is done in our full-stack SSE example to prevent newly emitted events being ignored while yield'ing the original batch based on lastEventId.\n\nimport EventEmitter, { on } from 'events';\nimport { tracked } from '@trpc/server';\nimport { z } from 'zod';\nimport { publicProcedure, router } from '../trpc';\nconst ee = new EventEmitter();\nexport const subRouter = router({\n  onPostAdd: publicProcedure\n    .input(\n      z\n        .object({\n          // lastEventId is the last event id that the client has received\n          // On the first call, it will be whatever was passed in the initial setup\n          // If the client reconnects, it will be the last event id that the client received\n          lastEventId: z.string().nullish(),\n        })\n        .optional(),\n    )\n    .subscription(async function* (opts) {\n      if (opts.input.lastEventId) {\n        // [...] get the posts since the last event id and yield them\n      }\n      // listen for new events\n      for await (const [data] of on(ee, 'add', {\n        // Passing the AbortSignal from the request automatically cancels the event emitter when the subscription is aborted\n        signal: opts.signal,\n      })) {\n        const post = data as Post;\n        // tracking the post id ensures the client can reconnect at any time and get the latest events this id\n        yield tracked(post.id, post);\n      }\n    }),\n});\nCopy\nWebSockets RPC Specification​\n\nYou can read more details by drilling into the TypeScript definitions:\n\n/packages/server/src/unstable-core-do-not-import/rpc/envelopes.ts\n/packages/server/src/unstable-core-do-not-import/rpc/codes.ts.\nquery / mutation​\nRequest​\n{\n  id: number | string;\n  jsonrpc?: '2.0'; // optional\n  method: 'query' | 'mutation';\n  params: {\n    path: string;\n    input?: unknown; // <-- pass input of procedure, serialized by transformer\n  };\n}\nCopy\nResponse​\n\n... below, or an error.\n\n{\n  id: number | string;\n  jsonrpc?: '2.0'; // only defined if included in request\n  result: {\n    type: 'data'; // always 'data' for mutation / queries\n    data: TOutput; // output from procedure\n  }\n}\nCopy\nsubscription / subscription.stop​\nStart a subscription​\n{\n  id: number | string;\n  jsonrpc?: '2.0';\n  method: 'subscription';\n  params: {\n    path: string;\n    input?: unknown; // <-- pass input of procedure, serialized by transformer\n  };\n}\nCopy\nTo cancel a subscription, call subscription.stop​\n{\n  id: number | string; // <-- id of your created subscription\n  jsonrpc?: '2.0';\n  method: 'subscription.stop';\n}\nCopy\nSubscription response shape​\n\n... below, or an error.\n\n{\n  id: number | string;\n  jsonrpc?: '2.0';\n  result: (\n    | {\n        type: 'data';\n        data: TData; // subscription emitted data\n      }\n    | {\n        type: 'started'; // subscription started\n      }\n    | {\n        type: 'stopped'; // subscription stopped\n      }\n  )\n}\nCopy\nConnection params​\n\nIf the connection is initialized with ?connectionParams=1, the first message has to be connection params.\n\n{\n  data: Record<string, string> | null;\n  method: 'connectionParams';\n}\nCopy\nErrors​\n\nSee https://www.jsonrpc.org/specification#error_object or Error Formatting.\n\nNotifications from Server to Client​\n{ id: null, type: 'reconnect' }​\n\nTells clients to reconnect before shutting down the server. Invoked by wssHandler.broadcastReconnectNotification().\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/",
    "html": "API Reference (Auto-generated)\n@trpc/client\nVersion: 11.x\n@trpc/client\nModules​\nindex\nlinks/httpBatchLink\nlinks/httpLink\nlinks/loggerLink\nlinks/splitLink\nlinks/wsLink/wsLink\nEdit this page"
  },
  {
    "title": "TanStack React Query | tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query",
    "html": "📄️ Setup\n\nTanStack React Query setup\n\n📄️ Usage\n\nTanStack React Query usage\n\n📄️ Migrating\n\nMigrating from the classic React Client\n\n📄️ Server Components\n\nThis guide is an overview of how one may use tRPC with a React Server Components (RSC) framework such as Next.js App Router."
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react",
    "html": "Client Usage\nReact Query Integration (Classic)\nVersion: 11.x\nReact Query Integration (Classic)\nTIP\n\nThese are the docs for our 'Classic' React Query integration, which (while still supported) is not the recommended way to start new tRPC projects with TanStack React Query. We recommend using the new TanStack React Query Integration instead.\n\ntRPC offers a first class integration with React. Under the hood this is simply a wrapper around the very popular @tanstack/react-query, so we recommend that you familiarise yourself with React Query, as their docs go in to much greater depth on its usage.\n\nIf you are using Next.js we recommend using our integration with that instead.\n\n❓ Do I have to use an integration?\nThe tRPC React Query Integration​\n\nThis library enables usage directly within React components\n\npages/IndexPage.tsx\nimport { trpc } from '../utils/trpc';\nexport default function IndexPage() {\n  const helloQuery = trpc.hello.useQuery({ name: 'Bob' });\n  const goodbyeMutation = trpc.goodbye.useMutation();\n  return (\n    <div>\n      <p>{helloQuery.data?.greeting}</p>\n      <button onClick={() => goodbyeMutation.mutate()}>Say Goodbye</button>\n    </div>\n  );\n}\nCopy\nDifferences to vanilla React Query​\n\nThe wrapper abstracts some aspects of React Query for you:\n\nQuery Keys - these are generated and managed by tRPC on your behalf, based on the procedure inputs you provide\nIf you need the query key which tRPC calculates, you can use getQueryKey\nType safe by default - the types you provide in your tRPC Backend also drive the types of your React Query client, providing safety throughout your React app\nEdit this page"
  },
  {
    "title": "Set up with Next.js Pages Router | tRPC",
    "url": "https://trpc.io/docs/client/nextjs/setup",
    "html": "Client Usage\nNext.js Integration\nSetup\nVersion: 11.x\nSet up with Next.js Pages Router\nCAUTION\n\nThis guide is for Next.js Pages Router. If you are using Next.js App Router with React Server components, check out the RSC docs\n\nRecommended file structure​\n\nWe recommend a file structure like this one, although it is not enforced by tRPC. This is what you'll see in our examples. The rest of this page will take you through the process of adding tRPC in to this structure.\n\n.\n├── prisma  # <-- if prisma is added\n│   └── [..]\n├── src\n│   ├── pages\n│   │   ├── _app.tsx  # <-- add `withTRPC()`-HOC here\n│   │   ├── api\n│   │   │   └── trpc\n│   │   │       └── [trpc].ts  # <-- tRPC HTTP handler\n│   │   └── [..]\n│   ├── server\n│   │   ├── routers\n│   │   │   ├── _app.ts  # <-- main app router\n│   │   │   ├── post.ts  # <-- sub routers\n│   │   │   └── [..]\n│   │   ├── context.ts   # <-- create app context\n│   │   └── trpc.ts      # <-- procedure helpers\n│   └── utils\n│       └── trpc.ts  # <-- your typesafe tRPC hooks\n└── [..]\nCopy\nAdd tRPC to existing Next.js project​\n1. Install deps​\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/react-query @trpc/next @tanstack/react-query@latest zod\n\nThe Next.js integration is actually a combination of our React Query Integration and some Next.js specific integrations.\n\n2. Enable strict mode​\n\nIf you want to use Zod for input validation, make sure you have enabled strict mode in your tsconfig.json:\n\ntsconfig.json\n\"compilerOptions\": {\n+   \"strict\": true\n}\nCopy\n\nIf strict mode is too harsh, you'll at least want to enable strictNullChecks:\n\ntsconfig.json\n\"compilerOptions\": {\n+   \"strictNullChecks\": true\n}\nCopy\n3. Create a tRPC router​\n\nInitialize your tRPC backend in src/server/trpc.ts using the initTRPC function, and create your first router. We're going to make a simple \"hello world\" router and procedure here - but for deeper information on creating your tRPC API you should refer to:\n\nthe Quickstart guide and Backend usage docs for tRPC information\nthe Next.js Adapter docs for mounting tRPC within your Next.js server.\nView sample backend\nNOTE\n\nThe backend above is using the recommended file structure, but you can keep it simple and put everything in an API handler directly if you prefer.\n\n4. Create tRPC hooks​\n\nuse the createTRPCNext function to create a set of strongly-typed hooks from your API's type signature.\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport type { AppRouter } from '../server/routers/_app';\nfunction getBaseUrl() {\n  if (typeof window !== 'undefined')\n    // browser should use relative path\n    return '';\n  if (process.env.VERCEL_URL)\n    // reference for vercel.com\n    return `https://${process.env.VERCEL_URL}`;\n  if (process.env.RENDER_INTERNAL_HOSTNAME)\n    // reference for render.com\n    return `http://${process.env.RENDER_INTERNAL_HOSTNAME}:${process.env.PORT}`;\n  // assume localhost\n  return `http://localhost:${process.env.PORT ?? 3000}`;\n}\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    return {\n      links: [\n        httpBatchLink({\n          /**\n           * If you want to use SSR, you need to use the server's full URL\n           * @see https://trpc.io/docs/v11/ssr\n           **/\n          url: `${getBaseUrl()}/api/trpc`,\n          // You can pass any HTTP headers you wish here\n          async headers() {\n            return {\n              // authorization: getAuthCookie(),\n            };\n          },\n        }),\n      ],\n    };\n  },\n  /**\n   * @see https://trpc.io/docs/v11/ssr\n   **/\n  ssr: false,\n});\nCopy\nNOTE\n\ncreateTRPCNext does not work with the tRPC-v9 interop mode. If you are migrating from v9 using interop, you should continue using the old way of initializing tRPC.\n\n5. Configure _app.tsx​\n\nWrap your root app page in the trpc.withTRPC HOC, similar to this:\n\npages/_app.tsx\nimport type { AppType } from 'next/app';\nimport { trpc } from '../utils/trpc';\nconst MyApp: AppType = ({ Component, pageProps }) => {\n  return <Component {...pageProps} />;\n};\nexport default trpc.withTRPC(MyApp);\nCopy\n6. Make an API request​\n\nYou're all set!\n\nYou can now use the React hooks you have just created to invoke your API. For more detail see the React Query Integration\n\npages/index.tsx\nimport { trpc } from '../utils/trpc';\nexport default function IndexPage() {\n  const hello = trpc.hello.useQuery({ text: 'client' });\n  if (!hello.data) {\n    return <div>Loading...</div>;\n  }\n  return (\n    <div>\n      <p>{hello.data.greeting}</p>\n    </div>\n  );\n}\nCopy\ncreateTRPCNext() options​\nconfig-callback​\n\nThe config-argument is a function that returns an object that configures the tRPC and React Query clients. This function has a ctx input that gives you access to the Next.js req object, among other things. The returned value can contain the following properties:\n\nRequired:\nlinks to customize the flow of data between tRPC Client and the tRPC Server. Read more.\nOptional:\nqueryClientConfig: a configuration object for the React Query QueryClient used internally by the tRPC React hooks: QueryClient docs\nqueryClient: a React Query QueryClient instance\nNote: You can only provide either a queryClient or a queryClientConfig.\ntransformer: a transformer applied to outgoing payloads. Read more about Data Transformers\nabortOnUnmount: determines if in-flight requests will be cancelled on component unmount. This defaults to false.\noverrides: (default: undefined)​\n\nConfigure overrides for React Query's hooks.\n\nssr-boolean (default: false)​\n\nWhether tRPC should await queries when server-side rendering a page. Defaults to false.\n\nresponseMeta-callback​\n\nAbility to set request headers and HTTP status when server-side rendering.\n\nExample​\nutils/trpc.ts\nimport { createTRPCNext } from '@trpc/next';\nimport type { AppRouter } from '../pages/api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    /* [...] */\n  },\n});\nCopy\nNext steps​\n\nBrowse the rest of the docs to learn more about things like authorization, middlewares, and error handling.\n\nYou can also find information about queries and mutations now that you're using @trpc/react-query.\n\nEdit this page"
  },
  {
    "title": "Server-Side Rendering | tRPC",
    "url": "https://trpc.io/docs/client/nextjs/ssr",
    "html": "Client Usage\nNext.js Integration\nServer-Side Rendering (SSR)\nVersion: 11.x\nServer-Side Rendering\n\nTo enable SSR just set ssr: true in your createTRPCNext config callback.\n\nINFO\n\nWhen you enable SSR, tRPC will use getInitialProps to prefetch all queries on the server. This results in problems like this when you use getServerSideProps, and solving it is out of our hands.\n\n \nAlternatively, you can leave SSR disabled (the default) and use Server-Side Helpers to prefetch queries in getStaticProps or getServerSideProps.\n\nIn order to execute queries properly during the server-side render step we need to add extra logic inside our config:\n\nAdditionally, consider Response Caching.\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport { ssrPrepass } from '@trpc/next/ssrPrepass';\nimport superjson from 'superjson';\nimport type { AppRouter } from './api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  ssr: true,\n  ssrPrepass,\n  config(config) {\n    const { ctx } = opts;\n    if (typeof window !== 'undefined') {\n      // during client requests\n      return {\n        links: [\n          httpBatchLink({\n            url: '/api/trpc',\n          }),\n        ],\n      };\n    }\n    return {\n      links: [\n        httpBatchLink({\n          // The server needs to know your app's full url\n          url: `${getBaseUrl()}/api/trpc`,\n          /**\n           * Set custom request headers on every request from tRPC\n           * @see https://trpc.io/docs/v10/header\n           */\n          headers() {\n            if (!ctx?.req?.headers) {\n              return {};\n            }\n            // To use SSR properly, you need to forward client headers to the server\n            // This is so you can pass through things like cookies when we're server-side rendering\n            return {\n              cookie: ctx.req.headers.cookie,\n            };\n          },\n        }),\n      ],\n    };\n  },\n});\nCopy\n\nor, if you want to SSR conditional on a given request, you can pass a callback to ssr. This callback can return a boolean, or a Promise resolving to a boolean:\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport superjson from 'superjson';\nimport type { AppRouter } from './api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    const { ctx } = opts;\n    if (typeof window !== 'undefined') {\n      // during client requests\n      return {\n        links: [\n          httpBatchLink({\n            url: '/api/trpc',\n          }),\n        ],\n      };\n    }\n    return {\n      links: [\n        httpBatchLink({\n          // The server needs to know your app's full url\n          url: `${getBaseUrl()}/api/trpc`,\n          /**\n           * Set custom request headers on every request from tRPC\n           * @see https://trpc.io/docs/v10/header\n           */\n          headers() {\n            if (!ctx?.req?.headers) {\n              return {};\n            }\n            // To use SSR properly, you need to forward client headers to the server\n            // This is so you can pass through things like cookies when we're server-side rendering\n            return {\n              cookie: ctx.req.headers.cookie,\n            };\n          },\n        }),\n      ],\n    };\n  },\n  ssr(opts) {\n    // only SSR if the request is coming from a bot\n    return opts.ctx?.req?.headers['user-agent']?.includes('bot');\n  },\n});\nCopy\npages/_app.tsx\nimport { trpc } from '~/utils/trpc';\nimport type { AppProps } from 'next/app';\nimport React from 'react';\nconst MyApp: AppType = ({ Component, pageProps }: AppProps) => {\n  return <Component {...pageProps} />;\n};\nexport default trpc.withTRPC(MyApp);\nCopy\nFAQ​\nQ: Why do I need to forward the client's headers to the server manually? Why doesn't tRPC automatically do that for me?​\n\nWhile it's rare that you wouldn't want to forward the client's headers to the server when doing SSR, you might want to add things dynamically in the headers. Therefore, tRPC doesn't want to take responsibility for header keys colliding, etc.\n\nQ: Why do I need to delete the connection header when using SSR on Node 18?​\n\nIf you don't remove the connection header, the data fetching will fail with TRPCClientError: fetch failed because connection is a forbidden header name.\n\nQ: Why do I still see network requests being made in the Network tab?​\n\nBy default, @tanstack/react-query (which we use for the data fetching hooks) refetches data on mount and window refocus, even if it's already got initial data via SSR. This ensures data is always up-to-date. See the page on SSG if you'd like to disable this behavior.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/ssg",
    "html": "Client Usage\nNext.js Integration\nStatic Site Generation (SSG)\nVersion: 11.x\nStatic Site Generation\nTIP\n\nReference project: https://github.com/trpc/examples-next-prisma-todomvc\n\nStatic site generation requires executing tRPC queries inside getStaticProps on each page.\n\nThis can be done using server-side helpers to prefetch the queries, dehydrate them, and pass it to the page. The queries will then automatically pick up the trpcState and use it as an initial value.\n\nFetch data in getStaticProps​\npages/posts/[id].tsx\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport { prisma } from '~/server/context';\nimport { appRouter } from '~/server/routers/_app';\nimport { trpc } from '~/utils/trpc';\nimport {\n  GetStaticPaths,\n  GetStaticPropsContext,\n  InferGetStaticPropsType,\n} from 'next';\nimport superjson from 'superjson';\nexport async function getStaticProps(\n  context: GetStaticPropsContext<{ id: string }>,\n) {\n  const helpers = createServerSideHelpers({\n    router: appRouter,\n    ctx: {},\n    transformer: superjson, // optional - adds superjson serialization\n  });\n  const id = context.params?.id as string;\n  // prefetch `post.byId`\n  await helpers.post.byId.prefetch({ id });\n  return {\n    props: {\n      trpcState: helpers.dehydrate(),\n      id,\n    },\n    revalidate: 1,\n  };\n}\nexport const getStaticPaths: GetStaticPaths = async () => {\n  const posts = await prisma.post.findMany({\n    select: {\n      id: true,\n    },\n  });\n  return {\n    paths: posts.map((post) => ({\n      params: {\n        id: post.id,\n      },\n    })),\n    // https://nextjs.org/docs/pages/api-reference/functions/get-static-paths#fallback-blocking\n    fallback: 'blocking',\n  };\n};\nexport default function PostViewPage(\n  props: InferGetStaticPropsType<typeof getStaticProps>,\n) {\n  const { id } = props;\n  const postQuery = trpc.post.byId.useQuery({ id });\n  if (postQuery.status !== 'success') {\n    // won't happen since we're using `fallback: \"blocking\"`\n    return <>Loading...</>;\n  }\n  const { data } = postQuery;\n  return (\n    <>\n      <h1>{data.title}</h1>\n      <em>Created {data.createdAt.toLocaleDateString('en-us')}</em>\n      <p>{data.text}</p>\n      <h2>Raw data:</h2>\n      <pre>{JSON.stringify(data, null, 4)}</pre>\n    </>\n  );\n}\nCopy\n\nNote that the default behaviour of react-query is to refetch the data on the client-side when it mounts, so if you want to only fetch the data via getStaticProps, you need to set refetchOnMount and refetchOnWindowFocus to false in the query options.\n\nThis might be preferable if you want to minimize the number of requests to your API, which might be necessary if you're using a third-party rate-limited API for example.\n\nThis can be done per query:\n\nconst data = trpc.example.useQuery(\n  // if your query takes no input, make sure that you don't\n  // accidentally pass the query options as the first argument\n  undefined,\n  { refetchOnMount: false, refetchOnWindowFocus: false },\n);\nCopy\n\nOr globally, if every query across your app should behave the same way:\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport superjson from 'superjson';\nimport type { AppRouter } from './api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    return {\n      links: [\n        httpBatchLink({\n          url: `${getBaseUrl()}/api/trpc`,\n        }),\n      ],\n      // Change options globally\n      queryClientConfig: {\n        defaultOptions: {\n          queries: {\n            refetchOnMount: false,\n            refetchOnWindowFocus: false,\n          },\n        },\n      },\n    },\n  },\n});\nCopy\n\nBe careful with this approach if your app has a mixture of static and dynamic queries.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/server-side-helpers",
    "html": "Client Usage\nNext.js Integration\nServer-Side Helpers\nVersion: 11.x\nServer-Side Helpers\n\nThe server-side helpers provides you with a set of helper functions that you can use to prefetch queries on the server. This is useful for SSG, but also for SSR if you opt not to use ssr: true.\n\nPrefetching via the server-side helpers allows populating the query cache on the server, which means that these queries do not have to fetch on the client initially.\n\nThere are 2 ways to use the server-side helpers.​\n1. Internal router​\n\nThis method is used when you have direct access to your tRPC router. e.g. when developing a monolithic Next.js application.\n\nUsing the helpers makes tRPC call your procedures directly on the server, without an HTTP request, similar to server-side calls. That also means that you don't have the request and response at hand like you usually do. Make sure you're instantiating the server-side helpers with a context without req & res, which are typically filled via the context creation. We recommend the concept of \"inner\" and \"outer\" context in that scenario.\n\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport { createContext } from '~/server/context';\nimport superjson from 'superjson';\nconst helpers = createServerSideHelpers({\n  router: appRouter,\n  ctx: await createContext(),\n  transformer: superjson, // optional - adds superjson serialization\n});\nCopy\n2. External router​\n\nThis method is used when you don't have direct access to your tRPC router. e.g. when developing a Next.js application and a standalone API hosted separately.\n\nimport { createTRPCClient } from '@trpc/client';\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport superjson from 'superjson';\nconst proxyClient = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000/api/trpc',\n    }),\n  ],\n});\nconst helpers = createServerSideHelpers({\n  client: proxyClient,\n});\nCopy\nHelpers usage​\n\nThe server-side helpers methods return an object much like the tRPC client, with all of your routers as keys. However, rather than useQuery and useMutation, you get prefetch, fetch, prefetchInfinite, and fetchInfinite functions.\n\nThe primary difference between prefetch and fetch is that fetch acts much like a normal function call, returning the result of the query, whereas prefetch does not return the result and never throws - if you need that behavior, use fetch instead. Instead, prefetch will add the query to the cache, which you then dehydrate and send to the client.\n\nreturn {\n  props: {\n    // very important - use `trpcState` as the key\n    trpcState: helpers.dehydrate(),\n  },\n};\nCopy\n\nThe rule of thumb is prefetch for queries that you know you'll need on the client, and fetch for queries that you want to use the result of on the server.\n\nThe functions are all wrappers around react-query functions. Please check out their docs to learn more about them in detail.\n\nINFO\n\nFor a full example, see our E2E SSG test example\n\nNext.js Example​\npages/posts/[id].tsx\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport { appRouter } from '~/server/routers/_app';\nimport { trpc } from '~/utils/trpc';\nimport { GetServerSidePropsContext, InferGetServerSidePropsType } from 'next';\nimport superjson from 'superjson';\nexport async function getServerSideProps(\n  context: GetServerSidePropsContext<{ id: string }>,\n) {\n  const helpers = createServerSideHelpers({\n    router: appRouter,\n    ctx: {},\n    transformer: superjson,\n  });\n  const id = context.params?.id as string;\n  /*\n   * Prefetching the `post.byId` query.\n   * `prefetch` does not return the result and never throws - if you need that behavior, use `fetch` instead.\n   */\n  await helpers.post.byId.prefetch({ id });\n  // Make sure to return { props: { trpcState: helpers.dehydrate() } }\n  return {\n    props: {\n      trpcState: helpers.dehydrate(),\n      id,\n    },\n  };\n}\nexport default function PostViewPage(\n  props: InferGetServerSidePropsType<typeof getServerSideProps>,\n) {\n  const { id } = props;\n  const postQuery = trpc.post.byId.useQuery({ id });\n  if (postQuery.status !== 'success') {\n    // won't happen since the query has been prefetched\n    return <>Loading...</>;\n  }\n  const { data } = postQuery;\n  return (\n    <>\n      <h1>{data.title}</h1>\n      <em>Created {data.createdAt.toLocaleDateString()}</em>\n      <p>{data.text}</p>\n      <h2>Raw data:</h2>\n      <pre>{JSON.stringify(data, null, 4)}</pre>\n    </>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/aborting-procedure-calls",
    "html": "Client Usage\nNext.js Integration\nAborting Procedure Calls\nVersion: 11.x\nAborting Procedure Calls\n\nBy default, tRPC does not cancel requests on unmount. If you want to opt into this behavior, you can provide abortOnUnmount in your configuration callback.\n\nGlobally​\nclient.ts\n// @filename: utils.ts\nimport { createTRPCNext } from '@trpc/next';\n \nexport const trpc = createTRPCNext<AppRouter>({\n  config() {\n    return {\n      // ...\n      abortOnUnmount: true,\n    };\n  },\n});\nCopy\nPer-request​\n\nYou may also override this behavior at the request level.\n\nclient.ts\n// @filename: pages/posts/[id].tsx\nimport { trpc } from '~/utils/trpc';\n \nconst PostViewPage: NextPageWithLayout = () => {\n  const id = useRouter().query.id as string;\n  const postQuery = trpc.post.byId.useQuery({ id }, { trpc: { abortOnUnmount: true } });\n \n  return (...)\n}\nCopy\nEdit this page"
  },
  {
    "title": "Starter Projects | tRPC",
    "url": "https://trpc.io/docs/client/nextjs/starter-projects",
    "html": "Client Usage\nNext.js Integration\nStarter Projects\nVersion: 11.x\nStarter Projects\n\nGet started quickly with one of the sample projects! Copy the snippet from Quick start with create-next-app in the below list to clone the project.\n\nDescription\tURL\tLinks\n\n\nNext.js starter with Prisma, E2E testing, & ESLint.\n\n\n\n\nQuick start with create-next-app\n\tnextjs.trpc.io\t\nCodeSandbox\nSource\n\n\n\nzART-stack example (zero-API, TypeScript, React).\n\n\n\n\nMonorepo setup with React Native, Next.js, & Prisma\n\n\n\n\nQuick start with git clone\n\tn/a\t\nSource\n\n\n\nNext.js TodoMVC-example with SSG & Prisma.\n\n\n\n\nQuick start with create-next-app\n\ttodomvc.trpc.io\t\nCodeSandbox\nSource\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/vanilla",
    "html": "Client Usage\nVanilla Client\nVersion: 11.x\ntRPC Client\n\nThe \"Vanilla\" tRPC client can be used to call your API procedures as if they are local functions, enabling a seamless development experience.\n\nimport type { AppRouter } from '../path/to/server/trpc';\nconst bilbo = await client.getUser.query('id_bilbo');\n// => { id: 'id_bilbo', name: 'Bilbo' };\nCopy\nWhen to use the Vanilla Client?​\n\nYou are likely to use this client in two scenarios:\n\nWith a frontend framework for which we don't have an official integration\nWith a separate backend service written in TypeScript.\nWhen NOT to use the Vanilla Client?​\nWhile you can use the client to call procedures from a React component, you should usually use our React Query Integration. It offers many additional features such as the ability to manage loading and error state, caching, and invalidation.\nWe recommend you do not use this client when calling procedures of the same API instance, this is because the invocation has to pass through the network layer. For complete recommendations on invoking a procedure in the current API, you can read more here.\nEdit this page"
  },
  {
    "title": "Links Overview | tRPC",
    "url": "https://trpc.io/docs/client/links",
    "html": "Client Usage\nLinks\nVersion: 11.x\nLinks Overview\n\nLinks enable you to customize the flow of data between the tRPC Client and Server. A link should do only one thing, which can be either a self-contained modification to a tRPC operation (query, mutation, or subscription) or a side-effect based on the operation (such as logging).\n\nYou can compose links together into an array that you can provide to the tRPC client configuration via the links property, which represents a link chain. This means that the tRPC client will execute the links in the order they are added to the links array when doing a request and will execute them again in reverse when it's handling a response. Here's a visual representation of the link chain:\n\ntRPC Link Diagram. Based on Apollo's.\nNOTE\n\nThe below examples are assuming you use Next.js, but the same as below can be added if you use the vanilla tRPC client\n\nutils/trpc.ts\nimport { httpBatchLink, loggerLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nexport default createTRPCNext<AppRouter>({\n  config() {\n    const url = `http://localhost:3000`;\n    return {\n      links: [\n        loggerLink(),\n        httpBatchLink({\n          url,\n        }),\n      ],\n    };\n  },\n});\nCopy\nCreating a custom link​\n\nA link is a function that follows the TRPCLink type. Each link is composed of three parts:\n\nThe link returns a function that has a parameter with the TRPCClientRuntime type. This argument is passed by tRPC and it is used when creating a terminating link. If you're not creating a terminating link, you can just create a function that has no parameters. In such case, the link should be added to the links array without invoking (links: [..., myLink, httpBatchLink(...)]).\nThe function in step 1 returns another function that receives an object with two properties: op which is the Operation that is being executed by the client, and next which is the function we use to call the next link down the chain.\nThe function in step 2 returns a final function that returns the observable function provided by @trpc/server. The observable accepts a function that receives an observer which helps our link notify the next link up the chain how they should handle the operation result. In this function, we can just return next(op) and leave it as is, or we can subscribe to next, which enables our link to handle the operation result.\nExample​\nutils/customLink.ts\nimport { TRPCLink } from '@trpc/client';\nimport { observable } from '@trpc/server/observable';\nimport type { AppRouter } from '~/server/routers/_app';\nexport const customLink: TRPCLink<AppRouter> = () => {\n  // here we just got initialized in the app - this happens once per app\n  // useful for storing cache for instance\n  return ({ next, op }) => {\n    // this is when passing the result to the next link\n    // each link needs to return an observable which propagates results\n    return observable((observer) => {\n      console.log('performing operation:', op);\n      const unsubscribe = next(op).subscribe({\n        next(value) {\n          console.log('we received value', value);\n          observer.next(value);\n        },\n        error(err) {\n          console.log('we received error', err);\n          observer.error(err);\n        },\n        complete() {\n          observer.complete();\n        },\n      });\n      return unsubscribe;\n    });\n  };\n};\nCopy\nReferences​\n\nIf you need a more real reference for creating your custom link, you can check out some of the built-in links tRPC provides on GitHub.\n\nThe terminating link​\n\nThe terminating link is the last link in a link chain. Instead of calling the next function, the terminating link is responsible for sending your composed tRPC operation to the tRPC server and returning an OperationResultEnvelope.\n\nThe links array that you add to the tRPC client config should have at least one link, and that link should be a terminating link. If links don't have a terminating link at the end of them, the tRPC operation will not be sent to the tRPC server.\n\nhttpBatchLink is the recommended terminating link by tRPC.\n\nhttpLink, wsLink, and localLink are other examples of terminating links.\n\nManaging context​\n\nAs an operation moves along your link chain, it maintains a context that each link can read and modify. This allows links to pass metadata along the chain that other links use in their execution logic.\n\nObtain the current context object and modify it by accessing op.context.\n\nYou can set the context object's initial value for a particular operation by providing the context parameter to the query or useQuery hook (or mutation, subscription, etc.).\n\nFor an example use case, see Disable batching for certain requests.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/headers",
    "html": "Client Usage\nCreate Custom Header\nVersion: 11.x\nCustom header\n\nThe headers option can be customized in the config when using the httpBatchLink or the httpLink.\n\nheaders can be both an object or a function. If it's a function it will get called dynamically for every HTTP request.\n\nutils/trpc.ts\n// Import the router type from your server file\nimport type { AppRouter } from '@/server/routers/app';\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nlet token: string;\nexport function setToken(newToken: string) {\n  /**\n   * You can also save the token to cookies, and initialize from\n   * cookies above.\n   */\n  token = newToken;\n}\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    return {\n      links: [\n        httpBatchLink({\n          url: 'http://localhost:3000/api/trpc',\n          /**\n           * Headers will be called on each request.\n           */\n          headers() {\n            return {\n              Authorization: token,\n            };\n          },\n        }),\n      ],\n    };\n  },\n});\nCopy\nExample with auth login​\npages/auth.tsx\nconst loginMut = trpc.auth.login.useMutation({\n  onSuccess(opts) {\n    token = opts.accessToken;\n  },\n});\nCopy\n\nThe token can be whatever you want it to be. It's entirely up to you whether that's just a client-side variable that you update the value of on success or whether you store the token and pull it from local storage.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/cors",
    "html": "Client Usage\nCORS & Cookies\nVersion: 11.x\nSend cookies cross-origin\n\nIf your API resides on a different origin than your front-end and you wish to send cookies to it, you will need to enable CORS on your server and send cookies with your requests by providing the option {credentials: \"include\"} to fetch.\n\nThe arguments provided to the fetch function used by tRPC can be modified as follow.\n\napp.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'YOUR_SERVER_URL',\n      fetch(url, options) {\n        return fetch(url, {\n          ...options,\n          credentials: 'include',\n        });\n      },\n    }),\n  ],\n});\nCopy\nINFO\n\nYou also need to enable CORS on your server by modifying your adapter, or the HTTP server which fronts your API. The best way to do this varies adapter-by-adapter and based on your hosting infrastructure, and individual adapters generally document this process where applicable.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/disabling-queries",
    "html": "Client Usage\nReact Query Integration (Classic)\nDisabling Queries\nVersion: 11.x\nDisabling Queries\n\nTo disable queries, you can pass skipToken as the first argument to useQuery or useInfiniteQuery. This will prevent the query from being executed.\n\nTypesafe conditional queries using skipToken​\nimport { skipToken } from '@tanstack/react-query';\nexport function MyComponent() {\nconst [name, setName] = useState<string | undefined>();\nconst result = trpc.getUserByName.useQuery(name ? { name: name } : skipToken);\n  return (\n    ...\n  )\n}\nCopy\nEdit this page"
  },
  {
    "title": "Inferring Types | tRPC",
    "url": "https://trpc.io/docs/client/vanilla/infer-types#inferring-input--output-types",
    "html": "Client Usage\nVanilla Client\nInferring Types\nVersion: 11.x\nInferring Types\n\nIt is often useful to access the types of your API within your clients. For this purpose, you are able to infer the types contained in your AppRouter.\n\n@trpc/server exports the following helper types to assist with inferring these types from the AppRouter exported by your @trpc/server router:\n\ninferRouterInputs<TRouter>\ninferRouterOutputs<TRouter>\nInferring Input & Output Types​\n\nLet's assume we have this example router:\n\nserver.ts\n// @filename: server.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from \"zod\";\n \nconst t = initTRPC.create();\n \nconst appRouter = t.router({\n  post: t.router({\n    list: t.procedure\n      .query(() => {\n        // imaginary db call\n        return [{ id: 1, title: 'tRPC is the best!' }];\n    }),\n    byId: t.procedure\n      .input(z.string())\n      .query((opts) => {\n        // imaginary db call\n        return { id: 1, title: 'tRPC is the best!' };\n    }),\n    create: t.procedure\n      .input(z.object({ title: z.string(), text: z.string(), }))\n      .mutation((opts) => {\n        // imaginary db call\n        return { id: 1, ...opts.input };\n    }),\n  }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\n\nUsing the helpers, we can infer the types of our router. The following example shows how to infer the types of the post.create procedure:\n\nclient.ts\n// @filename: client.ts\nimport type { inferRouterInputs, inferRouterOutputs } from '@trpc/server';\nimport type { AppRouter } from './server';\n \ntype RouterInput = inferRouterInputs<AppRouter>;\ntype RouterOutput = inferRouterOutputs<AppRouter>;\n \ntype PostCreateInput = RouterInput['post']['create'];\n           \ntype PostCreateInput = {\n    title: string;\n    text: string;\n}\ntype PostCreateOutput = RouterOutput['post']['create'];\n            \ntype PostCreateOutput = {\n    title: string;\n    text: string;\n    id: number;\n}\nCopy\nInfer TRPCClientError types​\n\nIt's also useful to infer the error type for your AppRouter\n\nclient.ts\n// @filename: client.ts\nimport { TRPCClientError } from '@trpc/client';\nimport type { AppRouter } from './server';\nimport { trpc } from './trpc';\n \nexport function isTRPCClientError(\n  cause: unknown,\n): cause is TRPCClientError<AppRouter> {\n  return cause instanceof TRPCClientError;\n}\n \nasync function main() {\n  try {\n    await trpc.post.byId.query('1');\n  } catch (cause) {\n    if (isTRPCClientError(cause)) {\n      // `cause` is now typed as your router's `TRPCClientError`\n      console.log('data', cause.data);\n                                 \n(property) TRPCClientError<BuiltRouter<{ ctx: object; meta: object; errorShape: DefaultErrorShape; transformer: false; }, DecorateCreateRouterOptions<{ post: BuiltRouter<{ ctx: object; meta: object; errorShape: DefaultErrorShape; transformer: false; }, DecorateCreateRouterOptions<...>>; }>>>.data: Maybe<DefaultErrorData>\n    } else {\n      // [...]\n    }\n  }\n}\n \nmain();\nCopy\nEdit this page"
  },
  {
    "title": "Standalone Adapter | tRPC",
    "url": "https://trpc.io/docs/server/adapters/standalone",
    "html": "Backend Usage\nHosting tRPC with Adapters\nStandalone\nVersion: 11.x\nStandalone Adapter\n\ntRPC's Standalone Adapter is the simplest way to get a new project working. It's ideal for local development, and for server-based production environments. In essence it's just a wrapper around the standard Node.js HTTP Server with the normal options related to tRPC.\n\nIf you have an existing API deployment like Express, Fastify, or Next.js, which you want to integrate tRPC into, you should have a look at their respective adapters. Likewise if you have a preference to host on serverless or edge compute, we have adapters like AWS Lambda and Fetch which may fit your needs.\n\nIt's also not uncommon, where the deployed adapter is hard to run on local machines, to have 2 entry-points in your application. You could use the Standalone Adapter for local development, and a different adapter when deployed.\n\nExample app​\nDescription\tLinks\nStandalone tRPC Server\t\nStackBlitz\nSource\n\nStandalone tRPC Server with CORS handling\t\nStackBlitz\nSource\nSetting up a Standalone tRPC Server​\n1. Implement your App Router​\n\nImplement your tRPC router. For example:\n\nappRouter.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\nexport const t = initTRPC.create();\nexport const appRouter = t.router({\n  getUser: t.procedure.input(z.string()).query((opts) => {\n    return { id: opts.input, name: 'Bilbo' };\n  }),\n  createUser: t.procedure\n    .input(z.object({ name: z.string().min(5) }))\n    .mutation(async (opts) => {\n      // use your ORM of choice\n      return await UserModel.create({\n        data: opts.input,\n      });\n    }),\n});\n// export type definition of API\nexport type AppRouter = typeof appRouter;\nCopy\n\nFor more information you can look at the quickstart guide\n\n2. Use the Standalone adapter​\n\nThe Standalone adapter runs a simple Node.js HTTP server.\n\nserver.ts\nimport { initTRPC } from '@trpc/server';\nimport { createHTTPServer } from '@trpc/server/adapters/standalone';\nimport { appRouter } from './appRouter.ts';\ncreateHTTPServer({\n  router: appRouter,\n  createContext() {\n    console.log('context 3');\n    return {};\n  },\n  // basePath: '/trpc/', // optional, defaults to '/'\n}).listen(2022);\nCopy\nHandling CORS & OPTIONS​\n\nBy default the standalone server will not respond to HTTP OPTIONS requests, or set any CORS headers.\n\nIf you're not hosting in an environment which can handle this for you, like during local development, you may need to handle it.\n\n1. Install cors​\n\nYou can add support yourself with the popular cors package\n\nyarn add cors\nyarn add -D @types/cors\nCopy\n\nFor full information on how to configure this package, check the docs\n\n2. Configure the Standalone server​\n\nThis example just throws open CORS to any request, which is useful for development, but you can and should configure it more strictly in a production environment.\n\nserver.ts\nimport { initTRPC } from '@trpc/server';\nimport { createHTTPServer } from '@trpc/server/adapters/standalone';\nimport cors from 'cors';\ncreateHTTPServer({\n  middleware: cors(),\n  router: appRouter,\n  createContext() {\n    console.log('context 3');\n    return {};\n  },\n}).listen(3333);\nCopy\n\nThe middleware option will accept any function which resembles a connect/node.js middleware, so it can be used for more than cors handling if you wish. It is, however, intended to be a simple escape hatch and as such won't on its own allow you to compose multiple middlewares together. If you want to do this then you could:\n\nUse an alternate adapter with more comprehensive middleware support, like the Express adapter\nUse a solution to compose middlewares such as connect\nExtend the Standalone createHTTPHandler with a custom http server (see below)\nAdding a handler to an Custom HTTP server​\n\ncreateHTTPServer is returning an instance of Node's built-in http.Server(https://nodejs.org/api/http.html#class-httpserver), which means that you have an access to all it's properties and APIs. However, if createHTTPServer isn't enough for your usecase, you can also use the standalone adapter's createHTTPHandler function to create your own HTTP server. For instance:\n\nserver.ts\nimport { createServer } from 'http';\nimport { initTRPC } from '@trpc/server';\nimport { createHTTPHandler } from '@trpc/server/adapters/standalone';\nconst handler = createHTTPHandler({\n  router: appRouter,\n  createContext() {\n    return {};\n  },\n});\ncreateServer((req, res) => {\n  /**\n   * Handle the request however you like,\n   * just call the tRPC handler when you're ready\n   */\n  handler(req, res);\n}).listen(3001);\nCopy\nCustom base path to handle requests under​\n\nThe Standalone adapter also supports a basePath option, which will slice the basePath from the beginning of the request path.\n\nserver.ts\nimport { createServer } from 'http';\nimport { initTRPC } from '@trpc/server';\nimport { createHTTPHandler } from '@trpc/server/adapters/standalone';\nconst handler = createHTTPHandler({\n  router: appRouter,\n  basePath: '/trpc/',\n});\ncreateServer((req, res) => {\n  if (req.url?.startsWith('/trpc/')) {\n    return handler(req, res);\n  }\n  // [... insert your custom logic here ...]\n  res.statusCode = 404;\n  res.end('Not Found');\n}).listen(3001);\nCopy\nHTTP2​\n\nThe Standalone adapter also supports HTTP/2.\n\nserver.ts\nimport http2 from 'http2';\nimport { createHTTP2Handler } from '@trpc/server/adapters/standalone';\nimport { appRouter } from './_app.ts';\nimport { createContext } from './context.ts';\nconst handler = createHTTP2Handler({\n  router: appRouter,\n  createContext,\n  // basePath: '/trpc/', // optional, defaults to '/'\n});\nconst server = http2.createSecureServer(\n  {\n    key: '...',\n    cert: '...',\n  },\n  (req, res) => {\n    /**\n     * Handle the request however you like,\n     * just call the tRPC handler when you're ready\n     */\n    handler(req, res);\n  },\n);\nserver.listen(3001);\nCopy\ncontext.ts\nimport { CreateHTTP2ContextOptions } from '@trpc/server/adapters/standalone';\n \nexport async function createContext(opts: CreateHTTP2ContextOptions) {\n  opts.req;\n       \n(property) req: http2.Http2ServerRequest\n  opts.res;\n       \n(property) res: http2.Http2ServerResponse\n \n  opts.info;\n        \n(property) info: TRPCRequestInfo\n  return {};\n}\n \nexport type Context = Awaited<ReturnType<typeof createContext>>;\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/adapters/express",
    "html": "Backend Usage\nHosting tRPC with Adapters\nExpress\nVersion: 11.x\nExpress Adapter\nExample app​\nDescription\tLinks\nExpress server & procedure calls with Node.js.\t\nCodeSandbox\nSource\nHow to add tRPC to existing Express project​\n1. Install deps​\nyarn add @trpc/server zod\nCopy\n\nZod isn't a required dependency, but it's used in the sample router below.\n\n2. Create a tRPC router​\n\nImplement your tRPC router. A sample router is given below:\n\nserver.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\nexport const t = initTRPC.create();\nexport const appRouter = t.router({\n  getUser: t.procedure.input(z.string()).query((opts) => {\n    opts.input; // string\n    return { id: opts.input, name: 'Bilbo' };\n  }),\n  createUser: t.procedure\n    .input(z.object({ name: z.string().min(5) }))\n    .mutation(async (opts) => {\n      // use your ORM of choice\n      return await UserModel.create({\n        data: opts.input,\n      });\n    }),\n});\n// export type definition of API\nexport type AppRouter = typeof appRouter;\nCopy\n\nIf your router file starts getting too big, split your router into several subrouters each implemented in its own file. Then merge them into a single root appRouter.\n\n3. Use the Express adapter​\n\ntRPC includes an adapter for Express out of the box. This adapter lets you convert your tRPC router into an Express middleware.\n\nserver.ts\nimport { initTRPC } from '@trpc/server';\nimport * as trpcExpress from '@trpc/server/adapters/express';\nimport express from 'express';\n// created for each request\nconst createContext = ({\n  req,\n  res,\n}: trpcExpress.CreateExpressContextOptions) => ({}); // no context\ntype Context = Awaited<ReturnType<typeof createContext>>;\nconst t = initTRPC.context<Context>().create();\nconst appRouter = t.router({\n  // [...]\n});\nconst app = express();\napp.use(\n  '/trpc',\n  trpcExpress.createExpressMiddleware({\n    router: appRouter,\n    createContext,\n  }),\n);\napp.listen(4000);\nCopy\n\nYour endpoints are now available via HTTP!\n\nEndpoint\tHTTP URI\ngetUser\tGET http://localhost:4000/trpc/getUser?input=INPUT\n\nwhere INPUT is a URI-encoded JSON string.\ncreateUser\tPOST http://localhost:4000/trpc/createUser\n\nwith req.body of type {name: string}\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/adapters/fastify",
    "html": "Backend Usage\nHosting tRPC with Adapters\nFastify\nVersion: 11.x\nFastify Adapter\nExample app​\n\nThe best way to start with the Fastify adapter is to take a look at the example application.\n\nDescription\tLinks\n\nFastify server with WebSocket\nSimple tRPC client in node\n\t\nCodeSandbox\nSource\nHow to use tRPC with Fastify​\nInstall dependencies​\nyarn add @trpc/server fastify zod\nCopy\n\nZod isn't a required dependency, but it's used in the sample router below.\n\nCreate the router​\n\nFirst of all you need a router to handle your queries, mutations and subscriptions.\n\nA sample router is given below, save it in a file named router.ts.\n\nrouter.ts\n\nIf your router file starts getting too big, split your router into several subrouters each implemented in its own file. Then merge them into a single root appRouter.\n\nCreate the context​\n\nThen you need a context that will be created for each request.\n\nA sample context is given below, save it in a file named context.ts:\n\ncontext.ts\nCreate Fastify server​\n\ntRPC includes an adapter for Fastify out of the box. This adapter lets you convert your tRPC router into a Fastify plugin. In order to prevent errors during large batch requests, make sure to set the maxParamLength Fastify option to a suitable value, as shown.\n\nTIP\n\nDue to limitations in Fastify's plugin system and type inference, there might be some issues getting for example onError typed correctly. You can add a satisfies FastifyTRPCPluginOptions<AppRouter>['trpcOptions'] to help TypeScript out and get the correct types.\n\nserver.ts\nimport {\n  fastifyTRPCPlugin,\n  FastifyTRPCPluginOptions,\n} from '@trpc/server/adapters/fastify';\nimport fastify from 'fastify';\nimport { createContext } from './context';\nimport { appRouter, type AppRouter } from './router';\nconst server = fastify({\n  routerOptions: {\n    maxParamLength: 5000,\n  },\n});\nserver.register(fastifyTRPCPlugin, {\n  prefix: '/trpc',\n  trpcOptions: {\n    router: appRouter,\n    createContext,\n    onError({ path, error }) {\n      // report to error monitoring\n      console.error(`Error in tRPC handler on path '${path}':`, error);\n    },\n  } satisfies FastifyTRPCPluginOptions<AppRouter>['trpcOptions'],\n});\n(async () => {\n  try {\n    await server.listen({ port: 3000 });\n  } catch (err) {\n    server.log.error(err);\n    process.exit(1);\n  }\n})();\nCopy\n\nYour endpoints are now available via HTTP!\n\nEndpoint\tHTTP URI\ngetUser\tGET http://localhost:3000/trpc/getUserById?input=INPUT\n\nwhere INPUT is a URI-encoded JSON string.\ncreateUser\tPOST http://localhost:3000/trpc/createUser\n\nwith req.body of type User\nEnable WebSockets​\n\nThe Fastify adapter supports WebSockets via the @fastify/websocket plugin. All you have to do in addition to the above steps is install the dependency, add some subscriptions to your router and activate the useWSS option in the plugin. The minimum Fastify version required for @fastify/websocket is 3.11.0.\n\nInstall dependencies​\nyarn add @fastify/websocket\nCopy\nImport and register @fastify/websocket​\nimport ws from '@fastify/websocket';\nserver.register(ws);\nCopy\nAdd some subscriptions​\n\nEdit the router.ts file created in the previous steps and add the following code:\n\nrouter.ts\nimport { initTRPC } from '@trpc/server';\nimport { observable } from '@trpc/server/observable';\nconst t = initTRPC.create();\nexport const appRouter = t.router({\n  randomNumber: t.procedure.subscription(async function* () {\n    while (true) {\n      yield { randomNumber: Math.random() };\n      await new Promise((resolve) => setTimeout(resolve, 1000));\n    }\n  }),\n});\nCopy\nActivate the useWSS option​\nserver.ts\nserver.register(fastifyTRPCPlugin, {\n  useWSS: true,\n  // Enable heartbeat messages to keep connection open (disabled by default)\n  keepAlive: {\n    enabled: true,\n    // server ping message interval in milliseconds\n    pingMs: 30000,\n    // connection is terminated if pong message is not received in this many milliseconds\n    pongWaitMs: 5000,\n  },\n  // ...\n});\nCopy\n\nIt's alright, you can subscribe to the topic randomNumber and you should receive a random number every second 🚀.\n\nFastify plugin options​\nname\ttype\toptional\tdefault\tdescription\nprefix\tstring\ttrue\t\"/trpc\"\t\nuseWSS\tboolean\ttrue\tfalse\t\ntrpcOptions\tNodeHTTPHandlerOptions\tfalse\tn/a\t\nEdit this page"
  },
  {
    "title": "Next.js Adapter | tRPC",
    "url": "https://trpc.io/docs/server/adapters/nextjs",
    "html": "Backend Usage\nHosting tRPC with Adapters\nNext.js\nVersion: 11.x\nNext.js Adapter\nTIP\n\ntRPC's support for Next.js is far more expansive than just an adapter. This page covers a brief summary of how to set up the adapter, but complete documentation is available here\n\nExample app​\nDescription\tLinks\nNext.js Minimal Starter\t\nCodeSandbox\nSource\nNext.js example​\n\nServing your tRPC router in a Next.js project is straight-forward. Just create an API handler in pages/api/trpc/[trpc].ts as shown below:\n\npages/api/trpc/[trpc].ts\nimport { createNextApiHandler } from '@trpc/server/adapters/next';\nimport { createContext } from '../../../server/trpc/context';\nimport { appRouter } from '../../../server/trpc/router/_app';\n// @link https://nextjs.org/docs/api-routes/introduction\nexport default createNextApiHandler({\n  router: appRouter,\n  createContext,\n});\nCopy\nHandling CORS, and other Advanced usage​\n\nWhile you can usually just \"set and forget\" the API Handler as shown above, sometimes you might want to modify it further.\n\nThe API handler created by createNextApiHandler and equivalents in other frameworks is just a function that takes req and res objects. This means you can also modify those objects before passing them to the handler, for example to enable CORS.\n\npages/api/trpc/[trpc].ts\nimport { createNextApiHandler } from '@trpc/server/adapters/next';\nimport { createContext } from '../../../server/trpc/context';\nimport { appRouter } from '../../../server/trpc/router/_app';\n// create the API handler, but don't return it yet\nconst nextApiHandler = createNextApiHandler({\n  router: appRouter,\n  createContext,\n});\n// @link https://nextjs.org/docs/api-routes/introduction\nexport default async function handler(\n  req: NextApiRequest,\n  res: NextApiResponse,\n) {\n  // We can use the response object to enable CORS\n  res.setHeader('Access-Control-Allow-Origin', '*');\n  res.setHeader('Access-Control-Request-Method', '*');\n  res.setHeader('Access-Control-Allow-Methods', 'OPTIONS, GET');\n  res.setHeader('Access-Control-Allow-Headers', '*');\n  // If you need to make authenticated CORS calls then\n  // remove what is above and uncomment the below code\n  // Allow-Origin has to be set to the requesting domain that you want to send the credentials back to\n  // res.setHeader('Access-Control-Allow-Origin', 'http://example:6006');\n  // res.setHeader('Access-Control-Request-Method', '*');\n  // res.setHeader('Access-Control-Allow-Methods', 'OPTIONS, GET');\n  // res.setHeader('Access-Control-Allow-Headers', 'content-type');\n  // res.setHeader('Referrer-Policy', 'no-referrer');\n  // res.setHeader('Access-Control-Allow-Credentials', 'true');\n  if (req.method === 'OPTIONS') {\n    res.writeHead(200);\n    return res.end();\n  }\n  // finally pass the request on to the tRPC handler\n  return nextApiHandler(req, res);\n}\nCopy\nRoute Handlers​\n\nIf you're trying out the Next.js App Router and want to use route handlers, you can do so by using the fetch adapter, as they build on web standard Request and Response objects:\n\napp/api/trpc/[trpc]/route.ts\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\nimport { appRouter } from '~/server/api/router';\nfunction handler(req: Request) {\n  return fetchRequestHandler({\n    endpoint: '/api/trpc',\n    req,\n    router: appRouter,\n    createContext: () => ({ ... })\n  });\n}\nexport { handler as GET, handler as POST };\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/server/adapters/aws-lambda",
    "html": "Backend Usage\nHosting tRPC with Adapters\nAWS Lambda + API Gateway\nVersion: 11.x\nAWS Lambda + API Gateway Adapter\nAWS Lambda adapter​\n\nThe AWS Lambda adapter is supported for API Gateway REST API(v1) and HTTP API(v2), and Lambda Function URL use cases.\n\nhttpBatchLink requires the router to work on a single API Gateway Resource (as shown in the example). If you'd like to have a Resource per procedure, you can use the httpLink instead (more info).\n\nExample app​\nDescription\tLinks\nAPI Gateway with NodeJS client.\t\nSource\nHow to add tRPC​\n1. Install deps​\nyarn add @trpc/server\nCopy\n2. Create a tRPC router​\n\nImplement your tRPC router. A sample router is given below:\n\nserver.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\nexport const t = initTRPC.create();\nconst appRouter = t.router({\n  getUser: t.procedure.input(z.string()).query((opts) => {\n    opts.input; // string\n    return { id: opts.input, name: 'Bilbo' };\n  }),\n});\n// export type definition of API\nexport type AppRouter = typeof appRouter;\nCopy\n3. Use the Amazon API Gateway adapter​\n\ntRPC includes an adapter for API Gateway out of the box. This adapter lets you run your routes through the API Gateway handler.\n\nserver.ts\nimport { CreateAWSLambdaContextOptions, awsLambdaRequestHandler } from '@trpc/server/adapters/aws-lambda';\nconst appRouter = /* ... */;\n// created for each request\nconst createContext = ({\n  event,\n  context,\n}: CreateAWSLambdaContextOptions<APIGatewayProxyEventV2>) => ({}) // no context\ntype Context = Awaited<ReturnType<typeof createContext>>;\nexport const handler = awsLambdaRequestHandler({\n  router: appRouter,\n  createContext,\n})\nCopy\n\nBuild & deploy your code, now use your API Gateway URL to call your function.\n\nEndpoint\tHTTP URI\ngetUser\tGET https://<execution-api-link>/getUser?input=INPUT\n\nwhere INPUT is a URI-encoded JSON string.\nA word about payload format version​\n\nAPI Gateway has two different event data formats when it invokes a Lambda. For REST APIs they should be version \"1.0\"(APIGatewayProxyEvent), but you can choose which for HTTP APIs by stating either version \"1.0\" or \"2.0\".\n\nVersion 1.0: APIGatewayProxyEvent\nVersion 2.0: APIGatewayProxyEventV2\n\nTo infer what version you might have, supply the context as following:\n\nfunction createContext({\n  event,\n  context,\n}: CreateAWSLambdaContextOptions<APIGatewayProxyEvent>) {\n  ...\n}\n// CreateAWSLambdaContextOptions<APIGatewayProxyEvent> or CreateAWSLambdaContextOptions<APIGatewayProxyEventV2>\nCopy\n\nRead more here about payload format version\n\nAWS Lambda Response Streaming Adapter​\n\nAWS Lambda supports streaming responses to clients.\n\nResponse streaming is only supported for Lambda Function URLs. You can not use API Gateway to stream responses. Read more here about response streaming.\n\nExample app​\nDescription\tLinks\nLambda Function URL with NodeJS client.\t\nSource\nResponse Streaming​\n\nThe signature of a streaming handler is different from the default handler. The streaming handler additonally receives a writable stream parameter, responseStream, besides the default node handler parameters, event and context. To indicate that Lambda should stream your responses, you must wrap your function handler with the awslambda.streamifyResponse() decorator.\n\nNote that the awslambda namespace is automatically provided by the Lambda execution environment. You can import the types from @types/aws-lambda to augment the global namespace with the awslambda namespace.\n\nserver.ts\nimport { awsLambdaStreamingRequestHandler } from '@trpc/server/adapters/aws-lambda';\nimport type { StreamifyHandler } from 'aws-lambda';\nconst appRouter = router({\n  iterable: publicProcedure.query(async function* () {\n    for (let i = 0; i < 10; i++) {\n      await new Promise((resolve) => setTimeout(resolve, 500));\n      yield i;\n    }\n  }),\n});\nexport const handler = awslambda.streamifyResponse(\n  awsLambdaStreamingRequestHandler({\n    router: appRouter,\n    /* ... */\n  }),\n);\nCopy\nEdit this page"
  },
  {
    "title": "Fetch / Edge Runtimes Adapter | tRPC",
    "url": "https://trpc.io/docs/server/adapters/fetch",
    "html": "Backend Usage\nHosting tRPC with Adapters\nFetch / Edge Runtimes\nVersion: 11.x\nFetch / Edge Runtimes Adapter\n\nYou can create a tRPC server within any edge runtime that follow the WinterCG, specifically the Minimum Common Web Platform API specification.\n\nSome of these runtimes includes, but not limited to:\n\nCloudflare Workers\nDeno Deploy\nVercel Edge Runtime (& Next.js Edge Runtime)\n\nThis also makes it easy to integrate into frameworks that uses the web platform APIs to represent requests and responses, such as:\n\nAstro (SSR mode)\nRemix\nSolidStart\nExample apps​\nDescription\tLinks\nCloudflare Workers example\t\n\nSource\n\n\nDeno Deploy example\t\n\nSource\n\n\nNext.js Edge Runtime example\t\n\nSource\n\n\nVercel Edge Runtime example\t\n\nSource\n\nHow to use tRPC server with an edge runtime​\n\ntRPC provides a fetch adapter that uses the native Request and Response APIs as input and output. The tRPC-specific code is the same across all runtimes, the only difference being how the response is returned.\n\ntRPC includes an adapter for the native Fetch API out of the box. This adapter lets you convert your tRPC router into a Request handler that returns Response objects.\n\nRequired Web APIs​\n\ntRPC server uses the following Fetch APIs:\n\nRequest, Response\nfetch\nHeaders\nURL\n\nIf your runtime supports these APIs, you can use tRPC server.\n\nTIP\n\nFun fact: that also means you can use a tRPC server in your browser!\n\nCommon setup​\nInstall dependencies​\nTIP\n\nYou can skip this step if you use Deno Deploy.\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client zod\n\nZod isn't a required dependency, but it's used in the sample router below.\n\nCreate the router​\n\nFirst of all you need a router to handle your queries, mutations and subscriptions.\n\nA sample router is given below, save it in a file named router.ts.\n\nrouter.ts\n\nIf your router file starts getting too big, split your router into several subrouters each implemented in its own file. Then merge them into a single root appRouter.\n\nCreate the context​\n\nThen you need a context that will be created for each request.\n\nA sample context is given below, save it in a file named context.ts:\n\ncontext.ts\nRuntimes-specific setup​\nAstro​\nsrc/pages/trpc/[trpc].ts\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\nimport type { APIRoute } from 'astro';\nimport { createContext } from '../../server/context';\nimport { appRouter } from '../../server/router';\nexport const ALL: APIRoute = (opts) => {\n  return fetchRequestHandler({\n    endpoint: '/trpc',\n    req: opts.request,\n    router: appRouter,\n    createContext,\n  });\n};\nCopy\nCloudflare Worker​\nNOTE\n\nYou need the Wrangler CLI to run Cloudflare Workers.\n\nCreate Cloudflare Worker​\nserver.ts\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\nimport { createContext } from './context';\nimport { appRouter } from './router';\nexport default {\n  async fetch(request: Request): Promise<Response> {\n    return fetchRequestHandler({\n      endpoint: '/trpc',\n      req: request,\n      router: appRouter,\n      createContext,\n    });\n  },\n};\nCopy\n\nRun wrangler dev server.ts and your endpoints will be available via HTTP!\n\nEndpoint\tHTTP URI\ngetUser\tGET http://localhost:8787/trpc/getUserById?input=INPUT\n\nwhere INPUT is a URI-encoded JSON string.\ncreateUser\tPOST http://localhost:8787/trpc/createUser\n\nwith req.body of type User\nDeno Oak​\nNOTE\n\nThis assumes you have Deno installed and setup. Refer to their getting started guide for more information.\n\nUpdate the imports in router.ts​\nrouter.ts\nimport { initTRPC } from 'npm:@trpc/server';\nimport { z } from 'npm:zod';\nimport { Context } from './context.ts';\nCopy\nUpdate the imports in context.ts​\ncontext.ts\nimport { FetchCreateContextFnOptions } from 'npm:@trpc/server/adapters/fetch';\nCopy\nUse fetchRequestHandler with Oak in app.ts​\napp.ts\nimport { Application, Router } from 'https://deno.land/x/oak/mod.ts';\nimport { fetchRequestHandler } from 'npm:@trpc/server/adapters/fetch';\nimport { createContext } from './context.ts';\nimport { appRouter } from './router.ts';\nconst app = new Application();\nconst router = new Router();\nrouter.all('/trpc/(.*)', async (ctx) => {\n  const res = await fetchRequestHandler({\n    endpoint: '/trpc',\n    req: new Request(ctx.request.url, {\n      headers: ctx.request.headers,\n      body:\n        ctx.request.method !== 'GET' && ctx.request.method !== 'HEAD'\n          ? ctx.request.body({ type: 'stream' }).value\n          : void 0,\n      method: ctx.request.method,\n    }),\n    router: appRouter,\n    createContext,\n  });\n  ctx.response.status = res.status;\n  ctx.response.headers = res.headers;\n  ctx.response.body = res.body;\n});\napp.use(router.routes());\napp.use(router.allowedMethods());\nawait app.listen({ port: 3000 });\nCopy\nDeno Deploy​\nNOTE\n\nThis assumes you have Deno installed and setup. Refer to their getting started guide for more information.\n\nTIP\n\nSee our example Deno Deploy app for a working example.\n\nUpdate the imports in router.ts​\nrouter.ts\nimport { initTRPC } from 'npm:@trpc/server';\nimport { z } from 'npm:zod';\nimport { Context } from './context.ts';\nCopy\nUpdate the imports in context.ts​\ncontext.ts\nimport { FetchCreateContextFnOptions } from 'npm:@trpc/server/adapters/fetch';\nCopy\nCreate Deno Deploy Function​\nserver.ts\nimport { fetchRequestHandler } from 'npm:@trpc/server/adapters/fetch';\nimport { createContext } from './context.ts';\nimport { appRouter } from './router.ts';\nfunction handler(request) {\n  return fetchRequestHandler({\n    endpoint: '/trpc',\n    req: request,\n    router: appRouter,\n    createContext,\n  });\n}\nDeno.serve(handler);\nCopy\n\nRun deno run --allow-net=:8000 --allow-env ./server.ts and your endpoints will be available via HTTP!\n\nEndpoint\tHTTP URI\ngetUser\tGET http://localhost:8000/trpc/getUserById?input=INPUT\n\nwhere INPUT is a URI-encoded JSON string.\ncreateUser\tPOST http://localhost:8000/trpc/createUser\n\nwith req.body of type User\nNext.js Edge Runtime​\n\nSee a full example here.\n\nRemix​\napp/routes/trpc.$trpc.ts\nimport type { ActionFunctionArgs, LoaderFunctionArgs } from '@remix-run/node';\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\nimport { createContext } from '~/server/context';\nimport { appRouter } from '~/server/router';\nexport const loader = async (args: LoaderFunctionArgs) => {\n  return handleRequest(args);\n};\nexport const action = async (args: ActionFunctionArgs) => {\n  return handleRequest(args);\n};\nfunction handleRequest(args: LoaderFunctionArgs | ActionFunctionArgs) {\n  return fetchRequestHandler({\n    endpoint: '/trpc',\n    req: args.request,\n    router: appRouter,\n    createContext,\n  });\n}\nCopy\nSolidStart​\nsrc/routes/api/trpc/[trpc].ts\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\nimport type { APIEvent } from 'solid-start';\nimport { createContext } from '../../server/context';\nimport { appRouter } from '../../server/router';\nconst handler = (event: APIEvent) =>\n  fetchRequestHandler({\n    endpoint: '/api/trpc',\n    req: event.request,\n    router: appRouter,\n    createContext,\n  });\nexport { handler as GET, handler as POST };\nCopy\nVercel Edge Runtime​\nNOTE\n\nSee the official Vercel Edge Runtime documentation for more information.\n\nTIP\n\nSee our example Vercel Edge Runtime app for a working example.\n\nInstall dependencies​\nnpm\nyarn\npnpm\nbun\nnpm install -g edge-runtime\nCopy\nCreate Edge Runtime Function​\nserver.ts\nimport { fetchRequestHandler } from '@trpc/server/adapters/fetch';\nimport { createContext } from './context';\nimport { appRouter } from './router';\naddEventListener('fetch', (event) => {\n  return event.respondWith(\n    fetchRequestHandler({\n      endpoint: '/trpc',\n      req: event.request,\n      router: appRouter,\n      createContext,\n    }),\n  );\n});\nCopy\n\nRun edge-runtime --listen server.ts --port 3000 and your endpoints will be available via HTTP!\n\nEndpoint\tHTTP URI\ngetUser\tGET http://localhost:3000/trpc/getUserById?input=INPUT\n\nwhere INPUT is a URI-encoded JSON string.\ncreateUser\tPOST http://localhost:3000/trpc/createUser\n\nwith req.body of type User\nEdit this page"
  },
  {
    "title": "Split Link | tRPC",
    "url": "https://trpc.io/docs/client/links/splitLink",
    "html": "Client Usage\nLinks\nSplit Link\nVersion: 11.x\nSplit Link\n\nsplitLink is a link that allows you to branch your link chain's execution depending on a given condition. Both the true and false branches are required. You can provide just one link, or multiple links per branch via an array.\n\nIt's important to note that when you provide links for splitLink to execute, splitLink will create an entirely new link chain based on the links you passed. Therefore, you need to use a terminating link if you only provide one link or add the terminating link at the end of the array if you provide multiple links to be executed on a branch. Here's a visual representation of how splitLink works:\n\ntRPC Client\nOperation\nLink\nLink\nsplitLink\nInitiated\nCompleted\ndown\ndown\nup\nup\nTerminating Link\nRequest\nResponse\nRequest\ntRPC Server\npasses \ncondition?\nLink\nTerminating Link\nLink\ntrue\nBranch\nfalse\nBranch\ndown\nup\nResponse\nYES\nNO\ndown\nup\ndown\nup\nUsage Example​\nDisable batching for certain requests​\n\nLet's say you're using httpBatchLink as the terminating link in your tRPC client config. This means request batching is enabled in every request. However, if you need to disable batching only for certain requests, you would need to change the terminating link in your tRPC client config dynamically between httpLink and httpBatchLink. This is a perfect opportunity for splitLink to be used:\n\n1. Configure client / utils/trpc.ts​\nclient/index.ts\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpLink,\n  splitLink,\n} from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst url = `http://localhost:3000`;\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition(op) {\n        // check for context property `skipBatch`\n        return Boolean(op.context.skipBatch);\n      },\n      // when condition is true, use normal request\n      true: httpLink({\n        url,\n      }),\n      // when condition is false, use batching\n      false: httpBatchLink({\n        url,\n      }),\n    }),\n  ],\n});\nCopy\n2. Perform request without batching​\nclient.ts\nconst postResult = proxy.posts.query(null, {\n  context: {\n    skipBatch: true,\n  },\n});\nCopy\n\nor:\n\nMyComponent.tsx\nexport function MyComponent() {\n  const postsQuery = proxy.posts.useQuery(undefined, {\n    trpc: {\n      context: {\n        skipBatch: true,\n      },\n    }\n  });\n  return (\n    <pre>{JSON.stringify(postsQuery.data ?? null, null, 4)}</pre>\n  )\n})\nCopy\nsplitLink Options​\n\nThe splitLink function takes an options object that has three fields: condition, true, and false.\n\nfunction splitLink<TRouter extends AnyRouter = AnyRouter>(opts: {\n  condition: (op: Operation) => boolean;\n  /**\n   * The link to execute next if the test function returns `true`.\n   */\n  true: TRPCLink<TRouter> | TRPCLink<TRouter>[];\n  /**\n   * The link to execute next if the test function returns `false`.\n   */\n  false: TRPCLink<TRouter> | TRPCLink<TRouter>[];\n}) => TRPCLink<TRouter>\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/httpSubscriptionLink",
    "html": "Client Usage\nLinks\nHTTP Subscription Link\nVersion: 11.x\nHTTP Subscription Link\n\nhttpSubscriptionLink is a terminating link that's uses Server-sent Events (SSE) for subscriptions.\n\nSSE is a good option for real-time as it's a bit easier than setting up a WebSockets-server.\n\nSetup​\nINFO\n\nIf your client's environment doesn't support EventSource, you need an EventSource polyfill. For React Native specific instructions please defer to the compatibility section.\n\nTo use httpSubscriptionLink, you need to use a splitLink to make it explicit that we want to use SSE for subscriptions.\n\nclient/index.ts\nimport type { TRPCLink } from '@trpc/client';\nimport {\n  httpBatchLink,\n  httpSubscriptionLink,\n  loggerLink,\n  splitLink,\n} from '@trpc/client';\nconst trpcClient = createTRPCClient<AppRouter>({\n  /**\n   * @see https://trpc.io/docs/v11/client/links\n   */\n  links: [\n    // adds pretty logs to your console in development and logs errors in production\n    loggerLink(),\n    splitLink({\n      // uses the httpSubscriptionLink for subscriptions\n      condition: (op) => op.type === 'subscription',\n      true: httpSubscriptionLink({\n        url: `/api/trpc`,\n      }),\n      false: httpBatchLink({\n        url: `/api/trpc`,\n      }),\n    }),\n  ],\n});\nCopy\nTIP\n\nThe document here outlines the specific details of using httpSubscriptionLink. For general usage of subscriptions, see our subscriptions guide.\n\nHeaders and authorization / authentication​\nWeb apps​\nSame domain​\n\nIf you're doing a web application, cookies are sent as part of the request as long as your client is on the same domain as the server.\n\nCross-domain​\n\nIf the client and server are not on the same domain, you can use withCredentials: true (read more on MDN here).\n\nExample:\n\n// [...]\nhttpSubscriptionLink({\n  url: 'https://example.com/api/trpc',\n  eventSourceOptions() {\n    return {\n      withCredentials: true, // <---\n    };\n  },\n});\nCopy\nCustom headers through ponyfill​\n\nRecommended for non-web environments\n\nYou can ponyfill EventSource and use the eventSourceOptions -callback to populate headers.\n\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpSubscriptionLink,\n  splitLink,\n} from '@trpc/client';\nimport { EventSourcePolyfill } from 'event-source-polyfill';\nimport type { AppRouter } from '../server/index.js';\n// Initialize the tRPC client\nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition: (op) => op.type === 'subscription',\n      true: httpSubscriptionLink({\n        url: 'http://localhost:3000',\n        // ponyfill EventSource\n        EventSource: EventSourcePolyfill,\n        // options to pass to the EventSourcePolyfill constructor\n        eventSourceOptions: async ({ op }) => {\n          //                          ^ Includes the operation that's being executed\n          // you can use this to generate a signature for the operation\n          const signature = await getSignature(op);\n          return {\n            headers: {\n              authorization: 'Bearer supersecret',\n              'x-signature': signature,\n            },\n          };\n        },\n      }),\n      false: httpBatchLink({\n        url: 'http://localhost:3000',\n      }),\n    }),\n  ],\n});\nCopy\nUpdating configuration on an active connection​\n\nhttpSubscriptionLink leverages SSE through EventSource, ensuring that connections encountering errors like network failures or bad response codes are automatically retried. However, EventSource does not allow re-execution of the eventSourceOptions() or url() options to update its configuration, which is particularly important in scenarios where authentication has expired since the last connection.\n\nTo address this limitation, you can use a retryLink in conjunction with httpSubscriptionLink. This approach ensures that the connection is re-established with the latest configuration, including any updated authentication details.\n\nCAUTION\n\nPlease note that restarting the connection will result in the EventSource being recreated from scratch, which means any previously tracked events will be lost.\n\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpSubscriptionLink,\n  retryLink,\n  splitLink,\n} from '@trpc/client';\nimport {\n  EventSourcePolyfill,\n  EventSourcePolyfillInit,\n} from 'event-source-polyfill';\nimport type { AppRouter } from '../server/index.js';\n// Initialize the tRPC client\nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition: (op) => op.type === 'subscription',\n      false: httpBatchLink({\n        url: 'http://localhost:3000',\n      }),\n      true: [\n        retryLink({\n          retry: (opts) => {\n            opts.op.type;\n            //       ^? will always be 'subscription' since we're in a splitLink\n            const code = opts.error.data?.code;\n            if (!code) {\n              // This shouldn't happen as our httpSubscriptionLink will automatically retry within when there's a non-parsable response\n              console.error('No error code found, retrying', opts);\n              return true;\n            }\n            if (code === 'UNAUTHORIZED' || code === 'FORBIDDEN') {\n              console.log('Retrying due to 401/403 error');\n              return true;\n            }\n            return false;\n          },\n        }),\n        httpSubscriptionLink({\n          url: async () => {\n            // calculate the latest URL if needed...\n            return getAuthenticatedUri();\n          },\n          // ponyfill EventSource\n          EventSource: EventSourcePolyfill,\n          eventSourceOptions: async () => {\n            // ...or maybe renew an access token\n            const token = await auth.getOrRenewToken();\n            return {\n              headers: {\n                authorization: `Bearer ${token}`,\n              },\n            };\n          },\n        }),\n      ],\n    }),\n  ],\n});\nCopy\nConnection params​\n\nIn order to authenticate with EventSource, you can define connectionParams in httpSubscriptionLink. This will be sent as part of the URL, which is why other methods are preferred).\n\nserver/context.ts\nimport type { CreateHTTPContextOptions } from '@trpc/server/adapters/standalone';\n \nexport const createContext = async (opts: CreateHTTPContextOptions) => {\n  const token = opts.info.connectionParams?.token;\n         \nconst token: string | undefined\n \n  // [... authenticate]\n \n  return {};\n};\n \nexport type Context = Awaited<ReturnType<typeof createContext>>;\nCopy\nclient/trpc.ts\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpSubscriptionLink,\n  splitLink,\n} from '@trpc/client';\nimport type { AppRouter } from '../server/index.js';\n// Initialize the tRPC client\nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition: (op) => op.type === 'subscription',\n      true: httpSubscriptionLink({\n        url: 'http://localhost:3000',\n        connectionParams: async () => {\n          // Will be serialized as part of the URL\n          return {\n            token: 'supersecret',\n          };\n        },\n      }),\n      false: httpBatchLink({\n        url: 'http://localhost:3000',\n      }),\n    }),\n  ],\n});\nCopy\nTimeout Configuration​\n\nThe httpSubscriptionLink supports configuring a timeout for inactivity through the reconnectAfterInactivityMs option. If no messages (including ping messages) are received within the specified timeout period, the connection will be marked as \"connecting\" and automatically attempt to reconnect.\n\nThe timeout configuration is set on the server side when initializing tRPC:\n\nserver/trpc.ts\nimport { initTRPC } from '@trpc/server';\nexport const t = initTRPC.create({\n  sse: {\n    client: {\n      reconnectAfterInactivityMs: 3_000,\n    },\n  },\n});\nCopy\nServer Ping Configuration​\n\nThe server can be configured to send periodic ping messages to keep the connection alive and prevent timeout disconnections. This is particularly useful when combined with the reconnectAfterInactivityMs-option.\n\nserver/trpc.ts\nimport { initTRPC } from '@trpc/server';\nexport const t = initTRPC.create({\n  sse: {\n    // Maximum duration of a single SSE connection in milliseconds\n    // maxDurationMs: 60_00,\n    ping: {\n      // Enable periodic ping messages to keep connection alive\n      enabled: true,\n      // Send ping message every 2s\n      intervalMs: 2_000,\n    },\n    // client: {\n    //   reconnectAfterInactivityMs: 3_000\n    // }\n  },\n});\nCopy\nCompatibility (React Native)​\n\nThe httpSubscriptionLink makes use of the EventSource API, Streams API, and AsyncIterators, these are not natively supported by React Native and will have to be ponyfilled.\n\nTo ponyfill EventSource we recommend to use a polyfill that utilizes the networking library exposed by React Native, over using a polyfill that using the XMLHttpRequest API. Libraries that polyfill EventSource using XMLHttpRequest fail to reconnect after the app has been in the background. Consider using the rn-eventsource-reborn package.\n\nThe Streams API can be ponyfilled using the web-streams-polyfill package.\n\nAsyncIterators can be polyfilled using the @azure/core-asynciterator-polyfill package.\n\nInstallation​\n\nInstall the required polyfills:\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install rn-eventsource-reborn web-streams-polyfill @azure/core-asynciterator-polyfill\n\nAdd the polyfills to your project before the link is used (e.g. where you add your TRPCReact.Provider):\n\nutils/api.tsx\nimport '@azure/core-asynciterator-polyfill';\nimport { RNEventSource } from 'rn-eventsource-reborn';\nimport { ReadableStream, TransformStream } from 'web-streams-polyfill';\nglobalThis.ReadableStream = globalThis.ReadableStream || ReadableStream;\nglobalThis.TransformStream = globalThis.TransformStream || TransformStream;\nCopy\n\nOnce the ponyfills are added, you can continue setting up the httpSubscriptionLink as described in the setup section.\n\nhttpSubscriptionLink Options​\ntype HTTPSubscriptionLinkOptions<\n  TRoot extends AnyClientTypes,\n  TEventSource extends EventSourceLike.AnyConstructor = typeof EventSource,\n> = {\n  /**\n   * EventSource ponyfill\n   */\n  EventSource?: TEventSource;\n  /**\n   * EventSource options or a callback that returns them\n   */\n  eventSourceOptions?:\n    | EventSourceLike.InitDictOf<TEventSource>\n    | ((opts: {\n        op: Operation;\n      }) =>\n        | EventSourceLike.InitDictOf<TEventSource>\n        | Promise<EventSourceLike.InitDictOf<TEventSource>>);\n};\nCopy\nSSE Options on the server​\nexport interface SSEStreamProducerOptions<TValue = unknown> {\n  ping?: {\n    /**\n     * Enable ping comments sent from the server\n     * @default false\n     */\n    enabled: boolean;\n    /**\n     * Interval in milliseconds\n     * @default 1000\n     */\n    intervalMs?: number;\n  };\n  /**\n   * Maximum duration in milliseconds for the request before ending the stream\n   * @default undefined\n   */\n  maxDurationMs?: number;\n  /**\n   * End the request immediately after data is sent\n   * Only useful for serverless runtimes that do not support streaming responses\n   * @default false\n   */\n  emitAndEndImmediately?: boolean;\n  /**\n   * Client-specific options - these will be sent to the client as part of the first message\n   * @default {}\n   */\n  client?: {\n    /**\n     * Timeout and reconnect after inactivity in milliseconds\n     * @default undefined\n     */\n    reconnectAfterInactivityMs?: number;\n  };\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/wsLink",
    "html": "Client Usage\nLinks\nWebSocket Link\nVersion: 11.x\nWebSocket Link\n\nwsLink is a terminating link that's used when using tRPC's WebSockets Client and Subscriptions, which you can learn more about here).\n\nUsage​\n\nTo use wsLink, you need to pass it a TRPCWebSocketClient, which you can create with createWSClient:\n\nclient/index.ts\nimport { createTRPCClient, createWSClient, wsLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst wsClient = createWSClient({\n  url: 'ws://localhost:3000',\n});\nconst trpcClient = createTRPCClient<AppRouter>({\n  links: [wsLink<AppRouter>({ client: wsClient })],\n});\nCopy\nAuthentication / Connection params​\n\nSee more here\n\nwsLink / createWSClient Options​\n\nThe wsLink function requires a TRPCWebSocketClient to be passed, which can be configured with the fields defined in WebSocketClientOptions:\n\nexport interface WebSocketLinkOptions {\n  client: TRPCWebSocketClient;\n  /**\n   * Data transformer\n   * @see https://trpc.io/docs/v11/data-transformers\n   **/\n  transformer?: DataTransformerOptions;\n}\nfunction createWSClient(opts: WebSocketClientOptions) => TRPCWebSocketClient\nexport interface WebSocketClientOptions {\n  /**\n   * The URL to connect to (can be a function that returns a URL)\n   */\n  url: string | (() => MaybePromise<string>);\n  /**\n   * Connection params that are available in `createContext()`\n   * These are sent as the first message\n   */\n  connectionParams: string | (() => MaybePromise<string>);\n  /**\n   * Ponyfill which WebSocket implementation to use\n   */\n  WebSocket?: typeof WebSocket;\n  /**\n   * The number of milliseconds before a reconnect is attempted.\n   * @default {@link exponentialBackoff}\n   */\n  retryDelayMs?: typeof exponentialBackoff;\n  /**\n   * Triggered when a WebSocket connection is established\n   */\n  onOpen?: () => void;\n  /**\n   * Triggered when a WebSocket connection encounters an error\n   */\n  onError?: (evt?: Event) => void;\n  /**\n   * Triggered when a WebSocket connection is closed\n   */\n  onClose?: (cause?: { code?: number }) => void;\n  /**\n   * Lazy mode will close the WebSocket automatically after a period of inactivity (no messages sent or received and no pending requests)\n   */\n  lazy?: {\n    /**\n     * Enable lazy mode\n     * @default false\n     */\n    enabled: boolean;\n    /**\n     * Close the WebSocket after this many milliseconds\n     * @default 0\n     */\n    closeMs: number;\n  };\n  /**\n   * Send ping messages to the server and kill the connection if no pong message is returned\n   */\n  keepAlive?: {\n    /**\n     * @default false\n     */\n    enabled: boolean;\n    /**\n     * Send a ping message every this many milliseconds\n     * @default 5_000\n     */\n    intervalMs?: number;\n    /**\n     * Close the WebSocket after this many milliseconds if the server does not respond\n     * @default 1_000\n     */\n    pongTimeoutMs?: number;\n  };\n}\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nVersion: 11.x\nindex\nClasses​\nTRPCClientError\nTRPCUntypedClient\nInterfaces​\nTRPCClientErrorBase\nTRPCClientRuntime\nTRPCProcedureOptions\nTRPCRequestOptions\nWebSocketClientOptions\nType Aliases​\nCreateTRPCClient\nHTTPBatchLinkOptions\ninferRouterProxyClient\nLocalLinkOptions\nTRPCClient\nTRPCClientErrorLike\nTRPCFetch\nTRPCLink\nTRPCWebSocketClient\nFunctions​\ncreateTRPCProxyClient\ncreateTRPCUntypedClient\ncreateWSClient\nexperimental_localLink\ngetFetch\nhttpBatchStreamLink\nhttpSubscriptionLink\nisFormData\nisNonJsonSerializable\nisOctetType\nisTRPCClientError\nretryLink\nunstable_httpBatchStreamLink\nunstable_httpSubscriptionLink\nunstable_localLink\nReferences​\ncreateTRPCClient​\n\nRenames and re-exports createTRPCProxyClient\n\nhttpBatchLink​\n\nRe-exports httpBatchLink\n\nhttpLink​\n\nRe-exports httpLink\n\nHTTPLinkOptions​\n\nRe-exports HTTPLinkOptions\n\ninferRouterClient​\n\nRenames and re-exports inferRouterProxyClient\n\nloggerLink​\n\nRe-exports loggerLink\n\nLoggerLinkOptions​\n\nRe-exports LoggerLinkOptions\n\nsplitLink​\n\nRe-exports splitLink\n\nWebSocketLinkOptions​\n\nRe-exports WebSocketLinkOptions\n\nwsLink​\n\nRe-exports wsLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/next/",
    "html": "API Reference (Auto-generated)\n@trpc/next\nVersion: 11.x\n@trpc/next\nType Aliases​\nTRPCPrepassHelper\nTRPCPrepassProps\nWithTRPCConfig\nWithTRPCNoSSROptions\nWithTRPCSSROptions\nFunctions​\ncreateTRPCNext\nwithTRPC\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nVersion: 11.x\n@trpc/react-query\nModules​\nindex\nserver\nshared\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/server/",
    "html": "API Reference (Auto-generated)\n@trpc/server\nVersion: 11.x\n@trpc/server\nType Aliases​\ninferProcedureInput\ninferProcedureOutput\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/httpBatchLink/",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/httpBatchLink\nVersion: 11.x\nlinks/httpBatchLink\nFunctions​\nhttpBatchLink\nEdit this page"
  },
  {
    "title": "links/httpLink | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/httpLink/",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/httpLink\nVersion: 11.x\nlinks/httpLink\nType Aliases​\nHTTPLinkOptions\nFunctions​\nhttpLink\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/loggerLink/",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/loggerLink\nVersion: 11.x\nlinks/loggerLink\nInterfaces​\nLoggerLinkOptions\nFunctions​\nloggerLink\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/splitLink/",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/splitLink\nVersion: 11.x\nlinks/splitLink\nFunctions​\nsplitLink\nEdit this page"
  },
  {
    "title": "links/wsLink/wsLink | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/wsLink/wsLink/",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nwsLink\nlinks/wsLink/wsLink\nVersion: 11.x\nlinks/wsLink/wsLink\nType Aliases​\nWebSocketLinkOptions\nFunctions​\nwsLink\nReferences​\ncreateWSClient​\n\nRe-exports createWSClient\n\nTRPCWebSocketClient​\n\nRe-exports TRPCWebSocketClient\n\nWebSocketClientOptions​\n\nRe-exports WebSocketClientOptions\n\nEdit this page"
  },
  {
    "title": "TanStack React Query | tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/setup",
    "html": "Client Usage\nTanStack React Query (⭐️)\nSetup\nVersion: 11.x\nTanStack React Query\n\nCompared to our classic React Query Integration this client is simpler and more TanStack Query-native, providing factories for common TanStack React Query interfaces like QueryKeys, QueryOptions, and MutationOptions. We think it's the future and recommend using this over the classic client, read the announcement post for more information about this change.\n\nTIP\n\nYou can try this integration out on the homepage of tRPC.io: https://trpc.io/?try=minimal-react#try-it-out\n\n❓ Do I have to use an integration?\nSetup​\n1. Install dependencies​\n\nThe following dependencies should be installed\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/tanstack-react-query @tanstack/react-query\n2. Import your AppRouter​\n\nImport your AppRouter type into the client application. This type holds the shape of your entire API.\n\nutils/trpc.ts\nimport type { AppRouter } from '../server/router';\nCopy\nTIP\n\nBy using import type you ensure that the reference will be stripped at compile-time, meaning you don't inadvertently import server-side code into your client. For more information, see the Typescript docs.\n\n3a. Set up the tRPC context provider​\n\nIn cases where you rely on React context, such as when using server-side rendering in full-stack frameworks like Next.js, it's important to create a new QueryClient for each request so that your users don't end up sharing the same cache, you can use the createTRPCContext to create a set of type-safe context providers and consumers from your AppRouter type signature.\n\nutils/trpc.ts\nimport { createTRPCContext } from '@trpc/tanstack-react-query';\nimport type { AppRouter } from '../server/router';\n \nexport const { TRPCProvider, useTRPC, useTRPCClient } = createTRPCContext<AppRouter>();\nCopy\n\nThen, create a tRPC client, and wrap your application in the TRPCProvider, as below. You will also need to set up and connect React Query, which they document in more depth.\n\nTIP\n\nIf you already use React Query in your application, you should re-use the QueryClient and QueryClientProvider you already have. You can read more about the QueryClient initialization in the React Query docs.\n\ncomponents/App.tsx\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport { useState } from 'react';\nimport { TRPCProvider } from './utils/trpc';\nfunction makeQueryClient() {\n  return new QueryClient({\n    defaultOptions: {\n      queries: {\n        // With SSR, we usually want to set some default staleTime\n        // above 0 to avoid refetching immediately on the client\n        staleTime: 60 * 1000,\n      },\n    },\n  });\n}\nlet browserQueryClient: QueryClient | undefined = undefined;\nfunction getQueryClient() {\n  if (typeof window === 'undefined') {\n    // Server: always make a new query client\n    return makeQueryClient();\n  } else {\n    // Browser: make a new query client if we don't already have one\n    // This is very important, so we don't re-make a new client if React\n    // suspends during the initial render. This may not be needed if we\n    // have a suspense boundary BELOW the creation of the query client\n    if (!browserQueryClient) browserQueryClient = makeQueryClient();\n    return browserQueryClient;\n  }\n}\nexport function App() {\n  const queryClient = getQueryClient();\n  const [trpcClient] = useState(() =>\n    createTRPCClient<AppRouter>({\n      links: [\n        httpBatchLink({\n          url: 'http://localhost:2022',\n        }),\n      ],\n    }),\n  );\n  return (\n    <QueryClientProvider client={queryClient}>\n      <TRPCProvider trpcClient={trpcClient} queryClient={queryClient}>\n        {/* Your app here */}\n      </TRPCProvider>\n    </QueryClientProvider>\n  );\n}\nCopy\n3b. Set up with Query/Mutation Key Prefixing enabled​\n\nIf you want to prefix all queries and mutations with a specific key, see Query Key Prefixing for setup and usage examples.\n\n3c. Set up without React context​\n\nWhen building an SPA using only client-side rendering with something like Vite, you can create the QueryClient and tRPC client outside of React context as singletons.\n\nutils/trpc.ts\nimport { QueryClient } from '@tanstack/react-query';\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport { createTRPCOptionsProxy } from '@trpc/tanstack-react-query';\nimport type { AppRouter } from '../server/router';\nexport const queryClient = new QueryClient();\nconst trpcClient = createTRPCClient<AppRouter>({\n  links: [httpBatchLink({ url: 'http://localhost:2022' })],\n});\nexport const trpc = createTRPCOptionsProxy<AppRouter>({\n  client: trpcClient,\n  queryClient,\n});\nCopy\ncomponents/App.tsx\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport React from 'react';\nimport { queryClient } from './utils/trpc';\nexport function App() {\n  return (\n    <QueryClientProvider client={queryClient}>\n      {/* Your app here */}\n    </QueryClientProvider>\n  );\n}\nCopy\n4. Fetch data​\n\nYou can now use the tRPC React Query integration to call queries and mutations on your API.\n\ncomponents/user-list.tsx\nimport { useMutation, useQuery } from '@tanstack/react-query';\nimport { useTRPC } from '../utils/trpc';\nexport default function UserList() {\n  const trpc = useTRPC(); // use `import { trpc } from './utils/trpc'` if you're using the singleton pattern\n  const userQuery = useQuery(trpc.getUser.queryOptions({ id: 'id_bilbo' }));\n  const userCreator = useMutation(trpc.createUser.mutationOptions());\n  return (\n    <div>\n      <p>{userQuery.data?.name}</p>\n      <button onClick={() => userCreator.mutate({ name: 'Frodo' })}>\n        Create Frodo\n      </button>\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/migrating",
    "html": "Client Usage\nTanStack React Query (⭐️)\nMigrating\nVersion: 11.x\nMigrating from the classic React Client\n\nThere are a few approaches to migrate over, and this library is a significant departure from the classic client, so we're not expecting anybody to do it in one shot. But you will probably want to try a combination of...\n\nCodemod migration​\nINFO\n\nThe codemod is a work in progress and we're looking for help to make it better. If you're interested in contributing to the codemod, please see Julius' comment here.\n\nWe're working on a codemod to help you migrate your existing codebase over to the new client. This is already available to try but we need your feedback and contributions to improve it. Codemods are very tricky to get right so we're looking for your help to make it as effective as possible.\n\nRun our upgrade CLI:\n\nnpx @trpc/upgrade\nCopy\n\nWhen prompted, select the transforms Migrate Hooks to xxxOptions API and Migrate context provider setup.\n\nGradual migration​\n\nThe new and classic clients are compatible with each other and can live together in the same application. This means you can start migrating by using the new client in new parts of your application, and gradually migrate over existing usage as you see fit. Most importantly, Query Keys are identical, which means you can use the new client and classic client together and still rely on TanStack Query's caching.\n\nMigrating Queries​\n\nA classic query would look like this\n\nimport { trpc } from './trpc';\nfunction Users() {\n  const greetingQuery = trpc.greeting.useQuery({ name: 'Jerry' });\n  // greetingQuery.data === 'Hello Jerry'\n}\nCopy\n\nand changes to\n\nimport { useQuery } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const greetingQuery = useQuery(trpc.greeting.queryOptions({ name: 'Jerry' }));\n  // greetingQuery.data === 'Hello Jerry'\n}\nCopy\nMigrating Invalidations and other QueryClient usages​\n\nA classic query would look like this\n\nimport { trpc } from './trpc';\nfunction Users() {\n  const utils = trpc.useUtils();\n  async function invalidateGreeting() {\n    await utils.greeting.invalidate({ name: 'Jerry' });\n  }\n}\nCopy\n\nand changes to\n\nimport { useQuery, useQueryClient } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const queryClient = useQueryClient();\n  async function invalidateGreeting() {\n    await queryClient.invalidateQueries(\n      trpc.greeting.queryFilter({ name: 'Jerry' }),\n    );\n  }\n}\nCopy\n\nThis is the same for any QueryClient usage, instead of using tRPC's useUtils you can now follow the TanStack documentation directly\n\nMigrating Mutations​\n\nA classic mutation might look like this\n\nimport { trpc } from './trpc';\nfunction Users() {\n  const createUserMutation = trpc.createUser.useMutation();\n  createUserMutation.mutate({ name: 'Jerry' });\n}\nCopy\n\nand changes to\n\nimport { useMutation } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const createUserMutation = useMutation(trpc.createUser.mutationOptions());\n  createUserMutation.mutate({ name: 'Jerry' });\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/usage",
    "html": "Client Usage\nTanStack React Query (⭐️)\nUsage\nVersion: 11.x\nTanStack React Query\n\nCompared to our classic React Query Integration this client is simpler and more TanStack Query-native, providing factories for common TanStack React Query interfaces like QueryKeys, QueryOptions, and MutationOptions. We think it's the future and recommend using this over the classic client, read the announcement post for more information about this change.\n\nQuick example query​\nimport { useQuery } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const greetingQuery = useQuery(trpc.greeting.queryOptions({ name: 'Jerry' }));\n  // greetingQuery.data === 'Hello Jerry'\n}\nCopy\nUsage​\n\nThe philosophy of this client is to provide thin and type-safe factories which work natively and type-safely with Tanstack React Query. This means just by following the autocompletes the client gives you, you can focus on building just with the knowledge the TanStack React Query docs provide.\n\nexport default function Basics() {\n  const trpc = useTRPC();\n  const queryClient = useQueryClient();\n  // Create QueryOptions which can be passed to query hooks\n  const myQueryOptions = trpc.path.to.query.queryOptions({ /** inputs */ })\n  const myQuery = useQuery(myQueryOptions)\n  // or:\n  // useSuspenseQuery(myQueryOptions)\n  // useInfiniteQuery(myQueryOptions)\n  // Create MutationOptions which can be passed to useMutation\n  const myMutationOptions = trpc.path.to.mutation.mutationOptions()\n  const myMutation = useMutation(myMutationOptions)\n  // Create a QueryKey which can be used to manipulated many methods\n  // on TanStack's QueryClient in a type-safe manner\n  const myQueryKey = trpc.path.to.query.queryKey()\n  const invalidateMyQueryKey = () => {\n    queryClient.invalidateQueries({ queryKey: myQueryKey })\n  }\n  return (\n    // Your app here\n  )\n}\nCopy\n\nThe trpc object is fully type-safe and will provide autocompletes for all the procedures in your AppRouter. At the end of the proxy, the following methods are available:\n\nqueryOptions - querying data​\n\nAvailable for all query procedures. Provides a type-safe wrapper around Tanstack's queryOptions function. The first argument is the input for the procedure, and the second argument accepts any native Tanstack React Query options.\n\nconst queryOptions = trpc.path.to.query.queryOptions(\n  {\n    /** input */\n  },\n  {\n    // Any Tanstack React Query options\n    staleTime: 1000,\n  },\n);\nCopy\n\nYou can additionally provide a trpc object to the queryOptions function to provide tRPC request options to the client.\n\nconst queryOptions = trpc.path.to.query.queryOptions(\n  {\n    /** input */\n  },\n  {\n    trpc: {\n      // Provide tRPC request options to the client\n      context: {\n        // see https://trpc.io/docs/client/links#managing-context\n      },\n    },\n  },\n);\nCopy\n\nIf you want to disable a query in a type safe way, you can use skipToken:\n\nimport { skipToken } from '@tanstack/react-query';\nconst query = useQuery(\n  trpc.user.details.queryOptions(\n    user?.id && project?.id\n      ? {\n          userId: user.id,\n          projectId: project.id,\n        }\n      : skipToken,\n    {\n      staleTime: 1000,\n    },\n  ),\n);\nCopy\n\nThe result can be passed to useQuery or useSuspenseQuery hooks or query client methods like fetchQuery, prefetchQuery, prefetchInfiniteQuery, invalidateQueries, etc.\n\ninfiniteQueryOptions - querying infinite data​\n\nAvailable for all query procedures that takes a cursor input. Provides a type-safe wrapper around Tanstack's infiniteQueryOptions function. The first argument is the input for the procedure, and the second argument accepts any native Tanstack React Query options.\n\nconst infiniteQueryOptions = trpc.path.to.query.infiniteQueryOptions(\n  {\n    /** input */\n  },\n  {\n    // Any Tanstack React Query options\n    getNextPageParam: (lastPage, pages) => lastPage.nextCursor,\n  },\n);\nCopy\nqueryKey - getting the query key and performing operations on the query client​\n\nAvailable for all query procedures. Allows you to access the query key in a type-safe manner.\n\nconst queryKey = trpc.path.to.query.queryKey();\nCopy\n\nSince Tanstack React Query uses fuzzy matching for query keys, you can also create a partial query key for any sub-path to match all queries belonging to a router:\n\nconst queryKey = trpc.router.pathKey();\nCopy\n\nOr even the root path to match all tRPC queries:\n\nconst queryKey = trpc.pathKey();\nCopy\nqueryFilter - creating query filters​\n\nAvailable for all query procedures. Allows creating query filters in a type-safe manner.\n\nconst queryFilter = trpc.path.to.query.queryFilter(\n  {\n    /** input */\n  },\n  {\n    // Any Tanstack React Query filter\n    predicate: (query) => {\n      query.state.data;\n    },\n  },\n);\nCopy\n\nLike with query keys, if you want to run a filter across a whole router you can use pathFilter to target any sub-path.\n\nconst queryFilter = trpc.path.pathFilter({\n  // Any Tanstack React Query filter\n  predicate: (query) => {\n    query.state.data;\n  },\n});\nCopy\n\nUseful for creating filters that can be passed to client methods like queryClient.invalidateQueries etc.\n\nmutationOptions - creating mutation options​\n\nAvailable for all mutation procedures. Provides a type-safe identify function for constructing options that can be passed to useMutation.\n\nconst mutationOptions = trpc.path.to.mutation.mutationOptions({\n  // Any Tanstack React Query options\n  onSuccess: (data) => {\n    // do something with the data\n  },\n});\nCopy\nmutationKey - getting the mutation key​\n\nAvailable for all mutation procedures. Allows you to get the mutation key in a type-safe manner.\n\nconst mutationKey = trpc.path.to.mutation.mutationKey();\nCopy\nsubscriptionOptions - creating subscription options​\n\nTanStack does not provide a subscription hook, so we continue to expose our own abstraction here which works with a standard tRPC subscription setup. Available for all subscription procedures. Provides a type-safe identify function for constructing options that can be passed to useSubscription. Note that you need to have either the httpSubscriptionLink or wsLink configured in your tRPC client to use subscriptions.\n\nfunction SubscriptionExample() {\n  const trpc = useTRPC();\n  const subscription = useSubscription(\n    trpc.path.to.subscription.subscriptionOptions(\n      {\n        /** input */\n      },\n      {\n        enabled: true,\n        onStarted: () => {\n          // do something when the subscription is started\n        },\n        onData: (data) => {\n          // you can handle the data here\n        },\n        onError: (error) => {\n          // you can handle the error here\n        },\n        onConnectionStateChange: (state) => {\n          // you can handle the connection state here\n        },\n      },\n    ),\n  );\n  // Or you can handle the state here\n  subscription.data; // The lastly received data\n  subscription.error; // The lastly received error\n  /**\n   * The current status of the subscription.\n   * Will be one of: `'idle'`, `'connecting'`, `'pending'`, or `'error'`.\n   *\n   * - `idle`: subscription is disabled or ended\n   * - `connecting`: trying to establish a connection\n   * - `pending`: connected to the server, receiving data\n   * - `error`: an error occurred and the subscription is stopped\n   */\n  subscription.status;\n  // Reset the subscription (if you have an error etc)\n  subscription.reset();\n  return <>{/* ... */}</>;\n}\nCopy\nQuery Key Prefixing​\n\nWhen using multiple tRPC providers in a single application (e.g., connecting to different backend services), queries with the same path will collide in the cache. You can prevent this by enabling query key prefixing.\n\n// Without prefixes - these would collide!\nconst authQuery = useQuery(trpcAuth.list.queryOptions()); // auth service\nconst billingQuery = useQuery(trpcBilling.list.queryOptions()); // billing service\nCopy\n\nEnable the feature flag when creating your context:\n\nutils/trpc.ts\n// [...]\nconst billing = createTRPCContext<BillingRouter, { keyPrefix: true }>();\nexport const BillingProvider = billing.TRPCProvider;\nexport const useBilling = billing.useTRPC;\nexport const createBillingClient = () =>\n  createTRPCClient<BillingRouter>({\n    links: [\n      /* ... */\n    ],\n  });\nconst account = createTRPCContext<AccountRouter, { keyPrefix: true }>();\nexport const AccountProvider = account.TRPCProvider;\nexport const useAccount = account.useTRPC;\nexport const createAccountClient = () =>\n  createTRPCClient<AccountRouter>({\n    links: [\n      /* ... */\n    ],\n  });\nCopy\nApp.tsx\n// [...]\nexport function App() {\n  const [queryClient] = useState(() => new QueryClient());\n  const [billingClient] = useState(() => createBillingClient());\n  const [accountClient] = useState(() => createAccountClient());\n  return (\n    <QueryClientProvider client={queryClient}>\n      <BillingProvider\n        trpcClient={billingClient}\n        queryClient={queryClient}\n        keyPrefix=\"billing\"\n      >\n        <AccountProvider\n          trpcClient={accountClient}\n          queryClient={queryClient}\n          keyPrefix=\"account\"\n        >\n          {/* ... */}\n        </AccountProvider>\n      </BillingProvider>\n    </QueryClientProvider>\n  );\n}\nCopy\ncomponents/MyComponent.tsx\n// [...]\nexport function MyComponent() {\n  const billing = useBilling();\n  const account = useAccount();\n  const billingList = useQuery(billing.list.queryOptions());\n  const accountList = useQuery(account.list.queryOptions());\n  return (\n    <div>\n      <div>Billing: {JSON.stringify(billingList.data ?? null)}</div>\n      <div>Account: {JSON.stringify(accountList.data ?? null)}</div>\n    </div>\n  );\n}\nCopy\n\nThe query keys will be properly prefixed to avoid collisions:\n\n// Example of how the query keys look with prefixes\nconst queryKeys = [\n  [['billing'], ['list'], { type: 'query' }],\n  [['account'], ['list'], { type: 'query' }],\n];\nCopy\nInferring Input and Output types​\n\nWhen you need to infer the input and output types for a procedure or router, there are 2 options available depending on the situation.\n\nInfer the input and output types of a full router\n\nimport type { inferRouterInputs, inferRouterOutputs } from '@trpc/server';\nimport { AppRouter } from './path/to/server';\nexport type Inputs = inferRouterInputs<AppRouter>;\nexport type Outputs = inferRouterOutputs<AppRouter>;\nCopy\n\nInfer types for a single procedure\n\nimport type { inferInput, inferOutput } from '@trpc/tanstack-react-query';\nfunction Component() {\n  const trpc = useTRPC();\n  type Input = inferInput<typeof trpc.path.to.procedure>;\n  type Output = inferOutput<typeof trpc.path.to.procedure>;\n}\nCopy\nAccessing the tRPC client​\n\nIf you used the setup with React Context, you can access the tRPC client using the useTRPCClient hook.\n\nimport { useTRPCClient } from './trpc';\nfunction Component() {\n  const trpcClient = useTRPCClient();\n  const result = await trpcClient.path.to.procedure.query({\n    /** input */\n  });\n}\nCopy\n\nIf you setup without React Context, you can import the global client instance directly instead.\n\nimport { client } from './trpc';\nconst result = await client.path.to.procedure.query({\n  /** input */\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/server-components",
    "html": "Client Usage\nTanStack React Query (⭐️)\nServer Components\nVersion: 11.x\nSet up with React Server Components\n\nThis guide is an overview of how one may use tRPC with a React Server Components (RSC) framework such as Next.js App Router. Be aware that RSC on its own solves a lot of the same problems tRPC was designed to solve, so you may not need tRPC at all.\n\nThere are also not a one-size-fits-all way to integrate tRPC with RSCs, so see this guide as a starting point and adjust it to your needs and preferences.\n\nINFO\n\nIf you're looking for how to use tRPC with Server Actions, check out this blog post by Julius.\n\nCAUTION\n\nPlease read React Query's Advanced Server Rendering docs before proceeding to understand the different types of server rendering and what footguns to avoid.\n\nAdd tRPC to existing projects​\n1. Install deps​\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/tanstack-react-query @tanstack/react-query@latest zod client-only server-only\n2. Create a tRPC router​\n\nInitialize your tRPC backend in trpc/init.ts using the initTRPC function, and create your first router. We're going to make a simple \"hello world\" router and procedure here - but for deeper information on creating your tRPC API you should refer to the Quickstart guide and Backend usage docs for tRPC information.\n\nINFO\n\nThe file names used here are not enforced by tRPC. You may use any file structure you wish.\n\nView sample backend\n3. Create a Query Client factory​\n\nCreate a shared file trpc/query-client.ts that exports a function that creates a QueryClient instance.\n\ntrpc/query-client.ts\nimport {\n  defaultShouldDehydrateQuery,\n  QueryClient,\n} from '@tanstack/react-query';\nimport superjson from 'superjson';\nexport function makeQueryClient() {\n  return new QueryClient({\n    defaultOptions: {\n      queries: {\n        staleTime: 30 * 1000,\n      },\n      dehydrate: {\n        // serializeData: superjson.serialize,\n        shouldDehydrateQuery: (query) =>\n          defaultShouldDehydrateQuery(query) ||\n          query.state.status === 'pending',\n      },\n      hydrate: {\n        // deserializeData: superjson.deserialize,\n      },\n    },\n  });\n}\nCopy\n\nWe're setting a few default options here:\n\nstaleTime: With SSR, we usually want to set some default staleTime above 0 to avoid refetching immediately on the client.\nshouldDehydrateQuery: This is a function that determines whether a query should be dehydrated or not. Since the RSC transport protocol supports hydrating promises over the network, we extend the defaultShouldDehydrateQuery function to also include queries that are still pending. This will allow us to start prefetching in a server component high up the tree, then consuming that promise in a client component further down.\nserializeData and deserializeData (optional): If you set up a data transformer in the previous step, set this option to make sure the data is serialized correctly when hydrating the query client over the server-client boundary.\n4. Create a tRPC client for Client Components​\n\nThe trpc/client.tsx is the entrypoint when consuming your tRPC API from client components. In here, import the type definition of your tRPC router and create typesafe hooks using createTRPCContext. We'll also export our context provider from this file.\n\ntrpc/client.tsx\n'use client';\n// ^-- to make sure we can mount the Provider from a server component\nimport type { QueryClient } from '@tanstack/react-query';\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport { createTRPCContext } from '@trpc/tanstack-react-query';\nimport { useState } from 'react';\nimport { makeQueryClient } from './query-client';\nimport type { AppRouter } from './routers/_app';\nexport const { TRPCProvider, useTRPC } = createTRPCContext<AppRouter>();\nlet browserQueryClient: QueryClient;\nfunction getQueryClient() {\n  if (typeof window === 'undefined') {\n    // Server: always make a new query client\n    return makeQueryClient();\n  }\n  // Browser: make a new query client if we don't already have one\n  // This is very important, so we don't re-make a new client if React\n  // suspends during the initial render. This may not be needed if we\n  // have a suspense boundary BELOW the creation of the query client\n  if (!browserQueryClient) browserQueryClient = makeQueryClient();\n  return browserQueryClient;\n}\nfunction getUrl() {\n  const base = (() => {\n    if (typeof window !== 'undefined') return '';\n    if (process.env.VERCEL_URL) return `https://${process.env.VERCEL_URL}`;\n    return 'http://localhost:3000';\n  })();\n  return `${base}/api/trpc`;\n}\nexport function TRPCReactProvider(\n  props: Readonly<{\n    children: React.ReactNode;\n  }>,\n) {\n  // NOTE: Avoid useState when initializing the query client if you don't\n  //       have a suspense boundary between this and the code that may\n  //       suspend because React will throw away the client on the initial\n  //       render if it suspends and there is no boundary\n  const queryClient = getQueryClient();\n  const [trpcClient] = useState(() =>\n    createTRPCClient<AppRouter>({\n      links: [\n        httpBatchLink({\n          // transformer: superjson, <-- if you use a data transformer\n          url: getUrl(),\n        }),\n      ],\n    }),\n  );\n  return (\n    <QueryClientProvider client={queryClient}>\n      <TRPCProvider trpcClient={trpcClient} queryClient={queryClient}>\n        {props.children}\n      </TRPCProvider>\n    </QueryClientProvider>\n  );\n}\nCopy\n\nMount the provider in the root of your application (e.g. app/layout.tsx when using Next.js).\n\n5. Create a tRPC caller for Server Components​\n\nTo prefetch queries from server components, we create a proxy from our router. You can also pass in a client if your router is on a separate server.\n\ntrpc/server.tsx\nimport 'server-only'; // <-- ensure this file cannot be imported from the client\nimport { createTRPCOptionsProxy } from '@trpc/tanstack-react-query';\nimport { cache } from 'react';\nimport { createTRPCContext } from './init';\nimport { makeQueryClient } from './query-client';\nimport { appRouter } from './routers/_app';\n// IMPORTANT: Create a stable getter for the query client that\n//            will return the same client during the same request.\nexport const getQueryClient = cache(makeQueryClient);\nexport const trpc = createTRPCOptionsProxy({\n  ctx: createTRPCContext,\n  router: appRouter,\n  queryClient: getQueryClient,\n});\n// If your router is on a separate server, pass a client:\ncreateTRPCOptionsProxy({\n  client: createTRPCClient({\n    links: [httpLink({ url: '...' })],\n  }),\n  queryClient: getQueryClient,\n});\nCopy\nUsing your API​\n\nNow you can use your tRPC API in your app. While you can use the React Query hooks in client components just like you would in any other React app, we can take advantage of the RSC capabilities by prefetching queries in a server component high up the tree. You may be familiar with this concept as \"render as you fetch\" commonly implemented as loaders. This means the request fires as soon as possible but without suspending until the data is needed by using the useQuery or useSuspenseQuery hooks.\n\nThis approach leverages Next.js App Router's streaming capabilities, initiating the query on the server and streaming data to the client as it becomes available. It optimizes both the time to first byte in the browser and the data fetch time, resulting in faster page loads. However, greeting.data may initially be undefined before the data streams in.\n\nIf you prefer to avoid this initial undefined state, you can await the prefetchQuery call. This ensures the query on the client always has data on first render, but it comes with a tradeoff - the page will load more slowly since the server must complete the query before sending HTML to the client.\n\napp/page.tsx\nimport { dehydrate, HydrationBoundary } from '@tanstack/react-query';\nimport { getQueryClient, trpc } from '~/trpc/server';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  const queryClient = getQueryClient();\n  void queryClient.prefetchQuery(\n    trpc.hello.queryOptions({\n      /** input */\n    }),\n  );\n  return (\n    <HydrationBoundary state={dehydrate(queryClient)}>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrationBoundary>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\n// <-- hooks can only be used in client components\nimport { useQuery } from '@tanstack/react-query';\nimport { useTRPC } from '~/trpc/client';\nexport function ClientGreeting() {\n  const trpc = useTRPC();\n  const greeting = useQuery(trpc.hello.queryOptions({ text: 'world' }));\n  if (!greeting.data) return <div>Loading...</div>;\n  return <div>{greeting.data.greeting}</div>;\n}\nCopy\nTIP\n\nYou can also create a prefetch and HydrateClient helper functions to make it a bit more consice and reusable:\n\ntrpc/server.tsx\nexport function HydrateClient(props: { children: React.ReactNode }) {\n  const queryClient = getQueryClient();\n  return (\n    <HydrationBoundary state={dehydrate(queryClient)}>\n      {props.children}\n    </HydrationBoundary>\n  );\n}\nexport function prefetch<T extends ReturnType<TRPCQueryOptions<any>>>(\n  queryOptions: T,\n) {\n  const queryClient = getQueryClient();\n  if (queryOptions.queryKey[1]?.type === 'infinite') {\n    void queryClient.prefetchInfiniteQuery(queryOptions as any);\n  } else {\n    void queryClient.prefetchQuery(queryOptions);\n  }\n}\nCopy\n\nThen you can use it like this:\n\nimport { HydrateClient, prefetch, trpc } from '~/trpc/server';\nfunction Home() {\n  prefetch(\n    trpc.hello.queryOptions({\n      /** input */\n    }),\n  );\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrateClient>\n  );\n}\nCopy\nLeveraging Suspense​\n\nYou may prefer handling loading and error states using Suspense and Error Boundaries. You can do this by using the useSuspenseQuery hook.\n\napp/page.tsx\nimport { HydrateClient, prefetch, trpc } from '~/trpc/server';\nimport { Suspense } from 'react';\nimport { ErrorBoundary } from 'react-error-boundary';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  prefetch(trpc.hello.queryOptions());\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ErrorBoundary fallback={<div>Something went wrong</div>}>\n        <Suspense fallback={<div>Loading...</div>}>\n          <ClientGreeting />\n        </Suspense>\n      </ErrorBoundary>\n    </HydrateClient>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\nimport { useSuspenseQuery } from '@tanstack/react-query';\nimport { trpc } from '~/trpc/client';\nexport function ClientGreeting() {\n  const trpc = useTRPC();\n  const { data } = useSuspenseQuery(trpc.hello.queryOptions());\n  return <div>{data.greeting}</div>;\n}\nCopy\nGetting data in a server component​\n\nIf you need access to the data in a server component, we recommend creating a server caller and using it directly. Please note that this method is detached from your query client and does not store the data in the cache. This means that you cannot use the data in a server component and expect it to be available in the client. This is intentional and explained in more detail in the Advanced Server Rendering guide.\n\ntrpc/server.tsx\n// ...\nexport const caller = appRouter.createCaller(createTRPCContext);\nCopy\napp/page.tsx\nimport { caller } from '~/trpc/server';\nexport default async function Home() {\n  const greeting = await caller.hello();\n  //    ^? { greeting: string }\n  return <div>{greeting.greeting}</div>;\n}\nCopy\n\nIf you really need to use the data both on the server as well as inside client components and understand the tradeoffs explained in the Advanced Server Rendering guide, you can use fetchQuery instead of prefetch to have the data both on the server as well as hydrating it down to the client:\n\napp/page.tsx\nimport { getQueryClient, HydrateClient, trpc } from '~/trpc/server';\nexport default async function Home() {\n  const queryClient = getQueryClient();\n  const greeting = await queryClient.fetchQuery(trpc.hello.queryOptions());\n  // Do something with greeting on the server\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrateClient>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "Set up the React Query Integration | tRPC",
    "url": "https://trpc.io/docs/client/react/setup",
    "html": "Client Usage\nReact Query Integration (Classic)\nSetup\nVersion: 11.x\nSet up the React Query Integration\n1. Install dependencies​\n\nThe following dependencies should be installed\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/react-query @tanstack/react-query\n2. Import your AppRouter​\n\nImport your AppRouter type into the client application. This type holds the shape of your entire API.\n\nutils/trpc.ts\nimport type { AppRouter } from '../server/router';\nCopy\nTIP\n\nBy using import type you ensure that the reference will be stripped at compile-time, meaning you don't inadvertently import server-side code into your client. For more information, see the Typescript docs.\n\n3. Create tRPC hooks​\n\nCreate a set of strongly-typed React hooks from your AppRouter type signature with createTRPCReact.\n\nutils/trpc.ts\nimport { createTRPCReact } from '@trpc/react-query';\nimport type { AppRouter } from '../server/router';\n \nexport const trpc = createTRPCReact<AppRouter>();\nCopy\n4. Add tRPC providers​\n\nCreate a tRPC client, and wrap your application in the tRPC Provider, as below. You will also need to set up and connect React Query, which they document in more depth.\n\nTIP\n\nIf you already use React Query in your application, you should re-use the QueryClient and QueryClientProvider you already have.\n\nApp.tsx\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { httpBatchLink } from '@trpc/client';\nimport React, { useState } from 'react';\nimport { trpc } from './utils/trpc';\nexport function App() {\n  const [queryClient] = useState(() => new QueryClient());\n  const [trpcClient] = useState(() =>\n    trpc.createClient({\n      links: [\n        httpBatchLink({\n          url: 'http://localhost:3000/trpc',\n          // You can pass any HTTP headers you wish here\n          async headers() {\n            return {\n              authorization: getAuthCookie(),\n            };\n          },\n        }),\n      ],\n    }),\n  );\n  return (\n    <trpc.Provider client={trpcClient} queryClient={queryClient}>\n      <QueryClientProvider client={queryClient}>\n        {/* Your app here */}\n      </QueryClientProvider>\n    </trpc.Provider>\n  );\n}\nCopy\nNOTE\n\nThe reason for using useState in the creation of the queryClient and the TRPCClient, as opposed to declaring them outside of the component, is to ensure that each request gets a unique client when using SSR. If you use client side rendering then you can move them if you wish.\n\n5. Fetch data​\n\nYou can now use the tRPC React Query integration to call queries and mutations on your API.\n\npages/IndexPage.tsx\nimport { trpc } from '../utils/trpc';\n \nexport default function IndexPage() {\n  const userQuery = trpc.getUser.useQuery({ id: 'id_bilbo' });\n  const userCreator = trpc.createUser.useMutation();\n \n  return (\n    <div>\n      <p>{userQuery.data?.name}</p>\n \n      <button onClick={() => userCreator.mutate({ name: 'Frodo' })}>\n        Create Frodo\n      </button>\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/server-components",
    "html": "Client Usage\nReact Query Integration (Classic)\nServer Components\nVersion: 11.x\nSet up with React Server Components\nTIP\n\nThese are the docs for our 'Classic' React Query integration, which (while still supported) is not the recommended way to start new tRPC projects with TanStack React Query. We recommend using the new TanStack React Query Integration instead.\n\nThis guide is an overview of how one may use tRPC with a React Server Components (RSC) framework such as Next.js App Router. Be aware that RSC on its own solves a lot of the same problems tRPC was designed to solve, so you may not need tRPC at all.\n\nThere are also not a one-size-fits-all way to integrate tRPC with RSCs, so see this guide as a starting point and adjust it to your needs and preferences.\n\nINFO\n\nIf you're looking for how to use tRPC with Server Actions, check out this blog post by Julius.\n\nCAUTION\n\nPlease read React Query's Advanced Server Rendering docs before proceeding to understand the different types of server rendering and what footguns to avoid.\n\nAdd tRPC to existing projects​\n1. Install deps​\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/react-query @tanstack/react-query@latest zod client-only server-only\n2. Create a tRPC router​\n\nInitialize your tRPC backend in trpc/init.ts using the initTRPC function, and create your first router. We're going to make a simple \"hello world\" router and procedure here - but for deeper information on creating your tRPC API you should refer to the Quickstart guide and Backend usage docs for tRPC information.\n\nINFO\n\nThe file names used here are not enforced by tRPC. You may use any file structure you wish.\n\nView sample backend\n3. Create a Query Client factory​\n\nCreate a shared file trpc/query-client.ts that exports a function that creates a QueryClient instance.\n\ntrpc/query-client.ts\nimport {\n  defaultShouldDehydrateQuery,\n  QueryClient,\n} from '@tanstack/react-query';\nimport superjson from 'superjson';\nexport function makeQueryClient() {\n  return new QueryClient({\n    defaultOptions: {\n      queries: {\n        staleTime: 30 * 1000,\n      },\n      dehydrate: {\n        // serializeData: superjson.serialize,\n        shouldDehydrateQuery: (query) =>\n          defaultShouldDehydrateQuery(query) ||\n          query.state.status === 'pending',\n      },\n      hydrate: {\n        // deserializeData: superjson.deserialize,\n      },\n    },\n  });\n}\nCopy\n\nWe're setting a few default options here:\n\nstaleTime: With SSR, we usually want to set some default staleTime above 0 to avoid refetching immediately on the client.\nshouldDehydrateQuery: This is a function that determines whether a query should be dehydrated or not. Since the RSC transport protocol supports hydrating promises over the network, we extend the defaultShouldDehydrateQuery function to also include queries that are still pending. This will allow us to start prefetching in a server component high up the tree, then consuming that promise in a client component further down.\nserializeData and deserializeData (optional): If you set up a data transformer in the previous step, set this option to make sure the data is serialized correctly when hydrating the query client over the server-client boundary.\n4. Create a tRPC client for Client Components​\n\nThe trpc/client.tsx is the entrypoint when consuming your tRPC API from client components. In here, import the type definition of your tRPC router and create typesafe hooks using createTRPCReact. We'll also export our context provider from this file.\n\ntrpc/client.tsx\n'use client';\n// ^-- to make sure we can mount the Provider from a server component\nimport type { QueryClient } from '@tanstack/react-query';\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCReact } from '@trpc/react-query';\nimport { useState } from 'react';\nimport { makeQueryClient } from './query-client';\nimport type { AppRouter } from './routers/_app';\nexport const trpc = createTRPCReact<AppRouter>();\nlet clientQueryClientSingleton: QueryClient;\nfunction getQueryClient() {\n  if (typeof window === 'undefined') {\n    // Server: always make a new query client\n    return makeQueryClient();\n  }\n  // Browser: use singleton pattern to keep the same query client\n  return (clientQueryClientSingleton ??= makeQueryClient());\n}\nfunction getUrl() {\n  const base = (() => {\n    if (typeof window !== 'undefined') return '';\n    if (process.env.VERCEL_URL) return `https://${process.env.VERCEL_URL}`;\n    return 'http://localhost:3000';\n  })();\n  return `${base}/api/trpc`;\n}\nexport function TRPCProvider(\n  props: Readonly<{\n    children: React.ReactNode;\n  }>,\n) {\n  // NOTE: Avoid useState when initializing the query client if you don't\n  //       have a suspense boundary between this and the code that may\n  //       suspend because React will throw away the client on the initial\n  //       render if it suspends and there is no boundary\n  const queryClient = getQueryClient();\n  const [trpcClient] = useState(() =>\n    trpc.createClient({\n      links: [\n        httpBatchLink({\n          // transformer: superjson, <-- if you use a data transformer\n          url: getUrl(),\n        }),\n      ],\n    }),\n  );\n  return (\n    <trpc.Provider client={trpcClient} queryClient={queryClient}>\n      <QueryClientProvider client={queryClient}>\n        {props.children}\n      </QueryClientProvider>\n    </trpc.Provider>\n  );\n}\nCopy\n\nMount the provider in the root of your application (e.g. app/layout.tsx when using Next.js).\n\n5. Create a tRPC caller for Server Components​\n\nTo prefetch queries from server components, we use a tRPC caller. The @trpc/react-query/rsc module exports a thin wrapper around createCaller that integrates with your React Query client.\n\ntrpc/server.tsx\nimport 'server-only'; // <-- ensure this file cannot be imported from the client\nimport { createHydrationHelpers } from '@trpc/react-query/rsc';\nimport { cache } from 'react';\nimport { createCallerFactory, createTRPCContext } from './init';\nimport { makeQueryClient } from './query-client';\nimport { appRouter } from './routers/_app';\n// IMPORTANT: Create a stable getter for the query client that\n//            will return the same client during the same request.\nexport const getQueryClient = cache(makeQueryClient);\nconst caller = createCallerFactory(appRouter)(createTRPCContext);\nexport const { trpc, HydrateClient } = createHydrationHelpers<typeof appRouter>(\n  caller,\n  getQueryClient,\n);\nCopy\nUsing your API​\n\nNow you can use your tRPC API in your app. While you can use the React Query hooks in client components just like you would in any other React app, we can take advantage of the RSC capabilities by prefetching queries in a server component high up the tree. You may be familiar with this concept as \"render as you fetch\" commonly implemented as loaders. This means the request fires as soon as possible but without suspending until the data is needed by using the useQuery or useSuspenseQuery hooks.\n\napp/page.tsx\nimport { trpc } from '~/trpc/server';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  void trpc.hello.prefetch();\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrateClient>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\n// <-- hooks can only be used in client components\nimport { trpc } from '~/trpc/client';\nexport function ClientGreeting() {\n  const greeting = trpc.hello.useQuery();\n  if (!greeting.data) return <div>Loading...</div>;\n  return <div>{greeting.data.greeting}</div>;\n}\nCopy\nLeveraging Suspense​\n\nYou may prefer handling loading and error states using Suspense and Error Boundaries. You can do this by using the useSuspenseQuery hook.\n\napp/page.tsx\nimport { trpc } from '~/trpc/server';\nimport { Suspense } from 'react';\nimport { ErrorBoundary } from 'react-error-boundary';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  void trpc.hello.prefetch();\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ErrorBoundary fallback={<div>Something went wrong</div>}>\n        <Suspense fallback={<div>Loading...</div>}>\n          <ClientGreeting />\n        </Suspense>\n      </ErrorBoundary>\n    </HydrateClient>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\nimport { trpc } from '~/trpc/client';\nexport function ClientGreeting() {\n  const [data] = trpc.hello.useSuspenseQuery();\n  return <div>{data.greeting}</div>;\n}\nCopy\nGetting data in a server component​\n\nIf you need access to the data in a server component, you can invoke the procedure directly instead of using .prefetch(), just like you use the normal server caller. Please note that this method is de-attached from your query client and does not store the data in the cache. This means that you cannot use the data in a server component and expect it to be available in the client. This is intentional and explained in more detail in the Advanced Server Rendering guide.\n\napp/page.tsx\nimport { trpc } from '~/trpc/server';\nexport default async function Home() {\n  // Use the caller directly without using `.prefetch()`\n  const greeting = await trpc.hello();\n  //    ^? { greeting: string }\n  return <div>{greeting.greeting}</div>;\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/infer-types",
    "html": "Client Usage\nReact Query Integration (Classic)\nInferring Types\nVersion: 11.x\nInferring Types\n\nIn addition to the type inference made available by @trpc/server (see here) this integration also provides some inference helpers for usage purely in React.\n\nInfer React Query options based on your router​\n\nWhen creating custom hooks around tRPC procedures, it's sometimes necessary to have the types of the options inferred from the router. You can do so via the inferReactQueryProcedureOptions helper exported from @trpc/react-query.\n\ntrpc.ts\nimport {\n  createTRPCReact,\n  type inferReactQueryProcedureOptions,\n} from '@trpc/react-query';\nimport type { inferRouterInputs, inferRouterOutputs } from '@trpc/server';\nimport type { AppRouter } from './server';\n \n// infer the types for your router\nexport type ReactQueryOptions = inferReactQueryProcedureOptions<AppRouter>;\nexport type RouterInputs = inferRouterInputs<AppRouter>;\nexport type RouterOutputs = inferRouterOutputs<AppRouter>;\n \nexport const trpc = createTRPCReact<AppRouter>();\nCopy\nusePostCreate.ts\nimport {\n  trpc,\n  type ReactQueryOptions,\n  type RouterInputs,\n  type RouterOutputs,\n} from './trpc';\n \ntype PostCreateOptions = ReactQueryOptions['post']['create'];\n \nfunction usePostCreate(options?: PostCreateOptions) {\n  const utils = trpc.useUtils();\n \n  return trpc.post.create.useMutation({\n    ...options,\n    onSuccess(post) {\n      // invalidate all queries on the post router\n      // when a new post is created\n      utils.post.invalidate();\n      options?.onSuccess?.(post);\n    },\n  });\n}\nCopy\nusePostById.ts\nimport { ReactQueryOptions, RouterInputs, trpc } from './trpc';\n \ntype PostByIdOptions = ReactQueryOptions['post']['byId'];\ntype PostByIdInput = RouterInputs['post']['byId'];\n \nfunction usePostById(input: PostByIdInput, options?: PostByIdOptions) {\n  return trpc.post.byId.useQuery(input, options);\n}\nCopy\nInfer abstract types from a \"Router Factory\"​\n\nIf you write a factory which creates a similar router interface several times in your application, you may wish to share client code between usages of the factory. @trpc/react-query/shared exports several types which can be used to generate abstract types for a router factory, and build common React components which are passed the router as a prop.\n\napi/factory.ts\nimport { t, publicProcedure } from './trpc';\n \n// @trpc/react-query/shared exports several **Like types which can be used to generate abstract types\nimport { RouterLike, UtilsLike } from '@trpc/react-query/shared';\n \n// Factory function written by you, however you need,\n// so long as you can infer the resulting type of t.router() later\nexport function createMyRouter() {\n  return t.router({\n    createThing: publicProcedure\n      .input(ThingRequest)\n      .output(Thing)\n      .mutation(/* do work */),\n    listThings: publicProcedure\n      .input(ThingQuery)\n      .output(ThingArray)\n      .query(/* do work */),\n  })\n}\n \n// Infer the type of your router, and then generate the abstract types for use in the client\ntype MyRouterType = ReturnType<typeof createMyRouter>\nexport MyRouterLike = RouterLike<MyRouterType>\nexport MyRouterUtilsLike = UtilsLike<MyRouterType>\nCopy\napi/server.ts\nexport type AppRouter = typeof appRouter;\n \n// Export your MyRouter types to the client\nexport type { MyRouterLike, MyRouterUtilsLike } from './factory';\nCopy\nfrontend/usePostCreate.ts\nimport type { MyRouterLike, MyRouterUtilsLike, trpc, useUtils } from './trpc';\n \ntype MyGenericComponentProps = {\n  route: MyRouterLike;\n  utils: MyRouterUtilsLike;\n};\n \nfunction MyGenericComponent(props: MyGenericComponentProps) {\n  const { route } = props;\n  const thing = route.listThings.useQuery({\n    filter: 'qwerty',\n  });\n \n  const mutation = route.doThing.useMutation({\n    onSuccess() {\n      props.utils.listThings.invalidate();\n    },\n  });\n \n  function handleClick() {\n    mutation.mutate({\n      name: 'Thing 1',\n    });\n  }\n \n  return; /* ui */\n}\n \nfunction MyPageComponent() {\n  const utils = useUtils();\n \n  return (\n    <MyGenericComponent\n      route={trpc.deep.route.things}\n      utils={utils.deep.route.things}\n    />\n  );\n}\n \nfunction MyOtherPageComponent() {\n  const utils = useUtils();\n \n  return (\n    <MyGenericComponent\n      route={trpc.different.things}\n      utils={utils.different.things}\n    />\n  );\n}\nCopy\n\nA more complete working example can be found here\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useQuery",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseQuery()\nVersion: 11.x\nuseQuery()\n\nuseQuery is the primary hook for data fetching, it works similarly to @tanstack/react-query's useQuery, but with some trpc specific options and additional features like streaming.\n\nNOTE\n\nFor in-depth information about options and usage patterns, refer to the TanStack Query docs on queries.\n\nSignature​\nfunction useQuery(\n  input: TInput | SkipToken,\n  opts?: UseTRPCQueryOptions;\n)\ninterface UseTRPCQueryOptions\n  extends UseQueryOptions {\n  trpc: {\n    ssr?: boolean;\n    abortOnUnmount?: boolean;\n    context?: Record<string, unknown>;\n  }\n}\nCopy\n\nSince UseTRPCQueryOptions extends @tanstack/react-query's UseQueryOptions, you can use any of their options here such as enabled, refetchOnWindowFocus, etc. We also have some trpc specific options that let you opt in or out of certain behaviors on a per-procedure level:\n\ntrpc.ssr: If you have ssr: true in your global config, you can set this to false to disable ssr for this particular query. Note that this does not work the other way around, i.e., you can not enable ssr on a procedure if your global config is set to false.\ntrpc.abortOnUnmount: Override the global config and opt in or out of aborting queries on unmount.\ntrpc.context: Add extra meta data that could be used in Links.\nTIP\n\nIf you need to set any options but don't want to pass any input, you can pass undefined instead.\n\nYou'll notice that you get autocompletion on the input based on what you have set in your input schema on your backend.\n\nExample usage​\nBackend code\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  // input is optional, so we don't have to pass second argument\n  const helloNoArgs = trpc.hello.useQuery();\n  const helloWithArgs = trpc.hello.useQuery({ text: 'client' });\n  return (\n    <div>\n      <h1>Hello World Example</h1>\n      <ul>\n        <li>\n          helloNoArgs ({helloNoArgs.status}):{' '}\n          <pre>{JSON.stringify(helloNoArgs.data, null, 2)}</pre>\n        </li>\n        <li>\n          helloWithArgs ({helloWithArgs.status}):{' '}\n          <pre>{JSON.stringify(helloWithArgs.data, null, 2)}</pre>\n        </li>\n      </ul>\n    </div>\n  );\n}\nCopy\nStreaming responses using async generators​\nINFO\n\nSince v11 we now support streaming queries when using the httpBatchStreamLink.\n\nWhen returning an async generators in a query, you will:\n\nGet the results of the iterator in the data-property as an array which updates as the response comes in\nThe status will be success as soon as the first chunk is received.\nThe fetchStatus property which will be fetching until the last chunk is received.\nExample​\nserver/routers/_app.ts\nimport { publicProcedure, router } from './trpc';\nconst appRouter = router({\n  iterable: publicProcedure.query(async function* () {\n    for (let i = 0; i < 3; i++) {\n      await new Promise((resolve) => setTimeout(resolve, 500));\n      yield i;\n    }\n  }),\n});\nexport type AppRouter = typeof appRouter;\nCopy\ncomponents/MyComponent.tsx\nimport { trpc } from '~/utils';\nexport function MyComponent() {\n  const result = trpc.iterable.useQuery();\n  return (\n    <div>\n      {result.data?.map((chunk, index) => (\n        <Fragment key={index}>{chunk}</Fragment>\n      ))}\n    </div>\n  );\n}\nCopy\n\nresult properties while streaming:\n\nstatus\tfetchStatus\tdata\n'pending'\t'fetching'\tundefined\n'success'\t'fetching'\t[]\n'success'\t'fetching'\t[1]\n'success'\t'fetching'\t[1, 2]\n'success'\t'fetching'\t[1, 2, 3]\n'success'\t'idle'\t[1, 2, 3]\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useMutation",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseMutation()\nVersion: 11.x\nuseMutation()\nNOTE\n\nThe hooks provided by @trpc/react-query are a thin wrapper around @tanstack/react-query. For in-depth information about options and usage patterns, refer to their docs on mutations.\n\nWorks like react-query's mutations - see their docs.\n\nExample​\nBackend code\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const mutation = trpc.login.useMutation();\n  const handleLogin = () => {\n    const name = 'John Doe';\n    mutation.mutate({ name });\n  };\n  return (\n    <div>\n      <h1>Login Form</h1>\n      <button onClick={handleLogin} disabled={mutation.isPending}>\n        Login\n      </button>\n      {mutation.error && <p>Something went wrong! {mutation.error.message}</p>}\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useInfiniteQuery",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseInfiniteQuery()\nVersion: 11.x\nuseInfiniteQuery\nINFO\nYour procedure needs to accept a cursor input of any type (string, number, etc) to expose this hook.\nFor more details on infinite queries read the react-query docs\nIn this example we're using Prisma - see their docs on cursor-based pagination\nExample Procedure​\nserver/routers/_app.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\nimport { Context } from './[trpc]';\nexport const t = initTRPC.create();\nexport const appRouter = t.router({\n  infinitePosts: t.procedure\n    .input(\n      z.object({\n        limit: z.number().min(1).max(100).nullish(),\n        cursor: z.number().nullish(), // <-- \"cursor\" needs to exist, but can be any type\n        direction: z.enum(['forward', 'backward']), // optional, useful for bi-directional query\n      }),\n    )\n    .query(async (opts) => {\n      const { input } = opts;\n      const limit = input.limit ?? 50;\n      const { cursor } = input;\n      const items = await prisma.post.findMany({\n        take: limit + 1, // get an extra item at the end which we'll use as next cursor\n        where: {\n          title: {\n            contains: 'Prisma' /* Optional filter */,\n          },\n        },\n        cursor: cursor ? { myCursor: cursor } : undefined,\n        orderBy: {\n          myCursor: 'asc',\n        },\n      });\n      let nextCursor: typeof cursor | undefined = undefined;\n      if (items.length > limit) {\n        const nextItem = items.pop();\n        nextCursor = nextItem!.myCursor;\n      }\n      return {\n        items,\n        nextCursor,\n      };\n    }),\n});\nCopy\nExample React Component​\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const myQuery = trpc.infinitePosts.useInfiniteQuery(\n    {\n      limit: 10,\n    },\n    {\n      getNextPageParam: (lastPage) => lastPage.nextCursor,\n      // initialCursor: 1, // <-- optional you can pass an initialCursor\n    },\n  );\n  // [...]\n}\nCopy\nHelpers​\ngetInfiniteData()​\n\nThis helper gets the currently cached data from an existing infinite query\n\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const utils = trpc.useUtils();\n  const myMutation = trpc.infinitePosts.add.useMutation({\n    async onMutate(opts) {\n      await utils.infinitePosts.cancel();\n      const allPosts = utils.infinitePosts.getInfiniteData({ limit: 10 });\n      // [...]\n    },\n  });\n}\nCopy\nsetInfiniteData()​\n\nThis helper allows you to update a query's cached data\n\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const utils = trpc.useUtils();\n  const myMutation = trpc.infinitePosts.delete.useMutation({\n    async onMutate(opts) {\n      await utils.infinitePosts.cancel();\n      utils.infinitePosts.setInfiniteData({ limit: 10 }, (data) => {\n        if (!data) {\n          return {\n            pages: [],\n            pageParams: [],\n          };\n        }\n        return {\n          ...data,\n          pages: data.pages.map((page) => ({\n            ...page,\n            items: page.items.filter((item) => item.status === 'published'),\n          })),\n        };\n      });\n    },\n  });\n  // [...]\n}\nCopy\nEdit this page"
  },
  {
    "title": "useSubscription() | tRPC",
    "url": "https://trpc.io/docs/client/react/useSubscription",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseSubscription()\nVersion: 11.x\nuseSubscription()\n\nThe useSubscription hook can be used to subscribe to a subscription procedure on the server.\n\nSignature​\nOptions​\nTIP\nIf you need to set any options but don't want to pass any input, you can pass undefined instead.\nIf you pass skipToken from @tanstack/react-query, the subscription will be paused.\nHave a look at our SSE example for a complete example of how to use subscriptions\nfunction useSubscription<TOutput, TError>(\n  input: TInput | SkipToken,\n  opts?: UseTRPCSubscriptionOptions<TOutput, TError>,\n): TRPCSubscriptionResult<TOutput, TError>;\ninterface UseTRPCSubscriptionOptions<TOutput, TError> {\n  /**\n   * Callback invoked when the subscription starts.\n   */\n  onStarted?: () => void;\n  /**\n   * Callback invoked when new data is received from the subscription.\n   * @param data - The data received.\n   */\n  onData?: (data: TOutput) => void;\n  /**\n   * Callback invoked when an **unrecoverable error** occurs and the subscription is stopped.\n   */\n  onError?: (error: TError) => void;\n  /**\n   * Callback invoked when the subscription is completed.\n   */\n  onComplete?: () => void;\n  /**\n   * @deprecated Use a `skipToken` from `@tanstack/react-query` instead.\n   * This will be removed in a future version.\n   */\n  enabled?: boolean;\n}\nCopy\nReturn type​\ntype TRPCSubscriptionResult<TOutput, TError> = {\n  /**\n   * The current status of the subscription.\n   * Will be one of: `'idle'`, `'connecting'`, `'pending'`, or `'error'`.\n   *\n   * - `idle`: subscription is disabled or ended\n   * - `connecting`: trying to establish a connection\n   * - `pending`: connected to the server, receiving data\n   * - `error`: an error occurred and the subscription is stopped\n   */\n  status: 'idle' | 'connecting' | 'pending' | 'error';\n  /**\n   * The last data received from the subscription.\n   */\n  data: TOutput | undefined;\n  /**\n   * The last error received - will be `null` whenever the status is `'pending'` or `'idle'`\n   * - has a value only when the status is `'error'`\n   * - *may* have a value when the status is `'connecting'`\n   */\n  error: TRPCClientError | null;\n  /**\n   * Function to reset the subscription.\n   */\n  reset: () => void;\n};\nCopy\nExample​\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const [numbers, setNumbers] = React.useState<number[]>([]);\n  const result = trpc.onNumber.useSubscription(undefined, {\n    onData: (num) => {\n      setNumbers((prev) => [...prev, num]);\n    },\n  });\n  return (\n    <div>\n      <h1>Subscription Example</h1>\n      <p>\n        {result.status}: <pre>{JSON.stringify(result.data, null, 2)}</pre>\n      </p>\n      <h2>Previous numbers:</h2>\n      <ul>\n        {numbers.map((num, i) => (\n          <li key={i}>{num}</li>\n        ))}\n      </ul>\n      {result.status === 'error' && (\n        <button onClick={() => result.reset()}>\n          Something went wrong - restart the subscription\n        </button>\n      )}\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useUtils",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseUtils()\nVersion: 11.x\nuseUtils\n\nuseUtils is a hook that gives you access to helpers that let you manage the cached data of the queries you execute via @trpc/react-query. These helpers are actually thin wrappers around @tanstack/react-query's queryClient methods. If you want more in-depth information about options and usage patterns for useContext helpers than what we provide here, we will link to their respective @tanstack/react-query docs so you can refer to them accordingly.\n\nNOTE\n\nThis hook was called useContext() until 10.41.0 (and is still aliased for the foreseeable future)\n\nUsage​\n\nuseUtils returns an object with all the available queries you have in your routers. You use it the same way as your trpc client object. Once you reach a query, you'll have access to the query helpers. For example, let's say you have a post router with an all query:\n\nserver.ts\n// @filename: server.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \nconst t = initTRPC.create();\n \nconst appRouter = t.router({\n  post: t.router({\n    all: t.procedure.query(() => {\n      return {\n        posts: [\n          { id: 1, title: 'everlong' },\n          { id: 2, title: 'After Dark' },\n        ],\n      };\n    }),\n  }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\n\nNow in our component, when we navigate the object useUtils gives us and reach the post.all query, we'll get access to our query helpers!\n\nMyComponent.tsx\nfunction MyComponent() {\n  const utils = trpc.useUtils();\n  utils.post.all.f;\n                  \nfetch\nfetchInfinite\n  // [...]\n}\nCopy\nHelpers​\n\nThese are the helpers you'll get access to via useUtils. The table below will help you know which tRPC helper wraps which @tanstack/react-query helper method. Each react-query method will link to its respective docs/guide:\n\ntRPC helper wrapper\t@tanstack/react-query helper method\nfetch\tqueryClient.fetchQuery\nprefetch\tqueryClient.prefetchQuery\nfetchInfinite\tqueryClient.fetchInfiniteQuery\nprefetchInfinite\tqueryClient.prefetchInfiniteQuery\nensureData\tqueryClient.ensureData\ninvalidate\tqueryClient.invalidateQueries\nrefetch\tqueryClient.refetchQueries\ncancel\tqueryClient.cancelQueries\nsetData\tqueryClient.setQueryData\nsetQueriesData\tqueryClient.setQueriesData\ngetData\tqueryClient.getQueryData\nsetInfiniteData\tqueryClient.setInfiniteQueryData\ngetInfiniteData\tqueryClient.getInfiniteData\nsetMutationDefaults\tqueryClient.setMutationDefaults\ngetMutationDefaults\tqueryClient.getMutationDefaults\nisMutating\tqueryClient.isMutating\n❓ The function I want isn't here!​\n\n@tanstack/react-query has a lot of functions that we haven't put in the tRPC context yet. If you need a function that isn't here, feel free to open a feature request requesting it.\n\nIn the meantime, you can import and use the function directly from @tanstack/react-query. We also provide a getQueryKey which you can use to get the correct queryKey on the filters when using these functions.\n\nProxy client​\n\nIn addition to the above react-query helpers, the context also exposes your tRPC proxy client. This lets you call your procedures with async/await without needing to create an additional vanilla client.\n\nimport { trpc } from '../utils/trpc';\nfunction MyComponent() {\n  const [apiKey, setApiKey] = useState();\n  const utils = trpc.useUtils();\n  return (\n    <Form\n      handleSubmit={async (event) => {\n        const apiKey = await utils.client.apiKey.create.mutate(event);\n        setApiKey(apiKey);\n      }}\n    >\n      ...\n    </Form>\n  );\n}\nCopy\nQuery Invalidation​\n\nYou invalidate queries via the invalidate helper. invalidate is actually a special helper given that, unlike the other helpers, it's available at every level of the router map. This means you can either run invalidate on a single query, a whole router, or every router if you want. We get more in detail in the sections below.\n\nInvalidating a single query​\n\nYou can invalidate a query relating to a single procedure and even filter based on the input passed to it to prevent unnecessary calls to the back end.\n\nExample code​\nimport { trpc } from '../utils/trpc';\nfunction MyComponent() {\n  const utils = trpc.useUtils();\n  const mutation = trpc.post.edit.useMutation({\n    onSuccess(input) {\n      utils.post.all.invalidate();\n      utils.post.byId.invalidate({ id: input.id }); // Will not invalidate queries for other id's 👍\n    },\n  });\n  // [...]\n}\nCopy\nInvalidating across whole routers​\n\nIt is also possible to invalidate queries across an entire router rather then just one query.\n\nExample code​\nBackend code\nimport { trpc } from '../utils/trpc';\nfunction MyComponent() {\n  const utils = trpc.useUtils();\n  const invalidateAllQueriesAcrossAllRouters = () => {\n    // 1️⃣\n    // All queries on all routers will be invalidated 🔥\n    utils.invalidate();\n  };\n  const invalidateAllPostQueries = () => {\n    // 2️⃣\n    // All post queries will be invalidated 📭\n    utils.post.invalidate();\n  };\n  const invalidatePostById = () => {\n    // 3️⃣\n    // All queries in the post router with input {id:1} invalidated 📭\n    utils.post.byId.invalidate({ id: 1 });\n  };\n  // Example queries\n  trpc.user.all.useQuery(); // Would only be validated by 1️⃣ only.\n  trpc.post.all.useQuery(); // Would be invalidated by 1️⃣ & 2️⃣\n  trpc.post.byId.useQuery({ id: 1 }); // Would be invalidated by 1️⃣, 2️⃣ and 3️⃣\n  trpc.post.byId.useQuery({ id: 2 }); // would be invalidated by 1️⃣ and 2️⃣ but NOT 3️⃣!\n  // [...]\n}\nCopy\nInvalidate full cache on every mutation​\n\nKeeping track of exactly what queries a mutation should invalidate is hard, therefore, it can be a pragmatic solution to invalidate the full cache as a side-effect on any mutation. Since we have request batching, this invalidation will simply refetch all queries on the page you're looking at in one single request.\n\nWe have added a feature to help with this:\n\nexport const trpc = createTRPCReact<AppRouter, SSRContext>({\n  overrides: {\n    useMutation: {\n      /**\n       * This function is called whenever a `.useMutation` succeeds\n       **/\n      async onSuccess(opts) {\n        /**\n         * @note that order here matters:\n         * The order here allows route changes in `onSuccess` without\n         * having a flash of content change whilst redirecting.\n         **/\n        // Calls the `onSuccess` defined in the `useQuery()`-options:\n        await opts.originalFn();\n        // Invalidate all queries in the react-query cache:\n        await opts.queryClient.invalidateQueries();\n      },\n    },\n  },\n});\nCopy\nAdditional Options​\n\nAside from the query helpers, the object useUtils returns also contains the following properties:\n\ninterface ProxyTRPCContextProps<TRouter extends AnyRouter, TSSRContext> {\n  /**\n   * The `TRPCClient`\n   */\n  client: TRPCClient<TRouter>;\n  /**\n   * The SSR context when server-side rendering\n   * @default null\n   */\n  ssrContext?: TSSRContext | null;\n  /**\n   * State of SSR hydration.\n   * - `false` if not using SSR.\n   * - `prepass` when doing a prepass to fetch queries' data\n   * - `mounting` before TRPCProvider has been rendered on the client\n   * - `mounted` when the TRPCProvider has been rendered on the client\n   * @default false\n   */\n  ssrState?: SSRState;\n  /**\n   * Abort loading query calls when unmounting a component - usually when navigating to a new page\n   * @default false\n   */\n  abortOnUnmount?: boolean;\n}\nCopy\nEdit this page"
  },
  {
    "title": "createTRPCQueryUtils | tRPC",
    "url": "https://trpc.io/docs/client/react/createTRPCQueryUtils",
    "html": "Client Usage\nReact Query Integration (Classic)\ncreateTRPCQueryUtils()\nVersion: 11.x\ncreateTRPCQueryUtils\n\nThe use case for createTRPCQueryUtils is when you need to use the helpers outside of a React Component, for example in react-routers loaders.\n\nSimilar to useUtils, createTRPCQueryUtils is a function that gives you access to helpers that let you manage the cached data of the queries you execute via @trpc/react-query. These helpers are actually thin wrappers around @tanstack/react-query's queryClient methods. If you want more in-depth information about options and usage patterns for useUtils helpers than what we provide here, we will link to their respective @tanstack/react-query docs so you can refer to them accordingly.\n\nThe difference between useUtils and createTRPCQueryUtils is that useUtils is a react hook that uses useQueryClient under the hood. This means that it is able to work better within React Components.\n\nIf you need access to the client directly, you can use the client object that you passed to createTRPCQueryUtils during creation.\n\nCAUTION\n\nYou should avoid using createTRPCQueryUtils in React Components. Instead, use useUtils which is a React hook that implements useCallback and useQueryClient under the hood.\n\nUsage​\n\ncreateTRPCQueryUtils returns an object with all the available queries you have in your routers. You use it the same way as your trpc client object. Once you reach a query, you'll have access to the query helpers. For example, let's say you have a post router with an all query:\n\nNow in our component, when we navigate the object createTRPCQueryUtils gives us and reach the post.all query, we'll get access to our query helpers!\n\nMyPage.tsx\nimport { QueryClient } from '@tanstack/react-query';\nimport { createTRPCQueryUtils, createTRPCReact } from '@trpc/react-query';\nimport { useLoaderData } from 'react-router-dom';\nimport type { AppRouter } from './server';\nconst trpc = createTRPCReact<AppRouter>();\nconst trpcClient = trpc.createClient({ links: [] });\nconst queryClient = new QueryClient();\nconst clientUtils = createTRPCQueryUtils({ queryClient, client: trpcClient });\n// This is a react-router loader\nexport async function loader() {\n  const allPostsData = await clientUtils.post.all.ensureData(); // Fetches data if it doesn't exist in the cache\n  return {\n    allPostsData,\n  };\n}\n// This is a react component\nexport function Component() {\n  const loaderData = useLoaderData() as Awaited<ReturnType<typeof loader>>;\n  const allPostQuery = trpc.post.all.useQuery({\n    initialData: loaderData.allPostsData, // Uses the data from the loader\n  });\n  return (\n    <div>\n      {allPostQuery.data.posts.map((post) => (\n        <div key={post.id}>{post.title}</div>\n      ))}\n    </div>\n  );\n}\nCopy\nNOTE\n\nIf you were using Remix Run or SSR you wouldn't re-use the same queryClient for every request. Instead, you would create a new queryClient for every request so that there's no cross-request data leakage.\n\nHelpers​\n\nMuch like useUtils, createTRPCQueryUtils gives you access to same set of helpers. The only difference is that you need to pass in the queryClient and client objects.\n\nYou can see them on the useUtils-page.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useQueries",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseQueries()\nVersion: 11.x\nuseQueries()\n\nThe useQueries hook can be used to fetch a variable number of queries at the same time using only one hook call.\n\nThe main use case for such a hook is to be able to fetch a number of queries, usually of the same type. For example if you fetch a list of todo ids, you can then map over them in a useQueries hook calling a byId endpoint that would fetch the details of each todo.\n\nNOTE\n\nWhile fetching multiple types in a useQueries hook is possible, there is not much of an advantage compared to using multiple useQuery calls unless you use the suspense option as that useQueries can trigger suspense in parallel while multiple useQuery calls would waterfall.\n\nUsage​\n\nThe useQueries hook is the same as that of @tanstack/query useQueries. The only difference is that you pass in a function that returns an array of queries instead of an array of queries inside an object parameter.\n\nTIP\n\nWhen you're using the httpBatchLink or wsLink, the below will end up being only 1 HTTP call to your server. Additionally, if the underlying procedure is using something like Prisma's findUnique() it will automatically batch & do exactly 1 database query as a well.\n\nconst Component = (props: { postIds: string[] }) => {\n  const postQueries = trpc.useQueries((t) =>\n    props.postIds.map((id) => t.post.byId({ id })),\n  );\n  return <>{/* [...] */}</>;\n};\nCopy\nProviding options to individual queries​\n\nYou can also pass in any normal query options to the second parameter of any of the query calls in the array such as enabled, suspense, refetchOnWindowFocus...etc. For a complete overview of all the available options, see the tanstack useQuery documentation.\n\nconst Component = () => {\n  const [post, greeting] = trpc.useQueries((t) => [\n    t.post.byId({ id: '1' }, { enabled: false }),\n    t.greeting({ text: 'world' }),\n  ]);\n  const onButtonClick = () => {\n    post.refetch();\n  };\n  return (\n    <div>\n      <h1>{post.data && post.data.title}</h1>\n      <p>{greeting.data.message}</p>\n      <button onClick={onButtonClick}>Click to fetch</button>\n    </div>\n  );\n};\nCopy\nContext​\n\nYou can also pass in an optional React Query context to override the default.\n\nconst [post, greeting] = trpc.useQueries(\n  (t) => [t.post.byId({ id: '1' }), t.greeting({ text: 'world' })],\n  myCustomContext,\n);\nCopy\nEdit this page"
  },
  {
    "title": "Suspense | tRPC",
    "url": "https://trpc.io/docs/client/react/suspense",
    "html": "Client Usage\nReact Query Integration (Classic)\nSuspense\nVersion: 11.x\nSuspense\nINFO\nEnsure you're on the latest version of React\nIf you use suspense with tRPC's automatic SSR in Next.js, the full page will crash on the server if a query fails, even if you have an <ErrorBoundary />\nUsage​\nTIP\n\nuseSuspenseQuery & useSuspenseInfiniteQuery both return a [data, query]-tuple, to make it easy to directly use your data and renaming the variable to something descriptive\n\nuseSuspenseQuery()​\n// @filename: pages/index.tsx\nimport React from 'react';\nimport { trpc } from '../utils/trpc';\n \nfunction PostView() {\n  const [post, postQuery] = trpc.post.byId.useSuspenseQuery({ id: '1' });\n          \nconst post: {\n    id: string;\n    title: string;\n}\n \n  return <>{/* ... */}</>;\n}\nCopy\nuseSuspenseInfiniteQuery()​\n// @filename: pages/index.tsx\nimport React from 'react';\nimport { trpc } from '../utils/trpc';\nfunction PostView() {\n  const [{ pages }, allPostsQuery] = trpc.post.all.useSuspenseInfiniteQuery(\n    {},\n    {\n      getNextPageParam(lastPage) {\n        return lastPage.nextCursor;\n      },\n    },\n  );\n  const { isFetching, isFetchingNextPage, fetchNextPage, hasNextPage } =\n    allPostsQuery;\n  return <>{/* ... */}</>;\n}\nCopy\nuseSuspenseQueries()​\n\nSuspense equivalent of useQueries().\n\nconst Component = (props: { postIds: string[] }) => {\n  const [posts, postQueries] = trpc.useSuspenseQueries((t) =>\n    props.postIds.map((id) => t.post.byId({ id })),\n  );\n  return <>{/* [...] */}</>;\n};\nCopy\nPrefetching​\n\nThe performance of suspense queries can be improved by prefetching the query data before the Suspense component is rendered (this is sometimes called \"render-as-you-fetch\").\n\nNOTE\nPrefetching and the render-as-you-fetch model are very dependent on the framework and router you are using. We recommend reading your frameworks router docs along with the @tanstack/react-query docs to understand how to implement these patterns.\nIf you are using Next.js please look at the docs on Server-Side Helpers to implement server-side prefetching.\nRoute-level prefetching​\nconst utils = createTRPCQueryUtils({ queryClient, client: trpcClient });\n// tanstack router/ react router loader\nconst loader = async (params: { id: string }) =>\n  utils.post.byId.ensureQueryData({ id: params.id });\nCopy\nComponent-level prefetching with usePrefetchQuery​\nimport { trpc } from '../utils/trpc';\nfunction PostViewPage(props: { postId: string }) {\n  trpc.post.byId.usePrefetchQuery({ id: props.postId });\n  return (\n    <Suspense>\n      <PostView postId={props.postId} />\n    </Suspense>\n  );\n}\nCopy\nComponent-level prefetching with usePrefetchInfiniteQuery​\nimport { trpc } from '../utils/trpc';\n// will have to be passed to the child PostView `useSuspenseInfiniteQuery`\nexport const getNextPageParam = (lastPage) => lastPage.nextCursor;\nfunction PostViewPage(props: { postId: string }) {\n  trpc.post.all.usePrefetchInfiniteQuery({}, { getNextPageParam });\n  return (\n    <Suspense>\n      <PostView postId={props.postId} />\n    </Suspense>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/getQueryKey",
    "html": "Client Usage\nReact Query Integration (Classic)\ngetQueryKey()\nVersion: 11.x\ngetQueryKey\n\nWe provide a getQueryKey helper that accepts a router or procedure so that you can easily provide the native function the correct query key.\n\n// Queries\nfunction getQueryKey(\n  procedure: AnyQueryProcedure,\n  input?: DeepPartial<TInput>,\n  type?: QueryType; /** @default 'any' */\n): TRPCQueryKey;\n// Routers\nfunction getQueryKey(\n  router: AnyRouter,\n): TRPCQueryKey;\ntype QueryType = \"query\" | \"infinite\" | \"any\";\n// for useQuery ──┘         │            │\n// for useInfiniteQuery ────┘            │\n// will match all ───────────────────────┘\nCopy\nNOTE\n\nThe query type any will match all queries in the cache only if the react query method where it's used uses fuzzy matching. See TanStack/query#5111 (comment) for more context.\n\nimport { useIsFetching, useQueryClient } from '@tanstack/react-query';\nimport { getQueryKey } from '@trpc/react-query';\nimport { trpc } from '~/utils/trpc';\nfunction MyComponent() {\n  const queryClient = useQueryClient();\n  const posts = trpc.post.list.useQuery();\n  // See if a query is fetching\n  const postListKey = getQueryKey(trpc.post.list, undefined, 'query');\n  const isFetching = useIsFetching(postListKey);\n  // Set some query defaults for an entire router\n  const postKey = getQueryKey(trpc.post);\n  queryClient.setQueryDefaults(postKey, { staleTime: 30 * 60 * 1000 });\n  // ...\n}\nCopy\nMutations​\n\nSimilarly to queries, we provide a getMutationKey for mutations. The underlying function is the same as getQueryKey (in fact, you could technically use getQueryKey for mutations as well), the only difference is in semantics.\n\nfunction getMutationKey(procedure: AnyMutationProcedure): TRPCMutationKey;\nCopy\nEdit this page"
  },
  {
    "title": "Aborting Procedure Calls | tRPC",
    "url": "https://trpc.io/docs/client/react/aborting-procedure-calls",
    "html": "Client Usage\nReact Query Integration (Classic)\nAborting Procedure Calls\nVersion: 11.x\nAborting Procedure Calls\n\nBy default, tRPC does not cancel requests via React Query. If you want to opt into this behaviour, you can provide abortOnUnmount in your configuration.\n\nNOTE\n\n@tanstack/react-query only supports aborting queries.\n\nGlobally​\nclient.ts\n// @filename: utils.ts\nimport { createTRPCReact } from '@trpc/react-query';\n \nexport const trpc = createTRPCReact<AppRouter>({\n  abortOnUnmount: true,\n});\n \ntrpc.createClient({\n  // ...\n});\nCopy\nPer-request​\n\nYou may also override this behaviour at the query level.\n\npages/post/[id].tsx\nimport { trpc } from '../utils/trpc';\n \nfunction PostViewPage() {\n  const { query } = useRouter();\n  const postQuery = trpc.post.byId.useQuery(\n    { id: query.id },\n    { trpc: { abortOnUnmount: true } }\n  );\n \n  // ...\n}\nCopy\nEdit this page"
  },
  {
    "title": "Set up a tRPC Client | tRPC",
    "url": "https://trpc.io/docs/client/vanilla/setup",
    "html": "Client Usage\nVanilla Client\nSetup\nVersion: 11.x\nSet up a tRPC Client\n1. Install the tRPC Client library​\n\nUse your preferred package manager to install the @trpc/client library, and also install @trpc/server which contains some required types.\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client\n2. Import your App Router​\n\nImport your AppRouter type into the client application. This type holds the shape of your entire API.\n\nutils/trpc.ts\nimport type { AppRouter } from '../server/router';\nCopy\nTIP\n\nBy using import type you ensure that the reference will be stripped at compile-time, meaning you don't inadvertently import server-side code into your client. For more information, see the Typescript docs.\n\n3. Initialize the tRPC client​\n\nCreate a tRPC client with the createTRPCClient method, and add a links array with a terminating link pointing at your API. To learn more about tRPC links, click here.\n\nclient.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from '../path/to/server/trpc';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000/trpc',\n      // You can pass any HTTP headers you wish here\n      async headers() {\n        return {\n          authorization: getAuthCookie(),\n        };\n      },\n    }),\n  ],\n});\nCopy\n4. Use the tRPC Client​\n\nUnder the hood this creates a typed JavaScript Proxy which allows you to interact with your tRPC API in a fully type-safe way:\n\nclient.ts\nconst bilbo = await client.getUser.query('id_bilbo');\n// => { id: 'id_bilbo', name: 'Bilbo' };\nconst frodo = await client.createUser.mutate({ name: 'Frodo' });\n// => { id: 'id_frodo', name: 'Frodo' };\nCopy\n\nYou're all set!\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/vanilla/aborting-procedure-calls",
    "html": "Client Usage\nVanilla Client\nAborting Procedure Calls\nVersion: 11.x\nAborting Procedure Calls\n\ntRPC adheres to the industry standard when it comes to aborting procedures. All you have to do is pass an AbortSignal to the query or mutation options, and call the AbortController instance's abort method if you need to cancel the request.\n\nutils.ts\n// @filename: server.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from './server.ts';\n \nconst proxy = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000/trpc',\n    }),\n  ],\n});\n \n// 1. Create an AbortController instance - this is a standard javascript API\nconst ac = new AbortController();\n \n// 2. Pass the signal to a query or mutation\nconst query = proxy.userById.query('id_bilbo', { signal: ac.signal });\n \n// 3. Cancel the request if needed\nac.abort();\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/httpLink",
    "html": "Client Usage\nLinks\nHTTP Link\nVersion: 11.x\nHTTP Link\n\nhttpLink is a terminating link that sends a tRPC operation to a tRPC procedure over HTTP.\n\nhttpLink supports both POST and GET requests.\n\nUsage​\n\nYou can import and add the httpLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpLink({\n      url: 'http://localhost:3000',\n      // transformer,\n    }),\n  ],\n});\nCopy\nhttpLink Options​\n\nThe httpLink function takes an options object that has the HTTPLinkOptions shape.\n\nexport interface HTTPLinkOptions {\n  url: string;\n  /**\n   * Add ponyfill for fetch\n   */\n  fetch?: typeof fetch;\n  /**\n   * Add ponyfill for AbortController\n   */\n  AbortController?: typeof AbortController | null;\n  /**\n   * Data transformer\n   * @see https://trpc.io/docs/v11/data-transformers\n   **/\n  transformer?: DataTransformerOptions;\n  /**\n   * Headers to be set on outgoing requests or a callback that of said headers\n   * @see http://trpc.io/docs/v10/header\n   */\n  headers?:\n    | HTTPHeaders\n    | ((opts: { op: Operation }) => HTTPHeaders | Promise<HTTPHeaders>);\n  /**\n   * Send all requests as POSTS requests regardless of the procedure type\n   * The server must separately allow overriding the method. See:\n   * @see https://trpc.io/docs/rpc\n   */\n  methodOverride?: 'POST';\n}\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/httpBatchLink",
    "html": "Client Usage\nLinks\nHTTP Batch Link\nVersion: 11.x\nHTTP Batch Link\n\nhttpBatchLink is a terminating link that batches an array of individual tRPC operations into a single HTTP request that's sent to a single tRPC procedure.\n\nUsage​\n\nYou can import and add the httpBatchLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000',\n    }),\n    // transformer,\n  ],\n});\nCopy\n\nAfter that, you can make use of batching by setting all your procedures in a Promise.all. The code below will produce exactly one HTTP request and on the server exactly one database query:\n\nconst somePosts = await Promise.all([\n  trpc.post.byId.query(1),\n  trpc.post.byId.query(2),\n  trpc.post.byId.query(3),\n]);\nCopy\nhttpBatchLink Options​\n\nThe httpBatchLink function takes an options object that has the HTTPBatchLinkOptions shape.\n\nexport interface HTTPBatchLinkOptions extends HTTPLinkOptions {\n  /**\n   * Maximum length of HTTP URL allowed before operations are split into multiple requests\n   * @default Infinity\n   */\n  maxURLLength?: number;\n  /**\n   * Maximum number of operations allowed in a single batch request\n   * @default Infinity\n   */\n  maxItems?: number;\n}\nexport interface HTTPLinkOptions {\n  url: string;\n  /**\n   * Add ponyfill for fetch\n   */\n  fetch?: typeof fetch;\n  /**\n   * Add ponyfill for AbortController\n   */\n  AbortController?: typeof AbortController | null;\n  /**\n   * Data transformer\n   * @see https://trpc.io/docs/data-transformers\n   **/\n  transformer?: DataTransformerOptions;\n  /**\n   * Headers to be set on outgoing requests or a callback that of said headers\n   * @see http://trpc.io/docs/header\n   */\n  headers?:\n    | HTTPHeaders\n    | ((opts: { opList: Operation[] }) => HTTPHeaders | Promise<HTTPHeaders>);\n}\nCopy\nSetting a maximum URL length​\n\nWhen sending batch requests, sometimes the URL can become too large causing HTTP errors like 413 Payload Too Large, 414 URI Too Long, and 404 Not Found. The maxURLLength option will limit the number of requests that can be sent together in a batch.\n\nAn alternative way of doing this is to\n\nclient/index.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000',\n      maxURLLength: 2083, // a suitable size\n      // alternatively, you can make all RPC-calls to be called with POST\n      // methodOverride: 'POST',\n    }),\n  ],\n});\nCopy\nDisabling request batching​\n1. Disable batching on your server:​\nserver.ts\nimport { createHTTPServer } from '@trpc/server/adapters/standalone';\ncreateHTTPServer({\n  // [...]\n  // 👇 disable batching\n  allowBatching: false,\n});\nCopy\n\nor, if you're using Next.js:\n\npages/api/trpc/[trpc].ts\nexport default trpcNext.createNextApiHandler({\n  // [...]\n  // 👇 disable batching\n  allowBatching: false,\n});\nCopy\n2. Replace httpBatchLink with httpLink in your tRPC Client​\nclient/index.ts\nimport { createTRPCClient, httpLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nor, if you're using Next.js:\n\nutils/trpc.ts\nimport type { AppRouter } from '@/server/routers/app';\nimport { httpLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nexport const trpc = createTRPCNext<AppRouter>({\n  config() {\n    return {\n      links: [\n        httpLink({\n          url: '/api/trpc',\n        }),\n      ],\n    };\n  },\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/httpBatchStreamLink",
    "html": "Client Usage\nLinks\nHTTP Batch Stream Link\nVersion: 11.x\nHTTP Batch Stream Link\n\nhttpBatchStreamLink is a terminating link that batches an array of individual tRPC operations into a single HTTP request that's sent to a single tRPC procedure (equivalent to httpBatchLink), but doesn't wait for all the responses of the batch to be ready and streams the responses as soon as any data is available.\n\nOptions​\n\nOptions are identical to httpBatchLink options.\n\nUsage​\n\nAll usage and options are identical to httpBatchLink.\n\nNOTE\n\nIf you require the ability to change/set response headers (which includes cookies) from within your procedures, make sure to use httpBatchLink instead! This is due to the fact that httpBatchStreamLink does not support setting headers once the stream has begun. Read more.\n\nYou can import and add the httpBatchStreamLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpBatchStreamLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchStreamLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nAfter that, you can make use of batching by setting all your procedures in a Promise.all. The code below will produce exactly one HTTP request and on the server exactly one database query:\n\nconst somePosts = await Promise.all([\n  trpc.post.byId.query(1),\n  trpc.post.byId.query(2),\n  trpc.post.byId.query(3),\n]);\nCopy\nStreaming mode​\n\nWhen batching requests together, the behavior of a regular httpBatchLink is to wait for all requests to finish before sending the response. If you want to send responses as soon as they are ready, you can use httpBatchStreamLink instead. This is useful for long-running requests.\n\nclient/index.ts\nimport { createTRPCClient, httpBatchStreamLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchStreamLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nCompared to a regular httpBatchLink, a httpBatchStreamLink will:\n\nCause the requests to be sent with a trpc-accept: application/jsonl header\nCause the response to be sent with a transfer-encoding: chunked and content-type: application/jsonl\nRemove the data key from the argument object passed to responseMeta (because with a streamed response, the headers are sent before the data is available)\nAsync generators and deferred promises​\n\nYou can try this out on the homepage of tRPC.io: https://trpc.io/?try=minimal#try-it-out\n\n// @filename: server.ts\nimport { publicProcedure, router } from './trpc';\n \nconst appRouter = router({\n  examples: {\n    iterable: publicProcedure.query(async function* () {\n      for (let i = 0; i < 3; i++) {\n        await new Promise((resolve) => setTimeout(resolve, 500));\n        yield i;\n      }\n    }),\n  },\n});\n \nexport type AppRouter = typeof appRouter;\n \n \n// @filename: client.ts\nimport { createTRPCClient, httpBatchStreamLink } from '@trpc/client';\nimport type { AppRouter } from './server';\n \nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchStreamLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nconst iterable = await trpc.examples.iterable.query();\n         \nconst iterable: AsyncIterable<number, never, unknown>\n \nfor await (const value of iterable) {\n  console.log('Iterable:', value);\n                            \nconst value: number\n}\nCopy\nCompatibility (client-side)​\nBrowsers​\n\nBrowser support should be identical to fetch support.\n\nNode.js / Deno​\n\nFor runtimes other than the browser ones, the fetch implementation should support streaming, meaning that the response obtained by await fetch(...) should have a body property of type ReadableStream<Uint8Array> | NodeJS.ReadableStream, meaning that:\n\neither response.body.getReader is a function that returns a ReadableStreamDefaultReader<Uint8Array> object\nor response.body is a Uint8Array Buffer\n\nThis includes support for undici, node-fetch, native Node.js fetch implementation, and WebAPI fetch implementation (browsers).\n\nReact Native​\n\nReceiving the stream relies on the TextDecoder and TextDecoderStream APIs, which is not available in React Native. It's important to note that if your TextDecoderStream polyfill does not automatically polyfill ReadableStream and WritableStream those will also need to be polyfilled. If you still want to enable streaming, you need to polyfill those.\n\nYou will also need to overide the default fetch in the httpBatchStreamLink configuration options. In the below example we will be using the Expo fetch package for the fetch implementation.\n\nhttpBatchStreamLink({\n  fetch: (url, opts) =>\n    fetch(url, {\n      ...opts,\n      reactNative: { textStreaming: true },\n    }),\n  ...restOfConfig,\n});\nCopy\nCompatibility (server-side)​\n\n⚠️ for aws lambda, httpBatchStreamLink is not supported (will simply behave like a regular httpBatchLink). It should not break anything if enabled, but will not have any effect.\n\n⚠️ for cloudflare workers, you need to enable the ReadableStream API through a feature flag: streams_enable_constructors\n\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nConfigure a ping option to keep the connection alive​\n\nWhen setting up your root config, you can pass in a jsonl option to configure a ping option to keep the connection alive.\n\nimport { initTRPC } from '@trpc/server';\nconst t = initTRPC.create({\n  jsonl: {\n    pingMs: 1000,\n  },\n});\nCopy\nEdit this page"
  },
  {
    "title": "Local Link | tRPC",
    "url": "https://trpc.io/docs/client/links/localLink",
    "html": "Client Usage\nLinks\nLocal Link\nVersion: 11.x\nLocal Link\n\nlocalLink is a terminating link that allows you to make tRPC procedure calls directly in your application without going through HTTP.\n\nINFO\n\nWe have prefixed this as unstable_ as it's a new API, but you're safe to use it! Read more.\n\nUsage​\nimport { createTRPCClient, unstable_localLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    unstable_localLink({\n      router: appRouter,\n      createContext: async () => {\n        // Create your context here\n        return {};\n      },\n      onError: (opts) => {\n        // Log errors here, similarly to how you would in an API route\n        console.error('Error:', opts.error);\n      },\n    }),\n  ],\n});\nCopy\nFeatures​\nDirect procedure calls without HTTP overhead\nFull support for queries, mutations, and subscriptions\nAutomatic error handling and transformation\nSupport for abort signals\nType-safe context creation\nOptions​\n\nThe localLink accepts the following options:\n\ntype LocalLinkOptions<TRouter extends AnyRouter> = {\n  router: TRouter;\n  createContext: () => Promise<inferRouterContext<TRouter>>;\n  onError?: (opts: ErrorHandlerOptions<inferRouterContext<TRouter>>) => void;\n} & TransformerOptions<inferClientTypes<TRouter>>;\nCopy\nrouter​\n\nThe tRPC router instance to use for procedure calls.\n\ncreateContext​\n\nA function that creates the context for each procedure call. This is called for each request and should return a promise that resolves to the context object.\n\nonError​\n\nAn optional error handler that is called when an error occurs during a procedure call. It receives the error, operation type, path, input, and context.\n\ntransformer​\n\nOptional input/output transformers for serialization/deserialization of data.\n\nNotes​\nIt's recommended to use this link in scenarios where you need direct procedure calls without HTTP\nFor most client-side applications, you should use the httpLink or other HTTP-based links instead\nThe link supports all tRPC features including queries, mutations, and subscriptions\nError handling and transformation are handled automatically, just like with HTTP-based links\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/loggerLink",
    "html": "Client Usage\nLinks\nLogger Link\nVersion: 11.x\nLogger Link\n\nloggerLink is a link that lets you implement a logger for your tRPC client. It allows you to see more clearly what operations are queries, mutations, or subscriptions, their requests, and responses. The link, by default, prints a prettified log to the browser's console. However, you can customize the logging behavior and the way it prints to the console with your own implementations.\n\nUsage​\n\nYou can import and add the loggerLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpBatchLink, loggerLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    /**\n     * The function passed to enabled is an example in case you want to the link to\n     * log to your console in development and only log errors in production\n     */\n    loggerLink({\n      enabled: (opts) =>\n        (process.env.NODE_ENV === 'development' &&\n          typeof window !== 'undefined') ||\n        (opts.direction === 'down' && opts.result instanceof Error),\n    }),\n    httpBatchLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\nloggerLink Options​\n\nThe loggerLink function takes an options object that has the LoggerLinkOptions shape:\n\ntype LoggerLinkOptions<TRouter extends AnyRouter> = {\n  logger?: LogFn<TRouter>;\n  /**\n   * It is a function that returns a condition that determines whether to enable the logger.\n   * It is true by default.\n   */\n  enabled?: EnabledFn<TRouter>;\n  /**\n   * Used in the built-in defaultLogger\n   */\n  console?: ConsoleEsque;\n  /**\n   * Color mode used in the default logger.\n   * @default typeof window === 'undefined' ? 'ansi' : 'css'\n   */\n  colorMode?: 'ansi' | 'css';\n};\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/retryLink",
    "html": "Client Usage\nLinks\nRetry Link\nVersion: 11.x\nRetry Link\n\nretryLink is a link that allows you to retry failed operations in your tRPC client. It provides a customizable way to handle transient errors, such as network failures or server errors, by automatically retrying the failed requests based on specified conditions.\n\nTIP\n\nIf you use @trpc/react-query you will generally not need this link as it's built into the useQuery() and the useMutation() hooks from @tanstack/react-query.\n\nUsage​\n\nYou can import and add the retryLink to the links array when creating your tRPC client. This link can be placed before or after other links in your setup, depending on your requirements.\n\nimport { createTRPCClient, retryLink } from '@trpc/client';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    retryLink({\n      retry(opts) {\n        if (\n          opts.error.data &&\n          opts.error.data.code !== 'INTERNAL_SERVER_ERROR'\n        ) {\n          // Don't retry on non-500s\n          return false;\n        }\n        if (opts.op.type !== 'query') {\n          // Only retry queries\n          return false;\n        }\n        // Retry up to 3 times\n        return opts.attempts <= 3;\n      },\n      // Double every attempt, with max of 30 seconds (starting at 1 second)\n      retryDelayMs: (attemptIndex) => Math.min(1000 * 2 ** attemptIndex, 30000),\n    }),\n    httpBatchLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nIn the example above, we add the retryLink before the httpBatchLink. By default, retryLink will:\n\nRetry the request if the error is a TRPCClientError with a status code of 500 or if we couldn't get a valid TRPC error.\nRetry the request up to 3 times.\n\nYou can customize the retry logic by providing a custom retry function.\n\nOptions​\ninterface RetryLinkOptions<TInferrable extends InferrableClientTypes> {\n  /**\n   * The retry function\n   */\n  retry: (opts: RetryFnOptions<TInferrable>) => boolean;\n  /**\n   * The delay between retries in ms (defaults to 0)\n   */\n  retryDelayMs?: (attempt: number) => number;\n}\ninterface RetryFnOptions<TInferrable extends InferrableClientTypes> {\n  /**\n   * The operation that failed\n   */\n  op: Operation;\n  /**\n   * The error that occurred\n   */\n  error: TRPCClientError<TInferrable>;\n  /**\n   * The number of attempts that have been made (including the first call)\n   */\n  attempts: number;\n}\nCopy\nHandling tracked() events​\n\nWhen using retryLink with subscriptions that use tracked(), the link will automatically include the last known event ID when retrying. This ensures that when a subscription reconnects, it can resume from where it left off without missing any events.\n\nFor example, if you're using Server-sent Events (SSE) with httpSubscriptionLink, the retryLink will automatically handle reconnecting with the last event ID when errors like 401 Unauthorized occur.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/classes/TRPCClientError",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nclasses\nClass: TRPCClientError\\<TRouterOrProcedure\\>\nVersion: 11.x\nClass: TRPCClientError<TRouterOrProcedure>\n\nDefined in: packages/client/src/TRPCClientError.ts:47\n\nExtends​\nError\nType Parameters​\nType Parameter\nTRouterOrProcedure extends InferrableClientTypes\nImplements​\nTRPCClientErrorBase<inferErrorShape<TRouterOrProcedure>>\nConstructors​\nnew TRPCClientError()​\n\nnew TRPCClientError<TRouterOrProcedure>(message, opts?): TRPCClientError<TRouterOrProcedure>\n\nDefined in: packages/client/src/TRPCClientError.ts:63\n\nParameters​\nParameter\tType\nmessage\tstring\nopts?\t{ cause: Error; meta: Record<string, unknown>; result: Maybe<TRPCErrorResponse<inferErrorShape<TRouterOrProcedure>>>; }\nopts.cause?\tError\nopts.meta?\tRecord<string, unknown>\nopts.result?\tMaybe<TRPCErrorResponse<inferErrorShape<TRouterOrProcedure>>>\nReturns​\n\nTRPCClientError<TRouterOrProcedure>\n\nOverrides​\n\nError.constructor\n\nProperties​\ncause​\n\nreadonly cause: undefined | Error\n\nDefined in: packages/client/src/TRPCClientError.ts:53\n\nOverrides​\n\nError.cause\n\ndata​\n\nreadonly data: Maybe<inferErrorShape<TRouterOrProcedure>[\"data\"]>\n\nDefined in: packages/client/src/TRPCClientError.ts:55\n\nImplementation of​\n\nTRPCClientErrorBase.data\n\nmessage​\n\nmessage: string\n\nDefined in: node_modules/.pnpm/typescript@5.9.2/node_modules/typescript/lib/lib.es5.d.ts:1077\n\nImplementation of​\n\nTRPCClientErrorBase.message\n\nInherited from​\n\nError.message\n\nmeta​\n\nmeta: undefined | Record<string, unknown>\n\nDefined in: packages/client/src/TRPCClientError.ts:61\n\nAdditional meta data about the error In the case of HTTP-errors, we'll have response and potentially responseJSON here\n\nname​\n\nname: string\n\nDefined in: node_modules/.pnpm/typescript@5.9.2/node_modules/typescript/lib/lib.es5.d.ts:1076\n\nInherited from​\n\nError.name\n\nshape​\n\nreadonly shape: Maybe<inferErrorShape<TRouterOrProcedure>>\n\nDefined in: packages/client/src/TRPCClientError.ts:54\n\nImplementation of​\n\nTRPCClientErrorBase.shape\n\nstack?​\n\noptional stack: string\n\nDefined in: node_modules/.pnpm/typescript@5.9.2/node_modules/typescript/lib/lib.es5.d.ts:1078\n\nInherited from​\n\nError.stack\n\nstackTraceLimit​\n\nstatic stackTraceLimit: number\n\nDefined in: node_modules/.pnpm/@types+node@22.17.0/node_modules/@types/node/globals.d.ts:161\n\nThe Error.stackTraceLimit property specifies the number of stack frames collected by a stack trace (whether generated by new Error().stack or Error.captureStackTrace(obj)).\n\nThe default value is 10 but may be set to any valid JavaScript number. Changes will affect any stack trace captured after the value has been changed.\n\nIf set to a non-number value, or set to a negative number, stack traces will not capture any frames.\n\nInherited from​\n\nError.stackTraceLimit\n\nMethods​\ncaptureStackTrace()​\n\nstatic captureStackTrace(targetObject, constructorOpt?): void\n\nDefined in: node_modules/.pnpm/@types+node@22.17.0/node_modules/@types/node/globals.d.ts:145\n\nCreates a .stack property on targetObject, which when accessed returns a string representing the location in the code at which Error.captureStackTrace() was called.\n\nconst myObject = {};\nError.captureStackTrace(myObject);\nmyObject.stack;  // Similar to `new Error().stack`\nCopy\n\nThe first line of the trace will be prefixed with ${myObject.name}: ${myObject.message}.\n\nThe optional constructorOpt argument accepts a function. If given, all frames above constructorOpt, including constructorOpt, will be omitted from the generated stack trace.\n\nThe constructorOpt argument is useful for hiding implementation details of error generation from the user. For instance:\n\nfunction a() {\n  b();\n}\nfunction b() {\n  c();\n}\nfunction c() {\n  // Create an error without stack trace to avoid calculating the stack trace twice.\n  const { stackTraceLimit } = Error;\n  Error.stackTraceLimit = 0;\n  const error = new Error();\n  Error.stackTraceLimit = stackTraceLimit;\n  // Capture the stack trace above function b\n  Error.captureStackTrace(error, b); // Neither function c, nor b is included in the stack trace\n  throw error;\n}\na();\nCopy\nParameters​\nParameter\tType\ntargetObject\tobject\nconstructorOpt?\tFunction\nReturns​\n\nvoid\n\nInherited from​\n\nError.captureStackTrace\n\nfrom()​\n\nstatic from<TRouterOrProcedure>(_cause, opts): TRPCClientError<TRouterOrProcedure>\n\nDefined in: packages/client/src/TRPCClientError.ts:87\n\nType Parameters​\nType Parameter\nTRouterOrProcedure extends InferrableClientTypes\nParameters​\nParameter\tType\n_cause\tobject | Error | TRPCErrorResponse<any>\nopts\t{ meta: Record<string, unknown>; }\nopts.meta?\tRecord<string, unknown>\nReturns​\n\nTRPCClientError<TRouterOrProcedure>\n\nprepareStackTrace()​\n\nstatic prepareStackTrace(err, stackTraces): any\n\nDefined in: node_modules/.pnpm/@types+node@22.17.0/node_modules/@types/node/globals.d.ts:149\n\nParameters​\nParameter\tType\nerr\tError\nstackTraces\tCallSite[]\nReturns​\n\nany\n\nSee​\n\nhttps://v8.dev/docs/stack-trace-api#customizing-stack-traces\n\nInherited from​\n\nError.prepareStackTrace\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/classes/TRPCUntypedClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nclasses\nClass: TRPCUntypedClient\\<TInferrable\\>\nVersion: 11.x\nClass: TRPCUntypedClient<TInferrable>\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:47\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nConstructors​\nnew TRPCUntypedClient()​\n\nnew TRPCUntypedClient<TInferrable>(opts): TRPCUntypedClient<TInferrable>\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:52\n\nParameters​\nParameter\tType\nopts\tCreateTRPCClientOptions<TInferrable>\nReturns​\n\nTRPCUntypedClient<TInferrable>\n\nProperties​\nruntime​\n\nreadonly runtime: TRPCClientRuntime\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:49\n\nMethods​\nmutation()​\n\nmutation(path, input?, opts?): Promise<unknown>\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:106\n\nParameters​\nParameter\tType\npath\tstring\ninput?\tunknown\nopts?\tTRPCRequestOptions\nReturns​\n\nPromise<unknown>\n\nquery()​\n\nquery(path, input?, opts?): Promise<unknown>\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:97\n\nParameters​\nParameter\tType\npath\tstring\ninput?\tunknown\nopts?\tTRPCRequestOptions\nReturns​\n\nPromise<unknown>\n\nsubscription()​\n\nsubscription(path, input, opts): Unsubscribable\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:115\n\nParameters​\nParameter\tType\npath\tstring\ninput\tunknown\nopts\tPartial<TRPCSubscriptionObserver<unknown, TRPCClientError<AnyRouter>>> & TRPCRequestOptions\nReturns​\n\nUnsubscribable\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/interfaces/TRPCClientErrorBase",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ninterfaces\nInterface: TRPCClientErrorBase\\<TShape\\>\nVersion: 11.x\nInterface: TRPCClientErrorBase<TShape>\n\nDefined in: packages/client/src/TRPCClientError.ts:14\n\nType Parameters​\nType Parameter\nTShape extends DefaultErrorShape\nProperties​\ndata​\n\nreadonly data: Maybe<TShape[\"data\"]>\n\nDefined in: packages/client/src/TRPCClientError.ts:17\n\nmessage​\n\nreadonly message: string\n\nDefined in: packages/client/src/TRPCClientError.ts:15\n\nshape​\n\nreadonly shape: Maybe<TShape>\n\nDefined in: packages/client/src/TRPCClientError.ts:16\n\nEdit this page"
  },
  {
    "title": "Interface: TRPCClientRuntime | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/interfaces/TRPCClientRuntime",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ninterfaces\nInterface: TRPCClientRuntime\nVersion: 11.x\nInterface: TRPCClientRuntime\n\nDefined in: packages/client/src/links/types.ts:55\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/interfaces/TRPCProcedureOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ninterfaces\nInterface: TRPCProcedureOptions\nVersion: 11.x\nInterface: TRPCProcedureOptions\n\nDefined in: packages/client/src/internals/types.ts:95\n\nProperties​\ncontext?​\n\noptional context: ClientContext\n\nDefined in: packages/client/src/internals/types.ts:99\n\nClient-side context\n\nsignal?​\n\noptional signal: AbortSignal\n\nDefined in: packages/client/src/internals/types.ts:100\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/interfaces/TRPCRequestOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ninterfaces\nInterface: TRPCRequestOptions\nVersion: 11.x\nInterface: TRPCRequestOptions\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:24\n\nProperties​\ncontext?​\n\noptional context: OperationContext\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:28\n\nPass additional context to links\n\nsignal?​\n\noptional signal: AbortSignal\n\nDefined in: packages/client/src/internals/TRPCUntypedClient.ts:29\n\nEdit this page"
  },
  {
    "title": "Interface: WebSocketClientOptions | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/interfaces/WebSocketClientOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ninterfaces\nInterface: WebSocketClientOptions\nVersion: 11.x\nInterface: WebSocketClientOptions\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:3\n\nExtends​\nUrlOptionsWithConnectionParams\nProperties​\nconnectionParams?​\n\noptional connectionParams: CallbackOrValue<null | Dict<string>>\n\nDefined in: packages/client/src/links/internals/urlWithConnectionParams.ts:32\n\nConnection params that are available in createContext()\n\nFor wsLink/wsClient, these are sent as the first message\nFor httpSubscriptionLink, these are serialized as part of the URL under the connectionParams query\nInherited from​\n\nUrlOptionsWithConnectionParams.connectionParams\n\nkeepAlive?​\n\noptional keepAlive: object\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:43\n\nSend ping messages to the server and kill the connection if no pong message is returned\n\nenabled​\n\nenabled: boolean\n\nDefault​\nfalse\nCopy\nintervalMs?​\n\noptional intervalMs: number\n\nSend a ping message every this many milliseconds\n\nDefault​\n5_000\nCopy\npongTimeoutMs?​\n\noptional pongTimeoutMs: number\n\nClose the WebSocket after this many milliseconds if the server does not respond\n\nDefault​\n1_000\nCopy\nlazy?​\n\noptional lazy: object\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:28\n\nLazy mode will close the WebSocket automatically after a period of inactivity (no messages sent or received and no pending requests)\n\ncloseMs​\n\ncloseMs: number\n\nClose the WebSocket after this many milliseconds\n\nDefault​\n0\nCopy\nenabled​\n\nenabled: boolean\n\nEnable lazy mode\n\nDefault​\nfalse\nCopy\nonClose()?​\n\noptional onClose: (cause?) => void\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:24\n\nTriggered when a WebSocket connection is closed\n\nParameters​\nParameter\tType\ncause?\t{ code: number; }\ncause.code?\tnumber\nReturns​\n\nvoid\n\nonError()?​\n\noptional onError: (evt?) => void\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:20\n\nTriggered when a WebSocket connection encounters an error\n\nParameters​\nParameter\tType\nevt?\tEvent\nReturns​\n\nvoid\n\nonOpen()?​\n\noptional onOpen: () => void\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:16\n\nTriggered when a WebSocket connection is established\n\nReturns​\n\nvoid\n\nretryDelayMs()?​\n\noptional retryDelayMs: (attemptIndex) => number\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:12\n\nThe number of milliseconds before a reconnect is attempted.\n\nParameters​\nParameter\tType\nattemptIndex\tnumber\nReturns​\n\nnumber\n\nDefault​\n\nexponentialBackoff\n\nurl​\n\nurl: CallbackOrValue<string>\n\nDefined in: packages/client/src/links/internals/urlWithConnectionParams.ts:25\n\nThe URL to connect to (can be a function that returns a URL)\n\nInherited from​\n\nUrlOptionsWithConnectionParams.url\n\nWebSocket()?​\n\noptional WebSocket: (url, protocols?) => WebSocket\n\nDefined in: packages/client/src/links/wsLink/wsClient/options.ts:7\n\nPonyfill which WebSocket implementation to use\n\nParameters​\nParameter\tType\nurl\tstring | URL\nprotocols?\tstring | string[]\nReturns​\n\nWebSocket\n\nCLOSED​\n\nreadonly CLOSED: 3\n\nCLOSING​\n\nreadonly CLOSING: 2\n\nCONNECTING​\n\nreadonly CONNECTING: 0\n\nOPEN​\n\nreadonly OPEN: 1\n\nprototype​\n\nprototype: WebSocket\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/CreateTRPCClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: ~~CreateTRPCClient\\<TRouter\\>~~\nVersion: 11.x\nType Alias: CreateTRPCClient<TRouter>\n\nCreateTRPCClient<TRouter>: TRPCClient<TRouter>\n\nDefined in: packages/client/src/createTRPCClient.ts:33\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nDeprecated​\n\nuse TRPCClient instead, will be removed in v12\n\nEdit this page"
  },
  {
    "title": "Type Alias: HTTPBatchLinkOptions\\<TRoot\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/HTTPBatchLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: HTTPBatchLinkOptions\\<TRoot\\>\nVersion: 11.x\nType Alias: HTTPBatchLinkOptions<TRoot>\n\nHTTPBatchLinkOptions<TRoot>: HTTPLinkBaseOptions<TRoot> & object\n\nDefined in: packages/client/src/links/HTTPBatchLinkOptions.ts:6\n\nType declaration​\nheaders?​\n\noptional headers: HTTPHeaders | (opts) => HTTPHeaders | Promise<HTTPHeaders>\n\nHeaders to be set on outgoing requests or a callback that of said headers\n\nSee​\n\nhttp://trpc.io/docs/client/headers\n\nmaxItems?​\n\noptional maxItems: number\n\nMaximum number of calls in a single batch request\n\nDefault​\nInfinity\nCopy\nmaxURLLength?​\n\noptional maxURLLength: number\n\nType Parameters​\nType Parameter\nTRoot extends AnyClientTypes\nEdit this page"
  },
  {
    "title": "Type Alias: ~~inferRouterProxyClient\\<TRouter\\>~~ | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/inferRouterProxyClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: ~~inferRouterProxyClient\\<TRouter\\>~~\nVersion: 11.x\nType Alias: inferRouterProxyClient<TRouter>\n\ninferRouterProxyClient<TRouter>: TRPCClient<TRouter>\n\nDefined in: packages/client/src/createTRPCClient.ts:27\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nDeprecated​\n\nuse TRPCClient instead, will be removed in v12\n\nEdit this page"
  },
  {
    "title": "Type Alias: LocalLinkOptions\\<TRouter\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/LocalLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: LocalLinkOptions\\<TRouter\\>\nVersion: 11.x\nType Alias: LocalLinkOptions<TRouter>\n\nLocalLinkOptions<TRouter>: object & TransformerOptions<inferClientTypes<TRouter>>\n\nDefined in: packages/client/src/links/localLink.ts:29\n\nType declaration​\ncreateContext()​\n\ncreateContext: () => Promise<inferRouterContext<TRouter>>\n\nReturns​\n\nPromise<inferRouterContext<TRouter>>\n\nonError()?​\n\noptional onError: (opts) => void\n\nParameters​\nParameter\tType\nopts\tErrorHandlerOptions<inferRouterContext<TRouter>>\nReturns​\n\nvoid\n\nrouter​\n\nrouter: TRouter\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "Type Alias: TRPCClient\\<TRouter\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/TRPCClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: TRPCClient\\<TRouter\\>\nVersion: 11.x\nType Alias: TRPCClient<TRouter>\n\nTRPCClient<TRouter>: DecoratedProcedureRecord<{ errorShape: TRouter[\"_def\"][\"_config\"][\"$types\"][\"errorShape\"]; transformer: TRouter[\"_def\"][\"_config\"][\"$types\"][\"transformer\"]; }, TRouter[\"_def\"][\"record\"]> & object\n\nDefined in: packages/client/src/createTRPCClient.ts:40\n\nType declaration​\n[untypedClientSymbol]​\n\n[untypedClientSymbol]: TRPCUntypedClient<TRouter>\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/TRPCClientErrorLike",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: TRPCClientErrorLike\\<TInferrable\\>\nVersion: 11.x\nType Alias: TRPCClientErrorLike<TInferrable>\n\nTRPCClientErrorLike<TInferrable>: TRPCClientErrorBase<inferErrorShape<TInferrable>>\n\nDefined in: packages/client/src/TRPCClientError.ts:19\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/TRPCFetch",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: TRPCFetch()\nVersion: 11.x\nType Alias: TRPCFetch()\n\nTRPCFetch: (url, options?) => Promise<ResponseEsque>\n\nDefined in: packages/client/src/links/types.ts:50\n\nThe default fetch implementation has an overloaded signature. By convention this library only uses the overload taking a string and options object.\n\nParameters​\nParameter\tType\nurl\tstring\noptions?\tRequestInit\nReturns​\n\nPromise<ResponseEsque>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/TRPCLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: TRPCLink()\\<TInferrable\\>\nVersion: 11.x\nType Alias: TRPCLink()<TInferrable>\n\nTRPCLink<TInferrable>: (opts) => OperationLink<TInferrable>\n\nDefined in: packages/client/src/links/types.ts:109\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nParameters​\nParameter\tType\nopts\tTRPCClientRuntime\nReturns​\n\nOperationLink<TInferrable>\n\nEdit this page"
  },
  {
    "title": "Type Alias: TRPCWebSocketClient | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/type-aliases/TRPCWebSocketClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\ntype-aliases\nType Alias: TRPCWebSocketClient\nVersion: 11.x\nType Alias: TRPCWebSocketClient\n\nTRPCWebSocketClient: ReturnType<typeof createWSClient>\n\nDefined in: packages/client/src/links/wsLink/createWsClient.ts:8\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/createTRPCProxyClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: createTRPCProxyClient()\nVersion: 11.x\nFunction: createTRPCProxyClient()\n\ncreateTRPCProxyClient<TRouter>(opts): TRPCClient<TRouter>\n\nDefined in: packages/client/src/createTRPCClient.ts:158\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tCreateTRPCClientOptions<TRouter>\nReturns​\n\nTRPCClient<TRouter>\n\nEdit this page"
  },
  {
    "title": "Function: createTRPCUntypedClient() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/createTRPCUntypedClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: createTRPCUntypedClient()\nVersion: 11.x\nFunction: createTRPCUntypedClient()\n\ncreateTRPCUntypedClient<TRouter>(opts): TRPCUntypedClient<TRouter>\n\nDefined in: packages/client/src/createTRPCUntypedClient.ts:5\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tCreateTRPCClientOptions<TRouter>\nReturns​\n\nTRPCUntypedClient<TRouter>\n\nEdit this page"
  },
  {
    "title": "Function: createWSClient() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/createWSClient",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: createWSClient()\nVersion: 11.x\nFunction: createWSClient()\n\ncreateWSClient(opts): WsClient\n\nDefined in: packages/client/src/links/wsLink/createWsClient.ts:4\n\nParameters​\nParameter\tType\nopts\tWebSocketClientOptions\nReturns​\n\nWsClient\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/experimental_localLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: ~~experimental\\_localLink()~~\nVersion: 11.x\nFunction: experimental_localLink()\n\nexperimental_localLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/localLink.ts:281\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tLocalLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nDeprecated​\n\nRenamed to unstable_localLink. This alias will be removed in a future major release.\n\nSee​\n\nhttps://trpc.io/docs/links/localLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/getFetch",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: getFetch()\nVersion: 11.x\nFunction: getFetch()\n\ngetFetch(customFetchImpl?): FetchEsque\n\nDefined in: packages/client/src/getFetch.ts:7\n\nParameters​\nParameter\tType\ncustomFetchImpl?\tFetchEsque | NativeFetchEsque\nReturns​\n\nFetchEsque\n\nEdit this page"
  },
  {
    "title": "Function: httpBatchStreamLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/httpBatchStreamLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: httpBatchStreamLink()\nVersion: 11.x\nFunction: httpBatchStreamLink()\n\nhttpBatchStreamLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/httpBatchStreamLink.ts:23\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tHTTPBatchLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpBatchStreamLink\n\nEdit this page"
  },
  {
    "title": "Function: httpSubscriptionLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/httpSubscriptionLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: httpSubscriptionLink()\nVersion: 11.x\nFunction: httpSubscriptionLink()\n\nhttpSubscriptionLink<TInferrable, TEventSource>(opts): TRPCLink<TInferrable>\n\nDefined in: packages/client/src/links/httpSubscriptionLink.ts:65\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nTEventSource extends AnyConstructor\nParameters​\nParameter\tType\nopts\tHTTPSubscriptionLinkOptions<inferClientTypes<TInferrable>, TEventSource>\nReturns​\n\nTRPCLink<TInferrable>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpSubscriptionLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/isFormData",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: isFormData()\nVersion: 11.x\nFunction: isFormData()\n\nisFormData(input): input is FormData\n\nDefined in: packages/client/src/links/internals/contentTypes.ts:11\n\nParameters​\nParameter\tType\ninput\tunknown\nReturns​\n\ninput is FormData\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/isNonJsonSerializable",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: isNonJsonSerializable()\nVersion: 11.x\nFunction: isNonJsonSerializable()\n\nisNonJsonSerializable(input): input is Uint8Array<ArrayBuffer> | Blob | FormData\n\nDefined in: packages/client/src/links/internals/contentTypes.ts:15\n\nParameters​\nParameter\tType\ninput\tunknown\nReturns​\n\ninput is Uint8Array<ArrayBuffer> | Blob | FormData\n\nEdit this page"
  },
  {
    "title": "Function: isOctetType() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/isOctetType",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: isOctetType()\nVersion: 11.x\nFunction: isOctetType()\n\nisOctetType(input): input is Uint8Array<ArrayBuffer> | Blob\n\nDefined in: packages/client/src/links/internals/contentTypes.ts:1\n\nParameters​\nParameter\tType\ninput\tunknown\nReturns​\n\ninput is Uint8Array<ArrayBuffer> | Blob\n\nEdit this page"
  },
  {
    "title": "Function: isTRPCClientError() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/isTRPCClientError",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: isTRPCClientError()\nVersion: 11.x\nFunction: isTRPCClientError()\n\nisTRPCClientError<TInferrable>(cause): cause is TRPCClientError<TInferrable>\n\nDefined in: packages/client/src/TRPCClientError.ts:22\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nParameters​\nParameter\tType\ncause\tunknown\nReturns​\n\ncause is TRPCClientError<TInferrable>\n\nEdit this page"
  },
  {
    "title": "Function: retryLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/retryLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: retryLink()\nVersion: 11.x\nFunction: retryLink()\n\nretryLink<TInferrable>(opts): TRPCLink<TInferrable>\n\nDefined in: packages/client/src/links/retryLink.ts:39\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nParameters​\nParameter\tType\nopts\tRetryLinkOptions<TInferrable>\nReturns​\n\nTRPCLink<TInferrable>\n\nSee​\n\nhttps://trpc.io/docs/v11/client/links/retryLink\n\nEdit this page"
  },
  {
    "title": "Function: ~~unstable\\_httpBatchStreamLink()~~ | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/unstable_httpBatchStreamLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: ~~unstable\\_httpBatchStreamLink()~~\nVersion: 11.x\nFunction: unstable_httpBatchStreamLink()\n\nunstable_httpBatchStreamLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/httpBatchStreamLink.ts:191\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tHTTPBatchLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nDeprecated​\n\nuse httpBatchStreamLink instead\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpBatchStreamLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/unstable_httpSubscriptionLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: ~~unstable\\_httpSubscriptionLink()~~\nVersion: 11.x\nFunction: unstable_httpSubscriptionLink()\n\nunstable_httpSubscriptionLink<TInferrable, TEventSource>(opts): TRPCLink<TInferrable>\n\nDefined in: packages/client/src/links/httpSubscriptionLink.ts:245\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nTEventSource extends AnyConstructor\nParameters​\nParameter\tType\nopts\tHTTPSubscriptionLinkOptions<inferClientTypes<TInferrable>, TEventSource>\nReturns​\n\nTRPCLink<TInferrable>\n\nDeprecated​\n\nuse httpSubscriptionLink instead\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpSubscriptionLink\n\nEdit this page"
  },
  {
    "title": "Function: unstable\\_localLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/index/functions/unstable_localLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nindex\nfunctions\nFunction: unstable\\_localLink()\nVersion: 11.x\nFunction: unstable_localLink()\n\nunstable_localLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/localLink.ts:40\n\nlocalLink is a terminating link that allows you to make tRPC procedure calls directly in your application without going through HTTP.\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tLocalLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/links/localLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/httpBatchLink/functions/httpBatchLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/httpBatchLink\nfunctions\nFunction: httpBatchLink()\nVersion: 11.x\nFunction: httpBatchLink()\n\nhttpBatchLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/httpBatchLink.ts:21\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tHTTPBatchLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpBatchLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/httpLink/functions/httpLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/httpLink\nfunctions\nFunction: httpLink()\nVersion: 11.x\nFunction: httpLink()\n\nhttpLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/httpLink.ts:75\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\tAnyRouter\nParameters​\nParameter\tType\nopts\tHTTPLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/httpLink/type-aliases/HTTPLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/httpLink\ntype-aliases\nType Alias: HTTPLinkOptions\\<TRoot\\>\nVersion: 11.x\nType Alias: HTTPLinkOptions<TRoot>\n\nHTTPLinkOptions<TRoot>: HTTPLinkBaseOptions<TRoot> & object\n\nDefined in: packages/client/src/links/httpLink.ts:27\n\nType declaration​\nheaders?​\n\noptional headers: HTTPHeaders | (opts) => HTTPHeaders | Promise<HTTPHeaders>\n\nHeaders to be set on outgoing requests or a callback that of said headers\n\nSee​\n\nhttp://trpc.io/docs/client/headers\n\nType Parameters​\nType Parameter\nTRoot extends AnyClientTypes\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/loggerLink/functions/loggerLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/loggerLink\nfunctions\nFunction: loggerLink()\nVersion: 11.x\nFunction: loggerLink()\n\nloggerLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/loggerLink.ts:214\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\tAnyRouter\nParameters​\nParameter\tType\nopts\tLoggerLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/v11/client/links/loggerLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/loggerLink/interfaces/LoggerLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/loggerLink\ninterfaces\nInterface: LoggerLinkOptions\\<TRouter\\>\nVersion: 11.x\nInterface: LoggerLinkOptions<TRouter>\n\nDefined in: packages/client/src/links/loggerLink.ts:61\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nProperties​\ncolorMode?​\n\noptional colorMode: ColorMode\n\nDefined in: packages/client/src/links/loggerLink.ts:72\n\nColor mode\n\nDefault​\ntypeof window === 'undefined' ? 'ansi' : 'css'\nCopy\nconsole?​\n\noptional console: ConsoleEsque\n\nDefined in: packages/client/src/links/loggerLink.ts:67\n\nUsed in the built-in defaultLogger\n\nenabled?​\n\noptional enabled: EnabledFn<TRouter>\n\nDefined in: packages/client/src/links/loggerLink.ts:63\n\nlogger?​\n\noptional logger: LoggerLinkFn<TRouter>\n\nDefined in: packages/client/src/links/loggerLink.ts:62\n\nwithContext?​\n\noptional withContext: boolean\n\nDefined in: packages/client/src/links/loggerLink.ts:77\n\nInclude context in the log - defaults to false unless colorMode is 'css'\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/splitLink/functions/splitLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nlinks/splitLink\nfunctions\nFunction: splitLink()\nVersion: 11.x\nFunction: splitLink()\n\nsplitLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/splitLink.ts:9\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\tAnyRouter\nParameters​\nParameter\tType\tDescription\nopts\t{ condition: (op) => boolean; false: TRPCLink<TRouter> | TRPCLink<TRouter>[]; true: TRPCLink<TRouter> | TRPCLink<TRouter>[]; }\t-\nopts.condition\t(op) => boolean\t-\nopts.false\tTRPCLink<TRouter> | TRPCLink<TRouter>[]\tThe link to execute next if the test function returns false.\nopts.true\tTRPCLink<TRouter> | TRPCLink<TRouter>[]\tThe link to execute next if the test function returns true.\nReturns​\n\nTRPCLink<TRouter>\n\nEdit this page"
  },
  {
    "title": "Type Alias: WebSocketLinkOptions\\<TRouter\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/wsLink/wsLink/type-aliases/WebSocketLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nwsLink\nlinks/wsLink/wsLink\ntype-aliases\nType Alias: WebSocketLinkOptions\\<TRouter\\>\nVersion: 11.x\nType Alias: WebSocketLinkOptions<TRouter>\n\nWebSocketLinkOptions<TRouter>: object & TransformerOptions<inferClientTypes<TRouter>>\n\nDefined in: packages/client/src/links/wsLink/wsLink.ts:15\n\nType declaration​\nclient​\n\nclient: TRPCWebSocketClient\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "Function: wsLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/client/links/wsLink/wsLink/functions/wsLink",
    "html": "API Reference (Auto-generated)\n@trpc/client\nlinks\nwsLink\nlinks/wsLink/wsLink\nfunctions\nFunction: wsLink()\nVersion: 11.x\nFunction: wsLink()\n\nwsLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/src/links/wsLink/wsLink.ts:19\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tWebSocketLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nEdit this page"
  },
  {
    "title": "Type Alias: TRPCPrepassHelper() | tRPC",
    "url": "https://trpc.io/docs/typedoc/next/type-aliases/TRPCPrepassHelper",
    "html": "API Reference (Auto-generated)\n@trpc/next\ntype-aliases\nType Alias: TRPCPrepassHelper()\nVersion: 11.x\nType Alias: TRPCPrepassHelper()\n\nTRPCPrepassHelper: (opts) => void\n\nDefined in: withTRPC.tsx:49\n\nParameters​\nParameter\tType\nopts\t{ AppOrPage: NextComponentType<any, any, any>; parent: WithTRPCSSROptions<AnyRouter>; WithTRPC: NextComponentType<any, any, any>; }\nopts.AppOrPage\tNextComponentType<any, any, any>\nopts.parent\tWithTRPCSSROptions<AnyRouter>\nopts.WithTRPC\tNextComponentType<any, any, any>\nReturns​\n\nvoid\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/next/type-aliases/TRPCPrepassProps",
    "html": "API Reference (Auto-generated)\n@trpc/next\ntype-aliases\nType Alias: TRPCPrepassProps\\<TRouter, TSSRContext\\>\nVersion: 11.x\nType Alias: TRPCPrepassProps<TRouter, TSSRContext>\n\nTRPCPrepassProps<TRouter, TSSRContext>: object\n\nDefined in: withTRPC.tsx:79\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\t-\nTSSRContext extends NextPageContext\tNextPageContext\nType declaration​\nconfig​\n\nconfig: WithTRPCConfig<TRouter>\n\nqueryClient​\n\nqueryClient: QueryClient\n\nssrContext​\n\nssrContext: TSSRContext\n\nssrState​\n\nssrState: \"prepass\"\n\ntrpcClient​\n\ntrpcClient: TRPCUntypedClient<TRouter> | TRPCClient<TRouter>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/next/type-aliases/WithTRPCConfig",
    "html": "API Reference (Auto-generated)\n@trpc/next\ntype-aliases\nType Alias: WithTRPCConfig\\<TRouter\\>\nVersion: 11.x\nType Alias: WithTRPCConfig<TRouter>\n\nWithTRPCConfig<TRouter>: CreateTRPCClientOptions<TRouter> & CreateTRPCReactQueryClientConfig & object\n\nDefined in: withTRPC.tsx:38\n\nType declaration​\nabortOnUnmount?​\n\noptional abortOnUnmount: boolean\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/next/type-aliases/WithTRPCNoSSROptions",
    "html": "API Reference (Auto-generated)\n@trpc/next\ntype-aliases\nType Alias: WithTRPCNoSSROptions\\<TRouter\\>\nVersion: 11.x\nType Alias: WithTRPCNoSSROptions<TRouter>\n\nWithTRPCNoSSROptions<TRouter>: WithTRPCOptions<TRouter> & object\n\nDefined in: withTRPC.tsx:74\n\nType declaration​\nssr?​\n\noptional ssr: false\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "Type Alias: WithTRPCSSROptions\\<TRouter\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/next/type-aliases/WithTRPCSSROptions",
    "html": "API Reference (Auto-generated)\n@trpc/next\ntype-aliases\nType Alias: WithTRPCSSROptions\\<TRouter\\>\nVersion: 11.x\nType Alias: WithTRPCSSROptions<TRouter>\n\nWithTRPCSSROptions<TRouter>: WithTRPCOptions<TRouter> & object\n\nDefined in: withTRPC.tsx:54\n\nType declaration​\nresponseMeta()?​\n\noptional responseMeta: (opts) => ResponseMeta\n\nParameters​\nParameter\tType\nopts\t{ clientErrors: TRPCClientError<TRouter>[]; ctx: NextPageContext; }\nopts.clientErrors\tTRPCClientError<TRouter>[]\nopts.ctx\tNextPageContext\nReturns​\n\nResponseMeta\n\nssr​\n\nssr: true | (opts) => boolean | Promise<boolean>\n\nIf you enable this, you also need to add a ssrPrepass-prop\n\nSee​\n\nhttps://trpc.io/docs/client/nextjs/ssr\n\nssrPrepass​\n\nssrPrepass: TRPCPrepassHelper\n\nuse import { ssrPrepass } from '@trpc/next/ssrPrepass'\n\nSee​\n\nhttps://trpc.io/docs/client/nextjs/ssr\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "Function: createTRPCNext() | tRPC",
    "url": "https://trpc.io/docs/typedoc/next/functions/createTRPCNext",
    "html": "API Reference (Auto-generated)\n@trpc/next\nfunctions\nFunction: createTRPCNext()\nVersion: 11.x\nFunction: createTRPCNext()\n\ncreateTRPCNext<TRouter, TSSRContext>(opts): ProtectedIntersection<CreateTRPCNextBase<TRouter, TSSRContext>, DecorateRouterRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nDefined in: createTRPCNext.tsx:60\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\t-\nTSSRContext extends NextPageContext\tNextPageContext\nParameters​\nParameter\tType\nopts\tWithTRPCNoSSROptions<TRouter> | WithTRPCSSROptions<TRouter>\nReturns​\n\nProtectedIntersection<CreateTRPCNextBase<TRouter, TSSRContext>, DecorateRouterRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nEdit this page"
  },
  {
    "title": "Function: withTRPC() | tRPC",
    "url": "https://trpc.io/docs/typedoc/next/functions/withTRPC",
    "html": "API Reference (Auto-generated)\n@trpc/next\nfunctions\nFunction: withTRPC()\nVersion: 11.x\nFunction: withTRPC()\n\nwithTRPC<TRouter, TSSRContext>(opts): (AppOrPage) => NextComponentType\n\nDefined in: withTRPC.tsx:90\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\t-\nTSSRContext extends NextPageContext\tNextPageContext\nParameters​\nParameter\tType\nopts\tWithTRPCNoSSROptions<TRouter> | WithTRPCSSROptions<TRouter>\nReturns​\n\nFunction\n\nParameters​\nParameter\tType\nAppOrPage\tNextComponentType<any, any, any>\nReturns​\n\nNextComponentType\n\nEdit this page"
  },
  {
    "title": "index | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nVersion: 11.x\nindex\nClasses​\nTRPCClientError\nTRPCUntypedClient\nInterfaces​\nLoggerLinkOptions\nTRPCClientErrorBase\nTRPCClientRuntime\nTRPCProcedureOptions\nTRPCRequestOptions\nWebSocketClientOptions\nType Aliases​\nCreateTRPCClient\nCreateTRPCReact\nHTTPBatchLinkOptions\nHTTPLinkOptions\ninferReactQueryProcedureOptions\ninferRouterClient\nLocalLinkOptions\nTRPCClient\nTRPCClientErrorLike\nTRPCFetch\nTRPCLink\nTRPCWebSocketClient\nWebSocketLinkOptions\nFunctions​\ncreateTRPCClient\ncreateTRPCQueryUtils\ncreateTRPCReact\ncreateTRPCUntypedClient\ncreateWSClient\nexperimental_localLink\ngetFetch\ngetMutationKey\ngetQueryKey\nhttpBatchLink\nhttpBatchStreamLink\nhttpLink\nhttpSubscriptionLink\nisFormData\nisNonJsonSerializable\nisOctetType\nisTRPCClientError\nloggerLink\nretryLink\nsplitLink\nunstable_httpBatchStreamLink\nunstable_httpSubscriptionLink\nunstable_localLink\nwsLink\nReferences​\ncreateTRPCProxyClient​\n\nRenames and re-exports createTRPCClient\n\ninferRouterProxyClient​\n\nRenames and re-exports inferRouterClient\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/server/",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nserver\nVersion: 11.x\nserver\nFunctions​\ncreateServerSideHelpers\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\nVersion: 11.x\nshared\nInterfaces​\nDefinedTRPCInfiniteQueryOptionsIn\nDefinedTRPCInfiniteQueryOptionsOut\nDefinedTRPCQueryOptionsIn\nDefinedTRPCQueryOptionsOut\nTRPCContextProps\nTRPCContextPropsBase\nTRPCFetchQueryOptions\nTRPCHookResult\nTRPCProviderProps\nTRPCQueryBaseOptions\nTRPCQueryOptions\nTRPCQueryOptionsResult\nTRPCReactRequestOptions\nTRPCSubscriptionBaseResult\nTRPCSubscriptionConnectingResult\nTRPCSubscriptionErrorResult\nTRPCSubscriptionIdleResult\nTRPCSubscriptionPendingResult\nTRPCUseQueryBaseOptions\nUndefinedTRPCInfiniteQueryOptionsIn\nUndefinedTRPCInfiniteQueryOptionsOut\nUndefinedTRPCQueryOptionsIn\nUndefinedTRPCQueryOptionsOut\nUnusedSkipTokenTRPCInfiniteQueryOptionsIn\nUnusedSkipTokenTRPCInfiniteQueryOptionsOut\nUnusedSkipTokenTRPCQueryOptionsIn\nUnusedSkipTokenTRPCQueryOptionsOut\nUseTRPCInfiniteQueryOptions\nUseTRPCMutationOptions\nUseTRPCPrefetchQueryOptions\nUseTRPCQueryOptions\nUseTRPCSubscriptionOptions\nUseTRPCSuspenseInfiniteQueryOptions\nUseTRPCSuspenseQueryOptions\nType Aliases​\nCreateClient\nCreateQueryUtils\nCreateReactUtils\nDecorateQueryProcedure\nExtractCursorType\nInferMutationLikeData\nInferMutationLikeInput\nInferQueryLikeData\nInferQueryLikeInput\nMutationLike\nOutputWithCursor\nQueryLike\nRouterLike\nRouterLikeInner\nTRPCFetchInfiniteQueryOptions\nTRPCProvider\nTRPCSubscriptionResult\nUseTRPCPrefetchInfiniteQueryOptions\nUtilsLike\nVariables​\ncontextProps\nFunctions​\ngetQueryType\nTRPCContext\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/server/type-aliases/inferProcedureInput",
    "html": "API Reference (Auto-generated)\n@trpc/server\ntype-aliases\nType Alias: inferProcedureInput\\<TProcedure\\>\nVersion: 11.x\nType Alias: inferProcedureInput<TProcedure>\n\ninferProcedureInput<TProcedure>: undefined extends inferProcedureParams<TProcedure>[\"$types\"][\"input\"] ? void | inferProcedureParams<TProcedure>[\"$types\"][\"input\"] : inferProcedureParams<TProcedure>[\"$types\"][\"input\"]\n\nDefined in: procedure.ts:83\n\nType Parameters​\nType Parameter\nTProcedure extends AnyProcedure\nEdit this page"
  },
  {
    "title": "Type Alias: inferProcedureOutput\\<TProcedure\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/server/type-aliases/inferProcedureOutput",
    "html": "API Reference (Auto-generated)\n@trpc/server\ntype-aliases\nType Alias: inferProcedureOutput\\<TProcedure\\>\nVersion: 11.x\nType Alias: inferProcedureOutput<TProcedure>\n\ninferProcedureOutput<TProcedure>: inferProcedureParams<TProcedure>[\"$types\"][\"output\"]\n\nDefined in: procedure.ts:91\n\nType Parameters​\nType Parameter\nTProcedure\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/variables/contextProps",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\nvariables\nVariable: contextProps\nVersion: 11.x\nVariable: contextProps\n\nconst contextProps: keyof TRPCContextPropsBase<any, any>[]\n\nDefined in: packages/react-query/src/internals/context.tsx:118\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/classes/TRPCClientError",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nclasses\nClass: TRPCClientError\\<TRouterOrProcedure\\>\nVersion: 11.x\nClass: TRPCClientError<TRouterOrProcedure>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:97\n\nExtends​\nError\nType Parameters​\nType Parameter\nTRouterOrProcedure extends InferrableClientTypes\nImplements​\nTRPCClientErrorBase<inferErrorShape<TRouterOrProcedure>>\nConstructors​\nnew TRPCClientError()​\n\nnew TRPCClientError<TRouterOrProcedure>(message, opts?): TRPCClientError<TRouterOrProcedure>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:106\n\nParameters​\nParameter\tType\nmessage\tstring\nopts?\t{ cause: Error; meta: Record<string, unknown>; result: Maybe<TRPCErrorResponse<inferErrorShape<TRouterOrProcedure>>>; }\nopts.cause?\tError\nopts.meta?\tRecord<string, unknown>\nopts.result?\tMaybe<TRPCErrorResponse<inferErrorShape<TRouterOrProcedure>>>\nReturns​\n\nTRPCClientError<TRouterOrProcedure>\n\nOverrides​\n\nError.constructor\n\nProperties​\ncause​\n\nreadonly cause: undefined | Error\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:98\n\nOverrides​\n\nError.cause\n\ndata​\n\nreadonly data: Maybe<inferErrorShape<TRouterOrProcedure>[\"data\"]>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:100\n\nImplementation of​\n\nTRPCClientErrorBase.data\n\nmessage​\n\nmessage: string\n\nDefined in: node_modules/.pnpm/typescript@5.9.2/node_modules/typescript/lib/lib.es5.d.ts:1077\n\nImplementation of​\n\nTRPCClientErrorBase.message\n\nInherited from​\n\nError.message\n\nmeta​\n\nmeta: undefined | Record<string, unknown>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:105\n\nAdditional meta data about the error In the case of HTTP-errors, we'll have response and potentially responseJSON here\n\nname​\n\nname: string\n\nDefined in: node_modules/.pnpm/typescript@5.9.2/node_modules/typescript/lib/lib.es5.d.ts:1076\n\nInherited from​\n\nError.name\n\nshape​\n\nreadonly shape: Maybe<inferErrorShape<TRouterOrProcedure>>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:99\n\nImplementation of​\n\nTRPCClientErrorBase.shape\n\nstack?​\n\noptional stack: string\n\nDefined in: node_modules/.pnpm/typescript@5.9.2/node_modules/typescript/lib/lib.es5.d.ts:1078\n\nInherited from​\n\nError.stack\n\nstackTraceLimit​\n\nstatic stackTraceLimit: number\n\nDefined in: node_modules/.pnpm/@types+node@22.17.0/node_modules/@types/node/globals.d.ts:161\n\nThe Error.stackTraceLimit property specifies the number of stack frames collected by a stack trace (whether generated by new Error().stack or Error.captureStackTrace(obj)).\n\nThe default value is 10 but may be set to any valid JavaScript number. Changes will affect any stack trace captured after the value has been changed.\n\nIf set to a non-number value, or set to a negative number, stack traces will not capture any frames.\n\nInherited from​\n\nError.stackTraceLimit\n\nMethods​\ncaptureStackTrace()​\n\nstatic captureStackTrace(targetObject, constructorOpt?): void\n\nDefined in: node_modules/.pnpm/@types+node@22.17.0/node_modules/@types/node/globals.d.ts:145\n\nCreates a .stack property on targetObject, which when accessed returns a string representing the location in the code at which Error.captureStackTrace() was called.\n\nconst myObject = {};\nError.captureStackTrace(myObject);\nmyObject.stack;  // Similar to `new Error().stack`\nCopy\n\nThe first line of the trace will be prefixed with ${myObject.name}: ${myObject.message}.\n\nThe optional constructorOpt argument accepts a function. If given, all frames above constructorOpt, including constructorOpt, will be omitted from the generated stack trace.\n\nThe constructorOpt argument is useful for hiding implementation details of error generation from the user. For instance:\n\nfunction a() {\n  b();\n}\nfunction b() {\n  c();\n}\nfunction c() {\n  // Create an error without stack trace to avoid calculating the stack trace twice.\n  const { stackTraceLimit } = Error;\n  Error.stackTraceLimit = 0;\n  const error = new Error();\n  Error.stackTraceLimit = stackTraceLimit;\n  // Capture the stack trace above function b\n  Error.captureStackTrace(error, b); // Neither function c, nor b is included in the stack trace\n  throw error;\n}\na();\nCopy\nParameters​\nParameter\tType\ntargetObject\tobject\nconstructorOpt?\tFunction\nReturns​\n\nvoid\n\nInherited from​\n\nError.captureStackTrace\n\nfrom()​\n\nstatic from<TRouterOrProcedure>(_cause, opts?): TRPCClientError<TRouterOrProcedure>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:111\n\nType Parameters​\nType Parameter\nTRouterOrProcedure extends InferrableClientTypes\nParameters​\nParameter\tType\n_cause\tobject | Error | TRPCErrorResponse<any>\nopts?\t{ meta: Record<string, unknown>; }\nopts.meta?\tRecord<string, unknown>\nReturns​\n\nTRPCClientError<TRouterOrProcedure>\n\nprepareStackTrace()​\n\nstatic prepareStackTrace(err, stackTraces): any\n\nDefined in: node_modules/.pnpm/@types+node@22.17.0/node_modules/@types/node/globals.d.ts:149\n\nParameters​\nParameter\tType\nerr\tError\nstackTraces\tCallSite[]\nReturns​\n\nany\n\nSee​\n\nhttps://v8.dev/docs/stack-trace-api#customizing-stack-traces\n\nInherited from​\n\nError.prepareStackTrace\n\nEdit this page"
  },
  {
    "title": "Class: TRPCUntypedClient\\<TInferrable\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/classes/TRPCUntypedClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nclasses\nClass: TRPCUntypedClient\\<TInferrable\\>\nVersion: 11.x\nClass: TRPCUntypedClient<TInferrable>\n\nDefined in: packages/client/dist/index.d.mts:37\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nConstructors​\nnew TRPCUntypedClient()​\n\nnew TRPCUntypedClient<TInferrable>(opts): TRPCUntypedClient<TInferrable>\n\nDefined in: packages/client/dist/index.d.mts:41\n\nParameters​\nParameter\tType\nopts\tCreateTRPCClientOptions<TInferrable>\nReturns​\n\nTRPCUntypedClient<TInferrable>\n\nProperties​\nruntime​\n\nreadonly runtime: TRPCClientRuntime\n\nDefined in: packages/client/dist/index.d.mts:39\n\nMethods​\nmutation()​\n\nmutation(path, input?, opts?): Promise<unknown>\n\nDefined in: packages/client/dist/index.d.mts:45\n\nParameters​\nParameter\tType\npath\tstring\ninput?\tunknown\nopts?\tTRPCRequestOptions\nReturns​\n\nPromise<unknown>\n\nquery()​\n\nquery(path, input?, opts?): Promise<unknown>\n\nDefined in: packages/client/dist/index.d.mts:44\n\nParameters​\nParameter\tType\npath\tstring\ninput?\tunknown\nopts?\tTRPCRequestOptions\nReturns​\n\nPromise<unknown>\n\nsubscription()​\n\nsubscription(path, input, opts): Unsubscribable\n\nDefined in: packages/client/dist/index.d.mts:46\n\nParameters​\nParameter\tType\npath\tstring\ninput\tunknown\nopts\tPartial<TRPCSubscriptionObserver<unknown, TRPCClientError<AnyRouter>>> & TRPCRequestOptions\nReturns​\n\nUnsubscribable\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/interfaces/LoggerLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ninterfaces\nInterface: LoggerLinkOptions\\<TRouter\\>\nVersion: 11.x\nInterface: LoggerLinkOptions<TRouter>\n\nDefined in: packages/client/dist/loggerLink.d-B_ylo7O3.d.mts:31\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nProperties​\ncolorMode?​\n\noptional colorMode: ColorMode\n\nDefined in: packages/client/dist/loggerLink.d-B_ylo7O3.d.mts:42\n\nColor mode\n\nDefault​\ntypeof window === 'undefined' ? 'ansi' : 'css'\nCopy\nconsole?​\n\noptional console: ConsoleEsque\n\nDefined in: packages/client/dist/loggerLink.d-B_ylo7O3.d.mts:37\n\nUsed in the built-in defaultLogger\n\nenabled?​\n\noptional enabled: EnabledFn<TRouter>\n\nDefined in: packages/client/dist/loggerLink.d-B_ylo7O3.d.mts:33\n\nlogger?​\n\noptional logger: LoggerLinkFn<TRouter>\n\nDefined in: packages/client/dist/loggerLink.d-B_ylo7O3.d.mts:32\n\nwithContext?​\n\noptional withContext: boolean\n\nDefined in: packages/client/dist/loggerLink.d-B_ylo7O3.d.mts:46\n\nInclude context in the log - defaults to false unless colorMode is 'css'\n\nEdit this page"
  },
  {
    "title": "Interface: TRPCClientErrorBase\\<TShape\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/interfaces/TRPCClientErrorBase",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ninterfaces\nInterface: TRPCClientErrorBase\\<TShape\\>\nVersion: 11.x\nInterface: TRPCClientErrorBase<TShape>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:90\n\nType Parameters​\nType Parameter\nTShape extends DefaultErrorShape\nProperties​\ndata​\n\nreadonly data: Maybe<TShape[\"data\"]>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:93\n\nmessage​\n\nreadonly message: string\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:91\n\nshape​\n\nreadonly shape: Maybe<TShape>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:92\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/interfaces/TRPCClientRuntime",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ninterfaces\nInterface: TRPCClientRuntime\nVersion: 11.x\nInterface: TRPCClientRuntime\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:151\n\nEdit this page"
  },
  {
    "title": "Interface: TRPCProcedureOptions | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/interfaces/TRPCProcedureOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ninterfaces\nInterface: TRPCProcedureOptions\nVersion: 11.x\nInterface: TRPCProcedureOptions\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:80\n\nProperties​\ncontext?​\n\noptional context: ClientContext\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:84\n\nClient-side context\n\nsignal?​\n\noptional signal: AbortSignal\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:85\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/interfaces/TRPCRequestOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ninterfaces\nInterface: TRPCRequestOptions\nVersion: 11.x\nInterface: TRPCRequestOptions\n\nDefined in: packages/client/dist/index.d.mts:15\n\nProperties​\ncontext?​\n\noptional context: OperationContext\n\nDefined in: packages/client/dist/index.d.mts:19\n\nPass additional context to links\n\nsignal?​\n\noptional signal: AbortSignal\n\nDefined in: packages/client/dist/index.d.mts:20\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/interfaces/WebSocketClientOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ninterfaces\nInterface: WebSocketClientOptions\nVersion: 11.x\nInterface: WebSocketClientOptions\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:30\n\nExtends​\nUrlOptionsWithConnectionParams\nProperties​\nconnectionParams?​\n\noptional connectionParams: CallbackOrValue<null | Dict<string>>\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:25\n\nConnection params that are available in createContext()\n\nFor wsLink/wsClient, these are sent as the first message\nFor httpSubscriptionLink, these are serialized as part of the URL under the connectionParams query\nInherited from​\n\nUrlOptionsWithConnectionParams.connectionParams\n\nkeepAlive?​\n\noptional keepAlive: object\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:72\n\nSend ping messages to the server and kill the connection if no pong message is returned\n\nenabled​\n\nenabled: boolean\n\nDefault​\nfalse\nCopy\nintervalMs?​\n\noptional intervalMs: number\n\nSend a ping message every this many milliseconds\n\nDefault​\n5_000\nCopy\npongTimeoutMs?​\n\noptional pongTimeoutMs: number\n\nClose the WebSocket after this many milliseconds if the server does not respond\n\nDefault​\n1_000\nCopy\nlazy?​\n\noptional lazy: object\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:57\n\nLazy mode will close the WebSocket automatically after a period of inactivity (no messages sent or received and no pending requests)\n\ncloseMs​\n\ncloseMs: number\n\nClose the WebSocket after this many milliseconds\n\nDefault​\n0\nCopy\nenabled​\n\nenabled: boolean\n\nEnable lazy mode\n\nDefault​\nfalse\nCopy\nonClose()?​\n\noptional onClose: (cause?) => void\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:51\n\nTriggered when a WebSocket connection is closed\n\nParameters​\nParameter\tType\ncause?\t{ code: number; }\ncause.code?\tnumber\nReturns​\n\nvoid\n\nonError()?​\n\noptional onError: (evt?) => void\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:47\n\nTriggered when a WebSocket connection encounters an error\n\nParameters​\nParameter\tType\nevt?\tEvent\nReturns​\n\nvoid\n\nonOpen()?​\n\noptional onOpen: () => void\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:43\n\nTriggered when a WebSocket connection is established\n\nReturns​\n\nvoid\n\nretryDelayMs()?​\n\noptional retryDelayMs: (attemptIndex) => number\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:39\n\nThe number of milliseconds before a reconnect is attempted.\n\nParameters​\nParameter\tType\nattemptIndex\tnumber\nReturns​\n\nnumber\n\nDefault​\n\nexponentialBackoff\n\nurl​\n\nurl: CallbackOrValue<string>\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:19\n\nThe URL to connect to (can be a function that returns a URL)\n\nInherited from​\n\nUrlOptionsWithConnectionParams.url\n\nWebSocket()?​\n\noptional WebSocket: (url, protocols?) => WebSocket\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:34\n\nPonyfill which WebSocket implementation to use\n\nParameters​\nParameter\tType\nurl\tstring | URL\nprotocols?\tstring | string[]\nReturns​\n\nWebSocket\n\nCLOSED​\n\nreadonly CLOSED: 3\n\nCLOSING​\n\nreadonly CLOSING: 2\n\nCONNECTING​\n\nreadonly CONNECTING: 0\n\nOPEN​\n\nreadonly OPEN: 1\n\nprototype​\n\nprototype: WebSocket\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/CreateTRPCClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: ~~CreateTRPCClient\\<TRouter\\>~~\nVersion: 11.x\nType Alias: CreateTRPCClient<TRouter>\n\nCreateTRPCClient<TRouter>: TRPCClient<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:63\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nDeprecated​\n\nuse TRPCClient instead, will be removed in v12\n\nEdit this page"
  },
  {
    "title": "Type Alias: CreateTRPCReact\\<TRouter, TSSRContext\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/CreateTRPCReact",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: CreateTRPCReact\\<TRouter, TSSRContext\\>\nVersion: 11.x\nType Alias: CreateTRPCReact<TRouter, TSSRContext>\n\nCreateTRPCReact<TRouter, TSSRContext>: ProtectedIntersection<CreateTRPCReactBase<TRouter, TSSRContext>, DecorateRouterRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nDefined in: packages/react-query/src/createTRPCReact.tsx:463\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nTSSRContext\nEdit this page"
  },
  {
    "title": "Type Alias: HTTPBatchLinkOptions\\<TRoot\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/HTTPBatchLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: HTTPBatchLinkOptions\\<TRoot\\>\nVersion: 11.x\nType Alias: HTTPBatchLinkOptions<TRoot>\n\nHTTPBatchLinkOptions<TRoot>: HTTPLinkBaseOptions<TRoot> & object\n\nDefined in: packages/client/dist/httpBatchLink.d-B0jS5RCU.d.mts:7\n\nType declaration​\nheaders?​\n\noptional headers: HTTPHeaders | (opts) => HTTPHeaders | Promise<HTTPHeaders>\n\nHeaders to be set on outgoing requests or a callback that of said headers\n\nSee​\n\nhttp://trpc.io/docs/client/headers\n\nmaxItems?​\n\noptional maxItems: number\n\nMaximum number of calls in a single batch request\n\nDefault​\nInfinity\nCopy\nmaxURLLength?​\n\noptional maxURLLength: number\n\nType Parameters​\nType Parameter\nTRoot extends AnyClientTypes\nEdit this page"
  },
  {
    "title": "Type Alias: HTTPLinkOptions\\<TRoot\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/HTTPLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: HTTPLinkOptions\\<TRoot\\>\nVersion: 11.x\nType Alias: HTTPLinkOptions<TRoot>\n\nHTTPLinkOptions<TRoot>: HTTPLinkBaseOptions<TRoot> & object\n\nDefined in: packages/client/dist/httpLink.d-BEC5B7OH.d.mts:6\n\nType declaration​\nheaders?​\n\noptional headers: HTTPHeaders | (opts) => HTTPHeaders | Promise<HTTPHeaders>\n\nHeaders to be set on outgoing requests or a callback that of said headers\n\nSee​\n\nhttp://trpc.io/docs/client/headers\n\nType Parameters​\nType Parameter\nTRoot extends AnyClientTypes\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/inferReactQueryProcedureOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: inferReactQueryProcedureOptions\\<TRouter\\>\nVersion: 11.x\nType Alias: inferReactQueryProcedureOptions<TRouter>\n\ninferReactQueryProcedureOptions<TRouter>: inferReactQueryProcedureOptionsInner<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>\n\nDefined in: packages/react-query/src/utils/inferReactQueryProcedure.ts:90\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/inferRouterClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: ~~inferRouterClient\\<TRouter\\>~~\nVersion: 11.x\nType Alias: inferRouterClient<TRouter>\n\ninferRouterClient<TRouter>: TRPCClient<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:58\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nDeprecated​\n\nuse TRPCClient instead, will be removed in v12\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/LocalLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: LocalLinkOptions\\<TRouter\\>\nVersion: 11.x\nType Alias: LocalLinkOptions<TRouter>\n\nLocalLinkOptions<TRouter>: object & TransformerOptions<inferClientTypes<TRouter>>\n\nDefined in: packages/client/dist/index.d.mts:182\n\nType declaration​\ncreateContext()​\n\ncreateContext: () => Promise<inferRouterContext<TRouter>>\n\nReturns​\n\nPromise<inferRouterContext<TRouter>>\n\nonError()?​\n\noptional onError: (opts) => void\n\nParameters​\nParameter\tType\nopts\tErrorHandlerOptions<inferRouterContext<TRouter>>\nReturns​\n\nvoid\n\nrouter​\n\nrouter: TRouter\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/TRPCClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: TRPCClient\\<TRouter\\>\nVersion: 11.x\nType Alias: TRPCClient<TRouter>\n\nTRPCClient<TRouter>: DecoratedProcedureRecord<{ errorShape: TRouter[\"_def\"][\"_config\"][\"$types\"][\"errorShape\"]; transformer: TRouter[\"_def\"][\"_config\"][\"$types\"][\"transformer\"]; }, TRouter[\"_def\"][\"record\"]> & object\n\nDefined in: packages/client/dist/index.d.mts:68\n\nType declaration​\n[untypedClientSymbol]​\n\n[untypedClientSymbol]: TRPCUntypedClient<TRouter>\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/TRPCClientErrorLike",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: TRPCClientErrorLike\\<TInferrable\\>\nVersion: 11.x\nType Alias: TRPCClientErrorLike<TInferrable>\n\nTRPCClientErrorLike<TInferrable>: TRPCClientErrorBase<inferErrorShape<TInferrable>>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:95\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/TRPCFetch",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: TRPCFetch()\nVersion: 11.x\nType Alias: TRPCFetch()\n\nTRPCFetch: (url, options?) => Promise<ResponseEsque>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:150\n\nThe default fetch implementation has an overloaded signature. By convention this library only uses the overload taking a string and options object.\n\nParameters​\nParameter\tType\nurl\tstring\noptions?\tRequestInit\nReturns​\n\nPromise<ResponseEsque>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/TRPCLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: TRPCLink()\\<TInferrable\\>\nVersion: 11.x\nType Alias: TRPCLink()<TInferrable>\n\nTRPCLink<TInferrable>: (opts) => OperationLink<TInferrable>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:177\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nParameters​\nParameter\tType\nopts\tTRPCClientRuntime\nReturns​\n\nOperationLink<TInferrable>\n\nEdit this page"
  },
  {
    "title": "Type Alias: TRPCWebSocketClient | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/TRPCWebSocketClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: TRPCWebSocketClient\nVersion: 11.x\nType Alias: TRPCWebSocketClient\n\nTRPCWebSocketClient: ReturnType<typeof createWSClient>\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:185\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/type-aliases/WebSocketLinkOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\ntype-aliases\nType Alias: WebSocketLinkOptions\\<TRouter\\>\nVersion: 11.x\nType Alias: WebSocketLinkOptions<TRouter>\n\nWebSocketLinkOptions<TRouter>: object & TransformerOptions<inferClientTypes<TRouter>>\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:188\n\nType declaration​\nclient​\n\nclient: TRPCWebSocketClient\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "Function: createTRPCClient() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/createTRPCClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: createTRPCClient()\nVersion: 11.x\nFunction: createTRPCClient()\n\ncreateTRPCClient<TRouter>(opts): TRPCClient<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:106\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tCreateTRPCClientOptions<TRouter>\nReturns​\n\nTRPCClient<TRouter>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/createTRPCQueryUtils",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: createTRPCQueryUtils()\nVersion: 11.x\nFunction: createTRPCQueryUtils()\n\ncreateTRPCQueryUtils<TRouter>(opts): CreateQueryUtils<TRouter>\n\nDefined in: packages/react-query/src/createTRPCQueryUtils.tsx:6\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tCreateQueryUtilsOptions<TRouter>\nReturns​\n\nCreateQueryUtils<TRouter>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/createTRPCReact",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: createTRPCReact()\nVersion: 11.x\nFunction: createTRPCReact()\n\ncreateTRPCReact<TRouter, TSSRContext>(opts?): ProtectedIntersection<CreateTRPCReactBase<TRouter, TSSRContext>, DecorateRouterRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nDefined in: packages/react-query/src/createTRPCReact.tsx:508\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\t-\nTSSRContext\tunknown\nParameters​\nParameter\tType\nopts?\tCreateTRPCReactOptions<TRouter>\nReturns​\n\nProtectedIntersection<CreateTRPCReactBase<TRouter, TSSRContext>, DecorateRouterRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/createTRPCUntypedClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: createTRPCUntypedClient()\nVersion: 11.x\nFunction: createTRPCUntypedClient()\n\ncreateTRPCUntypedClient<TRouter>(opts): TRPCUntypedClient<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:51\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tCreateTRPCClientOptions<TRouter>\nReturns​\n\nTRPCUntypedClient<TRouter>\n\nEdit this page"
  },
  {
    "title": "Function: createWSClient() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/createWSClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: createWSClient()\nVersion: 11.x\nFunction: createWSClient()\n\ncreateWSClient(opts): WsClient\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:184\n\nParameters​\nParameter\tType\nopts\tWebSocketClientOptions\nReturns​\n\nWsClient\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/experimental_localLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: ~~experimental\\_localLink()~~\nVersion: 11.x\nFunction: experimental_localLink()\n\nexperimental_localLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:196\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tLocalLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nDeprecated​\n\nRenamed to unstable_localLink. This alias will be removed in a future major release.\n\nSee​\n\nhttps://trpc.io/docs/links/localLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/getFetch",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: getFetch()\nVersion: 11.x\nFunction: getFetch()\n\ngetFetch(customFetchImpl?): FetchEsque\n\nDefined in: packages/client/dist/index.d.mts:114\n\nParameters​\nParameter\tType\ncustomFetchImpl?\tFetchEsque | NativeFetchEsque\nReturns​\n\nFetchEsque\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/getMutationKey",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: getMutationKey()\nVersion: 11.x\nFunction: getMutationKey()\n\ngetMutationKey<TProcedure>(procedure): TRPCMutationKey\n\nDefined in: packages/react-query/src/internals/getQueryKey.ts:132\n\nMethod to extract the mutation key for a procedure\n\nType Parameters​\nType Parameter\nTProcedure extends DecoratedMutation<any>\nParameters​\nParameter\tType\tDescription\nprocedure\tTProcedure\tprocedure\nReturns​\n\nTRPCMutationKey\n\nSee​\n\nhttps://trpc.io/docs/v11/getQueryKey#mutations\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/getQueryKey",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: getQueryKey()\nVersion: 11.x\nFunction: getQueryKey()\n\ngetQueryKey<TProcedureOrRouter>(procedureOrRouter, ..._params): TRPCQueryKey\n\nDefined in: packages/react-query/src/internals/getQueryKey.ts:109\n\nMethod to extract the query key for a procedure\n\nType Parameters​\nType Parameter\nTProcedureOrRouter extends ProcedureOrRouter\nParameters​\nParameter\tType\tDescription\nprocedureOrRouter\tTProcedureOrRouter\tprocedure or AnyRouter\n..._params\tGetParams<TProcedureOrRouter>\t-\nReturns​\n\nTRPCQueryKey\n\nSee​\n\nhttps://trpc.io/docs/v11/getQueryKey\n\nEdit this page"
  },
  {
    "title": "Function: httpBatchLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/httpBatchLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: httpBatchLink()\nVersion: 11.x\nFunction: httpBatchLink()\n\nhttpBatchLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/httpBatchLink.d-B0jS5RCU.d.mts:28\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tHTTPBatchLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpBatchLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/httpBatchStreamLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: httpBatchStreamLink()\nVersion: 11.x\nFunction: httpBatchStreamLink()\n\nhttpBatchStreamLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:122\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tHTTPBatchLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpBatchStreamLink\n\nEdit this page"
  },
  {
    "title": "Function: httpLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/httpLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: httpLink()\nVersion: 11.x\nFunction: httpLink()\n\nhttpLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/httpLink.d-BEC5B7OH.d.mts:18\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\tAnyRouter\nParameters​\nParameter\tType\nopts\tHTTPLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpLink\n\nEdit this page"
  },
  {
    "title": "Function: httpSubscriptionLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/httpSubscriptionLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: httpSubscriptionLink()\nVersion: 11.x\nFunction: httpSubscriptionLink()\n\nhttpSubscriptionLink<TInferrable, TEventSource>(opts): TRPCLink<TInferrable>\n\nDefined in: packages/client/dist/index.d.mts:145\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nTEventSource extends AnyConstructor\nParameters​\nParameter\tType\nopts\tHTTPSubscriptionLinkOptions<inferClientTypes<TInferrable>, TEventSource>\nReturns​\n\nTRPCLink<TInferrable>\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpSubscriptionLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/isFormData",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: isFormData()\nVersion: 11.x\nFunction: isFormData()\n\nisFormData(input): input is FormData\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:118\n\nParameters​\nParameter\tType\ninput\tunknown\nReturns​\n\ninput is FormData\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/isNonJsonSerializable",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: isNonJsonSerializable()\nVersion: 11.x\nFunction: isNonJsonSerializable()\n\nisNonJsonSerializable(input): input is FormData | Blob | Uint8Array<ArrayBuffer>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:119\n\nParameters​\nParameter\tType\ninput\tunknown\nReturns​\n\ninput is FormData | Blob | Uint8Array<ArrayBuffer>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/isOctetType",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: isOctetType()\nVersion: 11.x\nFunction: isOctetType()\n\nisOctetType(input): input is Blob | Uint8Array<ArrayBuffer>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:117\n\nParameters​\nParameter\tType\ninput\tunknown\nReturns​\n\ninput is Blob | Uint8Array<ArrayBuffer>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/isTRPCClientError",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: isTRPCClientError()\nVersion: 11.x\nFunction: isTRPCClientError()\n\nisTRPCClientError<TInferrable>(cause): cause is TRPCClientError<TInferrable>\n\nDefined in: packages/client/dist/types.d-CAt1zKAY.d.mts:96\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nParameters​\nParameter\tType\ncause\tunknown\nReturns​\n\ncause is TRPCClientError<TInferrable>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/loggerLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: loggerLink()\nVersion: 11.x\nFunction: loggerLink()\n\nloggerLink<TRouter>(opts?): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/loggerLink.d-B_ylo7O3.d.mts:51\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\tAnyRouter\nParameters​\nParameter\tType\nopts?\tLoggerLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/v11/client/links/loggerLink\n\nEdit this page"
  },
  {
    "title": "Function: retryLink() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/retryLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: retryLink()\nVersion: 11.x\nFunction: retryLink()\n\nretryLink<TInferrable>(opts): TRPCLink<TInferrable>\n\nDefined in: packages/client/dist/index.d.mts:179\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nParameters​\nParameter\tType\nopts\tRetryLinkOptions<TInferrable>\nReturns​\n\nTRPCLink<TInferrable>\n\nSee​\n\nhttps://trpc.io/docs/v11/client/links/retryLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/splitLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: splitLink()\nVersion: 11.x\nFunction: splitLink()\n\nsplitLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/splitLink.d-Df2gT0RV.d.mts:5\n\nType Parameters​\nType Parameter\tDefault type\nTRouter extends AnyRouter\tAnyRouter\nParameters​\nParameter\tType\tDescription\nopts\t{ condition: (op) => boolean; false: TRPCLink<TRouter> | TRPCLink<TRouter>[]; true: TRPCLink<TRouter> | TRPCLink<TRouter>[]; }\t-\nopts.condition\t(op) => boolean\t-\nopts.false\tTRPCLink<TRouter> | TRPCLink<TRouter>[]\tThe link to execute next if the test function returns false.\nopts.true\tTRPCLink<TRouter> | TRPCLink<TRouter>[]\tThe link to execute next if the test function returns true.\nReturns​\n\nTRPCLink<TRouter>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/unstable_httpBatchStreamLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: ~~unstable\\_httpBatchStreamLink()~~\nVersion: 11.x\nFunction: unstable_httpBatchStreamLink()\n\nunstable_httpBatchStreamLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:126\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tHTTPBatchLinkOptions<TRouter[\"_def\"][\"_config\"][\"$types\"]>\nReturns​\n\nTRPCLink<TRouter>\n\nDeprecated​\n\nuse httpBatchStreamLink instead\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpBatchStreamLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/unstable_httpSubscriptionLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: ~~unstable\\_httpSubscriptionLink()~~\nVersion: 11.x\nFunction: unstable_httpSubscriptionLink()\n\nunstable_httpSubscriptionLink<TInferrable, TEventSource>(opts): TRPCLink<TInferrable>\n\nDefined in: packages/client/dist/index.d.mts:149\n\nType Parameters​\nType Parameter\nTInferrable extends InferrableClientTypes\nTEventSource extends AnyConstructor\nParameters​\nParameter\tType\nopts\tHTTPSubscriptionLinkOptions<inferClientTypes<TInferrable>, TEventSource>\nReturns​\n\nTRPCLink<TInferrable>\n\nDeprecated​\n\nuse httpSubscriptionLink instead\n\nSee​\n\nhttps://trpc.io/docs/client/links/httpSubscriptionLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/unstable_localLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: unstable\\_localLink()\nVersion: 11.x\nFunction: unstable_localLink()\n\nunstable_localLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/index.d.mts:192\n\nlocalLink is a terminating link that allows you to make tRPC procedure calls directly in your application without going through HTTP.\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tLocalLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nSee​\n\nhttps://trpc.io/docs/links/localLink\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/index/functions/wsLink",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nindex\nfunctions\nFunction: wsLink()\nVersion: 11.x\nFunction: wsLink()\n\nwsLink<TRouter>(opts): TRPCLink<TRouter>\n\nDefined in: packages/client/dist/wsLink.d-Bssh2HIQ.d.mts:191\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tWebSocketLinkOptions<TRouter>\nReturns​\n\nTRPCLink<TRouter>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/server/functions/createServerSideHelpers",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nserver\nfunctions\nFunction: createServerSideHelpers()\nVersion: 11.x\nFunction: createServerSideHelpers()\n\ncreateServerSideHelpers<TRouter>(opts): ProtectedIntersection<{ dehydrate: (opts?) => DehydratedState; queryClient: QueryClient; }, DecoratedProcedureSSGRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nDefined in: packages/react-query/src/server/ssgProxy.ts:82\n\nCreate functions you can use for server-side rendering / static generation\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tCreateServerSideHelpersOptions<TRouter>\nReturns​\n\nProtectedIntersection<{ dehydrate: (opts?) => DehydratedState; queryClient: QueryClient; }, DecoratedProcedureSSGRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nSee​\n\nhttps://trpc.io/docs/v11/client/nextjs/server-side-helpers\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/DefinedTRPCInfiniteQueryOptionsIn",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: DefinedTRPCInfiniteQueryOptionsIn\\<TInput, TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: DefinedTRPCInfiniteQueryOptionsIn<TInput, TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:154\n\nExtends​\nDistributiveOmit<DefinedInitialDataInfiniteOptions<TQueryFnData, TError, InfiniteData<TData, NonNullable<ExtractCursorType<TInput>> | null>, TRPCQueryKey, NonNullable<ExtractCursorType<TInput>> | null>, TRPCInfiniteOptionOverrides>.TRPCQueryBaseOptions\nType Parameters​\nType Parameter\nTInput\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialCursor?​\n\noptional initialCursor: null | NonNullable<ExtractCursorType<TInput>>\n\nDefined in: packages/react-query/src/shared/types.ts:170\n\ninitialData​\n\ninitialData: undefined | (InfiniteData<TQueryFnData, NonNullable<ExtractCursorType<TInput>> | null> | InitialDataFunction<InfiniteData<TQueryFnData, NonNullable<...> | null>>) & (InfiniteData<...> | (() => InfiniteData<...>))\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TQueryFnData>, TRPCQueryKey, NoInfer<null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | PlaceholderDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => InfiniteData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nInfiniteData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/types.ts:25\n\ntRPC-related options\n\nInherited from​\n\nTRPCQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/DefinedTRPCInfiniteQueryOptionsOut",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: DefinedTRPCInfiniteQueryOptionsOut\\<TInput, TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: DefinedTRPCInfiniteQueryOptionsOut<TInput, TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:173\n\nExtends​\nDistributiveOmit<DefinedInitialDataInfiniteOptions<TQueryFnData, TError, InfiniteData<TData, NonNullable<ExtractCursorType<TInput>> | null>, TRPCQueryKey, NonNullable<ExtractCursorType<TInput>> | null>, \"initialPageParam\">.TRPCQueryOptionsResult\nType Parameters​\nType Parameter\nTInput\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialData​\n\ninitialData: undefined | (InfiniteData<TQueryFnData, NonNullable<ExtractCursorType<TInput>> | null> | InitialDataFunction<InfiniteData<TQueryFnData, NonNullable<...> | null>>) & (InfiniteData<...> | (() => InfiniteData<...>))\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\ninitialPageParam​\n\ninitialPageParam: null | NonNullable<ExtractCursorType<TInput>>\n\nDefined in: packages/react-query/src/shared/types.ts:190\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TQueryFnData>, TRPCQueryKey, NoInfer<null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | PlaceholderDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<TQueryFnData, TRPCQueryKey, null | NonNullable<ExtractCursorType<TInput>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKey​\n\nqueryKey: TRPCQueryKey & object\n\nDefined in: packages/react-query/src/shared/types.ts:189\n\nType declaration​\n[dataTagErrorSymbol]​\n\n[dataTagErrorSymbol]: TError\n\n[dataTagSymbol]​\n\n[dataTagSymbol]: TData\n\nOverrides​\n\nDistributiveOmit.queryKey\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => InfiniteData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nInfiniteData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/types.ts:29\n\npath​\n\npath: string\n\nInherited from​\n\nTRPCQueryOptionsResult.trpc\n\nEdit this page"
  },
  {
    "title": "Interface: DefinedTRPCQueryOptionsIn\\<TQueryFnData, TData, TError\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/DefinedTRPCQueryOptionsIn",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: DefinedTRPCQueryOptionsIn\\<TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: DefinedTRPCQueryOptionsIn<TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:63\n\nExtends​\nDistributiveOmit<DefinedInitialDataOptions<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TData>, TRPCQueryKey>, TRPCOptionOverrides>.TRPCQueryBaseOptions\nType Parameters​\nType Parameter\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData​\n\ninitialData: undefined | coerceAsyncIterableToArray<TQueryFnData> | InitialDataFunction<coerceAsyncIterableToArray<TQueryFnData>> & NonUndefinedGuard<coerceAsyncIterableToArray<TQueryFnData>> | () => NonUndefinedGuard<coerceAsyncIterableToArray<TQueryFnData>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: TRPCQueryKey; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tTRPCQueryKey\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>> | PlaceholderDataFunction<NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TError, NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => coerceAsyncIterableToArray\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tcoerceAsyncIterableToArray\nReturns​\n\ncoerceAsyncIterableToArray\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/types.ts:25\n\ntRPC-related options\n\nInherited from​\n\nTRPCQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/DefinedTRPCQueryOptionsOut",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: DefinedTRPCQueryOptionsOut\\<TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: DefinedTRPCQueryOptionsOut<TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:75\n\nExtends​\nDefinedInitialDataOptions<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TData>, TRPCQueryKey>.TRPCQueryOptionsResult\nType Parameters​\nType Parameter\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDefinedInitialDataOptions._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDefinedInitialDataOptions._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDefinedInitialDataOptions.behavior\n\nenabled?​\n\noptional enabled: Enabled<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDefinedInitialDataOptions.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDefinedInitialDataOptions.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDefinedInitialDataOptions.gcTime\n\ninitialData​\n\ninitialData: undefined | coerceAsyncIterableToArray<TQueryFnData> | InitialDataFunction<coerceAsyncIterableToArray<TQueryFnData>> & NonUndefinedGuard<coerceAsyncIterableToArray<TQueryFnData>> | () => NonUndefinedGuard<coerceAsyncIterableToArray<TQueryFnData>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDefinedInitialDataOptions.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDefinedInitialDataOptions.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDefinedInitialDataOptions.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDefinedInitialDataOptions.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDefinedInitialDataOptions.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDefinedInitialDataOptions.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: TRPCQueryKey; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tTRPCQueryKey\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nInherited from​\n\nDefinedInitialDataOptions.persister\n\nplaceholderData?​\n\noptional placeholderData: NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>> | PlaceholderDataFunction<NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TError, NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDefinedInitialDataOptions.placeholderData\n\nqueryFn?​\n\noptional queryFn: QueryFunction<coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/queryOptions.d.ts:12\n\nInherited from​\n\nDefinedInitialDataOptions.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDefinedInitialDataOptions.queryHash\n\nqueryKey​\n\nqueryKey: TRPCQueryKey & object\n\nDefined in: packages/react-query/src/shared/types.ts:83\n\nType declaration​\n[dataTagErrorSymbol]​\n\n[dataTagErrorSymbol]: TError\n\n[dataTagSymbol]​\n\n[dataTagSymbol]: coerceAsyncIterableToArray\n\nOverrides​\n\nDefinedInitialDataOptions.queryKey\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDefinedInitialDataOptions.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDefinedInitialDataOptions.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDefinedInitialDataOptions.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDefinedInitialDataOptions.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDefinedInitialDataOptions.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDefinedInitialDataOptions.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDefinedInitialDataOptions.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDefinedInitialDataOptions.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDefinedInitialDataOptions.retryOnMount\n\nselect()?​\n\noptional select: (data) => coerceAsyncIterableToArray\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tcoerceAsyncIterableToArray\nReturns​\n\ncoerceAsyncIterableToArray\n\nInherited from​\n\nDefinedInitialDataOptions.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDefinedInitialDataOptions.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDefinedInitialDataOptions.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDefinedInitialDataOptions.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDefinedInitialDataOptions.throwOnError\n\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/types.ts:29\n\npath​\n\npath: string\n\nInherited from​\n\nTRPCQueryOptionsResult.trpc\n\nEdit this page"
  },
  {
    "title": "Interface: TRPCContextProps\\<TRouter, TSSRContext\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCContextProps",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCContextProps\\<TRouter, TSSRContext\\>\nVersion: 11.x\nInterface: TRPCContextProps<TRouter, TSSRContext>\n\nDefined in: packages/react-query/src/internals/context.tsx:110\n\nExtends​\nTRPCContextPropsBase<TRouter, TSSRContext>\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nTSSRContext\nProperties​\nabortOnUnmount?​\n\noptional abortOnUnmount: boolean\n\nDefined in: packages/react-query/src/internals/context.tsx:97\n\nDeprecated​\n\npass abortOnUnmount to createTRPCReact instead Abort loading query calls when unmounting a component - usually when navigating to a new page\n\nDefault​\nfalse\nCopy\nInherited from​\n\nTRPCContextPropsBase.abortOnUnmount\n\nclient​\n\nclient: TRPCUntypedClient<TRouter>\n\nDefined in: packages/react-query/src/internals/context.tsx:77\n\nThe TRPCClient\n\nInherited from​\n\nTRPCContextPropsBase.client\n\nqueryClient​\n\nqueryClient: QueryClient\n\nDefined in: packages/react-query/src/internals/context.tsx:115\n\nThe react-query QueryClient\n\nssrContext?​\n\noptional ssrContext: null | TSSRContext\n\nDefined in: packages/react-query/src/internals/context.tsx:82\n\nThe SSR context when server-side rendering\n\nDefault​\nnull\nCopy\nInherited from​\n\nTRPCContextPropsBase.ssrContext\n\nssrState?​\n\noptional ssrState: SSRState\n\nDefined in: packages/react-query/src/internals/context.tsx:91\n\nState of SSR hydration.\n\nfalse if not using SSR.\nprepass when doing a prepass to fetch queries' data\nmounting before TRPCProvider has been rendered on the client\nmounted when the TRPCProvider has been rendered on the client\nDefault​\nfalse\nCopy\nInherited from​\n\nTRPCContextPropsBase.ssrState\n\nEdit this page"
  },
  {
    "title": "Interface: TRPCContextPropsBase\\<TRouter, TSSRContext\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCContextPropsBase",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCContextPropsBase\\<TRouter, TSSRContext\\>\nVersion: 11.x\nInterface: TRPCContextPropsBase<TRouter, TSSRContext>\n\nDefined in: packages/react-query/src/internals/context.tsx:73\n\nExtended by​\nTRPCContextProps\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nTSSRContext\nProperties​\nabortOnUnmount?​\n\noptional abortOnUnmount: boolean\n\nDefined in: packages/react-query/src/internals/context.tsx:97\n\nDeprecated​\n\npass abortOnUnmount to createTRPCReact instead Abort loading query calls when unmounting a component - usually when navigating to a new page\n\nDefault​\nfalse\nCopy\nclient​\n\nclient: TRPCUntypedClient<TRouter>\n\nDefined in: packages/react-query/src/internals/context.tsx:77\n\nThe TRPCClient\n\nssrContext?​\n\noptional ssrContext: null | TSSRContext\n\nDefined in: packages/react-query/src/internals/context.tsx:82\n\nThe SSR context when server-side rendering\n\nDefault​\nnull\nCopy\nssrState?​\n\noptional ssrState: SSRState\n\nDefined in: packages/react-query/src/internals/context.tsx:91\n\nState of SSR hydration.\n\nfalse if not using SSR.\nprepass when doing a prepass to fetch queries' data\nmounting before TRPCProvider has been rendered on the client\nmounted when the TRPCProvider has been rendered on the client\nDefault​\nfalse\nCopy\nEdit this page"
  },
  {
    "title": "Interface: TRPCFetchQueryOptions\\<TOutput, TError\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCFetchQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCFetchQueryOptions\\<TOutput, TError\\>\nVersion: 11.x\nInterface: TRPCFetchQueryOptions<TOutput, TError>\n\nDefined in: packages/react-query/src/internals/context.tsx:49\n\nExtends​\nDistributiveOmit<FetchQueryOptions<TOutput, TError>, \"queryKey\">.TRPCUseUtilsOptions\nType Parameters​\nType Parameter\nTOutput\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\nbehavior?​\n\noptional behavior: QueryBehavior<TOutput, TError, TOutput, readonly unknown[]>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData?​\n\noptional initialData: TOutput | InitialDataFunction<TOutput>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\ninitialPageParam?​\n\noptional initialPageParam: undefined\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:746\n\nInherited from​\n\nDistributiveOmit.initialPageParam\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<TOutput>, readonly unknown[], never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: readonly unknown[]; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\treadonly unknown[]\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<TOutput, readonly unknown[], never>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<readonly unknown[]>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TOutput, TError, TOutput, readonly unknown[]>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:751\n\nThe time in milliseconds after data is considered stale. If the data is fresh it will be returned from the cache.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\ntrpc?​\n\noptional trpc: TRPCRequestOptions\n\nDefined in: packages/react-query/src/internals/context.tsx:47\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseUtilsOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCHookResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCHookResult\nVersion: 11.x\nInterface: TRPCHookResult\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:311\n\nProperties​\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:312\n\npath​\n\npath: string\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCProviderProps",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCProviderProps\\<TRouter, TSSRContext\\>\nVersion: 11.x\nInterface: TRPCProviderProps<TRouter, TSSRContext>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:231\n\nExtends​\nOmit<TRPCContextProps<TRouter, TSSRContext>, \"client\">\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nTSSRContext\nProperties​\nabortOnUnmount?​\n\noptional abortOnUnmount: boolean\n\nDefined in: packages/react-query/src/internals/context.tsx:97\n\nDeprecated​\n\npass abortOnUnmount to createTRPCReact instead Abort loading query calls when unmounting a component - usually when navigating to a new page\n\nDefault​\nfalse\nCopy\nInherited from​\n\nOmit.abortOnUnmount\n\nchildren​\n\nchildren: ReactNode\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:233\n\nclient​\n\nclient: TRPCClient<TRouter> | TRPCUntypedClient<TRouter>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:234\n\nqueryClient​\n\nqueryClient: QueryClient\n\nDefined in: packages/react-query/src/internals/context.tsx:115\n\nThe react-query QueryClient\n\nInherited from​\n\nOmit.queryClient\n\nssrContext?​\n\noptional ssrContext: null | TSSRContext\n\nDefined in: packages/react-query/src/internals/context.tsx:82\n\nThe SSR context when server-side rendering\n\nDefault​\nnull\nCopy\nInherited from​\n\nOmit.ssrContext\n\nssrState?​\n\noptional ssrState: SSRState\n\nDefined in: packages/react-query/src/internals/context.tsx:91\n\nState of SSR hydration.\n\nfalse if not using SSR.\nprepass when doing a prepass to fetch queries' data\nmounting before TRPCProvider has been rendered on the client\nmounted when the TRPCProvider has been rendered on the client\nDefault​\nfalse\nCopy\nInherited from​\n\nOmit.ssrState\n\nEdit this page"
  },
  {
    "title": "Interface: TRPCQueryBaseOptions | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCQueryBaseOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCQueryBaseOptions\nVersion: 11.x\nInterface: TRPCQueryBaseOptions\n\nDefined in: packages/react-query/src/shared/types.ts:21\n\nExtended by​\nUndefinedTRPCQueryOptionsIn\nDefinedTRPCQueryOptionsIn\nUnusedSkipTokenTRPCQueryOptionsIn\nUndefinedTRPCInfiniteQueryOptionsIn\nDefinedTRPCInfiniteQueryOptionsIn\nUnusedSkipTokenTRPCInfiniteQueryOptionsIn\nProperties​\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/types.ts:25\n\ntRPC-related options\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCQueryOptions\\<TData, TError\\>\nVersion: 11.x\nInterface: TRPCQueryOptions<TData, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:99\n\nExtends​\nDistributiveOmit<QueryOptions<TData, TError, TData, any>, \"queryKey\">.TRPCUseQueryBaseOptions\nType Parameters​\nType Parameter\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\nbehavior?​\n\noptional behavior: QueryBehavior<TData, TError, TData, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData?​\n\noptional initialData: TData | InitialDataFunction<TData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<TData> | Promise<NoInfer<TData>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<TData>, any, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: any; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tany\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<TData> | Promise<NoInfer<TData>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<TData, any, never>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKey​\n\nqueryKey: TRPCQueryKey\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:102\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCQueryOptionsResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCQueryOptionsResult\nVersion: 11.x\nInterface: TRPCQueryOptionsResult\n\nDefined in: packages/react-query/src/shared/types.ts:28\n\nExtended by​\nUndefinedTRPCQueryOptionsOut\nDefinedTRPCQueryOptionsOut\nUnusedSkipTokenTRPCQueryOptionsOut\nUndefinedTRPCInfiniteQueryOptionsOut\nDefinedTRPCInfiniteQueryOptionsOut\nUnusedSkipTokenTRPCInfiniteQueryOptionsOut\nProperties​\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/types.ts:29\n\npath​\n\npath: string\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCReactRequestOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCReactRequestOptions\nVersion: 11.x\nInterface: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:41\n\nExtends​\nOmit<TRPCRequestOptions, \"signal\">\nProperties​\nabortOnUnmount?​\n\noptional abortOnUnmount: boolean\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:51\n\nOpt out or into aborting request on unmount\n\ncontext?​\n\noptional context: OperationContext\n\nDefined in: packages/client/dist/index.d.mts:19\n\nPass additional context to links\n\nInherited from​\n\nOmit.context\n\nssr?​\n\noptional ssr: boolean\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:47\n\nOpt out of SSR for this query by passing ssr: false\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCSubscriptionBaseResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCSubscriptionBaseResult\\<TOutput, TError\\>\nVersion: 11.x\nInterface: TRPCSubscriptionBaseResult<TOutput, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:187\n\nExtended by​\nTRPCSubscriptionIdleResult\nTRPCSubscriptionConnectingResult\nTRPCSubscriptionPendingResult\nTRPCSubscriptionErrorResult\nType Parameters​\nType Parameter\nTOutput\nTError\nProperties​\ndata​\n\ndata: undefined | TOutput\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:189\n\nerror​\n\nerror: null | TError\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:190\n\nreset()​\n\nreset: () => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:194\n\nReset the subscription\n\nReturns​\n\nvoid\n\nstatus​\n\nstatus: \"error\" | \"idle\" | \"connecting\" | \"pending\"\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:188\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCSubscriptionConnectingResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCSubscriptionConnectingResult\\<TOutput, TError\\>\nVersion: 11.x\nInterface: TRPCSubscriptionConnectingResult<TOutput, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:204\n\nExtends​\nTRPCSubscriptionBaseResult<TOutput, TError>\nType Parameters​\nType Parameter\nTOutput\nTError\nProperties​\ndata​\n\ndata: undefined | TOutput\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:207\n\nOverrides​\n\nTRPCSubscriptionBaseResult.data\n\nerror​\n\nerror: null | TError\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:208\n\nOverrides​\n\nTRPCSubscriptionBaseResult.error\n\nreset()​\n\nreset: () => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:194\n\nReset the subscription\n\nReturns​\n\nvoid\n\nInherited from​\n\nTRPCSubscriptionBaseResult.reset\n\nstatus​\n\nstatus: \"connecting\"\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:206\n\nOverrides​\n\nTRPCSubscriptionBaseResult.status\n\nEdit this page"
  },
  {
    "title": "Interface: TRPCSubscriptionErrorResult\\<TOutput, TError\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCSubscriptionErrorResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCSubscriptionErrorResult\\<TOutput, TError\\>\nVersion: 11.x\nInterface: TRPCSubscriptionErrorResult<TOutput, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:218\n\nExtends​\nTRPCSubscriptionBaseResult<TOutput, TError>\nType Parameters​\nType Parameter\nTOutput\nTError\nProperties​\ndata​\n\ndata: undefined | TOutput\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:221\n\nOverrides​\n\nTRPCSubscriptionBaseResult.data\n\nerror​\n\nerror: TError\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:222\n\nOverrides​\n\nTRPCSubscriptionBaseResult.error\n\nreset()​\n\nreset: () => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:194\n\nReset the subscription\n\nReturns​\n\nvoid\n\nInherited from​\n\nTRPCSubscriptionBaseResult.reset\n\nstatus​\n\nstatus: \"error\"\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:220\n\nOverrides​\n\nTRPCSubscriptionBaseResult.status\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCSubscriptionIdleResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCSubscriptionIdleResult\\<TOutput\\>\nVersion: 11.x\nInterface: TRPCSubscriptionIdleResult<TOutput>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:197\n\nExtends​\nTRPCSubscriptionBaseResult<TOutput, null>\nType Parameters​\nType Parameter\nTOutput\nProperties​\ndata​\n\ndata: undefined\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:200\n\nOverrides​\n\nTRPCSubscriptionBaseResult.data\n\nerror​\n\nerror: null\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:201\n\nOverrides​\n\nTRPCSubscriptionBaseResult.error\n\nreset()​\n\nreset: () => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:194\n\nReset the subscription\n\nReturns​\n\nvoid\n\nInherited from​\n\nTRPCSubscriptionBaseResult.reset\n\nstatus​\n\nstatus: \"idle\"\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:199\n\nOverrides​\n\nTRPCSubscriptionBaseResult.status\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCSubscriptionPendingResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCSubscriptionPendingResult\\<TOutput\\>\nVersion: 11.x\nInterface: TRPCSubscriptionPendingResult<TOutput>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:211\n\nExtends​\nTRPCSubscriptionBaseResult<TOutput, undefined>\nType Parameters​\nType Parameter\nTOutput\nProperties​\ndata​\n\ndata: undefined | TOutput\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:214\n\nOverrides​\n\nTRPCSubscriptionBaseResult.data\n\nerror​\n\nerror: null\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:215\n\nOverrides​\n\nTRPCSubscriptionBaseResult.error\n\nreset()​\n\nreset: () => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:194\n\nReset the subscription\n\nReturns​\n\nvoid\n\nInherited from​\n\nTRPCSubscriptionBaseResult.reset\n\nstatus​\n\nstatus: \"pending\"\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:213\n\nOverrides​\n\nTRPCSubscriptionBaseResult.status\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/TRPCUseQueryBaseOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: TRPCUseQueryBaseOptions\nVersion: 11.x\nInterface: TRPCUseQueryBaseOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:54\n\nExtended by​\nUseTRPCQueryOptions\nUseTRPCSuspenseQueryOptions\nUseTRPCPrefetchQueryOptions\nTRPCQueryOptions\nUseTRPCInfiniteQueryOptions\nUseTRPCSuspenseInfiniteQueryOptions\nUseTRPCMutationOptions\nProperties​\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UndefinedTRPCInfiniteQueryOptionsIn",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UndefinedTRPCInfiniteQueryOptionsIn\\<TInput, TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: UndefinedTRPCInfiniteQueryOptionsIn<TInput, TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:115\n\nInifiniteQueryOptions helpers\n\nExtends​\nDistributiveOmit<UndefinedInitialDataInfiniteOptions<TQueryFnData, TError, InfiniteData<TData, NonNullable<ExtractCursorType<TInput>> | null>, TRPCQueryKey, NonNullable<ExtractCursorType<TInput>> | null>, TRPCInfiniteOptionOverrides>.TRPCQueryBaseOptions\nType Parameters​\nType Parameter\nTInput\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialCursor?​\n\noptional initialCursor: null | NonNullable<ExtractCursorType<TInput>>\n\nDefined in: packages/react-query/src/shared/types.ts:131\n\ninitialData?​\n\noptional initialData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | InitialDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TQueryFnData>, TRPCQueryKey, NoInfer<null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | PlaceholderDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => InfiniteData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nInfiniteData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/types.ts:25\n\ntRPC-related options\n\nInherited from​\n\nTRPCQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UndefinedTRPCInfiniteQueryOptionsOut",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UndefinedTRPCInfiniteQueryOptionsOut\\<TInput, TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: UndefinedTRPCInfiniteQueryOptionsOut<TInput, TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:134\n\nExtends​\nDistributiveOmit<UndefinedInitialDataInfiniteOptions<TQueryFnData, TError, InfiniteData<TData, NonNullable<ExtractCursorType<TInput>> | null>, TRPCQueryKey, NonNullable<ExtractCursorType<TInput>> | null>, \"initialPageParam\">.TRPCQueryOptionsResult\nType Parameters​\nType Parameter\nTInput\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialData?​\n\noptional initialData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | InitialDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\ninitialPageParam​\n\ninitialPageParam: null | NonNullable<ExtractCursorType<TInput>>\n\nDefined in: packages/react-query/src/shared/types.ts:151\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TQueryFnData>, TRPCQueryKey, NoInfer<null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | PlaceholderDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<TQueryFnData, TRPCQueryKey, null | NonNullable<ExtractCursorType<TInput>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKey​\n\nqueryKey: TRPCQueryKey & object\n\nDefined in: packages/react-query/src/shared/types.ts:150\n\nType declaration​\n[dataTagErrorSymbol]​\n\n[dataTagErrorSymbol]: TError\n\n[dataTagSymbol]​\n\n[dataTagSymbol]: TData\n\nOverrides​\n\nDistributiveOmit.queryKey\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => InfiniteData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nInfiniteData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/types.ts:29\n\npath​\n\npath: string\n\nInherited from​\n\nTRPCQueryOptionsResult.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UndefinedTRPCQueryOptionsIn",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UndefinedTRPCQueryOptionsIn\\<TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: UndefinedTRPCQueryOptionsIn<TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:40\n\nQueryOptions API helpers\n\nExtends​\nDistributiveOmit<UndefinedInitialDataOptions<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TData>, TRPCQueryKey>, TRPCOptionOverrides>.TRPCQueryBaseOptions\nType Parameters​\nType Parameter\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData?​\n\noptional initialData: (coerceAsyncIterableToArray<TQueryFnData> | InitialDataFunction<coerceAsyncIterableToArray<TQueryFnData>>) & (NonUndefinedGuard<...> | InitialDataFunction<...>)\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: TRPCQueryKey; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tTRPCQueryKey\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>> | PlaceholderDataFunction<NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TError, NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => coerceAsyncIterableToArray\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tcoerceAsyncIterableToArray\nReturns​\n\ncoerceAsyncIterableToArray\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/types.ts:25\n\ntRPC-related options\n\nInherited from​\n\nTRPCQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UndefinedTRPCQueryOptionsOut",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UndefinedTRPCQueryOptionsOut\\<TQueryFnData, TOutput, TError\\>\nVersion: 11.x\nInterface: UndefinedTRPCQueryOptionsOut<TQueryFnData, TOutput, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:52\n\nExtends​\nUndefinedInitialDataOptions<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TOutput>, TRPCQueryKey>.TRPCQueryOptionsResult\nType Parameters​\nType Parameter\nTQueryFnData\nTOutput\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nUndefinedInitialDataOptions._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nUndefinedInitialDataOptions._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nUndefinedInitialDataOptions.behavior\n\nenabled?​\n\noptional enabled: Enabled<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nUndefinedInitialDataOptions.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nUndefinedInitialDataOptions.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nUndefinedInitialDataOptions.gcTime\n\ninitialData?​\n\noptional initialData: (coerceAsyncIterableToArray<TQueryFnData> | InitialDataFunction<coerceAsyncIterableToArray<TQueryFnData>>) & (NonUndefinedGuard<...> | InitialDataFunction<...>)\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nUndefinedInitialDataOptions.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nUndefinedInitialDataOptions.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nUndefinedInitialDataOptions.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nUndefinedInitialDataOptions.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nUndefinedInitialDataOptions.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nUndefinedInitialDataOptions.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: TRPCQueryKey; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tTRPCQueryKey\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nInherited from​\n\nUndefinedInitialDataOptions.persister\n\nplaceholderData?​\n\noptional placeholderData: NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>> | PlaceholderDataFunction<NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TError, NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nUndefinedInitialDataOptions.placeholderData\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey, never>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nUndefinedInitialDataOptions.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nUndefinedInitialDataOptions.queryHash\n\nqueryKey​\n\nqueryKey: TRPCQueryKey & object\n\nDefined in: packages/react-query/src/shared/types.ts:60\n\nType declaration​\n[dataTagErrorSymbol]​\n\n[dataTagErrorSymbol]: TError\n\n[dataTagSymbol]​\n\n[dataTagSymbol]: coerceAsyncIterableToArray\n\nOverrides​\n\nUndefinedInitialDataOptions.queryKey\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nUndefinedInitialDataOptions.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nUndefinedInitialDataOptions.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nUndefinedInitialDataOptions.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nUndefinedInitialDataOptions.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nUndefinedInitialDataOptions.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nUndefinedInitialDataOptions.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nUndefinedInitialDataOptions.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nUndefinedInitialDataOptions.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nUndefinedInitialDataOptions.retryOnMount\n\nselect()?​\n\noptional select: (data) => coerceAsyncIterableToArray\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tcoerceAsyncIterableToArray\nReturns​\n\ncoerceAsyncIterableToArray\n\nInherited from​\n\nUndefinedInitialDataOptions.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nUndefinedInitialDataOptions.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nUndefinedInitialDataOptions.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nUndefinedInitialDataOptions.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nUndefinedInitialDataOptions.throwOnError\n\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/types.ts:29\n\npath​\n\npath: string\n\nInherited from​\n\nTRPCQueryOptionsResult.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UnusedSkipTokenTRPCInfiniteQueryOptionsIn",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UnusedSkipTokenTRPCInfiniteQueryOptionsIn\\<TInput, TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: UnusedSkipTokenTRPCInfiniteQueryOptionsIn<TInput, TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:193\n\nExtends​\nDistributiveOmit<UnusedSkipTokenInfiniteOptions<TQueryFnData, TError, InfiniteData<TData, NonNullable<ExtractCursorType<TInput>> | null>, TRPCQueryKey, NonNullable<ExtractCursorType<TInput>> | null>, TRPCInfiniteOptionOverrides>.TRPCQueryBaseOptions\nType Parameters​\nType Parameter\nTInput\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialCursor?​\n\noptional initialCursor: null | NonNullable<ExtractCursorType<TInput>>\n\nDefined in: packages/react-query/src/shared/types.ts:209\n\ninitialData?​\n\noptional initialData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | InitialDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TQueryFnData>, TRPCQueryKey, NoInfer<null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | PlaceholderDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => InfiniteData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nInfiniteData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/types.ts:25\n\ntRPC-related options\n\nInherited from​\n\nTRPCQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UnusedSkipTokenTRPCInfiniteQueryOptionsOut",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UnusedSkipTokenTRPCInfiniteQueryOptionsOut\\<TInput, TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: UnusedSkipTokenTRPCInfiniteQueryOptionsOut<TInput, TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:212\n\nExtends​\nDistributiveOmit<UnusedSkipTokenInfiniteOptions<TQueryFnData, TError, InfiniteData<TData, NonNullable<ExtractCursorType<TInput>> | null>, TRPCQueryKey, NonNullable<ExtractCursorType<TInput>> | null>, \"initialPageParam\">.TRPCQueryOptionsResult\nType Parameters​\nType Parameter\nTInput\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<null | NonNullable<ExtractCursorType<TInput>>, TQueryFnData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialData?​\n\noptional initialData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | InitialDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\ninitialPageParam​\n\ninitialPageParam: null | NonNullable<ExtractCursorType<TInput>>\n\nDefined in: packages/react-query/src/shared/types.ts:229\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TQueryFnData>, TRPCQueryKey, NoInfer<null | NonNullable<ExtractCursorType<TInput>>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>> | PlaceholderDataFunction<InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryFn?​\n\noptional queryFn: QueryFunction<TQueryFnData, TRPCQueryKey, null | NonNullable<ExtractCursorType<TInput>>>\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/infiniteQueryOptions.d.ts:8\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKey​\n\nqueryKey: TRPCQueryKey & object\n\nDefined in: packages/react-query/src/shared/types.ts:228\n\nType declaration​\n[dataTagErrorSymbol]​\n\n[dataTagErrorSymbol]: TError\n\n[dataTagSymbol]​\n\n[dataTagSymbol]: TData\n\nOverrides​\n\nDistributiveOmit.queryKey\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => InfiniteData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nInfiniteData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TQueryFnData, TError, InfiniteData<TQueryFnData, null | NonNullable<ExtractCursorType<TInput>>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/types.ts:29\n\npath​\n\npath: string\n\nInherited from​\n\nTRPCQueryOptionsResult.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UnusedSkipTokenTRPCQueryOptionsIn",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UnusedSkipTokenTRPCQueryOptionsIn\\<TQueryFnData, TData, TError\\>\nVersion: 11.x\nInterface: UnusedSkipTokenTRPCQueryOptionsIn<TQueryFnData, TData, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:86\n\nExtends​\nDistributiveOmit<UnusedSkipTokenOptions<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TData>, TRPCQueryKey>, TRPCOptionOverrides>.TRPCQueryBaseOptions\nType Parameters​\nType Parameter\nTQueryFnData\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData?​\n\noptional initialData: coerceAsyncIterableToArray<TQueryFnData> | InitialDataFunction<coerceAsyncIterableToArray<TQueryFnData>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: TRPCQueryKey; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tTRPCQueryKey\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>> | PlaceholderDataFunction<NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TError, NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => coerceAsyncIterableToArray\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tcoerceAsyncIterableToArray\nReturns​\n\ncoerceAsyncIterableToArray\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/types.ts:25\n\ntRPC-related options\n\nInherited from​\n\nTRPCQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UnusedSkipTokenTRPCQueryOptionsOut",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UnusedSkipTokenTRPCQueryOptionsOut\\<TQueryFnData, TOutput, TError\\>\nVersion: 11.x\nInterface: UnusedSkipTokenTRPCQueryOptionsOut<TQueryFnData, TOutput, TError>\n\nDefined in: packages/react-query/src/shared/types.ts:98\n\nExtends​\nUnusedSkipTokenOptions<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TOutput>, TRPCQueryKey>.TRPCQueryOptionsResult\nType Parameters​\nType Parameter\nTQueryFnData\nTOutput\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nUnusedSkipTokenOptions._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nUnusedSkipTokenOptions._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nUnusedSkipTokenOptions.behavior\n\nenabled?​\n\noptional enabled: Enabled<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nUnusedSkipTokenOptions.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nUnusedSkipTokenOptions.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nUnusedSkipTokenOptions.gcTime\n\ninitialData?​\n\noptional initialData: coerceAsyncIterableToArray<TQueryFnData> | InitialDataFunction<coerceAsyncIterableToArray<TQueryFnData>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nUnusedSkipTokenOptions.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nUnusedSkipTokenOptions.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nUnusedSkipTokenOptions.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nUnusedSkipTokenOptions.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nUnusedSkipTokenOptions.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nUnusedSkipTokenOptions.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: TRPCQueryKey; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tTRPCQueryKey\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<coerceAsyncIterableToArray<TQueryFnData>> | Promise<NoInfer<coerceAsyncIterableToArray<TQueryFnData>>>\n\nInherited from​\n\nUnusedSkipTokenOptions.persister\n\nplaceholderData?​\n\noptional placeholderData: NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>> | PlaceholderDataFunction<NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TError, NonFunctionGuard<coerceAsyncIterableToArray<TQueryFnData>>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nUnusedSkipTokenOptions.placeholderData\n\nqueryFn?​\n\noptional queryFn: QueryFunction<coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey, never>\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/queryOptions.d.ts:8\n\nInherited from​\n\nUnusedSkipTokenOptions.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nUnusedSkipTokenOptions.queryHash\n\nqueryKey​\n\nqueryKey: TRPCQueryKey & object\n\nDefined in: packages/react-query/src/shared/types.ts:109\n\nType declaration​\n[dataTagErrorSymbol]​\n\n[dataTagErrorSymbol]: TError\n\n[dataTagSymbol]​\n\n[dataTagSymbol]: coerceAsyncIterableToArray\n\nOverrides​\n\nUnusedSkipTokenOptions.queryKey\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nUnusedSkipTokenOptions.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nUnusedSkipTokenOptions.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nUnusedSkipTokenOptions.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nUnusedSkipTokenOptions.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nUnusedSkipTokenOptions.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nUnusedSkipTokenOptions.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nUnusedSkipTokenOptions.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nUnusedSkipTokenOptions.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nUnusedSkipTokenOptions.retryOnMount\n\nselect()?​\n\noptional select: (data) => coerceAsyncIterableToArray\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tcoerceAsyncIterableToArray\nReturns​\n\ncoerceAsyncIterableToArray\n\nInherited from​\n\nUnusedSkipTokenOptions.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nUnusedSkipTokenOptions.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nUnusedSkipTokenOptions.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nUnusedSkipTokenOptions.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<coerceAsyncIterableToArray<TQueryFnData>, TError, coerceAsyncIterableToArray<TQueryFnData>, TRPCQueryKey>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nUnusedSkipTokenOptions.throwOnError\n\ntrpc​\n\ntrpc: object\n\nDefined in: packages/react-query/src/shared/types.ts:29\n\npath​\n\npath: string\n\nInherited from​\n\nTRPCQueryOptionsResult.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UseTRPCInfiniteQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UseTRPCInfiniteQueryOptions\\<TInput, TOutput, TError\\>\nVersion: 11.x\nInterface: UseTRPCInfiniteQueryOptions<TInput, TOutput, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:109\n\nExtends​\nDistributiveOmit<UseInfiniteQueryOptions<TOutput, TError, TOutput, any, ExtractCursorType<TInput>>, \"queryKey\" | \"initialPageParam\">.TRPCUseQueryBaseOptions\nType Parameters​\nType Parameter\nTInput\nTOutput\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TOutput, TError, InfiniteData<TOutput, ExtractCursorType<TInput>>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TOutput, TError, InfiniteData<TOutput, ExtractCursorType<TInput>>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<ExtractCursorType<TInput>, TOutput>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<ExtractCursorType<TInput>, TOutput>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialCursor?​\n\noptional initialCursor: ExtractCursorType<TInput>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:121\n\ninitialData?​\n\noptional initialData: InfiniteData<TOutput, ExtractCursorType<TInput>> | InitialDataFunction<InfiniteData<TOutput, ExtractCursorType<TInput>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TOutput>, any, NoInfer<ExtractCursorType<TInput>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: InfiniteData<TOutput, ExtractCursorType<TInput>> | PlaceholderDataFunction<InfiniteData<TOutput, ExtractCursorType<TInput>>, TError, InfiniteData<TOutput, ExtractCursorType<TInput>>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<TOutput, any, ExtractCursorType<TInput>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => TOutput\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nTOutput\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TOutput, TError, InfiniteData<TOutput, ExtractCursorType<TInput>>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TOutput, TError, InfiniteData<TOutput, ExtractCursorType<TInput>>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UseTRPCMutationOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UseTRPCMutationOptions\\<TInput, TError, TOutput, TContext\\>\nVersion: 11.x\nInterface: UseTRPCMutationOptions<TInput, TError, TOutput, TContext>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:154\n\nExtends​\nUseMutationOptions<TOutput, TError, TInput, TContext>.TRPCUseQueryBaseOptions\nType Parameters​\nType Parameter\tDefault type\nTInput\t-\nTError\t-\nTOutput\t-\nTContext\tunknown\nProperties​\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1190\n\nInherited from​\n\nUseMutationOptions.gcTime\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1192\n\nInherited from​\n\nUseMutationOptions.meta\n\nmutationFn?​\n\noptional mutationFn: MutationFunction<TOutput, TInput>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1181\n\nInherited from​\n\nUseMutationOptions.mutationFn\n\nmutationKey?​\n\noptional mutationKey: readonly unknown[]\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1182\n\nInherited from​\n\nUseMutationOptions.mutationKey\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1189\n\nInherited from​\n\nUseMutationOptions.networkMode\n\nonError()?​\n\noptional onError: (error, variables, context) => void | Promise<void>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1185\n\nParameters​\nParameter\tType\nerror\tTError\nvariables\tTInput\ncontext\tundefined | TContext\nReturns​\n\nvoid | Promise<void>\n\nInherited from​\n\nUseMutationOptions.onError\n\nonMutate()?​\n\noptional onMutate: (variables) => undefined | TContext | Promise<undefined | TContext>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1183\n\nParameters​\nParameter\tType\nvariables\tTInput\nReturns​\n\nundefined | TContext | Promise<undefined | TContext>\n\nInherited from​\n\nUseMutationOptions.onMutate\n\nonSettled()?​\n\noptional onSettled: (data, error, variables, context) => void | Promise<void>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1186\n\nParameters​\nParameter\tType\ndata\tundefined | TOutput\nerror\tnull | TError\nvariables\tTInput\ncontext\tundefined | TContext\nReturns​\n\nvoid | Promise<void>\n\nInherited from​\n\nUseMutationOptions.onSettled\n\nonSuccess()?​\n\noptional onSuccess: (data, variables, context) => void | Promise<void>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1184\n\nParameters​\nParameter\tType\ndata\tTOutput\nvariables\tTInput\ncontext\tTContext\nReturns​\n\nvoid | Promise<void>\n\nInherited from​\n\nUseMutationOptions.onSuccess\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1187\n\nInherited from​\n\nUseMutationOptions.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1188\n\nInherited from​\n\nUseMutationOptions.retryDelay\n\nscope?​\n\noptional scope: MutationScope\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1193\n\nInherited from​\n\nUseMutationOptions.scope\n\nthrowOnError?​\n\noptional throwOnError: boolean | (error) => boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:1196\n\nInherited from​\n\nUseMutationOptions.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "Interface: UseTRPCQueryOptions\\<TOutput, TData, TError, TQueryOptsData\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UseTRPCQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UseTRPCQueryOptions\\<TOutput, TData, TError, TQueryOptsData\\>\nVersion: 11.x\nInterface: UseTRPCQueryOptions<TOutput, TData, TError, TQueryOptsData>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:61\n\nExtends​\nDistributiveOmit<UseBaseQueryOptions<TOutput, TError, TData, TQueryOptsData, any>, \"queryKey\">.TRPCUseQueryBaseOptions\nType Parameters​\nType Parameter\tDefault type\nTOutput\t-\nTData\t-\nTError\t-\nTQueryOptsData\tTOutput\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TOutput, TError, TQueryOptsData, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nenabled?​\n\noptional enabled: Enabled<TOutput, TError, TQueryOptsData, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:654\n\nSet this to false or a function that returns false to disable automatic refetching when the query mounts or changes query keys. To refetch the query, use the refetch method returned from the useQuery instance. Accepts a boolean or function that returns a boolean. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.enabled\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData?​\n\noptional initialData: TQueryOptsData | InitialDataFunction<TQueryOptsData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<TOutput>, any, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: any; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tany\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nplaceholderData?​\n\noptional placeholderData: NonFunctionGuard<TQueryOptsData> | PlaceholderDataFunction<NonFunctionGuard<TQueryOptsData>, TError, NonFunctionGuard<TQueryOptsData>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:731\n\nIf set, this value will be used as the placeholder data for this particular query observer while the query is still in the loading data and no initialData has been provided.\n\nInherited from​\n\nDistributiveOmit.placeholderData\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<TOutput, any, never>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => TData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tTQueryOptsData\nReturns​\n\nTData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TOutput, TError, TQueryOptsData, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\nsuspense?​\n\noptional suspense: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:727\n\nIf set to true, the query will suspend when status === 'pending' and throw errors when status === 'error'. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.suspense\n\nthrowOnError?​\n\noptional throwOnError: ThrowOnError<TOutput, TError, TQueryOptsData, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:717\n\nWhether errors should be thrown instead of setting the error property. If set to true or suspense is true, all errors will be thrown to the error boundary. If set to false and suspense is false, errors are returned as state. If set to a function, it will be passed the error and the query, and it should return a boolean indicating whether to show the error in an error boundary (true) or return the error as state (false). Defaults to false.\n\nInherited from​\n\nDistributiveOmit.throwOnError\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "Interface: UseTRPCPrefetchQueryOptions\\<TOutput, TData, TError\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UseTRPCPrefetchQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UseTRPCPrefetchQueryOptions\\<TOutput, TData, TError\\>\nVersion: 11.x\nInterface: UseTRPCPrefetchQueryOptions<TOutput, TData, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:79\n\nExtends​\nDistributiveOmit<FetchQueryOptions<TOutput, TError, TData, any>, \"queryKey\">.TRPCUseQueryBaseOptions\nType Parameters​\nType Parameter\nTOutput\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\nbehavior?​\n\noptional behavior: QueryBehavior<TOutput, TError, TData, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData?​\n\noptional initialData: TData | InitialDataFunction<TData>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\ninitialPageParam?​\n\noptional initialPageParam: undefined\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:746\n\nInherited from​\n\nDistributiveOmit.initialPageParam\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<TOutput>, any, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: any; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tany\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nqueryFn?​\n\noptional queryFn: typeof skipToken | QueryFunction<TOutput, any, never>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:606\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TOutput, TError, TData, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:751\n\nThe time in milliseconds after data is considered stale. If the data is fresh it will be returned from the cache.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UseTRPCSubscriptionOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UseTRPCSubscriptionOptions\\<TOutput, TError\\>\nVersion: 11.x\nInterface: UseTRPCSubscriptionOptions<TOutput, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:162\n\nType Parameters​\nType Parameter\nTOutput\nTError\nProperties​\nenabled?​\n\noptional enabled: boolean\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:168\n\nDeprecated​\n\nuse a skipToken from @tanstack/react-query instead this will be removed in v12\n\nonComplete()?​\n\noptional onComplete: () => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:184\n\nCalled when the subscription is completed on the server\n\nReturns​\n\nvoid\n\nonData()?​\n\noptional onData: (data) => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:176\n\nCalled when new data is received\n\nParameters​\nParameter\tType\ndata\tTOutput\nReturns​\n\nvoid\n\nonError()?​\n\noptional onError: (err) => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:180\n\nCalled when an unrecoverable error occurs and the subscription is closed\n\nParameters​\nParameter\tType\nerr\tTError\nReturns​\n\nvoid\n\nonStarted()?​\n\noptional onStarted: () => void\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:172\n\nCalled when the subscription is started\n\nReturns​\n\nvoid\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UseTRPCSuspenseInfiniteQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UseTRPCSuspenseInfiniteQueryOptions\\<TInput, TOutput, TError\\>\nVersion: 11.x\nInterface: UseTRPCSuspenseInfiniteQueryOptions<TInput, TOutput, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:139\n\nExtends​\nDistributiveOmit<UseSuspenseInfiniteQueryOptions<TOutput, TError, TOutput, any, ExtractCursorType<TInput>>, \"queryKey\" | \"initialPageParam\">.TRPCUseQueryBaseOptions\nType Parameters​\nType Parameter\nTInput\nTOutput\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TOutput, TError, InfiniteData<TOutput, ExtractCursorType<TInput>>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ngetNextPageParam​\n\ngetNextPageParam: GetNextPageParamFunction<ExtractCursorType<TInput>, TOutput>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:644\n\nThis function can be set to automatically get the next cursor for infinite queries. The result will also be used to determine the value of hasNextPage.\n\nInherited from​\n\nDistributiveOmit.getNextPageParam\n\ngetPreviousPageParam?​\n\noptional getPreviousPageParam: GetPreviousPageParamFunction<ExtractCursorType<TInput>, TOutput>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:639\n\nThis function can be set to automatically get the previous cursor for infinite queries. The result will also be used to determine the value of hasPreviousPage.\n\nInherited from​\n\nDistributiveOmit.getPreviousPageParam\n\ninitialCursor?​\n\noptional initialCursor: ExtractCursorType<TInput>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:151\n\ninitialData?​\n\noptional initialData: InfiniteData<TOutput, ExtractCursorType<TInput>> | InitialDataFunction<InfiniteData<TOutput, ExtractCursorType<TInput>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister?​\n\noptional persister: QueryPersister<NoInfer<TOutput>, any, NoInfer<ExtractCursorType<TInput>>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nInherited from​\n\nDistributiveOmit.persister\n\nqueryFn?​\n\noptional queryFn: QueryFunction<TOutput, any, ExtractCursorType<TInput>>\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:28\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => TOutput\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tInfiniteData\nReturns​\n\nTOutput\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TOutput, TError, InfiniteData<TOutput, ExtractCursorType<TInput>>, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:24\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "Interface: UseTRPCSuspenseQueryOptions\\<TOutput, TData, TError\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/interfaces/UseTRPCSuspenseQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ninterfaces\nInterface: UseTRPCSuspenseQueryOptions\\<TOutput, TData, TError\\>\nVersion: 11.x\nInterface: UseTRPCSuspenseQueryOptions<TOutput, TData, TError>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:72\n\nExtends​\nDistributiveOmit<UseSuspenseQueryOptions<TOutput, TError, TData, any>, \"queryKey\">.TRPCUseQueryBaseOptions\nType Parameters​\nType Parameter\nTOutput\nTData\nTError\nProperties​\n_defaulted?​\n\noptional _defaulted: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:620\n\nInherited from​\n\nDistributiveOmit._defaulted\n\n_optimisticResults?​\n\noptional _optimisticResults: \"optimistic\" | \"isRestoring\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:732\n\nInherited from​\n\nDistributiveOmit._optimisticResults\n\nbehavior?​\n\noptional behavior: QueryBehavior<TOutput, TError, TOutput, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:613\n\nInherited from​\n\nDistributiveOmit.behavior\n\nexperimental_prefetchInRender?​\n\noptional experimental_prefetchInRender: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:736\n\nEnable prefetching during rendering\n\nInherited from​\n\nDistributiveOmit.experimental_prefetchInRender\n\ngcTime?​\n\noptional gcTime: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:605\n\nThe time in milliseconds that unused/inactive cache data remains in memory. When a query's cache becomes unused or inactive, that cache data will be garbage collected after this duration. When different garbage collection times are specified, the longest one will be used. Setting it to Infinity will disable garbage collection.\n\nInherited from​\n\nDistributiveOmit.gcTime\n\ninitialData?​\n\noptional initialData: TOutput | InitialDataFunction<TOutput>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:611\n\nInherited from​\n\nDistributiveOmit.initialData\n\ninitialDataUpdatedAt?​\n\noptional initialDataUpdatedAt: number | () => undefined | number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:612\n\nInherited from​\n\nDistributiveOmit.initialDataUpdatedAt\n\nmaxPages?​\n\noptional maxPages: number\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:629\n\nMaximum number of pages to store in the data of an infinite query.\n\nInherited from​\n\nDistributiveOmit.maxPages\n\nmeta?​\n\noptional meta: Record<string, unknown>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:625\n\nAdditional payload to be stored on each query. Use this property to pass information that can be used in other places.\n\nInherited from​\n\nDistributiveOmit.meta\n\nnetworkMode?​\n\noptional networkMode: NetworkMode\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:598\n\nInherited from​\n\nDistributiveOmit.networkMode\n\nnotifyOnChangeProps?​\n\noptional notifyOnChangeProps: NotifyOnChangeProps\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:709\n\nIf set, the component will only re-render if any of the listed properties change. When set to ['data', 'error'], the component will only re-render when the data or error properties change. When set to 'all', the component will re-render whenever a query is updated. When set to a function, the function will be executed to compute the list of properties. By default, access to properties will be tracked, and the component will only re-render when one of the tracked properties change.\n\nInherited from​\n\nDistributiveOmit.notifyOnChangeProps\n\npersister()?​\n\noptional persister: (queryFn, context, query) => NoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:607\n\nParameters​\nParameter\tType\tDescription\nqueryFn\tQueryFunction<NoInfer<TOutput>, any, never>\t-\ncontext\t{ client: QueryClient; direction: unknown; meta: undefined | Record<string, unknown>; pageParam: unknown; queryKey: any; signal: AbortSignal; }\t-\ncontext.client\tQueryClient\t-\ncontext.direction?\tunknown\tDeprecated if you want access to the direction, you can add it to the pageParam\ncontext.meta\tundefined | Record<string, unknown>\t-\ncontext.pageParam?\tunknown\t-\ncontext.queryKey\tany\t-\ncontext.signal\tAbortSignal\t-\nquery\tQuery\t-\nReturns​\n\nNoInfer<TOutput> | Promise<NoInfer<TOutput>>\n\nInherited from​\n\nDistributiveOmit.persister\n\nqueryFn?​\n\noptional queryFn: QueryFunction<TOutput, any, never>\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:16\n\nInherited from​\n\nDistributiveOmit.queryFn\n\nqueryHash?​\n\noptional queryHash: string\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:608\n\nInherited from​\n\nDistributiveOmit.queryHash\n\nqueryKeyHashFn?​\n\noptional queryKeyHashFn: QueryKeyHashFunction<any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:610\n\nInherited from​\n\nDistributiveOmit.queryKeyHashFn\n\nrefetchInterval?​\n\noptional refetchInterval: number | false | (query) => undefined | number | false\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:667\n\nIf set to a number, the query will continuously refetch at this frequency in milliseconds. If set to a function, the function will be executed with the latest data and query to compute a frequency Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchInterval\n\nrefetchIntervalInBackground?​\n\noptional refetchIntervalInBackground: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:672\n\nIf set to true, the query will continue to refetch while their tab/window is in the background. Defaults to false.\n\nInherited from​\n\nDistributiveOmit.refetchIntervalInBackground\n\nrefetchOnMount?​\n\noptional refetchOnMount: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:696\n\nIf set to true, the query will refetch on mount if the data is stale. If set to false, will disable additional instances of a query to trigger background refetch. If set to 'always', the query will always refetch on mount. If set to a function, the function will be executed with the latest data and query to compute the value Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnMount\n\nrefetchOnReconnect?​\n\noptional refetchOnReconnect: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:688\n\nIf set to true, the query will refetch on reconnect if the data is stale. If set to false, the query will not refetch on reconnect. If set to 'always', the query will always refetch on reconnect. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to the value of networkOnline (true)\n\nInherited from​\n\nDistributiveOmit.refetchOnReconnect\n\nrefetchOnWindowFocus?​\n\noptional refetchOnWindowFocus: boolean | \"always\" | (query) => boolean | \"always\"\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:680\n\nIf set to true, the query will refetch on window focus if the data is stale. If set to false, the query will not refetch on window focus. If set to 'always', the query will always refetch on window focus. If set to a function, the function will be executed with the latest data and query to compute the value. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.refetchOnWindowFocus\n\nretry?​\n\noptional retry: RetryValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:596\n\nIf false, failed queries will not retry by default. If true, failed queries will retry infinitely., failureCount: num If set to an integer number, e.g. 3, failed queries will retry until the failed query count meets that number. If set to a function (failureCount, error) => boolean failed queries will retry until the function returns false.\n\nInherited from​\n\nDistributiveOmit.retry\n\nretryDelay?​\n\noptional retryDelay: RetryDelayValue<TError>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:597\n\nInherited from​\n\nDistributiveOmit.retryDelay\n\nretryOnMount?​\n\noptional retryOnMount: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:701\n\nIf set to false, the query will not be retried on mount if it contains an error. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.retryOnMount\n\nselect()?​\n\noptional select: (data) => TData\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:721\n\nThis option can be used to transform or select a part of the data returned by the query function.\n\nParameters​\nParameter\tType\ndata\tTOutput\nReturns​\n\nTData\n\nInherited from​\n\nDistributiveOmit.select\n\nstaleTime?​\n\noptional staleTime: StaleTimeFunction<TOutput, TError, TOutput, any>\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:661\n\nThe time in milliseconds after data is considered stale. If set to Infinity, the data will never be considered stale. If set to a function, the function will be executed with the query to compute a staleTime. Defaults to 0.\n\nInherited from​\n\nDistributiveOmit.staleTime\n\nstructuralSharing?​\n\noptional structuralSharing: boolean | (oldData, newData) => unknown\n\nDefined in: node_modules/.pnpm/@tanstack+query-core@5.80.2/node_modules/@tanstack/query-core/build/modern/hydration-DYrnn9Jo.d.ts:619\n\nSet this to false to disable structural sharing between query results. Set this to a function which accepts the old and new data and returns resolved data of the same type to implement custom structural sharing logic. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.structuralSharing\n\nsubscribed?​\n\noptional subscribed: boolean\n\nDefined in: node_modules/.pnpm/@tanstack+react-query@5.80.3_react@19.1.0/node_modules/@tanstack/react-query/build/modern/types.d.ts:9\n\nSet this to false to unsubscribe this observer from updates to the query cache. Defaults to true.\n\nInherited from​\n\nDistributiveOmit.subscribed\n\ntrpc?​\n\noptional trpc: TRPCReactRequestOptions\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:58\n\ntRPC-related options\n\nInherited from​\n\nTRPCUseQueryBaseOptions.trpc\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/CreateClient",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: CreateClient()\\<TRouter\\>\nVersion: 11.x\nType Alias: CreateClient()<TRouter>\n\nCreateClient<TRouter>: (opts) => TRPCUntypedClient<TRouter>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:241\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nParameters​\nParameter\tType\nopts\tCreateTRPCClientOptions<TRouter>\nReturns​\n\nTRPCUntypedClient<TRouter>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/CreateQueryUtils",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: CreateQueryUtils\\<TRouter\\>\nVersion: 11.x\nType Alias: CreateQueryUtils<TRouter>\n\nCreateQueryUtils<TRouter>: DecoratedProcedureUtilsRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>\n\nDefined in: packages/react-query/src/shared/proxy/utilsProxy.ts:425\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/CreateReactUtils",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: CreateReactUtils\\<TRouter, TSSRContext\\>\nVersion: 11.x\nType Alias: CreateReactUtils<TRouter, TSSRContext>\n\nCreateReactUtils<TRouter, TSSRContext>: ProtectedIntersection<DecoratedTRPCContextProps<TRouter, TSSRContext>, DecoratedProcedureUtilsRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>>\n\nDefined in: packages/react-query/src/shared/proxy/utilsProxy.ts:414\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nTSSRContext\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/DecorateQueryProcedure",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: DecorateQueryProcedure\\<TRoot, TProcedure\\>\nVersion: 11.x\nType Alias: DecorateQueryProcedure<TRoot, TProcedure>\n\nDecorateQueryProcedure<TRoot, TProcedure>: object\n\nDefined in: packages/react-query/src/shared/proxy/utilsProxy.ts:64\n\nType Parameters​\nType Parameter\nTRoot extends AnyRootTypes\nTProcedure extends AnyQueryProcedure\nType declaration​\ncancel()​\nParameters​\nParameter\tType\ninput?\tinferProcedureInput<TProcedure>\noptions?\tCancelOptions\nReturns​\n\nPromise<void>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientcancelqueries\n\nensureData()​\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure>\nopts?\tTRPCFetchQueryOptions<inferTransformedProcedureOutput<TRoot, TProcedure>, TRPCClientError<TRoot>>\nReturns​\n\nPromise<inferTransformedProcedureOutput<TRoot, TProcedure>>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientensurequerydata\n\nfetch()​\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure>\nopts?\tTRPCFetchQueryOptions<inferTransformedProcedureOutput<TRoot, TProcedure>, TRPCClientError<TRoot>>\nReturns​\n\nPromise<inferTransformedProcedureOutput<TRoot, TProcedure>>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientfetchquery\n\nfetchInfinite()​\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure>\nopts?\tTRPCFetchInfiniteQueryOptions<inferProcedureInput<TProcedure>, inferTransformedProcedureOutput<TRoot, TProcedure>, TRPCClientError<TRoot>>\nReturns​\n\nPromise<InfiniteData<inferTransformedProcedureOutput<TRoot, TProcedure>, null | NonNullable<ExtractCursorType<inferProcedureInput<TProcedure>>>>>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientfetchinfinitequery\n\ngetData()​\nParameters​\nParameter\tType\ninput?\tinferProcedureInput<TProcedure>\nReturns​\n\nundefined | inferTransformedProcedureOutput<TRoot, TProcedure>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientgetquerydata\n\ngetInfiniteData()​\nParameters​\nParameter\tType\ninput?\tinferProcedureInput<TProcedure>\nReturns​\n\nundefined | InfiniteData<inferTransformedProcedureOutput<TRoot, TProcedure>, null | NonNullable<ExtractCursorType<inferProcedureInput<TProcedure>>>>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientgetquerydata\n\ninfiniteQueryOptions()​\nCall Signature​\nType Parameters​\nType Parameter\tDefault type\nTQueryFnData extends any\t-\nTData\tTQueryFnData\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure> | typeof skipToken\nopts\tDefinedTRPCInfiniteQueryOptionsIn<inferProcedureInput<TProcedure>, TQueryFnData, TData, TRPCClientError<TRoot>>\nReturns​\n\nDefinedTRPCInfiniteQueryOptionsOut<inferProcedureInput<TProcedure>, TQueryFnData, TData, TRPCClientError<TRoot>>\n\nSee​\n\nhttps://tanstack.com/query/latest/docs/framework/react/reference/infiniteQueryOptions#infinitequeryoptions\n\nCall Signature​\nType Parameters​\nType Parameter\tDefault type\nTQueryFnData extends any\t-\nTData\tTQueryFnData\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure>\nopts\tUnusedSkipTokenTRPCInfiniteQueryOptionsIn<inferProcedureInput<TProcedure>, TQueryFnData, TData, TRPCClientError<TRoot>>\nReturns​\n\nUnusedSkipTokenTRPCInfiniteQueryOptionsOut<inferProcedureInput<TProcedure>, TQueryFnData, TData, TRPCClientError<TRoot>>\n\nSee​\n\nhttps://tanstack.com/query/latest/docs/framework/react/reference/infiniteQueryOptions#infinitequeryoptions\n\nCall Signature​\nType Parameters​\nType Parameter\tDefault type\nTQueryFnData extends any\t-\nTData\tTQueryFnData\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure> | typeof skipToken\nopts?\tUndefinedTRPCInfiniteQueryOptionsIn<inferProcedureInput<TProcedure>, TQueryFnData, TData, TRPCClientError<TRoot>>\nReturns​\n\nUndefinedTRPCInfiniteQueryOptionsOut<inferProcedureInput<TProcedure>, TQueryFnData, TData, TRPCClientError<TRoot>>\n\nSee​\n\nhttps://tanstack.com/query/latest/docs/framework/react/reference/infiniteQueryOptions#infinitequeryoptions\n\ninvalidate()​\nParameters​\nParameter\tType\ninput?\tDeepPartial<inferProcedureInput<TProcedure>>\nfilters?\tOmit<InvalidateQueryFilters<readonly unknown[]>, \"predicate\"> & object\noptions?\tInvalidateOptions\nReturns​\n\nPromise<void>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientinvalidatequeries\n\nprefetch()​\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure>\nopts?\tTRPCFetchQueryOptions<inferTransformedProcedureOutput<TRoot, TProcedure>, TRPCClientError<TRoot>>\nReturns​\n\nPromise<void>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientprefetchquery\n\nprefetchInfinite()​\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure>\nopts?\tTRPCFetchInfiniteQueryOptions<inferProcedureInput<TProcedure>, inferTransformedProcedureOutput<TRoot, TProcedure>, TRPCClientError<TRoot>>\nReturns​\n\nPromise<void>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientprefetchinfinitequery\n\nqueryOptions()​\nCall Signature​\nType Parameters​\nType Parameter\tDefault type\nTQueryFnData extends any\t-\nTData\tTQueryFnData\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure> | typeof skipToken\nopts\tDefinedTRPCQueryOptionsIn<TQueryFnData, TData, TRPCClientError<TRoot>>\nReturns​\n\nDefinedTRPCQueryOptionsOut<TQueryFnData, TData, TRPCClientError<TRoot>>\n\nSee​\n\nhttps://tanstack.com/query/latest/docs/framework/react/reference/queryOptions#queryoptions\n\nCall Signature​\nType Parameters​\nType Parameter\tDefault type\nTQueryFnData extends any\t-\nTData\tTQueryFnData\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure> | typeof skipToken\nopts?\tUnusedSkipTokenTRPCQueryOptionsIn<TQueryFnData, TData, TRPCClientError<TRoot>>\nReturns​\n\nUnusedSkipTokenTRPCQueryOptionsOut<TQueryFnData, TData, TRPCClientError<TRoot>>\n\nSee​\n\nhttps://tanstack.com/query/latest/docs/framework/react/reference/queryOptions#queryoptions\n\nCall Signature​\nType Parameters​\nType Parameter\tDefault type\nTQueryFnData extends any\t-\nTData\tTQueryFnData\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure> | typeof skipToken\nopts?\tUndefinedTRPCQueryOptionsIn<TQueryFnData, TData, TRPCClientError<TRoot>>\nReturns​\n\nUndefinedTRPCQueryOptionsOut<TQueryFnData, TData, TRPCClientError<TRoot>>\n\nSee​\n\nhttps://tanstack.com/query/latest/docs/framework/react/reference/queryOptions#queryoptions\n\nrefetch()​\nParameters​\nParameter\tType\ninput?\tinferProcedureInput<TProcedure>\nfilters?\tRefetchQueryFilters<readonly unknown[]>\noptions?\tRefetchOptions\nReturns​\n\nPromise<void>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientrefetchqueries\n\nreset()​\nParameters​\nParameter\tType\ninput?\tinferProcedureInput<TProcedure>\noptions?\tResetOptions\nReturns​\n\nPromise<void>\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientresetqueries\n\nsetData()​\nParameters​\nParameter\tType\tDescription\ninput\tinferProcedureInput<TProcedure>\tThe input of the procedure\nupdater\tUpdater<undefined | inferTransformedProcedureOutput<TRoot, TProcedure>, undefined | inferTransformedProcedureOutput<TRoot, TProcedure>>\t-\noptions?\tSetDataOptions\t-\nReturns​\n\nvoid\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientsetquerydata\n\nsetInfiniteData()​\nParameters​\nParameter\tType\ninput\tinferProcedureInput<TProcedure>\nupdater\tUpdater<undefined | InfiniteData<inferTransformedProcedureOutput<TRoot, TProcedure>, null | NonNullable<ExtractCursorType<inferProcedureInput<TProcedure>>>>, undefined | InfiniteData<inferTransformedProcedureOutput<TRoot, TProcedure>, null | NonNullable<ExtractCursorType<inferProcedureInput<TProcedure>>>>>\noptions?\tSetDataOptions\nReturns​\n\nvoid\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientsetquerydata\n\nsetQueriesData()​\nParameters​\nParameter\tType\tDescription\ninput\tinferProcedureInput<TProcedure>\tThe input of the procedure\nfilters\tQueryFilters\t-\nupdater\tUpdater<undefined | inferTransformedProcedureOutput<TRoot, TProcedure>, undefined | inferTransformedProcedureOutput<TRoot, TProcedure>>\t-\noptions?\tSetDataOptions\t-\nReturns​\n\n[readonly unknown[], inferTransformedProcedureOutput<TRoot, TProcedure>]\n\nSee​\n\nhttps://tanstack.com/query/v5/docs/reference/QueryClient#queryclientsetquerydata\n\nEdit this page"
  },
  {
    "title": "Type Alias: ExtractCursorType\\<TInput\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/ExtractCursorType",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: ExtractCursorType\\<TInput\\>\nVersion: 11.x\nType Alias: ExtractCursorType<TInput>\n\nExtractCursorType<TInput>: TInput extends object ? TInput[\"cursor\"] : unknown\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:105\n\nType Parameters​\nType Parameter\nTInput\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/InferMutationLikeData",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: InferMutationLikeData\\<TMutationLike\\>\nVersion: 11.x\nType Alias: InferMutationLikeData<TMutationLike>\n\nInferMutationLikeData<TMutationLike>: TMutationLike extends MutationLike<infer TRoot, infer TProcedure> ? inferTransformedProcedureOutput<TRoot, TProcedure> : never\n\nDefined in: packages/react-query/src/shared/polymorphism/mutationLike.ts:37\n\nUse to unwrap a MutationLike's data output\n\nType Parameters​\nType Parameter\nTMutationLike extends MutationLike<any, any>\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/InferMutationLikeInput",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: InferMutationLikeInput\\<TMutationLike\\>\nVersion: 11.x\nType Alias: InferMutationLikeInput<TMutationLike>\n\nInferMutationLikeInput<TMutationLike>: TMutationLike extends MutationLike<any, infer $Procedure> ? inferProcedureInput<$Procedure> : never\n\nDefined in: packages/react-query/src/shared/polymorphism/mutationLike.ts:27\n\nUse to unwrap a MutationLike's input\n\nType Parameters​\nType Parameter\nTMutationLike extends MutationLike<any, any>\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/InferQueryLikeData",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: InferQueryLikeData\\<TQueryLike\\>\nVersion: 11.x\nType Alias: InferQueryLikeData<TQueryLike>\n\nInferQueryLikeData<TQueryLike>: TQueryLike extends DecoratedQuery<infer $Def> ? $Def[\"output\"] : TQueryLike extends QueryLike<infer TRoot, infer TProcedure> ? inferTransformedProcedureOutput<TRoot, TProcedure> : never\n\nDefined in: packages/react-query/src/shared/polymorphism/queryLike.ts:50\n\nUse to unwrap a QueryLike's data output\n\nType Parameters​\nType Parameter\nTQueryLike\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/InferQueryLikeInput",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: InferQueryLikeInput\\<TQueryLike\\>\nVersion: 11.x\nType Alias: InferQueryLikeInput<TQueryLike>\n\nInferQueryLikeInput<TQueryLike>: TQueryLike extends DecoratedQuery<infer $Def> ? $Def[\"input\"] : TQueryLike extends QueryLike<any, infer TProcedure> ? inferProcedureInput<TProcedure> : never\n\nDefined in: packages/react-query/src/shared/polymorphism/queryLike.ts:40\n\nUse to unwrap a QueryLike's input\n\nType Parameters​\nType Parameter\nTQueryLike\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/MutationLike",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: MutationLike\\<TRoot, TProcedure\\>\nVersion: 11.x\nType Alias: MutationLike<TRoot, TProcedure>\n\nMutationLike<TRoot, TProcedure>: object\n\nDefined in: packages/react-query/src/shared/polymorphism/mutationLike.ts:15\n\nUse to describe a mutation route which matches a given mutation procedure's interface\n\nType Parameters​\nType Parameter\nTRoot extends AnyRootTypes\nTProcedure extends AnyProcedure\nType declaration​\nuseMutation()​\n\nuseMutation: (opts?) => InferMutationResult<TRoot, TProcedure>\n\nParameters​\nParameter\tType\nopts?\tInferMutationOptions<TRoot, TProcedure>\nReturns​\n\nInferMutationResult<TRoot, TProcedure>\n\nEdit this page"
  },
  {
    "title": "Type Alias: OutputWithCursor\\<TData, TCursor\\> | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/OutputWithCursor",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: OutputWithCursor\\<TData, TCursor\\>\nVersion: 11.x\nType Alias: OutputWithCursor<TData, TCursor>\n\nOutputWithCursor<TData, TCursor>: object\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:36\n\nType Parameters​\nType Parameter\tDefault type\nTData\t-\nTCursor\tany\nType declaration​\ncursor​\n\ncursor: TCursor | null\n\ndata​\n\ndata: TData\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/QueryLike",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: QueryLike\\<TRoot, TProcedure\\>\nVersion: 11.x\nType Alias: QueryLike<TRoot, TProcedure>\n\nQueryLike<TRoot, TProcedure>: object\n\nDefined in: packages/react-query/src/shared/polymorphism/queryLike.ts:19\n\nUse to request a query route which matches a given query procedure's interface\n\nType Parameters​\nType Parameter\nTRoot extends AnyRootTypes\nTProcedure extends AnyProcedure\nType declaration​\nuseQuery()​\n\nuseQuery: (variables, opts?) => InferQueryResult<TRoot, TProcedure>\n\nParameters​\nParameter\tType\nvariables\tinferProcedureInput<TProcedure>\nopts?\tInferQueryOptions<TRoot, TProcedure, any>\nReturns​\n\nInferQueryResult<TRoot, TProcedure>\n\nuseSuspenseQuery()​\n\nuseSuspenseQuery: (variables, opts?) => UseTRPCSuspenseQueryResult<inferProcedureOutput<TProcedure>, TRPCClientErrorLike<TRoot>>\n\nParameters​\nParameter\tType\nvariables\tinferProcedureInput<TProcedure>\nopts?\tInferQueryOptions<TRoot, TProcedure, any>\nReturns​\n\nUseTRPCSuspenseQueryResult<inferProcedureOutput<TProcedure>, TRPCClientErrorLike<TRoot>>\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/RouterLike",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: RouterLike\\<TRouter\\>\nVersion: 11.x\nType Alias: RouterLike<TRouter>\n\nRouterLike<TRouter>: RouterLikeInner<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>\n\nDefined in: packages/react-query/src/shared/polymorphism/routerLike.ts:14\n\nUse to describe a route path which matches a given route's interface\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/RouterLikeInner",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: RouterLikeInner\\<TRoot, TRecord\\>\nVersion: 11.x\nType Alias: RouterLikeInner<TRoot, TRecord>\n\nRouterLikeInner<TRoot, TRecord>: { [TKey in keyof TRecord]: TRecord[TKey] extends infer $Value ? $Value extends AnyQueryProcedure ? QueryLike<TRoot, $Value> : $Value extends AnyMutationProcedure ? MutationLike<TRoot, $Value> : $Value extends RouterRecord ? RouterLikeInner<TRoot, $Value> : never : never }\n\nDefined in: packages/react-query/src/shared/polymorphism/routerLike.ts:18\n\nType Parameters​\nType Parameter\nTRoot extends AnyRootTypes\nTRecord extends RouterRecord\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/TRPCFetchInfiniteQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: TRPCFetchInfiniteQueryOptions\\<TInput, TOutput, TError\\>\nVersion: 11.x\nType Alias: TRPCFetchInfiniteQueryOptions<TInput, TOutput, TError>\n\nTRPCFetchInfiniteQueryOptions<TInput, TOutput, TError>: DistributiveOmit<FetchInfiniteQueryOptions<TOutput, TError, TOutput, TRPCQueryKey, ExtractCursorType<TInput>>, \"queryKey\" | \"initialPageParam\"> & TRPCUseUtilsOptions & object\n\nDefined in: packages/react-query/src/internals/context.tsx:55\n\nType declaration​\ninitialCursor?​\n\noptional initialCursor: ExtractCursorType<TInput>\n\nType Parameters​\nType Parameter\nTInput\nTOutput\nTError\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/TRPCProvider",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: TRPCProvider()\\<TRouter, TSSRContext\\>\nVersion: 11.x\nType Alias: TRPCProvider()<TRouter, TSSRContext>\n\nTRPCProvider<TRouter, TSSRContext>: (props) => JSX.Element\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:237\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nTSSRContext\nParameters​\nParameter\tType\nprops\tTRPCProviderProps<TRouter, TSSRContext>\nReturns​\n\nJSX.Element\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/TRPCSubscriptionResult",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: TRPCSubscriptionResult\\<TOutput, TError\\>\nVersion: 11.x\nType Alias: TRPCSubscriptionResult<TOutput, TError>\n\nTRPCSubscriptionResult<TOutput, TError>: TRPCSubscriptionIdleResult<TOutput> | TRPCSubscriptionConnectingResult<TOutput, TError> | TRPCSubscriptionErrorResult<TOutput, TError> | TRPCSubscriptionPendingResult<TOutput>\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:225\n\nType Parameters​\nType Parameter\nTOutput\nTError\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/UseTRPCPrefetchInfiniteQueryOptions",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: UseTRPCPrefetchInfiniteQueryOptions\\<TInput, TOutput, TError\\>\nVersion: 11.x\nType Alias: UseTRPCPrefetchInfiniteQueryOptions<TInput, TOutput, TError>\n\nUseTRPCPrefetchInfiniteQueryOptions<TInput, TOutput, TError>: DistributiveOmit<FetchInfiniteQueryOptions<TOutput, TError, TOutput, any, ExtractCursorType<TInput>>, \"queryKey\" | \"initialPageParam\"> & TRPCUseQueryBaseOptions & object\n\nDefined in: packages/react-query/src/shared/hooks/types.ts:124\n\nType declaration​\ninitialCursor?​\n\noptional initialCursor: ExtractCursorType<TInput>\n\nType Parameters​\nType Parameter\nTInput\nTOutput\nTError\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/type-aliases/UtilsLike",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\ntype-aliases\nType Alias: UtilsLike\\<TRouter\\>\nVersion: 11.x\nType Alias: UtilsLike<TRouter>\n\nUtilsLike<TRouter>: DecoratedProcedureUtilsRecord<TRouter[\"_def\"][\"_config\"][\"$types\"], TRouter[\"_def\"][\"record\"]>\n\nDefined in: packages/react-query/src/shared/polymorphism/utilsLike.ts:7\n\nUse to describe a Utils/Context path which matches the given route's interface\n\nType Parameters​\nType Parameter\nTRouter extends AnyRouter\nEdit this page"
  },
  {
    "title": "Function: getQueryType() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/functions/getQueryType",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\nfunctions\nFunction: getQueryType()\nVersion: 11.x\nFunction: getQueryType()\n\ngetQueryType(utilName): QueryType\n\nDefined in: packages/react-query/src/shared/proxy/utilsProxy.ts:431\n\nParameters​\nParameter\tType\nutilName\tkeyof DecorateQueryProcedure<any, any> | keyof DecorateMutationProcedure<any, any>\nReturns​\n\nQueryType\n\nEdit this page"
  },
  {
    "title": "Function: TRPCContext() | tRPC",
    "url": "https://trpc.io/docs/typedoc/react-query/shared/functions/TRPCContext",
    "html": "API Reference (Auto-generated)\n@trpc/react-query\nshared\nfunctions\nFunction: TRPCContext()\nVersion: 11.x\nFunction: TRPCContext()\n\nTRPCContext(props): ReactNode\n\nDefined in: packages/react-query/src/internals/context.tsx:350\n\nParameters​\nParameter\tType\nprops\tProviderProps\nReturns​\n\nReactNode\n\nEdit this page"
  }
]
</file>

<file path="output/jobs/zod.json">
[
  {
    "title": "Basic usage | Zod",
    "url": "https://zod.dev/basics",
    "html": "Basic usage\nCopy markdown\nEdit this page\n\nThis page will walk you through the basics of creating schemas, parsing data, and using inferred types. For complete documentation on Zod's schema API, refer to Defining schemas.\n\nDefining a schema\n\nBefore you can do anything else, you need to define a schema. For the purposes of this guide, we'll use a simple object schema.\n\nZod\nZod Mini\nimport * as z from \"zod\"; \n \nconst Player = z.object({ \n  username: z.string(),\n  xp: z.number()\n});\nParsing data\n\nGiven any Zod schema, use .parse to validate an input. If it's valid, Zod returns a strongly-typed deep clone of the input.\n\nPlayer.parse({ username: \"billie\", xp: 100 }); \n// => returns { username: \"billie\", xp: 100 }\n\nNote — If your schema uses certain asynchronous APIs like async refinements or transforms, you'll need to use the .parseAsync() method instead.\n\nawait Player.parseAsync({ username: \"billie\", xp: 100 }); \nHandling errors\n\nWhen validation fails, the .parse() method will throw a ZodError instance with granular information about the validation issues.\n\nZod\nZod Mini\ntry {\n  Player.parse({ username: 42, xp: \"100\" });\n} catch(error){\n  if(error instanceof z.ZodError){\n    error.issues; \n    /* [\n      {\n        expected: 'string',\n        code: 'invalid_type',\n        path: [ 'username' ],\n        message: 'Invalid input: expected string'\n      },\n      {\n        expected: 'number',\n        code: 'invalid_type',\n        path: [ 'xp' ],\n        message: 'Invalid input: expected number'\n      }\n    ] */\n  }\n}\n\nTo avoid a try/catch block, you can use the .safeParse() method to get back a plain result object containing either the successfully parsed data or a ZodError. The result type is a discriminated union, so you can handle both cases conveniently.\n\nconst result = Player.safeParse({ username: 42, xp: \"100\" });\nif (!result.success) {\n  result.error;   // ZodError instance\n} else {\n  result.data;    // { username: string; xp: number }\n}\n\nNote — If your schema uses certain asynchronous APIs like async refinements or transforms, you'll need to use the .safeParseAsync() method instead.\n\nawait schema.safeParseAsync(\"hello\");\nInferring types\n\nZod infers a static type from your schema definitions. You can extract this type with the z.infer<> utility and use it however you like.\n\nconst Player = z.object({ \n  username: z.string(),\n  xp: z.number()\n});\n \n// extract the inferred type\ntype Player = z.infer<typeof Player>;\n \n// use it in your code\nconst player: Player = { username: \"billie\", xp: 100 };\n\nIn some cases, the input & output types of a schema can diverge. For instance, the .transform() API can convert the input from one type to another. In these cases, you can extract the input and output types independently:\n\nconst mySchema = z.string().transform((val) => val.length);\n \ntype MySchemaIn = z.input<typeof mySchema>;\n// => string\n \ntype MySchemaOut = z.output<typeof mySchema>; // equivalent to z.infer<typeof mySchema>\n// number\n\nNow that we have the basics covered, let's jump into the Schema API.\n\nIntro\n\nIntroduction to Zod - TypeScript-first schema validation library with static type inference\n\nDefining schemas\n\nComplete API reference for all Zod schema types, methods, and validation features"
  },
  {
    "title": "Intro | Zod",
    "url": "https://zod.dev/",
    "html": "Zod\n\nTypeScript-first schema validation with static type inference\nby @colinhacks\n\n\n\nWebsite\n  •  \nDiscord\n  •  \n𝕏\n  •  \nBluesky\n\n\n\n\n\nZod 4 is now stable! Read the release notes here.\n\n\n\n\n\nFeatured sponsor: Jazz\n\nInterested in featuring? Get in touch.\n\nIntroduction\n\nZod is a TypeScript-first validation library. Using Zod, you can define schemas you can use to validate data, from a simple string to a complex nested object.\n\nimport * as z from \"zod\";\n \nconst User = z.object({\n  name: z.string(),\n});\n \n// some untrusted data...\nconst input = { /* stuff */ };\n \n// the parsed result is validated and type safe!\nconst data = User.parse(input);\n \n// so you can use it with confidence :)\nconsole.log(data.name);\nFeatures\nZero external dependencies\nWorks in Node.js and all modern browsers\nTiny: 2kb core bundle (gzipped)\nImmutable API: methods return a new instance\nConcise interface\nWorks with TypeScript and plain JS\nBuilt-in JSON Schema conversion\nExtensive ecosystem\nInstallation\nnpm install zod\n\nZod is also available as @zod/zod on jsr.io.\n\nZod provides an MCP server that can be used by agents to search Zod's docs. To add to your editor, follow these instructions. Zod also provides an llms.txt file.\n\nRequirements\n\nZod is tested against TypeScript v5.5 and later. Older versions may work but are not officially supported.\n\n\"strict\"\n\nYou must enable strict mode in your tsconfig.json. This is a best practice for all TypeScript projects.\n\n// tsconfig.json\n{\n  // ...\n  \"compilerOptions\": {\n    // ...\n    \"strict\": true\n  }\n}\nEcosystem\n\nZod has a thriving ecosystem of libraries, tools, and integrations. Refer to the Ecosystem page for a complete list of libraries that support Zod or are built on top of it.\n\nResources\nAPI Libraries\nForm Integrations\nZod to X\nX to Zod\nMocking Libraries\nPowered by Zod\n\nI also contribute to the following projects, which I'd like to highlight:\n\ntRPC - End-to-end typesafe APIs, with support for Zod schemas\nReact Hook Form - Hook-based form validation with a Zod resolver\nzshy - Originally created as Zod's internal build tool. Bundler-free, batteries-included build tool for TypeScript libraries. Powered by tsc.\nSponsors\n\nSponsorship at any level is appreciated and encouraged. If you built a paid product using Zod, consider one of the corporate tiers.\n\nPlatinum\n\nCut code review time & bugs in half\n\ncoderabbit.ai\n\n\n\nGold\n\nThe API platform for sending notifications\n\ncourier.com\n\nGenerate better SDKs for your APIs\n\nliblab.com\n\nServerless Postgres — Ship faster\n\nneon.tech\n\nBuild AI apps and workflows with Retool AI\n\nretool.com\n\nGenerate best-in-class SDKs\n\nstainlessapi.com\n\nSDKs & Terraform providers for your API\n\nspeakeasy.com\n\n\nSilver\nsubtotal.com\njuno.build\nnitric.io\npropelauth.com\ncerbos.dev\nscalar.com\ntrigger.dev\ntransloadit.com\ninfisical.com\nwhop.com\ncryptojobslist.com\nplain.com\ninngest.com\nstoryblok.com\nmux.link/zod\n\n\nBronze\n\n\n\nMigration guide\n\nComplete changelog and migration guide for upgrading from Zod 3 to Zod 4\n\nBasic usage\n\nBasic usage guide covering schema definition, parsing data, error handling, and type inference"
  },
  {
    "title": "Defining schemas | Zod",
    "url": "https://zod.dev/api",
    "html": "Defining schemas\nCopy markdown\nEdit this page\n\nTo validate data, you must first define a schema. Schemas represent types, from simple primitive values to complex nested objects and arrays.\n\nPrimitives\nimport * as z from \"zod\";\n \n// primitive types\nz.string();\nz.number();\nz.bigint();\nz.boolean();\nz.symbol();\nz.undefined();\nz.null();\nCoercion\n\nTo coerce input data to the appropriate type, use z.coerce instead:\n\nz.coerce.string();    // String(input)\nz.coerce.number();    // Number(input)\nz.coerce.boolean();   // Boolean(input)\nz.coerce.bigint();    // BigInt(input)\n\nThe coerced variant of these schemas attempts to convert the input value to the appropriate type.\n\nconst schema = z.coerce.string();\n \nschema.parse(\"tuna\");    // => \"tuna\"\nschema.parse(42);        // => \"42\"\nschema.parse(true);      // => \"true\"\nschema.parse(null);      // => \"null\"\n\nThe input type of these coerced schemas is unknown by default. To specify a more specific input type, pass a generic parameter:\n\nconst A = z.coerce.number();\ntype AInput = z.input<typeof A>; // => unknown\n \nconst B = z.coerce.number<number>();\ntype BInput = z.input<typeof B>; // => number\nHow coercion works in Zod\nCustomizing the input type\nLiterals\n\nLiteral schemas represent a literal type, like \"hello world\" or 5.\n\nconst tuna = z.literal(\"tuna\");\nconst twelve = z.literal(12);\nconst twobig = z.literal(2n);\nconst tru = z.literal(true);\n\nTo represent the JavaScript literals null and undefined:\n\nz.null();\nz.undefined();\nz.void(); // equivalent to z.undefined()\n\nTo allow multiple literal values:\n\nconst colors = z.literal([\"red\", \"green\", \"blue\"]);\n \ncolors.parse(\"green\"); // ✅\ncolors.parse(\"yellow\"); // ❌\n\nTo extract the set of allowed values from a literal schema:\n\nZod\nZod Mini\ncolors.values; // => Set<\"red\" | \"green\" | \"blue\">\nStrings\n\nZod provides a handful of built-in string validation and transform APIs. To perform some common string validations:\n\nZod\nZod Mini\nz.string().max(5);\nz.string().min(5);\nz.string().length(5);\nz.string().regex(/^[a-z]+$/);\nz.string().startsWith(\"aaa\");\nz.string().endsWith(\"zzz\");\nz.string().includes(\"---\");\nz.string().uppercase();\nz.string().lowercase();\n\nTo perform some simple string transforms:\n\nZod\nZod Mini\nz.string().trim(); // trim whitespace\nz.string().toLowerCase(); // toLowerCase\nz.string().toUpperCase(); // toUpperCase\nz.string().normalize(); // normalize unicode characters\nString formats\n\nTo validate against some common string formats:\n\nz.email();\nz.uuid();\nz.url();\nz.httpUrl();       // http or https URLs only\nz.hostname();\nz.emoji();         // validates a single emoji character\nz.base64();\nz.base64url();\nz.hex();\nz.jwt();\nz.nanoid();\nz.cuid();\nz.cuid2();\nz.ulid();\nz.ipv4();\nz.ipv6();\nz.cidrv4();        // ipv4 CIDR block\nz.cidrv6();        // ipv6 CIDR block\nz.hash(\"sha256\");  // or \"sha1\", \"sha384\", \"sha512\", \"md5\"\nz.iso.date();\nz.iso.time();\nz.iso.datetime();\nz.iso.duration();\nEmails\n\nTo validate email addresses:\n\nz.email();\n\nBy default, Zod uses a comparatively strict email regex designed to validate normal email addresses containing common characters. It's roughly equivalent to the rules enforced by Gmail. To learn more about this regex, refer to this post.\n\n/^(?!\\.)(?!.*\\.\\.)([a-z0-9_'+\\-\\.]*)[a-z0-9_+-]@([a-z0-9][a-z0-9\\-]*\\.)+[a-z]{2,}$/i\n\nTo customize the email validation behavior, you can pass a custom regular expression to the pattern param.\n\nz.email({ pattern: /your regex here/ });\n\nZod exports several useful regexes you could use.\n\n// Zod's default email regex\nz.email();\nz.email({ pattern: z.regexes.email }); // equivalent\n \n// the regex used by browsers to validate input[type=email] fields\n// https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/email\nz.email({ pattern: z.regexes.html5Email });\n \n// the classic emailregex.com regex (RFC 5322)\nz.email({ pattern: z.regexes.rfc5322Email });\n \n// a loose regex that allows Unicode (good for intl emails)\nz.email({ pattern: z.regexes.unicodeEmail });\nUUIDs\n\nTo validate UUIDs:\n\nz.uuid();\n\nTo specify a particular UUID version:\n\n// supports \"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\"\nz.uuid({ version: \"v4\" });\n \n// for convenience\nz.uuidv4();\nz.uuidv6();\nz.uuidv7();\n\nThe RFC 9562/4122 UUID spec requires the first two bits of byte 8 to be 10. Other UUID-like identifiers do not enforce this constraint. To validate any UUID-like identifier:\n\nz.guid();\nURLs\n\nTo validate any WHATWG-compatible URL:\n\nconst schema = z.url();\n \nschema.parse(\"https://example.com\"); // ✅\nschema.parse(\"http://localhost\"); // ✅\nschema.parse(\"mailto:noreply@zod.dev\"); // ✅\n\nAs you can see this is quite permissive. Internally this uses the new URL() constructor to validate inputs; this behavior may differ across platforms and runtimes but it's the mostly rigorous way to validate URIs/URLs on any given JS runtime/engine.\n\nTo validate the hostname against a specific regex:\n\nconst schema = z.url({ hostname: /^example\\.com$/ });\n \nschema.parse(\"https://example.com\"); // ✅\nschema.parse(\"https://zombo.com\"); // ❌\n\nTo validate the protocol against a specific regex, use the protocol param.\n\nconst schema = z.url({ protocol: /^https$/ });\n \nschema.parse(\"https://example.com\"); // ✅\nschema.parse(\"http://example.com\"); // ❌\n\nWeb URLs — In many cases, you'll want to validate Web URLs specifically. Here's the recommended schema for doing so:\n\nconst httpUrl = z.url({\n  protocol: /^https?$/,\n  hostname: z.regexes.domain\n});\n\nThis restricts the protocol to http/https and ensures the hostname is a valid domain name with the z.regexes.domain regular expression:\n\n/^([a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\\.)+[a-zA-Z]{2,}$/\n\nTo normalize URLs, use the normalize flag. This will overwrite the input value with the normalized URL returned by new URL().\n\nnew URL(\"HTTP://ExAmPle.com:80/./a/../b?X=1#f oo\").href\n// => \"http://example.com/b?X=1#f%20oo\"\nISO datetimes\n\nAs you may have noticed, Zod string includes a few date/time related validations. These validations are regular expression based, so they are not as strict as a full date/time library. However, they are very convenient for validating user input.\n\nThe z.iso.datetime() method enforces ISO 8601; by default, no timezone offsets are allowed:\n\nconst datetime = z.iso.datetime();\n \ndatetime.parse(\"2020-01-01T06:15:00Z\"); // ✅\ndatetime.parse(\"2020-01-01T06:15:00.123Z\"); // ✅\ndatetime.parse(\"2020-01-01T06:15:00.123456Z\"); // ✅ (arbitrary precision)\ndatetime.parse(\"2020-01-01T06:15:00+02:00\"); // ❌ (offsets not allowed)\ndatetime.parse(\"2020-01-01T06:15:00\"); // ❌ (local not allowed)\n\nTo allow timezone offsets:\n\nconst datetime = z.iso.datetime({ offset: true });\n \n// allows timezone offsets\ndatetime.parse(\"2020-01-01T06:15:00+02:00\"); // ✅\n \n// basic offsets not allowed\ndatetime.parse(\"2020-01-01T06:15:00+02\");    // ❌\ndatetime.parse(\"2020-01-01T06:15:00+0200\");  // ❌\n \n// Z is still supported\ndatetime.parse(\"2020-01-01T06:15:00Z\"); // ✅ \n\nTo allow unqualified (timezone-less) datetimes:\n\nconst schema = z.iso.datetime({ local: true });\nschema.parse(\"2020-01-01T06:15:01\"); // ✅\nschema.parse(\"2020-01-01T06:15\"); // ✅ seconds optional\n\nTo constrain the allowable time precision. By default, seconds are optional and arbitrary sub-second precision is allowed.\n\nconst a = z.iso.datetime();\na.parse(\"2020-01-01T06:15Z\"); // ✅\na.parse(\"2020-01-01T06:15:00Z\"); // ✅\na.parse(\"2020-01-01T06:15:00.123Z\"); // ✅\n \nconst b = z.iso.datetime({ precision: -1 }); // minute precision (no seconds)\nb.parse(\"2020-01-01T06:15Z\"); // ✅\nb.parse(\"2020-01-01T06:15:00Z\"); // ❌\nb.parse(\"2020-01-01T06:15:00.123Z\"); // ❌\n \nconst c = z.iso.datetime({ precision: 0 }); // second precision only\nc.parse(\"2020-01-01T06:15Z\"); // ❌\nc.parse(\"2020-01-01T06:15:00Z\"); // ✅\nc.parse(\"2020-01-01T06:15:00.123Z\"); // ❌\n \nconst d = z.iso.datetime({ precision: 3 }); // millisecond precision only\nd.parse(\"2020-01-01T06:15Z\"); // ❌\nd.parse(\"2020-01-01T06:15:00Z\"); // ❌\nd.parse(\"2020-01-01T06:15:00.123Z\"); // ✅\nISO dates\n\nThe z.iso.date() method validates strings in the format YYYY-MM-DD.\n\nconst date = z.iso.date();\n \ndate.parse(\"2020-01-01\"); // ✅\ndate.parse(\"2020-1-1\"); // ❌\ndate.parse(\"2020-01-32\"); // ❌\nISO times\n\nThe z.iso.time() method validates strings in the format HH:MM[:SS[.s+]]. By default seconds are optional, as are sub-second deciams.\n\nconst time = z.iso.time();\n \ntime.parse(\"03:15\"); // ✅\ntime.parse(\"03:15:00\"); // ✅\ntime.parse(\"03:15:00.9999999\"); // ✅ (arbitrary precision)\n\nNo offsets of any kind are allowed.\n\ntime.parse(\"03:15:00Z\"); // ❌ (no `Z` allowed)\ntime.parse(\"03:15:00+02:00\"); // ❌ (no offsets allowed)\n\nUse the precision parameter to constrain the allowable decimal precision.\n\nz.iso.time({ precision: -1 }); // HH:MM (minute precision)\nz.iso.time({ precision: 0 }); // HH:MM:SS (second precision)\nz.iso.time({ precision: 1 }); // HH:MM:SS.s (decisecond precision)\nz.iso.time({ precision: 2 }); // HH:MM:SS.ss (centisecond precision)\nz.iso.time({ precision: 3 }); // HH:MM:SS.sss (millisecond precision)\nIP addresses\nconst ipv4 = z.ipv4();\nipv4.parse(\"192.168.0.0\"); // ✅\n \nconst ipv6 = z.ipv6();\nipv6.parse(\"2001:db8:85a3::8a2e:370:7334\"); // ✅\nIP blocks (CIDR)\n\nValidate IP address ranges specified with CIDR notation.\n\nconst cidrv4 = z.string().cidrv4();\ncidrv4.parse(\"192.168.0.0/24\"); // ✅\n \nconst cidrv6 = z.string().cidrv6();\ncidrv6.parse(\"2001:db8::/32\"); // ✅\nJWTs\n\nValidate JSON Web Tokens.\n\nz.jwt();\nz.jwt({ alg: \"HS256\" });\nHashes\n\nTo validate cryptographic hash values:\n\nz.hash(\"md5\");\nz.hash(\"sha1\");\nz.hash(\"sha256\");\nz.hash(\"sha384\");\nz.hash(\"sha512\");\n\nBy default, z.hash() expects hexadecimal encoding, as is conventional. You can specify a different encoding with the enc parameter:\n\nz.hash(\"sha256\", { enc: \"hex\" });       // default\nz.hash(\"sha256\", { enc: \"base64\" });    // base64 encoding\nz.hash(\"sha256\", { enc: \"base64url\" }); // base64url encoding (no padding)\nExpected lengths and padding\nCustom formats\n\nTo define your own string formats:\n\nconst coolId = z.stringFormat(\"cool-id\", ()=>{\n  // arbitrary validation here\n  return val.length === 100 && val.startsWith(\"cool-\");\n});\n \n// a regex is also accepted\nz.stringFormat(\"cool-id\", /^cool-[a-z0-9]{95}$/);\n\nThis schema will produce \"invalid_format\" issues, which are more descriptive than the \"custom\" errors produced by refinements or z.custom().\n\nmyFormat.parse(\"invalid input!\");\n// ZodError: [\n//   {\n//     \"code\": \"invalid_format\",\n//     \"format\": \"cool-id\",\n//     \"path\": [],\n//     \"message\": \"Invalid cool-id\"\n//   }\n// ]\nTemplate literals\n\nNew — Introduced in zod@4.0.\n\nTo define a template literal schema:\n\nconst schema = z.templateLiteral([ \"hello, \", z.string(), \"!\" ]);\n// `hello, ${string}!`\n\nThe z.templateLiteral API can handle any number of string literals (e.g. \"hello\") and schemas. Any schema with an inferred type that's assignable to string | number | bigint | boolean | null | undefined can be passed.\n\nz.templateLiteral([ \"hi there\" ]);\n// `hi there`\n \nz.templateLiteral([ \"email: \", z.string() ]);\n// `email: ${string}`\n \nz.templateLiteral([ \"high\", z.literal(5) ]);\n// `high5`\n \nz.templateLiteral([ z.nullable(z.literal(\"grassy\")) ]);\n// `grassy` | `null`\n \nz.templateLiteral([ z.number(), z.enum([\"px\", \"em\", \"rem\"]) ]);\n// `${number}px` | `${number}em` | `${number}rem`\nNumbers\n\nUse z.number() to validate numbers. It allows any finite number.\n\nconst schema = z.number();\n \nschema.parse(3.14);      // ✅\nschema.parse(NaN);       // ❌\nschema.parse(Infinity);  // ❌\n\nZod implements a handful of number-specific validations:\n\nZod\nZod Mini\nz.number().gt(5);\nz.number().gte(5);                     // alias .min(5)\nz.number().lt(5);\nz.number().lte(5);                     // alias .max(5)\nz.number().positive();       \nz.number().nonnegative();    \nz.number().negative(); \nz.number().nonpositive(); \nz.number().multipleOf(5);              // alias .step(5)\n\nIf (for some reason) you want to validate NaN, use z.nan().\n\nz.nan().parse(NaN);              // ✅\nz.nan().parse(\"anything else\");  // ❌\nIntegers\n\nTo validate integers:\n\nz.int();     // restricts to safe integer range\nz.int32();   // restrict to int32 range\nBigInts\n\nTo validate BigInts:\n\nz.bigint();\n\nZod includes a handful of bigint-specific validations.\n\nZod\nZod Mini\nz.bigint().gt(5n);\nz.bigint().gte(5n);                    // alias `.min(5n)`\nz.bigint().lt(5n);\nz.bigint().lte(5n);                    // alias `.max(5n)`\nz.bigint().positive(); \nz.bigint().nonnegative(); \nz.bigint().negative(); \nz.bigint().nonpositive(); \nz.bigint().multipleOf(5n);             // alias `.step(5n)`\nBooleans\n\nTo validate boolean values:\n\nz.boolean().parse(true); // => true\nz.boolean().parse(false); // => false\nDates\n\nUse z.date() to validate Date instances.\n\nz.date().safeParse(new Date()); // success: true\nz.date().safeParse(\"2022-01-12T06:15:00.000Z\"); // success: false\n\nTo customize the error message:\n\nz.date({\n  error: issue => issue.input === undefined ? \"Required\" : \"Invalid date\"\n});\n\nZod provides a handful of date-specific validations.\n\nZod\nZod Mini\nz.date().min(new Date(\"1900-01-01\"), { error: \"Too old!\" });\nz.date().max(new Date(), { error: \"Too young!\" });\nEnums\n\nUse z.enum to validate inputs against a fixed set of allowable string values.\n\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\n \nFishEnum.parse(\"Salmon\"); // => \"Salmon\"\nFishEnum.parse(\"Swordfish\"); // => ❌\n\nCareful — If you declare your string array as a variable, Zod won't be able to properly infer the exact values of each element.\n\nconst fish = [\"Salmon\", \"Tuna\", \"Trout\"];\n \nconst FishEnum = z.enum(fish);\ntype FishEnum = z.infer<typeof FishEnum>; // string\n\nTo fix this, always pass the array directly into the z.enum() function, or use as const.\n\nconst fish = [\"Salmon\", \"Tuna\", \"Trout\"] as const;\n \nconst FishEnum = z.enum(fish);\ntype FishEnum = z.infer<typeof FishEnum>; // \"Salmon\" | \"Tuna\" | \"Trout\"\n\nEnum-like object literals ({ [key: string]: string | number }) are supported.\n\nconst Fish = {\n  Salmon: \"Salmon\",\n  Tuna: \"Tuna\"\n} as const\n \nconst FishEnum = z.enum(Fish)\nFishEnum.parse(\"Salmon\"); // => \"Salmon\"\nFishEnum.parse(\"Swordfish\"); // => ❌\n\nYou can also pass in an externally-declared TypeScript enum.\n\nZod 4 — This replaces the z.nativeEnum() API in Zod 3.\n\nNote that using TypeScript's enum keyword is not recommended.\n\nenum Fish {\n  Salmon = \"Salmon\",\n  Tuna = \"Tuna\",\n  Trout = \"Trout\",\n}\n \nconst FishEnum = z.enum(Fish);\n.enum\n\nTo extract the schema's values as an enum-like object:\n\nZod\nZod Mini\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\n \nFishEnum.enum;\n// => { Salmon: \"Salmon\", Tuna: \"Tuna\", Trout: \"Trout\" }\n.exclude()\n\nTo create a new enum schema, excluding certain values:\n\nZod\nZod Mini\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\nconst TunaOnly = FishEnum.exclude([\"Salmon\", \"Trout\"]);\n.extract()\n\nTo create a new enum schema, extracting certain values:\n\nZod\nZod Mini\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\nconst SalmonAndTroutOnly = FishEnum.extract([\"Salmon\", \"Trout\"]);\nStringbools\n\n💎 New in Zod 4\n\nIn some cases (e.g. parsing environment variables) it's valuable to parse certain string \"boolish\" values to a plain boolean value. To support this, Zod 4 introduces z.stringbool():\n\nconst strbool = z.stringbool();\n \nstrbool.parse(\"true\")         // => true\nstrbool.parse(\"1\")            // => true\nstrbool.parse(\"yes\")          // => true\nstrbool.parse(\"on\")           // => true\nstrbool.parse(\"y\")            // => true\nstrbool.parse(\"enabled\")      // => true\n \nstrbool.parse(\"false\");       // => false\nstrbool.parse(\"0\");           // => false\nstrbool.parse(\"no\");          // => false\nstrbool.parse(\"off\");         // => false\nstrbool.parse(\"n\");           // => false\nstrbool.parse(\"disabled\");    // => false\n \nstrbool.parse(/* anything else */); // ZodError<[{ code: \"invalid_value\" }]>\n\nTo customize the truthy and falsy values:\n\n// these are the defaults\nz.stringbool({\n  truthy: [\"true\", \"1\", \"yes\", \"on\", \"y\", \"enabled\"],\n  falsy: [\"false\", \"0\", \"no\", \"off\", \"n\", \"disabled\"],\n});\n\nBy default the schema is case-insensitive; all inputs are converted to lowercase before comparison to the truthy/falsy values. To make it case-sensitive:\n\nz.stringbool({\n  case: \"sensitive\"\n});\nOptionals\n\nTo make a schema optional (that is, to allow undefined inputs).\n\nZod\nZod Mini\nz.optional(z.literal(\"yoda\")); // or z.literal(\"yoda\").optional()\n\nThis returns a ZodOptional instance that wraps the original schema. To extract the inner schema:\n\nZod\nZod Mini\noptionalYoda.unwrap(); // ZodLiteral<\"yoda\">\nNullables\n\nTo make a schema nullable (that is, to allow null inputs).\n\nZod\nZod Mini\nz.nullable(z.literal(\"yoda\")); // or z.literal(\"yoda\").nullable()\n\nThis returns a ZodNullable instance that wraps the original schema. To extract the inner schema:\n\nZod\nZod Mini\nnullableYoda.unwrap(); // ZodLiteral<\"yoda\">\nNullish\n\nTo make a schema nullish (both optional and nullable):\n\nZod\nZod Mini\nconst nullishYoda = z.nullish(z.literal(\"yoda\"));\n\nRefer to the TypeScript manual for more about the concept of nullish.\n\nUnknown\n\nZod aims to mirror TypeScript's type system one-to-one. As such, Zod provides APIs to represent the following special types:\n\n// allows any values\nz.any(); // inferred type: `any`\nz.unknown(); // inferred type: `unknown`\nNever\n\nNo value will pass validation.\n\nz.never(); // inferred type: `never`\nObjects\n\nTo define an object type:\n\n  // all properties are required by default\n  const Person = z.object({\n    name: z.string(),\n    age: z.number(),\n  });\n \n  type Person = z.infer<typeof Person>;\n  // => { name: string; age: number; }\n\nBy default, all properties are required. To make certain properties optional:\n\nZod\nZod Mini\nconst Dog = z.object({\n  name: z.string(),\n  age: z.number().optional(),\n});\n \nDog.parse({ name: \"Yeller\" }); // ✅\n\nBy default, unrecognized keys are stripped from the parsed result:\n\nDog.parse({ name: \"Yeller\", extraKey: true });\n// => { name: \"Yeller\" }\nz.strictObject\n\nTo define a strict schema that throws an error when unknown keys are found:\n\nconst StrictDog = z.strictObject({\n  name: z.string(),\n});\n \nStrictDog.parse({ name: \"Yeller\", extraKey: true });\n// ❌ throws\nz.looseObject\n\nTo define a loose schema that allows unknown keys to pass through:\n\nconst LooseDog = z.looseObject({\n  name: z.string(),\n});\n \nLooseDog.parse({ name: \"Yeller\", extraKey: true });\n// => { name: \"Yeller\", extraKey: true }\n.catchall()\n\nTo define a catchall schema that will be used to validate any unrecognized keys:\n\nZod\nZod Mini\nconst DogWithStrings = z.object({\n  name: z.string(),\n  age: z.number().optional(),\n}).catchall(z.string());\n \nDogWithStrings.parse({ name: \"Yeller\", extraKey: \"extraValue\" }); // ✅\nDogWithStrings.parse({ name: \"Yeller\", extraKey: 42 }); // ❌\n.shape\n\nTo access the internal schemas:\n\nZod\nZod Mini\nDog.shape.name; // => string schema\nDog.shape.age; // => number schema\n.keyof()\n\nTo create a ZodEnum schema from the keys of an object schema:\n\nZod\nZod Mini\nconst keySchema = Dog.keyof();\n// => ZodEnum<[\"name\", \"age\"]>\n.extend()\n\nTo add additional fields to an object schema:\n\nZod\nZod Mini\nconst DogWithBreed = Dog.extend({\n  breed: z.string(),\n});\n\nThis API can be used to overwrite existing fields! Be careful with this power! If the two schemas share keys, B will override A.\n\nAlternative: spread syntax — You can alternatively avoid .extend() altogether by creating a new object schema entirely. This makes the strictness level of the resulting schema visually obvious.\n\nconst DogWithBreed = z.object({ // or z.strictObject() or z.looseObject()...\n  ...Dog.shape,\n  breed: z.string(),\n});\n\nYou can also use this to merge multiple objects in one go.\n\nconst DogWithBreed = z.object({\n  ...Animal.shape,\n  ...Pet.shape,\n  breed: z.string(),\n});\n\nThis approach has a few advantages:\n\nIt uses language-level features (spread syntax) instead of library-specific APIs\nThe same syntax works in Zod and Zod Mini\nIt's more tsc-efficient — the .extend() method can be expensive on large schemas, and due to a TypeScript limitation it gets quadratically more expensive when calls are chained\nIf you wish, you can change the strictness level of the resulting schema by using z.strictObject() or z.looseObject()\n.safeExtend()\n\nThe .safeExtend() method works similarly to .extend(), but it won't let you overwrite an existing properly with a non-assignable schema. In other words, the result of .safeExtend() will have an inferred type that extends the original (in the TypeScript sense).\n\nz.object({ a: z.string() }).safeExtend({ a: z.string().min(5) }); // ✅\nz.object({ a: z.string() }).safeExtend({ a: z.any() }); // ✅\nz.object({ a: z.string() }).safeExtend({ a: z.number() });\n//                                       ^  ❌ ZodNumber is not assignable \n\nUse .safeExtend() to extend schemas that contain refinements. (Regular .extend() will throw an error when used on schemas with refinements.)\n\nZod\nZod Mini\nconst Base = z.object({\n  a: z.string(),\n  b: z.string()\n}).refine(user => user.a === user.b);\n \n// Extended inherits the refinements of Base\nconst Extended = Base.safeExtend({\n  a: z.string().min(10)\n});\n.pick()\n\nInspired by TypeScript's built-in Pick and Omit utility types, Zod provides dedicated APIs for picking and omitting certain keys from an object schema.\n\nStarting from this initial schema:\n\nconst Recipe = z.object({\n  title: z.string(),\n  description: z.string().optional(),\n  ingredients: z.array(z.string()),\n});\n// { title: string; description?: string | undefined; ingredients: string[] }\n\nTo pick certain keys:\n\nZod\nZod Mini\nconst JustTheTitle = Recipe.pick({ title: true });\n.omit()\n\nTo omit certain keys:\n\nZod\nZod Mini\nconst RecipeNoId = Recipe.omit({ id: true });\n.partial()\n\nFor convenience, Zod provides a dedicated API for making some or all properties optional, inspired by the built-in TypeScript utility type Partial.\n\nTo make all fields optional:\n\nZod\nZod Mini\nconst PartialRecipe = Recipe.partial();\n// { title?: string | undefined; description?: string | undefined; ingredients?: string[] | undefined }\n\nTo make certain properties optional:\n\nZod\nZod Mini\nconst RecipeOptionalIngredients = Recipe.partial({\n  ingredients: true,\n});\n// { title: string; description?: string | undefined; ingredients?: string[] | undefined }\n.required()\n\nZod provides an API for making some or all properties required, inspired by TypeScript's Required utility type.\n\nTo make all properties required:\n\nZod\nZod Mini\nconst RequiredRecipe = Recipe.required();\n// { title: string; description: string; ingredients: string[] }\n\nTo make certain properties required:\n\nZod\nZod Mini\nconst RecipeRequiredDescription = Recipe.required({description: true});\n// { title: string; description: string; ingredients: string[] }\nRecursive objects\n\nTo define a self-referential type, use a getter on the key. This lets JavaScript resolve the cyclical schema at runtime.\n\nconst Category = z.object({\n  name: z.string(),\n  get subcategories(){\n    return z.array(Category)\n  }\n});\n \ntype Category = z.infer<typeof Category>;\n// { name: string; subcategories: Category[] }\n\nThough recursive schemas are supported, passing cyclical data into Zod will cause an infinite loop.\n\nYou can also represent mutually recursive types:\n\nconst User = z.object({\n  email: z.email(),\n  get posts(){\n    return z.array(Post)\n  }\n});\n \nconst Post = z.object({\n  title: z.string(),\n  get author(){\n    return User\n  }\n});\n\nAll object APIs (.pick(), .omit(), .required(), .partial(), etc.) work as you'd expect.\n\nCircularity errors\n\nDue to TypeScript limitations, recursive type inference can be finicky, and it only works in certain scenarios. Some more complicated types may trigger recursive type errors like this:\n\nconst Activity = z.object({\n  name: z.string(),\n  get subactivities() {\n    // ^ ❌ 'subactivities' implicitly has return type 'any' because it does not\n    // have a return type annotation and is referenced directly or indirectly\n    // in one of its return expressions.ts(7023)\n \n    return z.nullable(z.array(Activity));\n  },\n});\n\nIn these cases, you can resolve the error with a type annotation on the offending getter:\n\nconst Activity = z.object({\n  name: z.string(),\n  get subactivities(): z.ZodNullable<z.ZodArray<typeof Activity>> {\n    return z.nullable(z.array(Activity));\n  },\n});\nArrays\n\nTo define an array schema:\n\nZod\nZod Mini\nconst stringArray = z.array(z.string()); // or z.string().array()\n\nTo access the inner schema for an element of the array.\n\nZod\nZod Mini\nstringArray.unwrap(); // => string schema\n\nZod implements a number of array-specific validations:\n\nZod\nZod Mini\nz.array(z.string()).min(5); // must contain 5 or more items\nz.array(z.string()).max(5); // must contain 5 or fewer items\nz.array(z.string()).length(5); // must contain 5 items exactly\nTuples\n\nUnlike arrays, tuples are typically fixed-length arrays that specify different schemas for each index.\n\nconst MyTuple = z.tuple([\n  z.string(),\n  z.number(),\n  z.boolean()\n]);\n \ntype MyTuple = z.infer<typeof MyTuple>;\n// [string, number, boolean]\n\nTo add a variadic (\"rest\") argument:\n\nconst variadicTuple = z.tuple([z.string()], z.number());\n// => [string, ...number[]];\nUnions\n\nUnion types (A | B) represent a logical \"OR\". Zod union schemas will check the input against each option in order. The first value that validates successfully is returned.\n\nconst stringOrNumber = z.union([z.string(), z.number()]);\n// string | number\n \nstringOrNumber.parse(\"foo\"); // passes\nstringOrNumber.parse(14); // passes\n\nTo extract the internal option schemas:\n\nZod\nZod Mini\nstringOrNumber.options; // [ZodString, ZodNumber]\nDiscriminated unions\n\nA discriminated union is a special kind of union in which a) all the options are object schemas that b) share a particular key (the \"discriminator\"). Based on the value of the discriminator key, TypeScript is able to \"narrow\" the type signature as you'd expect.\n\ntype MyResult =\n  | { status: \"success\"; data: string }\n  | { status: \"failed\"; error: string };\n \nfunction handleResult(result: MyResult){\n  if(result.status === \"success\"){\n    result.data; // string\n  } else {\n    result.error; // string\n  }\n}\n\nYou could represent it with a regular z.union(). But regular unions are naive—they check the input against each option in order and return the first one that passes. This can be slow for large unions.\n\nSo Zod provides a z.discriminatedUnion() API that uses a discriminator key to make parsing more efficient.\n\nconst MyResult = z.discriminatedUnion(\"status\", [\n  z.object({ status: z.literal(\"success\"), data: z.string() }),\n  z.object({ status: z.literal(\"failed\"), error: z.string() }),\n]);\n\nEach option should be an object schema whose discriminator prop (status in the example above) corresponds to some literal value or set of values, usually z.enum(), z.literal(), z.null(), or z.undefined().\n\nNesting discriminated unions\nIntersections\n\nIntersection types (A & B) represent a logical \"AND\".\n\nconst a = z.union([z.number(), z.string()]);\nconst b = z.union([z.number(), z.boolean()]);\nconst c = z.intersection(a, b);\n \ntype c = z.infer<typeof c>; // => number\n\nThis can be useful for intersecting two object types.\n\nconst Person = z.object({ name: z.string() });\ntype Person = z.infer<typeof Person>;\n \nconst Employee = z.object({ role: z.string() });\ntype Employee = z.infer<typeof Employee>;\n \nconst EmployedPerson = z.intersection(Person, Employee);\ntype EmployedPerson = z.infer<typeof EmployedPerson>;\n// Person & Employee\n\nWhen merging object schemas, prefer A.extend(B) over intersections. Using .extend() will give you a new object schema, whereas z.intersection(A, B) returns a ZodIntersection instance which lacks common object methods like pick and omit.\n\nRecords\n\nRecord schemas are used to validate types such as Record<string, string>.\n\nconst IdCache = z.record(z.string(), z.string());\ntype IdCache = z.infer<typeof IdCache>; // Record<string, string>\n \nIdCache.parse({\n  carlotta: \"77d2586b-9e8e-4ecf-8b21-ea7e0530eadd\",\n  jimmie: \"77d2586b-9e8e-4ecf-8b21-ea7e0530eadd\",\n});\n\nThe key schema can be any Zod schema that is assignable to string | number | symbol.\n\nconst Keys = z.union([z.string(), z.number(), z.symbol()]);\nconst AnyObject = z.record(Keys, z.unknown());\n// Record<string | number | symbol, unknown>\n\nTo create an object schemas containing keys defined by an enum:\n\nconst Keys = z.enum([\"id\", \"name\", \"email\"]);\nconst Person = z.record(Keys, z.string());\n// { id: string; name: string; email: string }\n\nZod 4 — In Zod 4, if you pass a z.enum as the first argument to z.record(), Zod will exhaustively check that all enum values exist in the input as keys. This behavior agrees with TypeScript:\n\ntype MyRecord = Record<\"a\" | \"b\", string>;\nconst myRecord: MyRecord = { a: \"foo\", b: \"bar\" }; // ✅\nconst myRecord: MyRecord = { a: \"foo\" }; // ❌ missing required key `b`\n\nIn Zod 3, exhaustiveness was not checked. To replicate the old behavior, use z.partialRecord().\n\nIf you want a partial record type, use z.partialRecord(). This skips the special exhaustiveness checks Zod normally runs with z.enum() and z.literal() key schemas.\n\nconst Keys = z.enum([\"id\", \"name\", \"email\"]).or(z.never()); \nconst Person = z.partialRecord(Keys, z.string());\n// { id?: string; name?: string; email?: string }\nA note on numeric keys\nMaps\nconst StringNumberMap = z.map(z.string(), z.number());\ntype StringNumberMap = z.infer<typeof StringNumberMap>; // Map<string, number>\n \nconst myMap: StringNumberMap = new Map();\nmyMap.set(\"one\", 1);\nmyMap.set(\"two\", 2);\n \nStringNumberMap.parse(myMap);\nSets\nconst NumberSet = z.set(z.number());\ntype NumberSet = z.infer<typeof NumberSet>; // Set<number>\n \nconst mySet: NumberSet = new Set();\nmySet.add(1);\nmySet.add(2);\nNumberSet.parse(mySet);\n\nSet schemas can be further constrained with the following utility methods.\n\nZod\nZod Mini\nz.set(z.string()).min(5); // must contain 5 or more items\nz.set(z.string()).max(5); // must contain 5 or fewer items\nz.set(z.string()).size(5); // must contain 5 items exactly\nFiles\n\nTo validate File instances:\n\nZod\nZod Mini\nconst fileSchema = z.file();\n \nfileSchema.min(10_000); // minimum .size (bytes)\nfileSchema.max(1_000_000); // maximum .size (bytes)\nfileSchema.mime(\"image/png\"); // MIME type\nfileSchema.mime([\"image/png\", \"image/jpeg\"]); // multiple MIME types\nPromises\n\nDeprecated — z.promise() is deprecated in Zod 4. There are vanishingly few valid uses cases for a Promise schema. If you suspect a value might be a Promise, simply await it before parsing it with Zod.\n\nSee z.promise() documentation\nInstanceof\n\nYou can use z.instanceof to check that the input is an instance of a class. This is useful to validate inputs against classes that are exported from third-party libraries.\n\nclass Test {\n  name: string;\n}\n \nconst TestSchema = z.instanceof(Test);\n \nTestSchema.parse(new Test()); // ✅\nTestSchema.parse(\"whatever\"); // ❌\nProperty\n\nTo validate a particular property of a class instance against a Zod schema:\n\nconst blobSchema = z.instanceof(URL).check(\n  z.property(\"protocol\", z.literal(\"https:\" as string, \"Only HTTPS allowed\"))\n);\n \nblobSchema.parse(new URL(\"https://example.com\")); // ✅\nblobSchema.parse(new URL(\"http://example.com\")); // ❌\n\nThe z.property() API works with any data type (but it's most useful when used in conjunction with z.instanceof()).\n\nconst blobSchema = z.string().check(\n  z.property(\"length\", z.number().min(10))\n);\n \nblobSchema.parse(\"hello there!\"); // ✅\nblobSchema.parse(\"hello.\"); // ❌\nRefinements\n\nEvery Zod schema stores an array of refinements. Refinements are a way to perform custom validation that Zod doesn't provide a native API for.\n\n.refine()\nZod\nZod Mini\nconst myString = z.string().refine((val) => val.length <= 255);\n\nRefinement functions should never throw. Instead they should return a falsy value to signal failure. Thrown errors are not caught by Zod.\n\nerror\n\nTo customize the error message:\n\nZod\nZod Mini\nconst myString = z.string().refine((val) => val.length > 8, { \n  error: \"Too short!\" \n});\nabort\n\nBy default, validation issues from checks are considered continuable; that is, Zod will execute all checks in sequence, even if one of them causes a validation error. This is usually desirable, as it means Zod can surface as many errors as possible in one go.\n\nZod\nZod Mini\nconst myString = z.string()\n  .refine((val) => val.length > 8, { error: \"Too short!\" })\n  .refine((val) => val === val.toLowerCase(), { error: \"Must be lowercase\" });\n  \n \nconst result = myString.safeParse(\"OH NO\");\nresult.error?.issues;\n/* [\n  { \"code\": \"custom\", \"message\": \"Too short!\" },\n  { \"code\": \"custom\", \"message\": \"Must be lowercase\" }\n] */\n\nTo mark a particular refinement as non-continuable, use the abort parameter. Validation will terminate if the check fails.\n\nZod\nZod Mini\nconst myString = z.string()\n  .refine((val) => val.length > 8, { error: \"Too short!\", abort: true })\n  .refine((val) => val === val.toLowerCase(), { error: \"Must be lowercase\", abort: true });\n \n \nconst result = myString.safeParse(\"OH NO\");\nresult.error?.issues;\n// => [{ \"code\": \"custom\", \"message\": \"Too short!\" }]\npath\n\nTo customize the error path, use the path parameter. This is typically only useful in the context of object schemas.\n\nZod\nZod Mini\nconst passwordForm = z\n  .object({\n    password: z.string(),\n    confirm: z.string(),\n  })\n  .refine((data) => data.password === data.confirm, {\n    message: \"Passwords don't match\",\n    path: [\"confirm\"], // path of error\n  });\n\nThis will set the path parameter in the associated issue:\n\nZod\nZod Mini\nconst result = passwordForm.safeParse({ password: \"asdf\", confirm: \"qwer\" });\nresult.error.issues;\n/* [{\n  \"code\": \"custom\",\n  \"path\": [ \"confirm\" ],\n  \"message\": \"Passwords don't match\"\n}] */\n\nTo define an asynchronous refinement, just pass an async function:\n\nconst userId = z.string().refine(async (id) => {\n  // verify that ID exists in database\n  return true;\n});\n\nIf you use async refinements, you must use the .parseAsync method to parse data! Otherwise Zod will throw an error.\n\nZod\nZod Mini\nconst result = await userId.parseAsync(\"abc123\");\nwhen\n\nNote — This is a power user feature and can absolutely be abused in ways that will increase the probability of uncaught errors originating from inside your refinements.\n\nBy default, refinements don't run if any non-continuable issues have already been encountered. Zod is careful to ensure the type signature of the value is correct before passing it into any refinement functions.\n\nconst schema = z.string().refine((val) => {\n  return val.length > 8\n});\n \nschema.parse(1234); // invalid_type: refinement won't be executed\n\nIn some cases, you want finer control over when refinements run. For instance consider this \"password confirm\" check:\n\nZod\nZod Mini\nconst schema = z\n  .object({\n    password: z.string().min(8),\n    confirmPassword: z.string(),\n    anotherField: z.string(),\n  })\n  .refine((data) => data.password === data.confirmPassword, {\n    message: \"Passwords do not match\",\n    path: [\"confirmPassword\"],\n  });\n \nschema.parse({\n  password: \"asdf\",\n  confirmPassword: \"asdf\",\n  anotherField: 1234 // ❌ this error will prevent the password check from running\n});\n\nAn error on anotherField will prevent the password confirmation check from executing, even though the check doesn't depend on anotherField. To control when a refinement will run, use the when parameter:\n\nZod\nZod Mini\nconst schema = z\n  .object({\n    password: z.string().min(8),\n    confirmPassword: z.string(),\n    anotherField: z.string(),\n  })\n  .refine((data) => data.password === data.confirmPassword, {\n    message: \"Passwords do not match\",\n    path: [\"confirmPassword\"],\n \n    // run if password & confirmPassword are valid\n    when(payload) { \n      return schema \n        .pick({ password: true, confirmPassword: true }) \n        .safeParse(payload.value).success; \n    },  \n  });\n \nschema.parse({\n  password: \"asdf\",\n  confirmPassword: \"asdf\",\n  anotherField: 1234 // ❌ this error will not prevent the password check from running\n});\n.superRefine()\n\nThe regular .refine API only generates a single issue with a \"custom\" error code, but .superRefine() makes it possible to create multiple issues using any of Zod's internal issue types.\n\nZod\nZod Mini\nconst UniqueStringArray = z.array(z.string()).superRefine((val, ctx) => {\n  if (val.length > 3) {\n    ctx.addIssue({\n      code: \"too_big\",\n      maximum: 3,\n      origin: \"array\",\n      inclusive: true,\n      message: \"Too many items 😡\",\n      input: val,\n    });\n  }\n \n  if (val.length !== new Set(val).size) {\n    ctx.addIssue({\n      code: \"custom\",\n      message: `No duplicates allowed.`,\n      input: val,\n    });\n  }\n});\n \n.check()\n\nNote — The .check() API is a more low-level API that's generally more complex than .superRefine(). It can be faster in performance-sensitive code paths, but it's also more verbose.\n\nView example\nCodecs\n\nNew — Introduced in Zod 4.1. Refer to the dedicated Codecs page for more information.\n\nCodecs are a special kind of schema that implement bidirectional transformations between two other schemas.\n\nconst stringToDate = z.codec(\n  z.iso.datetime(),  // input schema: ISO date string\n  z.date(),          // output schema: Date object\n  {\n    decode: (isoString) => new Date(isoString), // ISO string → Date\n    encode: (date) => date.toISOString(),       // Date → ISO string\n  }\n);\n\nA regular .parse() operations performs the forward transform. It calls the codec's decode function.\n\nstringToDate.parse(\"2024-01-15T10:30:00.000Z\"); // => Date\n\nYou can alternatively use the top-level z.decode() function. Unlike .parse() (which accepts unknown input), z.decode() expects a strongly-typed input (string in this example).\n\nz.decode(stringToDate, \"2024-01-15T10:30:00.000Z\"); // => Date\n\nTo perform the reverse transform, use the inverse: z.encode().\n\nz.encode(stringToDate, new Date(\"2024-01-15\")); // => \"2024-01-15T00:00:00.000Z\"\n\nRefer to the dedicated Codecs page for more information. That page contains implementations for commonly-needed codecs that you can copy/paste into your project:\n\nstringToNumber\nstringToInt\nstringToBigInt\nnumberToBigInt\nisoDatetimeToDate\nepochSecondsToDate\nepochMillisToDate\njsonCodec\nutf8ToBytes\nbytesToUtf8\nbase64ToBytes\nbase64urlToBytes\nhexToBytes\nstringToURL\nstringToHttpURL\nuriComponent\nstringToBoolean\nPipes\n\nSchemas can be chained together into \"pipes\". Pipes are primarily useful when used in conjunction with Transforms.\n\nZod\nZod Mini\nconst stringToLength = z.string().pipe(z.transform(val => val.length));\n \nstringToLength.parse(\"hello\"); // => 5\nTransforms\n\nNote — For bi-directional transforms, use codecs.\n\nTransforms are a special kind of schema that perform a unidirectional transformation. Instead of validating input, they accept anything and perform some transformation on the data. To define a transform:\n\nZod\nZod Mini\nconst castToString = z.transform((val) => String(val));\n \ncastToString.parse(\"asdf\"); // => \"asdf\"\ncastToString.parse(123); // => \"123\"\ncastToString.parse(true); // => \"true\"\n\nRefinement functions should never throw. Thrown errors are not caught by Zod.\n\nTo perform validation logic inside a transform, use ctx. To report a validation issue, push a new issue onto ctx.issues (similar to the .check() API).\n\nconst coercedInt = z.transform((val, ctx) => {\n  try {\n    const parsed = Number.parseInt(String(val));\n    return parsed;\n  } catch (e) {\n    ctx.issues.push({\n      code: \"custom\",\n      message: \"Not a number\",\n      input: val,\n    });\n \n    // this is a special constant with type `never`\n    // returning it lets you exit the transform without impacting the inferred return type\n    return z.NEVER;\n  }\n});\n\nMost commonly, transforms are used in conjunction with Pipes. This combination is useful for performing some initial validation, then transforming the parsed data into another form.\n\nZod\nZod Mini\nconst stringToLength = z.string().pipe(z.transform(val => val.length));\n \nstringToLength.parse(\"hello\"); // => 5\n.transform()\n\nPiping some schema into a transform is a common pattern, so Zod provides a convenience .transform() method.\n\nZod\nZod Mini\nconst stringToLength = z.string().transform(val => val.length); \n\nTransforms can also be async:\n\nZod\nZod Mini\nconst idToUser = z\n  .string()\n  .transform(async (id) => {\n    // fetch user from database\n    return db.getUserById(id); \n  });\n \nconst user = await idToUser.parseAsync(\"abc123\");\n\nIf you use async transforms, you must use a .parseAsync or .safeParseAsync when parsing data! Otherwise Zod will throw an error.\n\n.preprocess()\n\nPiping a transform into another schema is another common pattern, so Zod provides a convenience z.preprocess() function.\n\nconst coercedInt = z.preprocess((val) => {\n  if (typeof val === \"string\") {\n    return Number.parseInt(val);\n  }\n  return val;\n}, z.int());\nDefaults\n\nTo set a default value for a schema:\n\nZod\nZod Mini\nconst defaultTuna = z.string().default(\"tuna\");\n \ndefaultTuna.parse(undefined); // => \"tuna\"\n\nAlternatively, you can pass a function which will be re-executed whenever a default value needs to be generated:\n\nZod\nZod Mini\nconst randomDefault = z.number().default(Math.random);\n \nrandomDefault.parse(undefined);    // => 0.4413456736055323\nrandomDefault.parse(undefined);    // => 0.1871840107401901\nrandomDefault.parse(undefined);    // => 0.7223408162401552\nPrefaults\n\nIn Zod, setting a default value will short-circuit the parsing process. If the input is undefined, the default value is eagerly returned. As such, the default value must be assignable to the output type of the schema.\n\nconst schema = z.string().transform(val => val.length).default(0);\nschema.parse(undefined); // => 0\n\nSometimes, it's useful to define a prefault (\"pre-parse default\") value. If the input is undefined, the prefault value will be parsed instead. The parsing process is not short circuited. As such, the prefault value must be assignable to the input type of the schema.\n\nz.string().transform(val => val.length).prefault(\"tuna\");\nschema.parse(undefined); // => 4\n\nThis is also useful if you want to pass some input value through some mutating refinements.\n\nconst a = z.string().trim().toUpperCase().prefault(\"  tuna  \");\na.parse(undefined); // => \"TUNA\"\n \nconst b = z.string().trim().toUpperCase().default(\"  tuna  \");\nb.parse(undefined); // => \"  tuna  \"\nCatch\n\nUse .catch() to define a fallback value to be returned in the event of a validation error:\n\nZod\nZod Mini\nconst numberWithCatch = z.number().catch(42);\n \nnumberWithCatch.parse(5); // => 5\nnumberWithCatch.parse(\"tuna\"); // => 42\n\nAlternatively, you can pass a function which will be re-executed whenever a catch value needs to be generated.\n\nZod\nZod Mini\nconst numberWithRandomCatch = z.number().catch((ctx) => {\n  ctx.error; // the caught ZodError\n  return Math.random();\n});\n \nnumberWithRandomCatch.parse(\"sup\"); // => 0.4413456736055323\nnumberWithRandomCatch.parse(\"sup\"); // => 0.1871840107401901\nnumberWithRandomCatch.parse(\"sup\"); // => 0.7223408162401552\nBranded types\n\nTypeScript's type system is structural, meaning that two types that are structurally equivalent are considered the same.\n\ntype Cat = { name: string };\ntype Dog = { name: string };\n \nconst pluto: Dog = { name: \"pluto\" };\nconst simba: Cat = pluto; // works fine\n\nIn some cases, it can be desirable to simulate nominal typing inside TypeScript. This can be achieved with branded types (also known as \"opaque types\").\n\nconst Cat = z.object({ name: z.string() }).brand<\"Cat\">();\nconst Dog = z.object({ name: z.string() }).brand<\"Dog\">();\n \ntype Cat = z.infer<typeof Cat>; // { name: string } & z.$brand<\"Cat\">\ntype Dog = z.infer<typeof Dog>; // { name: string } & z.$brand<\"Dog\">\n \nconst pluto = Dog.parse({ name: \"pluto\" });\nconst simba: Cat = pluto; // ❌ not allowed\n\nUnder the hood, this works by attaching a \"brand\" to the schema's inferred type.\n\nconst Cat = z.object({ name: z.string() }).brand<\"Cat\">();\ntype Cat = z.infer<typeof Cat>; // { name: string } & z.$brand<\"Cat\">\n\nWith this brand, any plain (unbranded) data structures are no longer assignable to the inferred type. You have to parse some data with the schema to get branded data.\n\nNote that branded types do not affect the runtime result of .parse. It is a static-only construct.\n\nReadonly\n\nTo mark a schema as readonly:\n\nZod\nZod Mini\nconst ReadonlyUser = z.object({ name: z.string() }).readonly();\ntype ReadonlyUser = z.infer<typeof ReadonlyUser>;\n// Readonly<{ name: string }>\n\nThe inferred type of the new schemas will be marked as readonly. Note that in TypeScript, this only affects objects, arrays, tuples, Set, and Map:\n\nZod\nZod Mini\nz.object({ name: z.string() }).readonly(); // { readonly name: string }\nz.array(z.string()).readonly(); // readonly string[]\nz.tuple([z.string(), z.number()]).readonly(); // readonly [string, number]\nz.map(z.string(), z.date()).readonly(); // ReadonlyMap<string, Date>\nz.set(z.string()).readonly(); // ReadonlySet<string>\n\nInputs will be parsed like normal, then the result will be frozen with Object.freeze() to prevent modifications.\n\nZod\nZod Mini\nconst result = ReadonlyUser.parse({ name: \"fido\" });\nresult.name = \"simba\"; // throws TypeError\nJSON\n\nTo validate any JSON-encodable value:\n\nconst jsonSchema = z.json();\n\nThis is a convenience API that returns the following union schema:\n\nconst jsonSchema = z.lazy(() => {\n  return z.union([\n    z.string(params), \n    z.number(), \n    z.boolean(), \n    z.null(), \n    z.array(jsonSchema), \n    z.record(z.string(), jsonSchema)\n  ]);\n});\nFunctions\n\nZod provides a z.function() utility for defining Zod-validated functions. This way, you can avoid intermixing validation code with your business logic.\n\nconst MyFunction = z.function({\n  input: [z.string()], // parameters (must be an array or a ZodTuple)\n  output: z.number()  // return type\n});\n \ntype MyFunction = z.infer<typeof MyFunction>;\n// (input: string) => number\n\nFunction schemas have an .implement() method which accepts a function and returns a new function that automatically validates its inputs and outputs.\n\nconst computeTrimmedLength = MyFunction.implement((input) => {\n  // TypeScript knows input is a string!\n  return input.trim().length;\n});\n \ncomputeTrimmedLength(\"sandwich\"); // => 8\ncomputeTrimmedLength(\" asdf \"); // => 4\n\nThis function will throw a ZodError if the input is invalid:\n\ncomputeTrimmedLength(42); // throws ZodError\n\nIf you only care about validating inputs, you can omit the output field.\n\nconst MyFunction = z.function({\n  input: [z.string()], // parameters (must be an array or a ZodTuple)\n});\n \nconst computeTrimmedLength = MyFunction.implement((input) => input.trim.length);\n\nUse the .implementAsync() method to create an async function.\n\nconst computeTrimmedLengthAsync = MyFunction.implementAsync(\n  async (input) => input.trim().length\n);\n \ncomputeTrimmedLengthAsync(\"sandwich\"); // => Promise<8>\nCustom\n\nYou can create a Zod schema for any TypeScript type by using z.custom(). This is useful for creating schemas for types that are not supported by Zod out of the box, such as template string literals.\n\nconst px = z.custom<`${number}px`>((val) => {\n  return typeof val === \"string\" ? /^\\d+px$/.test(val) : false;\n});\n \ntype px = z.infer<typeof px>; // `${number}px`\n \npx.parse(\"42px\"); // \"42px\"\npx.parse(\"42vw\"); // throws;\n\nIf you don't provide a validation function, Zod will allow any value. This can be dangerous!\n\nz.custom<{ arg: string }>(); // performs no validation\n\nYou can customize the error message and other options by passing a second argument. This parameter works the same way as the params parameter of .refine.\n\nz.custom<...>((val) => ..., \"custom error message\");\n\nBasic usage\n\nBasic usage guide covering schema definition, parsing data, error handling, and type inference\n\nCustomizing errors\n\nGuide to customizing validation error messages and error handling patterns"
  },
  {
    "title": "Customizing errors | Zod",
    "url": "https://zod.dev/error-customization",
    "html": "Customizing errors\nCopy markdown\nEdit this page\n\nIn Zod, validation errors are surfaced as instances of the z.core.$ZodError class.\n\nThe ZodError class in the zod package is a subclass that implements some additional convenience methods.\n\nInstances of $ZodError contain an .issues array. Each issue contains a human-readable message and additional structured metadata about the issue.\n\nZod\nZod Mini\nimport * as z from \"zod\";\n \nconst result = z.string().safeParse(12); // { success: false, error: ZodError }\nresult.error.issues;\n// [\n//   {\n//     expected: 'string',\n//     code: 'invalid_type',\n//     path: [],\n//     message: 'Invalid input: expected string, received number'\n//   }\n// ]\n\nEvery issue contains a message property with a human-readable error message. Error messages can be customized in a number of ways.\n\nThe error param\n\nVirtually every Zod API accepts an optional error message.\n\nz.string(\"Not a string!\");\n\nThis custom error will show up as the message property of any validation issues that originate from this schema.\n\nz.string(\"Not a string!\").parse(12);\n// ❌ throws ZodError {\n//   issues: [\n//     {\n//       expected: 'string',\n//       code: 'invalid_type',\n//       path: [],\n//       message: 'Not a string!'   <-- 👀 custom error message\n//     }\n//   ]\n// }\n\nAll z functions and schema methods accept custom errors.\n\nZod\nZod Mini\nz.string(\"Bad!\");\nz.string().min(5, \"Too short!\");\nz.uuid(\"Bad UUID!\");\nz.iso.date(\"Bad date!\");\nz.array(z.string(), \"Not an array!\");\nz.array(z.string()).min(5, \"Too few items!\");\nz.set(z.string(), \"Bad set!\");\n\nIf you prefer, you can pass a params object with an error parameter instead.\n\nZod\nZod Mini\nz.string({ error: \"Bad!\" });\nz.string().min(5, { error: \"Too short!\" });\nz.uuid({ error: \"Bad UUID!\" });\nz.iso.date({ error: \"Bad date!\" });\nz.array(z.string(), { error: \"Bad array!\" });\nz.array(z.string()).min(5, { error: \"Too few items!\" });\nz.set(z.string(), { error: \"Bad set!\" });\n\nThe error param optionally accepts a function. An error customization function is known as an error map in Zod terminology. The error map will run at parse time if a validation error occurs.\n\nz.string({ error: ()=>`[${Date.now()}]: Validation failure.` });\n\nNote — In Zod v3, there were separate params for message (a string) and errorMap (a function). These have been unified in Zod 4 as error.\n\nThe error map receives a context object you can use to customize the error message based on the validation issue.\n\nz.string({\n  error: (iss) => iss.input === undefined ? \"Field is required.\" : \"Invalid input.\"\n});\n\nFor advanced cases, the iss object provides additional information you can use to customize the error.\n\nz.string({\n  error: (iss) => {\n    iss.code; // the issue code\n    iss.input; // the input data\n    iss.inst; // the schema/check that originated this issue\n    iss.path; // the path of the error\n  },\n});\n\nDepending on the API you are using, there may be additional properties available. Use TypeScript's autocomplete to explore the available properties.\n\nz.string().min(5, {\n  error: (iss) => {\n    // ...the same as above\n    iss.minimum; // the minimum value\n    iss.inclusive; // whether the minimum is inclusive\n    return `Password must have ${iss.minimum} characters or more`;\n  },\n});\n\nReturn undefined to avoid customizing the error message and fall back to the default message. (More specifically, Zod will yield control to the next error map in the precedence chain.) This is useful for selectively customizing certain error messages but not others.\n\nz.int64({\n  error: (issue) => {\n    // override too_big error message\n    if (issue.code === \"too_big\") {\n      return { message: `Value must be <${issue.maximum}` };\n    }\n \n    //  defer to default\n    return undefined;\n  },\n});\nPer-parse error customization\n\nTo customize errors on a per-parse basis, pass an error map into the parse method:\n\nconst schema = z.string();\n \nschema.parse(12, {\n  error: iss => \"per-parse custom error\"\n});\n\nThis has lower precedence than any schema-level custom messages.\n\nconst schema = z.string({ error: \"highest priority\" });\nconst result = schema.safeParse(12, {\n  error: (iss) => \"lower priority\",\n});\n \nresult.error.issues;\n// [{ message: \"highest priority\", ... }]\n\nThe iss object is a discriminated union of all possible issue types. Use the code property to discriminate between them.\n\nFor a breakdown of all Zod issue codes, see the zod/v4/core documentation.\n\nconst result = schema.safeParse(12, {\n  error: (iss) => {\n    if (iss.code === \"invalid_type\") {\n      return `invalid type, expected ${iss.expected}`;\n    }\n    if (iss.code === \"too_small\") {\n      return `minimum is ${iss.minimum}`;\n    }\n    // ...\n  }\n});\nInclude input in issues\n\nBy default, Zod does not include input data in issues. This is to prevent unintentional logging of potentially sensitive input data. To include the input data in each issue, use the reportInput flag:\n\nz.string().parse(12, {\n  reportInput: true\n})\n \n// ZodError: [\n//   {\n//     \"expected\": \"string\",\n//     \"code\": \"invalid_type\",\n//     \"input\": 12, // 👀\n//     \"path\": [],\n//     \"message\": \"Invalid input: expected string, received number\"\n//   }\n// ]\nGlobal error customization\n\nTo specify a global error map, use z.config() to set Zod's customError configuration setting:\n\nz.config({\n  customError: (iss) => {\n    return \"globally modified error\";\n  },\n});\n\nGlobal error messages have lower precedence than schema-level or per-parse error messages.\n\nThe iss object is a discriminated union of all possible issue types. Use the code property to discriminate between them.\n\nFor a breakdown of all Zod issue codes, see the zod/v4/core documentation.\n\nconst result = schema.safeParse(12, {\n  error: (iss) => {\n    if (iss.code === \"invalid_type\") {\n      return `invalid type, expected ${iss.expected}`;\n    }\n    if (iss.code === \"too_small\") {\n      return `minimum is ${iss.minimum}`;\n    }\n    // ...\n  }\n})\nInternationalization\n\nTo support internationalization of error message, Zod provides several built-in locales. These are exported from the zod/v4/core package.\n\nNote — The regular zod library automatically loads the en locale automatically. Zod Mini does not load any locale by default; instead all error messages default to Invalid input.\n\nZod\nZod Mini\nimport * as z from \"zod\";\nimport { en } from \"zod/locales\"\n \nz.config(en());\n\nTo lazily load a locale, consider dynamic imports:\n\nimport * as z from \"zod\";\n \nasync function loadLocale(locale: string) {\n  const { default: locale } = await import(`zod/v4/locales/${locale}.js`);\n  z.config(locale());\n};\n \nawait loadLocale(\"fr\");\n\nFor convenience, all locales are exported as z.locales from \"zod\". In some bundlers, this may not be tree-shakable.\n\nZod\nZod Mini\nimport * as z from \"zod\";\n \nz.config(z.locales.en());\nLocales\n\nThe following locales are available:\n\nar — Arabic\naz — Azerbaijani\nbe — Belarusian\nbg — Bulgarian\nca — Catalan\ncs — Czech\nda — Danish\nde — German\nen — English\neo — Esperanto\nes — Spanish\nfa — Farsi\nfi — Finnish\nfr — French\nfrCA — Canadian French\nhe — Hebrew\nhu — Hungarian\nid — Indonesian\nis — Icelandic\nit — Italian\nja — Japanese\nka — Georgian\nkm — Khmer\nko — Korean\nlt — Lithuanian\nmk — Macedonian\nms — Malay\nnl — Dutch\nno — Norwegian\nota — Türkî\nps — Pashto\npl — Polish\npt — Portuguese\nru — Russian\nsl — Slovenian\nsv — Swedish\nta — Tamil\nth — Thai\ntr — Türkçe\nuk — Ukrainian\nur — Urdu\nvi — Tiếng Việt\nzhCN — Simplified Chinese\nzhTW — Traditional Chinese\nyo — Yorùbá\nError precedence\n\nBelow is a quick reference for determining error precedence: if multiple error customizations have been defined, which one takes priority? From highest to lowest priority:\n\nSchema-level error — Any error message \"hard coded\" into a schema definition.\nz.string(\"Not a string!\");\nPer-parse error — A custom error map passed into the .parse() method.\nz.string().parse(12, {\n  error: (iss) => \"My custom error\"\n});\nGlobal error map — A custom error map passed into z.config().\nz.config({\n  customError: (iss) => \"My custom error\"\n});\nLocale error map — A custom error map passed into z.config().\nz.config(z.locales.en());\n\nDefining schemas\n\nComplete API reference for all Zod schema types, methods, and validation features\n\nFormatting errors\n\nUtilities for formatting and displaying Zod errors"
  },
  {
    "title": "Formatting errors | Zod",
    "url": "https://zod.dev/error-formatting",
    "html": "Formatting errors\nCopy markdown\nEdit this page\n\nZod emphasizes completeness and correctness in its error reporting. In many cases, it's helpful to convert the $ZodError to a more useful format. Zod provides some utilities for this.\n\nConsider this simple object schema.\n\nimport * as z from \"zod\";\n \nconst schema = z.strictObject({\n  username: z.string(),\n  favoriteNumbers: z.array(z.number()),\n});\n\nAttempting to parse this invalid data results in an error containing three issues.\n\nconst result = schema.safeParse({\n  username: 1234,\n  favoriteNumbers: [1234, \"4567\"],\n  extraKey: 1234,\n});\n \nresult.error!.issues;\n[\n  {\n    expected: 'string',\n    code: 'invalid_type',\n    path: [ 'username' ],\n    message: 'Invalid input: expected string, received number'\n  },\n  {\n    expected: 'number',\n    code: 'invalid_type',\n    path: [ 'favoriteNumbers', 1 ],\n    message: 'Invalid input: expected number, received string'\n  },\n  {\n    code: 'unrecognized_keys',\n    keys: [ 'extraKey' ],\n    path: [],\n    message: 'Unrecognized key: \"extraKey\"'\n  }\n];\nz.treeifyError()\n\nTo convert (\"treeify\") this error into a nested object, use z.treeifyError().\n\nconst tree = z.treeifyError(result.error);\n \n// =>\n{\n  errors: [ 'Unrecognized key: \"extraKey\"' ],\n  properties: {\n    username: { errors: [ 'Invalid input: expected string, received number' ] },\n    favoriteNumbers: {\n      errors: [],\n      items: [\n        undefined,\n        {\n          errors: [ 'Invalid input: expected number, received string' ]\n        }\n      ]\n    }\n  }\n}\n\nThe result is a nested structure that mirrors the schema itself. You can easily access the errors that occurred at a particular path. The errors field contains the error messages at a given path, and the special properties properties and items let you traverse deeper into the tree.\n\ntree.properties?.username?.errors;\n// => [\"Invalid input: expected string, received number\"]\n \ntree.properties?.favoriteNumbers?.items?.[1]?.errors;\n// => [\"Invalid input: expected number, received string\"];\n\nBe sure to use optional chaining (?.) to avoid errors when accessing nested properties.\n\nz.prettifyError()\n\nThe z.prettifyError() provides a human-readable string representation of the error.\n\nconst pretty = z.prettifyError(result.error);\n\nThis returns the following string:\n\n✖ Unrecognized key: \"extraKey\"\n✖ Invalid input: expected string, received number\n  → at username\n✖ Invalid input: expected number, received string\n  → at favoriteNumbers[1]\nz.formatError()\n\nThis has been deprecated in favor of z.treeifyError().\n\nShow docs\nz.flattenError()\n\nWhile z.treeifyError() is useful for traversing a potentially complex nested structure, the majority of schemas are flat—just one level deep. In this case, use z.flattenError() to retrieve a clean, shallow error object.\n\nconst flattened = z.flattenError(result.error);\n// { errors: string[], properties: { [key: string]: string[] } }\n \n{\n  formErrors: [ 'Unrecognized key: \"extraKey\"' ],\n  fieldErrors: {\n    username: [ 'Invalid input: expected string, received number' ],\n    favoriteNumbers: [ 'Invalid input: expected number, received string' ]\n  }\n}\n\nThe formErrors array contains any top-level errors (where path is []). The fieldErrors object provides an array of errors for each field in the schema.\n\nflattened.fieldErrors.username; // => [ 'Invalid input: expected string, received number' ]\nflattened.fieldErrors.favoriteNumbers; // => [ 'Invalid input: expected number, received string' ]\n\nCustomizing errors\n\nGuide to customizing validation error messages and error handling patterns\n\nMetadata and registries\n\nAttaching and manipulatinvg metadata on Zod schemas"
  },
  {
    "title": "Metadata and registries | Zod",
    "url": "https://zod.dev/metadata",
    "html": "Metadata and registries\nCopy markdown\nEdit this page\n\nIt's often useful to associate a schema with some additional metadata for documentation, code generation, AI structured outputs, form validation, and other purposes.\n\nRegistries\n\nMetadata in Zod is handled via registries. Registries are collections of schemas, each associated with some strongly-typed metadata. To create a simple registry:\n\nimport * as z from \"zod\";\n \nconst myRegistry = z.registry<{ description: string }>();\n\nTo register, lookup, and remove schemas from this registry:\n\nconst mySchema = z.string();\n \nmyRegistry.add(mySchema, { description: \"A cool schema!\"});\nmyRegistry.has(mySchema); // => true\nmyRegistry.get(mySchema); // => { description: \"A cool schema!\" }\nmyRegistry.remove(mySchema);\nmyRegistry.clear(); // wipe registry\n\nTypeScript enforces that the metadata for each schema matches the registry's metadata type.\n\nmyRegistry.add(mySchema, { description: \"A cool schema!\" }); // ✅\nmyRegistry.add(mySchema, { description: 123 }); // ❌\n\nSpecial handling for id — Zod registries treat the id property specially. An Error will be thrown if multiple schemas are registered with the same id value. This is true for all registries, including the global registry.\n\n.register()\n\nNote — This method is special in that it does not return a new schema; instead, it returns the original schema. No other Zod method does this! That includes .meta() and .describe() (documented below) which return a new instance.\n\nSchemas provide a .register() method to more conveniently add it to a registry.\n\nconst mySchema = z.string();\n \nmySchema.register(myRegistry, { description: \"A cool schema!\" });\n// => mySchema\n\nThis lets you define metadata \"inline\" in your schemas.\n\nconst mySchema = z.object({\n  name: z.string().register(myRegistry, { description: \"The user's name\" }),\n  age: z.number().register(myRegistry, { description: \"The user's age\" }),\n})\n\nIf a registry is defined without a metadata type, you can use it as a generic \"collection\", no metadata required.\n\nconst myRegistry = z.registry();\n \nmyRegistry.add(z.string());\nmyRegistry.add(z.number());\nMetadata\nz.globalRegistry\n\nFor convenience, Zod provides a global registry (z.globalRegistry) that can be used to store metadata for JSON Schema generation or other purposes. It accepts the following metadata:\n\nexport interface GlobalMeta {\n  id?: string ;\n  title?: string ;\n  description?: string;\n  deprecated?: boolean;\n  [k: string]: unknown;\n}\n\nTo register some metadata in z.globalRegistry for a schema:\n\nimport * as z from \"zod\";\n \nconst emailSchema = z.email().register(z.globalRegistry, { \n  id: \"email_address\",\n  title: \"Email address\",\n  description: \"Your email address\",\n  examples: [\"first.last@example.com\"]\n});\n\nTo globally augment the GlobalMeta interface, use declaration merging. Add the following anywhere in your codebase. Creating a zod.d.ts file in your project root is a common convention.\n\ndeclare module \"zod\" {\n  interface GlobalMeta {\n    // add new fields here\n    examples?: unknown[];\n  }\n}\n.meta()\n\nFor a more convenient approach, use the .meta() method to register a schema in z.globalRegistry.\n\nZod\nZod Mini\nconst emailSchema = z.email().meta({ \n  id: \"email_address\",\n  title: \"Email address\",\n  description: \"Please enter a valid email address\",\n});\n\nCalling .meta() without an argument will retrieve the metadata for a schema.\n\nemailSchema.meta();\n// => { id: \"email_address\", title: \"Email address\", ... }\n\nMetadata is associated with a specific schema instance. This is important to keep in mind, especially since Zod methods are immutable—they always return a new instance.\n\nconst A = z.string().meta({ description: \"A cool string\" });\nA.meta(); // => { description: \"A cool string\" }\n \nconst B = A.refine(_ => true);\nB.meta(); // => undefined\n.describe()\n\nThe .describe() method still exists for compatibility with Zod 3, but .meta() is now the recommended approach.\n\nThe .describe() method is a shorthand for registering a schema in z.globalRegistry with just a description field.\n\nZod\nZod Mini\nconst emailSchema = z.email();\nemailSchema.describe(\"An email address\");\n \n// equivalent to\nemailSchema.meta({ description: \"An email address\" });\nCustom registries\n\nYou've already seen a simple example of a custom registry:\n\nimport * as z from \"zod\";\n \nconst myRegistry = z.registry<{ description: string };>();\n\nLet's look at some more advanced patterns.\n\nReferencing inferred types\n\nIt's often valuable for the metadata type to reference the inferred type of a schema. For instance, you may want an examples field to contain examples of the schema's output.\n\nimport * as z from \"zod\";\n \ntype MyMeta = { examples: z.$output[] };\nconst myRegistry = z.registry<MyMeta>();\n \nmyRegistry.add(z.string(), { examples: [\"hello\", \"world\"] });\nmyRegistry.add(z.number(), { examples: [1, 2, 3] });\n\nThe special symbol z.$output is a reference to the schemas inferred output type (z.infer<typeof schema>). Similarly you can use z.$input to reference the input type.\n\nConstraining schema types\n\nPass a second generic to z.registry() to constrain the schema types that can be added to a registry. This registry only accepts string schemas.\n\nimport * as z from \"zod\";\n \nconst myRegistry = z.registry<{ description: string }, z.ZodString>();\n \nmyRegistry.add(z.string(), { description: \"A number\" }); // ✅\nmyRegistry.add(z.number(), { description: \"A number\" }); // ❌ \n//             ^ 'ZodNumber' is not assignable to parameter of type 'ZodString' \n\nFormatting errors\n\nUtilities for formatting and displaying Zod errors\n\nJSON Schema\n\nHow to convert Zod schemas to JSON Schema"
  },
  {
    "title": "Codecs | Zod",
    "url": "https://zod.dev/codecs",
    "html": "Codecs\nCopy markdown\nEdit this page\n\n✨ New — Introduced in zod@4.1\n\nAll Zod schemas can process inputs in both the forward and backward direction:\n\nForward: Input to Output\n.parse()\n.decode()\nBackward: Output to Input\n.encode()\n\nIn most cases, this is a distinction without a difference. The input and output types are identical, so there's no difference between \"forward\" and \"backward\".\n\nZod\nZod Mini\nconst schema = z.string();\n \ntype Input = z.input<typeof schema>;    // string\ntype Output = z.output<typeof schema>;  // string\n \nschema.parse(\"asdf\");   // => \"asdf\"\nschema.decode(\"asdf\");  // => \"asdf\"\nschema.encode(\"asdf\");  // => \"asdf\"\n\nHowever, some schema types cause the input and output types to diverge, notably z.codec(). Codecs are a special type of schema that defines a bi-directional transformation between two other schemas.\n\nconst stringToDate = z.codec(\n  z.iso.datetime(),  // input schema: ISO date string\n  z.date(),          // output schema: Date object\n  {\n    decode: (isoString) => new Date(isoString), // ISO string → Date\n    encode: (date) => date.toISOString(),       // Date → ISO string\n  }\n);\n\nIn these cases, z.decode() and z.encode() behave quite differently.\n\nZod\nZod Mini\nstringToDate.decode(\"2024-01-15T10:30:00.000Z\")\n// => Date\n \nstringToDate.encode(new Date(\"2024-01-15T10:30:00.000Z\"))\n// => string\n\nNote —There's nothing special about the directions or terminology here. Instead of encoding with an A -> B codec, you could instead decode with a B -> A codec. The use of the terms \"decode\" and \"encode\" is just a convention.\n\nThis is particularly useful when parsing data at a network boundary. You can share a single Zod schema between your client and server, then use this single schema to convert between a network-friendly format (say, JSON) and a richer JavaScript representation.\n\nComposability\n\nNote — You can use z.encode() and z.decode() with any schema. It doesn't have to be a ZodCodec.\n\nCodecs are a schema like any other. You can nest them inside objects, arrays, pipes, etc. There are no rules on where you can use them!\n\nconst payloadSchema = z.object({ \n  startDate: stringToDate \n});\n \npayloadSchema.decode({\n  startDate: \"2024-01-15T10:30:00.000Z\"\n}); // => { startDate: Date }\nType-safe inputs\n\nWhile .parse() and .decode() behave identically at runtime, they have different type signatures. The .parse() method accepts unknown as input, and returns a value that matches the schema's inferred output type. By constrast, the z.decode() and z.encode() functions have strongly-typed inputs.\n\nstringToDate.parse(12345); \n// no complaints from TypeScript (fails at runtime)\n \nstringToDate.decode(12345); \n// ❌ TypeScript error: Argument of type 'number' is not assignable to parameter of type 'string'.\n \nstringToDate.encode(12345); \n// ❌ TypeScript error: Argument of type 'number' is not assignable to parameter of type 'Date'.\n\nWhy the difference? Encoding and decoding imply transformation. In many cases, the inputs to these methods Here's a diagram demonstrating the differences between the type signatures for parse(), decode(), and encode().\n\nAsync and safe variants\n\nAs with .transform() and .refine(), codecs support async transforms.\n\nconst asyncCodec = z.codec(z.string(), z.number(), {\n  decode: async (str) => Number(str),\n  encode: async (num) => num.toString(),\n});\n\nAs with regular parse(), there are \"safe\" and \"async\" variants of decode() and encode().\n\nstringToDate.decode(\"2024-01-15T10:30:00.000Z\"); \n// => Date\n \nstringToDate.decodeAsync(\"2024-01-15T10:30:00.000Z\"); \n// => Promise<Date>\n \nstringToDate.decodeSafe(\"2024-01-15T10:30:00.000Z\"); \n// => { success: true, data: Date } | { success: false, error: ZodError }\n \nstringToDate.decodeSafeAsync(\"2024-01-15T10:30:00.000Z\"); \n// => Promise<{ success: true, data: Date } | { success: false, error: ZodError }>\nHow encoding works\n\nThere are some subtleties to how certain Zod schemas \"reverse\" their parse behavior.\n\nCodecs\n\nThis one is fairly self-explanatory. Codecs encapsulate a bi-directional transformation between two types. During z.decode(), the decode transform is executed. During z.encode(), the encode transform is executed.\n\nconst stringToDate = z.codec(\n  z.iso.datetime(),  // input schema: ISO date string\n  z.date(),          // output schema: Date object\n  {\n    decode: (isoString) => new Date(isoString), // ISO string → Date\n    encode: (date) => date.toISOString(),       // Date → ISO string\n  }\n);\n \nstringToDate.decode(\"2024-01-15T10:30:00.000Z\"); \n// => Date\n \nstringToDate.encode(new Date(\"2024-01-15\")); \n// => string\nPipes\n\nFun fact — Codecs are actually implemented internally as subclass of pipes that have been augmented with \"interstitial\" transform logic.\n\nDuring regular decoding, a ZodPipe<A, B> schema will first parse the data with A, then pass it into B. As you might expect, during encoding, the data is first encoded with B, then passed into A.\n\nRefinements\n\nAll checks (.refine(), .min(), .max(), etc.) are still executed in both directions.\n\nconst schema = stringToDate.refine((date) => date.getFullYear() >= 2000, \"Must be this millenium\");\n \nschema.encode(new Date(\"2000-01-01\"));\n// => Date\n \nschema.encode(new Date(\"1999-01-01\"));\n// => ❌ ZodError: [\n//   {\n//     \"code\": \"custom\",\n//     \"path\": [],\n//     \"message\": \"Must be this millenium\"\n//   }\n// ]\n\nTo avoid unexpected errors in your custom .refine() logic, Zod performs two \"passes\" during z.encode(). The first pass ensures the input type conforms to the expected type (no invalid_type errors). If that passes, Zod performs the second pass which executes the refinement logic.\n\nThis approach also supports \"mutating transforms\" like z.string().trim() or z.string().toLowerCase():\n\nconst schema = z.string().trim();\n \nschema.decode(\"  hello  \");\n// => \"hello\"\n \nschema.encode(\"  hello  \");\n// => \"hello\"\nDefaults and prefaults\n\nDefaults and prefaults are only applied in the \"forward\" direction.\n\nconst stringWithDefault = z.string().default(\"hello\");\n \nstringWithDefault.decode(undefined); \n// => \"hello\"\n \nstringWithDefault.encode(undefined); \n// => ZodError: Expected string, received undefined\n\nWhen you attach a default value to a schema, the input becomes optional (| undefined) but the output does not. As such, undefined is not a valid input to z.encode() and defaults/prefaults will not be applied.\n\nCatch\n\nSimilarly, .catch() is only applied in the \"forward\" direction.\n\nconst stringWithCatch = z.string().catch(\"hello\");\n \nstringWithCatch.decode(1234); \n// => \"hello\"\n \nstringWithCatch.encode(1234); \n// => ZodError: Expected string, received number\nStringbool\n\nNote — Stringbool pre-dates the introduction of codecs in Zod. It has since been internally re-implemented as a codec.\n\nThe z.stringbool() API converts string values (\"true\", \"false\", \"yes\", \"no\", etc.) into boolean. By default, it will convert true to \"true\" and false to \"false\" during z.encode()..\n\nconst stringbool = z.stringbool();\n \nstringbool.decode(\"true\");  // => true\nstringbool.decode(\"false\"); // => false\n \nstringbool.encode(true);    // => \"true\"\nstringbool.encode(false);   // => \"false\"\n\nIf you specify a custom set of truthy and falsy values, the first element in the array will be used instead.\n\nconst stringbool = z.stringbool({ truthy: [\"yes\", \"y\"], falsy: [\"no\", \"n\"] });\n \nstringbool.encode(true);    // => \"yes\"\nstringbool.encode(false);   // => \"no\"\nTransforms\n\n⚠️ — The .transform() API implements a unidirectional transformation. If any .transform() exists anywhere in your schema, attempting a z.encode() operation will throw a runtime error (not a ZodError).\n\nconst schema = z.string().transform(val => val.length);\n \nschema.encode(1234); \n// ❌ Error: Encountered unidirectional transform during encode: ZodTransform\nUseful codecs\n\nBelow are implementations for a bunch of commonly-needed codecs. For the sake of customizability, these are not included as first-class APIs in Zod itself. Instead, you should copy/paste them into your project and modify them as needed.\n\nNote — All of these codec implementations have been tested for correctness.\n\nstringToNumber\n\nConverts string representations of numbers to JavaScript number type using parseFloat().\n\nconst stringToNumber = z.codec(z.string().regex(z.regexes.number), z.number(), {\n  decode: (str) => Number.parseFloat(str),\n  encode: (num) => num.toString(),\n});\n \nstringToNumber.decode(\"42.5\");  // => 42.5\nstringToNumber.encode(42.5);    // => \"42.5\"\nstringToInt\n\nConverts string representations of integers to JavaScript number type using parseInt().\n\nconst stringToInt = z.codec(z.string().regex(z.regexes.integer), z.int(), {\n  decode: (str) => Number.parseInt(str, 10),\n  encode: (num) => num.toString(),\n});\n \nstringToInt.decode(\"42\");  // => 42\nstringToInt.encode(42);    // => \"42\"\nstringToBigInt\n\nConverts string representations to JavaScript bigint type.\n\nconst stringToBigInt = z.codec(z.string(), z.bigint(), {\n  decode: (str) => BigInt(str),\n  encode: (bigint) => bigint.toString(),\n});\n \nstringToBigInt.decode(\"12345\");  // => 12345n\nstringToBigInt.encode(12345n);   // => \"12345\"\nnumberToBigInt\n\nConverts JavaScript number to bigint type.\n\nconst numberToBigInt = z.codec(z.int(), z.bigint(), {\n  decode: (num) => BigInt(num),\n  encode: (bigint) => Number(bigint),\n});\n \nnumberToBigInt.decode(42);   // => 42n\nnumberToBigInt.encode(42n);  // => 42\nisoDatetimeToDate\n\nConverts ISO datetime strings to JavaScript Date objects.\n\nconst isoDatetimeToDate = z.codec(z.iso.datetime(), z.date(), {\n  decode: (isoString) => new Date(isoString),\n  encode: (date) => date.toISOString(),\n});\n \nisoDatetimeToDate.decode(\"2024-01-15T10:30:00.000Z\");  // => Date object\nisoDatetimeToDate.encode(new Date(\"2024-01-15\"));       // => \"2024-01-15T00:00:00.000Z\"\nepochSecondsToDate\n\nConverts Unix timestamps (seconds since epoch) to JavaScript Date objects.\n\nconst epochSecondsToDate = z.codec(z.int().min(0), z.date(), {\n  decode: (seconds) => new Date(seconds * 1000),\n  encode: (date) => Math.floor(date.getTime() / 1000),\n});\n \nepochSecondsToDate.decode(1705314600);  // => Date object\nepochSecondsToDate.encode(new Date());  // => Unix timestamp in seconds\nepochMillisToDate\n\nConverts Unix timestamps (milliseconds since epoch) to JavaScript Date objects.\n\nconst epochMillisToDate = z.codec(z.int().min(0), z.date(), {\n  decode: (millis) => new Date(millis),\n  encode: (date) => date.getTime(),\n});\n \nepochMillisToDate.decode(1705314600000);  // => Date object\nepochMillisToDate.encode(new Date());     // => Unix timestamp in milliseconds\njson(schema)\n\nParses JSON strings into structured data and serializes back to JSON. This generic function accepts an output schema to validate the parsed JSON data.\n\nconst jsonCodec = <T extends z.core.$ZodType>(schema: T) =>\n  z.codec(z.string(), schema, {\n    decode: (jsonString, ctx) => {\n      try {\n        return JSON.parse(jsonString);\n      } catch (err: any) {\n        ctx.issues.push({\n          code: \"invalid_format\",\n          format: \"json\",\n          input: jsonString,\n          message: err.message,\n        });\n        return z.NEVER;\n      }\n    },\n    encode: (value) => JSON.stringify(value),\n  });\n\nUsage example with a specific schema:\n\nconst jsonToObject = jsonCodec(z.object({ name: z.string(), age: z.number() }));\n \njsonToObject.decode('{\"name\":\"Alice\",\"age\":30}');  \n// => { name: \"Alice\", age: 30 }\n \njsonToObject.encode({ name: \"Bob\", age: 25 });     \n// => '{\"name\":\"Bob\",\"age\":25}'\n \njsonToObject.decode('~~invalid~~'); \n// ZodError: [\n//   {\n//     \"code\": \"invalid_format\",\n//     \"format\": \"json\",\n//     \"path\": [],\n//     \"message\": \"Unexpected token '~', \\\"~~invalid~~\\\" is not valid JSON\"\n//   }\n// ]\nutf8ToBytes\n\nConverts UTF-8 strings to Uint8Array byte arrays.\n\nconst utf8ToBytes = z.codec(z.string(), z.instanceof(Uint8Array), {\n  decode: (str) => new TextEncoder().encode(str),\n  encode: (bytes) => new TextDecoder().decode(bytes),\n});\n \nutf8ToBytes.decode(\"Hello, 世界!\");  // => Uint8Array\nutf8ToBytes.encode(bytes);          // => \"Hello, 世界!\"\nbytesToUtf8\n\nConverts Uint8Array byte arrays to UTF-8 strings.\n\nconst bytesToUtf8 = z.codec(z.instanceof(Uint8Array), z.string(), {\n  decode: (bytes) => new TextDecoder().decode(bytes),\n  encode: (str) => new TextEncoder().encode(str),\n});\n \nbytesToUtf8.decode(bytes);          // => \"Hello, 世界!\"\nbytesToUtf8.encode(\"Hello, 世界!\");  // => Uint8Array\nbase64ToBytes\n\nConverts base64 strings to Uint8Array byte arrays and vice versa.\n\nconst base64ToBytes = z.codec(z.base64(), z.instanceof(Uint8Array), {\n  decode: (base64String) => z.util.base64ToUint8Array(base64String),\n  encode: (bytes) => z.util.uint8ArrayToBase64(bytes),\n});\n \nbase64ToBytes.decode(\"SGVsbG8=\");  // => Uint8Array([72, 101, 108, 108, 111])\nbase64ToBytes.encode(bytes);       // => \"SGVsbG8=\"\nbase64urlToBytes\n\nConverts base64url strings (URL-safe base64) to Uint8Array byte arrays.\n\nconst base64urlToBytes = z.codec(z.base64url(), z.instanceof(Uint8Array), {\n  decode: (base64urlString) => z.util.base64urlToUint8Array(base64urlString),\n  encode: (bytes) => z.util.uint8ArrayToBase64url(bytes),\n});\n \nbase64urlToBytes.decode(\"SGVsbG8\");  // => Uint8Array([72, 101, 108, 108, 111])\nbase64urlToBytes.encode(bytes);      // => \"SGVsbG8\"\nhexToBytes\n\nConverts hexadecimal strings to Uint8Array byte arrays and vice versa.\n\nconst hexToBytes = z.codec(z.hex(), z.instanceof(Uint8Array), {\n  decode: (hexString) => z.util.hexToUint8Array(hexString),\n  encode: (bytes) => z.util.uint8ArrayToHex(bytes),\n});\n \nhexToBytes.decode(\"48656c6c6f\");     // => Uint8Array([72, 101, 108, 108, 111])\nhexToBytes.encode(bytes);            // => \"48656c6c6f\"\nstringToURL\n\nConverts URL strings to JavaScript URL objects.\n\nconst stringToURL = z.codec(z.url(), z.instanceof(URL), {\n  decode: (urlString) => new URL(urlString),\n  encode: (url) => url.href,\n});\n \nstringToURL.decode(\"https://example.com/path\");  // => URL object\nstringToURL.encode(new URL(\"https://example.com\"));  // => \"https://example.com/\"\nstringToHttpURL\n\nConverts HTTP/HTTPS URL strings to JavaScript URL objects.\n\nconst stringToHttpURL = z.codec(z.httpUrl(), z.instanceof(URL), {\n  decode: (urlString) => new URL(urlString),\n  encode: (url) => url.href,\n});\n \nstringToHttpURL.decode(\"https://api.example.com/v1\");  // => URL object\nstringToHttpURL.encode(url);                           // => \"https://api.example.com/v1\"\nuriComponent\n\nEncodes and decodes URI components using encodeURIComponent() and decodeURIComponent().\n\nconst uriComponent = z.codec(z.string(), z.string(), {\n  decode: (encodedString) => decodeURIComponent(encodedString),\n  encode: (decodedString) => encodeURIComponent(decodedString),\n});\n \nuriComponent.decode(\"Hello%20World%21\");  // => \"Hello World!\"\nuriComponent.encode(\"Hello World!\");      // => \"Hello%20World!\"\n\nJSON Schema\n\nHow to convert Zod schemas to JSON Schema\n\nEcosystem\n\nOverview of the Zod ecosystem including integrations, tools, and community resources"
  },
  {
    "title": "JSON Schema | Zod",
    "url": "https://zod.dev/json-schema",
    "html": "JSON Schema\nCopy markdown\nEdit this page\n💎\n\nNew — Zod 4 introduces a new feature: native JSON Schema conversion. JSON Schema is a standard for describing the structure of JSON (with JSON). It's widely used in OpenAPI definitions and defining structured outputs for AI.\n\nTo convert a Zod schema to JSON Schema, use the z.toJSONSchema() function.\n\nimport * as z from \"zod\";\n \nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n \nz.toJSONSchema(schema)\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, age: { type: 'number' } },\n//   required: [ 'name', 'age' ],\n//   additionalProperties: false,\n// }\n\nAll schema & checks are converted to their closest JSON Schema equivalent. Some types have no analog and cannot be reasonably represented. See the unrepresentable section below for more information on handling these cases.\n\nz.bigint(); // ❌\nz.int64(); // ❌\nz.symbol(); // ❌\nz.void(); // ❌\nz.date(); // ❌\nz.map(); // ❌\nz.set(); // ❌\nz.transform(); // ❌\nz.nan(); // ❌\nz.custom(); // ❌\nString formats\n\nZod converts the following schema types to the equivalent JSON Schema format:\n\n// Supported via `format`\nz.email(); // => { type: \"string\", format: \"email\" }\nz.iso.datetime(); // => { type: \"string\", format: \"date-time\" }\nz.iso.date(); // => { type: \"string\", format: \"date\" }\nz.iso.time(); // => { type: \"string\", format: \"time\" }\nz.iso.duration(); // => { type: \"string\", format: \"duration\" }\nz.ipv4(); // => { type: \"string\", format: \"ipv4\" }\nz.ipv6(); // => { type: \"string\", format: \"ipv6\" }\nz.uuid(); // => { type: \"string\", format: \"uuid\" }\nz.guid(); // => { type: \"string\", format: \"uuid\" }\nz.url(); // => { type: \"string\", format: \"uri\" }\n\nThese schemas are supported via contentEncoding:\n\nz.base64(); // => { type: \"string\", contentEncoding: \"base64\" }\n\nAll other string formats are supported via pattern:\n\nz.base64url();\nz.cuid();\nz.emoji();\nz.nanoid();\nz.cuid2();\nz.ulid();\nz.cidrv4();\nz.cidrv6();\nNumeric types\n\nZod converts the following numeric types to JSON Schema:\n\n// number\nz.number(); // => { type: \"number\" }\nz.float32(); // => { type: \"number\", exclusiveMinimum: ..., exclusiveMaximum: ... }\nz.float64(); // => { type: \"number\", exclusiveMinimum: ..., exclusiveMaximum: ... }\n \n// integer\nz.int(); // => { type: \"integer\" }\nz.int32(); // => { type: \"integer\", exclusiveMinimum: ..., exclusiveMaximum: ... }\nObject schemas\n\nBy default, z.object() schemas contain additionalProperties: \"false\". This is an accurate representation of Zod's default behavior, as plain z.object() schema strip additional properties.\n\nimport * as z from \"zod\";\n \nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n \nz.toJSONSchema(schema)\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, age: { type: 'number' } },\n//   required: [ 'name', 'age' ],\n//   additionalProperties: false,\n// }\n\nWhen converting to JSON Schema in \"input\" mode, additionalProperties is not set. See the io docs for more information.\n\nimport * as z from \"zod\";\n \nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n \nz.toJSONSchema(schema, { io: \"input\" });\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, age: { type: 'number' } },\n//   required: [ 'name', 'age' ],\n// }\n\nBy contrast:\n\nz.looseObject() will never set additionalProperties: false\nz.strictObject() will always set additionalProperties: false\nFile schemas\n\nZod converts z.file() to the following OpenAPI-friendly schema:\n\nz.file();\n// => { type: \"string\", format: \"binary\", contentEncoding: \"binary\" }\n\nSize and MIME checks are also represented:\n\nz.file().min(1).max(1024 * 1024).mime(\"image/png\");\n// => {\n//   type: \"string\",\n//   format: \"binary\",\n//   contentEncoding: \"binary\",\n//   contentMediaType: \"image/png\",\n//   minLength: 1,\n//   maxLength: 1048576,\n// }\nNullability\n\nZod converts both undefined/null to { type: \"null\" } in JSON Schema.\n\nz.null(); \n// => { type: \"null\" }\n \nz.undefined(); \n// => { type: \"null\" }\n\nSimilarly, nullable is represented via a union with null::\n\nz.nullable(z.string());\n// => { oneOf: [{ type: \"string\" }, { type: \"null\" }] }\n\nOptional schemas are represented as-is, though they are decorated with an optional annotation.\n\nz.optional(z.string());\n// => { type: \"string\" }\nConfiguration\n\nA second argument can be used to customize the conversion logic.\n\nz.toJSONSchema(schema, {\n  // ...params\n})\n\nBelow is a quick reference for each supported parameter. Each one is explained in more detail below.\n\ninterface ToJSONSchemaParams {\n  /** The JSON Schema version to target.\n   * - `\"draft-2020-12\"` — Default. JSON Schema Draft 2020-12\n   * - `\"draft-7\"` — JSON Schema Draft 7\n   * - `\"draft-4\"` — JSON Schema Draft 4\n   * - `\"openapi-3.0\"` — OpenAPI 3.0 Schema Object */\n  target?: \"draft-4\" | \"draft-7\" | \"draft-2020-12\" | \"openapi-3.0\";\n \n  /** A registry used to look up metadata for each schema. \n   * Any schema with an `id` property will be extracted as a $def. */\n  metadata?: $ZodRegistry<Record<string, any>>;\n \n  /** How to handle unrepresentable types.\n   * - `\"throw\"` — Default. Unrepresentable types throw an error\n   * - `\"any\"` — Unrepresentable types become `{}` */\n  unrepresentable?: \"throw\" | \"any\";\n \n  /** How to handle cycles.\n   * - `\"ref\"` — Default. Cycles will be broken using $defs\n   * - `\"throw\"` — Cycles will throw an error if encountered */\n  cycles?: \"ref\" | \"throw\";\n \n  /* How to handle reused schemas.\n   * - `\"inline\"` — Default. Reused schemas will be inlined\n   * - `\"ref\"` — Reused schemas will be extracted as $defs */\n  reused?: \"ref\" | \"inline\";\n \n  /** A function used to convert `id` values to URIs to be used in *external* $refs.\n   *\n   * Default is `(id) => id`.\n   */\n  uri?: (id: string) => string;\n}\ntarget\n\nTo set the target JSON Schema version, use the target parameter. By default, Zod will target Draft 2020-12.\n\nz.toJSONSchema(schema, { target: \"draft-7\" });\nz.toJSONSchema(schema, { target: \"draft-2020-12\" });\nz.toJSONSchema(schema, { target: \"draft-4\" });\nz.toJSONSchema(schema, { target: \"openapi-3.0\" });\nmetadata\n\nIf you haven't already, read through the Metadata and registries page for context on storing metadata in Zod.\n\nIn Zod, metadata is stored in registries. Zod exports a global registry z.globalRegistry that can be used to store common metadata fields like id, title, description, and examples.\n\nZod\nZod Mini\nimport * as z from \"zod\";\n \n// `.meta()` is a convenience method for registering a schema in `z.globalRegistry`\nconst emailSchema = z.string().meta({ \n  title: \"Email address\",\n  description: \"Your email address\",\n});\n \nz.toJSONSchema(emailSchema);\n// => { type: \"string\", title: \"Email address\", description: \"Your email address\", ... } \n\nAll metadata fields get copied into the resulting JSON Schema.\n\nconst schema = z.string().meta({\n  whatever: 1234\n});\n \nz.toJSONSchema(schema);\n// => { type: \"string\", whatever: 1234 }\nunrepresentable\n\nThe following APIs are not representable in JSON Schema. By default, Zod will throw an error if they are encountered. It is unsound to attempt a conversion to JSON Schema; you should modify your schemas as they have no equivalent in JSON. An error will be thrown if any of these are encountered.\n\nz.bigint(); // ❌\nz.int64(); // ❌\nz.symbol(); // ❌\nz.void(); // ❌\nz.date(); // ❌\nz.map(); // ❌\nz.set(); // ❌\nz.transform(); // ❌\nz.nan(); // ❌\nz.custom(); // ❌\n\nBy default, Zod will throw an error if any of these are encountered.\n\nz.toJSONSchema(z.bigint());\n// => throws Error\n\nYou can change this behavior by setting the unrepresentable option to \"any\". This will convert any unrepresentable types to {} (the equivalent of unknown in JSON Schema).\n\nz.toJSONSchema(z.bigint(), { unrepresentable: \"any\" });\n// => {}\ncycles\n\nHow to handle cycles. If a cycle is encountered as z.toJSONSchema() traverses the schema, it will be represented using $ref.\n\nconst User = z.object({\n  name: z.string(),\n  get friend() {\n    return User;\n  },\n});\n \nz.toJSONSchema(User);\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, friend: { '$ref': '#' } },\n//   required: [ 'name', 'friend' ],\n//   additionalProperties: false,\n// }\n\nIf instead you want to throw an error, set the cycles option to \"throw\".\n\nz.toJSONSchema(User, { cycles: \"throw\" });\n// => throws Error\nreused\n\nHow to handle schemas that occur multiple times in the same schema. By default, Zod will inline these schemas.\n\nconst name = z.string();\nconst User = z.object({\n  firstName: name,\n  lastName: name,\n});\n \nz.toJSONSchema(User);\n// => {\n//   type: 'object',\n//   properties: { \n//     firstName: { type: 'string' }, \n//     lastName: { type: 'string' } \n//   },\n//   required: [ 'firstName', 'lastName' ],\n//   additionalProperties: false,\n// }\n\nInstead you can set the reused option to \"ref\" to extract these schemas into $defs.\n\nz.toJSONSchema(User, { reused: \"ref\" });\n// => {\n//   type: 'object',\n//   properties: {\n//     firstName: { '$ref': '#/$defs/__schema0' },\n//     lastName: { '$ref': '#/$defs/__schema0' }\n//   },\n//   required: [ 'firstName', 'lastName' ],\n//   additionalProperties: false,\n//   '$defs': { __schema0: { type: 'string' } }\n// }\noverride\n\nTo define some custom override logic, use override. The provided callback has access to the original Zod schema and the default JSON Schema. This function should directly modify ctx.jsonSchema.\n\nconst mySchema = /* ... */\nz.toJSONSchema(mySchema, {\n  override: (ctx)=>{\n    ctx.zodSchema; // the original Zod schema\n    ctx.jsonSchema; // the default JSON Schema\n \n    // directly modify\n    ctx.jsonSchema.whatever = \"sup\";\n  }\n});\n\nNote that unrepresentable types will throw an Error before this functions is called. If you are trying to define custom behavior for an unrepresentable type, you'll need to use set the unrepresentable: \"any\" alongside override.\n\n// support z.date() as ISO datetime strings\nconst result = z.toJSONSchema(z.date(), {\n  unrepresentable: \"any\",\n  override: (ctx) => {\n    const def = ctx.zodSchema._zod.def;\n    if(def.type ===\"date\"){\n      ctx.jsonSchema.type = \"string\";\n      ctx.jsonSchema.format = \"date-time\";\n    }\n  },\n});\nio\n\nSome schema types have different input and output types, e.g. ZodPipe, ZodDefault, and coerced primitives. By default, the result of z.toJSONSchema represents the output type; use \"io\": \"input\" to extract the input type instead.\n\nconst mySchema = z.string().transform(val => val.length).pipe(z.number());\n// ZodPipe\n \nconst jsonSchema = z.toJSONSchema(mySchema); \n// => { type: \"number\" }\n \nconst jsonSchema = z.toJSONSchema(mySchema, { io: \"input\" }); \n// => { type: \"string\" }\nRegistries\n\nPassing a schema into z.toJSONSchema() will return a self-contained JSON Schema.\n\nIn other cases, you may have a set of Zod schemas you'd like to represent using multiple interlinked JSON Schemas, perhaps to write to .json files and serve from a web server.\n\nimport * as z from \"zod\";\n \nconst User = z.object({\n  name: z.string(),\n  get posts(){\n    return z.array(Post);\n  }\n});\n \nconst Post = z.object({\n  title: z.string(),\n  content: z.string(),\n  get author(){\n    return User;\n  }\n});\n \nz.globalRegistry.add(User, {id: \"User\"});\nz.globalRegistry.add(Post, {id: \"Post\"});\n\nTo achieve this, you can pass a registry into z.toJSONSchema().\n\nImportant — All schemas should have a registered id property in the registry! Any schemas without an id will be ignored.\n\nz.toJSONSchema(z.globalRegistry);\n// => {\n//   schemas: {\n//     User: {\n//       id: 'User',\n//       type: 'object',\n//       properties: {\n//         name: { type: 'string' },\n//         posts: { type: 'array', items: { '$ref': 'Post' } }\n//       },\n//       required: [ 'name', 'posts' ],\n//       additionalProperties: false,\n//     },\n//     Post: {\n//       id: 'Post',\n//       type: 'object',\n//       properties: {\n//         title: { type: 'string' },\n//         content: { type: 'string' },\n//         author: { '$ref': 'User' }\n//       },\n//       required: [ 'title', 'content', 'author' ],\n//       additionalProperties: false,\n//     }\n//   }\n// }\n\nBy default, the $ref URIs are simple relative paths like \"User\". To make these absolute URIs, use the uri option. This expects a function that converts an id to a fully-qualified URI.\n\nz.toJSONSchema(z.globalRegistry, {\n  uri: (id) => `https://example.com/${id}.json`\n});\n// => {\n//   schemas: {\n//     User: {\n//       id: 'User',\n//       type: 'object',\n//       properties: {\n//         name: { type: 'string' },\n//         posts: {\n//           type: 'array',\n//           items: { '$ref': 'https://example.com/Post.json' }\n//         }\n//       },\n//       required: [ 'name', 'posts' ],\n//       additionalProperties: false,\n//     },\n//     Post: {\n//       id: 'Post',\n//       type: 'object',\n//       properties: {\n//         title: { type: 'string' },\n//         content: { type: 'string' },\n//         author: { '$ref': 'https://example.com/User.json' }\n//       },\n//       required: [ 'title', 'content', 'author' ],\n//       additionalProperties: false,\n//     }\n//   }\n// }\n\nMetadata and registries\n\nAttaching and manipulatinvg metadata on Zod schemas\n\nCodecs\n\nBidirectional transformations with encode and decode"
  },
  {
    "title": "Zod Mini | Zod",
    "url": "https://zod.dev/packages/mini",
    "html": "Zod Mini\nCopy markdown\nEdit this page\n\nNote — The docs for Zod Mini are interleaved with the regular Zod docs via tabbed code blocks. This page is designed to explain why Zod Mini exists, when to use it, and some key differences from regular Zod.\n\nZod Mini variant was introduced with the release of Zod 4. To try it:\n\nnpm install zod@^4.0.0\n\nTo import it:\n\nimport * as z from \"zod/mini\";\n\nZod Mini implements the exact same functionality as zod, but using a functional, tree-shakable API. If you're coming from zod, this means you generally will use functions in place of methods.\n\n// regular Zod\nconst mySchema = z.string().optional().nullable();\n \n// Zod Mini\nconst mySchema = z.nullable(z.optional(z.string()));\nTree-shaking\n\nTree-shaking is a technique used by modern bundlers to remove unused code from the final bundle. It's also referred to as dead-code elimination.\n\nIn regular Zod, schemas provide a range of convenience methods to perform some common operations (e.g. .min() on string schemas). Bundlers are generally not able to remove (\"treeshake\") unused method implementations from your bundle, but they are able to remove unused top-level functions. As such, the API of Zod Mini uses more functions than methods.\n\n// regular Zod\nz.string().min(5).max(10).trim()\n \n// Zod Mini\nz.string().check(z.minLength(5), z.maxLength(10), z.trim());\n\nTo give a general idea about the bundle size reduction, consider this simple script:\n\nz.boolean().parse(true)\n\nBundling this with Zod and Zod Mini results in the following bundle sizes. Zod Mini results in a 64% reduction.\n\nPackage\tBundle size (gzip)\nZod Mini\t2.12kb\nZod\t5.91kb\n\nWith a marginally more complex schema that involves object types:\n\nconst schema = z.object({ a: z.string(), b: z.number(), c: z.boolean() });\n \nschema.parse({\n  a: \"asdf\",\n  b: 123,\n  c: true,\n});\nPackage\tBundle size (gzip)\nZod Mini\t4.0kb\nZod\t13.1kb\n\nThis gives you a sense of the bundle sizes involved. Look closely at these numbers and run your own benchmarks to determine if using Zod Mini is worth it for your use case.\n\nWhen (not) to use Zod Mini\n\nIn general you should probably use regular Zod unless you have uncommonly strict constraints around bundle size. Many developers massively overestimate the importance of bundle size to application performance. In practice, bundle size on the scale of Zod (5-10kb typically) is only a meaningful concern when optimizing front-end bundles for a user base with slow mobile network connections in rural or developing areas.\n\nLet's run through some considerations:\n\nDX\n\nThe API of Zod Mini is more verbose and less discoverable. The methods in Zod's API are much easier to discover & autocomplete through Intellisense than the top-level functions in Zod Mini. It isn't possible to quickly build a schema with chained APIs. (Speaking as the creator of Zod: I spent a lot of time designing the Zod Mini API to be as ergonomic as possible, but I still have a strong preference the standard Zod API.)\n\nBackend development\n\nIf you are using Zod on the backend, bundle size on the scale of Zod is not meaningful. This is true even in resource-constrained environments like Lambda. This post benchmarks cold start times with bundles of various sizes. Here is a subset of the results:\n\nBundle size\tLambda cold start time\n1kb\t171ms\n17kb (size of gzipped non-Mini Zod)\t171.6ms (interpolated)\n128kb\t176ms\n256kb\t182ms\n512kb\t279ms\n1mb\t557ms\n\nThe minimum cold start time for a negligible 1kb bundle is 171ms. The next bundle size tested is 128kb, which added only 5ms. When gzipped, the bundle size for the entirely of regular Zod is roughly 17kb, which would correspond to a 0.6ms increase in startup time.\n\nInternet speed\n\nGenerally, the round trip time to the server (100-200ms) will dwarf the time required to download an additional 10kb. Only on slow 3G connections (sub-1Mbps) does the download time for an additional 10kb become more significant. If you aren't optimizing specifically for users in rural or developing areas, your time is likely better spent optimizing something else.\n\nZodMiniType\n\nAll Zod Mini schemas extend the z.ZodMiniType base class, which in turn extends z.core.$ZodType from zod/v4/core. While this class implements far fewer methods than ZodType in zod, some particularly useful methods remain.\n\n.parse\n\nThis is an obvious one. All Zod Mini schemas implement the same parsing methods as zod.\n\nimport * as z from \"zod/mini\"\n \nconst mySchema = z.string();\n \nmySchema.parse('asdf')\nawait mySchema.parseAsync('asdf')\nmySchema.safeParse('asdf')\nawait mySchema.safeParseAsync('asdf')\n.check()\n\nIn regular Zod there are dedicated methods on schema subclasses for performing common checks:\n\nimport * as z from \"zod\";\n \nz.string()\n  .min(5)\n  .max(10)\n  .refine(val => val.includes(\"@\"))\n  .trim()\n\nIn Zod Mini such methods aren't implemented. Instead you pass these checks into schemas using the .check() method:\n\nimport * as z from \"zod/mini\"\n \nz.string().check(\n  z.minLength(5), \n  z.maxLength(10),\n  z.refine(val => val.includes(\"@\")),\n  z.trim()\n);\n\nThe following checks are implemented. Some of these checks only apply to schemas of certain types (e.g. strings or numbers). The APIs are all type-safe; TypeScript won't let you add an unsupported check to your schema.\n\nz.lt(value);\nz.lte(value); // alias: z.maximum()\nz.gt(value);\nz.gte(value); // alias: z.minimum()\nz.positive();\nz.negative();\nz.nonpositive();\nz.nonnegative();\nz.multipleOf(value);\nz.maxSize(value);\nz.minSize(value);\nz.size(value);\nz.maxLength(value);\nz.minLength(value);\nz.length(value);\nz.regex(regex);\nz.lowercase();\nz.uppercase();\nz.includes(value);\nz.startsWith(value);\nz.endsWith(value);\nz.property(key, schema);\nz.mime(value);\n \n// custom checks\nz.refine()\nz.check()   // replaces .superRefine()\n \n// mutations (these do not change the inferred types)\nz.overwrite(value => newValue);\nz.normalize();\nz.trim();\nz.toLowerCase();\nz.toUpperCase();\n.register()\n\nFor registering a schema in a registry.\n\nconst myReg = z.registry<{title: string}>();\n \nz.string().register(myReg, { title: \"My cool string schema\" });\n.brand()\n\nFor branding a schema. Refer to the Branded types docs for more information.\n\nimport * as z from \"zod/mini\"\n \nconst USD = z.string().brand(\"USD\");\n.clone(def)\n\nReturns an identical clone of the current schema using the provided def.\n\nconst mySchema = z.string()\n \nmySchema.clone(mySchema._zod.def);\nNo default locale\n\nWhile regular Zod automatically loads the English (en) locale, Zod Mini does not. This reduces the bundle size in scenarios where error messages are unnecessary, localized to a non-English language, or otherwise customized.\n\nThis means, by default the message property of all issues will simply read \"Invalid input\". To load the English locale:\n\nimport * as z from \"zod/mini\"\n \nz.config(z.locales.en());\n\nRefer to the Locales docs for more on localization.\n\nZod\n\nInternals and structure of the Zod library\n\nZod Core\n\nZod Core package - minimal core functionality for custom implementations"
  },
  {
    "title": "Zod | Zod",
    "url": "https://zod.dev/packages/zod",
    "html": "Zod\nCopy markdown\nEdit this page\n\nThe zod/v4 package is the \"flagship\" library of the Zod ecosystem. It strikes a balance between developer experience and bundle size that's ideal for the vast majority of applications.\n\nIf you have uncommonly strict constraints around bundle size, consider Zod Mini.\n\nZod aims to provide a schema API that maps one-to-one to TypeScript's type system.\n\nimport * as z from \"zod\";\n \nconst schema = z.object({\n  name: z.string(),\n  age: z.number().int().positive(),\n  email: z.string().email(),\n});\n\nThe API relies on methods to provide a concise, chainable, autocomplete-friendly way to define complex types.\n\nz.string()\n  .min(5)\n  .max(10)\n  .toLowerCase();\n\nAll schemas extend the z.ZodType base class, which in turn extends z.$ZodType from zod/v4/core. All instance of ZodType implement the following methods:\n\nimport * as z from \"zod\";\n \nconst mySchema = z.string();\n \n// parsing\nmySchema.parse(data);\nmySchema.safeParse(data);\nmySchema.parseAsync(data);\nmySchema.safeParseAsync(data);\n \n \n// refinements\nmySchema.refine(refinementFunc);\nmySchema.superRefine(refinementFunc); // deprecated, use `.check()`\nmySchema.overwrite(overwriteFunc);\n \n// wrappers\nmySchema.optional();\nmySchema.nonoptional();\nmySchema.nullable();\nmySchema.nullish();\nmySchema.default(defaultValue);\nmySchema.array();\nmySchema.or(otherSchema);\nmySchema.transform(transformFunc);\nmySchema.catch(catchValue);\nmySchema.pipe(otherSchema);\nmySchema.readonly();\n \n// metadata and registries\nmySchema.register(registry, metadata);\nmySchema.describe(description);\nmySchema.meta(metadata);\n \n// utilities\nmySchema.check(checkOrFunction);\nmySchema.clone(def);\nmySchema.brand<T>();\nmySchema.isOptional(); // boolean\nmySchema.isNullable(); // boolean\n\nFor library authors\n\nGuidelines and best practices for library authors integrating with Zod\n\nZod Mini\n\nZod Mini - a tree-shakable Zod"
  },
  {
    "title": "Zod Core | Zod",
    "url": "https://zod.dev/packages/core",
    "html": "Zod Core\nCopy markdown\nEdit this page\n\nThis sub-package exports the core classes and utilities that are consumed by Zod and Zod Mini. It is not intended to be used directly; instead it's designed to be extended by other packages. It implements:\n\nimport * as z from \"zod/v4/core\";\n \n// the base class for all Zod schemas\nz.$ZodType;\n \n// subclasses of $ZodType that implement common parsers\nz.$ZodString\nz.$ZodObject\nz.$ZodArray\n// ...\n \n// the base class for all Zod checks\nz.$ZodCheck;\n \n// subclasses of $ZodCheck that implement common checks\nz.$ZodCheckMinLength\nz.$ZodCheckMaxLength\n \n// the base class for all Zod errors\nz.$ZodError;\n \n// issue formats (types only)\n{} as z.$ZodIssue;\n \n// utils\nz.util.isValidJWT(...);\nSchemas\n\nThe base class for all Zod schemas is $ZodType. It accepts two generic parameters: Output and Input.\n\nexport class $ZodType<Output = unknown, Input = unknown> {\n  _zod: { /* internals */}\n}\n\nzod/v4/core exports a number of subclasses that implement some common parsers. A union of all first-party subclasses is exported as z.$ZodTypes.\n\nexport type $ZodTypes =\n  | $ZodString\n  | $ZodNumber\n  | $ZodBigInt\n  | $ZodBoolean\n  | $ZodDate\n  | $ZodSymbol\n  | $ZodUndefined\n  | $ZodNullable\n  | $ZodNull\n  | $ZodAny\n  | $ZodUnknown\n  | $ZodNever\n  | $ZodVoid\n  | $ZodArray\n  | $ZodObject\n  | $ZodUnion // $ZodDiscriminatedUnion extends this\n  | $ZodIntersection\n  | $ZodTuple\n  | $ZodRecord\n  | $ZodMap\n  | $ZodSet\n  | $ZodLiteral\n  | $ZodEnum\n  | $ZodPromise\n  | $ZodLazy\n  | $ZodOptional\n  | $ZodDefault\n  | $ZodTemplateLiteral\n  | $ZodCustom\n  | $ZodTransform\n  | $ZodNonOptional\n  | $ZodReadonly\n  | $ZodNaN\n  | $ZodPipe // $ZodCodec extends this\n  | $ZodSuccess\n  | $ZodCatch\n  | $ZodFile;\nInheritance diagram\nInternals\n\nAll zod/v4/core subclasses only contain a single property: _zod. This property is an object containing the schemas internals. The goal is to make zod/v4/core as extensible and unopinionated as possible. Other libraries can \"build their own Zod\" on top of these classes without zod/v4/core cluttering up the interface. Refer to the implementations of zod and zod/mini for examples of how to extend these classes.\n\nThe _zod internals property contains some notable properties:\n\n.def — The schema's definition: this is the object you pass into the class's constructor to create an instance. It completely describes the schema, and it's JSON-serializable.\n.def.type — A string representing the schema's type, e.g. \"string\", \"object\", \"array\", etc.\n.def.checks — An array of checks that are executed by the schema after parsing.\n.input — A virtual property that \"stores\" the schema's inferred input type.\n.output — A virtual property that \"stores\" the schema's inferred output type.\n.run() — The schema's internal parser implementation.\n\nIf you are implementing a tool (say, a code generator) that must traverse Zod schemas, you can cast any schema to $ZodTypes and use the def property to discriminate between these classes.\n\nexport function walk(_schema: z.$ZodType) {\n  const schema = _schema as z.$ZodTypes;\n  const def = schema._zod.def;\n  switch (def.type) {\n    case \"string\": {\n      // ...\n      break;\n    }\n    case \"object\": {\n      // ...\n      break;\n    }\n  }\n}\n\nThere are a number of subclasses of $ZodString that implement various string formats. These are exported as z.$ZodStringFormatTypes.\n\nexport type $ZodStringFormatTypes =\n  | $ZodGUID\n  | $ZodUUID\n  | $ZodEmail\n  | $ZodURL\n  | $ZodEmoji\n  | $ZodNanoID\n  | $ZodCUID\n  | $ZodCUID2\n  | $ZodULID\n  | $ZodXID\n  | $ZodKSUID\n  | $ZodISODateTime\n  | $ZodISODate\n  | $ZodISOTime\n  | $ZodISODuration\n  | $ZodIPv4\n  | $ZodIPv6\n  | $ZodCIDRv4\n  | $ZodCIDRv6\n  | $ZodBase64\n  | $ZodBase64URL\n  | $ZodE164\n  | $ZodJWT\nParsing\n\nAs the Zod Core schema classes have no methods, there are top-level functions for parsing data.\n\nimport * as z from \"zod/v4/core\";\n \nconst schema = new z.$ZodString({ type: \"string\" });\nz.parse(schema, \"hello\");\nz.safeParse(schema, \"hello\");\nawait z.parseAsync(schema, \"hello\");\nawait z.safeParseAsync(schema, \"hello\");\nChecks\n\nEvery Zod schema contains an array of checks. These perform post-parsing refinements (and occasionally mutations) that do not affect the inferred type.\n\nconst schema = z.string().check(z.email()).check(z.min(5));\n// => $ZodString\n \nschema._zod.def.checks;\n// => [$ZodCheckEmail, $ZodCheckMinLength]\n\nThe base class for all Zod checks is $ZodCheck. It accepts a single generic parameter T.\n\nexport class $ZodCheck<in T = unknown> {\n  _zod: { /* internals */}\n}\n\nThe _zod internals property contains some notable properties:\n\n.def — The check's definition: this is the object you pass into the class's constructor to create the check. It completely describes the check, and it's JSON-serializable.\n.def.check — A string representing the check's type, e.g. \"min_length\", \"less_than\", \"string_format\", etc.\n.check() — Contains the check's validation logic.\n\nzod/v4/core exports a number of subclasses that perform some common refinements. All first-party subclasses are exported as a union called z.$ZodChecks.\n\nexport type $ZodChecks =\n  | $ZodCheckLessThan\n  | $ZodCheckGreaterThan\n  | $ZodCheckMultipleOf\n  | $ZodCheckNumberFormat\n  | $ZodCheckBigIntFormat\n  | $ZodCheckMaxSize\n  | $ZodCheckMinSize\n  | $ZodCheckSizeEquals\n  | $ZodCheckMaxLength\n  | $ZodCheckMinLength\n  | $ZodCheckLengthEquals\n  | $ZodCheckProperty\n  | $ZodCheckMimeType\n  | $ZodCheckOverwrite\n  | $ZodCheckStringFormat\n\nYou can use the ._zod.def.check property to discriminate between these classes.\n\nconst check = {} as z.$ZodChecks;\nconst def = check._zod.def;\n \nswitch (def.check) {\n  case \"less_than\":\n  case \"greater_than\":\n    // ...\n    break;\n}\n\nAs with schema types, there are a number of subclasses of $ZodCheckStringFormat that implement various string formats.\n\nexport type $ZodStringFormatChecks =\n  | $ZodCheckRegex\n  | $ZodCheckLowerCase\n  | $ZodCheckUpperCase\n  | $ZodCheckIncludes\n  | $ZodCheckStartsWith\n  | $ZodCheckEndsWith\n  | $ZodGUID\n  | $ZodUUID\n  | $ZodEmail\n  | $ZodURL\n  | $ZodEmoji\n  | $ZodNanoID\n  | $ZodCUID\n  | $ZodCUID2\n  | $ZodULID\n  | $ZodXID\n  | $ZodKSUID\n  | $ZodISODateTime\n  | $ZodISODate\n  | $ZodISOTime\n  | $ZodISODuration\n  | $ZodIPv4\n  | $ZodIPv6\n  | $ZodCIDRv4\n  | $ZodCIDRv6\n  | $ZodBase64\n  | $ZodBase64URL\n  | $ZodE164\n  | $ZodJWT;\n\nUse a nested switch to discriminate between the different string format checks.\n\nconst check = {} as z.$ZodChecks;\nconst def = check._zod.def;\n \nswitch (def.check) {\n  case \"less_than\":\n  case \"greater_than\":\n  // ...\n  case \"string_format\":\n    {\n      const formatCheck = check as z.$ZodStringFormatChecks;\n      const formatCheckDef = formatCheck._zod.def;\n \n      switch (formatCheckDef.format) {\n        case \"email\":\n        case \"url\":\n          // do stuff\n      }\n    }\n    break;\n}\n\nYou'll notice some of these string format checks overlap with the string format types above. That's because these classes implement both the $ZodCheck and $ZodType interfaces. That is, they can be used as either a check or a type. In these cases, both ._zod.parse (the schema parser) and ._zod.check (the check validation) are executed during parsing. In effect, the instance is prepended to its own checks array (though it won't actually exist in ._zod.def.checks).\n\n// as a type\nz.email().parse(\"user@example.com\");\n \n// as a check\nz.string().check(z.email()).parse(\"user@example.com\")\nErrors\n\nThe base class for all errors in Zod is $ZodError.\n\nFor performance reasons, $ZodError does not extend the built-in Error class! So using instanceof Error will return false.\n\nThe zod package implements a subclass of $ZodError called ZodError with some additional convenience methods.\nThe zod/mini sub-package directly uses $ZodError\nexport class $ZodError<T = unknown> implements Error {\n public issues: $ZodIssue[];\n}\nIssues\n\nThe issues property corresponds to an array of $ZodIssue objects. All issues extend the z.$ZodIssueBase interface.\n\nexport interface $ZodIssueBase {\n  readonly code?: string;\n  readonly input?: unknown;\n  readonly path: PropertyKey[];\n  readonly message: string;\n}\n\nZod defines the following issue subtypes:\n\nexport type $ZodIssue =\n  | $ZodIssueInvalidType\n  | $ZodIssueTooBig\n  | $ZodIssueTooSmall\n  | $ZodIssueInvalidStringFormat\n  | $ZodIssueNotMultipleOf\n  | $ZodIssueUnrecognizedKeys\n  | $ZodIssueInvalidUnion\n  | $ZodIssueInvalidKey\n  | $ZodIssueInvalidElement\n  | $ZodIssueInvalidValue\n  | $ZodIssueCustom;\n\nFor details on each type, refer to the implementation.\n\nZod Mini\n\nZod Mini - a tree-shakable Zod"
  }
]
</file>

</files>
