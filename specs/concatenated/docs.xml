<directory_structure>
output/
  ai-sdk/
    docs.json
  nextjs/
    docs.json
  prisma/
    docs.json
  react/
    reference.json
  trpc/
    docs.json
  zod/
    docs.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="output/ai-sdk/docs.json">
[
  {
    "title": "AI SDK UI",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui",
    "html": "AI SDK UI\nCopy markdown\nAI SDK UI\nOverview\nGet an overview about the AI SDK UI.\nChatbot\nLearn how to integrate an interface for a chatbot.\nChatbot Message Persistence\nLearn how to store and load chat messages in a chatbot.\nChatbot Tool Usage\nLearn how to integrate an interface for a chatbot with tool calling.\nCompletion\nLearn how to integrate an interface for text completion.\nObject Generation\nLearn how to integrate an interface for object generation.\nStreaming Data\nLearn how to stream data.\nReading UI Message Streams\nLearn how to read UIMessage streams for terminal UIs, custom clients, and server components.\nError Handling\nLearn how to handle errors.\nStream Protocol\nThe stream protocol defines how data is sent from the backend to the AI SDK UI frontend.\nPrevious\nTelemetry\nNext\nOverview"
  },
  {
    "title": "AI SDK UI: Overview",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/overview",
    "html": "AI SDK UI\nOverview\nCopy markdown\nAI SDK UI\n\nAI SDK UI is designed to help you build interactive chat, completion, and assistant applications with ease. It is a framework-agnostic toolkit, streamlining the integration of advanced AI functionalities into your applications.\n\nAI SDK UI provides robust abstractions that simplify the complex tasks of managing chat streams and UI updates on the frontend, enabling you to develop dynamic AI-driven interfaces more efficiently. With three main hooks — useChat, useCompletion, and useObject — you can incorporate real-time chat capabilities, text completions, streamed JSON, and interactive assistant features into your app.\n\nuseChat offers real-time streaming of chat messages, abstracting state management for inputs, messages, loading, and errors, allowing for seamless integration into any UI design.\nuseCompletion enables you to handle text completions in your applications, managing the prompt input and automatically updating the UI as new completions are streamed.\nuseObject is a hook that allows you to consume streamed JSON objects, providing a simple way to handle and display structured data in your application.\n\nThese hooks are designed to reduce the complexity and time required to implement AI interactions, letting you focus on creating exceptional user experiences.\n\nUI Framework Support\n\nAI SDK UI supports the following frameworks: React\n, Svelte\n, Vue.js\n, and Angular\n. Here is a comparison of the supported functions across these frameworks:\n\nFunction\tReact\tSvelte\tVue.js\tAngular\nuseChat\t\n\t\n Chat\t\n\t\n Chat\nuseCompletion\t\n\t\n Completion\t\n\t\n Completion\nuseObject\t\n\t\n StructuredObject\t\n\t\n StructuredObject\n\nContributions\n are welcome to implement missing features for non-React frameworks.\n\nFramework Examples\n\nExplore these example implementations for different frameworks:\n\nNext.js\nNuxt\nSvelteKit\nAngular\nAPI Reference\n\nPlease check out the AI SDK UI API Reference for more details on each function.\n\nPrevious\nAI SDK UI\nNext\nChatbot"
  },
  {
    "title": "AI SDK UI: Chatbot",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/chatbot",
    "html": "AI SDK UI\nChatbot\nCopy markdown\nChatbot\n\nThe useChat hook makes it effortless to create a conversational user interface for your chatbot application. It enables the streaming of chat messages from your AI provider, manages the chat state, and updates the UI automatically as new messages arrive.\n\nTo summarize, the useChat hook provides the following features:\n\nMessage Streaming: All the messages from the AI provider are streamed to the chat UI in real-time.\nManaged States: The hook manages the states for input, messages, status, error and more for you.\nSeamless Integration: Easily integrate your chat AI into any design or layout with minimal effort.\n\nIn this guide, you will learn how to use the useChat hook to create a chatbot application with real-time message streaming. Check out our chatbot with tools guide to learn how to use tools in your chatbot. Let's start with the following example first.\n\nExample\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Page() {\n  const { messages, sendMessage, status } = useChat({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n  });\n  const [input, setInput] = useState('');\n\n\n  return (\n    <>\n      {messages.map(message => (\n        <div key={message.id}>\n          {message.role === 'user' ? 'User: ' : 'AI: '}\n          {message.parts.map((part, index) =>\n            part.type === 'text' ? <span key={index}>{part.text}</span> : null,\n          )}\n        </div>\n      ))}\n\n\n      <form\n        onSubmit={e => {\n          e.preventDefault();\n          if (input.trim()) {\n            sendMessage({ text: input });\n            setInput('');\n          }\n        }}\n      >\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          disabled={status !== 'ready'}\n          placeholder=\"Say something...\"\n        />\n        <button type=\"submit\" disabled={status !== 'ready'}>\n          Submit\n        </button>\n      </form>\n    </>\n  );\n}\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\n\n\n// Allow streaming responses up to 30 seconds\nexport const maxDuration = 30;\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4.1'),\n    system: 'You are a helpful assistant.',\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\n\nThe UI messages have a new parts property that contains the message parts. We recommend rendering the messages using the parts property instead of the content property. The parts property supports different message types, including text, tool invocation, and tool result, and allows for more flexible and complex chat UIs.\n\nIn the Page component, the useChat hook will request to your AI provider endpoint whenever the user sends a message using sendMessage. The messages are then streamed back in real-time and displayed in the chat UI.\n\nThis enables a seamless chat experience where the user can see the AI response as soon as it is available, without having to wait for the entire response to be received.\n\nCustomized UI\n\nuseChat also provides ways to manage the chat message states via code, show status, and update messages without being triggered by user interactions.\n\nStatus\n\nThe useChat hook returns a status. It has the following possible values:\n\nsubmitted: The message has been sent to the API and we're awaiting the start of the response stream.\nstreaming: The response is actively streaming in from the API, receiving chunks of data.\nready: The full response has been received and processed; a new user message can be submitted.\nerror: An error occurred during the API request, preventing successful completion.\n\nYou can use status for e.g. the following purposes:\n\nTo show a loading spinner while the chatbot is processing the user's message.\nTo show a \"Stop\" button to abort the current message.\nTo disable the submit button.\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Page() {\n  const { messages, sendMessage, status, stop } = useChat({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n  });\n  const [input, setInput] = useState('');\n\n\n  return (\n    <>\n      {messages.map(message => (\n        <div key={message.id}>\n          {message.role === 'user' ? 'User: ' : 'AI: '}\n          {message.parts.map((part, index) =>\n            part.type === 'text' ? <span key={index}>{part.text}</span> : null,\n          )}\n        </div>\n      ))}\n\n\n      {(status === 'submitted' || status === 'streaming') && (\n        <div>\n          {status === 'submitted' && <Spinner />}\n          <button type=\"button\" onClick={() => stop()}>\n            Stop\n          </button>\n        </div>\n      )}\n\n\n      <form\n        onSubmit={e => {\n          e.preventDefault();\n          if (input.trim()) {\n            sendMessage({ text: input });\n            setInput('');\n          }\n        }}\n      >\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          disabled={status !== 'ready'}\n          placeholder=\"Say something...\"\n        />\n        <button type=\"submit\" disabled={status !== 'ready'}>\n          Submit\n        </button>\n      </form>\n    </>\n  );\n}\nError State\n\nSimilarly, the error state reflects the error object thrown during the fetch request. It can be used to display an error message, disable the submit button, or show a retry button:\n\nWe recommend showing a generic error message to the user, such as \"Something went wrong.\" This is a good practice to avoid leaking information from the server.\n\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const { messages, sendMessage, error, reload } = useChat({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n  });\n  const [input, setInput] = useState('');\n\n\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role}:{' '}\n          {m.parts.map((part, index) =>\n            part.type === 'text' ? <span key={index}>{part.text}</span> : null,\n          )}\n        </div>\n      ))}\n\n\n      {error && (\n        <>\n          <div>An error occurred.</div>\n          <button type=\"button\" onClick={() => reload()}>\n            Retry\n          </button>\n        </>\n      )}\n\n\n      <form\n        onSubmit={e => {\n          e.preventDefault();\n          if (input.trim()) {\n            sendMessage({ text: input });\n            setInput('');\n          }\n        }}\n      >\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          disabled={error != null}\n        />\n      </form>\n    </div>\n  );\n}\n\nPlease also see the error handling guide for more information.\n\nModify messages\n\nSometimes, you may want to directly modify some existing messages. For example, a delete button can be added to each message to allow users to remove them from the chat history.\n\nThe setMessages function can help you achieve these tasks:\n\nconst { messages, setMessages } = useChat()\n\n\nconst handleDelete = (id) => {\n  setMessages(messages.filter(message => message.id !== id))\n}\n\n\nreturn <>\n  {messages.map(message => (\n    <div key={message.id}>\n      {message.role === 'user' ? 'User: ' : 'AI: '}\n      {message.parts.map((part, index) => (\n        part.type === 'text' ? (\n          <span key={index}>{part.text}</span>\n        ) : null\n      ))}\n      <button onClick={() => handleDelete(message.id)}>Delete</button>\n    </div>\n  ))}\n  ...\n\nYou can think of messages and setMessages as a pair of state and setState in React.\n\nCancellation and regeneration\n\nIt's also a common use case to abort the response message while it's still streaming back from the AI provider. You can do this by calling the stop function returned by the useChat hook.\n\nconst { stop, status } = useChat()\n\n\nreturn <>\n  <button onClick={stop} disabled={!(status === 'streaming' || status === 'submitted')}>Stop</button>\n  ...\n\nWhen the user clicks the \"Stop\" button, the fetch request will be aborted. This avoids consuming unnecessary resources and improves the UX of your chatbot application.\n\nSimilarly, you can also request the AI provider to reprocess the last message by calling the regenerate function returned by the useChat hook:\n\nconst { regenerate, status } = useChat();\n\n\nreturn (\n  <>\n    <button\n      onClick={regenerate}\n      disabled={!(status === 'ready' || status === 'error')}\n    >\n      Regenerate\n    </button>\n    ...\n  </>\n);\n\nWhen the user clicks the \"Regenerate\" button, the AI provider will regenerate the last message and replace the current one correspondingly.\n\nThrottling UI Updates\nThis feature is currently only available for React.\n\nBy default, the useChat hook will trigger a render every time a new chunk is received. You can throttle the UI updates with the experimental_throttle option.\n\npage.tsx\nconst { messages, ... } = useChat({\n  // Throttle the messages and data updates to 50ms:\n  experimental_throttle: 50\n})\nEvent Callbacks\n\nuseChat provides optional event callbacks that you can use to handle different stages of the chatbot lifecycle:\n\nonFinish: Called when the assistant response is completed. The event includes the response message, all messages, and flags for abort, disconnect, and errors.\nonError: Called when an error occurs during the fetch request.\nonData: Called whenever a data part is received.\n\nThese callbacks can be used to trigger additional actions, such as logging, analytics, or custom UI updates.\n\nimport { UIMessage } from 'ai';\n\n\nconst {\n  /* ... */\n} = useChat({\n  onFinish: ({ message, messages, isAbort, isDisconnect, isError }) => {\n    // use information to e.g. update other UI states\n  },\n  onError: error => {\n    console.error('An error occurred:', error);\n  },\n  onData: data => {\n    console.log('Received data part from server:', data);\n  },\n});\n\nIt's worth noting that you can abort the processing by throwing an error in the onData callback. This will trigger the onError callback and stop the message from being appended to the chat UI. This can be useful for handling unexpected responses from the AI provider.\n\nRequest Configuration\nCustom headers, body, and credentials\n\nBy default, the useChat hook sends a HTTP POST request to the /api/chat endpoint with the message list as the request body. You can customize the request in two ways:\n\nHook-Level Configuration (Applied to all requests)\n\nYou can configure transport-level options that will be applied to all requests made by the hook:\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nconst { messages, sendMessage } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/custom-chat',\n    headers: {\n      Authorization: 'your_token',\n    },\n    body: {\n      user_id: '123',\n    },\n    credentials: 'same-origin',\n  }),\n});\nDynamic Hook-Level Configuration\n\nYou can also provide functions that return configuration values. This is useful for authentication tokens that need to be refreshed, or for configuration that depends on runtime conditions:\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nconst { messages, sendMessage } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/custom-chat',\n    headers: () => ({\n      Authorization: `Bearer ${getAuthToken()}`,\n      'X-User-ID': getCurrentUserId(),\n    }),\n    body: () => ({\n      sessionId: getCurrentSessionId(),\n      preferences: getUserPreferences(),\n    }),\n    credentials: () => 'include',\n  }),\n});\n\nFor component state that changes over time, use useRef to store the current value and reference ref.current in your configuration function, or prefer request-level options (see next section) for better reliability.\n\nRequest-Level Configuration (Recommended)\n\nRecommended: Use request-level options for better flexibility and control. Request-level options take precedence over hook-level options and allow you to customize each request individually.\n\n// Pass options as the second parameter to sendMessage\nsendMessage(\n  { text: input },\n  {\n    headers: {\n      Authorization: 'Bearer token123',\n      'X-Custom-Header': 'custom-value',\n    },\n    body: {\n      temperature: 0.7,\n      max_tokens: 100,\n      user_id: '123',\n    },\n    metadata: {\n      userId: 'user123',\n      sessionId: 'session456',\n    },\n  },\n);\n\nThe request-level options are merged with hook-level options, with request-level options taking precedence. On your server side, you can handle the request with this additional information.\n\nSetting custom body fields per request\n\nYou can configure custom body fields on a per-request basis using the second parameter of the sendMessage function. This is useful if you want to pass in additional information to your backend that is not part of the message list.\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const { messages, sendMessage } = useChat();\n  const [input, setInput] = useState('');\n\n\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role}:{' '}\n          {m.parts.map((part, index) =>\n            part.type === 'text' ? <span key={index}>{part.text}</span> : null,\n          )}\n        </div>\n      ))}\n\n\n      <form\n        onSubmit={event => {\n          event.preventDefault();\n          if (input.trim()) {\n            sendMessage(\n              { text: input },\n              {\n                body: {\n                  customKey: 'customValue',\n                },\n              },\n            );\n            setInput('');\n          }\n        }}\n      >\n        <input value={input} onChange={e => setInput(e.target.value)} />\n      </form>\n    </div>\n  );\n}\n\nYou can retrieve these custom fields on your server side by destructuring the request body:\n\napp/api/chat/route.ts\nexport async function POST(req: Request) {\n  // Extract additional information (\"customKey\") from the body of the request:\n  const { messages, customKey }: { messages: UIMessage[]; customKey: string } =\n    await req.json();\n  //...\n}\nMessage Metadata\n\nYou can attach custom metadata to messages for tracking information like timestamps, model details, and token usage.\n\n// Server: Send metadata about the message\nreturn result.toUIMessageStreamResponse({\n  messageMetadata: ({ part }) => {\n    if (part.type === 'start') {\n      return {\n        createdAt: Date.now(),\n        model: 'gpt-4o',\n      };\n    }\n\n\n    if (part.type === 'finish') {\n      return {\n        totalTokens: part.totalUsage.totalTokens,\n      };\n    }\n  },\n});\n// Client: Access metadata via message.metadata\n{\n  messages.map(message => (\n    <div key={message.id}>\n      {message.role}:{' '}\n      {message.metadata?.createdAt &&\n        new Date(message.metadata.createdAt).toLocaleTimeString()}\n      {/* Render message content */}\n      {message.parts.map((part, index) =>\n        part.type === 'text' ? <span key={index}>{part.text}</span> : null,\n      )}\n      {/* Show token count if available */}\n      {message.metadata?.totalTokens && (\n        <span>{message.metadata.totalTokens} tokens</span>\n      )}\n    </div>\n  ));\n}\n\nFor complete examples with type safety and advanced use cases, see the Message Metadata documentation.\n\nTransport Configuration\n\nYou can configure custom transport behavior using the transport option to customize how messages are sent to your API:\n\napp/page.tsx\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nexport default function Chat() {\n  const { messages, sendMessage } = useChat({\n    id: 'my-chat',\n    transport: new DefaultChatTransport({\n      prepareSendMessagesRequest: ({ id, messages }) => {\n        return {\n          body: {\n            id,\n            message: messages[messages.length - 1],\n          },\n        };\n      },\n    }),\n  });\n\n\n  // ... rest of your component\n}\n\nThe corresponding API route receives the custom request format:\n\napp/api/chat/route.ts\nexport async function POST(req: Request) {\n  const { id, message } = await req.json();\n\n\n  // Load existing messages and add the new one\n  const messages = await loadMessages(id);\n  messages.push(message);\n\n\n  const result = streamText({\n    model: openai('gpt-4.1'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\nAdvanced: Trigger-based routing\n\nFor more complex scenarios like message regeneration, you can use trigger-based routing:\n\napp/page.tsx\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nexport default function Chat() {\n  const { messages, sendMessage, regenerate } = useChat({\n    id: 'my-chat',\n    transport: new DefaultChatTransport({\n      prepareSendMessagesRequest: ({ id, messages, trigger, messageId }) => {\n        if (trigger === 'submit-user-message') {\n          return {\n            body: {\n              trigger: 'submit-user-message',\n              id,\n              message: messages[messages.length - 1],\n              messageId,\n            },\n          };\n        } else if (trigger === 'regenerate-assistant-message') {\n          return {\n            body: {\n              trigger: 'regenerate-assistant-message',\n              id,\n              messageId,\n            },\n          };\n        }\n        throw new Error(`Unsupported trigger: ${trigger}`);\n      },\n    }),\n  });\n\n\n  // ... rest of your component\n}\n\nThe corresponding API route would handle different triggers:\n\napp/api/chat/route.ts\nexport async function POST(req: Request) {\n  const { trigger, id, message, messageId } = await req.json();\n\n\n  const chat = await readChat(id);\n  let messages = chat.messages;\n\n\n  if (trigger === 'submit-user-message') {\n    // Handle new user message\n    messages = [...messages, message];\n  } else if (trigger === 'regenerate-assistant-message') {\n    // Handle message regeneration - remove messages after messageId\n    const messageIndex = messages.findIndex(m => m.id === messageId);\n    if (messageIndex !== -1) {\n      messages = messages.slice(0, messageIndex);\n    }\n  }\n\n\n  const result = streamText({\n    model: openai('gpt-4.1'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\n\nTo learn more about building custom transports, refer to the Transport API documentation.\n\nControlling the response stream\n\nWith streamText, you can control how error messages and usage information are sent back to the client.\n\nError Messages\n\nBy default, the error message is masked for security reasons. The default error message is \"An error occurred.\" You can forward error messages or send your own error message by providing a getErrorMessage function:\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4.1'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    onError: error => {\n      if (error == null) {\n        return 'unknown error';\n      }\n\n\n      if (typeof error === 'string') {\n        return error;\n      }\n\n\n      if (error instanceof Error) {\n        return error.message;\n      }\n\n\n      return JSON.stringify(error);\n    },\n  });\n}\nUsage Information\n\nTrack token consumption and resource usage with message metadata:\n\nDefine a custom metadata type with usage fields (optional, for type safety)\nAttach usage data using messageMetadata in your response\nDisplay usage metrics in your UI components\n\nUsage data is attached as metadata to messages and becomes available once the model completes its response generation.\n\nimport { openai } from '@ai-sdk/openai';\nimport {\n  convertToModelMessages,\n  streamText,\n  UIMessage,\n  type LanguageModelUsage,\n} from 'ai';\n\n\n// Create a new metadata type (optional for type-safety)\ntype MyMetadata = {\n  totalUsage: LanguageModelUsage;\n};\n\n\n// Create a new custom message type with your own metadata\nexport type MyUIMessage = UIMessage<MyMetadata>;\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: MyUIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    messageMetadata: ({ part }) => {\n      // Send total usage when generation is finished\n      if (part.type === 'finish') {\n        return { totalUsage: part.totalUsage };\n      }\n    },\n  });\n}\n\nThen, on the client, you can access the message-level metadata.\n\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport type { MyUIMessage } from './api/chat/route';\nimport { DefaultChatTransport } from 'ai';\n\n\nexport default function Chat() {\n  // Use custom message type defined on the server (optional for type-safety)\n  const { messages } = useChat<MyUIMessage>({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n  });\n\n\n  return (\n    <div className=\"flex flex-col w-full max-w-md py-24 mx-auto stretch\">\n      {messages.map(m => (\n        <div key={m.id} className=\"whitespace-pre-wrap\">\n          {m.role === 'user' ? 'User: ' : 'AI: '}\n          {m.parts.map(part => {\n            if (part.type === 'text') {\n              return part.text;\n            }\n          })}\n          {/* Render usage via metadata */}\n          {m.metadata?.totalUsage && (\n            <div>Total usage: {m.metadata?.totalUsage.totalTokens} tokens</div>\n          )}\n        </div>\n      ))}\n    </div>\n  );\n}\n\nYou can also access your metadata from the onFinish callback of useChat:\n\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport type { MyUIMessage } from './api/chat/route';\nimport { DefaultChatTransport } from 'ai';\n\n\nexport default function Chat() {\n  // Use custom message type defined on the server (optional for type-safety)\n  const { messages } = useChat<MyUIMessage>({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n    onFinish: ({ message }) => {\n      // Access message metadata via onFinish callback\n      console.log(message.metadata?.totalUsage);\n    },\n  });\n}\nText Streams\n\nuseChat can handle plain text streams by setting the streamProtocol option to text:\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { TextStreamChatTransport } from 'ai';\n\n\nexport default function Chat() {\n  const { messages } = useChat({\n    transport: new TextStreamChatTransport({\n      api: '/api/chat',\n    }),\n  });\n\n\n  return <>...</>;\n}\n\nThis configuration also works with other backend servers that stream plain text. Check out the stream protocol guide for more information.\n\nWhen using TextStreamChatTransport, tool calls, usage information and finish reasons are not available.\n\nReasoning\n\nSome models such as as DeepSeek deepseek-reasoner and Anthropic claude-3-7-sonnet-20250219 support reasoning tokens. These tokens are typically sent before the message content. You can forward them to the client with the sendReasoning option:\n\napp/api/chat/route.ts\nimport { deepseek } from '@ai-sdk/deepseek';\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: deepseek('deepseek-reasoner'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    sendReasoning: true,\n  });\n}\n\nOn the client side, you can access the reasoning parts of the message object.\n\nReasoning parts have a text property that contains the reasoning content.\n\napp/page.tsx\nmessages.map(message => (\n  <div key={message.id}>\n    {message.role === 'user' ? 'User: ' : 'AI: '}\n    {message.parts.map((part, index) => {\n      // text parts:\n      if (part.type === 'text') {\n        return <div key={index}>{part.text}</div>;\n      }\n\n\n      // reasoning parts:\n      if (part.type === 'reasoning') {\n        return <pre key={index}>{part.text}</pre>;\n      }\n    })}\n  </div>\n));\nSources\n\nSome providers such as Perplexity and Google Generative AI include sources in the response.\n\nCurrently sources are limited to web pages that ground the response. You can forward them to the client with the sendSources option:\n\napp/api/chat/route.ts\nimport { perplexity } from '@ai-sdk/perplexity';\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: perplexity('sonar-pro'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    sendSources: true,\n  });\n}\n\nOn the client side, you can access source parts of the message object. There are two types of sources: source-url for web pages and source-document for documents. Here is an example that renders both types of sources:\n\napp/page.tsx\nmessages.map(message => (\n  <div key={message.id}>\n    {message.role === 'user' ? 'User: ' : 'AI: '}\n\n\n    {/* Render URL sources */}\n    {message.parts\n      .filter(part => part.type === 'source-url')\n      .map(part => (\n        <span key={`source-${part.id}`}>\n          [\n          <a href={part.url} target=\"_blank\">\n            {part.title ?? new URL(part.url).hostname}\n          </a>\n          ]\n        </span>\n      ))}\n\n\n    {/* Render document sources */}\n    {message.parts\n      .filter(part => part.type === 'source-document')\n      .map(part => (\n        <span key={`source-${part.id}`}>\n          [<span>{part.title ?? `Document ${part.id}`}</span>]\n        </span>\n      ))}\n  </div>\n));\nImage Generation\n\nSome models such as Google gemini-2.5-flash-image-preview support image generation. When images are generated, they are exposed as files to the client. On the client side, you can access file parts of the message object and render them as images.\n\napp/page.tsx\nmessages.map(message => (\n  <div key={message.id}>\n    {message.role === 'user' ? 'User: ' : 'AI: '}\n    {message.parts.map((part, index) => {\n      if (part.type === 'text') {\n        return <div key={index}>{part.text}</div>;\n      } else if (part.type === 'file' && part.mediaType.startsWith('image/')) {\n        return <img key={index} src={part.url} alt=\"Generated image\" />;\n      }\n    })}\n  </div>\n));\nAttachments\n\nThe useChat hook supports sending file attachments along with a message as well as rendering them on the client. This can be useful for building applications that involve sending images, files, or other media content to the AI provider.\n\nThere are two ways to send files with a message: using a FileList object from file inputs or using an array of file objects.\n\nFileList\n\nBy using FileList, you can send multiple files as attachments along with a message using the file input element. The useChat hook will automatically convert them into data URLs and send them to the AI provider.\n\nCurrently, only image/* and text/* content types get automatically converted into multi-modal content parts. You will need to handle other content types manually.\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useRef, useState } from 'react';\n\n\nexport default function Page() {\n  const { messages, sendMessage, status } = useChat();\n\n\n  const [input, setInput] = useState('');\n  const [files, setFiles] = useState<FileList | undefined>(undefined);\n  const fileInputRef = useRef<HTMLInputElement>(null);\n\n\n  return (\n    <div>\n      <div>\n        {messages.map(message => (\n          <div key={message.id}>\n            <div>{`${message.role}: `}</div>\n\n\n            <div>\n              {message.parts.map((part, index) => {\n                if (part.type === 'text') {\n                  return <span key={index}>{part.text}</span>;\n                }\n\n\n                if (\n                  part.type === 'file' &&\n                  part.mediaType?.startsWith('image/')\n                ) {\n                  return <img key={index} src={part.url} alt={part.filename} />;\n                }\n\n\n                return null;\n              })}\n            </div>\n          </div>\n        ))}\n      </div>\n\n\n      <form\n        onSubmit={event => {\n          event.preventDefault();\n          if (input.trim()) {\n            sendMessage({\n              text: input,\n              files,\n            });\n            setInput('');\n            setFiles(undefined);\n\n\n            if (fileInputRef.current) {\n              fileInputRef.current.value = '';\n            }\n          }\n        }}\n      >\n        <input\n          type=\"file\"\n          onChange={event => {\n            if (event.target.files) {\n              setFiles(event.target.files);\n            }\n          }}\n          multiple\n          ref={fileInputRef}\n        />\n        <input\n          value={input}\n          placeholder=\"Send message...\"\n          onChange={e => setInput(e.target.value)}\n          disabled={status !== 'ready'}\n        />\n      </form>\n    </div>\n  );\n}\nFile Objects\n\nYou can also send files as objects along with a message. This can be useful for sending pre-uploaded files or data URLs.\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\nimport { FileUIPart } from 'ai';\n\n\nexport default function Page() {\n  const { messages, sendMessage, status } = useChat();\n\n\n  const [input, setInput] = useState('');\n  const [files] = useState<FileUIPart[]>([\n    {\n      type: 'file',\n      filename: 'earth.png',\n      mediaType: 'image/png',\n      url: 'https://example.com/earth.png',\n    },\n    {\n      type: 'file',\n      filename: 'moon.png',\n      mediaType: 'image/png',\n      url: 'data:image/png;base64,iVBORw0KGgo...',\n    },\n  ]);\n\n\n  return (\n    <div>\n      <div>\n        {messages.map(message => (\n          <div key={message.id}>\n            <div>{`${message.role}: `}</div>\n\n\n            <div>\n              {message.parts.map((part, index) => {\n                if (part.type === 'text') {\n                  return <span key={index}>{part.text}</span>;\n                }\n\n\n                if (\n                  part.type === 'file' &&\n                  part.mediaType?.startsWith('image/')\n                ) {\n                  return <img key={index} src={part.url} alt={part.filename} />;\n                }\n\n\n                return null;\n              })}\n            </div>\n          </div>\n        ))}\n      </div>\n\n\n      <form\n        onSubmit={event => {\n          event.preventDefault();\n          if (input.trim()) {\n            sendMessage({\n              text: input,\n              files,\n            });\n            setInput('');\n          }\n        }}\n      >\n        <input\n          value={input}\n          placeholder=\"Send message...\"\n          onChange={e => setInput(e.target.value)}\n          disabled={status !== 'ready'}\n        />\n      </form>\n    </div>\n  );\n}\nType Inference for Tools\n\nWhen working with tools in TypeScript, AI SDK UI provides type inference helpers to ensure type safety for your tool inputs and outputs.\n\nInferUITool\n\nThe InferUITool type helper infers the input and output types of a single tool for use in UI messages:\n\nimport { InferUITool } from 'ai';\nimport { z } from 'zod';\n\n\nconst weatherTool = {\n  description: 'Get the current weather',\n  inputSchema: z.object({\n    location: z.string().describe('The city and state'),\n  }),\n  execute: async ({ location }) => {\n    return `The weather in ${location} is sunny.`;\n  },\n};\n\n\n// Infer the types from the tool\ntype WeatherUITool = InferUITool<typeof weatherTool>;\n// This creates a type with:\n// {\n//   input: { location: string };\n//   output: string;\n// }\nInferUITools\n\nThe InferUITools type helper infers the input and output types of a ToolSet:\n\nimport { InferUITools, ToolSet } from 'ai';\nimport { z } from 'zod';\n\n\nconst tools = {\n  weather: {\n    description: 'Get the current weather',\n    inputSchema: z.object({\n      location: z.string().describe('The city and state'),\n    }),\n    execute: async ({ location }) => {\n      return `The weather in ${location} is sunny.`;\n    },\n  },\n  calculator: {\n    description: 'Perform basic arithmetic',\n    inputSchema: z.object({\n      operation: z.enum(['add', 'subtract', 'multiply', 'divide']),\n      a: z.number(),\n      b: z.number(),\n    }),\n    execute: async ({ operation, a, b }) => {\n      switch (operation) {\n        case 'add':\n          return a + b;\n        case 'subtract':\n          return a - b;\n        case 'multiply':\n          return a * b;\n        case 'divide':\n          return a / b;\n      }\n    },\n  },\n} satisfies ToolSet;\n\n\n// Infer the types from the tool set\ntype MyUITools = InferUITools<typeof tools>;\n// This creates a type with:\n// {\n//   weather: { input: { location: string }; output: string };\n//   calculator: { input: { operation: 'add' | 'subtract' | 'multiply' | 'divide'; a: number; b: number }; output: number };\n// }\nUsing Inferred Types\n\nYou can use these inferred types to create a custom UIMessage type and pass it to various AI SDK UI functions:\n\nimport { InferUITools, UIMessage, UIDataTypes } from 'ai';\n\n\ntype MyUITools = InferUITools<typeof tools>;\ntype MyUIMessage = UIMessage<never, UIDataTypes, MyUITools>;\n\nPass the custom type to useChat or createUIMessageStream:\n\nimport { useChat } from '@ai-sdk/react';\nimport { createUIMessageStream } from 'ai';\nimport type { MyUIMessage } from './types';\n\n\n// With useChat\nconst { messages } = useChat<MyUIMessage>();\n\n\n// With createUIMessageStream\nconst stream = createUIMessageStream<MyUIMessage>(/* ... */);\n\nThis provides full type safety for tool inputs and outputs on the client and server.\n\nPrevious\nOverview\nNext\nChatbot Message Persistence"
  },
  {
    "title": "AI SDK UI: Chatbot Message Persistence",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-message-persistence",
    "html": "AI SDK UI\nChatbot Message Persistence\nCopy markdown\nChatbot Message Persistence\n\nBeing able to store and load chat messages is crucial for most AI chatbots. In this guide, we'll show how to implement message persistence with useChat and streamText.\n\nThis guide does not cover authorization, error handling, or other real-world considerations. It is intended to be a simple example of how to implement message persistence.\n\nStarting a new chat\n\nWhen the user navigates to the chat page without providing a chat ID, we need to create a new chat and redirect to the chat page with the new chat ID.\n\napp/chat/page.tsx\nimport { redirect } from 'next/navigation';\nimport { createChat } from '@util/chat-store';\n\n\nexport default async function Page() {\n  const id = await createChat(); // create a new chat\n  redirect(`/chat/${id}`); // redirect to chat page, see below\n}\n\nOur example chat store implementation uses files to store the chat messages. In a real-world application, you would use a database or a cloud storage service, and get the chat ID from the database. That being said, the function interfaces are designed to be easily replaced with other implementations.\n\nutil/chat-store.ts\nimport { generateId } from 'ai';\nimport { existsSync, mkdirSync } from 'fs';\nimport { writeFile } from 'fs/promises';\nimport path from 'path';\n\n\nexport async function createChat(): Promise<string> {\n  const id = generateId(); // generate a unique chat ID\n  await writeFile(getChatFile(id), '[]'); // create an empty chat file\n  return id;\n}\n\n\nfunction getChatFile(id: string): string {\n  const chatDir = path.join(process.cwd(), '.chats');\n  if (!existsSync(chatDir)) mkdirSync(chatDir, { recursive: true });\n  return path.join(chatDir, `${id}.json`);\n}\nLoading an existing chat\n\nWhen the user navigates to the chat page with a chat ID, we need to load the chat messages from storage.\n\nThe loadChat function in our file-based chat store is implemented as follows:\n\nutil/chat-store.ts\nimport { UIMessage } from 'ai';\nimport { readFile } from 'fs/promises';\n\n\nexport async function loadChat(id: string): Promise<UIMessage[]> {\n  return JSON.parse(await readFile(getChatFile(id), 'utf8'));\n}\n\n\n// ... rest of the file\nValidating messages on the server\n\nWhen processing messages on the server that contain tool calls, custom metadata, or data parts, you should validate them using validateUIMessages before sending them to the model.\n\nValidation with tools\n\nWhen your messages include tool calls, validate them against your tool definitions:\n\napp/api/chat/route.ts\nimport {\n  convertToModelMessages,\n  streamText,\n  UIMessage,\n  validateUIMessages,\n  tool,\n} from 'ai';\nimport { z } from 'zod';\nimport { loadChat, saveChat } from '@util/chat-store';\nimport { openai } from '@ai-sdk/openai';\nimport { dataPartsSchema, metadataSchema } from '@util/schemas';\n\n\n// Define your tools\nconst tools = {\n  weather: tool({\n    description: 'Get weather information',\n    parameters: z.object({\n      location: z.string(),\n      units: z.enum(['celsius', 'fahrenheit']),\n    }),\n    execute: async ({ location, units }) => {\n      /* tool implementation */\n    },\n  }),\n  // other tools\n};\n\n\nexport async function POST(req: Request) {\n  const { message, id } = await req.json();\n\n\n  // Load previous messages from database\n  const previousMessages = await loadChat(id);\n\n\n  // Append new message to previousMessages messages\n  const messages = [...previousMessages, message];\n\n\n  // Validate loaded messages against\n  // tools, data parts schema, and metadata schema\n  const validatedMessages = await validateUIMessages({\n    messages,\n    tools, // Ensures tool calls in messages match current schemas\n    dataPartsSchema,\n    metadataSchema,\n  });\n\n\n  const result = streamText({\n    model: openai('gpt-4o-mini'),\n    messages: convertToModelMessages(validatedMessages),\n    tools,\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    onFinish: ({ messages }) => {\n      saveChat({ chatId: id, messages });\n    },\n  });\n}\nHandling validation errors\n\nHandle validation errors gracefully when messages from the database don't match current schemas:\n\napp/api/chat/route.ts\nimport {\n  convertToModelMessages,\n  streamText,\n  validateUIMessages,\n  TypeValidationError,\n} from 'ai';\nimport { type MyUIMessage } from '@/types';\n\n\nexport async function POST(req: Request) {\n  const { message, id } = await req.json();\n\n\n  // Load and validate messages from database\n  let validatedMessages: MyUIMessage[];\n\n\n  try {\n    const previousMessages = await loadMessagesFromDB(id);\n    validatedMessages = await validateUIMessages({\n      // append the new message to the previous messages:\n      messages: [...previousMessages, message],\n      tools,\n      metadataSchema,\n    });\n  } catch (error) {\n    if (error instanceof TypeValidationError) {\n      // Log validation error for monitoring\n      console.error('Database messages validation failed:', error);\n      // Could implement message migration or filtering here\n      // For now, start with empty history\n      validatedMessages = [];\n    } else {\n      throw error;\n    }\n  }\n\n\n  // Continue with validated messages...\n}\nDisplaying the chat\n\nOnce messages are loaded from storage, you can display them in your chat UI. Here's how to set up the page component and the chat display:\n\napp/chat/[id]/page.tsx\nimport { loadChat } from '@util/chat-store';\nimport Chat from '@ui/chat';\n\n\nexport default async function Page(props: { params: Promise<{ id: string }> }) {\n  const { id } = await props.params;\n  const messages = await loadChat(id);\n  return <Chat id={id} initialMessages={messages} />;\n}\n\nThe chat component uses the useChat hook to manage the conversation:\n\nui/chat.tsx\n'use client';\n\n\nimport { UIMessage, useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Chat({\n  id,\n  initialMessages,\n}: { id?: string | undefined; initialMessages?: UIMessage[] } = {}) {\n  const [input, setInput] = useState('');\n  const { sendMessage, messages } = useChat({\n    id, // use the provided chat ID\n    messages: initialMessages, // load initial messages\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n  });\n\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    if (input.trim()) {\n      sendMessage({ text: input });\n      setInput('');\n    }\n  };\n\n\n  // simplified rendering code, extend as needed:\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role === 'user' ? 'User: ' : 'AI: '}\n          {m.parts\n            .map(part => (part.type === 'text' ? part.text : ''))\n            .join('')}\n        </div>\n      ))}\n\n\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          placeholder=\"Type a message...\"\n        />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\nStoring messages\n\nuseChat sends the chat id and the messages to the backend.\n\nThe useChat message format is different from the ModelMessage format. The useChat message format is designed for frontend display, and contains additional fields such as id and createdAt. We recommend storing the messages in the useChat message format.\n\nWhen loading messages from storage that contain tools, metadata, or custom data parts, validate them using validateUIMessages before processing (see the validation section above).\n\nStoring messages is done in the onFinish callback of the toUIMessageStreamResponse function. onFinish receives the complete messages including the new AI response as UIMessage[].\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { saveChat } from '@util/chat-store';\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\n\n\nexport async function POST(req: Request) {\n  const { messages, chatId }: { messages: UIMessage[]; chatId: string } =\n    await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o-mini'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    onFinish: ({ messages }) => {\n      saveChat({ chatId, messages });\n    },\n  });\n}\n\nThe actual storage of the messages is done in the saveChat function, which in our file-based chat store is implemented as follows:\n\nutil/chat-store.ts\nimport { UIMessage } from 'ai';\nimport { writeFile } from 'fs/promises';\n\n\nexport async function saveChat({\n  chatId,\n  messages,\n}: {\n  chatId: string;\n  messages: UIMessage[];\n}): Promise<void> {\n  const content = JSON.stringify(messages, null, 2);\n  await writeFile(getChatFile(chatId), content);\n}\n\n\n// ... rest of the file\nMessage IDs\n\nIn addition to a chat ID, each message has an ID. You can use this message ID to e.g. manipulate individual messages.\n\nClient-side vs Server-side ID Generation\n\nBy default, message IDs are generated client-side:\n\nUser message IDs are generated by the useChat hook on the client\nAI response message IDs are generated by streamText on the server\n\nFor applications without persistence, client-side ID generation works perfectly. However, for persistence, you need server-side generated IDs to ensure consistency across sessions and prevent ID conflicts when messages are stored and retrieved.\n\nSetting Up Server-side ID Generation\n\nWhen implementing persistence, you have two options for generating server-side IDs:\n\nUsing generateMessageId in toUIMessageStreamResponse\nSetting IDs in your start message part with createUIMessageStream\nOption 1: Using generateMessageId in toUIMessageStreamResponse\n\nYou can control the ID format by providing ID generators using createIdGenerator():\n\napp/api/chat/route.ts\nimport { createIdGenerator, streamText } from 'ai';\n\n\nexport async function POST(req: Request) {\n  // ...\n  const result = streamText({\n    // ...\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    // Generate consistent server-side IDs for persistence:\n    generateMessageId: createIdGenerator({\n      prefix: 'msg',\n      size: 16,\n    }),\n    onFinish: ({ messages }) => {\n      saveChat({ chatId, messages });\n    },\n  });\n}\nOption 2: Setting IDs with createUIMessageStream\n\nAlternatively, you can use createUIMessageStream to control the message ID by writing a start message part:\n\napp/api/chat/route.ts\nimport {\n  generateId,\n  streamText,\n  createUIMessageStream,\n  createUIMessageStreamResponse,\n} from 'ai';\n\n\nexport async function POST(req: Request) {\n  const { messages, chatId } = await req.json();\n\n\n  const stream = createUIMessageStream({\n    execute: ({ writer }) => {\n      // Write start message part with custom ID\n      writer.write({\n        type: 'start',\n        messageId: generateId(), // Generate server-side ID for persistence\n      });\n\n\n      const result = streamText({\n        model: openai('gpt-4o-mini'),\n        messages: convertToModelMessages(messages),\n      });\n\n\n      writer.merge(result.toUIMessageStream({ sendStart: false })); // omit start message part\n    },\n    originalMessages: messages,\n    onFinish: ({ responseMessage }) => {\n      // save your chat here\n    },\n  });\n\n\n  return createUIMessageStreamResponse({ stream });\n}\n\nFor client-side applications that don't require persistence, you can still customize client-side ID generation:\n\nui/chat.tsx\nimport { createIdGenerator } from 'ai';\nimport { useChat } from '@ai-sdk/react';\n\n\nconst { ... } = useChat({\n  generateId: createIdGenerator({\n    prefix: 'msgc',\n    size: 16,\n  }),\n  // ...\n});\nSending only the last message\n\nOnce you have implemented message persistence, you might want to send only the last message to the server. This reduces the amount of data sent to the server on each request and can improve performance.\n\nTo achieve this, you can provide a prepareSendMessagesRequest function to the transport. This function receives the messages and the chat ID, and returns the request body to be sent to the server.\n\nui/chat.tsx\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nconst {\n  // ...\n} = useChat({\n  // ...\n  transport: new DefaultChatTransport({\n    api: '/api/chat',\n    // only send the last message to the server:\n    prepareSendMessagesRequest({ messages, id }) {\n      return { body: { message: messages[messages.length - 1], id } };\n    },\n  }),\n});\n\nOn the server, you can then load the previous messages and append the new message to the previous messages. If your messages contain tools, metadata, or custom data parts, you should validate them:\n\napp/api/chat/route.ts\nimport { convertToModelMessages, UIMessage, validateUIMessages } from 'ai';\n// import your tools and schemas\n\n\nexport async function POST(req: Request) {\n  // get the last message from the client:\n  const { message, id } = await req.json();\n\n\n  // load the previous messages from the server:\n  const previousMessages = await loadChat(id);\n\n\n  // validate messages if they contain tools, metadata, or data parts:\n  const validatedMessages = await validateUIMessages({\n    // append the new message to the previous messages:\n    messages: [...previousMessages, message],\n    tools, // if using tools\n    metadataSchema, // if using custom metadata\n    dataSchemas, // if using custom data parts\n  });\n\n\n  const result = streamText({\n    // ...\n    messages: convertToModelMessages(validatedMessages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: validatedMessages,\n    onFinish: ({ messages }) => {\n      saveChat({ chatId: id, messages });\n    },\n  });\n}\nHandling client disconnects\n\nBy default, the AI SDK streamText function uses backpressure to the language model provider to prevent the consumption of tokens that are not yet requested.\n\nHowever, this means that when the client disconnects, e.g. by closing the browser tab or because of a network issue, the stream from the LLM will be aborted and the conversation may end up in a broken state.\n\nAssuming that you have a storage solution in place, you can use the consumeStream method to consume the stream on the backend, and then save the result as usual. consumeStream effectively removes the backpressure, meaning that the result is stored even when the client has already disconnected.\n\napp/api/chat/route.ts\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\nimport { saveChat } from '@util/chat-store';\n\n\nexport async function POST(req: Request) {\n  const { messages, chatId }: { messages: UIMessage[]; chatId: string } =\n    await req.json();\n\n\n  const result = streamText({\n    model,\n    messages: convertToModelMessages(messages),\n  });\n\n\n  // consume the stream to ensure it runs to completion & triggers onFinish\n  // even when the client response is aborted:\n  result.consumeStream(); // no await\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    onFinish: ({ messages }) => {\n      saveChat({ chatId, messages });\n    },\n  });\n}\n\nWhen the client reloads the page after a disconnect, the chat will be restored from the storage solution.\n\nIn production applications, you would also track the state of the request (in progress, complete) in your stored messages and use it on the client to cover the case where the client reloads the page after a disconnection, but the streaming is not yet complete.\n\nFor more robust handling of disconnects, you may want to add resumability on disconnects. Check out the Chatbot Resume Streams documentation to learn more.\n\nPrevious\nChatbot\nNext\nChatbot Resume Streams"
  },
  {
    "title": "AI SDK UI: Chatbot Resume Streams",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-resume-streams",
    "html": "AI SDK UI\nChatbot Resume Streams\nCopy markdown\nChatbot Resume Streams\n\nuseChat supports resuming ongoing streams after page reloads. Use this feature to build applications with long-running generations.\n\nStream resumption is not compatible with abort functionality. Closing a tab or refreshing the page triggers an abort signal that will break the resumption mechanism. Do not use resume: true if you need abort functionality in your application. See troubleshooting for more details.\n\nHow stream resumption works\n\nStream resumption requires persistence for messages and active streams in your application. The AI SDK provides tools to connect to storage, but you need to set up the storage yourself.\n\nThe AI SDK provides:\n\nA resume option in useChat that automatically reconnects to active streams\nAccess to the outgoing stream through the consumeSseStream callback\nAutomatic HTTP requests to your resume endpoints\n\nYou build:\n\nStorage to track which stream belongs to each chat\nRedis to store the UIMessage stream\nTwo API endpoints: POST to create streams, GET to resume them\nIntegration with resumable-stream\n to manage Redis storage\nPrerequisites\n\nTo implement resumable streams in your chat application, you need:\n\nThe resumable-stream package - Handles the publisher/subscriber mechanism for streams\nA Redis instance - Stores stream data (e.g. Redis through Vercel\n)\nA persistence layer - Tracks which stream ID is active for each chat (e.g. database)\nImplementation\n1. Client-side: Enable stream resumption\n\nUse the resume option in the useChat hook to enable stream resumption. When resume is true, the hook automatically attempts to reconnect to any active stream for the chat on mount:\n\napp/chat/[chatId]/chat.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport, type UIMessage } from 'ai';\n\n\nexport function Chat({\n  chatData,\n  resume = false,\n}: {\n  chatData: { id: string; messages: UIMessage[] };\n  resume?: boolean;\n}) {\n  const { messages, sendMessage, status } = useChat({\n    id: chatData.id,\n    messages: chatData.messages,\n    resume, // Enable automatic stream resumption\n    transport: new DefaultChatTransport({\n      // You must send the id of the chat\n      prepareSendMessagesRequest: ({ id, messages }) => {\n        return {\n          body: {\n            id,\n            message: messages[messages.length - 1],\n          },\n        };\n      },\n    }),\n  });\n\n\n  return <div>{/* Your chat UI */}</div>;\n}\n\nYou must send the chat ID with each request (see prepareSendMessagesRequest).\n\nWhen you enable resume, the useChat hook makes a GET request to /api/chat/[id]/stream on mount to check for and resume any active streams.\n\nLet's start by creating the POST handler to create the resumable stream.\n\n2. Create the POST handler\n\nThe POST handler creates resumable streams using the consumeSseStream callback:\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { readChat, saveChat } from '@util/chat-store';\nimport {\n  convertToModelMessages,\n  generateId,\n  streamText,\n  type UIMessage,\n} from 'ai';\nimport { after } from 'next/server';\nimport { createResumableStreamContext } from 'resumable-stream';\n\n\nexport async function POST(req: Request) {\n  const {\n    message,\n    id,\n  }: {\n    message: UIMessage | undefined;\n    id: string;\n  } = await req.json();\n\n\n  const chat = await readChat(id);\n  let messages = chat.messages;\n\n\n  messages = [...messages, message!];\n\n\n  // Clear any previous active stream and save the user message\n  saveChat({ id, messages, activeStreamId: null });\n\n\n  const result = streamText({\n    model: openai('gpt-4o-mini'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages,\n    generateMessageId: generateId,\n    onFinish: ({ messages }) => {\n      // Clear the active stream when finished\n      saveChat({ id, messages, activeStreamId: null });\n    },\n    async consumeSseStream({ stream }) {\n      const streamId = generateId();\n\n\n      // Create a resumable stream from the SSE stream\n      const streamContext = createResumableStreamContext({ waitUntil: after });\n      await streamContext.createNewResumableStream(streamId, () => stream);\n\n\n      // Update the chat with the active stream ID\n      saveChat({ id, activeStreamId: streamId });\n    },\n  });\n}\n3. Implement the GET handler\n\nCreate a GET handler at /api/chat/[id]/stream that:\n\nReads the chat ID from the route params\nLoads the chat data to check for an active stream\nReturns 204 (No Content) if no stream is active\nResumes the existing stream if one is found\napp/api/chat/[id]/stream/route.ts\nimport { readChat } from '@util/chat-store';\nimport { UI_MESSAGE_STREAM_HEADERS } from 'ai';\nimport { after } from 'next/server';\nimport { createResumableStreamContext } from 'resumable-stream';\n\n\nexport async function GET(\n  _: Request,\n  { params }: { params: Promise<{ id: string }> },\n) {\n  const { id } = await params;\n\n\n  const chat = await readChat(id);\n\n\n  if (chat.activeStreamId == null) {\n    // no content response when there is no active stream\n    return new Response(null, { status: 204 });\n  }\n\n\n  const streamContext = createResumableStreamContext({\n    waitUntil: after,\n  });\n\n\n  return new Response(\n    await streamContext.resumeExistingStream(chat.activeStreamId),\n    { headers: UI_MESSAGE_STREAM_HEADERS },\n  );\n}\n\nThe after function from Next.js allows work to continue after the response has been sent. This ensures that the resumable stream persists in Redis even after the initial response is returned to the client, enabling reconnection later.\n\nHow it works\nRequest lifecycle\n\nThe diagram above shows the complete lifecycle of a resumable stream:\n\nStream creation: When you send a new message, the POST handler uses streamText to generate the response. The consumeSseStream callback creates a resumable stream with a unique ID and stores it in Redis through the resumable-stream package\nStream tracking: Your persistence layer saves the activeStreamId in the chat data\nClient reconnection: When the client reconnects (page reload), the resume option triggers a GET request to /api/chat/[id]/stream\nStream recovery: The GET handler checks for an activeStreamId and uses resumeExistingStream to reconnect. If no active stream exists, it returns a 204 (No Content) response\nCompletion cleanup: When the stream finishes, the onFinish callback clears the activeStreamId by setting it to null\nCustomize the resume endpoint\n\nBy default, the useChat hook makes a GET request to /api/chat/[id]/stream when resuming. Customize this endpoint, credentials, and headers, using the prepareReconnectToStreamRequest option in DefaultChatTransport:\n\napp/chat/[chatId]/chat.tsx\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nexport function Chat({ chatData, resume }) {\n  const { messages, sendMessage } = useChat({\n    id: chatData.id,\n    messages: chatData.messages,\n    resume,\n    transport: new DefaultChatTransport({\n      // Customize reconnect settings (optional)\n      prepareReconnectToStreamRequest: ({ id }) => {\n        return {\n          api: `/api/chat/${id}/stream`, // Default pattern\n          // Or use a different pattern:\n          // api: `/api/streams/${id}/resume`,\n          // api: `/api/resume-chat?id=${id}`,\n          credentials: 'include', // Include cookies/auth\n          headers: {\n            Authorization: 'Bearer token',\n            'X-Custom-Header': 'value',\n          },\n        };\n      },\n    }),\n  });\n\n\n  return <div>{/* Your chat UI */}</div>;\n}\n\nThis lets you:\n\nMatch your existing API route structure\nAdd query parameters or custom paths\nIntegrate with different backend architectures\nImportant considerations\nIncompatibility with abort: Stream resumption is not compatible with abort functionality. Closing a tab or refreshing the page triggers an abort signal that will break the resumption mechanism. Do not use resume: true if you need abort functionality in your application\nStream expiration: Streams in Redis expire after a set time (configurable in the resumable-stream package)\nMultiple clients: Multiple clients can connect to the same stream simultaneously\nError handling: When no active stream exists, the GET handler returns a 204 (No Content) status code\nSecurity: Ensure proper authentication and authorization for both creating and resuming streams\nRace conditions: Clear the activeStreamId when starting a new stream to prevent resuming outdated streams\n\n\nView Example on GitHub\nPrevious\nChatbot Message Persistence\nNext\nChatbot Tool Usage"
  },
  {
    "title": "AI SDK UI: Chatbot Tool Usage",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage",
    "html": "AI SDK UI\nChatbot Tool Usage\nCopy markdown\nChatbot Tool Usage\n\nWith useChat and streamText, you can use tools in your chatbot application. The AI SDK supports three types of tools in this context:\n\nAutomatically executed server-side tools\nAutomatically executed client-side tools\nTools that require user interaction, such as confirmation dialogs\n\nThe flow is as follows:\n\nThe user enters a message in the chat UI.\nThe message is sent to the API route.\nIn your server side route, the language model generates tool calls during the streamText call.\nAll tool calls are forwarded to the client.\nServer-side tools are executed using their execute method and their results are forwarded to the client.\nClient-side tools that should be automatically executed are handled with the onToolCall callback. You must call addToolResult to provide the tool result.\nClient-side tool that require user interactions can be displayed in the UI. The tool calls and results are available as tool invocation parts in the parts property of the last assistant message.\nWhen the user interaction is done, addToolResult can be used to add the tool result to the chat.\nThe chat can be configured to automatically submit when all tool results are available using sendAutomaticallyWhen. This triggers another iteration of this flow.\n\nThe tool calls and tool executions are integrated into the assistant message as typed tool parts. A tool part is at first a tool call, and then it becomes a tool result when the tool is executed. The tool result contains all information about the tool call as well as the result of the tool execution.\n\nTool result submission can be configured using the sendAutomaticallyWhen option. You can use the lastAssistantMessageIsCompleteWithToolCalls helper to automatically submit when all tool results are available. This simplifies the client-side code while still allowing full control when needed.\n\nExample\n\nIn this example, we'll use three tools:\n\ngetWeatherInformation: An automatically executed server-side tool that returns the weather in a given city.\naskForConfirmation: A user-interaction client-side tool that asks the user for confirmation.\ngetLocation: An automatically executed client-side tool that returns a random city.\nAPI route\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\nimport { z } from 'zod';\n\n\n// Allow streaming responses up to 30 seconds\nexport const maxDuration = 30;\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n    tools: {\n      // server-side tool with execute function:\n      getWeatherInformation: {\n        description: 'show the weather in a given city to the user',\n        inputSchema: z.object({ city: z.string() }),\n        execute: async ({}: { city: string }) => {\n          const weatherOptions = ['sunny', 'cloudy', 'rainy', 'snowy', 'windy'];\n          return weatherOptions[\n            Math.floor(Math.random() * weatherOptions.length)\n          ];\n        },\n      },\n      // client-side tool that starts user interaction:\n      askForConfirmation: {\n        description: 'Ask the user for confirmation.',\n        inputSchema: z.object({\n          message: z.string().describe('The message to ask for confirmation.'),\n        }),\n      },\n      // client-side tool that is automatically executed on the client:\n      getLocation: {\n        description:\n          'Get the user location. Always ask for confirmation before using this tool.',\n        inputSchema: z.object({}),\n      },\n    },\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\nClient-side page\n\nThe client-side page uses the useChat hook to create a chatbot application with real-time message streaming. Tool calls are displayed in the chat UI as typed tool parts. Please make sure to render the messages using the parts property of the message.\n\nThere are three things worth mentioning:\n\nThe onToolCall callback is used to handle client-side tools that should be automatically executed. In this example, the getLocation tool is a client-side tool that returns a random city. You call addToolResult to provide the result (without await to avoid potential deadlocks).\n\nAlways check if (toolCall.dynamic) first in your onToolCall handler. Without this check, TypeScript will throw an error like: Type 'string' is not assignable to type '\"toolName1\" | \"toolName2\"' when you try to use toolCall.toolName in addToolResult.\n\nThe sendAutomaticallyWhen option with lastAssistantMessageIsCompleteWithToolCalls helper automatically submits when all tool results are available.\n\nThe parts array of assistant messages contains tool parts with typed names like tool-askForConfirmation. The client-side tool askForConfirmation is displayed in the UI. It asks the user for confirmation and displays the result once the user confirms or denies the execution. The result is added to the chat using addToolResult with the tool parameter for type safety.\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport {\n  DefaultChatTransport,\n  lastAssistantMessageIsCompleteWithToolCalls,\n} from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const { messages, sendMessage, addToolResult } = useChat({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n\n\n    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls,\n\n\n    // run client-side tools that are automatically executed:\n    async onToolCall({ toolCall }) {\n      // Check if it's a dynamic tool first for proper type narrowing\n      if (toolCall.dynamic) {\n        return;\n      }\n\n\n      if (toolCall.toolName === 'getLocation') {\n        const cities = ['New York', 'Los Angeles', 'Chicago', 'San Francisco'];\n\n\n        // No await - avoids potential deadlocks\n        addToolResult({\n          tool: 'getLocation',\n          toolCallId: toolCall.toolCallId,\n          output: cities[Math.floor(Math.random() * cities.length)],\n        });\n      }\n    },\n  });\n  const [input, setInput] = useState('');\n\n\n  return (\n    <>\n      {messages?.map(message => (\n        <div key={message.id}>\n          <strong>{`${message.role}: `}</strong>\n          {message.parts.map(part => {\n            switch (part.type) {\n              // render text parts as simple text:\n              case 'text':\n                return part.text;\n\n\n              // for tool parts, use the typed tool part names:\n              case 'tool-askForConfirmation': {\n                const callId = part.toolCallId;\n\n\n                switch (part.state) {\n                  case 'input-streaming':\n                    return (\n                      <div key={callId}>Loading confirmation request...</div>\n                    );\n                  case 'input-available':\n                    return (\n                      <div key={callId}>\n                        {part.input.message}\n                        <div>\n                          <button\n                            onClick={() =>\n                              addToolResult({\n                                tool: 'askForConfirmation',\n                                toolCallId: callId,\n                                output: 'Yes, confirmed.',\n                              })\n                            }\n                          >\n                            Yes\n                          </button>\n                          <button\n                            onClick={() =>\n                              addToolResult({\n                                tool: 'askForConfirmation',\n                                toolCallId: callId,\n                                output: 'No, denied',\n                              })\n                            }\n                          >\n                            No\n                          </button>\n                        </div>\n                      </div>\n                    );\n                  case 'output-available':\n                    return (\n                      <div key={callId}>\n                        Location access allowed: {part.output}\n                      </div>\n                    );\n                  case 'output-error':\n                    return <div key={callId}>Error: {part.errorText}</div>;\n                }\n                break;\n              }\n\n\n              case 'tool-getLocation': {\n                const callId = part.toolCallId;\n\n\n                switch (part.state) {\n                  case 'input-streaming':\n                    return (\n                      <div key={callId}>Preparing location request...</div>\n                    );\n                  case 'input-available':\n                    return <div key={callId}>Getting location...</div>;\n                  case 'output-available':\n                    return <div key={callId}>Location: {part.output}</div>;\n                  case 'output-error':\n                    return (\n                      <div key={callId}>\n                        Error getting location: {part.errorText}\n                      </div>\n                    );\n                }\n                break;\n              }\n\n\n              case 'tool-getWeatherInformation': {\n                const callId = part.toolCallId;\n\n\n                switch (part.state) {\n                  // example of pre-rendering streaming tool inputs:\n                  case 'input-streaming':\n                    return (\n                      <pre key={callId}>{JSON.stringify(part, null, 2)}</pre>\n                    );\n                  case 'input-available':\n                    return (\n                      <div key={callId}>\n                        Getting weather information for {part.input.city}...\n                      </div>\n                    );\n                  case 'output-available':\n                    return (\n                      <div key={callId}>\n                        Weather in {part.input.city}: {part.output}\n                      </div>\n                    );\n                  case 'output-error':\n                    return (\n                      <div key={callId}>\n                        Error getting weather for {part.input.city}:{' '}\n                        {part.errorText}\n                      </div>\n                    );\n                }\n                break;\n              }\n            }\n          })}\n          <br />\n        </div>\n      ))}\n\n\n      <form\n        onSubmit={e => {\n          e.preventDefault();\n          if (input.trim()) {\n            sendMessage({ text: input });\n            setInput('');\n          }\n        }}\n      >\n        <input value={input} onChange={e => setInput(e.target.value)} />\n      </form>\n    </>\n  );\n}\nError handling\n\nSometimes an error may occur during client-side tool execution. Use the addToolResult method with a state of output-error and errorText value instead of output record the error.\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport {\n  DefaultChatTransport,\n  lastAssistantMessageIsCompleteWithToolCalls,\n} from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const { messages, sendMessage, addToolResult } = useChat({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n\n\n    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls,\n\n\n    // run client-side tools that are automatically executed:\n    async onToolCall({ toolCall }) {\n      // Check if it's a dynamic tool first for proper type narrowing\n      if (toolCall.dynamic) {\n        return;\n      }\n\n\n      if (toolCall.toolName === 'getWeatherInformation') {\n        try {\n          const weather = await getWeatherInformation(toolCall.input);\n\n\n          // No await - avoids potential deadlocks\n          addToolResult({\n            tool: 'getWeatherInformation',\n            toolCallId: toolCall.toolCallId,\n            output: weather,\n          });\n        } catch (err) {\n          addToolResult({\n            tool: 'getWeatherInformation',\n            toolCallId: toolCall.toolCallId,\n            state: 'output-error',\n            errorText: 'Unable to get the weather information',\n          });\n        }\n      }\n    },\n  });\n}\nDynamic Tools\n\nWhen using dynamic tools (tools with unknown types at compile time), the UI parts use a generic dynamic-tool type instead of specific tool types:\n\napp/page.tsx\n{\n  message.parts.map((part, index) => {\n    switch (part.type) {\n      // Static tools with specific (`tool-${toolName}`) types\n      case 'tool-getWeatherInformation':\n        return <WeatherDisplay part={part} />;\n\n\n      // Dynamic tools use generic `dynamic-tool` type\n      case 'dynamic-tool':\n        return (\n          <div key={index}>\n            <h4>Tool: {part.toolName}</h4>\n            {part.state === 'input-streaming' && (\n              <pre>{JSON.stringify(part.input, null, 2)}</pre>\n            )}\n            {part.state === 'output-available' && (\n              <pre>{JSON.stringify(part.output, null, 2)}</pre>\n            )}\n            {part.state === 'output-error' && (\n              <div>Error: {part.errorText}</div>\n            )}\n          </div>\n        );\n    }\n  });\n}\n\nDynamic tools are useful when integrating with:\n\nMCP (Model Context Protocol) tools without schemas\nUser-defined functions loaded at runtime\nExternal tool providers\nTool call streaming\n\nTool call streaming is enabled by default in AI SDK 5.0, allowing you to stream tool calls while they are being generated. This provides a better user experience by showing tool inputs as they are generated in real-time.\n\napp/api/chat/route.ts\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n    // toolCallStreaming is enabled by default in v5\n    // ...\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\n\nWith tool call streaming enabled, partial tool calls are streamed as part of the data stream. They are available through the useChat hook. The typed tool parts of assistant messages will also contain partial tool calls. You can use the state property of the tool part to render the correct UI.\n\napp/page.tsx\nexport default function Chat() {\n  // ...\n  return (\n    <>\n      {messages?.map(message => (\n        <div key={message.id}>\n          {message.parts.map(part => {\n            switch (part.type) {\n              case 'tool-askForConfirmation':\n              case 'tool-getLocation':\n              case 'tool-getWeatherInformation':\n                switch (part.state) {\n                  case 'input-streaming':\n                    return <pre>{JSON.stringify(part.input, null, 2)}</pre>;\n                  case 'input-available':\n                    return <pre>{JSON.stringify(part.input, null, 2)}</pre>;\n                  case 'output-available':\n                    return <pre>{JSON.stringify(part.output, null, 2)}</pre>;\n                  case 'output-error':\n                    return <div>Error: {part.errorText}</div>;\n                }\n            }\n          })}\n        </div>\n      ))}\n    </>\n  );\n}\nStep start parts\n\nWhen you are using multi-step tool calls, the AI SDK will add step start parts to the assistant messages. If you want to display boundaries between tool calls, you can use the step-start parts as follows:\n\napp/page.tsx\n// ...\n// where you render the message parts:\nmessage.parts.map((part, index) => {\n  switch (part.type) {\n    case 'step-start':\n      // show step boundaries as horizontal lines:\n      return index > 0 ? (\n        <div key={index} className=\"text-gray-500\">\n          <hr className=\"my-2 border-gray-300\" />\n        </div>\n      ) : null;\n    case 'text':\n    // ...\n    case 'tool-askForConfirmation':\n    case 'tool-getLocation':\n    case 'tool-getWeatherInformation':\n    // ...\n  }\n});\n// ...\nServer-side Multi-Step Calls\n\nYou can also use multi-step calls on the server-side with streamText. This works when all invoked tools have an execute function on the server side.\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { convertToModelMessages, streamText, UIMessage, stepCountIs } from 'ai';\nimport { z } from 'zod';\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n    tools: {\n      getWeatherInformation: {\n        description: 'show the weather in a given city to the user',\n        inputSchema: z.object({ city: z.string() }),\n        // tool has execute function:\n        execute: async ({}: { city: string }) => {\n          const weatherOptions = ['sunny', 'cloudy', 'rainy', 'snowy', 'windy'];\n          return weatherOptions[\n            Math.floor(Math.random() * weatherOptions.length)\n          ];\n        },\n      },\n    },\n    stopWhen: stepCountIs(5),\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\nErrors\n\nLanguage models can make errors when calling tools. By default, these errors are masked for security reasons, and show up as \"An error occurred\" in the UI.\n\nTo surface the errors, you can use the onError function when calling toUIMessageResponse.\n\nexport function errorHandler(error: unknown) {\n  if (error == null) {\n    return 'unknown error';\n  }\n\n\n  if (typeof error === 'string') {\n    return error;\n  }\n\n\n  if (error instanceof Error) {\n    return error.message;\n  }\n\n\n  return JSON.stringify(error);\n}\nconst result = streamText({\n  // ...\n});\n\n\nreturn result.toUIMessageStreamResponse({\n  onError: errorHandler,\n});\n\nIn case you are using createUIMessageResponse, you can use the onError function when calling toUIMessageResponse:\n\nconst response = createUIMessageResponse({\n  // ...\n  async execute(dataStream) {\n    // ...\n  },\n  onError: error => `Custom error: ${error.message}`,\n});\nPrevious\nChatbot Resume Streams\nNext\nGenerative User Interfaces"
  },
  {
    "title": "AI SDK UI: Generative User Interfaces",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/generative-user-interfaces",
    "html": "AI SDK UI\nGenerative User Interfaces\nCopy markdown\nGenerative User Interfaces\n\nGenerative user interfaces (generative UI) is the process of allowing a large language model (LLM) to go beyond text and \"generate UI\". This creates a more engaging and AI-native experience for users.\n\nWhat is the weather in SF?\ngetWeather(\"San Francisco\")\nThursday, March 7\n47°\nSunny\n7am\n48°\n8am\n50°\n9am\n52°\n10am\n54°\n11am\n56°\n12pm\n58°\n1pm\n60°\nThanks!\n\nAt the core of generative UI are tools , which are functions you provide to the model to perform specialized tasks like getting the weather in a location. The model can decide when and how to use these tools based on the context of the conversation.\n\nGenerative UI is the process of connecting the results of a tool call to a React component. Here's how it works:\n\nYou provide the model with a prompt or conversation history, along with a set of tools.\nBased on the context, the model may decide to call a tool.\nIf a tool is called, it will execute and return data.\nThis data can then be passed to a React component for rendering.\n\nBy passing the tool results to React components, you can create a generative UI experience that's more engaging and adaptive to your needs.\n\nBuild a Generative UI Chat Interface\n\nLet's create a chat interface that handles text-based conversations and incorporates dynamic UI elements based on model responses.\n\nBasic Chat Implementation\n\nStart with a basic chat implementation using the useChat hook:\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\n\n\nexport default function Page() {\n  const [input, setInput] = useState('');\n  const { messages, sendMessage } = useChat();\n\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    sendMessage({ text: input });\n    setInput('');\n  };\n\n\n  return (\n    <div>\n      {messages.map(message => (\n        <div key={message.id}>\n          <div>{message.role === 'user' ? 'User: ' : 'AI: '}</div>\n          <div>\n            {message.parts.map((part, index) => {\n              if (part.type === 'text') {\n                return <span key={index}>{part.text}</span>;\n              }\n              return null;\n            })}\n          </div>\n        </div>\n      ))}\n\n\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          placeholder=\"Type a message...\"\n        />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n\nTo handle the chat requests and model responses, set up an API route:\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { streamText, convertToModelMessages, UIMessage, stepCountIs } from 'ai';\n\n\nexport async function POST(request: Request) {\n  const { messages }: { messages: UIMessage[] } = await request.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    system: 'You are a friendly assistant!',\n    messages: convertToModelMessages(messages),\n    stopWhen: stepCountIs(5),\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\n\nThis API route uses the streamText function to process chat messages and stream the model's responses back to the client.\n\nCreate a Tool\n\nBefore enhancing your chat interface with dynamic UI elements, you need to create a tool and corresponding React component. A tool will allow the model to perform a specific action, such as fetching weather information.\n\nCreate a new file called ai/tools.ts with the following content:\n\nai/tools.ts\nimport { tool as createTool } from 'ai';\nimport { z } from 'zod';\n\n\nexport const weatherTool = createTool({\n  description: 'Display the weather for a location',\n  inputSchema: z.object({\n    location: z.string().describe('The location to get the weather for'),\n  }),\n  execute: async function ({ location }) {\n    await new Promise(resolve => setTimeout(resolve, 2000));\n    return { weather: 'Sunny', temperature: 75, location };\n  },\n});\n\n\nexport const tools = {\n  displayWeather: weatherTool,\n};\n\nIn this file, you've created a tool called weatherTool. This tool simulates fetching weather information for a given location. This tool will return simulated data after a 2-second delay. In a real-world application, you would replace this simulation with an actual API call to a weather service.\n\nUpdate the API Route\n\nUpdate the API route to include the tool you've defined:\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { streamText, convertToModelMessages, UIMessage, stepCountIs } from 'ai';\nimport { tools } from '@/ai/tools';\n\n\nexport async function POST(request: Request) {\n  const { messages }: { messages: UIMessage[] } = await request.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    system: 'You are a friendly assistant!',\n    messages: convertToModelMessages(messages),\n    stopWhen: stepCountIs(5),\n    tools,\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\n\nNow that you've defined the tool and added it to your streamText call, let's build a React component to display the weather information it returns.\n\nCreate UI Components\n\nCreate a new file called components/weather.tsx:\n\ncomponents/weather.tsx\ntype WeatherProps = {\n  temperature: number;\n  weather: string;\n  location: string;\n};\n\n\nexport const Weather = ({ temperature, weather, location }: WeatherProps) => {\n  return (\n    <div>\n      <h2>Current Weather for {location}</h2>\n      <p>Condition: {weather}</p>\n      <p>Temperature: {temperature}°C</p>\n    </div>\n  );\n};\n\nThis component will display the weather information for a given location. It takes three props: temperature, weather, and location (exactly what the weatherTool returns).\n\nRender the Weather Component\n\nNow that you have your tool and corresponding React component, let's integrate them into your chat interface. You'll render the Weather component when the model calls the weather tool.\n\nTo check if the model has called a tool, you can check the parts array of the UIMessage object for tool-specific parts. In AI SDK 5.0, tool parts use typed naming: tool-${toolName} instead of generic types.\n\nUpdate your page.tsx file:\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\nimport { Weather } from '@/components/weather';\n\n\nexport default function Page() {\n  const [input, setInput] = useState('');\n  const { messages, sendMessage } = useChat();\n\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    sendMessage({ text: input });\n    setInput('');\n  };\n\n\n  return (\n    <div>\n      {messages.map(message => (\n        <div key={message.id}>\n          <div>{message.role === 'user' ? 'User: ' : 'AI: '}</div>\n          <div>\n            {message.parts.map((part, index) => {\n              if (part.type === 'text') {\n                return <span key={index}>{part.text}</span>;\n              }\n\n\n              if (part.type === 'tool-displayWeather') {\n                switch (part.state) {\n                  case 'input-available':\n                    return <div key={index}>Loading weather...</div>;\n                  case 'output-available':\n                    return (\n                      <div key={index}>\n                        <Weather {...part.output} />\n                      </div>\n                    );\n                  case 'output-error':\n                    return <div key={index}>Error: {part.errorText}</div>;\n                  default:\n                    return null;\n                }\n              }\n\n\n              return null;\n            })}\n          </div>\n        </div>\n      ))}\n\n\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          placeholder=\"Type a message...\"\n        />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n\nIn this updated code snippet, you:\n\nUse manual input state management with useState instead of the built-in input and handleInputChange.\nUse sendMessage instead of handleSubmit to send messages.\nCheck the parts array of each message for different content types.\nHandle tool parts with type tool-displayWeather and their different states (input-available, output-available, output-error).\n\nThis approach allows you to dynamically render UI components based on the model's responses, creating a more interactive and context-aware chat experience.\n\nExpanding Your Generative UI Application\n\nYou can enhance your chat application by adding more tools and components, creating a richer and more versatile user experience. Here's how you can expand your application:\n\nAdding More Tools\n\nTo add more tools, simply define them in your ai/tools.ts file:\n\n// Add a new stock tool\nexport const stockTool = createTool({\n  description: 'Get price for a stock',\n  inputSchema: z.object({\n    symbol: z.string().describe('The stock symbol to get the price for'),\n  }),\n  execute: async function ({ symbol }) {\n    // Simulated API call\n    await new Promise(resolve => setTimeout(resolve, 2000));\n    return { symbol, price: 100 };\n  },\n});\n\n\n// Update the tools object\nexport const tools = {\n  displayWeather: weatherTool,\n  getStockPrice: stockTool,\n};\n\nNow, create a new file called components/stock.tsx:\n\ntype StockProps = {\n  price: number;\n  symbol: string;\n};\n\n\nexport const Stock = ({ price, symbol }: StockProps) => {\n  return (\n    <div>\n      <h2>Stock Information</h2>\n      <p>Symbol: {symbol}</p>\n      <p>Price: ${price}</p>\n    </div>\n  );\n};\n\nFinally, update your page.tsx file to include the new Stock component:\n\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\nimport { Weather } from '@/components/weather';\nimport { Stock } from '@/components/stock';\n\n\nexport default function Page() {\n  const [input, setInput] = useState('');\n  const { messages, sendMessage } = useChat();\n\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    sendMessage({ text: input });\n    setInput('');\n  };\n\n\n  return (\n    <div>\n      {messages.map(message => (\n        <div key={message.id}>\n          <div>{message.role}</div>\n          <div>\n            {message.parts.map((part, index) => {\n              if (part.type === 'text') {\n                return <span key={index}>{part.text}</span>;\n              }\n\n\n              if (part.type === 'tool-displayWeather') {\n                switch (part.state) {\n                  case 'input-available':\n                    return <div key={index}>Loading weather...</div>;\n                  case 'output-available':\n                    return (\n                      <div key={index}>\n                        <Weather {...part.output} />\n                      </div>\n                    );\n                  case 'output-error':\n                    return <div key={index}>Error: {part.errorText}</div>;\n                  default:\n                    return null;\n                }\n              }\n\n\n              if (part.type === 'tool-getStockPrice') {\n                switch (part.state) {\n                  case 'input-available':\n                    return <div key={index}>Loading stock price...</div>;\n                  case 'output-available':\n                    return (\n                      <div key={index}>\n                        <Stock {...part.output} />\n                      </div>\n                    );\n                  case 'output-error':\n                    return <div key={index}>Error: {part.errorText}</div>;\n                  default:\n                    return null;\n                }\n              }\n\n\n              return null;\n            })}\n          </div>\n        </div>\n      ))}\n\n\n      <form onSubmit={handleSubmit}>\n        <input\n          type=\"text\"\n          value={input}\n          onChange={e => setInput(e.target.value)}\n        />\n        <button type=\"submit\">Send</button>\n      </form>\n    </div>\n  );\n}\n\nBy following this pattern, you can continue to add more tools and components, expanding the capabilities of your Generative UI application.\n\nPrevious\nChatbot Tool Usage\nNext\nCompletion"
  },
  {
    "title": "AI SDK UI: Completion",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/completion",
    "html": "AI SDK UI\nCompletion\nCopy markdown\nCompletion\n\nThe useCompletion hook allows you to create a user interface to handle text completions in your application. It enables the streaming of text completions from your AI provider, manages the state for chat input, and updates the UI automatically as new messages are received.\n\nThe useCompletion hook is now part of the @ai-sdk/react package.\n\nIn this guide, you will learn how to use the useCompletion hook in your application to generate text completions and stream them in real-time to your users.\n\nExample\napp/page.tsx\n'use client';\n\n\nimport { useCompletion } from '@ai-sdk/react';\n\n\nexport default function Page() {\n  const { completion, input, handleInputChange, handleSubmit } = useCompletion({\n    api: '/api/completion',\n  });\n\n\n  return (\n    <form onSubmit={handleSubmit}>\n      <input\n        name=\"prompt\"\n        value={input}\n        onChange={handleInputChange}\n        id=\"input\"\n      />\n      <button type=\"submit\">Submit</button>\n      <div>{completion}</div>\n    </form>\n  );\n}\napp/api/completion/route.ts\nimport { streamText } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\n\n// Allow streaming responses up to 30 seconds\nexport const maxDuration = 30;\n\n\nexport async function POST(req: Request) {\n  const { prompt }: { prompt: string } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-3.5-turbo'),\n    prompt,\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\n\nIn the Page component, the useCompletion hook will request to your AI provider endpoint whenever the user submits a message. The completion is then streamed back in real-time and displayed in the UI.\n\nThis enables a seamless text completion experience where the user can see the AI response as soon as it is available, without having to wait for the entire response to be received.\n\nCustomized UI\n\nuseCompletion also provides ways to manage the prompt via code, show loading and error states, and update messages without being triggered by user interactions.\n\nLoading and error states\n\nTo show a loading spinner while the chatbot is processing the user's message, you can use the isLoading state returned by the useCompletion hook:\n\nconst { isLoading, ... } = useCompletion()\n\n\nreturn(\n  <>\n    {isLoading ? <Spinner /> : null}\n  </>\n)\n\nSimilarly, the error state reflects the error object thrown during the fetch request. It can be used to display an error message, or show a toast notification:\n\nconst { error, ... } = useCompletion()\n\n\nuseEffect(() => {\n  if (error) {\n    toast.error(error.message)\n  }\n}, [error])\n\n\n// Or display the error message in the UI:\nreturn (\n  <>\n    {error ? <div>{error.message}</div> : null}\n  </>\n)\nControlled input\n\nIn the initial example, we have handleSubmit and handleInputChange callbacks that manage the input changes and form submissions. These are handy for common use cases, but you can also use uncontrolled APIs for more advanced scenarios such as form validation or customized components.\n\nThe following example demonstrates how to use more granular APIs like setInput with your custom input and submit button components:\n\nconst { input, setInput } = useCompletion();\n\n\nreturn (\n  <>\n    <MyCustomInput value={input} onChange={value => setInput(value)} />\n  </>\n);\nCancelation\n\nIt's also a common use case to abort the response message while it's still streaming back from the AI provider. You can do this by calling the stop function returned by the useCompletion hook.\n\nconst { stop, isLoading, ... } = useCompletion()\n\n\nreturn (\n  <>\n    <button onClick={stop} disabled={!isLoading}>Stop</button>\n  </>\n)\n\nWhen the user clicks the \"Stop\" button, the fetch request will be aborted. This avoids consuming unnecessary resources and improves the UX of your application.\n\nThrottling UI Updates\nThis feature is currently only available for React.\n\nBy default, the useCompletion hook will trigger a render every time a new chunk is received. You can throttle the UI updates with the experimental_throttle option.\n\npage.tsx\nconst { completion, ... } = useCompletion({\n  // Throttle the completion and data updates to 50ms:\n  experimental_throttle: 50\n})\nEvent Callbacks\n\nuseCompletion also provides optional event callbacks that you can use to handle different stages of the chatbot lifecycle. These callbacks can be used to trigger additional actions, such as logging, analytics, or custom UI updates.\n\nconst { ... } = useCompletion({\n  onResponse: (response: Response) => {\n    console.log('Received response from server:', response)\n  },\n  onFinish: (prompt: string, completion: string) => {\n    console.log('Finished streaming completion:', completion)\n  },\n  onError: (error: Error) => {\n    console.error('An error occurred:', error)\n  },\n})\n\nIt's worth noting that you can abort the processing by throwing an error in the onResponse callback. This will trigger the onError callback and stop the message from being appended to the chat UI. This can be useful for handling unexpected responses from the AI provider.\n\nConfigure Request Options\n\nBy default, the useCompletion hook sends a HTTP POST request to the /api/completion endpoint with the prompt as part of the request body. You can customize the request by passing additional options to the useCompletion hook:\n\nconst { messages, input, handleInputChange, handleSubmit } = useCompletion({\n  api: '/api/custom-completion',\n  headers: {\n    Authorization: 'your_token',\n  },\n  body: {\n    user_id: '123',\n  },\n  credentials: 'same-origin',\n});\n\nIn this example, the useCompletion hook sends a POST request to the /api/completion endpoint with the specified headers, additional body fields, and credentials for that fetch request. On your server side, you can handle the request with these additional information.\n\nPrevious\nGenerative User Interfaces\nNext\nObject Generation"
  },
  {
    "title": "AI SDK UI: Object Generation",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/object-generation",
    "html": "AI SDK UI\nObject Generation\nCopy markdown\nObject Generation\n\nuseObject is an experimental feature and only available in React, Svelte, and Vue.\n\nThe useObject hook allows you to create interfaces that represent a structured JSON object that is being streamed.\n\nIn this guide, you will learn how to use the useObject hook in your application to generate UIs for structured data on the fly.\n\nExample\n\nThe example shows a small notifications demo app that generates fake notifications in real-time.\n\nSchema\n\nIt is helpful to set up the schema in a separate file that is imported on both the client and server.\n\napp/api/notifications/schema.ts\nimport { z } from 'zod';\n\n\n// define a schema for the notifications\nexport const notificationSchema = z.object({\n  notifications: z.array(\n    z.object({\n      name: z.string().describe('Name of a fictional person.'),\n      message: z.string().describe('Message. Do not use emojis or links.'),\n    }),\n  ),\n});\nClient\n\nThe client uses useObject to stream the object generation process.\n\nThe results are partial and are displayed as they are received. Please note the code for handling undefined values in the JSX.\n\napp/page.tsx\n'use client';\n\n\nimport { experimental_useObject as useObject } from '@ai-sdk/react';\nimport { notificationSchema } from './api/notifications/schema';\n\n\nexport default function Page() {\n  const { object, submit } = useObject({\n    api: '/api/notifications',\n    schema: notificationSchema,\n  });\n\n\n  return (\n    <>\n      <button onClick={() => submit('Messages during finals week.')}>\n        Generate notifications\n      </button>\n\n\n      {object?.notifications?.map((notification, index) => (\n        <div key={index}>\n          <p>{notification?.name}</p>\n          <p>{notification?.message}</p>\n        </div>\n      ))}\n    </>\n  );\n}\nServer\n\nOn the server, we use streamObject to stream the object generation process.\n\napp/api/notifications/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { streamObject } from 'ai';\nimport { notificationSchema } from './schema';\n\n\n// Allow streaming responses up to 30 seconds\nexport const maxDuration = 30;\n\n\nexport async function POST(req: Request) {\n  const context = await req.json();\n\n\n  const result = streamObject({\n    model: openai('gpt-4.1'),\n    schema: notificationSchema,\n    prompt:\n      `Generate 3 notifications for a messages app in this context:` + context,\n  });\n\n\n  return result.toTextStreamResponse();\n}\nEnum Output Mode\n\nWhen you need to classify or categorize input into predefined options, you can use the enum output mode with useObject. This requires a specific schema structure where the object has enum as a key with z.enum containing your possible values.\n\nExample: Text Classification\n\nThis example shows how to build a simple text classifier that categorizes statements as true or false.\n\nClient\n\nWhen using useObject with enum output mode, your schema must be an object with enum as the key:\n\napp/classify/page.tsx\n'use client';\n\n\nimport { experimental_useObject as useObject } from '@ai-sdk/react';\nimport { z } from 'zod';\n\n\nexport default function ClassifyPage() {\n  const { object, submit, isLoading } = useObject({\n    api: '/api/classify',\n    schema: z.object({ enum: z.enum(['true', 'false']) }),\n  });\n\n\n  return (\n    <>\n      <button onClick={() => submit('The earth is flat')} disabled={isLoading}>\n        Classify statement\n      </button>\n\n\n      {object && <div>Classification: {object.enum}</div>}\n    </>\n  );\n}\nServer\n\nOn the server, use streamObject with output: 'enum' to stream the classification result:\n\napp/api/classify/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { streamObject } from 'ai';\n\n\nexport async function POST(req: Request) {\n  const context = await req.json();\n\n\n  const result = streamObject({\n    model: openai('gpt-4.1'),\n    output: 'enum',\n    enum: ['true', 'false'],\n    prompt: `Classify this statement as true or false: ${context}`,\n  });\n\n\n  return result.toTextStreamResponse();\n}\nCustomized UI\n\nuseObject also provides ways to show loading and error states:\n\nLoading State\n\nThe isLoading state returned by the useObject hook can be used for several purposes:\n\nTo show a loading spinner while the object is generated.\nTo disable the submit button.\napp/page.tsx\n'use client';\n\n\nimport { useObject } from '@ai-sdk/react';\n\n\nexport default function Page() {\n  const { isLoading, object, submit } = useObject({\n    api: '/api/notifications',\n    schema: notificationSchema,\n  });\n\n\n  return (\n    <>\n      {isLoading && <Spinner />}\n\n\n      <button\n        onClick={() => submit('Messages during finals week.')}\n        disabled={isLoading}\n      >\n        Generate notifications\n      </button>\n\n\n      {object?.notifications?.map((notification, index) => (\n        <div key={index}>\n          <p>{notification?.name}</p>\n          <p>{notification?.message}</p>\n        </div>\n      ))}\n    </>\n  );\n}\nStop Handler\n\nThe stop function can be used to stop the object generation process. This can be useful if the user wants to cancel the request or if the server is taking too long to respond.\n\napp/page.tsx\n'use client';\n\n\nimport { useObject } from '@ai-sdk/react';\n\n\nexport default function Page() {\n  const { isLoading, stop, object, submit } = useObject({\n    api: '/api/notifications',\n    schema: notificationSchema,\n  });\n\n\n  return (\n    <>\n      {isLoading && (\n        <button type=\"button\" onClick={() => stop()}>\n          Stop\n        </button>\n      )}\n\n\n      <button onClick={() => submit('Messages during finals week.')}>\n        Generate notifications\n      </button>\n\n\n      {object?.notifications?.map((notification, index) => (\n        <div key={index}>\n          <p>{notification?.name}</p>\n          <p>{notification?.message}</p>\n        </div>\n      ))}\n    </>\n  );\n}\nError State\n\nSimilarly, the error state reflects the error object thrown during the fetch request. It can be used to display an error message, or to disable the submit button:\n\nWe recommend showing a generic error message to the user, such as \"Something went wrong.\" This is a good practice to avoid leaking information from the server.\n\n'use client';\n\n\nimport { useObject } from '@ai-sdk/react';\n\n\nexport default function Page() {\n  const { error, object, submit } = useObject({\n    api: '/api/notifications',\n    schema: notificationSchema,\n  });\n\n\n  return (\n    <>\n      {error && <div>An error occurred.</div>}\n\n\n      <button onClick={() => submit('Messages during finals week.')}>\n        Generate notifications\n      </button>\n\n\n      {object?.notifications?.map((notification, index) => (\n        <div key={index}>\n          <p>{notification?.name}</p>\n          <p>{notification?.message}</p>\n        </div>\n      ))}\n    </>\n  );\n}\nEvent Callbacks\n\nuseObject provides optional event callbacks that you can use to handle life-cycle events.\n\nonFinish: Called when the object generation is completed.\nonError: Called when an error occurs during the fetch request.\n\nThese callbacks can be used to trigger additional actions, such as logging, analytics, or custom UI updates.\n\napp/page.tsx\n'use client';\n\n\nimport { experimental_useObject as useObject } from '@ai-sdk/react';\nimport { notificationSchema } from './api/notifications/schema';\n\n\nexport default function Page() {\n  const { object, submit } = useObject({\n    api: '/api/notifications',\n    schema: notificationSchema,\n    onFinish({ object, error }) {\n      // typed object, undefined if schema validation fails:\n      console.log('Object generation completed:', object);\n\n\n      // error, undefined if schema validation succeeds:\n      console.log('Schema validation error:', error);\n    },\n    onError(error) {\n      // error during fetch request:\n      console.error('An error occurred:', error);\n    },\n  });\n\n\n  return (\n    <div>\n      <button onClick={() => submit('Messages during finals week.')}>\n        Generate notifications\n      </button>\n\n\n      {object?.notifications?.map((notification, index) => (\n        <div key={index}>\n          <p>{notification?.name}</p>\n          <p>{notification?.message}</p>\n        </div>\n      ))}\n    </div>\n  );\n}\nConfigure Request Options\n\nYou can configure the API endpoint, optional headers and credentials using the api, headers and credentials settings.\n\nconst { submit, object } = useObject({\n  api: '/api/use-object',\n  headers: {\n    'X-Custom-Header': 'CustomValue',\n  },\n  credentials: 'include',\n  schema: yourSchema,\n});\nPrevious\nCompletion\nNext\nStreaming Custom Data"
  },
  {
    "title": "AI SDK UI: Streaming Custom Data",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data",
    "html": "AI SDK UI\nStreaming Custom Data\nCopy markdown\nStreaming Custom Data\n\nIt is often useful to send additional data alongside the model's response. For example, you may want to send status information, the message ids after storing them, or references to content that the language model is referring to.\n\nThe AI SDK provides several helpers that allows you to stream additional data to the client and attach it to the UIMessage parts array:\n\ncreateUIMessageStream: creates a data stream\ncreateUIMessageStreamResponse: creates a response object that streams data\npipeUIMessageStreamToResponse: pipes a data stream to a server response object\n\nThe data is streamed as part of the response stream using Server-Sent Events.\n\nSetting Up Type-Safe Data Streaming\n\nFirst, define your custom message type with data part schemas for type safety:\n\nai/types.ts\nimport { UIMessage } from 'ai';\n\n\n// Define your custom message type with data part schemas\nexport type MyUIMessage = UIMessage<\n  never, // metadata type\n  {\n    weather: {\n      city: string;\n      weather?: string;\n      status: 'loading' | 'success';\n    };\n    notification: {\n      message: string;\n      level: 'info' | 'warning' | 'error';\n    };\n  } // data parts type\n>;\nStreaming Data from the Server\n\nIn your server-side route handler, you can create a UIMessageStream and then pass it to createUIMessageStreamResponse:\n\nroute.ts\nimport { openai } from '@ai-sdk/openai';\nimport {\n  createUIMessageStream,\n  createUIMessageStreamResponse,\n  streamText,\n  convertToModelMessages,\n} from 'ai';\nimport type { MyUIMessage } from '@/ai/types';\n\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n\n\n  const stream = createUIMessageStream<MyUIMessage>({\n    execute: ({ writer }) => {\n      // 1. Send initial status (transient - won't be added to message history)\n      writer.write({\n        type: 'data-notification',\n        data: { message: 'Processing your request...', level: 'info' },\n        transient: true, // This part won't be added to message history\n      });\n\n\n      // 2. Send sources (useful for RAG use cases)\n      writer.write({\n        type: 'source',\n        value: {\n          type: 'source',\n          sourceType: 'url',\n          id: 'source-1',\n          url: 'https://weather.com',\n          title: 'Weather Data Source',\n        },\n      });\n\n\n      // 3. Send data parts with loading state\n      writer.write({\n        type: 'data-weather',\n        id: 'weather-1',\n        data: { city: 'San Francisco', status: 'loading' },\n      });\n\n\n      const result = streamText({\n        model: openai('gpt-4.1'),\n        messages: convertToModelMessages(messages),\n        onFinish() {\n          // 4. Update the same data part (reconciliation)\n          writer.write({\n            type: 'data-weather',\n            id: 'weather-1', // Same ID = update existing part\n            data: {\n              city: 'San Francisco',\n              weather: 'sunny',\n              status: 'success',\n            },\n          });\n\n\n          // 5. Send completion notification (transient)\n          writer.write({\n            type: 'data-notification',\n            data: { message: 'Request completed', level: 'info' },\n            transient: true, // Won't be added to message history\n          });\n        },\n      });\n\n\n      writer.merge(result.toUIMessageStream());\n    },\n  });\n\n\n  return createUIMessageStreamResponse({ stream });\n}\n\nYou can also send stream data from custom backends, e.g. Python / FastAPI, using the UI Message Stream Protocol.\n\nTypes of Streamable Data\nData Parts (Persistent)\n\nRegular data parts are added to the message history and appear in message.parts:\n\nwriter.write({\n  type: 'data-weather',\n  id: 'weather-1', // Optional: enables reconciliation\n  data: { city: 'San Francisco', status: 'loading' },\n});\nSources\n\nSources are useful for RAG implementations where you want to show which documents or URLs were referenced:\n\nwriter.write({\n  type: 'source',\n  value: {\n    type: 'source',\n    sourceType: 'url',\n    id: 'source-1',\n    url: 'https://example.com',\n    title: 'Example Source',\n  },\n});\nTransient Data Parts (Ephemeral)\n\nTransient parts are sent to the client but not added to the message history. They are only accessible via the onData useChat handler:\n\n// server\nwriter.write({\n  type: 'data-notification',\n  data: { message: 'Processing...', level: 'info' },\n  transient: true, // Won't be added to message history\n});\n\n\n// client\nconst [notification, setNotification] = useState();\n\n\nconst { messages } = useChat({\n  onData: ({ data, type }) => {\n    if (type === 'data-notification') {\n      setNotification({ message: data.message, level: data.level });\n    }\n  },\n});\nData Part Reconciliation\n\nWhen you write to a data part with the same ID, the client automatically reconciles and updates that part. This enables powerful dynamic experiences like:\n\nCollaborative artifacts - Update code, documents, or designs in real-time\nProgressive data loading - Show loading states that transform into final results\nLive status updates - Update progress bars, counters, or status indicators\nInteractive components - Build UI elements that evolve based on user interaction\n\nThe reconciliation happens automatically - simply use the same id when writing to the stream.\n\nProcessing Data on the Client\nUsing the onData Callback\n\nThe onData callback is essential for handling streaming data, especially transient parts:\n\npage.tsx\nimport { useChat } from '@ai-sdk/react';\nimport type { MyUIMessage } from '@/ai/types';\n\n\nconst { messages } = useChat<MyUIMessage>({\n  api: '/api/chat',\n  onData: dataPart => {\n    // Handle all data parts as they arrive (including transient parts)\n    console.log('Received data part:', dataPart);\n\n\n    // Handle different data part types\n    if (dataPart.type === 'data-weather') {\n      console.log('Weather update:', dataPart.data);\n    }\n\n\n    // Handle transient notifications (ONLY available here, not in message.parts)\n    if (dataPart.type === 'data-notification') {\n      showToast(dataPart.data.message, dataPart.data.level);\n    }\n  },\n});\n\nImportant: Transient data parts are only available through the onData callback. They will not appear in the message.parts array since they're not added to message history.\n\nRendering Persistent Data Parts\n\nYou can filter and render data parts from the message parts array:\n\npage.tsx\nconst result = (\n  <>\n    {messages?.map(message => (\n      <div key={message.id}>\n        {/* Render weather data parts */}\n        {message.parts\n          .filter(part => part.type === 'data-weather')\n          .map((part, index) => (\n            <div key={index} className=\"weather-widget\">\n              {part.data.status === 'loading' ? (\n                <>Getting weather for {part.data.city}...</>\n              ) : (\n                <>\n                  Weather in {part.data.city}: {part.data.weather}\n                </>\n              )}\n            </div>\n          ))}\n\n\n        {/* Render text content */}\n        {message.parts\n          .filter(part => part.type === 'text')\n          .map((part, index) => (\n            <div key={index}>{part.text}</div>\n          ))}\n\n\n        {/* Render sources */}\n        {message.parts\n          .filter(part => part.type === 'source')\n          .map((part, index) => (\n            <div key={index} className=\"source\">\n              Source: <a href={part.url}>{part.title}</a>\n            </div>\n          ))}\n      </div>\n    ))}\n  </>\n);\nComplete Example\npage.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\nimport type { MyUIMessage } from '@/ai/types';\n\n\nexport default function Chat() {\n  const [input, setInput] = useState('');\n\n\n  const { messages, sendMessage } = useChat<MyUIMessage>({\n    api: '/api/chat',\n    onData: dataPart => {\n      // Handle transient notifications\n      if (dataPart.type === 'data-notification') {\n        console.log('Notification:', dataPart.data.message);\n      }\n    },\n  });\n\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    sendMessage({ text: input });\n    setInput('');\n  };\n\n\n  return (\n    <>\n      {messages?.map(message => (\n        <div key={message.id}>\n          {message.role === 'user' ? 'User: ' : 'AI: '}\n\n\n          {/* Render weather data */}\n          {message.parts\n            .filter(part => part.type === 'data-weather')\n            .map((part, index) => (\n              <span key={index} className=\"weather-update\">\n                {part.data.status === 'loading' ? (\n                  <>Getting weather for {part.data.city}...</>\n                ) : (\n                  <>\n                    Weather in {part.data.city}: {part.data.weather}\n                  </>\n                )}\n              </span>\n            ))}\n\n\n          {/* Render text content */}\n          {message.parts\n            .filter(part => part.type === 'text')\n            .map((part, index) => (\n              <div key={index}>{part.text}</div>\n            ))}\n        </div>\n      ))}\n\n\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          placeholder=\"Ask about the weather...\"\n        />\n        <button type=\"submit\">Send</button>\n      </form>\n    </>\n  );\n}\nUse Cases\nRAG Applications - Stream sources and retrieved documents\nReal-time Status - Show loading states and progress updates\nCollaborative Tools - Stream live updates to shared artifacts\nAnalytics - Send usage data without cluttering message history\nNotifications - Display temporary alerts and status messages\nMessage Metadata vs Data Parts\n\nBoth message metadata and data parts allow you to send additional information alongside messages, but they serve different purposes:\n\nMessage Metadata\n\nMessage metadata is best for message-level information that describes the message as a whole:\n\nAttached at the message level via message.metadata\nSent using the messageMetadata callback in toUIMessageStreamResponse\nIdeal for: timestamps, model info, token usage, user context\nType-safe with custom metadata types\n// Server: Send metadata about the message\nreturn result.toUIMessageStreamResponse({\n  messageMetadata: ({ part }) => {\n    if (part.type === 'finish') {\n      return {\n        model: part.response.modelId,\n        totalTokens: part.totalUsage.totalTokens,\n        createdAt: Date.now(),\n      };\n    }\n  },\n});\nData Parts\n\nData parts are best for streaming dynamic arbitrary data:\n\nAdded to the message parts array via message.parts\nStreamed using createUIMessageStream and writer.write()\nCan be reconciled/updated using the same ID\nSupport transient parts that don't persist\nIdeal for: dynamic content, loading states, interactive components\n// Server: Stream data as part of message content\nwriter.write({\n  type: 'data-weather',\n  id: 'weather-1',\n  data: { city: 'San Francisco', status: 'loading' },\n});\n\nFor more details on message metadata, see the Message Metadata documentation.\n\nPrevious\nObject Generation\nNext\nError Handling"
  },
  {
    "title": "AI SDK UI: Error Handling",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/error-handling",
    "html": "AI SDK UI\nError Handling\nCopy markdown\nError Handling and warnings\nWarnings\n\nThe AI SDK shows warnings when something might not work as expected. These warnings help you fix problems before they cause errors.\n\nWhen Warnings Appear\n\nWarnings are shown in the browser console when:\n\nUnsupported settings: You use a setting that the AI model doesn't support\nUnsupported tools: You use a tool that the AI model can't use\nOther issues: The AI model reports other problems\nWarning Messages\n\nAll warnings start with \"AI SDK Warning:\" so you can easily find them. For example:\n\nAI SDK Warning: The \"temperature\" setting is not supported by this model\nAI SDK Warning: The tool \"calculator\" is not supported by this model\nTurning Off Warnings\n\nBy default, warnings are shown in the console. You can control this behavior:\n\nTurn Off All Warnings\n\nSet a global variable to turn off warnings completely:\n\nglobalThis.AI_SDK_LOG_WARNINGS = false;\nCustom Warning Handler\n\nYou can also provide your own function to handle warnings:\n\nglobalThis.AI_SDK_LOG_WARNINGS = warnings => {\n  // Handle warnings your own way\n  warnings.forEach(warning => {\n    // Your custom logic here\n    console.log('Custom warning:', warning);\n  });\n};\n\nCustom warning functions are experimental and can change in patch releases without notice.\n\nError Handling\nError Helper Object\n\nEach AI SDK UI hook also returns an error object that you can use to render the error in your UI. You can use the error object to show an error message, disable the submit button, or show a retry button.\n\nWe recommend showing a generic error message to the user, such as \"Something went wrong.\" This is a good practice to avoid leaking information from the server.\n\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const [input, setInput] = useState('');\n  const { messages, sendMessage, error, regenerate } = useChat();\n\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    sendMessage({ text: input });\n    setInput('');\n  };\n\n\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role}:{' '}\n          {m.parts\n            .filter(part => part.type === 'text')\n            .map(part => part.text)\n            .join('')}\n        </div>\n      ))}\n\n\n      {error && (\n        <>\n          <div>An error occurred.</div>\n          <button type=\"button\" onClick={() => regenerate()}>\n            Retry\n          </button>\n        </>\n      )}\n\n\n      <form onSubmit={handleSubmit}>\n        <input\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          disabled={error != null}\n        />\n      </form>\n    </div>\n  );\n}\nAlternative: replace last message\n\nAlternatively you can write a custom submit handler that replaces the last message when an error is present.\n\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const [input, setInput] = useState('');\n  const { sendMessage, error, messages, setMessages } = useChat();\n\n\n  function customSubmit(event: React.FormEvent<HTMLFormElement>) {\n    event.preventDefault();\n\n\n    if (error != null) {\n      setMessages(messages.slice(0, -1)); // remove last message\n    }\n\n\n    sendMessage({ text: input });\n    setInput('');\n  }\n\n\n  return (\n    <div>\n      {messages.map(m => (\n        <div key={m.id}>\n          {m.role}:{' '}\n          {m.parts\n            .filter(part => part.type === 'text')\n            .map(part => part.text)\n            .join('')}\n        </div>\n      ))}\n\n\n      {error && <div>An error occurred.</div>}\n\n\n      <form onSubmit={customSubmit}>\n        <input value={input} onChange={e => setInput(e.target.value)} />\n      </form>\n    </div>\n  );\n}\nError Handling Callback\n\nErrors can be processed by passing an onError callback function as an option to the useChat or useCompletion hooks. The callback function receives an error object as an argument.\n\nimport { useChat } from '@ai-sdk/react';\n\n\nexport default function Page() {\n  const {\n    /* ... */\n  } = useChat({\n    // handle error:\n    onError: error => {\n      console.error(error);\n    },\n  });\n}\nInjecting Errors for Testing\n\nYou might want to create errors for testing. You can easily do so by throwing an error in your route handler:\n\nexport async function POST(req: Request) {\n  throw new Error('This is a test error');\n}\nPrevious\nStreaming Custom Data\nNext\nTransport"
  },
  {
    "title": "AI SDK UI: Transport",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/transport",
    "html": "AI SDK UI\nTransport\nCopy markdown\nTransport\n\nThe useChat transport system provides fine-grained control over how messages are sent to your API endpoints and how responses are processed. This is particularly useful for alternative communication protocols like WebSockets, custom authentication patterns, or specialized backend integrations.\n\nDefault Transport\n\nBy default, useChat uses HTTP POST requests to send messages to /api/chat:\n\nimport { useChat } from '@ai-sdk/react';\n\n\n// Uses default HTTP transport\nconst { messages, sendMessage } = useChat();\n\nThis is equivalent to:\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nconst { messages, sendMessage } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/chat',\n  }),\n});\nCustom Transport Configuration\n\nConfigure the default transport with custom options:\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\n\n\nconst { messages, sendMessage } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/custom-chat',\n    headers: {\n      Authorization: 'Bearer your-token',\n      'X-API-Version': '2024-01',\n    },\n    credentials: 'include',\n  }),\n});\nDynamic Configuration\n\nYou can also provide functions that return configuration values. This is useful for authentication tokens that need to be refreshed, or for configuration that depends on runtime conditions:\n\nconst { messages, sendMessage } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/chat',\n    headers: () => ({\n      Authorization: `Bearer ${getAuthToken()}`,\n      'X-User-ID': getCurrentUserId(),\n    }),\n    body: () => ({\n      sessionId: getCurrentSessionId(),\n      preferences: getUserPreferences(),\n    }),\n    credentials: () => 'include',\n  }),\n});\nRequest Transformation\n\nTransform requests before sending to your API:\n\nconst { messages, sendMessage } = useChat({\n  transport: new DefaultChatTransport({\n    api: '/api/chat',\n    prepareSendMessagesRequest: ({ id, messages, trigger, messageId }) => {\n      return {\n        headers: {\n          'X-Session-ID': id,\n        },\n        body: {\n          messages: messages.slice(-10), // Only send last 10 messages\n          trigger,\n          messageId,\n        },\n      };\n    },\n  }),\n});\nBuilding Custom Transports\n\nTo understand how to build your own transport, refer to the source code of the default implementation:\n\nDefaultChatTransport\n - The complete default HTTP transport implementation\nHttpChatTransport\n - Base HTTP transport with request handling\nChatTransport Interface\n - The transport interface you need to implement\n\nThese implementations show you exactly how to:\n\nHandle the sendMessages method\nProcess UI message streams\nTransform requests and responses\nHandle errors and connection management\n\nThe transport system gives you complete control over how your chat application communicates, enabling integration with any backend protocol or service.\n\nPrevious\nError Handling\nNext\nReading UIMessage Streams"
  },
  {
    "title": "AI SDK UI: Reading UIMessage Streams",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/reading-ui-message-streams",
    "html": "AI SDK UI\nReading UIMessage Streams\nCopy markdown\nReading UI Message Streams\n\nUIMessage streams are useful outside of traditional chat use cases. You can consume them for terminal UIs, custom stream processing on the client, or React Server Components (RSC).\n\nThe readUIMessageStream helper transforms a stream of UIMessageChunk objects into an AsyncIterableStream of UIMessage objects, allowing you to process messages as they're being constructed.\n\nBasic Usage\nimport { openai } from '@ai-sdk/openai';\nimport { readUIMessageStream, streamText } from 'ai';\n\n\nasync function main() {\n  const result = streamText({\n    model: openai('gpt-4o'),\n    prompt: 'Write a short story about a robot.',\n  });\n\n\n  for await (const uiMessage of readUIMessageStream({\n    stream: result.toUIMessageStream(),\n  })) {\n    console.log('Current message state:', uiMessage);\n  }\n}\nTool Calls Integration\n\nHandle streaming responses that include tool calls:\n\nimport { openai } from '@ai-sdk/openai';\nimport { readUIMessageStream, streamText, tool } from 'ai';\nimport { z } from 'zod';\n\n\nasync function handleToolCalls() {\n  const result = streamText({\n    model: openai('gpt-4o'),\n    tools: {\n      weather: tool({\n        description: 'Get the weather in a location',\n        inputSchema: z.object({\n          location: z.string().describe('The location to get the weather for'),\n        }),\n        execute: ({ location }) => ({\n          location,\n          temperature: 72 + Math.floor(Math.random() * 21) - 10,\n        }),\n      }),\n    },\n    prompt: 'What is the weather in Tokyo?',\n  });\n\n\n  for await (const uiMessage of readUIMessageStream({\n    stream: result.toUIMessageStream(),\n  })) {\n    // Handle different part types\n    uiMessage.parts.forEach(part => {\n      switch (part.type) {\n        case 'text':\n          console.log('Text:', part.text);\n          break;\n        case 'tool-call':\n          console.log('Tool called:', part.toolName, 'with args:', part.args);\n          break;\n        case 'tool-result':\n          console.log('Tool result:', part.result);\n          break;\n      }\n    });\n  }\n}\nResuming Conversations\n\nResume streaming from a previous message state:\n\nimport { readUIMessageStream, streamText } from 'ai';\n\n\nasync function resumeConversation(lastMessage: UIMessage) {\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: [\n      { role: 'user', content: 'Continue our previous conversation.' },\n    ],\n  });\n\n\n  // Resume from the last message\n  for await (const uiMessage of readUIMessageStream({\n    stream: result.toUIMessageStream(),\n    message: lastMessage, // Resume from this message\n  })) {\n    console.log('Resumed message:', uiMessage);\n  }\n}\nPrevious\nTransport\nNext\nMessage Metadata"
  },
  {
    "title": "AI SDK UI: Message Metadata",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/message-metadata",
    "html": "AI SDK UI\nMessage Metadata\nCopy markdown\nMessage Metadata\n\nMessage metadata allows you to attach custom information to messages at the message level. This is useful for tracking timestamps, model information, token usage, user context, and other message-level data.\n\nOverview\n\nMessage metadata differs from data parts in that it's attached at the message level rather than being part of the message content. While data parts are ideal for dynamic content that forms part of the message, metadata is perfect for information about the message itself.\n\nGetting Started\n\nHere's a simple example of using message metadata to track timestamps and model information:\n\nDefining Metadata Types\n\nFirst, define your metadata type for type safety:\n\napp/types.ts\nimport { UIMessage } from 'ai';\nimport { z } from 'zod';\n\n\n// Define your metadata schema\nexport const messageMetadataSchema = z.object({\n  createdAt: z.number().optional(),\n  model: z.string().optional(),\n  totalTokens: z.number().optional(),\n});\n\n\nexport type MessageMetadata = z.infer<typeof messageMetadataSchema>;\n\n\n// Create a typed UIMessage\nexport type MyUIMessage = UIMessage<MessageMetadata>;\nSending Metadata from the Server\n\nUse the messageMetadata callback in toUIMessageStreamResponse to send metadata at different streaming stages:\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { convertToModelMessages, streamText } from 'ai';\nimport type { MyUIMessage } from '@/types';\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: MyUIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse({\n    originalMessages: messages, // pass this in for type-safe return objects\n    messageMetadata: ({ part }) => {\n      // Send metadata when streaming starts\n      if (part.type === 'start') {\n        return {\n          createdAt: Date.now(),\n          model: 'gpt-4o',\n        };\n      }\n\n\n      // Send additional metadata when streaming completes\n      if (part.type === 'finish') {\n        return {\n          totalTokens: part.totalUsage.totalTokens,\n        };\n      }\n    },\n  });\n}\n\nTo enable type-safe metadata return object in messageMetadata, pass in the originalMessages parameter typed to your UIMessage type.\n\nAccessing Metadata on the Client\n\nAccess metadata through the message.metadata property:\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { DefaultChatTransport } from 'ai';\nimport type { MyUIMessage } from '@/types';\n\n\nexport default function Chat() {\n  const { messages } = useChat<MyUIMessage>({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n  });\n\n\n  return (\n    <div>\n      {messages.map(message => (\n        <div key={message.id}>\n          <div>\n            {message.role === 'user' ? 'User: ' : 'AI: '}\n            {message.metadata?.createdAt && (\n              <span className=\"text-sm text-gray-500\">\n                {new Date(message.metadata.createdAt).toLocaleTimeString()}\n              </span>\n            )}\n          </div>\n\n\n          {/* Render message content */}\n          {message.parts.map((part, index) =>\n            part.type === 'text' ? <div key={index}>{part.text}</div> : null,\n          )}\n\n\n          {/* Display additional metadata */}\n          {message.metadata?.totalTokens && (\n            <div className=\"text-xs text-gray-400\">\n              {message.metadata.totalTokens} tokens\n            </div>\n          )}\n        </div>\n      ))}\n    </div>\n  );\n}\n\nFor streaming arbitrary data that changes during generation, consider using data parts instead.\n\nCommon Use Cases\n\nMessage metadata is ideal for:\n\nTimestamps: When messages were created or completed\nModel Information: Which AI model was used\nToken Usage: Track costs and usage limits\nUser Context: User IDs, session information\nPerformance Metrics: Generation time, time to first token\nQuality Indicators: Finish reason, confidence scores\nSee Also\nChatbot Guide - Message metadata in the context of building chatbots\nStreaming Data - Comparison with data parts\nUIMessage Reference - Complete UIMessage type reference\nPrevious\nReading UIMessage Streams\nNext\nStream Protocols"
  },
  {
    "title": "AI SDK UI: Stream Protocols",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol",
    "html": "AI SDK UI\nStream Protocols\nCopy markdown\nStream Protocols\n\nAI SDK UI functions such as useChat and useCompletion support both text streams and data streams. The stream protocol defines how the data is streamed to the frontend on top of the HTTP protocol.\n\nThis page describes both protocols and how to use them in the backend and frontend.\n\nYou can use this information to develop custom backends and frontends for your use case, e.g., to provide compatible API endpoints that are implemented in a different language such as Python.\n\nFor instance, here's an example using FastAPI\n as a backend.\n\nText Stream Protocol\n\nA text stream contains chunks in plain text, that are streamed to the frontend. Each chunk is then appended together to form a full text response.\n\nText streams are supported by useChat, useCompletion, and useObject. When you use useChat or useCompletion, you need to enable text streaming by setting the streamProtocol options to text.\n\nYou can generate text streams with streamText in the backend. When you call toTextStreamResponse() on the result object, a streaming HTTP response is returned.\n\nText streams only support basic text data. If you need to stream other types of data such as tool calls, use data streams.\n\nText Stream Example\n\nHere is a Next.js example that uses the text stream protocol:\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { TextStreamChatTransport } from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const [input, setInput] = useState('');\n  const { messages, sendMessage } = useChat({\n    transport: new TextStreamChatTransport({ api: '/api/chat' }),\n  });\n\n\n  return (\n    <div className=\"flex flex-col w-full max-w-md py-24 mx-auto stretch\">\n      {messages.map(message => (\n        <div key={message.id} className=\"whitespace-pre-wrap\">\n          {message.role === 'user' ? 'User: ' : 'AI: '}\n          {message.parts.map((part, i) => {\n            switch (part.type) {\n              case 'text':\n                return <div key={`${message.id}-${i}`}>{part.text}</div>;\n            }\n          })}\n        </div>\n      ))}\n\n\n      <form\n        onSubmit={e => {\n          e.preventDefault();\n          sendMessage({ text: input });\n          setInput('');\n        }}\n      >\n        <input\n          className=\"fixed dark:bg-zinc-900 bottom-0 w-full max-w-md p-2 mb-8 border border-zinc-300 dark:border-zinc-800 rounded shadow-xl\"\n          value={input}\n          placeholder=\"Say something...\"\n          onChange={e => setInput(e.currentTarget.value)}\n        />\n      </form>\n    </div>\n  );\n}\napp/api/chat/route.ts\nimport { streamText, UIMessage, convertToModelMessages } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\n\n// Allow streaming responses up to 30 seconds\nexport const maxDuration = 30;\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toTextStreamResponse();\n}\nData Stream Protocol\n\nA data stream follows a special protocol that the AI SDK provides to send information to the frontend.\n\nThe data stream protocol uses Server-Sent Events (SSE) format for improved standardization, keep-alive through ping, reconnect capabilities, and better cache handling.\n\nWhen you provide data streams from a custom backend, you need to set the x-vercel-ai-ui-message-stream header to v1.\n\nThe following stream parts are currently supported:\n\nMessage Start Part\n\nIndicates the beginning of a new message with metadata.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"start\",\"messageId\":\"...\"}\nText Parts\n\nText content is streamed using a start/delta/end pattern with unique IDs for each text block.\n\nText Start Part\n\nIndicates the beginning of a text block.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"text-start\",\"id\":\"msg_68679a454370819ca74c8eb3d04379630dd1afb72306ca5d\"}\nText Delta Part\n\nContains incremental text content for the text block.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"text-delta\",\"id\":\"msg_68679a454370819ca74c8eb3d04379630dd1afb72306ca5d\",\"delta\":\"Hello\"}\nText End Part\n\nIndicates the completion of a text block.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"text-end\",\"id\":\"msg_68679a454370819ca74c8eb3d04379630dd1afb72306ca5d\"}\nReasoning Parts\n\nReasoning content is streamed using a start/delta/end pattern with unique IDs for each reasoning block.\n\nReasoning Start Part\n\nIndicates the beginning of a reasoning block.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"reasoning-start\",\"id\":\"reasoning_123\"}\nReasoning Delta Part\n\nContains incremental reasoning content for the reasoning block.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"reasoning-delta\",\"id\":\"reasoning_123\",\"delta\":\"This is some reasoning\"}\nReasoning End Part\n\nIndicates the completion of a reasoning block.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"reasoning-end\",\"id\":\"reasoning_123\"}\nSource Parts\n\nSource parts provide references to external content sources.\n\nSource URL Part\n\nReferences to external URLs.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"source-url\",\"sourceId\":\"https://example.com\",\"url\":\"https://example.com\"}\nSource Document Part\n\nReferences to documents or files.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"source-document\",\"sourceId\":\"https://example.com\",\"mediaType\":\"file\",\"title\":\"Title\"}\nFile Part\n\nThe file parts contain references to files with their media type.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"file\",\"url\":\"https://example.com/file.png\",\"mediaType\":\"image/png\"}\nData Parts\n\nCustom data parts allow streaming of arbitrary structured data with type-specific handling.\n\nFormat: Server-Sent Event with JSON object where the type includes a custom suffix\n\nExample:\n\ndata: {\"type\":\"data-weather\",\"data\":{\"location\":\"SF\",\"temperature\":100}}\n\nThe data-* type pattern allows you to define custom data types that your frontend can handle specifically.\n\nError Part\n\nThe error parts are appended to the message as they are received.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"error\",\"errorText\":\"error message\"}\nTool Input Start Part\n\nIndicates the beginning of tool input streaming.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"tool-input-start\",\"toolCallId\":\"call_fJdQDqnXeGxTmr4E3YPSR7Ar\",\"toolName\":\"getWeatherInformation\"}\nTool Input Delta Part\n\nIncremental chunks of tool input as it's being generated.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"tool-input-delta\",\"toolCallId\":\"call_fJdQDqnXeGxTmr4E3YPSR7Ar\",\"inputTextDelta\":\"San Francisco\"}\nTool Input Available Part\n\nIndicates that tool input is complete and ready for execution.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"tool-input-available\",\"toolCallId\":\"call_fJdQDqnXeGxTmr4E3YPSR7Ar\",\"toolName\":\"getWeatherInformation\",\"input\":{\"city\":\"San Francisco\"}}\nTool Output Available Part\n\nContains the result of tool execution.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"tool-output-available\",\"toolCallId\":\"call_fJdQDqnXeGxTmr4E3YPSR7Ar\",\"output\":{\"city\":\"San Francisco\",\"weather\":\"sunny\"}}\nStart Step Part\n\nA part indicating the start of a step.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"start-step\"}\nFinish Step Part\n\nA part indicating that a step (i.e., one LLM API call in the backend) has been completed.\n\nThis part is necessary to correctly process multiple stitched assistant calls, e.g. when calling tools in the backend, and using steps in useChat at the same time.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"finish-step\"}\nFinish Message Part\n\nA part indicating the completion of a message.\n\nFormat: Server-Sent Event with JSON object\n\nExample:\n\ndata: {\"type\":\"finish\"}\nStream Termination\n\nThe stream ends with a special [DONE] marker.\n\nFormat: Server-Sent Event with literal [DONE]\n\nExample:\n\ndata: [DONE]\n\nThe data stream protocol is supported by useChat and useCompletion on the frontend and used by default. useCompletion only supports the text and data stream parts.\n\nOn the backend, you can use toUIMessageStreamResponse() from the streamText result object to return a streaming HTTP response.\n\nUI Message Stream Example\n\nHere is a Next.js example that uses the UI message stream protocol:\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const [input, setInput] = useState('');\n  const { messages, sendMessage } = useChat();\n\n\n  return (\n    <div className=\"flex flex-col w-full max-w-md py-24 mx-auto stretch\">\n      {messages.map(message => (\n        <div key={message.id} className=\"whitespace-pre-wrap\">\n          {message.role === 'user' ? 'User: ' : 'AI: '}\n          {message.parts.map((part, i) => {\n            switch (part.type) {\n              case 'text':\n                return <div key={`${message.id}-${i}`}>{part.text}</div>;\n            }\n          })}\n        </div>\n      ))}\n\n\n      <form\n        onSubmit={e => {\n          e.preventDefault();\n          sendMessage({ text: input });\n          setInput('');\n        }}\n      >\n        <input\n          className=\"fixed dark:bg-zinc-900 bottom-0 w-full max-w-md p-2 mb-8 border border-zinc-300 dark:border-zinc-800 rounded shadow-xl\"\n          value={input}\n          placeholder=\"Say something...\"\n          onChange={e => setInput(e.currentTarget.value)}\n        />\n      </form>\n    </div>\n  );\n}\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { streamText, UIMessage, convertToModelMessages } from 'ai';\n\n\n// Allow streaming responses up to 30 seconds\nexport const maxDuration = 30;\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\nPrevious\nMessage Metadata\nNext\nAI SDK RSC"
  },
  {
    "title": "AI SDK UI: Chatbot Tool Usage",
    "url": "https://ai-sdk.dev/docs/ai-sdk-ui/chatbot-tool-usage",
    "html": "AI SDK UI\nChatbot Tool Usage\nCopy markdown\nChatbot Tool Usage\n\nWith useChat and streamText, you can use tools in your chatbot application. The AI SDK supports three types of tools in this context:\n\nAutomatically executed server-side tools\nAutomatically executed client-side tools\nTools that require user interaction, such as confirmation dialogs\n\nThe flow is as follows:\n\nThe user enters a message in the chat UI.\nThe message is sent to the API route.\nIn your server side route, the language model generates tool calls during the streamText call.\nAll tool calls are forwarded to the client.\nServer-side tools are executed using their execute method and their results are forwarded to the client.\nClient-side tools that should be automatically executed are handled with the onToolCall callback. You must call addToolResult to provide the tool result.\nClient-side tool that require user interactions can be displayed in the UI. The tool calls and results are available as tool invocation parts in the parts property of the last assistant message.\nWhen the user interaction is done, addToolResult can be used to add the tool result to the chat.\nThe chat can be configured to automatically submit when all tool results are available using sendAutomaticallyWhen. This triggers another iteration of this flow.\n\nThe tool calls and tool executions are integrated into the assistant message as typed tool parts. A tool part is at first a tool call, and then it becomes a tool result when the tool is executed. The tool result contains all information about the tool call as well as the result of the tool execution.\n\nTool result submission can be configured using the sendAutomaticallyWhen option. You can use the lastAssistantMessageIsCompleteWithToolCalls helper to automatically submit when all tool results are available. This simplifies the client-side code while still allowing full control when needed.\n\nExample\n\nIn this example, we'll use three tools:\n\ngetWeatherInformation: An automatically executed server-side tool that returns the weather in a given city.\naskForConfirmation: A user-interaction client-side tool that asks the user for confirmation.\ngetLocation: An automatically executed client-side tool that returns a random city.\nAPI route\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { convertToModelMessages, streamText, UIMessage } from 'ai';\nimport { z } from 'zod';\n\n\n// Allow streaming responses up to 30 seconds\nexport const maxDuration = 30;\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n    tools: {\n      // server-side tool with execute function:\n      getWeatherInformation: {\n        description: 'show the weather in a given city to the user',\n        inputSchema: z.object({ city: z.string() }),\n        execute: async ({}: { city: string }) => {\n          const weatherOptions = ['sunny', 'cloudy', 'rainy', 'snowy', 'windy'];\n          return weatherOptions[\n            Math.floor(Math.random() * weatherOptions.length)\n          ];\n        },\n      },\n      // client-side tool that starts user interaction:\n      askForConfirmation: {\n        description: 'Ask the user for confirmation.',\n        inputSchema: z.object({\n          message: z.string().describe('The message to ask for confirmation.'),\n        }),\n      },\n      // client-side tool that is automatically executed on the client:\n      getLocation: {\n        description:\n          'Get the user location. Always ask for confirmation before using this tool.',\n        inputSchema: z.object({}),\n      },\n    },\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\nClient-side page\n\nThe client-side page uses the useChat hook to create a chatbot application with real-time message streaming. Tool calls are displayed in the chat UI as typed tool parts. Please make sure to render the messages using the parts property of the message.\n\nThere are three things worth mentioning:\n\nThe onToolCall callback is used to handle client-side tools that should be automatically executed. In this example, the getLocation tool is a client-side tool that returns a random city. You call addToolResult to provide the result (without await to avoid potential deadlocks).\n\nAlways check if (toolCall.dynamic) first in your onToolCall handler. Without this check, TypeScript will throw an error like: Type 'string' is not assignable to type '\"toolName1\" | \"toolName2\"' when you try to use toolCall.toolName in addToolResult.\n\nThe sendAutomaticallyWhen option with lastAssistantMessageIsCompleteWithToolCalls helper automatically submits when all tool results are available.\n\nThe parts array of assistant messages contains tool parts with typed names like tool-askForConfirmation. The client-side tool askForConfirmation is displayed in the UI. It asks the user for confirmation and displays the result once the user confirms or denies the execution. The result is added to the chat using addToolResult with the tool parameter for type safety.\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport {\n  DefaultChatTransport,\n  lastAssistantMessageIsCompleteWithToolCalls,\n} from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const { messages, sendMessage, addToolResult } = useChat({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n\n\n    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls,\n\n\n    // run client-side tools that are automatically executed:\n    async onToolCall({ toolCall }) {\n      // Check if it's a dynamic tool first for proper type narrowing\n      if (toolCall.dynamic) {\n        return;\n      }\n\n\n      if (toolCall.toolName === 'getLocation') {\n        const cities = ['New York', 'Los Angeles', 'Chicago', 'San Francisco'];\n\n\n        // No await - avoids potential deadlocks\n        addToolResult({\n          tool: 'getLocation',\n          toolCallId: toolCall.toolCallId,\n          output: cities[Math.floor(Math.random() * cities.length)],\n        });\n      }\n    },\n  });\n  const [input, setInput] = useState('');\n\n\n  return (\n    <>\n      {messages?.map(message => (\n        <div key={message.id}>\n          <strong>{`${message.role}: `}</strong>\n          {message.parts.map(part => {\n            switch (part.type) {\n              // render text parts as simple text:\n              case 'text':\n                return part.text;\n\n\n              // for tool parts, use the typed tool part names:\n              case 'tool-askForConfirmation': {\n                const callId = part.toolCallId;\n\n\n                switch (part.state) {\n                  case 'input-streaming':\n                    return (\n                      <div key={callId}>Loading confirmation request...</div>\n                    );\n                  case 'input-available':\n                    return (\n                      <div key={callId}>\n                        {part.input.message}\n                        <div>\n                          <button\n                            onClick={() =>\n                              addToolResult({\n                                tool: 'askForConfirmation',\n                                toolCallId: callId,\n                                output: 'Yes, confirmed.',\n                              })\n                            }\n                          >\n                            Yes\n                          </button>\n                          <button\n                            onClick={() =>\n                              addToolResult({\n                                tool: 'askForConfirmation',\n                                toolCallId: callId,\n                                output: 'No, denied',\n                              })\n                            }\n                          >\n                            No\n                          </button>\n                        </div>\n                      </div>\n                    );\n                  case 'output-available':\n                    return (\n                      <div key={callId}>\n                        Location access allowed: {part.output}\n                      </div>\n                    );\n                  case 'output-error':\n                    return <div key={callId}>Error: {part.errorText}</div>;\n                }\n                break;\n              }\n\n\n              case 'tool-getLocation': {\n                const callId = part.toolCallId;\n\n\n                switch (part.state) {\n                  case 'input-streaming':\n                    return (\n                      <div key={callId}>Preparing location request...</div>\n                    );\n                  case 'input-available':\n                    return <div key={callId}>Getting location...</div>;\n                  case 'output-available':\n                    return <div key={callId}>Location: {part.output}</div>;\n                  case 'output-error':\n                    return (\n                      <div key={callId}>\n                        Error getting location: {part.errorText}\n                      </div>\n                    );\n                }\n                break;\n              }\n\n\n              case 'tool-getWeatherInformation': {\n                const callId = part.toolCallId;\n\n\n                switch (part.state) {\n                  // example of pre-rendering streaming tool inputs:\n                  case 'input-streaming':\n                    return (\n                      <pre key={callId}>{JSON.stringify(part, null, 2)}</pre>\n                    );\n                  case 'input-available':\n                    return (\n                      <div key={callId}>\n                        Getting weather information for {part.input.city}...\n                      </div>\n                    );\n                  case 'output-available':\n                    return (\n                      <div key={callId}>\n                        Weather in {part.input.city}: {part.output}\n                      </div>\n                    );\n                  case 'output-error':\n                    return (\n                      <div key={callId}>\n                        Error getting weather for {part.input.city}:{' '}\n                        {part.errorText}\n                      </div>\n                    );\n                }\n                break;\n              }\n            }\n          })}\n          <br />\n        </div>\n      ))}\n\n\n      <form\n        onSubmit={e => {\n          e.preventDefault();\n          if (input.trim()) {\n            sendMessage({ text: input });\n            setInput('');\n          }\n        }}\n      >\n        <input value={input} onChange={e => setInput(e.target.value)} />\n      </form>\n    </>\n  );\n}\nError handling\n\nSometimes an error may occur during client-side tool execution. Use the addToolResult method with a state of output-error and errorText value instead of output record the error.\n\napp/page.tsx\n'use client';\n\n\nimport { useChat } from '@ai-sdk/react';\nimport {\n  DefaultChatTransport,\n  lastAssistantMessageIsCompleteWithToolCalls,\n} from 'ai';\nimport { useState } from 'react';\n\n\nexport default function Chat() {\n  const { messages, sendMessage, addToolResult } = useChat({\n    transport: new DefaultChatTransport({\n      api: '/api/chat',\n    }),\n\n\n    sendAutomaticallyWhen: lastAssistantMessageIsCompleteWithToolCalls,\n\n\n    // run client-side tools that are automatically executed:\n    async onToolCall({ toolCall }) {\n      // Check if it's a dynamic tool first for proper type narrowing\n      if (toolCall.dynamic) {\n        return;\n      }\n\n\n      if (toolCall.toolName === 'getWeatherInformation') {\n        try {\n          const weather = await getWeatherInformation(toolCall.input);\n\n\n          // No await - avoids potential deadlocks\n          addToolResult({\n            tool: 'getWeatherInformation',\n            toolCallId: toolCall.toolCallId,\n            output: weather,\n          });\n        } catch (err) {\n          addToolResult({\n            tool: 'getWeatherInformation',\n            toolCallId: toolCall.toolCallId,\n            state: 'output-error',\n            errorText: 'Unable to get the weather information',\n          });\n        }\n      }\n    },\n  });\n}\nDynamic Tools\n\nWhen using dynamic tools (tools with unknown types at compile time), the UI parts use a generic dynamic-tool type instead of specific tool types:\n\napp/page.tsx\n{\n  message.parts.map((part, index) => {\n    switch (part.type) {\n      // Static tools with specific (`tool-${toolName}`) types\n      case 'tool-getWeatherInformation':\n        return <WeatherDisplay part={part} />;\n\n\n      // Dynamic tools use generic `dynamic-tool` type\n      case 'dynamic-tool':\n        return (\n          <div key={index}>\n            <h4>Tool: {part.toolName}</h4>\n            {part.state === 'input-streaming' && (\n              <pre>{JSON.stringify(part.input, null, 2)}</pre>\n            )}\n            {part.state === 'output-available' && (\n              <pre>{JSON.stringify(part.output, null, 2)}</pre>\n            )}\n            {part.state === 'output-error' && (\n              <div>Error: {part.errorText}</div>\n            )}\n          </div>\n        );\n    }\n  });\n}\n\nDynamic tools are useful when integrating with:\n\nMCP (Model Context Protocol) tools without schemas\nUser-defined functions loaded at runtime\nExternal tool providers\nTool call streaming\n\nTool call streaming is enabled by default in AI SDK 5.0, allowing you to stream tool calls while they are being generated. This provides a better user experience by showing tool inputs as they are generated in real-time.\n\napp/api/chat/route.ts\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n    // toolCallStreaming is enabled by default in v5\n    // ...\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\n\nWith tool call streaming enabled, partial tool calls are streamed as part of the data stream. They are available through the useChat hook. The typed tool parts of assistant messages will also contain partial tool calls. You can use the state property of the tool part to render the correct UI.\n\napp/page.tsx\nexport default function Chat() {\n  // ...\n  return (\n    <>\n      {messages?.map(message => (\n        <div key={message.id}>\n          {message.parts.map(part => {\n            switch (part.type) {\n              case 'tool-askForConfirmation':\n              case 'tool-getLocation':\n              case 'tool-getWeatherInformation':\n                switch (part.state) {\n                  case 'input-streaming':\n                    return <pre>{JSON.stringify(part.input, null, 2)}</pre>;\n                  case 'input-available':\n                    return <pre>{JSON.stringify(part.input, null, 2)}</pre>;\n                  case 'output-available':\n                    return <pre>{JSON.stringify(part.output, null, 2)}</pre>;\n                  case 'output-error':\n                    return <div>Error: {part.errorText}</div>;\n                }\n            }\n          })}\n        </div>\n      ))}\n    </>\n  );\n}\nStep start parts\n\nWhen you are using multi-step tool calls, the AI SDK will add step start parts to the assistant messages. If you want to display boundaries between tool calls, you can use the step-start parts as follows:\n\napp/page.tsx\n// ...\n// where you render the message parts:\nmessage.parts.map((part, index) => {\n  switch (part.type) {\n    case 'step-start':\n      // show step boundaries as horizontal lines:\n      return index > 0 ? (\n        <div key={index} className=\"text-gray-500\">\n          <hr className=\"my-2 border-gray-300\" />\n        </div>\n      ) : null;\n    case 'text':\n    // ...\n    case 'tool-askForConfirmation':\n    case 'tool-getLocation':\n    case 'tool-getWeatherInformation':\n    // ...\n  }\n});\n// ...\nServer-side Multi-Step Calls\n\nYou can also use multi-step calls on the server-side with streamText. This works when all invoked tools have an execute function on the server side.\n\napp/api/chat/route.ts\nimport { openai } from '@ai-sdk/openai';\nimport { convertToModelMessages, streamText, UIMessage, stepCountIs } from 'ai';\nimport { z } from 'zod';\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n\n  const result = streamText({\n    model: openai('gpt-4o'),\n    messages: convertToModelMessages(messages),\n    tools: {\n      getWeatherInformation: {\n        description: 'show the weather in a given city to the user',\n        inputSchema: z.object({ city: z.string() }),\n        // tool has execute function:\n        execute: async ({}: { city: string }) => {\n          const weatherOptions = ['sunny', 'cloudy', 'rainy', 'snowy', 'windy'];\n          return weatherOptions[\n            Math.floor(Math.random() * weatherOptions.length)\n          ];\n        },\n      },\n    },\n    stopWhen: stepCountIs(5),\n  });\n\n\n  return result.toUIMessageStreamResponse();\n}\nErrors\n\nLanguage models can make errors when calling tools. By default, these errors are masked for security reasons, and show up as \"An error occurred\" in the UI.\n\nTo surface the errors, you can use the onError function when calling toUIMessageResponse.\n\nexport function errorHandler(error: unknown) {\n  if (error == null) {\n    return 'unknown error';\n  }\n\n\n  if (typeof error === 'string') {\n    return error;\n  }\n\n\n  if (error instanceof Error) {\n    return error.message;\n  }\n\n\n  return JSON.stringify(error);\n}\nconst result = streamText({\n  // ...\n});\n\n\nreturn result.toUIMessageStreamResponse({\n  onError: errorHandler,\n});\n\nIn case you are using createUIMessageResponse, you can use the onError function when calling toUIMessageResponse:\n\nconst response = createUIMessageResponse({\n  // ...\n  async execute(dataStream) {\n    // ...\n  },\n  onError: error => `Custom error: ${error.message}`,\n});\nPrevious\nChatbot Resume Streams\nNext\nGenerative User Interfaces"
  }
]
</file>

<file path="output/zod/docs.json">
[
	{
		"title": "Intro | Zod",
		"url": "https://zod.dev/",
		"html": "Zod\n\nTypeScript-first schema validation with static type inference\nby @colinhacks\n\n\n\nWebsite\n  •  \nDiscord\n  •  \n𝕏\n  •  \nBluesky\n\n\n\n\n\nZod 4 is now stable! Read the release notes here.\n\n\n\n\n\nFeatured sponsor: Jazz\n\nInterested in featuring? Get in touch.\n\nIntroduction\n\nZod is a TypeScript-first validation library. Using Zod, you can define schemas you can use to validate data, from a simple string to a complex nested object.\n\nimport * as z from \"zod\";\n \nconst User = z.object({\n  name: z.string(),\n});\n \n// some untrusted data...\nconst input = { /* stuff */ };\n \n// the parsed result is validated and type safe!\nconst data = User.parse(input);\n \n// so you can use it with confidence :)\nconsole.log(data.name);\nFeatures\nZero external dependencies\nWorks in Node.js and all modern browsers\nTiny: 2kb core bundle (gzipped)\nImmutable API: methods return a new instance\nConcise interface\nWorks with TypeScript and plain JS\nBuilt-in JSON Schema conversion\nExtensive ecosystem\nInstallation\nnpm install zod\n\nZod is also available as @zod/zod on jsr.io.\n\nZod provides an MCP server that can be used by agents to search Zod's docs. To add to your editor, follow these instructions. Zod also provides an llms.txt file.\n\nRequirements\n\nZod is tested against TypeScript v5.5 and later. Older versions may work but are not officially supported.\n\n\"strict\"\n\nYou must enable strict mode in your tsconfig.json. This is a best practice for all TypeScript projects.\n\n// tsconfig.json\n{\n  // ...\n  \"compilerOptions\": {\n    // ...\n    \"strict\": true\n  }\n}\nEcosystem\n\nZod has a thriving ecosystem of libraries, tools, and integrations. Refer to the Ecosystem page for a complete list of libraries that support Zod or are built on top of it.\n\nResources\nAPI Libraries\nForm Integrations\nZod to X\nX to Zod\nMocking Libraries\nPowered by Zod\n\nI also contribute to the following projects, which I'd like to highlight:\n\ntRPC - End-to-end typesafe APIs, with support for Zod schemas\nReact Hook Form - Hook-based form validation with a Zod resolver\nzshy - Originally created as Zod's internal build tool. Bundler-free, batteries-included build tool for TypeScript libraries. Powered by tsc.\nSponsors\n\nSponsorship at any level is appreciated and encouraged. If you built a paid product using Zod, consider one of the corporate tiers.\n\nPlatinum\n\nCut code review time & bugs in half\n\ncoderabbit.ai\n\n\n\nGold\n\nThe API platform for sending notifications\n\ncourier.com\n\nGenerate better SDKs for your APIs\n\nliblab.com\n\nServerless Postgres — Ship faster\n\nneon.tech\n\nBuild AI apps and workflows with Retool AI\n\nretool.com\n\nGenerate best-in-class SDKs\n\nstainlessapi.com\n\nSDKs & Terraform providers for your API\n\nspeakeasy.com\n\n\nSilver\nsubtotal.com\njuno.build\nnitric.io\npropelauth.com\ncerbos.dev\nscalar.com\ntrigger.dev\ntransloadit.com\ninfisical.com\nwhop.com\ncryptojobslist.com\nplain.com\ninngest.com\nstoryblok.com\nmux.link/zod\n\n\nBronze\n\n\n\nMigration guide\n\nComplete changelog and migration guide for upgrading from Zod 3 to Zod 4\n\nBasic usage\n\nBasic usage guide covering schema definition, parsing data, error handling, and type inference"
	},
	{
		"title": "Basic usage | Zod",
		"url": "https://zod.dev/basics",
		"html": "Basic usage\nCopy markdown\nEdit this page\n\nThis page will walk you through the basics of creating schemas, parsing data, and using inferred types. For complete documentation on Zod's schema API, refer to Defining schemas.\n\nDefining a schema\n\nBefore you can do anything else, you need to define a schema. For the purposes of this guide, we'll use a simple object schema.\n\nZod\nZod Mini\nimport * as z from \"zod\"; \n \nconst Player = z.object({ \n  username: z.string(),\n  xp: z.number()\n});\nParsing data\n\nGiven any Zod schema, use .parse to validate an input. If it's valid, Zod returns a strongly-typed deep clone of the input.\n\nPlayer.parse({ username: \"billie\", xp: 100 }); \n// => returns { username: \"billie\", xp: 100 }\n\nNote — If your schema uses certain asynchronous APIs like async refinements or transforms, you'll need to use the .parseAsync() method instead.\n\nawait Player.parseAsync({ username: \"billie\", xp: 100 }); \nHandling errors\n\nWhen validation fails, the .parse() method will throw a ZodError instance with granular information about the validation issues.\n\nZod\nZod Mini\ntry {\n  Player.parse({ username: 42, xp: \"100\" });\n} catch(error){\n  if(error instanceof z.ZodError){\n    error.issues; \n    /* [\n      {\n        expected: 'string',\n        code: 'invalid_type',\n        path: [ 'username' ],\n        message: 'Invalid input: expected string'\n      },\n      {\n        expected: 'number',\n        code: 'invalid_type',\n        path: [ 'xp' ],\n        message: 'Invalid input: expected number'\n      }\n    ] */\n  }\n}\n\nTo avoid a try/catch block, you can use the .safeParse() method to get back a plain result object containing either the successfully parsed data or a ZodError. The result type is a discriminated union, so you can handle both cases conveniently.\n\nconst result = Player.safeParse({ username: 42, xp: \"100\" });\nif (!result.success) {\n  result.error;   // ZodError instance\n} else {\n  result.data;    // { username: string; xp: number }\n}\n\nNote — If your schema uses certain asynchronous APIs like async refinements or transforms, you'll need to use the .safeParseAsync() method instead.\n\nawait schema.safeParseAsync(\"hello\");\nInferring types\n\nZod infers a static type from your schema definitions. You can extract this type with the z.infer<> utility and use it however you like.\n\nconst Player = z.object({ \n  username: z.string(),\n  xp: z.number()\n});\n \n// extract the inferred type\ntype Player = z.infer<typeof Player>;\n \n// use it in your code\nconst player: Player = { username: \"billie\", xp: 100 };\n\nIn some cases, the input & output types of a schema can diverge. For instance, the .transform() API can convert the input from one type to another. In these cases, you can extract the input and output types independently:\n\nconst mySchema = z.string().transform((val) => val.length);\n \ntype MySchemaIn = z.input<typeof mySchema>;\n// => string\n \ntype MySchemaOut = z.output<typeof mySchema>; // equivalent to z.infer<typeof mySchema>\n// number\n\nNow that we have the basics covered, let's jump into the Schema API.\n\nIntro\n\nIntroduction to Zod - TypeScript-first schema validation library with static type inference\n\nDefining schemas\n\nComplete API reference for all Zod schema types, methods, and validation features"
	},
	{
		"title": "Release notes | Zod",
		"url": "https://zod.dev/v4",
		"html": "Release notes\nCopy markdown\nEdit this page\n\nAfter a year of active development: Zod 4 is now stable! It's faster, slimmer, more tsc-efficient, and implements some long-requested features.\n\n❤️\n\nHuge thanks to Clerk, who supported my work on Zod 4 through their extremely generous OSS Fellowship. They were an amazing partner throughout the (much longer than anticipated!) development process.\n\nVersioning\n\nTo upgrade:\n\nnpm install zod@^4.0.0\n\nFor a complete list of breaking changes, refer to the Migration guide. This post focuses on new features & enhancements.\n\nWhy a new major version?\n\nZod v3.0 was released in May 2021 (!). Back then Zod had 2700 stars on GitHub and 600k weekly downloads. Today it has 37.8k stars and 31M weekly downloads (up from 23M when the beta came out 6 weeks ago!). After 24 minor versions, the Zod 3 codebase had hit a ceiling; the most commonly requested features and improvements require breaking changes.\n\nZod 4 fixes a number of long-standing design limitations of Zod 3 in one fell swoop, paving the way for several long-requested features and a huge leap in performance. It closes 9 of Zod's 10 most upvoted open issues. With luck, it will serve as the new foundation for many more years to come.\n\nFor a scannable breakdown of what's new, see the table of contents. Click on any item to jump to that section.\n\nBenchmarks\n\nYou can run these benchmarks yourself in the Zod repo:\n\n$ git clone git@github.com:colinhacks/zod.git\n$ cd zod\n$ git switch v4\n$ pnpm install\n\nThen to run a particular benchmark:\n\n$ pnpm bench <name>\n14x faster string parsing\n$ pnpm bench string\nruntime: node v22.13.0 (arm64-darwin)\n \nbenchmark      time (avg)             (min … max)       p75       p99      p999\n------------------------------------------------- -----------------------------\n• z.string().parse\n------------------------------------------------- -----------------------------\nzod3          363 µs/iter       (338 µs … 683 µs)    351 µs    467 µs    572 µs\nzod4       24'674 ns/iter    (21'083 ns … 235 µs) 24'209 ns 76'125 ns    120 µs\n \nsummary for z.string().parse\n  zod4\n   14.71x faster than zod3\n7x faster array parsing\n$ pnpm bench array\nruntime: node v22.13.0 (arm64-darwin)\n \nbenchmark      time (avg)             (min … max)       p75       p99      p999\n------------------------------------------------- -----------------------------\n• z.array() parsing\n------------------------------------------------- -----------------------------\nzod3          147 µs/iter       (137 µs … 767 µs)    140 µs    246 µs    520 µs\nzod4       19'817 ns/iter    (18'125 ns … 436 µs) 19'125 ns 44'500 ns    137 µs\n \nsummary for z.array() parsing\n  zod4\n   7.43x faster than zod3\n6.5x faster object parsing\n\nThis runs the Moltar validation library benchmark.\n\n$ pnpm bench object-moltar\nbenchmark      time (avg)             (min … max)       p75       p99      p999\n------------------------------------------------- -----------------------------\n• z.object() safeParse\n------------------------------------------------- -----------------------------\nzod3          805 µs/iter     (771 µs … 2'802 µs)    804 µs    928 µs  2'802 µs\nzod4          124 µs/iter     (118 µs … 1'236 µs)    119 µs    231 µs    329 µs\n \nsummary for z.object() safeParse\n  zod4\n   6.5x faster than zod3\n100x reduction in tsc instantiations\n\nConsider the following simple file:\n\nimport * as z from \"zod\";\n \nexport const A = z.object({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n  d: z.string(),\n  e: z.string(),\n});\n \nexport const B = A.extend({\n  f: z.string(),\n  g: z.string(),\n  h: z.string(),\n});\n\nCompiling this file with tsc --extendedDiagnostics using \"zod/v3\" results in >25000 type instantiations. With \"zod/v4\" it only results in ~175.\n\nThe Zod repo contains a tsc benchmarking playground. Try this for yourself using the compiler benchmarks in packages/tsc. The exact numbers may change as the implementation evolves.\n\n$ cd packages/tsc\n$ pnpm bench object-with-extend\n\nMore importantly, Zod 4 has redesigned and simplified the generics of ZodObject and other schema classes to avoid some pernicious \"instantiation explosions\". For instance, chaining .extend() and .omit() repeatedly—something that previously caused compiler issues:\n\nimport * as z from \"zod\";\n \nexport const a = z.object({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const b = a.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const c = b.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const d = c.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const e = d.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const f = e.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const g = f.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const h = g.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const i = h.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const j = i.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const k = j.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const l = k.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const m = l.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const n = m.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const o = n.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n \nexport const p = o.omit({\n  a: true,\n  b: true,\n  c: true,\n});\n \nexport const q = p.extend({\n  a: z.string(),\n  b: z.string(),\n  c: z.string(),\n});\n\nIn Zod 3, this took 4000ms to compile; and adding additional calls to .extend() would trigger a \"Possibly infinite\" error. In Zod 4, this compiles in 400ms, 10x faster.\n\nCoupled with the upcoming tsgo compiler, Zod 4's editor performance will scale to vastly larger schemas and codebases.\n\n2x reduction in core bundle size\n\nConsider the following simple script.\n\nimport * as z from \"zod\";\n \nconst schema = z.boolean();\n \nschema.parse(true);\n\nIt's about as simple as it gets when it comes to validation. That's intentional; it's a good way to measure the core bundle size—the code that will end up in the bundle even in simple cases. We'll bundle this with rollup using both Zod 3 and Zod 4 and compare the final bundles.\n\nPackage\tBundle (gzip)\nZod 3\t12.47kb\nZod 4\t5.36kb\n\nThe core bundle is ~57% smaller in Zod 4 (2.3x). That's good! But we can do a lot better.\n\nIntroducing Zod Mini\n\nZod's method-heavy API is fundamentally difficult to tree-shake. Even our simple z.boolean() script pulls in the implementations of a bunch of methods we didn't use, like .optional(), .array(), etc. Writing slimmer implementations can only get you so far. That's where Zod Mini comes in.\n\nnpm install zod@^4.0.0\n\nIt's a Zod variant with a functional, tree-shakable API that corresponds one-to-one with zod. Where Zod uses methods, Zod Mini generally uses wrapper functions:\n\nZod Mini\nZod\nimport * as z from \"zod/mini\";\n \nz.optional(z.string());\n \nz.union([z.string(), z.number()]);\n \nz.extend(z.object({ /* ... */ }), { age: z.number() });\n\nNot all methods are gone! The parsing methods are identical in Zod and Zod Mini:\n\nimport * as z from \"zod/mini\";\n \nz.string().parse(\"asdf\");\nz.string().safeParse(\"asdf\");\nawait z.string().parseAsync(\"asdf\");\nawait z.string().safeParseAsync(\"asdf\");\n\nThere's also a general-purpose .check() method used to add refinements.\n\nZod Mini\nZod\nimport * as z from \"zod/mini\";\n \nz.array(z.number()).check(\n  z.minLength(5), \n  z.maxLength(10),\n  z.refine(arr => arr.includes(5))\n);\n\nThe following top-level refinements are available in Zod Mini. It should be fairly self-explanatory which Zod methods they correspond to.\n\nimport * as z from \"zod/mini\";\n \n// custom checks\nz.refine();\n \n// first-class checks\nz.lt(value);\nz.lte(value); // alias: z.maximum()\nz.gt(value);\nz.gte(value); // alias: z.minimum()\nz.positive();\nz.negative();\nz.nonpositive();\nz.nonnegative();\nz.multipleOf(value);\nz.maxSize(value);\nz.minSize(value);\nz.size(value);\nz.maxLength(value);\nz.minLength(value);\nz.length(value);\nz.regex(regex);\nz.lowercase();\nz.uppercase();\nz.includes(value);\nz.startsWith(value);\nz.endsWith(value);\nz.property(key, schema); // for object schemas; check `input[key]` against `schema`\nz.mime(value); // for file schemas (see below)\n \n// overwrites (these *do not* change the inferred type!)\nz.overwrite(value => newValue);\nz.normalize();\nz.trim();\nz.toLowerCase();\nz.toUpperCase();\n\nThis more functional API makes it easier for bundlers to tree-shake the APIs you don't use. While regular Zod is still recommended for the majority of use cases, any projects with uncommonly strict bundle size constraints should consider Zod Mini.\n\n6.6x reduction in core bundle size\n\nHere's the script from above, updated to use \"zod/mini\" instead of \"zod\".\n\nimport * as z from \"zod/mini\";\n \nconst schema = z.boolean();\nschema.parse(false);\n\nWhen we build this with rollup, the gzipped bundle size is 1.88kb. That's an 85% (6.6x) reduction in core bundle size compared to zod@3.\n\nPackage\tBundle (gzip)\nZod 3\t12.47kb\nZod 4 (regular)\t5.36kb\nZod 4 (mini)\t1.88kb\n\nLearn more on the dedicated zod/mini docs page. Complete API details are mixed into existing documentation pages; code blocks contain separate tabs for \"Zod\" and \"Zod Mini\" wherever their APIs diverge.\n\nMetadata\n\nZod 4 introduces a new system for adding strongly-typed metadata to your schemas. Metadata isn't stored inside the schema itself; instead it's stored in a \"schema registry\" that associates a schema with some typed metadata. To create a registry with z.registry():\n\nimport * as z from \"zod\";\n \nconst myRegistry = z.registry<{ title: string; description: string }>();\n\nTo add schemas to your registry:\n\nconst emailSchema = z.string().email();\n \nmyRegistry.add(emailSchema, { title: \"Email address\", description: \"...\" });\nmyRegistry.get(emailSchema);\n// => { title: \"Email address\", ... }\n\nAlternatively, you can use the .register() method on a schema for convenience:\n\nemailSchema.register(myRegistry, { title: \"Email address\", description: \"...\" })\n// => returns emailSchema\nThe global registry\n\nZod also exports a global registry z.globalRegistry that accepts some common JSON Schema-compatible metadata:\n\nz.globalRegistry.add(z.string(), { \n  id: \"email_address\",\n  title: \"Email address\",\n  description: \"Provide your email\",\n  examples: [\"naomie@example.com\"],\n  extraKey: \"Additional properties are also allowed\"\n});\n.meta()\n\nTo conveniently add a schema to z.globalRegistry, use the .meta() method.\n\nz.string().meta({ \n  id: \"email_address\",\n  title: \"Email address\",\n  description: \"Provide your email\",\n  examples: [\"naomie@example.com\"],\n  // ...\n});\n\nFor compatibility with Zod 3, .describe() is still available, but .meta() is preferred.\n\nz.string().describe(\"An email address\");\n \n// equivalent to\nz.string().meta({ description: \"An email address\" });\nJSON Schema conversion\n\nZod 4 introduces first-party JSON Schema conversion via z.toJSONSchema().\n\nimport * as z from \"zod\";\n \nconst mySchema = z.object({name: z.string(), points: z.number()});\n \nz.toJSONSchema(mySchema);\n// => {\n//   type: \"object\",\n//   properties: {\n//     name: {type: \"string\"},\n//     points: {type: \"number\"},\n//   },\n//   required: [\"name\", \"points\"],\n// }\n\nAny metadata in z.globalRegistry is automatically included in the JSON Schema output.\n\nconst mySchema = z.object({\n  firstName: z.string().describe(\"Your first name\"),\n  lastName: z.string().meta({ title: \"last_name\" }),\n  age: z.number().meta({ examples: [12, 99] }),\n});\n \nz.toJSONSchema(mySchema);\n// => {\n//   type: 'object',\n//   properties: {\n//     firstName: { type: 'string', description: 'Your first name' },\n//     lastName: { type: 'string', title: 'last_name' },\n//     age: { type: 'number', examples: [ 12, 99 ] }\n//   },\n//   required: [ 'firstName', 'lastName', 'age' ]\n// }\n\nRefer to the JSON Schema docs for information on customizing the generated JSON Schema.\n\nRecursive objects\n\nThis was an unexpected one. After years of trying to crack this problem, I finally found a way to properly infer recursive object types in Zod. To define a recursive type:\n\nconst Category = z.object({\n  name: z.string(),\n  get subcategories(){\n    return z.array(Category)\n  }\n});\n \ntype Category = z.infer<typeof Category>;\n// { name: string; subcategories: Category[] }\n\nYou can also represent mutually recursive types:\n\nconst User = z.object({\n  email: z.email(),\n  get posts(){\n    return z.array(Post)\n  }\n});\n \nconst Post = z.object({\n  title: z.string(),\n  get author(){\n    return User\n  }\n});\n\nUnlike the Zod 3 pattern for recursive types, there's no type casting required. The resulting schemas are plain ZodObject instances and have the full set of methods available.\n\nPost.pick({ title: true })\nPost.partial();\nPost.extend({ publishDate: z.date() });\nFile schemas\n\nTo validate File instances:\n\nconst fileSchema = z.file();\n \nfileSchema.min(10_000); // minimum .size (bytes)\nfileSchema.max(1_000_000); // maximum .size (bytes)\nfileSchema.mime([\"image/png\"]); // MIME type\nInternationalization\n\nZod 4 introduces a new locales API for globally translating error messages into different languages.\n\nimport * as z from \"zod\";\n \n// configure English locale (default)\nz.config(z.locales.en());\n\nAt the time of this writing only the English locale is available; There will be a call for pull request from the community shortly; this section will be updated with a list of supported languages as they become available.\n\nError pretty-printing\n\nThe popularity of the zod-validation-error package demonstrates that there's significant demand for an official API for pretty-printing errors. If you are using that package currently, by all means continue using it.\n\nZod now implements a top-level z.prettifyError function for converting a ZodError to a user-friendly formatted string.\n\nconst myError = new z.ZodError([\n  {\n    code: 'unrecognized_keys',\n    keys: [ 'extraField' ],\n    path: [],\n    message: 'Unrecognized key: \"extraField\"'\n  },\n  {\n    expected: 'string',\n    code: 'invalid_type',\n    path: [ 'username' ],\n    message: 'Invalid input: expected string, received number'\n  },\n  {\n    origin: 'number',\n    code: 'too_small',\n    minimum: 0,\n    inclusive: true,\n    path: [ 'favoriteNumbers', 1 ],\n    message: 'Too small: expected number to be >=0'\n  }\n]);\n \nz.prettifyError(myError);\n\nThis returns the following pretty-printable multi-line string:\n\n✖ Unrecognized key: \"extraField\"\n✖ Invalid input: expected string, received number\n  → at username\n✖ Invalid input: expected number, received string\n  → at favoriteNumbers[1]\n\nCurrently the formatting isn't configurable; this may change in the future.\n\nTop-level string formats\n\nAll \"string formats\" (email, etc.) have been promoted to top-level functions on the z module. This is both more concise and more tree-shakable. The method equivalents (z.string().email(), etc.) are still available but have been deprecated. They'll be removed in the next major version.\n\nz.email();\nz.uuidv4();\nz.uuidv7();\nz.uuidv8();\nz.ipv4();\nz.ipv6();\nz.cidrv4();\nz.cidrv6();\nz.url();\nz.e164();\nz.base64();\nz.base64url();\nz.jwt();\nz.lowercase();\nz.iso.date();\nz.iso.datetime();\nz.iso.duration();\nz.iso.time();\nCustom email regex\n\nThe z.email() API now supports a custom regular expression. There is no one canonical email regex; different applications may choose to be more or less strict. For convenience Zod exports some common ones.\n\n// Zod's default email regex (Gmail rules)\n// see colinhacks.com/essays/reasonable-email-regex\nz.email(); // z.regexes.email\n \n// the regex used by browsers to validate input[type=email] fields\n// https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/email\nz.email({ pattern: z.regexes.html5Email });\n \n// the classic emailregex.com regex (RFC 5322)\nz.email({ pattern: z.regexes.rfc5322Email });\n \n// a loose regex that allows Unicode (good for intl emails)\nz.email({ pattern: z.regexes.unicodeEmail });\nTemplate literal types\n\nZod 4 implements z.templateLiteral(). Template literal types are perhaps the biggest feature of TypeScript's type system that wasn't previously representable.\n\nconst hello = z.templateLiteral([\"hello, \", z.string()]);\n// `hello, ${string}`\n \nconst cssUnits = z.enum([\"px\", \"em\", \"rem\", \"%\"]);\nconst css = z.templateLiteral([z.number(), cssUnits]);\n// `${number}px` | `${number}em` | `${number}rem` | `${number}%`\n \nconst email = z.templateLiteral([\n  z.string().min(1),\n  \"@\",\n  z.string().max(64),\n]);\n// `${string}@${string}` (the min/max refinements are enforced!)\n\nEvery Zod schema type that can be stringified stores an internal regex: strings, string formats like z.email(), numbers, boolean, bigint, enums, literals, undefined/optional, null/nullable, and other template literals. The z.templateLiteral constructor concatenates these into a super-regex, so things like string formats (z.email()) are properly enforced (but custom refinements are not!).\n\nRead the template literal docs for more info.\n\nNumber formats\n\nNew numeric \"formats\" have been added for representing fixed-width integer and float types. These return a ZodNumber instance with proper minimum/maximum constraints already added.\n\nz.int();      // [Number.MIN_SAFE_INTEGER, Number.MAX_SAFE_INTEGER],\nz.float32();  // [-3.4028234663852886e38, 3.4028234663852886e38]\nz.float64();  // [-1.7976931348623157e308, 1.7976931348623157e308]\nz.int32();    // [-2147483648, 2147483647]\nz.uint32();   // [0, 4294967295]\n\nSimilarly the following bigint numeric formats have also been added. These integer types exceed what can be safely represented by a number in JavaScript, so these return a ZodBigInt instance with the proper minimum/maximum constraints already added.\n\nz.int64();    // [-9223372036854775808n, 9223372036854775807n]\nz.uint64();   // [0n, 18446744073709551615n]\nStringbool\n\nThe existing z.coerce.boolean() API is very simple: falsy values (false, undefined, null, 0, \"\", NaN etc) become false, truthy values become true.\n\nThis is still a good API, and its behavior aligns with the other z.coerce APIs. But some users requested a more sophisticated \"env-style\" boolean coercion. To support this, Zod 4 introduces z.stringbool():\n\nconst strbool = z.stringbool();\n \nstrbool.parse(\"true\")         // => true\nstrbool.parse(\"1\")            // => true\nstrbool.parse(\"yes\")          // => true\nstrbool.parse(\"on\")           // => true\nstrbool.parse(\"y\")            // => true\nstrbool.parse(\"enabled\")      // => true\n \nstrbool.parse(\"false\");       // => false\nstrbool.parse(\"0\");           // => false\nstrbool.parse(\"no\");          // => false\nstrbool.parse(\"off\");         // => false\nstrbool.parse(\"n\");           // => false\nstrbool.parse(\"disabled\");    // => false\n \nstrbool.parse(/* anything else */); // ZodError<[{ code: \"invalid_value\" }]>\n\nTo customize the truthy and falsy values:\n\nz.stringbool({\n  truthy: [\"yes\", \"true\"],\n  falsy: [\"no\", \"false\"]\n})\n\nRefer to the z.stringbool() docs for more information.\n\nSimplified error customization\n\nThe majority of breaking changes in Zod 4 involve the error customization APIs. They were a bit of a mess in Zod 3; Zod 4 makes things significantly more elegant, to the point where I think it's worth highlighting here.\n\nLong story short, there is now a single, unified error parameter for customizing errors, replacing the following APIs:\n\nReplace message with error. (The message parameter is still supported but deprecated.)\n\n- z.string().min(5, { message: \"Too short.\" });\n+ z.string().min(5, { error: \"Too short.\" });\n\nReplace invalid_type_error and required_error with error (function syntax):\n\n// Zod 3\n- z.string({ \n-   required_error: \"This field is required\" \n-   invalid_type_error: \"Not a string\", \n- });\n \n// Zod 4 \n+ z.string({ error: (issue) => issue.input === undefined ? \n+  \"This field is required\" :\n+  \"Not a string\" \n+ });\n\nReplace errorMap with error (function syntax):\n\n// Zod 3 \n- z.string({\n-   errorMap: (issue, ctx) => {\n-     if (issue.code === \"too_small\") {\n-       return { message: `Value must be >${issue.minimum}` };\n-     }\n-     return { message: ctx.defaultError };\n-   },\n- });\n \n// Zod 4\n+ z.string({\n+   error: (issue) => {\n+     if (issue.code === \"too_small\") {\n+       return `Value must be >${issue.minimum}`\n+     }\n+   },\n+ });\nUpgraded z.discriminatedUnion()\n\nDiscriminated unions now support a number of schema types not previously supported, including unions and pipes:\n\nconst MyResult = z.discriminatedUnion(\"status\", [\n  // simple literal\n  z.object({ status: z.literal(\"aaa\"), data: z.string() }),\n  // union discriminator\n  z.object({ status: z.union([z.literal(\"bbb\"), z.literal(\"ccc\")]) }),\n  // pipe discriminator\n  z.object({ status: z.literal(\"fail\").transform(val => val.toUpperCase()) }),\n]);\n\nPerhaps most importantly, discriminated unions now compose—you can use one discriminated union as a member of another.\n\nconst BaseError = z.object({ status: z.literal(\"failed\"), message: z.string() });\n \nconst MyResult = z.discriminatedUnion(\"status\", [\n  z.object({ status: z.literal(\"success\"), data: z.string() }),\n  z.discriminatedUnion(\"code\", [\n    BaseError.extend({ code: z.literal(400) }),\n    BaseError.extend({ code: z.literal(401) }),\n    BaseError.extend({ code: z.literal(500) })\n  ])\n]);\nMultiple values in z.literal()\n\nThe z.literal() API now optionally supports multiple values.\n\nconst httpCodes = z.literal([ 200, 201, 202, 204, 206, 207, 208, 226 ]);\n \n// previously in Zod 3:\nconst httpCodes = z.union([\n  z.literal(200),\n  z.literal(201),\n  z.literal(202),\n  z.literal(204),\n  z.literal(206),\n  z.literal(207),\n  z.literal(208),\n  z.literal(226)\n]);\nRefinements live inside schemas\n\nIn Zod 3, they were stored in a ZodEffects class that wrapped the original schema. This was inconvenient, as it meant you couldn't interleave .refine() with other schema methods like .min().\n\nz.string()\n  .refine(val => val.includes(\"@\"))\n  .min(5);\n// ^ ❌ Property 'min' does not exist on type ZodEffects<ZodString, string, string>\n\nIn Zod 4, refinements are stored inside the schemas themselves, so the code above works as expected.\n\nz.string()\n  .refine(val => val.includes(\"@\"))\n  .min(5); // ✅\n.overwrite()\n\nThe .transform() method is extremely useful, but it has one major downside: the output type is no longer introspectable at runtime. The transform function is a black box that can return anything. This means (among other things) there's no sound way to convert the schema to JSON Schema.\n\nconst Squared = z.number().transform(val => val ** 2);\n// => ZodPipe<ZodNumber, ZodTransform>\n\nZod 4 introduces a new .overwrite() method for representing transforms that don't change the inferred type. Unlike .transform(), this method returns an instance of the original class. The overwrite function is stored as a refinement, so it doesn't (and can't) modify the inferred type.\n\nz.number().overwrite(val => val ** 2).max(100);\n// => ZodNumber\n\nThe existing .trim(), .toLowerCase() and .toUpperCase() methods have been reimplemented using .overwrite().\n\nAn extensible foundation: zod/v4/core\n\nWhile this will not be relevant to the majority of Zod users, it's worth highlighting. The addition of Zod Mini necessitated the creation of a shared sub-package zod/v4/core which contains the core functionality shared between Zod and Zod Mini.\n\nI was resistant to this at first, but now I see it as one of Zod 4's most important features. It lets Zod level up from a simple library to a fast validation \"substrate\" that can be sprinkled into other libraries.\n\nIf you're building a schema library, refer to the implementations of Zod and Zod Mini to see how to build on top of the foundation zod/v4/core provides. Don't hesitate to get in touch in GitHub discussions or via X/Bluesky for help or feedback.\n\nWrapping up\n\nI'm planning to write up a series of additional posts explaining the design process behind some major features like Zod Mini. I'll update this section as those get posted.\n\nFor library authors, there is now a dedicated For library authors guide that describes the best practices for building on top of Zod. It answers common questions about how to support Zod 3 & Zod 4 (including Mini) simultaneously.\n\npnpm upgrade zod@latest\n\nHappy parsing!\n— Colin McDonnell @colinhacks\n\nMigration guide\n\nComplete changelog and migration guide for upgrading from Zod 3 to Zod 4"
	},
	{
		"title": "Customizing errors | Zod",
		"url": "https://zod.dev/error-customization",
		"html": "Customizing errors\nCopy markdown\nEdit this page\n\nIn Zod, validation errors are surfaced as instances of the z.core.$ZodError class.\n\nThe ZodError class in the zod package is a subclass that implements some additional convenience methods.\n\nInstances of $ZodError contain an .issues array. Each issue contains a human-readable message and additional structured metadata about the issue.\n\nZod\nZod Mini\nimport * as z from \"zod\";\n \nconst result = z.string().safeParse(12); // { success: false, error: ZodError }\nresult.error.issues;\n// [\n//   {\n//     expected: 'string',\n//     code: 'invalid_type',\n//     path: [],\n//     message: 'Invalid input: expected string, received number'\n//   }\n// ]\n\nEvery issue contains a message property with a human-readable error message. Error messages can be customized in a number of ways.\n\nThe error param\n\nVirtually every Zod API accepts an optional error message.\n\nz.string(\"Not a string!\");\n\nThis custom error will show up as the message property of any validation issues that originate from this schema.\n\nz.string(\"Not a string!\").parse(12);\n// ❌ throws ZodError {\n//   issues: [\n//     {\n//       expected: 'string',\n//       code: 'invalid_type',\n//       path: [],\n//       message: 'Not a string!'   <-- 👀 custom error message\n//     }\n//   ]\n// }\n\nAll z functions and schema methods accept custom errors.\n\nZod\nZod Mini\nz.string(\"Bad!\");\nz.string().min(5, \"Too short!\");\nz.uuid(\"Bad UUID!\");\nz.iso.date(\"Bad date!\");\nz.array(z.string(), \"Not an array!\");\nz.array(z.string()).min(5, \"Too few items!\");\nz.set(z.string(), \"Bad set!\");\n\nIf you prefer, you can pass a params object with an error parameter instead.\n\nZod\nZod Mini\nz.string({ error: \"Bad!\" });\nz.string().min(5, { error: \"Too short!\" });\nz.uuid({ error: \"Bad UUID!\" });\nz.iso.date({ error: \"Bad date!\" });\nz.array(z.string(), { error: \"Bad array!\" });\nz.array(z.string()).min(5, { error: \"Too few items!\" });\nz.set(z.string(), { error: \"Bad set!\" });\n\nThe error param optionally accepts a function. An error customization function is known as an error map in Zod terminology. The error map will run at parse time if a validation error occurs.\n\nz.string({ error: ()=>`[${Date.now()}]: Validation failure.` });\n\nNote — In Zod v3, there were separate params for message (a string) and errorMap (a function). These have been unified in Zod 4 as error.\n\nThe error map receives a context object you can use to customize the error message based on the validation issue.\n\nz.string({\n  error: (iss) => iss.input === undefined ? \"Field is required.\" : \"Invalid input.\"\n});\n\nFor advanced cases, the iss object provides additional information you can use to customize the error.\n\nz.string({\n  error: (iss) => {\n    iss.code; // the issue code\n    iss.input; // the input data\n    iss.inst; // the schema/check that originated this issue\n    iss.path; // the path of the error\n  },\n});\n\nDepending on the API you are using, there may be additional properties available. Use TypeScript's autocomplete to explore the available properties.\n\nz.string().min(5, {\n  error: (iss) => {\n    // ...the same as above\n    iss.minimum; // the minimum value\n    iss.inclusive; // whether the minimum is inclusive\n    return `Password must have ${iss.minimum} characters or more`;\n  },\n});\n\nReturn undefined to avoid customizing the error message and fall back to the default message. (More specifically, Zod will yield control to the next error map in the precedence chain.) This is useful for selectively customizing certain error messages but not others.\n\nz.int64({\n  error: (issue) => {\n    // override too_big error message\n    if (issue.code === \"too_big\") {\n      return { message: `Value must be <${issue.maximum}` };\n    }\n \n    //  defer to default\n    return undefined;\n  },\n});\nPer-parse error customization\n\nTo customize errors on a per-parse basis, pass an error map into the parse method:\n\nconst schema = z.string();\n \nschema.parse(12, {\n  error: iss => \"per-parse custom error\"\n});\n\nThis has lower precedence than any schema-level custom messages.\n\nconst schema = z.string({ error: \"highest priority\" });\nconst result = schema.safeParse(12, {\n  error: (iss) => \"lower priority\",\n});\n \nresult.error.issues;\n// [{ message: \"highest priority\", ... }]\n\nThe iss object is a discriminated union of all possible issue types. Use the code property to discriminate between them.\n\nFor a breakdown of all Zod issue codes, see the zod/v4/core documentation.\n\nconst result = schema.safeParse(12, {\n  error: (iss) => {\n    if (iss.code === \"invalid_type\") {\n      return `invalid type, expected ${iss.expected}`;\n    }\n    if (iss.code === \"too_small\") {\n      return `minimum is ${iss.minimum}`;\n    }\n    // ...\n  }\n});\nInclude input in issues\n\nBy default, Zod does not include input data in issues. This is to prevent unintentional logging of potentially sensitive input data. To include the input data in each issue, use the reportInput flag:\n\nz.string().parse(12, {\n  reportInput: true\n})\n \n// ZodError: [\n//   {\n//     \"expected\": \"string\",\n//     \"code\": \"invalid_type\",\n//     \"input\": 12, // 👀\n//     \"path\": [],\n//     \"message\": \"Invalid input: expected string, received number\"\n//   }\n// ]\nGlobal error customization\n\nTo specify a global error map, use z.config() to set Zod's customError configuration setting:\n\nz.config({\n  customError: (iss) => {\n    return \"globally modified error\";\n  },\n});\n\nGlobal error messages have lower precedence than schema-level or per-parse error messages.\n\nThe iss object is a discriminated union of all possible issue types. Use the code property to discriminate between them.\n\nFor a breakdown of all Zod issue codes, see the zod/v4/core documentation.\n\nconst result = schema.safeParse(12, {\n  error: (iss) => {\n    if (iss.code === \"invalid_type\") {\n      return `invalid type, expected ${iss.expected}`;\n    }\n    if (iss.code === \"too_small\") {\n      return `minimum is ${iss.minimum}`;\n    }\n    // ...\n  }\n})\nInternationalization\n\nTo support internationalization of error message, Zod provides several built-in locales. These are exported from the zod/v4/core package.\n\nNote — The regular zod library automatically loads the en locale automatically. Zod Mini does not load any locale by default; instead all error messages default to Invalid input.\n\nZod\nZod Mini\nimport * as z from \"zod\";\nimport { en } from \"zod/locales\"\n \nz.config(en());\n\nTo lazily load a locale, consider dynamic imports:\n\nimport * as z from \"zod\";\n \nasync function loadLocale(locale: string) {\n  const { default: locale } = await import(`zod/v4/locales/${locale}.js`);\n  z.config(locale());\n};\n \nawait loadLocale(\"fr\");\n\nFor convenience, all locales are exported as z.locales from \"zod\". In some bundlers, this may not be tree-shakable.\n\nZod\nZod Mini\nimport * as z from \"zod\";\n \nz.config(z.locales.en());\nLocales\n\nThe following locales are available:\n\nar — Arabic\naz — Azerbaijani\nbe — Belarusian\nbg — Bulgarian\nca — Catalan\ncs — Czech\nda — Danish\nde — German\nen — English\neo — Esperanto\nes — Spanish\nfa — Farsi\nfi — Finnish\nfr — French\nfrCA — Canadian French\nhe — Hebrew\nhu — Hungarian\nid — Indonesian\nis — Icelandic\nit — Italian\nja — Japanese\nka — Georgian\nkm — Khmer\nko — Korean\nlt — Lithuanian\nmk — Macedonian\nms — Malay\nnl — Dutch\nno — Norwegian\nota — Türkî\nps — Pashto\npl — Polish\npt — Portuguese\nru — Russian\nsl — Slovenian\nsv — Swedish\nta — Tamil\nth — Thai\ntr — Türkçe\nuk — Ukrainian\nur — Urdu\nvi — Tiếng Việt\nzhCN — Simplified Chinese\nzhTW — Traditional Chinese\nyo — Yorùbá\nError precedence\n\nBelow is a quick reference for determining error precedence: if multiple error customizations have been defined, which one takes priority? From highest to lowest priority:\n\nSchema-level error — Any error message \"hard coded\" into a schema definition.\nz.string(\"Not a string!\");\nPer-parse error — A custom error map passed into the .parse() method.\nz.string().parse(12, {\n  error: (iss) => \"My custom error\"\n});\nGlobal error map — A custom error map passed into z.config().\nz.config({\n  customError: (iss) => \"My custom error\"\n});\nLocale error map — A custom error map passed into z.config().\nz.config(z.locales.en());\n\nDefining schemas\n\nComplete API reference for all Zod schema types, methods, and validation features\n\nFormatting errors\n\nUtilities for formatting and displaying Zod errors"
	},
	{
		"title": "Defining schemas | Zod",
		"url": "https://zod.dev/api",
		"html": "Defining schemas\nCopy markdown\nEdit this page\n\nTo validate data, you must first define a schema. Schemas represent types, from simple primitive values to complex nested objects and arrays.\n\nPrimitives\nimport * as z from \"zod\";\n \n// primitive types\nz.string();\nz.number();\nz.bigint();\nz.boolean();\nz.symbol();\nz.undefined();\nz.null();\nCoercion\n\nTo coerce input data to the appropriate type, use z.coerce instead:\n\nz.coerce.string();    // String(input)\nz.coerce.number();    // Number(input)\nz.coerce.boolean();   // Boolean(input)\nz.coerce.bigint();    // BigInt(input)\n\nThe coerced variant of these schemas attempts to convert the input value to the appropriate type.\n\nconst schema = z.coerce.string();\n \nschema.parse(\"tuna\");    // => \"tuna\"\nschema.parse(42);        // => \"42\"\nschema.parse(true);      // => \"true\"\nschema.parse(null);      // => \"null\"\n\nThe input type of these coerced schemas is unknown by default. To specify a more specific input type, pass a generic parameter:\n\nconst A = z.coerce.number();\ntype AInput = z.input<typeof A>; // => unknown\n \nconst B = z.coerce.number<number>();\ntype BInput = z.input<typeof B>; // => number\nHow coercion works in Zod\nCustomizing the input type\nLiterals\n\nLiteral schemas represent a literal type, like \"hello world\" or 5.\n\nconst tuna = z.literal(\"tuna\");\nconst twelve = z.literal(12);\nconst twobig = z.literal(2n);\nconst tru = z.literal(true);\n\nTo represent the JavaScript literals null and undefined:\n\nz.null();\nz.undefined();\nz.void(); // equivalent to z.undefined()\n\nTo allow multiple literal values:\n\nconst colors = z.literal([\"red\", \"green\", \"blue\"]);\n \ncolors.parse(\"green\"); // ✅\ncolors.parse(\"yellow\"); // ❌\n\nTo extract the set of allowed values from a literal schema:\n\nZod\nZod Mini\ncolors.values; // => Set<\"red\" | \"green\" | \"blue\">\nStrings\n\nZod provides a handful of built-in string validation and transform APIs. To perform some common string validations:\n\nZod\nZod Mini\nz.string().max(5);\nz.string().min(5);\nz.string().length(5);\nz.string().regex(/^[a-z]+$/);\nz.string().startsWith(\"aaa\");\nz.string().endsWith(\"zzz\");\nz.string().includes(\"---\");\nz.string().uppercase();\nz.string().lowercase();\n\nTo perform some simple string transforms:\n\nZod\nZod Mini\nz.string().trim(); // trim whitespace\nz.string().toLowerCase(); // toLowerCase\nz.string().toUpperCase(); // toUpperCase\nz.string().normalize(); // normalize unicode characters\nString formats\n\nTo validate against some common string formats:\n\nz.email();\nz.uuid();\nz.url();\nz.httpUrl();       // http or https URLs only\nz.hostname();\nz.emoji();         // validates a single emoji character\nz.base64();\nz.base64url();\nz.hex();\nz.jwt();\nz.nanoid();\nz.cuid();\nz.cuid2();\nz.ulid();\nz.ipv4();\nz.ipv6();\nz.cidrv4();        // ipv4 CIDR block\nz.cidrv6();        // ipv6 CIDR block\nz.hash(\"sha256\");  // or \"sha1\", \"sha384\", \"sha512\", \"md5\"\nz.iso.date();\nz.iso.time();\nz.iso.datetime();\nz.iso.duration();\nEmails\n\nTo validate email addresses:\n\nz.email();\n\nBy default, Zod uses a comparatively strict email regex designed to validate normal email addresses containing common characters. It's roughly equivalent to the rules enforced by Gmail. To learn more about this regex, refer to this post.\n\n/^(?!\\.)(?!.*\\.\\.)([a-z0-9_'+\\-\\.]*)[a-z0-9_+-]@([a-z0-9][a-z0-9\\-]*\\.)+[a-z]{2,}$/i\n\nTo customize the email validation behavior, you can pass a custom regular expression to the pattern param.\n\nz.email({ pattern: /your regex here/ });\n\nZod exports several useful regexes you could use.\n\n// Zod's default email regex\nz.email();\nz.email({ pattern: z.regexes.email }); // equivalent\n \n// the regex used by browsers to validate input[type=email] fields\n// https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/email\nz.email({ pattern: z.regexes.html5Email });\n \n// the classic emailregex.com regex (RFC 5322)\nz.email({ pattern: z.regexes.rfc5322Email });\n \n// a loose regex that allows Unicode (good for intl emails)\nz.email({ pattern: z.regexes.unicodeEmail });\nUUIDs\n\nTo validate UUIDs:\n\nz.uuid();\n\nTo specify a particular UUID version:\n\n// supports \"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\"\nz.uuid({ version: \"v4\" });\n \n// for convenience\nz.uuidv4();\nz.uuidv6();\nz.uuidv7();\n\nThe RFC 9562/4122 UUID spec requires the first two bits of byte 8 to be 10. Other UUID-like identifiers do not enforce this constraint. To validate any UUID-like identifier:\n\nz.guid();\nURLs\n\nTo validate any WHATWG-compatible URL:\n\nconst schema = z.url();\n \nschema.parse(\"https://example.com\"); // ✅\nschema.parse(\"http://localhost\"); // ✅\nschema.parse(\"mailto:noreply@zod.dev\"); // ✅\n\nAs you can see this is quite permissive. Internally this uses the new URL() constructor to validate inputs; this behavior may differ across platforms and runtimes but it's the mostly rigorous way to validate URIs/URLs on any given JS runtime/engine.\n\nTo validate the hostname against a specific regex:\n\nconst schema = z.url({ hostname: /^example\\.com$/ });\n \nschema.parse(\"https://example.com\"); // ✅\nschema.parse(\"https://zombo.com\"); // ❌\n\nTo validate the protocol against a specific regex, use the protocol param.\n\nconst schema = z.url({ protocol: /^https$/ });\n \nschema.parse(\"https://example.com\"); // ✅\nschema.parse(\"http://example.com\"); // ❌\n\nWeb URLs — In many cases, you'll want to validate Web URLs specifically. Here's the recommended schema for doing so:\n\nconst httpUrl = z.url({\n  protocol: /^https?$/,\n  hostname: z.regexes.domain\n});\n\nThis restricts the protocol to http/https and ensures the hostname is a valid domain name with the z.regexes.domain regular expression:\n\n/^([a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\\.)+[a-zA-Z]{2,}$/\n\nTo normalize URLs, use the normalize flag. This will overwrite the input value with the normalized URL returned by new URL().\n\nnew URL(\"HTTP://ExAmPle.com:80/./a/../b?X=1#f oo\").href\n// => \"http://example.com/b?X=1#f%20oo\"\nISO datetimes\n\nAs you may have noticed, Zod string includes a few date/time related validations. These validations are regular expression based, so they are not as strict as a full date/time library. However, they are very convenient for validating user input.\n\nThe z.iso.datetime() method enforces ISO 8601; by default, no timezone offsets are allowed:\n\nconst datetime = z.iso.datetime();\n \ndatetime.parse(\"2020-01-01T06:15:00Z\"); // ✅\ndatetime.parse(\"2020-01-01T06:15:00.123Z\"); // ✅\ndatetime.parse(\"2020-01-01T06:15:00.123456Z\"); // ✅ (arbitrary precision)\ndatetime.parse(\"2020-01-01T06:15:00+02:00\"); // ❌ (offsets not allowed)\ndatetime.parse(\"2020-01-01T06:15:00\"); // ❌ (local not allowed)\n\nTo allow timezone offsets:\n\nconst datetime = z.iso.datetime({ offset: true });\n \n// allows timezone offsets\ndatetime.parse(\"2020-01-01T06:15:00+02:00\"); // ✅\n \n// basic offsets not allowed\ndatetime.parse(\"2020-01-01T06:15:00+02\");    // ❌\ndatetime.parse(\"2020-01-01T06:15:00+0200\");  // ❌\n \n// Z is still supported\ndatetime.parse(\"2020-01-01T06:15:00Z\"); // ✅ \n\nTo allow unqualified (timezone-less) datetimes:\n\nconst schema = z.iso.datetime({ local: true });\nschema.parse(\"2020-01-01T06:15:01\"); // ✅\nschema.parse(\"2020-01-01T06:15\"); // ✅ seconds optional\n\nTo constrain the allowable time precision. By default, seconds are optional and arbitrary sub-second precision is allowed.\n\nconst a = z.iso.datetime();\na.parse(\"2020-01-01T06:15Z\"); // ✅\na.parse(\"2020-01-01T06:15:00Z\"); // ✅\na.parse(\"2020-01-01T06:15:00.123Z\"); // ✅\n \nconst b = z.iso.datetime({ precision: -1 }); // minute precision (no seconds)\nb.parse(\"2020-01-01T06:15Z\"); // ✅\nb.parse(\"2020-01-01T06:15:00Z\"); // ❌\nb.parse(\"2020-01-01T06:15:00.123Z\"); // ❌\n \nconst c = z.iso.datetime({ precision: 0 }); // second precision only\nc.parse(\"2020-01-01T06:15Z\"); // ❌\nc.parse(\"2020-01-01T06:15:00Z\"); // ✅\nc.parse(\"2020-01-01T06:15:00.123Z\"); // ❌\n \nconst d = z.iso.datetime({ precision: 3 }); // millisecond precision only\nd.parse(\"2020-01-01T06:15Z\"); // ❌\nd.parse(\"2020-01-01T06:15:00Z\"); // ❌\nd.parse(\"2020-01-01T06:15:00.123Z\"); // ✅\nISO dates\n\nThe z.iso.date() method validates strings in the format YYYY-MM-DD.\n\nconst date = z.iso.date();\n \ndate.parse(\"2020-01-01\"); // ✅\ndate.parse(\"2020-1-1\"); // ❌\ndate.parse(\"2020-01-32\"); // ❌\nISO times\n\nThe z.iso.time() method validates strings in the format HH:MM[:SS[.s+]]. By default seconds are optional, as are sub-second deciams.\n\nconst time = z.iso.time();\n \ntime.parse(\"03:15\"); // ✅\ntime.parse(\"03:15:00\"); // ✅\ntime.parse(\"03:15:00.9999999\"); // ✅ (arbitrary precision)\n\nNo offsets of any kind are allowed.\n\ntime.parse(\"03:15:00Z\"); // ❌ (no `Z` allowed)\ntime.parse(\"03:15:00+02:00\"); // ❌ (no offsets allowed)\n\nUse the precision parameter to constrain the allowable decimal precision.\n\nz.iso.time({ precision: -1 }); // HH:MM (minute precision)\nz.iso.time({ precision: 0 }); // HH:MM:SS (second precision)\nz.iso.time({ precision: 1 }); // HH:MM:SS.s (decisecond precision)\nz.iso.time({ precision: 2 }); // HH:MM:SS.ss (centisecond precision)\nz.iso.time({ precision: 3 }); // HH:MM:SS.sss (millisecond precision)\nIP addresses\nconst ipv4 = z.ipv4();\nipv4.parse(\"192.168.0.0\"); // ✅\n \nconst ipv6 = z.ipv6();\nipv6.parse(\"2001:db8:85a3::8a2e:370:7334\"); // ✅\nIP blocks (CIDR)\n\nValidate IP address ranges specified with CIDR notation.\n\nconst cidrv4 = z.string().cidrv4();\ncidrv4.parse(\"192.168.0.0/24\"); // ✅\n \nconst cidrv6 = z.string().cidrv6();\ncidrv6.parse(\"2001:db8::/32\"); // ✅\nJWTs\n\nValidate JSON Web Tokens.\n\nz.jwt();\nz.jwt({ alg: \"HS256\" });\nHashes\n\nTo validate cryptographic hash values:\n\nz.hash(\"md5\");\nz.hash(\"sha1\");\nz.hash(\"sha256\");\nz.hash(\"sha384\");\nz.hash(\"sha512\");\n\nBy default, z.hash() expects hexadecimal encoding, as is conventional. You can specify a different encoding with the enc parameter:\n\nz.hash(\"sha256\", { enc: \"hex\" });       // default\nz.hash(\"sha256\", { enc: \"base64\" });    // base64 encoding\nz.hash(\"sha256\", { enc: \"base64url\" }); // base64url encoding (no padding)\nExpected lengths and padding\nCustom formats\n\nTo define your own string formats:\n\nconst coolId = z.stringFormat(\"cool-id\", ()=>{\n  // arbitrary validation here\n  return val.length === 100 && val.startsWith(\"cool-\");\n});\n \n// a regex is also accepted\nz.stringFormat(\"cool-id\", /^cool-[a-z0-9]{95}$/);\n\nThis schema will produce \"invalid_format\" issues, which are more descriptive than the \"custom\" errors produced by refinements or z.custom().\n\nmyFormat.parse(\"invalid input!\");\n// ZodError: [\n//   {\n//     \"code\": \"invalid_format\",\n//     \"format\": \"cool-id\",\n//     \"path\": [],\n//     \"message\": \"Invalid cool-id\"\n//   }\n// ]\nTemplate literals\n\nNew — Introduced in zod@4.0.\n\nTo define a template literal schema:\n\nconst schema = z.templateLiteral([ \"hello, \", z.string(), \"!\" ]);\n// `hello, ${string}!`\n\nThe z.templateLiteral API can handle any number of string literals (e.g. \"hello\") and schemas. Any schema with an inferred type that's assignable to string | number | bigint | boolean | null | undefined can be passed.\n\nz.templateLiteral([ \"hi there\" ]);\n// `hi there`\n \nz.templateLiteral([ \"email: \", z.string() ]);\n// `email: ${string}`\n \nz.templateLiteral([ \"high\", z.literal(5) ]);\n// `high5`\n \nz.templateLiteral([ z.nullable(z.literal(\"grassy\")) ]);\n// `grassy` | `null`\n \nz.templateLiteral([ z.number(), z.enum([\"px\", \"em\", \"rem\"]) ]);\n// `${number}px` | `${number}em` | `${number}rem`\nNumbers\n\nUse z.number() to validate numbers. It allows any finite number.\n\nconst schema = z.number();\n \nschema.parse(3.14);      // ✅\nschema.parse(NaN);       // ❌\nschema.parse(Infinity);  // ❌\n\nZod implements a handful of number-specific validations:\n\nZod\nZod Mini\nz.number().gt(5);\nz.number().gte(5);                     // alias .min(5)\nz.number().lt(5);\nz.number().lte(5);                     // alias .max(5)\nz.number().positive();       \nz.number().nonnegative();    \nz.number().negative(); \nz.number().nonpositive(); \nz.number().multipleOf(5);              // alias .step(5)\n\nIf (for some reason) you want to validate NaN, use z.nan().\n\nz.nan().parse(NaN);              // ✅\nz.nan().parse(\"anything else\");  // ❌\nIntegers\n\nTo validate integers:\n\nz.int();     // restricts to safe integer range\nz.int32();   // restrict to int32 range\nBigInts\n\nTo validate BigInts:\n\nz.bigint();\n\nZod includes a handful of bigint-specific validations.\n\nZod\nZod Mini\nz.bigint().gt(5n);\nz.bigint().gte(5n);                    // alias `.min(5n)`\nz.bigint().lt(5n);\nz.bigint().lte(5n);                    // alias `.max(5n)`\nz.bigint().positive(); \nz.bigint().nonnegative(); \nz.bigint().negative(); \nz.bigint().nonpositive(); \nz.bigint().multipleOf(5n);             // alias `.step(5n)`\nBooleans\n\nTo validate boolean values:\n\nz.boolean().parse(true); // => true\nz.boolean().parse(false); // => false\nDates\n\nUse z.date() to validate Date instances.\n\nz.date().safeParse(new Date()); // success: true\nz.date().safeParse(\"2022-01-12T06:15:00.000Z\"); // success: false\n\nTo customize the error message:\n\nz.date({\n  error: issue => issue.input === undefined ? \"Required\" : \"Invalid date\"\n});\n\nZod provides a handful of date-specific validations.\n\nZod\nZod Mini\nz.date().min(new Date(\"1900-01-01\"), { error: \"Too old!\" });\nz.date().max(new Date(), { error: \"Too young!\" });\nEnums\n\nUse z.enum to validate inputs against a fixed set of allowable string values.\n\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\n \nFishEnum.parse(\"Salmon\"); // => \"Salmon\"\nFishEnum.parse(\"Swordfish\"); // => ❌\n\nCareful — If you declare your string array as a variable, Zod won't be able to properly infer the exact values of each element.\n\nconst fish = [\"Salmon\", \"Tuna\", \"Trout\"];\n \nconst FishEnum = z.enum(fish);\ntype FishEnum = z.infer<typeof FishEnum>; // string\n\nTo fix this, always pass the array directly into the z.enum() function, or use as const.\n\nconst fish = [\"Salmon\", \"Tuna\", \"Trout\"] as const;\n \nconst FishEnum = z.enum(fish);\ntype FishEnum = z.infer<typeof FishEnum>; // \"Salmon\" | \"Tuna\" | \"Trout\"\n\nEnum-like object literals ({ [key: string]: string | number }) are supported.\n\nconst Fish = {\n  Salmon: \"Salmon\",\n  Tuna: \"Tuna\"\n} as const\n \nconst FishEnum = z.enum(Fish)\nFishEnum.parse(\"Salmon\"); // => \"Salmon\"\nFishEnum.parse(\"Swordfish\"); // => ❌\n\nYou can also pass in an externally-declared TypeScript enum.\n\nZod 4 — This replaces the z.nativeEnum() API in Zod 3.\n\nNote that using TypeScript's enum keyword is not recommended.\n\nenum Fish {\n  Salmon = \"Salmon\",\n  Tuna = \"Tuna\",\n  Trout = \"Trout\",\n}\n \nconst FishEnum = z.enum(Fish);\n.enum\n\nTo extract the schema's values as an enum-like object:\n\nZod\nZod Mini\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\n \nFishEnum.enum;\n// => { Salmon: \"Salmon\", Tuna: \"Tuna\", Trout: \"Trout\" }\n.exclude()\n\nTo create a new enum schema, excluding certain values:\n\nZod\nZod Mini\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\nconst TunaOnly = FishEnum.exclude([\"Salmon\", \"Trout\"]);\n.extract()\n\nTo create a new enum schema, extracting certain values:\n\nZod\nZod Mini\nconst FishEnum = z.enum([\"Salmon\", \"Tuna\", \"Trout\"]);\nconst SalmonAndTroutOnly = FishEnum.extract([\"Salmon\", \"Trout\"]);\nStringbools\n\n💎 New in Zod 4\n\nIn some cases (e.g. parsing environment variables) it's valuable to parse certain string \"boolish\" values to a plain boolean value. To support this, Zod 4 introduces z.stringbool():\n\nconst strbool = z.stringbool();\n \nstrbool.parse(\"true\")         // => true\nstrbool.parse(\"1\")            // => true\nstrbool.parse(\"yes\")          // => true\nstrbool.parse(\"on\")           // => true\nstrbool.parse(\"y\")            // => true\nstrbool.parse(\"enabled\")      // => true\n \nstrbool.parse(\"false\");       // => false\nstrbool.parse(\"0\");           // => false\nstrbool.parse(\"no\");          // => false\nstrbool.parse(\"off\");         // => false\nstrbool.parse(\"n\");           // => false\nstrbool.parse(\"disabled\");    // => false\n \nstrbool.parse(/* anything else */); // ZodError<[{ code: \"invalid_value\" }]>\n\nTo customize the truthy and falsy values:\n\n// these are the defaults\nz.stringbool({\n  truthy: [\"true\", \"1\", \"yes\", \"on\", \"y\", \"enabled\"],\n  falsy: [\"false\", \"0\", \"no\", \"off\", \"n\", \"disabled\"],\n});\n\nBy default the schema is case-insensitive; all inputs are converted to lowercase before comparison to the truthy/falsy values. To make it case-sensitive:\n\nz.stringbool({\n  case: \"sensitive\"\n});\nOptionals\n\nTo make a schema optional (that is, to allow undefined inputs).\n\nZod\nZod Mini\nz.optional(z.literal(\"yoda\")); // or z.literal(\"yoda\").optional()\n\nThis returns a ZodOptional instance that wraps the original schema. To extract the inner schema:\n\nZod\nZod Mini\noptionalYoda.unwrap(); // ZodLiteral<\"yoda\">\nNullables\n\nTo make a schema nullable (that is, to allow null inputs).\n\nZod\nZod Mini\nz.nullable(z.literal(\"yoda\")); // or z.literal(\"yoda\").nullable()\n\nThis returns a ZodNullable instance that wraps the original schema. To extract the inner schema:\n\nZod\nZod Mini\nnullableYoda.unwrap(); // ZodLiteral<\"yoda\">\nNullish\n\nTo make a schema nullish (both optional and nullable):\n\nZod\nZod Mini\nconst nullishYoda = z.nullish(z.literal(\"yoda\"));\n\nRefer to the TypeScript manual for more about the concept of nullish.\n\nUnknown\n\nZod aims to mirror TypeScript's type system one-to-one. As such, Zod provides APIs to represent the following special types:\n\n// allows any values\nz.any(); // inferred type: `any`\nz.unknown(); // inferred type: `unknown`\nNever\n\nNo value will pass validation.\n\nz.never(); // inferred type: `never`\nObjects\n\nTo define an object type:\n\n  // all properties are required by default\n  const Person = z.object({\n    name: z.string(),\n    age: z.number(),\n  });\n \n  type Person = z.infer<typeof Person>;\n  // => { name: string; age: number; }\n\nBy default, all properties are required. To make certain properties optional:\n\nZod\nZod Mini\nconst Dog = z.object({\n  name: z.string(),\n  age: z.number().optional(),\n});\n \nDog.parse({ name: \"Yeller\" }); // ✅\n\nBy default, unrecognized keys are stripped from the parsed result:\n\nDog.parse({ name: \"Yeller\", extraKey: true });\n// => { name: \"Yeller\" }\nz.strictObject\n\nTo define a strict schema that throws an error when unknown keys are found:\n\nconst StrictDog = z.strictObject({\n  name: z.string(),\n});\n \nStrictDog.parse({ name: \"Yeller\", extraKey: true });\n// ❌ throws\nz.looseObject\n\nTo define a loose schema that allows unknown keys to pass through:\n\nconst LooseDog = z.looseObject({\n  name: z.string(),\n});\n \nLooseDog.parse({ name: \"Yeller\", extraKey: true });\n// => { name: \"Yeller\", extraKey: true }\n.catchall()\n\nTo define a catchall schema that will be used to validate any unrecognized keys:\n\nZod\nZod Mini\nconst DogWithStrings = z.object({\n  name: z.string(),\n  age: z.number().optional(),\n}).catchall(z.string());\n \nDogWithStrings.parse({ name: \"Yeller\", extraKey: \"extraValue\" }); // ✅\nDogWithStrings.parse({ name: \"Yeller\", extraKey: 42 }); // ❌\n.shape\n\nTo access the internal schemas:\n\nZod\nZod Mini\nDog.shape.name; // => string schema\nDog.shape.age; // => number schema\n.keyof()\n\nTo create a ZodEnum schema from the keys of an object schema:\n\nZod\nZod Mini\nconst keySchema = Dog.keyof();\n// => ZodEnum<[\"name\", \"age\"]>\n.extend()\n\nTo add additional fields to an object schema:\n\nZod\nZod Mini\nconst DogWithBreed = Dog.extend({\n  breed: z.string(),\n});\n\nThis API can be used to overwrite existing fields! Be careful with this power! If the two schemas share keys, B will override A.\n\nAlternative: spread syntax — You can alternatively avoid .extend() altogether by creating a new object schema entirely. This makes the strictness level of the resulting schema visually obvious.\n\nconst DogWithBreed = z.object({ // or z.strictObject() or z.looseObject()...\n  ...Dog.shape,\n  breed: z.string(),\n});\n\nYou can also use this to merge multiple objects in one go.\n\nconst DogWithBreed = z.object({\n  ...Animal.shape,\n  ...Pet.shape,\n  breed: z.string(),\n});\n\nThis approach has a few advantages:\n\nIt uses language-level features (spread syntax) instead of library-specific APIs\nThe same syntax works in Zod and Zod Mini\nIt's more tsc-efficient — the .extend() method can be expensive on large schemas, and due to a TypeScript limitation it gets quadratically more expensive when calls are chained\nIf you wish, you can change the strictness level of the resulting schema by using z.strictObject() or z.looseObject()\n.safeExtend()\n\nThe .safeExtend() method works similarly to .extend(), but it won't let you overwrite an existing properly with a non-assignable schema. In other words, the result of .safeExtend() will have an inferred type that extends the original (in the TypeScript sense).\n\nz.object({ a: z.string() }).safeExtend({ a: z.string().min(5) }); // ✅\nz.object({ a: z.string() }).safeExtend({ a: z.any() }); // ✅\nz.object({ a: z.string() }).safeExtend({ a: z.number() });\n//                                       ^  ❌ ZodNumber is not assignable \n\nUse .safeExtend() to extend schemas that contain refinements. (Regular .extend() will throw an error when used on schemas with refinements.)\n\nZod\nZod Mini\nconst Base = z.object({\n  a: z.string(),\n  b: z.string()\n}).refine(user => user.a === user.b);\n \n// Extended inherits the refinements of Base\nconst Extended = Base.safeExtend({\n  a: z.string().min(10)\n});\n.pick()\n\nInspired by TypeScript's built-in Pick and Omit utility types, Zod provides dedicated APIs for picking and omitting certain keys from an object schema.\n\nStarting from this initial schema:\n\nconst Recipe = z.object({\n  title: z.string(),\n  description: z.string().optional(),\n  ingredients: z.array(z.string()),\n});\n// { title: string; description?: string | undefined; ingredients: string[] }\n\nTo pick certain keys:\n\nZod\nZod Mini\nconst JustTheTitle = Recipe.pick({ title: true });\n.omit()\n\nTo omit certain keys:\n\nZod\nZod Mini\nconst RecipeNoId = Recipe.omit({ id: true });\n.partial()\n\nFor convenience, Zod provides a dedicated API for making some or all properties optional, inspired by the built-in TypeScript utility type Partial.\n\nTo make all fields optional:\n\nZod\nZod Mini\nconst PartialRecipe = Recipe.partial();\n// { title?: string | undefined; description?: string | undefined; ingredients?: string[] | undefined }\n\nTo make certain properties optional:\n\nZod\nZod Mini\nconst RecipeOptionalIngredients = Recipe.partial({\n  ingredients: true,\n});\n// { title: string; description?: string | undefined; ingredients?: string[] | undefined }\n.required()\n\nZod provides an API for making some or all properties required, inspired by TypeScript's Required utility type.\n\nTo make all properties required:\n\nZod\nZod Mini\nconst RequiredRecipe = Recipe.required();\n// { title: string; description: string; ingredients: string[] }\n\nTo make certain properties required:\n\nZod\nZod Mini\nconst RecipeRequiredDescription = Recipe.required({description: true});\n// { title: string; description: string; ingredients: string[] }\nRecursive objects\n\nTo define a self-referential type, use a getter on the key. This lets JavaScript resolve the cyclical schema at runtime.\n\nconst Category = z.object({\n  name: z.string(),\n  get subcategories(){\n    return z.array(Category)\n  }\n});\n \ntype Category = z.infer<typeof Category>;\n// { name: string; subcategories: Category[] }\n\nThough recursive schemas are supported, passing cyclical data into Zod will cause an infinite loop.\n\nYou can also represent mutually recursive types:\n\nconst User = z.object({\n  email: z.email(),\n  get posts(){\n    return z.array(Post)\n  }\n});\n \nconst Post = z.object({\n  title: z.string(),\n  get author(){\n    return User\n  }\n});\n\nAll object APIs (.pick(), .omit(), .required(), .partial(), etc.) work as you'd expect.\n\nCircularity errors\n\nDue to TypeScript limitations, recursive type inference can be finicky, and it only works in certain scenarios. Some more complicated types may trigger recursive type errors like this:\n\nconst Activity = z.object({\n  name: z.string(),\n  get subactivities() {\n    // ^ ❌ 'subactivities' implicitly has return type 'any' because it does not\n    // have a return type annotation and is referenced directly or indirectly\n    // in one of its return expressions.ts(7023)\n \n    return z.nullable(z.array(Activity));\n  },\n});\n\nIn these cases, you can resolve the error with a type annotation on the offending getter:\n\nconst Activity = z.object({\n  name: z.string(),\n  get subactivities(): z.ZodNullable<z.ZodArray<typeof Activity>> {\n    return z.nullable(z.array(Activity));\n  },\n});\nArrays\n\nTo define an array schema:\n\nZod\nZod Mini\nconst stringArray = z.array(z.string()); // or z.string().array()\n\nTo access the inner schema for an element of the array.\n\nZod\nZod Mini\nstringArray.unwrap(); // => string schema\n\nZod implements a number of array-specific validations:\n\nZod\nZod Mini\nz.array(z.string()).min(5); // must contain 5 or more items\nz.array(z.string()).max(5); // must contain 5 or fewer items\nz.array(z.string()).length(5); // must contain 5 items exactly\nTuples\n\nUnlike arrays, tuples are typically fixed-length arrays that specify different schemas for each index.\n\nconst MyTuple = z.tuple([\n  z.string(),\n  z.number(),\n  z.boolean()\n]);\n \ntype MyTuple = z.infer<typeof MyTuple>;\n// [string, number, boolean]\n\nTo add a variadic (\"rest\") argument:\n\nconst variadicTuple = z.tuple([z.string()], z.number());\n// => [string, ...number[]];\nUnions\n\nUnion types (A | B) represent a logical \"OR\". Zod union schemas will check the input against each option in order. The first value that validates successfully is returned.\n\nconst stringOrNumber = z.union([z.string(), z.number()]);\n// string | number\n \nstringOrNumber.parse(\"foo\"); // passes\nstringOrNumber.parse(14); // passes\n\nTo extract the internal option schemas:\n\nZod\nZod Mini\nstringOrNumber.options; // [ZodString, ZodNumber]\nDiscriminated unions\n\nA discriminated union is a special kind of union in which a) all the options are object schemas that b) share a particular key (the \"discriminator\"). Based on the value of the discriminator key, TypeScript is able to \"narrow\" the type signature as you'd expect.\n\ntype MyResult =\n  | { status: \"success\"; data: string }\n  | { status: \"failed\"; error: string };\n \nfunction handleResult(result: MyResult){\n  if(result.status === \"success\"){\n    result.data; // string\n  } else {\n    result.error; // string\n  }\n}\n\nYou could represent it with a regular z.union(). But regular unions are naive—they check the input against each option in order and return the first one that passes. This can be slow for large unions.\n\nSo Zod provides a z.discriminatedUnion() API that uses a discriminator key to make parsing more efficient.\n\nconst MyResult = z.discriminatedUnion(\"status\", [\n  z.object({ status: z.literal(\"success\"), data: z.string() }),\n  z.object({ status: z.literal(\"failed\"), error: z.string() }),\n]);\n\nEach option should be an object schema whose discriminator prop (status in the example above) corresponds to some literal value or set of values, usually z.enum(), z.literal(), z.null(), or z.undefined().\n\nNesting discriminated unions\nIntersections\n\nIntersection types (A & B) represent a logical \"AND\".\n\nconst a = z.union([z.number(), z.string()]);\nconst b = z.union([z.number(), z.boolean()]);\nconst c = z.intersection(a, b);\n \ntype c = z.infer<typeof c>; // => number\n\nThis can be useful for intersecting two object types.\n\nconst Person = z.object({ name: z.string() });\ntype Person = z.infer<typeof Person>;\n \nconst Employee = z.object({ role: z.string() });\ntype Employee = z.infer<typeof Employee>;\n \nconst EmployedPerson = z.intersection(Person, Employee);\ntype EmployedPerson = z.infer<typeof EmployedPerson>;\n// Person & Employee\n\nWhen merging object schemas, prefer A.extend(B) over intersections. Using .extend() will give you a new object schema, whereas z.intersection(A, B) returns a ZodIntersection instance which lacks common object methods like pick and omit.\n\nRecords\n\nRecord schemas are used to validate types such as Record<string, string>.\n\nconst IdCache = z.record(z.string(), z.string());\ntype IdCache = z.infer<typeof IdCache>; // Record<string, string>\n \nIdCache.parse({\n  carlotta: \"77d2586b-9e8e-4ecf-8b21-ea7e0530eadd\",\n  jimmie: \"77d2586b-9e8e-4ecf-8b21-ea7e0530eadd\",\n});\n\nThe key schema can be any Zod schema that is assignable to string | number | symbol.\n\nconst Keys = z.union([z.string(), z.number(), z.symbol()]);\nconst AnyObject = z.record(Keys, z.unknown());\n// Record<string | number | symbol, unknown>\n\nTo create an object schemas containing keys defined by an enum:\n\nconst Keys = z.enum([\"id\", \"name\", \"email\"]);\nconst Person = z.record(Keys, z.string());\n// { id: string; name: string; email: string }\n\nZod 4 — In Zod 4, if you pass a z.enum as the first argument to z.record(), Zod will exhaustively check that all enum values exist in the input as keys. This behavior agrees with TypeScript:\n\ntype MyRecord = Record<\"a\" | \"b\", string>;\nconst myRecord: MyRecord = { a: \"foo\", b: \"bar\" }; // ✅\nconst myRecord: MyRecord = { a: \"foo\" }; // ❌ missing required key `b`\n\nIn Zod 3, exhaustiveness was not checked. To replicate the old behavior, use z.partialRecord().\n\nIf you want a partial record type, use z.partialRecord(). This skips the special exhaustiveness checks Zod normally runs with z.enum() and z.literal() key schemas.\n\nconst Keys = z.enum([\"id\", \"name\", \"email\"]).or(z.never()); \nconst Person = z.partialRecord(Keys, z.string());\n// { id?: string; name?: string; email?: string }\nA note on numeric keys\nMaps\nconst StringNumberMap = z.map(z.string(), z.number());\ntype StringNumberMap = z.infer<typeof StringNumberMap>; // Map<string, number>\n \nconst myMap: StringNumberMap = new Map();\nmyMap.set(\"one\", 1);\nmyMap.set(\"two\", 2);\n \nStringNumberMap.parse(myMap);\nSets\nconst NumberSet = z.set(z.number());\ntype NumberSet = z.infer<typeof NumberSet>; // Set<number>\n \nconst mySet: NumberSet = new Set();\nmySet.add(1);\nmySet.add(2);\nNumberSet.parse(mySet);\n\nSet schemas can be further constrained with the following utility methods.\n\nZod\nZod Mini\nz.set(z.string()).min(5); // must contain 5 or more items\nz.set(z.string()).max(5); // must contain 5 or fewer items\nz.set(z.string()).size(5); // must contain 5 items exactly\nFiles\n\nTo validate File instances:\n\nZod\nZod Mini\nconst fileSchema = z.file();\n \nfileSchema.min(10_000); // minimum .size (bytes)\nfileSchema.max(1_000_000); // maximum .size (bytes)\nfileSchema.mime(\"image/png\"); // MIME type\nfileSchema.mime([\"image/png\", \"image/jpeg\"]); // multiple MIME types\nPromises\n\nDeprecated — z.promise() is deprecated in Zod 4. There are vanishingly few valid uses cases for a Promise schema. If you suspect a value might be a Promise, simply await it before parsing it with Zod.\n\nSee z.promise() documentation\nInstanceof\n\nYou can use z.instanceof to check that the input is an instance of a class. This is useful to validate inputs against classes that are exported from third-party libraries.\n\nclass Test {\n  name: string;\n}\n \nconst TestSchema = z.instanceof(Test);\n \nTestSchema.parse(new Test()); // ✅\nTestSchema.parse(\"whatever\"); // ❌\nProperty\n\nTo validate a particular property of a class instance against a Zod schema:\n\nconst blobSchema = z.instanceof(URL).check(\n  z.property(\"protocol\", z.literal(\"https:\" as string, \"Only HTTPS allowed\"))\n);\n \nblobSchema.parse(new URL(\"https://example.com\")); // ✅\nblobSchema.parse(new URL(\"http://example.com\")); // ❌\n\nThe z.property() API works with any data type (but it's most useful when used in conjunction with z.instanceof()).\n\nconst blobSchema = z.string().check(\n  z.property(\"length\", z.number().min(10))\n);\n \nblobSchema.parse(\"hello there!\"); // ✅\nblobSchema.parse(\"hello.\"); // ❌\nRefinements\n\nEvery Zod schema stores an array of refinements. Refinements are a way to perform custom validation that Zod doesn't provide a native API for.\n\n.refine()\nZod\nZod Mini\nconst myString = z.string().refine((val) => val.length <= 255);\n\nRefinement functions should never throw. Instead they should return a falsy value to signal failure. Thrown errors are not caught by Zod.\n\nerror\n\nTo customize the error message:\n\nZod\nZod Mini\nconst myString = z.string().refine((val) => val.length > 8, { \n  error: \"Too short!\" \n});\nabort\n\nBy default, validation issues from checks are considered continuable; that is, Zod will execute all checks in sequence, even if one of them causes a validation error. This is usually desirable, as it means Zod can surface as many errors as possible in one go.\n\nZod\nZod Mini\nconst myString = z.string()\n  .refine((val) => val.length > 8, { error: \"Too short!\" })\n  .refine((val) => val === val.toLowerCase(), { error: \"Must be lowercase\" });\n  \n \nconst result = myString.safeParse(\"OH NO\");\nresult.error?.issues;\n/* [\n  { \"code\": \"custom\", \"message\": \"Too short!\" },\n  { \"code\": \"custom\", \"message\": \"Must be lowercase\" }\n] */\n\nTo mark a particular refinement as non-continuable, use the abort parameter. Validation will terminate if the check fails.\n\nZod\nZod Mini\nconst myString = z.string()\n  .refine((val) => val.length > 8, { error: \"Too short!\", abort: true })\n  .refine((val) => val === val.toLowerCase(), { error: \"Must be lowercase\", abort: true });\n \n \nconst result = myString.safeParse(\"OH NO\");\nresult.error?.issues;\n// => [{ \"code\": \"custom\", \"message\": \"Too short!\" }]\npath\n\nTo customize the error path, use the path parameter. This is typically only useful in the context of object schemas.\n\nZod\nZod Mini\nconst passwordForm = z\n  .object({\n    password: z.string(),\n    confirm: z.string(),\n  })\n  .refine((data) => data.password === data.confirm, {\n    message: \"Passwords don't match\",\n    path: [\"confirm\"], // path of error\n  });\n\nThis will set the path parameter in the associated issue:\n\nZod\nZod Mini\nconst result = passwordForm.safeParse({ password: \"asdf\", confirm: \"qwer\" });\nresult.error.issues;\n/* [{\n  \"code\": \"custom\",\n  \"path\": [ \"confirm\" ],\n  \"message\": \"Passwords don't match\"\n}] */\n\nTo define an asynchronous refinement, just pass an async function:\n\nconst userId = z.string().refine(async (id) => {\n  // verify that ID exists in database\n  return true;\n});\n\nIf you use async refinements, you must use the .parseAsync method to parse data! Otherwise Zod will throw an error.\n\nZod\nZod Mini\nconst result = await userId.parseAsync(\"abc123\");\nwhen\n\nNote — This is a power user feature and can absolutely be abused in ways that will increase the probability of uncaught errors originating from inside your refinements.\n\nBy default, refinements don't run if any non-continuable issues have already been encountered. Zod is careful to ensure the type signature of the value is correct before passing it into any refinement functions.\n\nconst schema = z.string().refine((val) => {\n  return val.length > 8\n});\n \nschema.parse(1234); // invalid_type: refinement won't be executed\n\nIn some cases, you want finer control over when refinements run. For instance consider this \"password confirm\" check:\n\nZod\nZod Mini\nconst schema = z\n  .object({\n    password: z.string().min(8),\n    confirmPassword: z.string(),\n    anotherField: z.string(),\n  })\n  .refine((data) => data.password === data.confirmPassword, {\n    message: \"Passwords do not match\",\n    path: [\"confirmPassword\"],\n  });\n \nschema.parse({\n  password: \"asdf\",\n  confirmPassword: \"asdf\",\n  anotherField: 1234 // ❌ this error will prevent the password check from running\n});\n\nAn error on anotherField will prevent the password confirmation check from executing, even though the check doesn't depend on anotherField. To control when a refinement will run, use the when parameter:\n\nZod\nZod Mini\nconst schema = z\n  .object({\n    password: z.string().min(8),\n    confirmPassword: z.string(),\n    anotherField: z.string(),\n  })\n  .refine((data) => data.password === data.confirmPassword, {\n    message: \"Passwords do not match\",\n    path: [\"confirmPassword\"],\n \n    // run if password & confirmPassword are valid\n    when(payload) { \n      return schema \n        .pick({ password: true, confirmPassword: true }) \n        .safeParse(payload.value).success; \n    },  \n  });\n \nschema.parse({\n  password: \"asdf\",\n  confirmPassword: \"asdf\",\n  anotherField: 1234 // ❌ this error will not prevent the password check from running\n});\n.superRefine()\n\nThe regular .refine API only generates a single issue with a \"custom\" error code, but .superRefine() makes it possible to create multiple issues using any of Zod's internal issue types.\n\nZod\nZod Mini\nconst UniqueStringArray = z.array(z.string()).superRefine((val, ctx) => {\n  if (val.length > 3) {\n    ctx.addIssue({\n      code: \"too_big\",\n      maximum: 3,\n      origin: \"array\",\n      inclusive: true,\n      message: \"Too many items 😡\",\n      input: val,\n    });\n  }\n \n  if (val.length !== new Set(val).size) {\n    ctx.addIssue({\n      code: \"custom\",\n      message: `No duplicates allowed.`,\n      input: val,\n    });\n  }\n});\n \n.check()\n\nNote — The .check() API is a more low-level API that's generally more complex than .superRefine(). It can be faster in performance-sensitive code paths, but it's also more verbose.\n\nView example\nCodecs\n\nNew — Introduced in Zod 4.1. Refer to the dedicated Codecs page for more information.\n\nCodecs are a special kind of schema that implement bidirectional transformations between two other schemas.\n\nconst stringToDate = z.codec(\n  z.iso.datetime(),  // input schema: ISO date string\n  z.date(),          // output schema: Date object\n  {\n    decode: (isoString) => new Date(isoString), // ISO string → Date\n    encode: (date) => date.toISOString(),       // Date → ISO string\n  }\n);\n\nA regular .parse() operations performs the forward transform. It calls the codec's decode function.\n\nstringToDate.parse(\"2024-01-15T10:30:00.000Z\"); // => Date\n\nYou can alternatively use the top-level z.decode() function. Unlike .parse() (which accepts unknown input), z.decode() expects a strongly-typed input (string in this example).\n\nz.decode(stringToDate, \"2024-01-15T10:30:00.000Z\"); // => Date\n\nTo perform the reverse transform, use the inverse: z.encode().\n\nz.encode(stringToDate, new Date(\"2024-01-15\")); // => \"2024-01-15T00:00:00.000Z\"\n\nRefer to the dedicated Codecs page for more information. That page contains implementations for commonly-needed codecs that you can copy/paste into your project:\n\nstringToNumber\nstringToInt\nstringToBigInt\nnumberToBigInt\nisoDatetimeToDate\nepochSecondsToDate\nepochMillisToDate\njsonCodec\nutf8ToBytes\nbytesToUtf8\nbase64ToBytes\nbase64urlToBytes\nhexToBytes\nstringToURL\nstringToHttpURL\nuriComponent\nstringToBoolean\nPipes\n\nSchemas can be chained together into \"pipes\". Pipes are primarily useful when used in conjunction with Transforms.\n\nZod\nZod Mini\nconst stringToLength = z.string().pipe(z.transform(val => val.length));\n \nstringToLength.parse(\"hello\"); // => 5\nTransforms\n\nNote — For bi-directional transforms, use codecs.\n\nTransforms are a special kind of schema that perform a unidirectional transformation. Instead of validating input, they accept anything and perform some transformation on the data. To define a transform:\n\nZod\nZod Mini\nconst castToString = z.transform((val) => String(val));\n \ncastToString.parse(\"asdf\"); // => \"asdf\"\ncastToString.parse(123); // => \"123\"\ncastToString.parse(true); // => \"true\"\n\nRefinement functions should never throw. Thrown errors are not caught by Zod.\n\nTo perform validation logic inside a transform, use ctx. To report a validation issue, push a new issue onto ctx.issues (similar to the .check() API).\n\nconst coercedInt = z.transform((val, ctx) => {\n  try {\n    const parsed = Number.parseInt(String(val));\n    return parsed;\n  } catch (e) {\n    ctx.issues.push({\n      code: \"custom\",\n      message: \"Not a number\",\n      input: val,\n    });\n \n    // this is a special constant with type `never`\n    // returning it lets you exit the transform without impacting the inferred return type\n    return z.NEVER;\n  }\n});\n\nMost commonly, transforms are used in conjunction with Pipes. This combination is useful for performing some initial validation, then transforming the parsed data into another form.\n\nZod\nZod Mini\nconst stringToLength = z.string().pipe(z.transform(val => val.length));\n \nstringToLength.parse(\"hello\"); // => 5\n.transform()\n\nPiping some schema into a transform is a common pattern, so Zod provides a convenience .transform() method.\n\nZod\nZod Mini\nconst stringToLength = z.string().transform(val => val.length); \n\nTransforms can also be async:\n\nZod\nZod Mini\nconst idToUser = z\n  .string()\n  .transform(async (id) => {\n    // fetch user from database\n    return db.getUserById(id); \n  });\n \nconst user = await idToUser.parseAsync(\"abc123\");\n\nIf you use async transforms, you must use a .parseAsync or .safeParseAsync when parsing data! Otherwise Zod will throw an error.\n\n.preprocess()\n\nPiping a transform into another schema is another common pattern, so Zod provides a convenience z.preprocess() function.\n\nconst coercedInt = z.preprocess((val) => {\n  if (typeof val === \"string\") {\n    return Number.parseInt(val);\n  }\n  return val;\n}, z.int());\nDefaults\n\nTo set a default value for a schema:\n\nZod\nZod Mini\nconst defaultTuna = z.string().default(\"tuna\");\n \ndefaultTuna.parse(undefined); // => \"tuna\"\n\nAlternatively, you can pass a function which will be re-executed whenever a default value needs to be generated:\n\nZod\nZod Mini\nconst randomDefault = z.number().default(Math.random);\n \nrandomDefault.parse(undefined);    // => 0.4413456736055323\nrandomDefault.parse(undefined);    // => 0.1871840107401901\nrandomDefault.parse(undefined);    // => 0.7223408162401552\nPrefaults\n\nIn Zod, setting a default value will short-circuit the parsing process. If the input is undefined, the default value is eagerly returned. As such, the default value must be assignable to the output type of the schema.\n\nconst schema = z.string().transform(val => val.length).default(0);\nschema.parse(undefined); // => 0\n\nSometimes, it's useful to define a prefault (\"pre-parse default\") value. If the input is undefined, the prefault value will be parsed instead. The parsing process is not short circuited. As such, the prefault value must be assignable to the input type of the schema.\n\nz.string().transform(val => val.length).prefault(\"tuna\");\nschema.parse(undefined); // => 4\n\nThis is also useful if you want to pass some input value through some mutating refinements.\n\nconst a = z.string().trim().toUpperCase().prefault(\"  tuna  \");\na.parse(undefined); // => \"TUNA\"\n \nconst b = z.string().trim().toUpperCase().default(\"  tuna  \");\nb.parse(undefined); // => \"  tuna  \"\nCatch\n\nUse .catch() to define a fallback value to be returned in the event of a validation error:\n\nZod\nZod Mini\nconst numberWithCatch = z.number().catch(42);\n \nnumberWithCatch.parse(5); // => 5\nnumberWithCatch.parse(\"tuna\"); // => 42\n\nAlternatively, you can pass a function which will be re-executed whenever a catch value needs to be generated.\n\nZod\nZod Mini\nconst numberWithRandomCatch = z.number().catch((ctx) => {\n  ctx.error; // the caught ZodError\n  return Math.random();\n});\n \nnumberWithRandomCatch.parse(\"sup\"); // => 0.4413456736055323\nnumberWithRandomCatch.parse(\"sup\"); // => 0.1871840107401901\nnumberWithRandomCatch.parse(\"sup\"); // => 0.7223408162401552\nBranded types\n\nTypeScript's type system is structural, meaning that two types that are structurally equivalent are considered the same.\n\ntype Cat = { name: string };\ntype Dog = { name: string };\n \nconst pluto: Dog = { name: \"pluto\" };\nconst simba: Cat = pluto; // works fine\n\nIn some cases, it can be desirable to simulate nominal typing inside TypeScript. This can be achieved with branded types (also known as \"opaque types\").\n\nconst Cat = z.object({ name: z.string() }).brand<\"Cat\">();\nconst Dog = z.object({ name: z.string() }).brand<\"Dog\">();\n \ntype Cat = z.infer<typeof Cat>; // { name: string } & z.$brand<\"Cat\">\ntype Dog = z.infer<typeof Dog>; // { name: string } & z.$brand<\"Dog\">\n \nconst pluto = Dog.parse({ name: \"pluto\" });\nconst simba: Cat = pluto; // ❌ not allowed\n\nUnder the hood, this works by attaching a \"brand\" to the schema's inferred type.\n\nconst Cat = z.object({ name: z.string() }).brand<\"Cat\">();\ntype Cat = z.infer<typeof Cat>; // { name: string } & z.$brand<\"Cat\">\n\nWith this brand, any plain (unbranded) data structures are no longer assignable to the inferred type. You have to parse some data with the schema to get branded data.\n\nNote that branded types do not affect the runtime result of .parse. It is a static-only construct.\n\nReadonly\n\nTo mark a schema as readonly:\n\nZod\nZod Mini\nconst ReadonlyUser = z.object({ name: z.string() }).readonly();\ntype ReadonlyUser = z.infer<typeof ReadonlyUser>;\n// Readonly<{ name: string }>\n\nThe inferred type of the new schemas will be marked as readonly. Note that in TypeScript, this only affects objects, arrays, tuples, Set, and Map:\n\nZod\nZod Mini\nz.object({ name: z.string() }).readonly(); // { readonly name: string }\nz.array(z.string()).readonly(); // readonly string[]\nz.tuple([z.string(), z.number()]).readonly(); // readonly [string, number]\nz.map(z.string(), z.date()).readonly(); // ReadonlyMap<string, Date>\nz.set(z.string()).readonly(); // ReadonlySet<string>\n\nInputs will be parsed like normal, then the result will be frozen with Object.freeze() to prevent modifications.\n\nZod\nZod Mini\nconst result = ReadonlyUser.parse({ name: \"fido\" });\nresult.name = \"simba\"; // throws TypeError\nJSON\n\nTo validate any JSON-encodable value:\n\nconst jsonSchema = z.json();\n\nThis is a convenience API that returns the following union schema:\n\nconst jsonSchema = z.lazy(() => {\n  return z.union([\n    z.string(params), \n    z.number(), \n    z.boolean(), \n    z.null(), \n    z.array(jsonSchema), \n    z.record(z.string(), jsonSchema)\n  ]);\n});\nFunctions\n\nZod provides a z.function() utility for defining Zod-validated functions. This way, you can avoid intermixing validation code with your business logic.\n\nconst MyFunction = z.function({\n  input: [z.string()], // parameters (must be an array or a ZodTuple)\n  output: z.number()  // return type\n});\n \ntype MyFunction = z.infer<typeof MyFunction>;\n// (input: string) => number\n\nFunction schemas have an .implement() method which accepts a function and returns a new function that automatically validates its inputs and outputs.\n\nconst computeTrimmedLength = MyFunction.implement((input) => {\n  // TypeScript knows input is a string!\n  return input.trim().length;\n});\n \ncomputeTrimmedLength(\"sandwich\"); // => 8\ncomputeTrimmedLength(\" asdf \"); // => 4\n\nThis function will throw a ZodError if the input is invalid:\n\ncomputeTrimmedLength(42); // throws ZodError\n\nIf you only care about validating inputs, you can omit the output field.\n\nconst MyFunction = z.function({\n  input: [z.string()], // parameters (must be an array or a ZodTuple)\n});\n \nconst computeTrimmedLength = MyFunction.implement((input) => input.trim.length);\n\nUse the .implementAsync() method to create an async function.\n\nconst computeTrimmedLengthAsync = MyFunction.implementAsync(\n  async (input) => input.trim().length\n);\n \ncomputeTrimmedLengthAsync(\"sandwich\"); // => Promise<8>\nCustom\n\nYou can create a Zod schema for any TypeScript type by using z.custom(). This is useful for creating schemas for types that are not supported by Zod out of the box, such as template string literals.\n\nconst px = z.custom<`${number}px`>((val) => {\n  return typeof val === \"string\" ? /^\\d+px$/.test(val) : false;\n});\n \ntype px = z.infer<typeof px>; // `${number}px`\n \npx.parse(\"42px\"); // \"42px\"\npx.parse(\"42vw\"); // throws;\n\nIf you don't provide a validation function, Zod will allow any value. This can be dangerous!\n\nz.custom<{ arg: string }>(); // performs no validation\n\nYou can customize the error message and other options by passing a second argument. This parameter works the same way as the params parameter of .refine.\n\nz.custom<...>((val) => ..., \"custom error message\");\n\nBasic usage\n\nBasic usage guide covering schema definition, parsing data, error handling, and type inference\n\nCustomizing errors\n\nGuide to customizing validation error messages and error handling patterns"
	},
	{
		"title": "Formatting errors | Zod",
		"url": "https://zod.dev/error-formatting",
		"html": "Formatting errors\nCopy markdown\nEdit this page\n\nZod emphasizes completeness and correctness in its error reporting. In many cases, it's helpful to convert the $ZodError to a more useful format. Zod provides some utilities for this.\n\nConsider this simple object schema.\n\nimport * as z from \"zod\";\n \nconst schema = z.strictObject({\n  username: z.string(),\n  favoriteNumbers: z.array(z.number()),\n});\n\nAttempting to parse this invalid data results in an error containing three issues.\n\nconst result = schema.safeParse({\n  username: 1234,\n  favoriteNumbers: [1234, \"4567\"],\n  extraKey: 1234,\n});\n \nresult.error!.issues;\n[\n  {\n    expected: 'string',\n    code: 'invalid_type',\n    path: [ 'username' ],\n    message: 'Invalid input: expected string, received number'\n  },\n  {\n    expected: 'number',\n    code: 'invalid_type',\n    path: [ 'favoriteNumbers', 1 ],\n    message: 'Invalid input: expected number, received string'\n  },\n  {\n    code: 'unrecognized_keys',\n    keys: [ 'extraKey' ],\n    path: [],\n    message: 'Unrecognized key: \"extraKey\"'\n  }\n];\nz.treeifyError()\n\nTo convert (\"treeify\") this error into a nested object, use z.treeifyError().\n\nconst tree = z.treeifyError(result.error);\n \n// =>\n{\n  errors: [ 'Unrecognized key: \"extraKey\"' ],\n  properties: {\n    username: { errors: [ 'Invalid input: expected string, received number' ] },\n    favoriteNumbers: {\n      errors: [],\n      items: [\n        undefined,\n        {\n          errors: [ 'Invalid input: expected number, received string' ]\n        }\n      ]\n    }\n  }\n}\n\nThe result is a nested structure that mirrors the schema itself. You can easily access the errors that occurred at a particular path. The errors field contains the error messages at a given path, and the special properties properties and items let you traverse deeper into the tree.\n\ntree.properties?.username?.errors;\n// => [\"Invalid input: expected string, received number\"]\n \ntree.properties?.favoriteNumbers?.items?.[1]?.errors;\n// => [\"Invalid input: expected number, received string\"];\n\nBe sure to use optional chaining (?.) to avoid errors when accessing nested properties.\n\nz.prettifyError()\n\nThe z.prettifyError() provides a human-readable string representation of the error.\n\nconst pretty = z.prettifyError(result.error);\n\nThis returns the following string:\n\n✖ Unrecognized key: \"extraKey\"\n✖ Invalid input: expected string, received number\n  → at username\n✖ Invalid input: expected number, received string\n  → at favoriteNumbers[1]\nz.formatError()\n\nThis has been deprecated in favor of z.treeifyError().\n\nShow docs\nz.flattenError()\n\nWhile z.treeifyError() is useful for traversing a potentially complex nested structure, the majority of schemas are flat—just one level deep. In this case, use z.flattenError() to retrieve a clean, shallow error object.\n\nconst flattened = z.flattenError(result.error);\n// { errors: string[], properties: { [key: string]: string[] } }\n \n{\n  formErrors: [ 'Unrecognized key: \"extraKey\"' ],\n  fieldErrors: {\n    username: [ 'Invalid input: expected string, received number' ],\n    favoriteNumbers: [ 'Invalid input: expected number, received string' ]\n  }\n}\n\nThe formErrors array contains any top-level errors (where path is []). The fieldErrors object provides an array of errors for each field in the schema.\n\nflattened.fieldErrors.username; // => [ 'Invalid input: expected string, received number' ]\nflattened.fieldErrors.favoriteNumbers; // => [ 'Invalid input: expected number, received string' ]\n\nCustomizing errors\n\nGuide to customizing validation error messages and error handling patterns\n\nMetadata and registries\n\nAttaching and manipulatinvg metadata on Zod schemas"
	},
	{
		"title": "Metadata and registries | Zod",
		"url": "https://zod.dev/metadata",
		"html": "Metadata and registries\nCopy markdown\nEdit this page\n\nIt's often useful to associate a schema with some additional metadata for documentation, code generation, AI structured outputs, form validation, and other purposes.\n\nRegistries\n\nMetadata in Zod is handled via registries. Registries are collections of schemas, each associated with some strongly-typed metadata. To create a simple registry:\n\nimport * as z from \"zod\";\n \nconst myRegistry = z.registry<{ description: string }>();\n\nTo register, lookup, and remove schemas from this registry:\n\nconst mySchema = z.string();\n \nmyRegistry.add(mySchema, { description: \"A cool schema!\"});\nmyRegistry.has(mySchema); // => true\nmyRegistry.get(mySchema); // => { description: \"A cool schema!\" }\nmyRegistry.remove(mySchema);\nmyRegistry.clear(); // wipe registry\n\nTypeScript enforces that the metadata for each schema matches the registry's metadata type.\n\nmyRegistry.add(mySchema, { description: \"A cool schema!\" }); // ✅\nmyRegistry.add(mySchema, { description: 123 }); // ❌\n\nSpecial handling for id — Zod registries treat the id property specially. An Error will be thrown if multiple schemas are registered with the same id value. This is true for all registries, including the global registry.\n\n.register()\n\nNote — This method is special in that it does not return a new schema; instead, it returns the original schema. No other Zod method does this! That includes .meta() and .describe() (documented below) which return a new instance.\n\nSchemas provide a .register() method to more conveniently add it to a registry.\n\nconst mySchema = z.string();\n \nmySchema.register(myRegistry, { description: \"A cool schema!\" });\n// => mySchema\n\nThis lets you define metadata \"inline\" in your schemas.\n\nconst mySchema = z.object({\n  name: z.string().register(myRegistry, { description: \"The user's name\" }),\n  age: z.number().register(myRegistry, { description: \"The user's age\" }),\n})\n\nIf a registry is defined without a metadata type, you can use it as a generic \"collection\", no metadata required.\n\nconst myRegistry = z.registry();\n \nmyRegistry.add(z.string());\nmyRegistry.add(z.number());\nMetadata\nz.globalRegistry\n\nFor convenience, Zod provides a global registry (z.globalRegistry) that can be used to store metadata for JSON Schema generation or other purposes. It accepts the following metadata:\n\nexport interface GlobalMeta {\n  id?: string ;\n  title?: string ;\n  description?: string;\n  deprecated?: boolean;\n  [k: string]: unknown;\n}\n\nTo register some metadata in z.globalRegistry for a schema:\n\nimport * as z from \"zod\";\n \nconst emailSchema = z.email().register(z.globalRegistry, { \n  id: \"email_address\",\n  title: \"Email address\",\n  description: \"Your email address\",\n  examples: [\"first.last@example.com\"]\n});\n\nTo globally augment the GlobalMeta interface, use declaration merging. Add the following anywhere in your codebase. Creating a zod.d.ts file in your project root is a common convention.\n\ndeclare module \"zod\" {\n  interface GlobalMeta {\n    // add new fields here\n    examples?: unknown[];\n  }\n}\n.meta()\n\nFor a more convenient approach, use the .meta() method to register a schema in z.globalRegistry.\n\nZod\nZod Mini\nconst emailSchema = z.email().meta({ \n  id: \"email_address\",\n  title: \"Email address\",\n  description: \"Please enter a valid email address\",\n});\n\nCalling .meta() without an argument will retrieve the metadata for a schema.\n\nemailSchema.meta();\n// => { id: \"email_address\", title: \"Email address\", ... }\n\nMetadata is associated with a specific schema instance. This is important to keep in mind, especially since Zod methods are immutable—they always return a new instance.\n\nconst A = z.string().meta({ description: \"A cool string\" });\nA.meta(); // => { description: \"A cool string\" }\n \nconst B = A.refine(_ => true);\nB.meta(); // => undefined\n.describe()\n\nThe .describe() method still exists for compatibility with Zod 3, but .meta() is now the recommended approach.\n\nThe .describe() method is a shorthand for registering a schema in z.globalRegistry with just a description field.\n\nZod\nZod Mini\nconst emailSchema = z.email();\nemailSchema.describe(\"An email address\");\n \n// equivalent to\nemailSchema.meta({ description: \"An email address\" });\nCustom registries\n\nYou've already seen a simple example of a custom registry:\n\nimport * as z from \"zod\";\n \nconst myRegistry = z.registry<{ description: string };>();\n\nLet's look at some more advanced patterns.\n\nReferencing inferred types\n\nIt's often valuable for the metadata type to reference the inferred type of a schema. For instance, you may want an examples field to contain examples of the schema's output.\n\nimport * as z from \"zod\";\n \ntype MyMeta = { examples: z.$output[] };\nconst myRegistry = z.registry<MyMeta>();\n \nmyRegistry.add(z.string(), { examples: [\"hello\", \"world\"] });\nmyRegistry.add(z.number(), { examples: [1, 2, 3] });\n\nThe special symbol z.$output is a reference to the schemas inferred output type (z.infer<typeof schema>). Similarly you can use z.$input to reference the input type.\n\nConstraining schema types\n\nPass a second generic to z.registry() to constrain the schema types that can be added to a registry. This registry only accepts string schemas.\n\nimport * as z from \"zod\";\n \nconst myRegistry = z.registry<{ description: string }, z.ZodString>();\n \nmyRegistry.add(z.string(), { description: \"A number\" }); // ✅\nmyRegistry.add(z.number(), { description: \"A number\" }); // ❌ \n//             ^ 'ZodNumber' is not assignable to parameter of type 'ZodString' \n\nFormatting errors\n\nUtilities for formatting and displaying Zod errors\n\nJSON Schema\n\nHow to convert Zod schemas to JSON Schema"
	},
	{
		"title": "JSON Schema | Zod",
		"url": "https://zod.dev/json-schema",
		"html": "JSON Schema\nCopy markdown\nEdit this page\n💎\n\nNew — Zod 4 introduces a new feature: native JSON Schema conversion. JSON Schema is a standard for describing the structure of JSON (with JSON). It's widely used in OpenAPI definitions and defining structured outputs for AI.\n\nTo convert a Zod schema to JSON Schema, use the z.toJSONSchema() function.\n\nimport * as z from \"zod\";\n \nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n \nz.toJSONSchema(schema)\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, age: { type: 'number' } },\n//   required: [ 'name', 'age' ],\n//   additionalProperties: false,\n// }\n\nAll schema & checks are converted to their closest JSON Schema equivalent. Some types have no analog and cannot be reasonably represented. See the unrepresentable section below for more information on handling these cases.\n\nz.bigint(); // ❌\nz.int64(); // ❌\nz.symbol(); // ❌\nz.void(); // ❌\nz.date(); // ❌\nz.map(); // ❌\nz.set(); // ❌\nz.transform(); // ❌\nz.nan(); // ❌\nz.custom(); // ❌\nString formats\n\nZod converts the following schema types to the equivalent JSON Schema format:\n\n// Supported via `format`\nz.email(); // => { type: \"string\", format: \"email\" }\nz.iso.datetime(); // => { type: \"string\", format: \"date-time\" }\nz.iso.date(); // => { type: \"string\", format: \"date\" }\nz.iso.time(); // => { type: \"string\", format: \"time\" }\nz.iso.duration(); // => { type: \"string\", format: \"duration\" }\nz.ipv4(); // => { type: \"string\", format: \"ipv4\" }\nz.ipv6(); // => { type: \"string\", format: \"ipv6\" }\nz.uuid(); // => { type: \"string\", format: \"uuid\" }\nz.guid(); // => { type: \"string\", format: \"uuid\" }\nz.url(); // => { type: \"string\", format: \"uri\" }\n\nThese schemas are supported via contentEncoding:\n\nz.base64(); // => { type: \"string\", contentEncoding: \"base64\" }\n\nAll other string formats are supported via pattern:\n\nz.base64url();\nz.cuid();\nz.emoji();\nz.nanoid();\nz.cuid2();\nz.ulid();\nz.cidrv4();\nz.cidrv6();\nNumeric types\n\nZod converts the following numeric types to JSON Schema:\n\n// number\nz.number(); // => { type: \"number\" }\nz.float32(); // => { type: \"number\", exclusiveMinimum: ..., exclusiveMaximum: ... }\nz.float64(); // => { type: \"number\", exclusiveMinimum: ..., exclusiveMaximum: ... }\n \n// integer\nz.int(); // => { type: \"integer\" }\nz.int32(); // => { type: \"integer\", exclusiveMinimum: ..., exclusiveMaximum: ... }\nObject schemas\n\nBy default, z.object() schemas contain additionalProperties: \"false\". This is an accurate representation of Zod's default behavior, as plain z.object() schema strip additional properties.\n\nimport * as z from \"zod\";\n \nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n \nz.toJSONSchema(schema)\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, age: { type: 'number' } },\n//   required: [ 'name', 'age' ],\n//   additionalProperties: false,\n// }\n\nWhen converting to JSON Schema in \"input\" mode, additionalProperties is not set. See the io docs for more information.\n\nimport * as z from \"zod\";\n \nconst schema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n \nz.toJSONSchema(schema, { io: \"input\" });\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, age: { type: 'number' } },\n//   required: [ 'name', 'age' ],\n// }\n\nBy contrast:\n\nz.looseObject() will never set additionalProperties: false\nz.strictObject() will always set additionalProperties: false\nFile schemas\n\nZod converts z.file() to the following OpenAPI-friendly schema:\n\nz.file();\n// => { type: \"string\", format: \"binary\", contentEncoding: \"binary\" }\n\nSize and MIME checks are also represented:\n\nz.file().min(1).max(1024 * 1024).mime(\"image/png\");\n// => {\n//   type: \"string\",\n//   format: \"binary\",\n//   contentEncoding: \"binary\",\n//   contentMediaType: \"image/png\",\n//   minLength: 1,\n//   maxLength: 1048576,\n// }\nNullability\n\nZod converts both undefined/null to { type: \"null\" } in JSON Schema.\n\nz.null(); \n// => { type: \"null\" }\n \nz.undefined(); \n// => { type: \"null\" }\n\nSimilarly, nullable is represented via a union with null::\n\nz.nullable(z.string());\n// => { oneOf: [{ type: \"string\" }, { type: \"null\" }] }\n\nOptional schemas are represented as-is, though they are decorated with an optional annotation.\n\nz.optional(z.string());\n// => { type: \"string\" }\nConfiguration\n\nA second argument can be used to customize the conversion logic.\n\nz.toJSONSchema(schema, {\n  // ...params\n})\n\nBelow is a quick reference for each supported parameter. Each one is explained in more detail below.\n\ninterface ToJSONSchemaParams {\n  /** The JSON Schema version to target.\n   * - `\"draft-2020-12\"` — Default. JSON Schema Draft 2020-12\n   * - `\"draft-7\"` — JSON Schema Draft 7\n   * - `\"draft-4\"` — JSON Schema Draft 4\n   * - `\"openapi-3.0\"` — OpenAPI 3.0 Schema Object */\n  target?: \"draft-4\" | \"draft-7\" | \"draft-2020-12\" | \"openapi-3.0\";\n \n  /** A registry used to look up metadata for each schema. \n   * Any schema with an `id` property will be extracted as a $def. */\n  metadata?: $ZodRegistry<Record<string, any>>;\n \n  /** How to handle unrepresentable types.\n   * - `\"throw\"` — Default. Unrepresentable types throw an error\n   * - `\"any\"` — Unrepresentable types become `{}` */\n  unrepresentable?: \"throw\" | \"any\";\n \n  /** How to handle cycles.\n   * - `\"ref\"` — Default. Cycles will be broken using $defs\n   * - `\"throw\"` — Cycles will throw an error if encountered */\n  cycles?: \"ref\" | \"throw\";\n \n  /* How to handle reused schemas.\n   * - `\"inline\"` — Default. Reused schemas will be inlined\n   * - `\"ref\"` — Reused schemas will be extracted as $defs */\n  reused?: \"ref\" | \"inline\";\n \n  /** A function used to convert `id` values to URIs to be used in *external* $refs.\n   *\n   * Default is `(id) => id`.\n   */\n  uri?: (id: string) => string;\n}\ntarget\n\nTo set the target JSON Schema version, use the target parameter. By default, Zod will target Draft 2020-12.\n\nz.toJSONSchema(schema, { target: \"draft-7\" });\nz.toJSONSchema(schema, { target: \"draft-2020-12\" });\nz.toJSONSchema(schema, { target: \"draft-4\" });\nz.toJSONSchema(schema, { target: \"openapi-3.0\" });\nmetadata\n\nIf you haven't already, read through the Metadata and registries page for context on storing metadata in Zod.\n\nIn Zod, metadata is stored in registries. Zod exports a global registry z.globalRegistry that can be used to store common metadata fields like id, title, description, and examples.\n\nZod\nZod Mini\nimport * as z from \"zod\";\n \n// `.meta()` is a convenience method for registering a schema in `z.globalRegistry`\nconst emailSchema = z.string().meta({ \n  title: \"Email address\",\n  description: \"Your email address\",\n});\n \nz.toJSONSchema(emailSchema);\n// => { type: \"string\", title: \"Email address\", description: \"Your email address\", ... } \n\nAll metadata fields get copied into the resulting JSON Schema.\n\nconst schema = z.string().meta({\n  whatever: 1234\n});\n \nz.toJSONSchema(schema);\n// => { type: \"string\", whatever: 1234 }\nunrepresentable\n\nThe following APIs are not representable in JSON Schema. By default, Zod will throw an error if they are encountered. It is unsound to attempt a conversion to JSON Schema; you should modify your schemas as they have no equivalent in JSON. An error will be thrown if any of these are encountered.\n\nz.bigint(); // ❌\nz.int64(); // ❌\nz.symbol(); // ❌\nz.void(); // ❌\nz.date(); // ❌\nz.map(); // ❌\nz.set(); // ❌\nz.transform(); // ❌\nz.nan(); // ❌\nz.custom(); // ❌\n\nBy default, Zod will throw an error if any of these are encountered.\n\nz.toJSONSchema(z.bigint());\n// => throws Error\n\nYou can change this behavior by setting the unrepresentable option to \"any\". This will convert any unrepresentable types to {} (the equivalent of unknown in JSON Schema).\n\nz.toJSONSchema(z.bigint(), { unrepresentable: \"any\" });\n// => {}\ncycles\n\nHow to handle cycles. If a cycle is encountered as z.toJSONSchema() traverses the schema, it will be represented using $ref.\n\nconst User = z.object({\n  name: z.string(),\n  get friend() {\n    return User;\n  },\n});\n \nz.toJSONSchema(User);\n// => {\n//   type: 'object',\n//   properties: { name: { type: 'string' }, friend: { '$ref': '#' } },\n//   required: [ 'name', 'friend' ],\n//   additionalProperties: false,\n// }\n\nIf instead you want to throw an error, set the cycles option to \"throw\".\n\nz.toJSONSchema(User, { cycles: \"throw\" });\n// => throws Error\nreused\n\nHow to handle schemas that occur multiple times in the same schema. By default, Zod will inline these schemas.\n\nconst name = z.string();\nconst User = z.object({\n  firstName: name,\n  lastName: name,\n});\n \nz.toJSONSchema(User);\n// => {\n//   type: 'object',\n//   properties: { \n//     firstName: { type: 'string' }, \n//     lastName: { type: 'string' } \n//   },\n//   required: [ 'firstName', 'lastName' ],\n//   additionalProperties: false,\n// }\n\nInstead you can set the reused option to \"ref\" to extract these schemas into $defs.\n\nz.toJSONSchema(User, { reused: \"ref\" });\n// => {\n//   type: 'object',\n//   properties: {\n//     firstName: { '$ref': '#/$defs/__schema0' },\n//     lastName: { '$ref': '#/$defs/__schema0' }\n//   },\n//   required: [ 'firstName', 'lastName' ],\n//   additionalProperties: false,\n//   '$defs': { __schema0: { type: 'string' } }\n// }\noverride\n\nTo define some custom override logic, use override. The provided callback has access to the original Zod schema and the default JSON Schema. This function should directly modify ctx.jsonSchema.\n\nconst mySchema = /* ... */\nz.toJSONSchema(mySchema, {\n  override: (ctx)=>{\n    ctx.zodSchema; // the original Zod schema\n    ctx.jsonSchema; // the default JSON Schema\n \n    // directly modify\n    ctx.jsonSchema.whatever = \"sup\";\n  }\n});\n\nNote that unrepresentable types will throw an Error before this functions is called. If you are trying to define custom behavior for an unrepresentable type, you'll need to use set the unrepresentable: \"any\" alongside override.\n\n// support z.date() as ISO datetime strings\nconst result = z.toJSONSchema(z.date(), {\n  unrepresentable: \"any\",\n  override: (ctx) => {\n    const def = ctx.zodSchema._zod.def;\n    if(def.type ===\"date\"){\n      ctx.jsonSchema.type = \"string\";\n      ctx.jsonSchema.format = \"date-time\";\n    }\n  },\n});\nio\n\nSome schema types have different input and output types, e.g. ZodPipe, ZodDefault, and coerced primitives. By default, the result of z.toJSONSchema represents the output type; use \"io\": \"input\" to extract the input type instead.\n\nconst mySchema = z.string().transform(val => val.length).pipe(z.number());\n// ZodPipe\n \nconst jsonSchema = z.toJSONSchema(mySchema); \n// => { type: \"number\" }\n \nconst jsonSchema = z.toJSONSchema(mySchema, { io: \"input\" }); \n// => { type: \"string\" }\nRegistries\n\nPassing a schema into z.toJSONSchema() will return a self-contained JSON Schema.\n\nIn other cases, you may have a set of Zod schemas you'd like to represent using multiple interlinked JSON Schemas, perhaps to write to .json files and serve from a web server.\n\nimport * as z from \"zod\";\n \nconst User = z.object({\n  name: z.string(),\n  get posts(){\n    return z.array(Post);\n  }\n});\n \nconst Post = z.object({\n  title: z.string(),\n  content: z.string(),\n  get author(){\n    return User;\n  }\n});\n \nz.globalRegistry.add(User, {id: \"User\"});\nz.globalRegistry.add(Post, {id: \"Post\"});\n\nTo achieve this, you can pass a registry into z.toJSONSchema().\n\nImportant — All schemas should have a registered id property in the registry! Any schemas without an id will be ignored.\n\nz.toJSONSchema(z.globalRegistry);\n// => {\n//   schemas: {\n//     User: {\n//       id: 'User',\n//       type: 'object',\n//       properties: {\n//         name: { type: 'string' },\n//         posts: { type: 'array', items: { '$ref': 'Post' } }\n//       },\n//       required: [ 'name', 'posts' ],\n//       additionalProperties: false,\n//     },\n//     Post: {\n//       id: 'Post',\n//       type: 'object',\n//       properties: {\n//         title: { type: 'string' },\n//         content: { type: 'string' },\n//         author: { '$ref': 'User' }\n//       },\n//       required: [ 'title', 'content', 'author' ],\n//       additionalProperties: false,\n//     }\n//   }\n// }\n\nBy default, the $ref URIs are simple relative paths like \"User\". To make these absolute URIs, use the uri option. This expects a function that converts an id to a fully-qualified URI.\n\nz.toJSONSchema(z.globalRegistry, {\n  uri: (id) => `https://example.com/${id}.json`\n});\n// => {\n//   schemas: {\n//     User: {\n//       id: 'User',\n//       type: 'object',\n//       properties: {\n//         name: { type: 'string' },\n//         posts: {\n//           type: 'array',\n//           items: { '$ref': 'https://example.com/Post.json' }\n//         }\n//       },\n//       required: [ 'name', 'posts' ],\n//       additionalProperties: false,\n//     },\n//     Post: {\n//       id: 'Post',\n//       type: 'object',\n//       properties: {\n//         title: { type: 'string' },\n//         content: { type: 'string' },\n//         author: { '$ref': 'https://example.com/User.json' }\n//       },\n//       required: [ 'title', 'content', 'author' ],\n//       additionalProperties: false,\n//     }\n//   }\n// }\n\nMetadata and registries\n\nAttaching and manipulatinvg metadata on Zod schemas\n\nCodecs\n\nBidirectional transformations with encode and decode"
	},
	{
		"title": "Codecs | Zod",
		"url": "https://zod.dev/codecs",
		"html": "Codecs\nCopy markdown\nEdit this page\n\n✨ New — Introduced in zod@4.1\n\nAll Zod schemas can process inputs in both the forward and backward direction:\n\nForward: Input to Output\n.parse()\n.decode()\nBackward: Output to Input\n.encode()\n\nIn most cases, this is a distinction without a difference. The input and output types are identical, so there's no difference between \"forward\" and \"backward\".\n\nZod\nZod Mini\nconst schema = z.string();\n \ntype Input = z.input<typeof schema>;    // string\ntype Output = z.output<typeof schema>;  // string\n \nschema.parse(\"asdf\");   // => \"asdf\"\nschema.decode(\"asdf\");  // => \"asdf\"\nschema.encode(\"asdf\");  // => \"asdf\"\n\nHowever, some schema types cause the input and output types to diverge, notably z.codec(). Codecs are a special type of schema that defines a bi-directional transformation between two other schemas.\n\nconst stringToDate = z.codec(\n  z.iso.datetime(),  // input schema: ISO date string\n  z.date(),          // output schema: Date object\n  {\n    decode: (isoString) => new Date(isoString), // ISO string → Date\n    encode: (date) => date.toISOString(),       // Date → ISO string\n  }\n);\n\nIn these cases, z.decode() and z.encode() behave quite differently.\n\nZod\nZod Mini\nstringToDate.decode(\"2024-01-15T10:30:00.000Z\")\n// => Date\n \nstringToDate.encode(new Date(\"2024-01-15T10:30:00.000Z\"))\n// => string\n\nNote —There's nothing special about the directions or terminology here. Instead of encoding with an A -> B codec, you could instead decode with a B -> A codec. The use of the terms \"decode\" and \"encode\" is just a convention.\n\nThis is particularly useful when parsing data at a network boundary. You can share a single Zod schema between your client and server, then use this single schema to convert between a network-friendly format (say, JSON) and a richer JavaScript representation.\n\nComposability\n\nNote — You can use z.encode() and z.decode() with any schema. It doesn't have to be a ZodCodec.\n\nCodecs are a schema like any other. You can nest them inside objects, arrays, pipes, etc. There are no rules on where you can use them!\n\nconst payloadSchema = z.object({ \n  startDate: stringToDate \n});\n \npayloadSchema.decode({\n  startDate: \"2024-01-15T10:30:00.000Z\"\n}); // => { startDate: Date }\nType-safe inputs\n\nWhile .parse() and .decode() behave identically at runtime, they have different type signatures. The .parse() method accepts unknown as input, and returns a value that matches the schema's inferred output type. By constrast, the z.decode() and z.encode() functions have strongly-typed inputs.\n\nstringToDate.parse(12345); \n// no complaints from TypeScript (fails at runtime)\n \nstringToDate.decode(12345); \n// ❌ TypeScript error: Argument of type 'number' is not assignable to parameter of type 'string'.\n \nstringToDate.encode(12345); \n// ❌ TypeScript error: Argument of type 'number' is not assignable to parameter of type 'Date'.\n\nWhy the difference? Encoding and decoding imply transformation. In many cases, the inputs to these methods Here's a diagram demonstrating the differences between the type signatures for parse(), decode(), and encode().\n\nAsync and safe variants\n\nAs with .transform() and .refine(), codecs support async transforms.\n\nconst asyncCodec = z.codec(z.string(), z.number(), {\n  decode: async (str) => Number(str),\n  encode: async (num) => num.toString(),\n});\n\nAs with regular parse(), there are \"safe\" and \"async\" variants of decode() and encode().\n\nstringToDate.decode(\"2024-01-15T10:30:00.000Z\"); \n// => Date\n \nstringToDate.decodeAsync(\"2024-01-15T10:30:00.000Z\"); \n// => Promise<Date>\n \nstringToDate.decodeSafe(\"2024-01-15T10:30:00.000Z\"); \n// => { success: true, data: Date } | { success: false, error: ZodError }\n \nstringToDate.decodeSafeAsync(\"2024-01-15T10:30:00.000Z\"); \n// => Promise<{ success: true, data: Date } | { success: false, error: ZodError }>\nHow encoding works\n\nThere are some subtleties to how certain Zod schemas \"reverse\" their parse behavior.\n\nCodecs\n\nThis one is fairly self-explanatory. Codecs encapsulate a bi-directional transformation between two types. During z.decode(), the decode transform is executed. During z.encode(), the encode transform is executed.\n\nconst stringToDate = z.codec(\n  z.iso.datetime(),  // input schema: ISO date string\n  z.date(),          // output schema: Date object\n  {\n    decode: (isoString) => new Date(isoString), // ISO string → Date\n    encode: (date) => date.toISOString(),       // Date → ISO string\n  }\n);\n \nstringToDate.decode(\"2024-01-15T10:30:00.000Z\"); \n// => Date\n \nstringToDate.encode(new Date(\"2024-01-15\")); \n// => string\nPipes\n\nFun fact — Codecs are actually implemented internally as subclass of pipes that have been augmented with \"interstitial\" transform logic.\n\nDuring regular decoding, a ZodPipe<A, B> schema will first parse the data with A, then pass it into B. As you might expect, during encoding, the data is first encoded with B, then passed into A.\n\nRefinements\n\nAll checks (.refine(), .min(), .max(), etc.) are still executed in both directions.\n\nconst schema = stringToDate.refine((date) => date.getFullYear() >= 2000, \"Must be this millenium\");\n \nschema.encode(new Date(\"2000-01-01\"));\n// => Date\n \nschema.encode(new Date(\"1999-01-01\"));\n// => ❌ ZodError: [\n//   {\n//     \"code\": \"custom\",\n//     \"path\": [],\n//     \"message\": \"Must be this millenium\"\n//   }\n// ]\n\nTo avoid unexpected errors in your custom .refine() logic, Zod performs two \"passes\" during z.encode(). The first pass ensures the input type conforms to the expected type (no invalid_type errors). If that passes, Zod performs the second pass which executes the refinement logic.\n\nThis approach also supports \"mutating transforms\" like z.string().trim() or z.string().toLowerCase():\n\nconst schema = z.string().trim();\n \nschema.decode(\"  hello  \");\n// => \"hello\"\n \nschema.encode(\"  hello  \");\n// => \"hello\"\nDefaults and prefaults\n\nDefaults and prefaults are only applied in the \"forward\" direction.\n\nconst stringWithDefault = z.string().default(\"hello\");\n \nstringWithDefault.decode(undefined); \n// => \"hello\"\n \nstringWithDefault.encode(undefined); \n// => ZodError: Expected string, received undefined\n\nWhen you attach a default value to a schema, the input becomes optional (| undefined) but the output does not. As such, undefined is not a valid input to z.encode() and defaults/prefaults will not be applied.\n\nCatch\n\nSimilarly, .catch() is only applied in the \"forward\" direction.\n\nconst stringWithCatch = z.string().catch(\"hello\");\n \nstringWithCatch.decode(1234); \n// => \"hello\"\n \nstringWithCatch.encode(1234); \n// => ZodError: Expected string, received number\nStringbool\n\nNote — Stringbool pre-dates the introduction of codecs in Zod. It has since been internally re-implemented as a codec.\n\nThe z.stringbool() API converts string values (\"true\", \"false\", \"yes\", \"no\", etc.) into boolean. By default, it will convert true to \"true\" and false to \"false\" during z.encode()..\n\nconst stringbool = z.stringbool();\n \nstringbool.decode(\"true\");  // => true\nstringbool.decode(\"false\"); // => false\n \nstringbool.encode(true);    // => \"true\"\nstringbool.encode(false);   // => \"false\"\n\nIf you specify a custom set of truthy and falsy values, the first element in the array will be used instead.\n\nconst stringbool = z.stringbool({ truthy: [\"yes\", \"y\"], falsy: [\"no\", \"n\"] });\n \nstringbool.encode(true);    // => \"yes\"\nstringbool.encode(false);   // => \"no\"\nTransforms\n\n⚠️ — The .transform() API implements a unidirectional transformation. If any .transform() exists anywhere in your schema, attempting a z.encode() operation will throw a runtime error (not a ZodError).\n\nconst schema = z.string().transform(val => val.length);\n \nschema.encode(1234); \n// ❌ Error: Encountered unidirectional transform during encode: ZodTransform\nUseful codecs\n\nBelow are implementations for a bunch of commonly-needed codecs. For the sake of customizability, these are not included as first-class APIs in Zod itself. Instead, you should copy/paste them into your project and modify them as needed.\n\nNote — All of these codec implementations have been tested for correctness.\n\nstringToNumber\n\nConverts string representations of numbers to JavaScript number type using parseFloat().\n\nconst stringToNumber = z.codec(z.string().regex(z.regexes.number), z.number(), {\n  decode: (str) => Number.parseFloat(str),\n  encode: (num) => num.toString(),\n});\n \nstringToNumber.decode(\"42.5\");  // => 42.5\nstringToNumber.encode(42.5);    // => \"42.5\"\nstringToInt\n\nConverts string representations of integers to JavaScript number type using parseInt().\n\nconst stringToInt = z.codec(z.string().regex(z.regexes.integer), z.int(), {\n  decode: (str) => Number.parseInt(str, 10),\n  encode: (num) => num.toString(),\n});\n \nstringToInt.decode(\"42\");  // => 42\nstringToInt.encode(42);    // => \"42\"\nstringToBigInt\n\nConverts string representations to JavaScript bigint type.\n\nconst stringToBigInt = z.codec(z.string(), z.bigint(), {\n  decode: (str) => BigInt(str),\n  encode: (bigint) => bigint.toString(),\n});\n \nstringToBigInt.decode(\"12345\");  // => 12345n\nstringToBigInt.encode(12345n);   // => \"12345\"\nnumberToBigInt\n\nConverts JavaScript number to bigint type.\n\nconst numberToBigInt = z.codec(z.int(), z.bigint(), {\n  decode: (num) => BigInt(num),\n  encode: (bigint) => Number(bigint),\n});\n \nnumberToBigInt.decode(42);   // => 42n\nnumberToBigInt.encode(42n);  // => 42\nisoDatetimeToDate\n\nConverts ISO datetime strings to JavaScript Date objects.\n\nconst isoDatetimeToDate = z.codec(z.iso.datetime(), z.date(), {\n  decode: (isoString) => new Date(isoString),\n  encode: (date) => date.toISOString(),\n});\n \nisoDatetimeToDate.decode(\"2024-01-15T10:30:00.000Z\");  // => Date object\nisoDatetimeToDate.encode(new Date(\"2024-01-15\"));       // => \"2024-01-15T00:00:00.000Z\"\nepochSecondsToDate\n\nConverts Unix timestamps (seconds since epoch) to JavaScript Date objects.\n\nconst epochSecondsToDate = z.codec(z.int().min(0), z.date(), {\n  decode: (seconds) => new Date(seconds * 1000),\n  encode: (date) => Math.floor(date.getTime() / 1000),\n});\n \nepochSecondsToDate.decode(1705314600);  // => Date object\nepochSecondsToDate.encode(new Date());  // => Unix timestamp in seconds\nepochMillisToDate\n\nConverts Unix timestamps (milliseconds since epoch) to JavaScript Date objects.\n\nconst epochMillisToDate = z.codec(z.int().min(0), z.date(), {\n  decode: (millis) => new Date(millis),\n  encode: (date) => date.getTime(),\n});\n \nepochMillisToDate.decode(1705314600000);  // => Date object\nepochMillisToDate.encode(new Date());     // => Unix timestamp in milliseconds\njson(schema)\n\nParses JSON strings into structured data and serializes back to JSON. This generic function accepts an output schema to validate the parsed JSON data.\n\nconst jsonCodec = <T extends z.core.$ZodType>(schema: T) =>\n  z.codec(z.string(), schema, {\n    decode: (jsonString, ctx) => {\n      try {\n        return JSON.parse(jsonString);\n      } catch (err: any) {\n        ctx.issues.push({\n          code: \"invalid_format\",\n          format: \"json\",\n          input: jsonString,\n          message: err.message,\n        });\n        return z.NEVER;\n      }\n    },\n    encode: (value) => JSON.stringify(value),\n  });\n\nUsage example with a specific schema:\n\nconst jsonToObject = jsonCodec(z.object({ name: z.string(), age: z.number() }));\n \njsonToObject.decode('{\"name\":\"Alice\",\"age\":30}');  \n// => { name: \"Alice\", age: 30 }\n \njsonToObject.encode({ name: \"Bob\", age: 25 });     \n// => '{\"name\":\"Bob\",\"age\":25}'\n \njsonToObject.decode('~~invalid~~'); \n// ZodError: [\n//   {\n//     \"code\": \"invalid_format\",\n//     \"format\": \"json\",\n//     \"path\": [],\n//     \"message\": \"Unexpected token '~', \\\"~~invalid~~\\\" is not valid JSON\"\n//   }\n// ]\nutf8ToBytes\n\nConverts UTF-8 strings to Uint8Array byte arrays.\n\nconst utf8ToBytes = z.codec(z.string(), z.instanceof(Uint8Array), {\n  decode: (str) => new TextEncoder().encode(str),\n  encode: (bytes) => new TextDecoder().decode(bytes),\n});\n \nutf8ToBytes.decode(\"Hello, 世界!\");  // => Uint8Array\nutf8ToBytes.encode(bytes);          // => \"Hello, 世界!\"\nbytesToUtf8\n\nConverts Uint8Array byte arrays to UTF-8 strings.\n\nconst bytesToUtf8 = z.codec(z.instanceof(Uint8Array), z.string(), {\n  decode: (bytes) => new TextDecoder().decode(bytes),\n  encode: (str) => new TextEncoder().encode(str),\n});\n \nbytesToUtf8.decode(bytes);          // => \"Hello, 世界!\"\nbytesToUtf8.encode(\"Hello, 世界!\");  // => Uint8Array\nbase64ToBytes\n\nConverts base64 strings to Uint8Array byte arrays and vice versa.\n\nconst base64ToBytes = z.codec(z.base64(), z.instanceof(Uint8Array), {\n  decode: (base64String) => z.util.base64ToUint8Array(base64String),\n  encode: (bytes) => z.util.uint8ArrayToBase64(bytes),\n});\n \nbase64ToBytes.decode(\"SGVsbG8=\");  // => Uint8Array([72, 101, 108, 108, 111])\nbase64ToBytes.encode(bytes);       // => \"SGVsbG8=\"\nbase64urlToBytes\n\nConverts base64url strings (URL-safe base64) to Uint8Array byte arrays.\n\nconst base64urlToBytes = z.codec(z.base64url(), z.instanceof(Uint8Array), {\n  decode: (base64urlString) => z.util.base64urlToUint8Array(base64urlString),\n  encode: (bytes) => z.util.uint8ArrayToBase64url(bytes),\n});\n \nbase64urlToBytes.decode(\"SGVsbG8\");  // => Uint8Array([72, 101, 108, 108, 111])\nbase64urlToBytes.encode(bytes);      // => \"SGVsbG8\"\nhexToBytes\n\nConverts hexadecimal strings to Uint8Array byte arrays and vice versa.\n\nconst hexToBytes = z.codec(z.hex(), z.instanceof(Uint8Array), {\n  decode: (hexString) => z.util.hexToUint8Array(hexString),\n  encode: (bytes) => z.util.uint8ArrayToHex(bytes),\n});\n \nhexToBytes.decode(\"48656c6c6f\");     // => Uint8Array([72, 101, 108, 108, 111])\nhexToBytes.encode(bytes);            // => \"48656c6c6f\"\nstringToURL\n\nConverts URL strings to JavaScript URL objects.\n\nconst stringToURL = z.codec(z.url(), z.instanceof(URL), {\n  decode: (urlString) => new URL(urlString),\n  encode: (url) => url.href,\n});\n \nstringToURL.decode(\"https://example.com/path\");  // => URL object\nstringToURL.encode(new URL(\"https://example.com\"));  // => \"https://example.com/\"\nstringToHttpURL\n\nConverts HTTP/HTTPS URL strings to JavaScript URL objects.\n\nconst stringToHttpURL = z.codec(z.httpUrl(), z.instanceof(URL), {\n  decode: (urlString) => new URL(urlString),\n  encode: (url) => url.href,\n});\n \nstringToHttpURL.decode(\"https://api.example.com/v1\");  // => URL object\nstringToHttpURL.encode(url);                           // => \"https://api.example.com/v1\"\nuriComponent\n\nEncodes and decodes URI components using encodeURIComponent() and decodeURIComponent().\n\nconst uriComponent = z.codec(z.string(), z.string(), {\n  decode: (encodedString) => decodeURIComponent(encodedString),\n  encode: (decodedString) => encodeURIComponent(decodedString),\n});\n \nuriComponent.decode(\"Hello%20World%21\");  // => \"Hello World!\"\nuriComponent.encode(\"Hello World!\");      // => \"Hello%20World!\"\n\nJSON Schema\n\nHow to convert Zod schemas to JSON Schema\n\nEcosystem\n\nOverview of the Zod ecosystem including integrations, tools, and community resources"
	}
]
</file>

<file path="output/nextjs/docs.json">
[
  {
    "title": "App Router: Getting Started | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started",
    "html": "Next.js Docs\nApp Router\nGetting Started\nCopy page\nGetting Started\n\nWelcome to the Next.js documentation!\n\nThis Getting Started section will help you create your first Next.js app and learn the core features you'll use in every project.\n\nPre-requisite knowledge\n\nOur documentation assumes some familiarity with web development. Before getting started, it'll help if you're comfortable with:\n\nHTML\nCSS\nJavaScript\nReact\n\nIf you're new to React or need a refresher, we recommend starting with our React Foundations course, and the Next.js Foundations course that has you building an application as you learn.\n\nNext Steps\nInstallation\nLearn how to create a new Next.js application with the `create-next-app` CLI, and set up TypeScript, ESLint, and Module Path Aliases.\nProject Structure\nLearn the folder and file conventions in Next.js, and how to organize your project.\nLayouts and Pages\nLearn how to create your first pages and layouts, and link between them with the Link component.\nLinking and Navigating\nLearn how the built-in navigation optimizations work, including prefetching, prerendering, and client-side navigation, and how to optimize navigation for dynamic routes and slow networks.\nServer and Client Components\nLearn how you can use React Server and Client Components to render parts of your application on the server or the client.\nCache Components\nLearn how to use Cache Components and combine the benefits of static and dynamic rendering.\nFetching Data\nLearn how to fetch data and stream content that depends on data.\nUpdating Data\nLearn how to mutate data using Server Functions.\nCaching and Revalidating\nLearn how to cache and revalidate data in your application.\nError Handling\nLearn how to display expected errors and handle uncaught exceptions.\nCSS\nLearn about the different ways to add CSS to your application, including Tailwind CSS, CSS Modules, Global CSS, and more.\nImage Optimization\nLearn how to optimize images in Next.js\nFont Optimization\nLearn how to optimize fonts in Next.js\nMetadata and OG images\nLearn how to add metadata to your pages and create dynamic OG images.\nRoute Handlers\nLearn how to use Route Handlers\nProxy\nLearn how to use Proxy\nDeploying\nLearn how to deploy your Next.js application.\nUpgrading\nLearn how to upgrade your Next.js application to the latest version or canary.\nPrevious\nApp Router\nNext\nInstallation\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Project Structure | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/project-structure",
    "html": "App Router\nGetting Started\nProject Structure\nCopy page\nProject structure and organization\n\nThis page provides an overview of all the folder and file conventions in Next.js, and recommendations for organizing your project.\n\nFolder and file conventions\nTop-level folders\n\nTop-level folders are used to organize your application's code and static assets.\n\n\t\napp\tApp Router\npages\tPages Router\npublic\tStatic assets to be served\nsrc\tOptional application source folder\nTop-level files\n\nTop-level files are used to configure your application, manage dependencies, run proxy, integrate monitoring tools, and define environment variables.\n\n\t\nNext.js\t\nnext.config.js\tConfiguration file for Next.js\npackage.json\tProject dependencies and scripts\ninstrumentation.ts\tOpenTelemetry and Instrumentation file\nproxy.ts\tNext.js request proxy\n.env\tEnvironment variables\n.env.local\tLocal environment variables\n.env.production\tProduction environment variables\n.env.development\tDevelopment environment variables\neslint.config.mjs\tConfiguration file for ESLint\n.gitignore\tGit files and folders to ignore\nnext-env.d.ts\tTypeScript declaration file for Next.js\ntsconfig.json\tConfiguration file for TypeScript\njsconfig.json\tConfiguration file for JavaScript\nRouting Files\n\nAdd page to expose a route, layout for shared UI such as header, nav, or footer, loading for skeletons, error for error boundaries, and route for APIs.\n\n\t\t\nlayout\t.js .jsx .tsx\tLayout\npage\t.js .jsx .tsx\tPage\nloading\t.js .jsx .tsx\tLoading UI\nnot-found\t.js .jsx .tsx\tNot found UI\nerror\t.js .jsx .tsx\tError UI\nglobal-error\t.js .jsx .tsx\tGlobal error UI\nroute\t.js .ts\tAPI endpoint\ntemplate\t.js .jsx .tsx\tRe-rendered layout\ndefault\t.js .jsx .tsx\tParallel route fallback page\nNested routes\n\nFolders define URL segments. Nesting folders nests segments. Layouts at any level wrap their child segments. A route becomes public when a page or route file exists.\n\nPath\tURL pattern\tNotes\napp/layout.tsx\t—\tRoot layout wraps all routes\napp/blog/layout.tsx\t—\tWraps /blog and descendants\napp/page.tsx\t/\tPublic route\napp/blog/page.tsx\t/blog\tPublic route\napp/blog/authors/page.tsx\t/blog/authors\tPublic route\nDynamic routes\n\nParameterize segments with square brackets. Use [segment] for a single param, [...segment] for catch‑all, and [[...segment]] for optional catch‑all. Access values via the params prop.\n\nPath\tURL pattern\napp/blog/[slug]/page.tsx\t/blog/my-first-post\napp/shop/[...slug]/page.tsx\t/shop/clothing, /shop/clothing/shirts\napp/docs/[[...slug]]/page.tsx\t/docs, /docs/layouts-and-pages, /docs/api-reference/use-router\nRoute groups and private folders\n\nOrganize code without changing URLs with route groups (group), and colocate non-routable files with private folders _folder.\n\nPath\tURL pattern\tNotes\napp/(marketing)/page.tsx\t/\tGroup omitted from URL\napp/(shop)/cart/page.tsx\t/cart\tShare layouts within (shop)\napp/blog/_components/Post.tsx\t—\tNot routable; safe place for UI utilities\napp/blog/_lib/data.ts\t—\tNot routable; safe place for utils\nParallel and Intercepted Routes\n\nThese features fit specific UI patterns, such as slot-based layouts or modal routing.\n\nUse @slot for named slots rendered by a parent layout. Use intercept patterns to render another route inside the current layout without changing the URL, for example, to show a details view as a modal over a list.\n\nPattern (docs)\tMeaning\tTypical use case\n@folder\tNamed slot\tSidebar + main content\n(.)folder\tIntercept same level\tPreview sibling route in a modal\n(..)folder\tIntercept parent\tOpen a child of the parent as an overlay\n(..)(..)folder\tIntercept two levels\tDeeply nested overlay\n(...)folder\tIntercept from root\tShow arbitrary route in current view\nMetadata file conventions\nApp icons\n\t\t\nfavicon\t.ico\tFavicon file\nicon\t.ico .jpg .jpeg .png .svg\tApp Icon file\nicon\t.js .ts .tsx\tGenerated App Icon\napple-icon\t.jpg .jpeg, .png\tApple App Icon file\napple-icon\t.js .ts .tsx\tGenerated Apple App Icon\nOpen Graph and Twitter images\n\t\t\nopengraph-image\t.jpg .jpeg .png .gif\tOpen Graph image file\nopengraph-image\t.js .ts .tsx\tGenerated Open Graph image\ntwitter-image\t.jpg .jpeg .png .gif\tTwitter image file\ntwitter-image\t.js .ts .tsx\tGenerated Twitter image\nSEO\n\t\t\nsitemap\t.xml\tSitemap file\nsitemap\t.js .ts\tGenerated Sitemap\nrobots\t.txt\tRobots file\nrobots\t.js .ts\tGenerated Robots file\nOrganizing your project\n\nNext.js is unopinionated about how you organize and colocate your project files. But it does provide several features to help you organize your project.\n\nComponent hierarchy\n\nThe components defined in special files are rendered in a specific hierarchy:\n\nlayout.js\ntemplate.js\nerror.js (React error boundary)\nloading.js (React suspense boundary)\nnot-found.js (React error boundary for \"not found\" UI)\npage.js or nested layout.js\n\nThe components are rendered recursively in nested routes, meaning the components of a route segment will be nested inside the components of its parent segment.\n\nColocation\n\nIn the app directory, nested folders define route structure. Each folder represents a route segment that is mapped to a corresponding segment in a URL path.\n\nHowever, even though route structure is defined through folders, a route is not publicly accessible until a page.js or route.js file is added to a route segment.\n\nAnd, even when a route is made publicly accessible, only the content returned by page.js or route.js is sent to the client.\n\nThis means that project files can be safely colocated inside route segments in the app directory without accidentally being routable.\n\nGood to know: While you can colocate your project files in app you don't have to. If you prefer, you can keep them outside the app directory.\n\nPrivate folders\n\nPrivate folders can be created by prefixing a folder with an underscore: _folderName\n\nThis indicates the folder is a private implementation detail and should not be considered by the routing system, thereby opting the folder and all its subfolders out of routing.\n\nSince files in the app directory can be safely colocated by default, private folders are not required for colocation. However, they can be useful for:\n\nSeparating UI logic from routing logic.\nConsistently organizing internal files across a project and the Next.js ecosystem.\nSorting and grouping files in code editors.\nAvoiding potential naming conflicts with future Next.js file conventions.\n\nGood to know:\n\nWhile not a framework convention, you might also consider marking files outside private folders as \"private\" using the same underscore pattern.\nYou can create URL segments that start with an underscore by prefixing the folder name with %5F (the URL-encoded form of an underscore): %5FfolderName.\nIf you don't use private folders, it would be helpful to know Next.js special file conventions to prevent unexpected naming conflicts.\nRoute groups\n\nRoute groups can be created by wrapping a folder in parenthesis: (folderName)\n\nThis indicates the folder is for organizational purposes and should not be included in the route's URL path.\n\nRoute groups are useful for:\n\nOrganizing routes by site section, intent, or team. e.g. marketing pages, admin pages, etc.\nEnabling nested layouts in the same route segment level:\nCreating multiple nested layouts in the same segment, including multiple root layouts\nAdding a layout to a subset of routes in a common segment\nsrc folder\n\nNext.js supports storing application code (including app) inside an optional src folder. This separates application code from project configuration files which mostly live in the root of a project.\n\nExamples\n\nThe following section lists a very high-level overview of common strategies. The simplest takeaway is to choose a strategy that works for you and your team and be consistent across the project.\n\nGood to know: In our examples below, we're using components and lib folders as generalized placeholders, their naming has no special framework significance and your projects might use other folders like ui, utils, hooks, styles, etc.\n\nStore project files outside of app\n\nThis strategy stores all application code in shared folders in the root of your project and keeps the app directory purely for routing purposes.\n\nStore project files in top-level folders inside of app\n\nThis strategy stores all application code in shared folders in the root of the app directory.\n\nSplit project files by feature or route\n\nThis strategy stores globally shared application code in the root app directory and splits more specific application code into the route segments that use them.\n\nOrganize routes without affecting the URL path\n\nTo organize routes without affecting the URL, create a group to keep related routes together. The folders in parenthesis will be omitted from the URL (e.g. (marketing) or (shop)).\n\nEven though routes inside (marketing) and (shop) share the same URL hierarchy, you can create a different layout for each group by adding a layout.js file inside their folders.\n\nOpting specific segments into a layout\n\nTo opt specific routes into a layout, create a new route group (e.g. (shop)) and move the routes that share the same layout into the group (e.g. account and cart). The routes outside of the group will not share the layout (e.g. checkout).\n\nOpting for loading skeletons on a specific route\n\nTo apply a loading skeleton via a loading.js file to a specific route, create a new route group (e.g., /(overview)) and then move your loading.tsx inside that route group.\n\nNow, the loading.tsx file will only apply to your dashboard → overview page instead of all your dashboard pages without affecting the URL path structure.\n\nCreating multiple root layouts\n\nTo create multiple root layouts, remove the top-level layout.js file, and add a layout.js file inside each route group. This is useful for partitioning an application into sections that have a completely different UI or experience. The <html> and <body> tags need to be added to each root layout.\n\nIn the example above, both (marketing) and (shop) have their own root layout.\n\nPrevious\nInstallation\nNext\nLayouts and Pages\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Installation | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/installation",
    "html": "App Router\nGetting Started\nInstallation\nCopy page\nInstallation\n\nCreate a new Next.js app and run it locally.\n\nQuick start\nCreate a new Next.js app named my-app\ncd my-app and start the dev server.\nVisit http://localhost:3000.\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm create next-app@latest my-app --yes\ncd my-app\npnpm dev\n--yes skips prompts using saved preferences or defaults. The default setup enables TypeScript, Tailwind, App Router, and Turbopack, with import alias @/*.\nSystem requirements\n\nBefore you begin, make sure your system meets the following requirements:\n\nNode.js 20.9\n or later.\nmacOS, Windows (including WSL), or Linux.\nCreate with the CLI\n\nThe quickest way to create a new Next.js app is using create-next-app, which sets up everything automatically for you. To create a project, run:\n\nTerminal\nnpx create-next-app@latest\n\nOn installation, you'll see the following prompts:\n\nTerminal\nWhat is your project named? my-app\nWould you like to use the recommended Next.js defaults?\n    Yes, use recommended defaults - TypeScript, ESLint, Tailwind CSS, App Router, Turbopack\n    No, reuse previous settings\n    No, customize settings - Choose your own preferences\n\nIf you choose to customize settings, you'll see the following prompts:\n\nTerminal\nWould you like to use TypeScript? No / Yes\nWhich linter would you like to use? ESLint / Biome / None\nWould you like to use React Compiler? No / Yes\nWould you like to use Tailwind CSS? No / Yes\nWould you like your code inside a `src/` directory? No / Yes\nWould you like to use App Router? (recommended) No / Yes\nWould you like to use Turbopack? (recommended) No / Yes\nWould you like to customize the import alias (`@/*` by default)? No / Yes\nWhat import alias would you like configured? @/*\n\nAfter the prompts, create-next-app will create a folder with your project name and install the required dependencies.\n\nManual installation\n\nTo manually create a new Next.js app, install the required packages:\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm i next@latest react@latest react-dom@latest\n\nGood to know: The App Router uses React canary releases\n built-in, which include all the stable React 19 changes, as well as newer features being validated in frameworks. The Pages Router uses the React version you install in package.json.\n\nThen, add the following scripts to your package.json file:\n\npackage.json\n{\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"next build\",\n    \"start\": \"next start\",\n    \"lint\": \"eslint\",\n    \"lint:fix\": \"eslint --fix\"\n  }\n}\n\nThese scripts refer to the different stages of developing an application:\n\nnext dev: Starts the development server using Turbopack (default bundler).\nnext build: Builds the application for production.\nnext start: Starts the production server.\neslint: Runs ESLint.\n\nTurbopack is now the default bundler. To use Webpack run next dev --webpack or next build --webpack. See the Turbopack docs for configuration details.\n\nCreate the app directory\n\nNext.js uses file-system routing, which means the routes in your application are determined by how you structure your files.\n\nCreate an app folder. Then, inside app, create a layout.tsx file. This file is the root layout. It's required and must contain the <html> and <body> tags.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body>{children}</body>\n    </html>\n  )\n}\n\nCreate a home page app/page.tsx with some initial content:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Page() {\n  return <h1>Hello, Next.js!</h1>\n}\n\nBoth layout.tsx and page.tsx will be rendered when the user visits the root of your application (/).\n\nGood to know:\n\nIf you forget to create the root layout, Next.js will automatically create this file when running the development server with next dev.\nYou can optionally use a src folder in the root of your project to separate your application's code from configuration files.\nCreate the public folder (optional)\n\nCreate a public folder at the root of your project to store static assets such as images, fonts, etc. Files inside public can then be referenced by your code starting from the base URL (/).\n\nYou can then reference these assets using the root path (/). For example, public/profile.png can be referenced as /profile.png:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Image from 'next/image'\n \nexport default function Page() {\n  return <Image src=\"/profile.png\" alt=\"Profile\" width={100} height={100} />\n}\nRun the development server\nRun npm run dev to start the development server.\nVisit http://localhost:3000 to view your application.\nEdit the app/page.tsx file and save it to see the updated result in your browser.\nSet up TypeScript\n\nMinimum TypeScript version: v5.1.0\n\nNext.js comes with built-in TypeScript support. To add TypeScript to your project, rename a file to .ts / .tsx and run next dev. Next.js will automatically install the necessary dependencies and add a tsconfig.json file with the recommended config options.\n\nIDE Plugin\n\nNext.js includes a custom TypeScript plugin and type checker, which VSCode and other code editors can use for advanced type-checking and auto-completion.\n\nYou can enable the plugin in VS Code by:\n\nOpening the command palette (Ctrl/⌘ + Shift + P)\nSearching for \"TypeScript: Select TypeScript Version\"\nSelecting \"Use Workspace Version\"\n\nSee the TypeScript reference page for more information.\n\nSet up linting\n\nNext.js supports linting with either ESLint or Biome. Choose a linter and run it directly via package.json scripts.\n\nUse ESLint (comprehensive rules):\npackage.json\n{\n  \"scripts\": {\n    \"lint\": \"eslint\",\n    \"lint:fix\": \"eslint --fix\"\n  }\n}\nOr use Biome (fast linter + formatter):\npackage.json\n{\n  \"scripts\": {\n    \"lint\": \"biome check\",\n    \"format\": \"biome format --write\"\n  }\n}\n\nIf your project previously used next lint, migrate your scripts to the ESLint CLI with the codemod:\n\nTerminal\nnpx @next/codemod@canary next-lint-to-eslint-cli .\n\nIf you use ESLint, create an explicit config (recommended eslint.config.mjs). ESLint supports both the legacy .eslintrc.* and the newer eslint.config.mjs formats\n. See the ESLint API reference for a recommended setup.\n\nGood to know: Starting with Next.js 16, next build no longer runs the linter automatically. Instead, you can run your linter through NPM scripts.\n\nSee the ESLint Plugin page for more information.\n\nSet up Absolute Imports and Module Path Aliases\n\nNext.js has in-built support for the \"paths\" and \"baseUrl\" options of tsconfig.json and jsconfig.json files.\n\nThese options allow you to alias project directories to absolute paths, making it easier and cleaner to import modules. For example:\n\n// Before\nimport { Button } from '../../../components/button'\n \n// After\nimport { Button } from '@/components/button'\n\nTo configure absolute imports, add the baseUrl configuration option to your tsconfig.json or jsconfig.json file. For example:\n\ntsconfig.json or jsconfig.json\n{\n  \"compilerOptions\": {\n    \"baseUrl\": \"src/\"\n  }\n}\n\nIn addition to configuring the baseUrl path, you can use the \"paths\" option to \"alias\" module paths.\n\nFor example, the following configuration maps @/components/* to components/*:\n\ntsconfig.json or jsconfig.json\n{\n  \"compilerOptions\": {\n    \"baseUrl\": \"src/\",\n    \"paths\": {\n      \"@/styles/*\": [\"styles/*\"],\n      \"@/components/*\": [\"components/*\"]\n    }\n  }\n}\n\nEach of the \"paths\" are relative to the baseUrl location.\n\nPrevious\nGetting Started\nNext\nProject Structure\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Layouts and Pages | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/layouts-and-pages",
    "html": "App Router\nGetting Started\nLayouts and Pages\nCopy page\nLayouts and Pages\n\nNext.js uses file-system based routing, meaning you can use folders and files to define routes. This page will guide you through how to create layouts and pages, and link between them.\n\nCreating a page\n\nA page is UI that is rendered on a specific route. To create a page, add a page file inside the app directory and default export a React component. For example, to create an index page (/):\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Page() {\n  return <h1>Hello Next.js!</h1>\n}\nCreating a layout\n\nA layout is UI that is shared between multiple pages. On navigation, layouts preserve state, remain interactive, and do not rerender.\n\nYou can define a layout by default exporting a React component from a layout file. The component should accept a children prop which can be a page or another layout.\n\nFor example, to create a layout that accepts your index page as child, add a layout file inside the app directory:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function DashboardLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body>\n        {/* Layout UI */}\n        {/* Place children where you want to render a page or nested layout */}\n        <main>{children}</main>\n      </body>\n    </html>\n  )\n}\n\nThe layout above is called a root layout because it's defined at the root of the app directory. The root layout is required and must contain html and body tags.\n\nCreating a nested route\n\nA nested route is a route composed of multiple URL segments. For example, the /blog/[slug] route is composed of three segments:\n\n/ (Root Segment)\nblog (Segment)\n[slug] (Leaf Segment)\n\nIn Next.js:\n\nFolders are used to define the route segments that map to URL segments.\nFiles (like page and layout) are used to create UI that is shown for a segment.\n\nTo create nested routes, you can nest folders inside each other. For example, to add a route for /blog, create a folder called blog in the app directory. Then, to make /blog publicly accessible, add a page.tsx file:\n\napp/blog/page.tsx\nTypeScript\nJavaScript\nTypeScript\n// Dummy imports\nimport { getPosts } from '@/lib/posts'\nimport { Post } from '@/ui/post'\n \nexport default async function Page() {\n  const posts = await getPosts()\n \n  return (\n    <ul>\n      {posts.map((post) => (\n        <Post key={post.id} post={post} />\n      ))}\n    </ul>\n  )\n}\n\nYou can continue nesting folders to create nested routes. For example, to create a route for a specific blog post, create a new [slug] folder inside blog and add a page file:\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nfunction generateStaticParams() {}\n \nexport default function Page() {\n  return <h1>Hello, Blog Post Page!</h1>\n}\n\nWrapping a folder name in square brackets (e.g. [slug]) creates a dynamic route segment which is used to generate multiple pages from data. e.g. blog posts, product pages, etc.\n\nNesting layouts\n\nBy default, layouts in the folder hierarchy are also nested, which means they wrap child layouts via their children prop. You can nest layouts by adding layout inside specific route segments (folders).\n\nFor example, to create a layout for the /blog route, add a new layout file inside the blog folder.\n\napp/blog/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function BlogLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return <section>{children}</section>\n}\n\nIf you were to combine the two layouts above, the root layout (app/layout.js) would wrap the blog layout (app/blog/layout.js), which would wrap the blog (app/blog/page.js) and blog post page (app/blog/[slug]/page.js).\n\nCreating a dynamic segment\n\nDynamic segments allow you to create routes that are generated from data. For example, instead of manually creating a route for each individual blog post, you can create a dynamic segment to generate the routes based on blog post data.\n\nTo create a dynamic segment, wrap the segment (folder) name in square brackets: [segmentName]. For example, in the app/blog/[slug]/page.tsx route, the [slug] is the dynamic segment.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function BlogPostPage({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  const post = await getPost(slug)\n \n  return (\n    <div>\n      <h1>{post.title}</h1>\n      <p>{post.content}</p>\n    </div>\n  )\n}\n\nLearn more about Dynamic Segments and the params props.\n\nNested layouts within Dynamic Segments, can also access the params props.\n\nRendering with search params\n\nIn a Server Component page, you can access search parameters using the searchParams prop:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page({\n  searchParams,\n}: {\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}) {\n  const filters = (await searchParams).filters\n}\n\nUsing searchParams opts your page into dynamic rendering because it requires a incoming request to read the search parameters from.\n\nClient Components can read search params using the useSearchParams hook.\n\nLearn more about useSearchParams in statically rendered and dynamically rendered routes.\n\nWhat to use and when\nUse the searchParams prop when you need search parameters to load data for the page (e.g. pagination, filtering from a database).\nUse useSearchParams when search parameters are used only on the client (e.g. filtering a list already loaded via props).\nAs a small optimization, you can use new URLSearchParams(window.location.search) in callbacks or event handlers to read search params without triggering re-renders.\nLinking between pages\n\nYou can use the <Link> component to navigate between routes. <Link> is a built-in Next.js component that extends the HTML <a> tag to provide prefetching and client-side navigation.\n\nFor example, to generate a list of blog posts, import <Link> from next/link and pass a href prop to the component:\n\napp/ui/post.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default async function Post({ post }) {\n  const posts = await getPosts()\n \n  return (\n    <ul>\n      {posts.map((post) => (\n        <li key={post.slug}>\n          <Link href={`/blog/${post.slug}`}>{post.title}</Link>\n        </li>\n      ))}\n    </ul>\n  )\n}\n\nGood to know: <Link> is the primary way to navigate between routes in Next.js. You can also use the useRouter hook for more advanced navigation.\n\nRoute Props Helpers\n\nNext.js exposes utility types that infer params and named slots from your route structure:\n\nPageProps: Props for page components, including params and searchParams.\nLayoutProps: Props for layout components, including children and any named slots (e.g. folders like @analytics).\n\nThese are globally available helpers, generated when running either next dev, next build or next typegen.\n\napp/blog/[slug]/page.tsx\nexport default async function Page(props: PageProps<'/blog/[slug]'>) {\n  const { slug } = await props.params\n  return <h1>Blog post: {slug}</h1>\n}\napp/dashboard/layout.tsx\nexport default function Layout(props: LayoutProps<'/dashboard'>) {\n  return (\n    <section>\n      {props.children}\n      {/* If you have app/dashboard/@analytics, it appears as a typed slot: */}\n      {/* {props.analytics} */}\n    </section>\n  )\n}\n\nGood to know\n\nStatic routes resolve params to {}.\nPageProps, LayoutProps are global helpers — no imports required.\nTypes are generated during next dev, next build or next typegen.\nAPI Reference\nLearn more about the features mentioned in this page by reading the API Reference.\nLinking and Navigating\nLearn how the built-in navigation optimizations work, including prefetching, prerendering, and client-side navigation, and how to optimize navigation for dynamic routes and slow networks.\nlayout.js\nAPI reference for the layout.js file.\npage.js\nAPI reference for the page.js file.\nLink Component\nEnable fast client-side navigation with the built-in `next/link` component.\nDynamic Segments\nDynamic Route Segments can be used to programmatically generate route segments from dynamic data.\nPrevious\nProject Structure\nNext\nLinking and Navigating\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Linking and Navigating | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/linking-and-navigating",
    "html": "App Router\nGetting Started\nLinking and Navigating\nCopy page\nLinking and Navigating\n\nIn Next.js, routes are rendered on the server by default. This often means the client has to wait for a server response before a new route can be shown. Next.js comes with built-in prefetching, streaming, and client-side transitions ensuring navigation stays fast and responsive.\n\nThis guide explains how navigation works in Next.js and how you can optimize it for dynamic routes and slow networks.\n\nHow navigation works\n\nTo understand how navigation works in Next.js, it helps to be familiar with the following concepts:\n\nServer Rendering\nPrefetching\nStreaming\nClient-side transitions\nServer Rendering\n\nIn Next.js, Layouts and Pages are React Server Components\n by default. On initial and subsequent navigations, the Server Component Payload is generated on the server before being sent to the client.\n\nThere are two types of server rendering, based on when it happens:\n\nStatic Rendering (or Prerendering) happens at build time or during revalidation and the result is cached.\nDynamic Rendering happens at request time in response to a client request.\n\nThe trade-off of server rendering is that the client must wait for the server to respond before the new route can be shown. Next.js addresses this delay by prefetching routes the user is likely to visit and performing client-side transitions.\n\nGood to know: HTML is also generated for the initial visit.\n\nPrefetching\n\nPrefetching is the process of loading a route in the background before the user navigates to it. This makes navigation between routes in your application feel instant, because by the time a user clicks on a link, the data to render the next route is already available client side.\n\nNext.js automatically prefetches routes linked with the <Link> component when they enter the user's viewport.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Link from 'next/link'\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return (\n    <html>\n      <body>\n        <nav>\n          {/* Prefetched when the link is hovered or enters the viewport */}\n          <Link href=\"/blog\">Blog</Link>\n          {/* No prefetching */}\n          <a href=\"/contact\">Contact</a>\n        </nav>\n        {children}\n      </body>\n    </html>\n  )\n}\n\nHow much of the route is prefetched depends on whether it's static or dynamic:\n\nStatic Route: the full route is prefetched.\nDynamic Route: prefetching is skipped, or the route is partially prefetched if loading.tsx is present.\n\nBy skipping or partially prefetching dynamic routes, Next.js avoids unnecessary work on the server for routes the users may never visit. However, waiting for a server response before navigation can give the users the impression that the app is not responding.\n\nTo improve the navigation experience to dynamic routes, you can use streaming.\n\nStreaming\n\nStreaming allows the server to send parts of a dynamic route to the client as soon as they're ready, rather than waiting for the entire route to be rendered. This means users see something sooner, even if parts of the page are still loading.\n\nFor dynamic routes, it means they can be partially prefetched. That is, shared layouts and loading skeletons can be requested ahead of time.\n\nTo use streaming, create a loading.tsx in your route folder:\n\napp/dashboard/loading.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Loading() {\n  // Add fallback UI that will be shown while the route is loading.\n  return <LoadingSkeleton />\n}\n\nBehind the scenes, Next.js will automatically wrap the page.tsx contents in a <Suspense> boundary. The prefetched fallback UI will be shown while the route is loading, and swapped for the actual content once ready.\n\nGood to know: You can also use <Suspense>\n to create loading UI for nested components.\n\nBenefits of loading.tsx:\n\nImmediate navigation and visual feedback for the user.\nShared layouts remain interactive and navigation is interruptible.\nImproved Core Web Vitals: TTFB\n, FCP\n, and TTI\n.\n\nTo further improve the navigation experience, Next.js performs a client-side transition with the <Link> component.\n\nClient-side transitions\n\nTraditionally, navigation to a server-rendered page triggers a full page load. This clears state, resets scroll position, and blocks interactivity.\n\nNext.js avoids this with client-side transitions using the <Link> component. Instead of reloading the page, it updates the content dynamically by:\n\nKeeping any shared layouts and UI.\nReplacing the current page with the prefetched loading state or a new page if available.\n\nClient-side transitions are what makes a server-rendered apps feel like client-rendered apps. And when paired with prefetching and streaming, it enables fast transitions, even for dynamic routes.\n\nWhat can make transitions slow?\n\nThese Next.js optimizations make navigation fast and responsive. However, under certain conditions, transitions can still feel slow. Here are some common causes and how to improve the user experience:\n\nDynamic routes without loading.tsx\n\nWhen navigating to a dynamic route, the client must wait for the server response before showing the result. This can give the users the impression that the app is not responding.\n\nWe recommend adding loading.tsx to dynamic routes to enable partial prefetching, trigger immediate navigation, and display a loading UI while the route renders.\n\napp/blog/[slug]/loading.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Loading() {\n  return <LoadingSkeleton />\n}\n\nGood to know: In development mode, you can use the Next.js Devtools to identify if the route is static or dynamic. See devIndicators for more information.\n\nDynamic segments without generateStaticParams\n\nIf a dynamic segment could be prerendered but isn't because it's missing generateStaticParams, the route will fallback to dynamic rendering at request time.\n\nEnsure the route is statically generated at build time by adding generateStaticParams:\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport async function generateStaticParams() {\n  const posts = await fetch('https://.../posts').then((res) => res.json())\n \n  return posts.map((post) => ({\n    slug: post.slug,\n  }))\n}\n \nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ slug: string }>\n}) {\n  const { slug } = await params\n  // ...\n}\nSlow networks\n\nOn slow or unstable networks, prefetching may not finish before the user clicks a link. This can affect both static and dynamic routes. In these cases, the loading.js fallback may not appear immediately because it hasn't been prefetched yet.\n\nTo improve perceived performance, you can use the useLinkStatus hook to show immediate feedback while the transition is in progress.\n\napp/ui/loading-indicator.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useLinkStatus } from 'next/link'\n \nexport default function LoadingIndicator() {\n  const { pending } = useLinkStatus()\n  return (\n    <span aria-hidden className={`link-hint ${pending ? 'is-pending' : ''}`} />\n  )\n}\n\nYou can \"debounce\" the hint by adding an initial animation delay (e.g. 100ms) and starting as invisible (e.g. opacity: 0). This means the loading indicator will only be shown if the navigation takes longer than the specified delay. See the useLinkStatus reference for a CSS example.\n\nGood to know: You can use other visual feedback patterns like a progress bar. View an example here\n.\n\nDisabling prefetching\n\nYou can opt out of prefetching by setting the prefetch prop to false on the <Link> component. This is useful to avoid unnecessary usage of resources when rendering large lists of links (e.g. an infinite scroll table).\n\n<Link prefetch={false} href=\"/blog\">\n  Blog\n</Link>\n\nHowever, disabling prefetching comes with trade-offs:\n\nStatic routes will only be fetched when the user clicks the link.\nDynamic routes will need to be rendered on the server first before the client can navigate to it.\n\nTo reduce resource usage without fully disabling prefetch, you can prefetch only on hover. This limits prefetching to routes the user is more likely to visit, rather than all links in the viewport.\n\napp/ui/hover-prefetch-link.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport Link from 'next/link'\nimport { useState } from 'react'\n \nfunction HoverPrefetchLink({\n  href,\n  children,\n}: {\n  href: string\n  children: React.ReactNode\n}) {\n  const [active, setActive] = useState(false)\n \n  return (\n    <Link\n      href={href}\n      prefetch={active ? null : false}\n      onMouseEnter={() => setActive(true)}\n    >\n      {children}\n    </Link>\n  )\n}\nHydration not completed\n\n<Link> is a Client Component and must be hydrated before it can prefetch routes. On the initial visit, large JavaScript bundles can delay hydration, preventing prefetching from starting right away.\n\nReact mitigates this with Selective Hydration and you can further improve this by:\n\nUsing the @next/bundle-analyzer plugin to identify and reduce bundle size by removing large dependencies.\nMoving logic from the client to the server where possible. See the Server and Client Components docs for guidance.\nExamples\nNative History API\n\nNext.js allows you to use the native window.history.pushState\n and window.history.replaceState\n methods to update the browser's history stack without reloading the page.\n\npushState and replaceState calls integrate into the Next.js Router, allowing you to sync with usePathname and useSearchParams.\n\nwindow.history.pushState\n\nUse it to add a new entry to the browser's history stack. The user can navigate back to the previous state. For example, to sort a list of products:\n\n'use client'\n \nimport { useSearchParams } from 'next/navigation'\n \nexport default function SortProducts() {\n  const searchParams = useSearchParams()\n \n  function updateSorting(sortOrder: string) {\n    const params = new URLSearchParams(searchParams.toString())\n    params.set('sort', sortOrder)\n    window.history.pushState(null, '', `?${params.toString()}`)\n  }\n \n  return (\n    <>\n      <button onClick={() => updateSorting('asc')}>Sort Ascending</button>\n      <button onClick={() => updateSorting('desc')}>Sort Descending</button>\n    </>\n  )\n}\nwindow.history.replaceState\n\nUse it to replace the current entry on the browser's history stack. The user is not able to navigate back to the previous state. For example, to switch the application's locale:\n\n'use client'\n \nimport { usePathname } from 'next/navigation'\n \nexport function LocaleSwitcher() {\n  const pathname = usePathname()\n \n  function switchLocale(locale: string) {\n    // e.g. '/en/about' or '/fr/contact'\n    const newPath = `/${locale}${pathname}`\n    window.history.replaceState(null, '', newPath)\n  }\n \n  return (\n    <>\n      <button onClick={() => switchLocale('en')}>English</button>\n      <button onClick={() => switchLocale('fr')}>French</button>\n    </>\n  )\n}\nNext Steps\nLink Component\nEnable fast client-side navigation with the built-in `next/link` component.\nloading.js\nAPI reference for the loading.js file.\nPrefetching\nLearn how to configure prefetching in Next.js\nPrevious\nLayouts and Pages\nNext\nServer and Client Components\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Server and Client Components | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/server-and-client-components",
    "html": "App Router\nGetting Started\nServer and Client Components\nCopy page\nServer and Client Components\n\nBy default, layouts and pages are Server Components\n, which lets you fetch data and render parts of your UI on the server, optionally cache the result, and stream it to the client. When you need interactivity or browser APIs, you can use Client Components\n to layer in functionality.\n\nThis page explains how Server and Client Components work in Next.js and when to use them, with examples of how to compose them together in your application.\n\nWhen to use Server and Client Components?\n\nThe client and server environments have different capabilities. Server and Client components allow you to run logic in each environment depending on your use case.\n\nUse Client Components when you need:\n\nState\n and event handlers\n. E.g. onClick, onChange.\nLifecycle logic\n. E.g. useEffect.\nBrowser-only APIs. E.g. localStorage, window, Navigator.geolocation, etc.\nCustom hooks\n.\n\nUse Server Components when you need:\n\nFetch data from databases or APIs close to the source.\nUse API keys, tokens, and other secrets without exposing them to the client.\nReduce the amount of JavaScript sent to the browser.\nImprove the First Contentful Paint (FCP)\n, and stream content progressively to the client.\n\nFor example, the <Page> component is a Server Component that fetches data about a post, and passes it as props to the <LikeButton> which handles client-side interactivity.\n\napp/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport LikeButton from '@/app/ui/like-button'\nimport { getPost } from '@/lib/data'\n \nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n  const post = await getPost(id)\n \n  return (\n    <div>\n      <main>\n        <h1>{post.title}</h1>\n        {/* ... */}\n        <LikeButton likes={post.likes} />\n      </main>\n    </div>\n  )\n}\napp/ui/like-button.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useState } from 'react'\n \nexport default function LikeButton({ likes }: { likes: number }) {\n  // ...\n}\nHow do Server and Client Components work in Next.js?\nOn the server\n\nOn the server, Next.js uses React's APIs to orchestrate rendering. The rendering work is split into chunks, by individual route segments (layouts and pages):\n\nServer Components are rendered into a special data format called the React Server Component Payload (RSC Payload).\nClient Components and the RSC Payload are used to pre-render HTML.\n\nWhat is the React Server Component Payload (RSC)?\n\nThe RSC Payload is a compact binary representation of the rendered React Server Components tree. It's used by React on the client to update the browser's DOM. The RSC Payload contains:\n\nThe rendered result of Server Components\nPlaceholders for where Client Components should be rendered and references to their JavaScript files\nAny props passed from a Server Component to a Client Component\nOn the client (first load)\n\nThen, on the client:\n\nHTML is used to immediately show a fast non-interactive preview of the route to the user.\nRSC Payload is used to reconcile the Client and Server Component trees.\nJavaScript is used to hydrate Client Components and make the application interactive.\n\nWhat is hydration?\n\nHydration is React's process for attaching event handlers\n to the DOM, to make the static HTML interactive.\n\nSubsequent Navigations\n\nOn subsequent navigations:\n\nThe RSC Payload is prefetched and cached for instant navigation.\nClient Components are rendered entirely on the client, without the server-rendered HTML.\nExamples\nUsing Client Components\n\nYou can create a Client Component by adding the \"use client\"\n directive at the top of the file, above your imports.\n\napp/ui/counter.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useState } from 'react'\n \nexport default function Counter() {\n  const [count, setCount] = useState(0)\n \n  return (\n    <div>\n      <p>{count} likes</p>\n      <button onClick={() => setCount(count + 1)}>Click me</button>\n    </div>\n  )\n}\n\n\"use client\" is used to declare a boundary between the Server and Client module graphs (trees).\n\nOnce a file is marked with \"use client\", all its imports and child components are considered part of the client bundle. This means you don't need to add the directive to every component that is intended for the client.\n\nReducing JS bundle size\n\nTo reduce the size of your client JavaScript bundles, add 'use client' to specific interactive components instead of marking large parts of your UI as Client Components.\n\nFor example, the <Layout> component contains mostly static elements like a logo and navigation links, but includes an interactive search bar. <Search /> is interactive and needs to be a Client Component, however, the rest of the layout can remain a Server Component.\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\n// Client Component\nimport Search from './search'\n// Server Component\nimport Logo from './logo'\n \n// Layout is a Server Component by default\nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return (\n    <>\n      <nav>\n        <Logo />\n        <Search />\n      </nav>\n      <main>{children}</main>\n    </>\n  )\n}\napp/ui/search.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nexport default function Search() {\n  // ...\n}\nPassing data from Server to Client Components\n\nYou can pass data from Server Components to Client Components using props.\n\napp/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport LikeButton from '@/app/ui/like-button'\nimport { getPost } from '@/lib/data'\n \nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n  const post = await getPost(id)\n \n  return <LikeButton likes={post.likes} />\n}\napp/ui/like-button.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nexport default function LikeButton({ likes }: { likes: number }) {\n  // ...\n}\n\nAlternatively, you can stream data from a Server Component to a Client Component with the use Hook\n. See an example.\n\nGood to know: Props passed to Client Components need to be serializable\n by React.\n\nInterleaving Server and Client Components\n\nYou can pass Server Components as a prop to a Client Component. This allows you to visually nest server-rendered UI within Client components.\n\nA common pattern is to use children to create a slot in a <ClientComponent>. For example, a <Cart> component that fetches data on the server, inside a <Modal> component that uses client state to toggle visibility.\n\napp/ui/modal.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nexport default function Modal({ children }: { children: React.ReactNode }) {\n  return <div>{children}</div>\n}\n\nThen, in a parent Server Component (e.g.<Page>), you can pass a <Cart> as the child of the <Modal>:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Modal from './ui/modal'\nimport Cart from './ui/cart'\n \nexport default function Page() {\n  return (\n    <Modal>\n      <Cart />\n    </Modal>\n  )\n}\n\nIn this pattern, all Server Components will be rendered on the server ahead of time, including those as props. The resulting RSC payload will contain references of where Client Components should be rendered within the component tree.\n\nContext providers\n\nReact context\n is commonly used to share global state like the current theme. However, React context is not supported in Server Components.\n\nTo use context, create a Client Component that accepts children:\n\napp/theme-provider.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { createContext } from 'react'\n \nexport const ThemeContext = createContext({})\n \nexport default function ThemeProvider({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return <ThemeContext.Provider value=\"dark\">{children}</ThemeContext.Provider>\n}\n\nThen, import it into a Server Component (e.g. layout):\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport ThemeProvider from './theme-provider'\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html>\n      <body>\n        <ThemeProvider>{children}</ThemeProvider>\n      </body>\n    </html>\n  )\n}\n\nYour Server Component will now be able to directly render your provider, and all other Client Components throughout your app will be able to consume this context.\n\nGood to know: You should render providers as deep as possible in the tree – notice how ThemeProvider only wraps {children} instead of the entire <html> document. This makes it easier for Next.js to optimize the static parts of your Server Components.\n\nThird-party components\n\nWhen using a third-party component that relies on client-only features, you can wrap it in a Client Component to ensure it works as expected.\n\nFor example, the <Carousel /> can be imported from the acme-carousel package. This component uses useState, but it doesn't yet have the \"use client\" directive.\n\nIf you use <Carousel /> within a Client Component, it will work as expected:\n\napp/gallery.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useState } from 'react'\nimport { Carousel } from 'acme-carousel'\n \nexport default function Gallery() {\n  const [isOpen, setIsOpen] = useState(false)\n \n  return (\n    <div>\n      <button onClick={() => setIsOpen(true)}>View pictures</button>\n      {/* Works, since Carousel is used within a Client Component */}\n      {isOpen && <Carousel />}\n    </div>\n  )\n}\n\nHowever, if you try to use it directly within a Server Component, you'll see an error. This is because Next.js doesn't know <Carousel /> is using client-only features.\n\nTo fix this, you can wrap third-party components that rely on client-only features in your own Client Components:\n\napp/carousel.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { Carousel } from 'acme-carousel'\n \nexport default Carousel\n\nNow, you can use <Carousel /> directly within a Server Component:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Carousel from './carousel'\n \nexport default function Page() {\n  return (\n    <div>\n      <p>View pictures</p>\n      {/*  Works, since Carousel is a Client Component */}\n      <Carousel />\n    </div>\n  )\n}\n\nAdvice for Library Authors\n\nIf you’re building a component library, add the \"use client\" directive to entry points that rely on client-only features. This lets your users import components into Server Components without needing to create wrappers.\n\nIt's worth noting some bundlers might strip out \"use client\" directives. You can find an example of how to configure esbuild to include the \"use client\" directive in the React Wrap Balancer\n and Vercel Analytics\n repositories.\n\nPreventing environment poisoning\n\nJavaScript modules can be shared between both Server and Client Components modules. This means it's possible to accidentally import server-only code into the client. For example, consider the following function:\n\nlib/data.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function getData() {\n  const res = await fetch('https://external-service.com/data', {\n    headers: {\n      authorization: process.env.API_KEY,\n    },\n  })\n \n  return res.json()\n}\n\nThis function contains an API_KEY that should never be exposed to the client.\n\nIn Next.js, only environment variables prefixed with NEXT_PUBLIC_ are included in the client bundle. If variables are not prefixed, Next.js replaces them with an empty string.\n\nAs a result, even though getData() can be imported and executed on the client, it won't work as expected.\n\nTo prevent accidental usage in Client Components, you can use the server-only package\n.\n\nThen, import the package into a file that contains server-only code:\n\nlib/data.js\nimport 'server-only'\n \nexport async function getData() {\n  const res = await fetch('https://external-service.com/data', {\n    headers: {\n      authorization: process.env.API_KEY,\n    },\n  })\n \n  return res.json()\n}\n\nNow, if you try to import the module into a Client Component, there will be a build-time error.\n\nThe corresponding client-only package\n can be used to mark modules that contain client-only logic like code that accesses the window object.\n\nIn Next.js, installing server-only or client-only is optional. However, if your linting rules flag extraneous dependencies, you may install them to avoid issues.\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm add server-only\n\nNext.js handles server-only and client-only imports internally to provide clearer error messages when a module is used in the wrong environment. The contents of these packages from NPM are not used by Next.js.\n\nNext.js also provides its own type declarations for server-only and client-only, for TypeScript configurations where noUncheckedSideEffectImports\n is active.\n\nNext Steps\nLearn more about the APIs mentioned in this page.\nuse client\nLearn how to use the use client directive to render a component on the client.\nPrevious\nLinking and Navigating\nNext\nCache Components\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Cache Components | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/cache-components",
    "html": "App Router\nGetting Started\nCache Components\nCopy page\nCache Components\n\nCache Components is a new approach to rendering and caching in Next.js that provides fine-grained control over what gets cached and when, while ensuring a great user experience through Partial Prerendering (PPR).\n\nCache Components\n\nWhen developing dynamic applications, you have to balance two primary approaches:\n\nFully static pages load fast but can't show personalized or real-time data\nFully dynamic pages can show fresh data but require rendering everything on each request, leading to slower initial loads\n\nWith Cache Components enabled, Next.js treats all routes as dynamic by default. Every request renders with the latest available data. However, most pages are made up of both static and dynamic parts, and not all dynamic data needs to be resolved from source on every request.\n\nCache Components allows you to mark data, and even parts of your UI as cacheable, which includes them in the pre-render pass alongside static parts of the page.\n\nBefore Cache Components, Next.js tried to statically optimize entire pages automatically, which could lead to unexpected behavior when adding dynamic code.\n\nCache Components implements Partial Prerendering (PPR), and use cache to give you the best of both worlds:\n\nWhen a user visits a route:\n\nThe server sends a static shell containing cached content, ensuring a fast initial load\nDynamic sections wrapped in Suspense boundaries display fallback UI in the shell\nOnly the dynamic parts render to replace their fallbacks, streaming in parallel as they become ready\nYou can include otherwise-dynamic data in the initial shell by caching it with use cache\n\n🎥 Watch: Why PPR and how it works → YouTube (10 minutes)\n.\n\nHow it works\n\nGood to know: Cache Components is an opt-in feature. Enable it by setting the cacheComponents flag to true in your Next config file. See Enabling Cache Components for more details.\n\nCache Components gives you three key tools to control rendering:\n\n1. Suspense for runtime data\n\nSome data is only available at runtime when an actual user makes a request. APIs like cookies, headers, and searchParams access request-specific information. Wrap components using these APIs in Suspense boundaries so the rest of the page can be pre-rendered as a static shell.\n\nRuntime APIs include:\n\ncookies\nheaders\nsearchParams prop\nparams prop - This is runtime data unless you provide at least one example value through generateStaticParams. When provided, those specific param values are treated as static for prerendered paths, while other values remain runtime\n2. Suspense for dynamic data\n\nDynamic data like fetch calls or database queries (db.query(...)) can change between requests but isn't user-specific. The connection API is meta-dynamic—it represents waiting for a user navigation even though there's no actual data to return. Wrap components that use these in Suspense boundaries to enable streaming.\n\nDynamic data patterns include:\n\nfetch requests\nDatabase queries\nconnection\n3. Cached data with use cache\n\nAdd use cache to any Server Component to make it cached and include it in the pre-rendered shell. You cannot use runtime APIs from inside a cached component. You can also mark utility functions as use cache and call them from Server Components.\n\nexport async function getProducts() {\n  'use cache'\n  const data = await db.query('SELECT * FROM products')\n  return data\n}\nUsing Suspense boundaries\n\nReact Suspense\n boundaries let you define what fallback UI to use when it wraps dynamic or runtime data.\n\nContent outside the boundary, including the fallback UI, is pre-rendered as a static shell, while content inside the boundary streams in when ready.\n\nHere's how to use Suspense with Cache Components:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Suspense } from 'react'\n \nexport default function Page() {\n  return (\n    <>\n      <h1>This will be pre-rendered</h1>\n      <Suspense fallback={<Skeleton />}>\n        <DynamicContent />\n      </Suspense>\n    </>\n  )\n}\n \nasync function DynamicContent() {\n  const res = await fetch('http://api.cms.com/posts')\n  const { posts } = await res.json()\n  return <div>{/* ... */}</div>\n}\n\nAt build time, Next.js pre-renders the static content and the fallback UI, while the dynamic content is postponed until a user requests the route.\n\nGood to know: Wrapping a component in Suspense doesn't make it dynamic; your API usage does. Suspense acts as a boundary that encapsulates dynamic content and enables streaming.\n\nMissing Suspense boundaries\n\nCache Components enforces that dynamic code must be wrapped in a Suspense boundary. If you forget, you'll see the Uncached data was accessed outside of <Suspense>\n error:\n\nUncached data was accessed outside of <Suspense>\n\nThis delays the entire page from rendering, resulting in a slow user experience. Next.js uses this error to ensure your app loads instantly on every navigation.\n\nTo fix this, you can either:\n\nWrap the component in a <Suspense> boundary. This allows Next.js to stream its contents to the user as soon as it's ready, without blocking the rest of the app.\n\nor\n\nMove the asynchronous await into a Cache Component(\"use cache\"). This allows Next.js to statically prerender the component as part of the HTML document, so it's instantly visible to the user.\n\nNote that request-specific information, such as params, cookies, and headers, is not available during static prerendering, so it must be wrapped in <Suspense>.\n\nThis error helps prevent a situation where, instead of getting a static shell instantly, users would hit a blocking runtime render with nothing to show. To fix it, add a Suspense boundary or use use cache to cache the work instead.\n\nHow streaming works\n\nStreaming splits the route into chunks and progressively streams them to the client as they become ready. This allows the user to see parts of the page immediately, before the entire content has finished rendering.\n\nWith partial pre-rendering, the initial UI can be sent immediately to the browser while the dynamic parts render. This decreases time to UI and may decrease total request time depending on how much of your UI is pre-rendered.\n\nTo reduce network overhead, the full response, including static HTML and streamed dynamic parts, is sent in a single HTTP request. This avoids extra round-trips and improves both initial load and overall performance.\n\nUsing use cache\n\nWhile Suspense boundaries manage dynamic content, the use cache directive is available for caching data or computations that don't change often.\n\nBasic usage\n\nAdd use cache to cache a page, component, or async function, and define a lifetime with cacheLife:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cacheLife } from 'next/cache'\n \nexport default async function Page() {\n  'use cache'\n  cacheLife('hours')\n  // fetch or compute\n  return <div>...</div>\n}\nCaveats\n\nWhen using use cache, keep these constraints in mind:\n\nArguments must be serializable\n\nLike Server Actions, arguments to cached functions must be serializable. This means you can pass primitives, plain objects, and arrays, but not class instances, functions, or other complex types.\n\nAccepting unserializable values without introspection\n\nYou can accept unserializable values as arguments as long as you don't introspect them. However, you can return them. This allows patterns like cached components that accept Server or Client Components as children:\n\napp/cached-wrapper.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ReactNode } from 'react'\n \nexport async function CachedWrapper({ children }: { children: ReactNode }) {\n  'use cache'\n  // Don't introspect children, just pass it through\n  return (\n    <div className=\"wrapper\">\n      <header>Cached Header</header>\n      {children}\n    </div>\n  )\n}\nAvoid passing dynamic inputs\n\nYou must not pass dynamic or runtime data into use cache functions unless you avoid introspecting them. Passing values from cookies(), headers(), or other runtime APIs as arguments will cause errors, as the cache key cannot be determined at pre-render time.\n\nTagging and revalidating\n\nTag cached data with cacheTag and revalidate it after mutations using updateTag in Server Actions for immediate updates, or revalidateTag delay in updates are acceptable.\n\nWith updateTag\n\nUse updateTag when you need to expire and immediately refresh cached data within the same request:\n\napp/actions.ts\nimport { cacheTag, updateTag } from 'next/cache'\n \nexport async function getCart() {\n  'use cache'\n  cacheTag('cart')\n  // fetch data\n}\n \nexport async function updateCart(itemId: string) {\n  'use server'\n  // write data using the itemId\n  // update the user cart\n  updateTag('cart')\n}\nWith revalidateTag\n\nUse revalidateTag when you want to invalidate only properly tagged cached entries with stale-while-revalidate behavior. This is ideal for static content that can tolerate eventual consistency.\n\napp/actions.ts\nimport { cacheTag, revalidateTag } from 'next/cache'\n \nexport async function getPosts() {\n  'use cache'\n  cacheTag('posts')\n  // fetch data\n}\n \nexport async function createPost(post: FormData) {\n  'use server'\n  // write data using the FormData\n  revalidateTag('posts', 'max')\n}\n\nFor more detailed explanation and usage examples, see the use cache API reference.\n\nEnabling Cache Components\n\nYou can enable Cache Components (which includes PPR) by adding the cacheComponents option to your Next config file:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst nextConfig: NextConfig = {\n  cacheComponents: true,\n}\n \nexport default nextConfig\nEffect on route segment config\n\nWhen Cache Components is enabled, several route segment config options are no longer needed or supported. Here's what changes and how to migrate:\n\ndynamic = \"force-dynamic\"\n\nNot needed. All pages are dynamic by default with Cache Components enabled, so this configuration is unnecessary.\n\n// Before - No longer needed\nexport const dynamic = 'force-dynamic'\n \nexport default function Page() {\n  return <div>...</div>\n}\n// After - Just remove it, pages are dynamic by default\nexport default function Page() {\n  return <div>...</div>\n}\ndynamic = \"force-static\"\n\nReplace with use cache. You must add use cache to each Layout and Page for the associated route instead.\n\nNote: force-static previously allowed the use of runtime APIs like cookies(), but this is no longer supported. If you add use cache and see an error related to runtime data, you must remove the use of runtime APIs.\n\n// Before\nexport const dynamic = 'force-static'\n \nexport default async function Page() {\n  const data = await fetch('https://api.example.com/data')\n  return <div>...</div>\n}\n// After - Use 'use cache' instead\nexport default async function Page() {\n  'use cache'\n  const data = await fetch('https://api.example.com/data')\n  return <div>...</div>\n}\nrevalidate\n\nReplace with cacheLife. Use the cacheLife function to define cache duration instead of the route segment config.\n\n// Before\nexport const revalidate = 3600 // 1 hour\n \nexport default async function Page() {\n  return <div>...</div>\n}\n// After - Use cacheLife\nimport { cacheLife } from 'next/cache'\n \nexport default async function Page() {\n  'use cache'\n  cacheLife('hours')\n  return <div>...</div>\n}\nfetchCache\n\nNot needed. With use cache, all data fetching within a cached scope is automatically cached, making fetchCache unnecessary.\n\n// Before\nexport const fetchCache = 'force-cache'\n// After - Use 'use cache' to control caching behavior\nexport default async function Page() {\n  'use cache'\n  // All fetches here are cached\n  return <div>...</div>\n}\nruntime = 'edge'\n\nNot supported. Cache Components requires Node.js runtime and will throw errors with Edge Runtime.\n\nBefore vs. after Cache Components\n\nUnderstanding how Cache Components changes your mental model:\n\nBefore Cache Components\nStatic by default: Next.js tried to pre-render and cache as much as possible for you unless you opted out\nRoute-level controls: Switches like dynamic, revalidate, fetchCache controlled caching for the whole page\nLimits of fetch: Using fetch alone was incomplete, as it didn't cover direct database clients or other server-side IO. A nested fetch switching to dynamic (e.g., { cache: 'no-store' }) could unintentionally change the entire route behavior\nWith Cache Components\nDynamic by default: Everything is dynamic by default. You decide which parts to cache by adding use cache where it helps\nFine-grained control: File/component/function-level use cache and cacheLife control caching exactly where you need it\nStreaming stays: Use <Suspense> or a loading.(js|tsx) file to stream dynamic parts while the shell shows immediately\nBeyond fetch: Using the use cache directive caching can be applied to all server IO (database calls, APIs, computations), not just fetch. Nested fetch calls won't silently flip an entire route because behavior is governed by explicit cache boundaries and Suspense\nExamples\nDynamic APIs\n\nWhen accessing runtime APIs like cookies(), Next.js will only pre-render the fallback UI above this component.\n\nIn this example, we have no fallback defined, so Next.js shows an error instructing us to provide one. The <User /> component needs to be wrapped in Suspense because it uses the cookies API:\n\napp/user.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers'\n \nexport async function User() {\n  const session = (await cookies()).get('session')?.value\n  return '...'\n}\n\nNow we have a Suspense boundary around our User component we can pre-render the Page with a Skeleton UI and stream in the <User /> UI when a specific user makes a request\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Suspense } from 'react'\nimport { User, AvatarSkeleton } from './user'\n \nexport default function Page() {\n  return (\n    <section>\n      <h1>This will be pre-rendered</h1>\n      <Suspense fallback={<AvatarSkeleton />}>\n        <User />\n      </Suspense>\n    </section>\n  )\n}\nPassing dynamic props\n\nComponents only opt into dynamic rendering when the value is accessed. For example, if you are reading searchParams from a <Page /> component, you can forward this value to another component as a prop:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Table, TableSkeleton } from './table'\nimport { Suspense } from 'react'\n \nexport default function Page({\n  searchParams,\n}: {\n  searchParams: Promise<{ sort: string }>\n}) {\n  return (\n    <section>\n      <h1>This will be pre-rendered</h1>\n      <Suspense fallback={<TableSkeleton />}>\n        <Table searchParams={searchParams.then((search) => search.sort)} />\n      </Suspense>\n    </section>\n  )\n}\n\nInside of the table component, accessing the value from searchParams will make the component dynamic while the rest of the page will be pre-rendered.\n\napp/table.tsx\nTypeScript\nJavaScript\nTypeScript\nexport async function Table({ sortPromise }: { sortPromise: Promise<string> }) {\n  const sort = (await sortPromise) === 'true'\n  return '...'\n}\nFrequently Asked Questions\nDoes this replace Partial Prerendering (PPR)?\n\nNo. Cache Components implements PPR as a feature. The old experimental PPR flag has been removed but PPR is here to stay.\n\nPPR provides the static shell and streaming infrastructure; use cache lets you include optimized dynamic output in that shell when beneficial.\n\nWhat should I cache first?\n\nWhat you cache should be a function of what you want your UI loading states to be. If data doesn't depend on runtime data and you're okay with a cached value being served for multiple requests over a period of time, use use cache with cacheLife to describe that behavior.\n\nFor content management systems with update mechanisms, consider using tags with longer cache durations and rely on revalidateTag to mark static initial UI as ready for revalidation. This pattern allows you to serve fast, cached responses while still updating content when it actually changes, rather than expiring the cache preemptively.\n\nHow do I update cached content quickly?\n\nUse cacheTag to tag your cached data, then trigger updateTag or revalidateTag.\n\nNext Steps\nLearn more about the config option for Cache Components.\ncacheComponents\nLearn how to enable the cacheComponents flag in Next.js.\nuse cache\nLearn how to use the use cache directive to cache data in your Next.js application.\ncacheLife\nLearn how to use the cacheLife function to set the cache expiration time for a cached function or component.\ncacheTag\nLearn how to use the cacheTag function to manage cache invalidation in your Next.js application.\nrevalidateTag\nAPI Reference for the revalidateTag function.\nupdateTag\nAPI Reference for the updateTag function.\nPrevious\nServer and Client Components\nNext\nFetching Data\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Updating Data | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/updating-data",
    "html": "App Router\nGetting Started\nUpdating Data\nCopy page\nUpdating Data\n\nYou can update data in Next.js using React's Server Functions\n. This page will go through how you can create and invoke Server Functions.\n\nWhat are Server Functions?\n\nA Server Function is an asynchronous function that runs on the server. They can be called from client through a network request, which is why they must be asynchronous.\n\nIn an action or mutation context, they are also called Server Actions.\n\nBy convention, a Server Action is an async function used with startTransition\n. This happens automatically when the function is:\n\nPassed to a <form> using the action prop.\nPassed to a <button> using the formAction prop.\n\nIn Next.js, Server Actions integrate with the framework's caching architecture. When an action is invoked, Next.js can return both the updated UI and new data in a single server roundtrip.\n\nBehind the scenes, actions use the POST method, and only this HTTP method can invoke them.\n\nCreating Server Functions\n\nA Server Function can be defined by using the use server\n directive. You can place the directive at the top of an asynchronous function to mark the function as a Server Function, or at the top of a separate file to mark all exports of that file.\n\napp/lib/actions.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function createPost(formData: FormData) {\n  'use server'\n  const title = formData.get('title')\n  const content = formData.get('content')\n \n  // Update data\n  // Revalidate cache\n}\n \nexport async function deletePost(formData: FormData) {\n  'use server'\n  const id = formData.get('id')\n \n  // Update data\n  // Revalidate cache\n}\nServer Components\n\nServer Functions can be inlined in Server Components by adding the \"use server\" directive to the top of the function body:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Page() {\n  // Server Action\n  async function createPost(formData: FormData) {\n    'use server'\n    // ...\n  }\n \n  return <></>\n}\n\nGood to know: Server Components support progressive enhancement by default, meaning forms that call Server Actions will be submitted even if JavaScript hasn't loaded yet or is disabled.\n\nClient Components\n\nIt's not possible to define Server Functions in Client Components. However, you can invoke them in Client Components by importing them from a file that has the \"use server\" directive at the top of it:\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nexport async function createPost() {}\napp/ui/button.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { createPost } from '@/app/actions'\n \nexport function Button() {\n  return <button formAction={createPost}>Create</button>\n}\n\nGood to know: In Client Components, forms invoking Server Actions will queue submissions if JavaScript isn't loaded yet, and will be prioritized for hydration. After hydration, the browser does not refresh on form submission.\n\nPassing actions as props\n\nYou can also pass an action to a Client Component as a prop:\n\n<ClientComponent updateItemAction={updateItem} />\napp/client-component.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nexport default function ClientComponent({\n  updateItemAction,\n}: {\n  updateItemAction: (formData: FormData) => void\n}) {\n  return <form action={updateItemAction}>{/* ... */}</form>\n}\nInvoking Server Functions\n\nThere are two main ways you can invoke a Server Function:\n\nForms in Server and Client Components\nEvent Handlers and useEffect in Client Components\n\nGood to know: Server Functions are designed for server-side mutations. The client currently dispatches and awaits them one at a time. This is an implementation detail and may change. If you need parallel data fetching, use data fetching in Server Components, or perform parallel work inside a single Server Function or Route Handler.\n\nForms\n\nReact extends the HTML <form>\n element to allow Server Function to be invoked with the HTML action prop.\n\nWhen invoked in a form, the function automatically receives the FormData\n object. You can extract the data using the native FormData methods\n:\n\napp/ui/form.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { createPost } from '@/app/actions'\n \nexport function Form() {\n  return (\n    <form action={createPost}>\n      <input type=\"text\" name=\"title\" />\n      <input type=\"text\" name=\"content\" />\n      <button type=\"submit\">Create</button>\n    </form>\n  )\n}\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nexport async function createPost(formData: FormData) {\n  const title = formData.get('title')\n  const content = formData.get('content')\n \n  // Update data\n  // Revalidate cache\n}\nEvent Handlers\n\nYou can invoke a Server Function in a Client Component by using event handlers such as onClick.\n\napp/like-button.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { incrementLike } from './actions'\nimport { useState } from 'react'\n \nexport default function LikeButton({ initialLikes }: { initialLikes: number }) {\n  const [likes, setLikes] = useState(initialLikes)\n \n  return (\n    <>\n      <p>Total Likes: {likes}</p>\n      <button\n        onClick={async () => {\n          const updatedLikes = await incrementLike()\n          setLikes(updatedLikes)\n        }}\n      >\n        Like\n      </button>\n    </>\n  )\n}\nExamples\nShowing a pending state\n\nWhile executing a Server Function, you can show a loading indicator with React's useActionState\n hook. This hook returns a pending boolean:\n\napp/ui/button.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useActionState, startTransition } from 'react'\nimport { createPost } from '@/app/actions'\nimport { LoadingSpinner } from '@/app/ui/loading-spinner'\n \nexport function Button() {\n  const [state, action, pending] = useActionState(createPost, false)\n \n  return (\n    <button onClick={() => startTransition(action)}>\n      {pending ? <LoadingSpinner /> : 'Create Post'}\n    </button>\n  )\n}\nRevalidating\n\nAfter performing an update, you can revalidate the Next.js cache and show the updated data by calling revalidatePath or revalidateTag within the Server Function:\n\napp/lib/actions.ts\nTypeScript\nJavaScript\nTypeScript\nimport { revalidatePath } from 'next/cache'\n \nexport async function createPost(formData: FormData) {\n  'use server'\n  // Update data\n  // ...\n \n  revalidatePath('/posts')\n}\nRedirecting\n\nYou may want to redirect the user to a different page after performing an update. You can do this by calling redirect within the Server Function.\n\napp/lib/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { revalidatePath } from 'next/cache'\nimport { redirect } from 'next/navigation'\n \nexport async function createPost(formData: FormData) {\n  // Update data\n  // ...\n \n  revalidatePath('/posts')\n  redirect('/posts')\n}\n\nCalling redirect throws a framework handled control-flow exception. Any code after it won't execute. If you need fresh data, call revalidatePath or revalidateTag beforehand.\n\nCookies\n\nYou can get, set, and delete cookies inside a Server Action using the cookies API.\n\nWhen you set or delete a cookie in a Server Action, Next.js re-renders the current page and its layouts on the server so the UI reflects the new cookie value.\n\nGood to know: The server update applies to the current React tree, re-rendering, mounting, or unmounting components, as needed. Client state is preserved for re-rendered components, and effects re-run if their dependencies changed.\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nimport { cookies } from 'next/headers'\n \nexport async function exampleAction() {\n  const cookieStore = await cookies()\n \n  // Get cookie\n  cookieStore.get('name')?.value\n \n  // Set cookie\n  cookieStore.set('name', 'Delba')\n \n  // Delete cookie\n  cookieStore.delete('name')\n}\nuseEffect\n\nYou can use the React useEffect\n hook to invoke a Server Action when the component mounts or a dependency changes. This is useful for mutations that depend on global events or need to be triggered automatically. For example, onKeyDown for app shortcuts, an intersection observer hook for infinite scrolling, or when the component mounts to update a view count:\n\napp/view-count.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { incrementViews } from './actions'\nimport { useState, useEffect, useTransition } from 'react'\n \nexport default function ViewCount({ initialViews }: { initialViews: number }) {\n  const [views, setViews] = useState(initialViews)\n  const [isPending, startTransition] = useTransition()\n \n  useEffect(() => {\n    startTransition(async () => {\n      const updatedViews = await incrementViews()\n      setViews(updatedViews)\n    })\n  }, [])\n \n  // You can use `isPending` to give users feedback\n  return <p>Total Views: {views}</p>\n}\nAPI Reference\nLearn more about the features mentioned in this page by reading the API Reference.\nrevalidatePath\nAPI Reference for the revalidatePath function.\nrevalidateTag\nAPI Reference for the revalidateTag function.\nredirect\nAPI Reference for the redirect function.\nPrevious\nFetching Data\nNext\nCaching and Revalidating\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Fetching Data | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/fetching-data",
    "html": "App Router\nGetting Started\nFetching Data\nCopy page\nFetching Data\n\nThis page will walk you through how you can fetch data in Server and Client Components, and how to stream components that depend on data.\n\nFetching data\nServer Components\n\nYou can fetch data in Server Components using:\n\nThe fetch API\nAn ORM or database\nWith the fetch API\n\nTo fetch data with the fetch API, turn your component into an asynchronous function, and await the fetch call. For example:\n\napp/blog/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page() {\n  const data = await fetch('https://api.vercel.app/blog')\n  const posts = await data.json()\n  return (\n    <ul>\n      {posts.map((post) => (\n        <li key={post.id}>{post.title}</li>\n      ))}\n    </ul>\n  )\n}\n\nGood to know:\n\nfetch responses are not cached by default. However, Next.js will pre-render the route and the output will be cached for improved performance. If you'd like to opt into dynamic rendering, use the { cache: 'no-store' } option. See the fetch API Reference.\nDuring development, you can log fetch calls for better visibility and debugging. See the logging API reference.\nWith an ORM or database\n\nSince Server Components are rendered on the server, you can safely make database queries using an ORM or database client. Turn your component into an asynchronous function, and await the call:\n\napp/blog/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { db, posts } from '@/lib/db'\n \nexport default async function Page() {\n  const allPosts = await db.select().from(posts)\n  return (\n    <ul>\n      {allPosts.map((post) => (\n        <li key={post.id}>{post.title}</li>\n      ))}\n    </ul>\n  )\n}\nClient Components\n\nThere are two ways to fetch data in Client Components, using:\n\nReact's use hook\nA community library like SWR\n or React Query\nStreaming data with the use hook\n\nYou can use React's use hook\n to stream data from the server to client. Start by fetching data in your Server component, and pass the promise to your Client Component as prop:\n\napp/blog/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Posts from '@/app/ui/posts'\nimport { Suspense } from 'react'\n \nexport default function Page() {\n  // Don't await the data fetching function\n  const posts = getPosts()\n \n  return (\n    <Suspense fallback={<div>Loading...</div>}>\n      <Posts posts={posts} />\n    </Suspense>\n  )\n}\n\nThen, in your Client Component, use the use hook to read the promise:\n\napp/ui/posts.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\nimport { use } from 'react'\n \nexport default function Posts({\n  posts,\n}: {\n  posts: Promise<{ id: string; title: string }[]>\n}) {\n  const allPosts = use(posts)\n \n  return (\n    <ul>\n      {allPosts.map((post) => (\n        <li key={post.id}>{post.title}</li>\n      ))}\n    </ul>\n  )\n}\n\nIn the example above, the <Posts> component is wrapped in a <Suspense> boundary\n. This means the fallback will be shown while the promise is being resolved. Learn more about streaming.\n\nCommunity libraries\n\nYou can use a community library like SWR\n or React Query\n to fetch data in Client Components. These libraries have their own semantics for caching, streaming, and other features. For example, with SWR:\n\napp/blog/page.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\nimport useSWR from 'swr'\n \nconst fetcher = (url) => fetch(url).then((r) => r.json())\n \nexport default function BlogPage() {\n  const { data, error, isLoading } = useSWR(\n    'https://api.vercel.app/blog',\n    fetcher\n  )\n \n  if (isLoading) return <div>Loading...</div>\n  if (error) return <div>Error: {error.message}</div>\n \n  return (\n    <ul>\n      {data.map((post: { id: string; title: string }) => (\n        <li key={post.id}>{post.title}</li>\n      ))}\n    </ul>\n  )\n}\nDeduplicate requests and cache data\n\nOne way to deduplicate fetch requests is with request memoization. With this mechanism, fetch calls using GET or HEAD with the same URL and options in a single render pass are combined into one request. This happens automatically, and you can opt out by passing an Abort signal to fetch.\n\nRequest memoization is scoped to the lifetime of a request.\n\nYou can also deduplicate fetch requests by using Next.js’ Data Cache, for example by setting cache: 'force-cache' in your fetch options.\n\nData Cache allows sharing data across the current render pass and incoming requests.\n\nIf you are not using fetch, and instead using an ORM or database directly, you can wrap your data access with the React cache\n function.\n\napp/lib/data.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cache } from 'react'\nimport { db, posts, eq } from '@/lib/db'\n \nexport const getPost = cache(async (id: string) => {\n  const post = await db.query.posts.findFirst({\n    where: eq(posts.id, parseInt(id)),\n  })\n})\nStreaming\n\nWarning: The content below assumes the cacheComponents config option is enabled in your application. The flag was introduced in Next.js 15 canary.\n\nWhen you fetch data in Server Components, the data is fetched and rendered on the server for each request. If you have any slow data requests, the whole route will be blocked from rendering until all the data is fetched.\n\nTo improve the initial load time and user experience, you can use streaming to break up the page's HTML into smaller chunks and progressively send those chunks from the server to the client.\n\nThere are two ways you can implement streaming in your application:\n\nWrapping a page with a loading.js file\nWrapping a component with <Suspense>\nWith loading.js\n\nYou can create a loading.js file in the same folder as your page to stream the entire page while the data is being fetched. For example, to stream app/blog/page.js, add the file inside the app/blog folder.\n\napp/blog/loading.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Loading() {\n  // Define the Loading UI here\n  return <div>Loading...</div>\n}\n\nOn navigation, the user will immediately see the layout and a loading state while the page is being rendered. The new content will then be automatically swapped in once rendering is complete.\n\nBehind-the-scenes, loading.js will be nested inside layout.js, and will automatically wrap the page.js file and any children below in a <Suspense> boundary.\n\nThis approach works well for route segments (layouts and pages), but for more granular streaming, you can use <Suspense>.\n\nWith <Suspense>\n\n<Suspense> allows you to be more granular about what parts of the page to stream. For example, you can immediately show any page content that falls outside of the <Suspense> boundary, and stream in the list of blog posts inside the boundary.\n\napp/blog/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Suspense } from 'react'\nimport BlogList from '@/components/BlogList'\nimport BlogListSkeleton from '@/components/BlogListSkeleton'\n \nexport default function BlogPage() {\n  return (\n    <div>\n      {/* This content will be sent to the client immediately */}\n      <header>\n        <h1>Welcome to the Blog</h1>\n        <p>Read the latest posts below.</p>\n      </header>\n      <main>\n        {/* Any content wrapped in a <Suspense> boundary will be streamed */}\n        <Suspense fallback={<BlogListSkeleton />}>\n          <BlogList />\n        </Suspense>\n      </main>\n    </div>\n  )\n}\nCreating meaningful loading states\n\nAn instant loading state is fallback UI that is shown immediately to the user after navigation. For the best user experience, we recommend designing loading states that are meaningful and help users understand the app is responding. For example, you can use skeletons and spinners, or a small but meaningful part of future screens such as a cover photo, title, etc.\n\nIn development, you can preview and inspect the loading state of your components using the React Devtools\n.\n\nExamples\nSequential data fetching\n\nSequential data fetching happens when nested components in a tree each fetch their own data and the requests are not deduplicated, leading to longer response times.\n\nThere may be cases where you want this pattern because one fetch depends on the result of the other.\n\nFor example, the <Playlists> component will only start fetching data once the <Artist> component has finished fetching data because <Playlists> depends on the artistID prop:\n\napp/artist/[username]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ username: string }>\n}) {\n  const { username } = await params\n  // Get artist information\n  const artist = await getArtist(username)\n \n  return (\n    <>\n      <h1>{artist.name}</h1>\n      {/* Show fallback UI while the Playlists component is loading */}\n      <Suspense fallback={<div>Loading...</div>}>\n        {/* Pass the artist ID to the Playlists component */}\n        <Playlists artistID={artist.id} />\n      </Suspense>\n    </>\n  )\n}\n \nasync function Playlists({ artistID }: { artistID: string }) {\n  // Use the artist ID to fetch playlists\n  const playlists = await getArtistPlaylists(artistID)\n \n  return (\n    <ul>\n      {playlists.map((playlist) => (\n        <li key={playlist.id}>{playlist.name}</li>\n      ))}\n    </ul>\n  )\n}\n\nTo improve the user experience, you should use React <Suspense> to show a fallback while data is being fetch. This will enable streaming and prevent the whole route from being blocked by the sequential data requests.\n\nParallel data fetching\n\nParallel data fetching happens when data requests in a route are eagerly initiated and start at the same time.\n\nBy default, layouts and pages are rendered in parallel. So each segment starts fetching data as soon as possible.\n\nHowever, within any component, multiple async/await requests can still be sequential if placed after the other. For example, getAlbums will be blocked until getArtist is resolved:\n\napp/artist/[username]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getArtist, getAlbums } from '@/app/lib/data'\n \nexport default async function Page({ params }) {\n  // These requests will be sequential\n  const { username } = await params\n  const artist = await getArtist(username)\n  const albums = await getAlbums(username)\n  return <div>{artist.name}</div>\n}\n\nStart multiple requests by calling fetch, then await them with Promise.all\n. Requests begin as soon as fetch is called.\n\napp/artist/[username]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Albums from './albums'\n \nasync function getArtist(username: string) {\n  const res = await fetch(`https://api.example.com/artist/${username}`)\n  return res.json()\n}\n \nasync function getAlbums(username: string) {\n  const res = await fetch(`https://api.example.com/artist/${username}/albums`)\n  return res.json()\n}\n \nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ username: string }>\n}) {\n  const { username } = await params\n \n  // Initiate requests\n  const artistData = getArtist(username)\n  const albumsData = getAlbums(username)\n \n  const [artist, albums] = await Promise.all([artistData, albumsData])\n \n  return (\n    <>\n      <h1>{artist.name}</h1>\n      <Albums list={albums} />\n    </>\n  )\n}\n\nGood to know: If one request fails when using Promise.all, the entire operation will fail. To handle this, you can use the Promise.allSettled\n method instead.\n\nPreloading data\n\nYou can preload data by creating an utility function that you eagerly call above blocking requests. <Item> conditionally renders based on the checkIsAvailable() function.\n\nYou can call preload() before checkIsAvailable() to eagerly initiate <Item/> data dependencies. By the time <Item/> is rendered, its data has already been fetched.\n\napp/item/[id]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getItem, checkIsAvailable } from '@/lib/data'\n \nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ id: string }>\n}) {\n  const { id } = await params\n  // starting loading item data\n  preload(id)\n  // perform another asynchronous task\n  const isAvailable = await checkIsAvailable()\n \n  return isAvailable ? <Item id={id} /> : null\n}\n \nexport const preload = (id: string) => {\n  // void evaluates the given expression and returns undefined\n  // https://developer.mozilla.org/docs/Web/JavaScript/Reference/Operators/void\n  void getItem(id)\n}\nexport async function Item({ id }: { id: string }) {\n  const result = await getItem(id)\n  // ...\n}\n\nAdditionally, you can use React's cache function\n and the server-only package\n to create a reusable utility function. This approach allows you to cache the data fetching function and ensure that it's only executed on the server.\n\nutils/get-item.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cache } from 'react'\nimport 'server-only'\nimport { getItem } from '@/lib/data'\n \nexport const preload = (id: string) => {\n  void getItem(id)\n}\n \nexport const getItem = cache(async (id: string) => {\n  // ...\n})\nAPI Reference\nLearn more about the features mentioned in this page by reading the API Reference.\nData Security\nLearn the built-in data security features in Next.js and learn best practices for protecting your application's data.\nfetch\nAPI reference for the extended fetch function.\nloading.js\nAPI reference for the loading.js file.\nlogging\nConfigure how data fetches are logged to the console when running Next.js in development mode.\ntaint\nEnable tainting Objects and Values.\nPrevious\nCache Components\nNext\nUpdating Data\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Caching and Revalidating | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/caching-and-revalidating",
    "html": "App Router\nGetting Started\nCaching and Revalidating\nCopy page\nCaching and Revalidating\n\nCaching is a technique for storing the result of data fetching and other computations so that future requests for the same data can be served faster, without doing the work again. While revalidation allows you to update cache entries without having to rebuild your entire application.\n\nNext.js provides a few APIs to handle caching and revalidation. This guide will walk you through when and how to use them.\n\nfetch\nunstable_cache\nrevalidatePath\nrevalidateTag\nupdateTag\nfetch\n\nBy default, fetch requests are not cached. You can cache individual requests by setting the cache option to 'force-cache'.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page() {\n  const data = await fetch('https://...', { cache: 'force-cache' })\n}\n\nGood to know: Although fetch requests are not cached by default, Next.js will pre-render routes that have fetch requests and cache the HTML. If you want to guarantee a route is dynamic, use the connection API.\n\nTo revalidate the data returned by a fetch request, you can use the next.revalidate option.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page() {\n  const data = await fetch('https://...', { next: { revalidate: 3600 } })\n}\n\nThis will revalidate the data after a specified amount of seconds.\n\nSee the fetch API reference to learn more.\n\nunstable_cache\n\nunstable_cache allows you to cache the result of database queries and other async functions. To use it, wrap unstable_cache around the function. For example:\n\napp/lib/data.ts\nTypeScript\nJavaScript\nTypeScript\nimport { db } from '@/lib/db'\nexport async function getUserById(id: string) {\n  return db\n    .select()\n    .from(users)\n    .where(eq(users.id, id))\n    .then((res) => res[0])\n}\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { unstable_cache } from 'next/cache'\nimport { getUserById } from '@/app/lib/data'\n \nexport default async function Page({\n  params,\n}: {\n  params: Promise<{ userId: string }>\n}) {\n  const { userId } = await params\n \n  const getCachedUser = unstable_cache(\n    async () => {\n      return getUserById(userId)\n    },\n    [userId] // add the user ID to the cache key\n  )\n}\n\nThe function accepts a third optional object to define how the cache should be revalidated. It accepts:\n\ntags: an array of tags used by Next.js to revalidate the cache.\nrevalidate: the number of seconds after cache should be revalidated.\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nconst getCachedUser = unstable_cache(\n  async () => {\n    return getUserById(userId)\n  },\n  [userId],\n  {\n    tags: ['user'],\n    revalidate: 3600,\n  }\n)\n\nSee the unstable_cache API reference to learn more.\n\nrevalidateTag\n\nrevalidateTag is used to revalidate cache entries based on a tag and following an event. The function now supports two behaviors:\n\nWith profile=\"max\": Uses stale-while-revalidate semantics, serving stale content while fetching fresh content in the background\nWithout the second argument: Legacy behavior that immediately expires the cache (deprecated)\n\nTo use it with fetch, start by tagging the function with the next.tags option:\n\napp/lib/data.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function getUserById(id: string) {\n  const data = await fetch(`https://...`, {\n    next: {\n      tags: ['user'],\n    },\n  })\n}\n\nAlternatively, you can mark an unstable_cache function with the tags option:\n\napp/lib/data.ts\nTypeScript\nJavaScript\nTypeScript\nexport const getUserById = unstable_cache(\n  async (id: string) => {\n    return db.query.users.findFirst({ where: eq(users.id, id) })\n  },\n  ['user'], // Needed if variables are not passed as parameters\n  {\n    tags: ['user'],\n  }\n)\n\nThen, call revalidateTag in a Route Handler or Server Action:\n\napp/lib/actions.ts\nTypeScript\nJavaScript\nTypeScript\nimport { revalidateTag } from 'next/cache'\n \nexport async function updateUser(id: string) {\n  // Mutate data\n  revalidateTag('user', 'max') // Recommended: Uses stale-while-revalidate\n}\n\nYou can reuse the same tag in multiple functions to revalidate them all at once.\n\nSee the revalidateTag API reference to learn more.\n\nrevalidatePath\n\nrevalidatePath is used to revalidate a route and following an event. To use it, call it in a Route Handler or Server Action:\n\napp/lib/actions.ts\nTypeScript\nJavaScript\nTypeScript\nimport { revalidatePath } from 'next/cache'\n \nexport async function updateUser(id: string) {\n  // Mutate data\n  revalidatePath('/profile')\n\nSee the revalidatePath API reference to learn more.\n\nupdateTag\n\nupdateTag is specifically designed for Server Actions to immediately expire cached data for read-your-own-writes scenarios. Unlike revalidateTag, it can only be used within Server Actions and immediately expires the cache entry.\n\napp/lib/actions.ts\nTypeScript\nJavaScript\nTypeScript\nimport { updateTag } from 'next/cache'\nimport { redirect } from 'next/navigation'\n \nexport async function createPost(formData: FormData) {\n  // Create post in database\n  const post = await db.post.create({\n    data: {\n      title: formData.get('title'),\n      content: formData.get('content'),\n    },\n  })\n \n  // Immediately expire cache so the new post is visible\n  updateTag('posts')\n  updateTag(`post-${post.id}`)\n \n  redirect(`/posts/${post.id}`)\n}\n\nThe key differences between revalidateTag and updateTag:\n\nupdateTag: Only in Server Actions, immediately expires cache, for read-your-own-writes\nrevalidateTag: In Server Actions and Route Handlers, supports stale-while-revalidate with profile=\"max\"\n\nSee the updateTag API reference to learn more.\n\nAPI Reference\nLearn more about the features mentioned in this page by reading the API Reference.\nfetch\nAPI reference for the extended fetch function.\nunstable_cache\nAPI Reference for the unstable_cache function.\nrevalidatePath\nAPI Reference for the revalidatePath function.\nrevalidateTag\nAPI Reference for the revalidateTag function.\nupdateTag\nAPI Reference for the updateTag function.\nPrevious\nUpdating Data\nNext\nError Handling\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Error Handling | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/error-handling",
    "html": "App Router\nGetting Started\nError Handling\nCopy page\nError Handling\n\nErrors can be divided into two categories: expected errors and uncaught exceptions. This page will walk you through how you can handle these errors in your Next.js application.\n\nHandling expected errors\n\nExpected errors are those that can occur during the normal operation of the application, such as those from server-side form validation or failed requests. These errors should be handled explicitly and returned to the client.\n\nServer Functions\n\nYou can use the useActionState\n hook to handle expected errors in Server Functions\n.\n\nFor these errors, avoid using try/catch blocks and throw errors. Instead, model expected errors as return values.\n\napp/actions.ts\nTypeScript\nJavaScript\nTypeScript\n'use server'\n \nexport async function createPost(prevState: any, formData: FormData) {\n  const title = formData.get('title')\n  const content = formData.get('content')\n \n  const res = await fetch('https://api.vercel.app/posts', {\n    method: 'POST',\n    body: { title, content },\n  })\n  const json = await res.json()\n \n  if (!res.ok) {\n    return { message: 'Failed to create post' }\n  }\n}\n\nYou can pass your action to the useActionState hook and use the returned state to display an error message.\n\napp/ui/form.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client'\n \nimport { useActionState } from 'react'\nimport { createPost } from '@/app/actions'\n \nconst initialState = {\n  message: '',\n}\n \nexport function Form() {\n  const [state, formAction, pending] = useActionState(createPost, initialState)\n \n  return (\n    <form action={formAction}>\n      <label htmlFor=\"title\">Title</label>\n      <input type=\"text\" id=\"title\" name=\"title\" required />\n      <label htmlFor=\"content\">Content</label>\n      <textarea id=\"content\" name=\"content\" required />\n      {state?.message && <p aria-live=\"polite\">{state.message}</p>}\n      <button disabled={pending}>Create Post</button>\n    </form>\n  )\n}\nServer Components\n\nWhen fetching data inside of a Server Component, you can use the response to conditionally render an error message or redirect.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default async function Page() {\n  const res = await fetch(`https://...`)\n  const data = await res.json()\n \n  if (!res.ok) {\n    return 'There was an error.'\n  }\n \n  return '...'\n}\nNot found\n\nYou can call the notFound function within a route segment and use the not-found.js file to show a 404 UI.\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getPostBySlug } from '@/lib/posts'\n \nexport default async function Page({ params }: { params: { slug: string } }) {\n  const { slug } = await params\n  const post = getPostBySlug(slug)\n \n  if (!post) {\n    notFound()\n  }\n \n  return <div>{post.title}</div>\n}\napp/blog/[slug]/not-found.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function NotFound() {\n  return <div>404 - Page Not Found</div>\n}\nHandling uncaught exceptions\n\nUncaught exceptions are unexpected errors that indicate bugs or issues that should not occur during the normal flow of your application. These should be handled by throwing errors, which will then be caught by error boundaries.\n\nNested error boundaries\n\nNext.js uses error boundaries to handle uncaught exceptions. Error boundaries catch errors in their child components and display a fallback UI instead of the component tree that crashed.\n\nCreate an error boundary by adding an error.js file inside a route segment and exporting a React component:\n\napp/dashboard/error.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client' // Error boundaries must be Client Components\n \nimport { useEffect } from 'react'\n \nexport default function Error({\n  error,\n  reset,\n}: {\n  error: Error & { digest?: string }\n  reset: () => void\n}) {\n  useEffect(() => {\n    // Log the error to an error reporting service\n    console.error(error)\n  }, [error])\n \n  return (\n    <div>\n      <h2>Something went wrong!</h2>\n      <button\n        onClick={\n          // Attempt to recover by trying to re-render the segment\n          () => reset()\n        }\n      >\n        Try again\n      </button>\n    </div>\n  )\n}\n\nErrors will bubble up to the nearest parent error boundary. This allows for granular error handling by placing error.tsx files at different levels in the route hierarchy.\n\nError boundaries don’t catch errors inside event handlers. They’re designed to catch errors during rendering\n to show a fallback UI instead of crashing the whole app.\n\nIn general, errors in event handlers or async code aren’t handled by error boundaries because they run after rendering.\n\nTo handle these cases, catch the error manually and store it using useState or useReducer, then update the UI to inform the user.\n\n'use client'\n \nimport { useState } from 'react'\n \nexport function Button() {\n  const [error, setError] = useState(null)\n \n  const handleClick = () => {\n    try {\n      // do some work that might fail\n      throw new Error('Exception')\n    } catch (reason) {\n      setError(reason)\n    }\n  }\n \n  if (error) {\n    /* render fallback UI */\n  }\n \n  return (\n    <button type=\"button\" onClick={handleClick}>\n      Click me\n    </button>\n  )\n}\n\nNote that unhandled errors inside startTransition from useTransition, will bubble up to the nearest error boundary.\n\n'use client'\n \nimport { useTransition } from 'react'\n \nexport function Button() {\n  const [pending, startTransition] = useTransition()\n \n  const handleClick = () =>\n    startTransition(() => {\n      throw new Error('Exception')\n    })\n \n  return (\n    <button type=\"button\" onClick={handleClick}>\n      Click me\n    </button>\n  )\n}\nGlobal errors\n\nWhile less common, you can handle errors in the root layout using the global-error.js file, located in the root app directory, even when leveraging internationalization. Global error UI must define its own <html> and <body> tags, since it is replacing the root layout or template when active.\n\napp/global-error.tsx\nTypeScript\nJavaScript\nTypeScript\n'use client' // Error boundaries must be Client Components\n \nexport default function GlobalError({\n  error,\n  reset,\n}: {\n  error: Error & { digest?: string }\n  reset: () => void\n}) {\n  return (\n    // global-error must include html and body tags\n    <html>\n      <body>\n        <h2>Something went wrong!</h2>\n        <button onClick={() => reset()}>Try again</button>\n      </body>\n    </html>\n  )\n}\nAPI Reference\nLearn more about the features mentioned in this page by reading the API Reference.\nredirect\nAPI Reference for the redirect function.\nerror.js\nAPI reference for the error.js special file.\nnotFound\nAPI Reference for the notFound function.\nnot-found.js\nAPI reference for the not-found.js file.\nPrevious\nCaching and Revalidating\nNext\nCSS\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Image Optimization | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/images",
    "html": "App Router\nGetting Started\nImage Optimization\nCopy page\nImage Optimization\n\nThe Next.js <Image> component extends the HTML <img> element to provide:\n\nSize optimization: Automatically serving correctly sized images for each device, using modern image formats like WebP.\nVisual stability: Preventing layout shift\n automatically when images are loading.\nFaster page loads: Only loading images when they enter the viewport using native browser lazy loading, with optional blur-up placeholders.\nAsset flexibility: Resizing images on-demand, even images stored on remote servers.\n\nTo start using <Image>, import it from next/image and render it within your component.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Image from 'next/image'\n \nexport default function Page() {\n  return <Image src=\"\" alt=\"\" />\n}\n\nThe src property can be a local or remote image.\n\n🎥 Watch: Learn more about how to use next/image → YouTube (9 minutes)\n.\n\nLocal images\n\nYou can store static files, like images and fonts, under a folder called public in the root directory. Files inside public can then be referenced by your code starting from the base URL (/).\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Image from 'next/image'\n \nexport default function Page() {\n  return (\n    <Image\n      src=\"/profile.png\"\n      alt=\"Picture of the author\"\n      width={500}\n      height={500}\n    />\n  )\n}\n\nIf the image is statically imported, Next.js will automatically determine the intrinsic width and height. These values are used to determine the image ratio and prevent Cumulative Layout Shift\n while your image is loading.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Image from 'next/image'\nimport ProfileImage from './profile.png'\n \nexport default function Page() {\n  return (\n    <Image\n      src={ProfileImage}\n      alt=\"Picture of the author\"\n      // width={500} automatically provided\n      // height={500} automatically provided\n      // blurDataURL=\"data:...\" automatically provided\n      // placeholder=\"blur\" // Optional blur-up while loading\n    />\n  )\n}\nRemote images\n\nTo use a remote image, you can provide a URL string for the src property.\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport Image from 'next/image'\n \nexport default function Page() {\n  return (\n    <Image\n      src=\"https://s3.amazonaws.com/my-bucket/profile.png\"\n      alt=\"Picture of the author\"\n      width={500}\n      height={500}\n    />\n  )\n}\n\nSince Next.js does not have access to remote files during the build process, you'll need to provide the width, height and optional blurDataURL props manually. The width and height are used to infer the correct aspect ratio of image and avoid layout shift from the image loading in. Alternatively, you can use the fill property to make the image fill the size of the parent element.\n\nTo safely allow images from remote servers, you need to define a list of supported URL patterns in next.config.js. Be as specific as possible to prevent malicious usage. For example, the following configuration will only allow images from a specific AWS S3 bucket:\n\nnext.config.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextConfig } from 'next'\n \nconst config: NextConfig = {\n  images: {\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: 's3.amazonaws.com',\n        port: '',\n        pathname: '/my-bucket/**',\n        search: '',\n      },\n    ],\n  },\n}\n \nexport default config\nAPI Reference\nSee the API Reference for the full feature set of Next.js Image.\nImage Component\nOptimize Images in your Next.js Application using the built-in `next/image` Component.\nPrevious\nCSS\nNext\nFont Optimization\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: CSS | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/css",
    "html": "App Router\nGetting Started\nCSS\nCopy page\nCSS\n\nNext.js provides several ways to style your application using CSS, including:\n\nTailwind CSS\nCSS Modules\nGlobal CSS\nExternal Stylesheets\nSass\nCSS-in-JS\nTailwind CSS\n\nTailwind CSS\n is a utility-first CSS framework that provides low-level utility classes to build custom designs.\n\nInstall Tailwind CSS:\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm add -D tailwindcss @tailwindcss/postcss\n\nAdd the PostCSS plugin to your postcss.config.mjs file:\n\npostcss.config.mjs\nexport default {\n  plugins: {\n    '@tailwindcss/postcss': {},\n  },\n}\n\nImport Tailwind in your global CSS file:\n\napp/globals.css\n@import 'tailwindcss';\n\nImport the CSS file in your root layout:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport './globals.css'\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body>{children}</body>\n    </html>\n  )\n}\n\nNow you can start using Tailwind's utility classes in your application:\n\napp/page.tsx\nTypeScript\nJavaScript\nTypeScript\nexport default function Page() {\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-between p-24\">\n      <h1 className=\"text-4xl font-bold\">Welcome to Next.js!</h1>\n    </main>\n  )\n}\n\nGood to know: If you need broader browser support for very old browsers, see the Tailwind CSS v3 setup instructions.\n\nCSS Modules\n\nCSS Modules locally scope CSS by generating unique class names. This allows you to use the same class in different files without worrying about naming collisions.\n\nTo start using CSS Modules, create a new file with the extension .module.css and import it into any component inside the app directory:\n\napp/blog/blog.module.css\n.blog {\n  padding: 24px;\n}\napp/blog/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport styles from './blog.module.css'\n \nexport default function Page() {\n  return <main className={styles.blog}></main>\n}\nGlobal CSS\n\nYou can use global CSS to apply styles across your application.\n\nCreate a app/global.css file and import it in the root layout to apply the styles to every route in your application:\n\napp/global.css\nbody {\n  padding: 20px 20px 60px;\n  max-width: 680px;\n  margin: 0 auto;\n}\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\n// These styles apply to every route in the application\nimport './global.css'\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body>{children}</body>\n    </html>\n  )\n}\n\nGood to know: Global styles can be imported into any layout, page, or component inside the app directory. However, since Next.js uses React's built-in support for stylesheets to integrate with Suspense, this currently does not remove stylesheets as you navigate between routes which can lead to conflicts. We recommend using global styles for truly global CSS (like Tailwind's base styles), Tailwind CSS for component styling, and CSS Modules for custom scoped CSS when needed.\n\nExternal stylesheets\n\nStylesheets published by external packages can be imported anywhere in the app directory, including colocated components:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport 'bootstrap/dist/css/bootstrap.css'\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\">\n      <body className=\"container\">{children}</body>\n    </html>\n  )\n}\n\nGood to know: In React 19, <link rel=\"stylesheet\" href=\"...\" /> can also be used. See the React link documentation\n for more information.\n\nOrdering and Merging\n\nNext.js optimizes CSS during production builds by automatically chunking (merging) stylesheets. The order of your CSS depends on the order you import styles in your code.\n\nFor example, base-button.module.css will be ordered before page.module.css since <BaseButton> is imported before page.module.css:\n\npage.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { BaseButton } from './base-button'\nimport styles from './page.module.css'\n \nexport default function Page() {\n  return <BaseButton className={styles.primary} />\n}\nbase-button.tsx\nTypeScript\nJavaScript\nTypeScript\nimport styles from './base-button.module.css'\n \nexport function BaseButton() {\n  return <button className={styles.primary} />\n}\nRecommendations\n\nTo keep CSS ordering predictable:\n\nTry to contain CSS imports to a single JavaScript or TypeScript entry file\nImport global styles and Tailwind stylesheets in the root of your application.\nUse Tailwind CSS for most styling needs as it covers common design patterns with utility classes.\nUse CSS Modules for component-specific styles when Tailwind utilities aren't sufficient.\nUse a consistent naming convention for your CSS modules. For example, using <name>.module.css over <name>.tsx.\nExtract shared styles into shared components to avoid duplicate imports.\nTurn off linters or formatters that auto-sort imports like ESLint’s sort-imports\n.\nYou can use the cssChunking option in next.config.js to control how CSS is chunked.\nDevelopment vs Production\nIn development (next dev), CSS updates apply instantly with Fast Refresh.\nIn production (next build), all CSS files are automatically concatenated into many minified and code-split .css files, ensuring the minimal amount of CSS is loaded for a route.\nCSS still loads with JavaScript disabled in production, but JavaScript is required in development for Fast Refresh.\nCSS ordering can behave differently in development, always ensure to check the build (next build) to verify the final CSS order.\nNext Steps\nLearn more about the alternatives ways you can use CSS in your application.\nTailwind CSS v3\nStyle your Next.js Application using Tailwind CSS v3 for broader browser support.\nSass\nStyle your Next.js application using Sass.\nCSS-in-JS\nUse CSS-in-JS libraries with Next.js\nPrevious\nError Handling\nNext\nImage Optimization\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Font Optimization | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/fonts",
    "html": "App Router\nGetting Started\nFont Optimization\nCopy page\nFont Optimization\n\nThe next/font module automatically optimizes your fonts and removes external network requests for improved privacy and performance.\n\nIt includes built-in self-hosting for any font file. This means you can optimally load web fonts with no layout shift.\n\nTo start using next/font, import it from next/font/local or next/font/google, call it as a function with the appropriate options, and set the className of the element you want to apply the font to. For example:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Geist } from 'next/font/google'\n \nconst geist = Geist({\n  subsets: ['latin'],\n})\n \nexport default function Layout({ children }: { children: React.ReactNode }) {\n  return (\n    <html lang=\"en\" className={geist.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\n\nFonts are scoped to the component they're used in. To apply a font to your entire application, add it to the Root Layout.\n\nGoogle fonts\n\nYou can automatically self-host any Google Font. Fonts are included stored as static assets and served from the same domain as your deployment, meaning no requests are sent to Google by the browser when the user visits your site.\n\nTo start using a Google Font, import your chosen font from next/font/google:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Geist } from 'next/font/google'\n \nconst geist = Geist({\n  subsets: ['latin'],\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={geist.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\n\nWe recommend using variable fonts\n for the best performance and flexibility. But if you can't use a variable font, you will need to specify a weight:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { Roboto } from 'next/font/google'\n \nconst roboto = Roboto({\n  weight: '400',\n  subsets: ['latin'],\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={roboto.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\nLocal fonts\n\nTo use a local font, import your font from next/font/local and specify the src of your local font file. Fonts can be stored in the public folder or co-located inside the app folder. For example:\n\napp/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport localFont from 'next/font/local'\n \nconst myFont = localFont({\n  src: './my-font.woff2',\n})\n \nexport default function RootLayout({\n  children,\n}: {\n  children: React.ReactNode\n}) {\n  return (\n    <html lang=\"en\" className={myFont.className}>\n      <body>{children}</body>\n    </html>\n  )\n}\n\nIf you want to use multiple files for a single font family, src can be an array:\n\nconst roboto = localFont({\n  src: [\n    {\n      path: './Roboto-Regular.woff2',\n      weight: '400',\n      style: 'normal',\n    },\n    {\n      path: './Roboto-Italic.woff2',\n      weight: '400',\n      style: 'italic',\n    },\n    {\n      path: './Roboto-Bold.woff2',\n      weight: '700',\n      style: 'normal',\n    },\n    {\n      path: './Roboto-BoldItalic.woff2',\n      weight: '700',\n      style: 'italic',\n    },\n  ],\n})\nAPI Reference\nSee the API Reference for the full feature set of Next.js Font\nFont\nOptimizing loading web fonts with the built-in `next/font` loaders.\nPrevious\nImage Optimization\nNext\nMetadata and OG images\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Metadata and OG images | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/metadata-and-og-images",
    "html": "App Router\nGetting Started\nMetadata and OG images\nCopy page\nMetadata and OG images\n\nThe Metadata APIs can be used to define your application metadata for improved SEO and web shareability and include:\n\nThe static metadata object\nThe dynamic generateMetadata function\nSpecial file conventions that can be used to add static or dynamically generated favicons and OG images.\n\nWith all the options above, Next.js will automatically generate the relevant <head> tags for your page, which can be inspected in the browser's developer tools.\n\nThe metadata object and generateMetadata function exports are only supported in Server Components.\n\nDefault fields\n\nThere are two default meta tags that are always added even if a route doesn't define metadata:\n\nThe meta charset tag\n sets the character encoding for the website.\nThe meta viewport tag\n sets the viewport width and scale for the website to adjust for different devices.\n<meta charset=\"utf-8\" />\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\nThe other metadata fields can be defined with the Metadata object (for static metadata) or the generateMetadata function (for generated metadata).\n\nStatic metadata\n\nTo define static metadata, export a Metadata object from a static layout.js or page.js file. For example, to add a title and description to the blog route:\n\napp/blog/layout.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata } from 'next'\n \nexport const metadata: Metadata = {\n  title: 'My Blog',\n  description: '...',\n}\n \nexport default function Layout() {}\n\nYou can view a full list of available options, in the generateMetadata documentation.\n\nGenerated metadata\n\nYou can use generateMetadata function to fetch metadata that depends on data. For example, to fetch the title and description for a specific blog post:\n\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport type { Metadata, ResolvingMetadata } from 'next'\n \ntype Props = {\n  params: Promise<{ slug: string }>\n  searchParams: Promise<{ [key: string]: string | string[] | undefined }>\n}\n \nexport async function generateMetadata(\n  { params, searchParams }: Props,\n  parent: ResolvingMetadata\n): Promise<Metadata> {\n  const slug = (await params).slug\n \n  // fetch post information\n  const post = await fetch(`https://api.vercel.app/blog/${slug}`).then((res) =>\n    res.json()\n  )\n \n  return {\n    title: post.title,\n    description: post.description,\n  }\n}\n \nexport default function Page({ params, searchParams }: Props) {}\nStreaming metadata\n\nFor dynamically rendered pages, Next.js streams metadata separately, injecting it into the HTML once generateMetadata resolves, without blocking UI rendering.\n\nStreaming metadata improves perceived performance by allowing visual content to stream first.\n\nStreaming metadata is disabled for bots and crawlers that expect metadata to be in the <head> tag (e.g. Twitterbot, Slackbot, Bingbot). These are detected by using the User Agent header from the incoming request.\n\nYou can customize or disable streaming metadata completely, with the htmlLimitedBots option in your Next.js config file.\n\nStatically rendered pages don’t use streaming since metadata is resolved at build time.\n\nLearn more about streaming metadata.\n\nMemoizing data requests\n\nThere may be cases where you need to fetch the same data for metadata and the page itself. To avoid duplicate requests, you can use React's cache function\n to memoize the return value and only fetch the data once. For example, to fetch the blog post information for both the metadata and the page:\n\napp/lib/data.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cache } from 'react'\nimport { db } from '@/app/lib/db'\n \n// getPost will be used twice, but execute only once\nexport const getPost = cache(async (slug: string) => {\n  const res = await db.query.posts.findFirst({ where: eq(posts.slug, slug) })\n  return res\n})\napp/blog/[slug]/page.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { getPost } from '@/app/lib/data'\n \nexport async function generateMetadata({\n  params,\n}: {\n  params: { slug: string }\n}) {\n  const post = await getPost(params.slug)\n  return {\n    title: post.title,\n    description: post.description,\n  }\n}\n \nexport default async function Page({ params }: { params: { slug: string } }) {\n  const post = await getPost(params.slug)\n  return <div>{post.title}</div>\n}\nFile-based metadata\n\nThe following special files are available for metadata:\n\nfavicon.ico, apple-icon.jpg, and icon.jpg\nopengraph-image.jpg and twitter-image.jpg\nrobots.txt\nsitemap.xml\n\nYou can use these for static metadata, or you can programmatically generate these files with code.\n\nFavicons\n\nFavicons are small icons that represent your site in bookmarks and search results. To add a favicon to your application, create a favicon.ico and add to the root of the app folder.\n\nYou can also programmatically generate favicons using code. See the favicon docs for more information.\n\nStatic Open Graph images\n\nOpen Graph (OG) images are images that represent your site in social media. To add a static OG image to your application, create a opengraph-image.png file in the root of the app folder.\n\nYou can also add OG images for specific routes by creating a opengraph-image.png deeper down the folder structure. For example, to create an OG image specific to the /blog route, add a opengraph-image.jpg file inside the blog folder.\n\nThe more specific image will take precedence over any OG images above it in the folder structure.\n\nOther image formats such as jpeg, png, and gif are also supported. See the Open Graph Image docs for more information.\n\nGenerated Open Graph images\n\nThe ImageResponse constructor allows you to generate dynamic images using JSX and CSS. This is useful for OG images that depend on data.\n\nFor example, to generate a unique OG image for each blog post, add a opengraph-image.tsx file inside the blog folder, and import the ImageResponse constructor from next/og:\n\napp/blog/[slug]/opengraph-image.tsx\nTypeScript\nJavaScript\nTypeScript\nimport { ImageResponse } from 'next/og'\nimport { getPost } from '@/app/lib/data'\n \n// Image metadata\nexport const size = {\n  width: 1200,\n  height: 630,\n}\n \nexport const contentType = 'image/png'\n \n// Image generation\nexport default async function Image({ params }: { params: { slug: string } }) {\n  const post = await getPost(params.slug)\n \n  return new ImageResponse(\n    (\n      // ImageResponse JSX element\n      <div\n        style={{\n          fontSize: 128,\n          background: 'white',\n          width: '100%',\n          height: '100%',\n          display: 'flex',\n          alignItems: 'center',\n          justifyContent: 'center',\n        }}\n      >\n        {post.title}\n      </div>\n    )\n  )\n}\n\nImageResponse supports common CSS properties including flexbox and absolute positioning, custom fonts, text wrapping, centering, and nested images. See the full list of supported CSS properties.\n\nGood to know:\n\nExamples are available in the Vercel OG Playground\n.\nImageResponse uses @vercel/og\n, satori\n, and resvg to convert HTML and CSS into PNG.\nOnly flexbox and a subset of CSS properties are supported. Advanced layouts (e.g. display: grid) will not work.\nAPI Reference\nLearn more about the Metadata APIs mentioned in this page.\ngenerateMetadata\nLearn how to add Metadata to your Next.js application for improved search engine optimization (SEO) and web shareability.\ngenerateViewport\nAPI Reference for the generateViewport function.\nImageResponse\nAPI Reference for the ImageResponse constructor.\nMetadata Files\nAPI documentation for the metadata file conventions.\nfavicon, icon, and apple-icon\nAPI Reference for the Favicon, Icon and Apple Icon file conventions.\nopengraph-image and twitter-image\nAPI Reference for the Open Graph Image and Twitter Image file conventions.\nrobots.txt\nAPI Reference for robots.txt file.\nsitemap.xml\nAPI Reference for the sitemap.xml file.\nhtmlLimitedBots\nSpecify a list of user agents that should receive blocking metadata.\nPrevious\nFont Optimization\nNext\nRoute Handlers\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Proxy | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/proxy",
    "html": "App Router\nGetting Started\nProxy\nCopy page\nProxy\nProxy\n\nProxy allows you to run code before a request is completed. Then, based on the incoming request, you can modify the response by rewriting, redirecting, modifying the request or response headers, or responding directly.\n\nUse cases\n\nSome common scenarios where Proxy is effective include:\n\nQuick redirects after reading parts of the incoming request\nRewriting to different pages based on A/B tests or experiments\nModifying headers for all pages or a subset of pages\n\nProxy is not a good fit for:\n\nSlow data fetching\nSession management\n\nUsing fetch with options.cache, options.next.revalidate, or options.next.tags, has no effect in Proxy.\n\nConvention\n\nCreate a proxy.ts (or .js) file in the project root, or inside src if applicable, so that it is located at the same level as pages or app.\n\nNote: While only one proxy.ts file is supported per project, you can still organize your proxy logic into modules. Break out proxy functionalities into separate .ts or .js files and import them into your main proxy.ts file. This allows for cleaner management of route-specific proxy, aggregated in the proxy.ts for centralized control. By enforcing a single proxy file, it simplifies configuration, prevents potential conflicts, and optimizes performance by avoiding multiple proxy layers.\n\nExample\nproxy.ts\nTypeScript\nJavaScript\nTypeScript\nimport { NextResponse } from 'next/server'\nimport type { NextRequest } from 'next/server'\n \n// This function can be marked `async` if using `await` inside\nexport function proxy(request: NextRequest) {\n  return NextResponse.redirect(new URL('/home', request.url))\n}\n \n// See \"Matching Paths\" below to learn more\nexport const config = {\n  matcher: '/about/:path*',\n}\n\nRead more about using proxy, or refer to the proxy API reference.\n\nAPI Reference\nLearn more about Proxy\nproxy.js\nAPI reference for the proxy.js file.\nBackend for Frontend\nLearn how to use Next.js as a backend framework\nPrevious\nRoute Handlers\nNext\nDeploying\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Route Handlers | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/route-handlers",
    "html": "App Router\nGetting Started\nRoute Handlers\nCopy page\nRoute Handlers\nRoute Handlers\n\nRoute Handlers allow you to create custom request handlers for a given route using the Web Request\n and Response\n APIs.\n\nGood to know: Route Handlers are only available inside the app directory. They are the equivalent of API Routes inside the pages directory meaning you do not need to use API Routes and Route Handlers together.\n\nConvention\n\nRoute Handlers are defined in a route.js|ts file inside the app directory:\n\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET(request: Request) {}\n\nRoute Handlers can be nested anywhere inside the app directory, similar to page.js and layout.js. But there cannot be a route.js file at the same route segment level as page.js.\n\nSupported HTTP Methods\n\nThe following HTTP methods\n are supported: GET, POST, PUT, PATCH, DELETE, HEAD, and OPTIONS. If an unsupported method is called, Next.js will return a 405 Method Not Allowed response.\n\nExtended NextRequest and NextResponse APIs\n\nIn addition to supporting the native Request\n and Response\n APIs, Next.js extends them with NextRequest and NextResponse to provide convenient helpers for advanced use cases.\n\nCaching\n\nRoute Handlers are not cached by default. You can, however, opt into caching for GET methods. Other supported HTTP methods are not cached. To cache a GET method, use a route config option such as export const dynamic = 'force-static' in your Route Handler file.\n\napp/items/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const dynamic = 'force-static'\n \nexport async function GET() {\n  const res = await fetch('https://data.mongodb-api.com/...', {\n    headers: {\n      'Content-Type': 'application/json',\n      'API-Key': process.env.DATA_API_KEY,\n    },\n  })\n  const data = await res.json()\n \n  return Response.json({ data })\n}\n\nGood to know: Other supported HTTP methods are not cached, even if they are placed alongside a GET method that is cached, in the same file.\n\nSpecial Route Handlers\n\nSpecial Route Handlers like sitemap.ts, opengraph-image.tsx, and icon.tsx, and other metadata files remain static by default unless they use Dynamic APIs or dynamic config options.\n\nRoute Resolution\n\nYou can consider a route the lowest level routing primitive.\n\nThey do not participate in layouts or client-side navigations like page.\nThere cannot be a route.js file at the same route as page.js.\nPage\tRoute\tResult\napp/page.js\tapp/route.js\t\n Conflict\napp/page.js\tapp/api/route.js\t\n Valid\napp/[user]/page.js\tapp/api/route.js\t\n Valid\n\nEach route.js or page.js file takes over all HTTP verbs for that route.\n\napp/page.ts\nTypeScript\nJavaScript\nTypeScript\nexport default function Page() {\n  return <h1>Hello, Next.js!</h1>\n}\n \n// Conflict\n// `app/route.ts`\nexport async function POST(request: Request) {}\n\nRead more about how Route Handlers complement your frontend application, or explore the Route Handlers API Reference.\n\nRoute Context Helper\n\nIn TypeScript, you can type the context parameter for Route Handlers with the globally available RouteContext helper:\n\napp/users/[id]/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextRequest } from 'next/server'\n \nexport async function GET(_req: NextRequest, ctx: RouteContext<'/users/[id]'>) {\n  const { id } = await ctx.params\n  return Response.json({ id })\n}\n\nGood to know\n\nTypes are generated during next dev, next build or next typegen.\nAPI Reference\nLearn more about Route Handlers\nroute.js\nAPI reference for the route.js special file.\nBackend for Frontend\nLearn how to use Next.js as a backend framework\nPrevious\nMetadata and OG images\nNext\nProxy\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Deploying | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/deploying",
    "html": "App Router\nGetting Started\nDeploying\nCopy page\nDeploying\n\nNext.js can be deployed as a Node.js server, Docker container, static export, or adapted to run on different platforms.\n\nDeployment Option\tFeature Support\nNode.js server\tAll\nDocker container\tAll\nStatic export\tLimited\nAdapters\tPlatform-specific\nNode.js server\n\nNext.js can be deployed to any provider that supports Node.js. Ensure your package.json has the \"build\" and \"start\" scripts:\n\npackage.json\n{\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"next build\",\n    \"start\": \"next start\"\n  }\n}\n\nThen, run npm run build to build your application and npm run start to start the Node.js server. This server supports all Next.js features. If needed, you can also eject to a custom server.\n\nNode.js deployments support all Next.js features. Learn how to configure them for your infrastructure.\n\nTemplates\nFlightcontrol\nRailway\nReplit\nDocker\n\nNext.js can be deployed to any provider that supports Docker\n containers. This includes container orchestrators like Kubernetes or a cloud provider that runs Docker.\n\nDocker deployments support all Next.js features. Learn how to configure them for your infrastructure.\n\nNote for development: While Docker is excellent for production deployments, consider using local development (npm run dev) instead of Docker during development on Mac and Windows for better performance. Learn more about optimizing local development.\n\nTemplates\nDocker\nDocker Multi-Environment\nDigitalOcean\nFly.io\nGoogle Cloud Run\nRender\nSST\nStatic export\n\nNext.js enables starting as a static site or Single-Page Application (SPA), then later optionally upgrading to use features that require a server.\n\nSince Next.js supports static exports, it can be deployed and hosted on any web server that can serve HTML/CSS/JS static assets. This includes tools like AWS S3, Nginx, or Apache.\n\nRunning as a static export does not support Next.js features that require a server. Learn more.\n\nTemplates\nGitHub Pages\nAdapters\n\nNext.js can be adapted to run on different platforms to support their infrastructure capabilities.\n\nRefer to each provider's documentation for information on supported Next.js features:\n\nAWS Amplify Hosting\nCloudflare\nDeno Deploy\nNetlify\nVercel\n\nNote: We are working on a Deployment Adapters API\n for all platforms to adopt. After completion, we will add documentation on how to write your own adapters.\n\nPrevious\nProxy\nNext\nUpgrading\n\nWas this helpful?\n\nsupported.\nSend"
  },
  {
    "title": "Getting Started: Upgrading | Next.js",
    "url": "https://nextjs.org/docs/app/getting-started/upgrading",
    "html": "App Router\nGetting Started\nUpgrading\nCopy page\nUpgrading\nLatest version\n\nTo update to the latest version of Next.js, you can use the upgrade codemod:\n\nTerminal\nnpx @next/codemod@latest upgrade latest\n\nIf you prefer to upgrade manually, install the latest Next.js and React versions:\n\npnpm\nnpm\nyarn\nbun\nTerminal\npnpm i next@latest react@latest react-dom@latest eslint-config-next@latest\nCanary version\n\nTo update to the latest canary, make sure you're on the latest version of Next.js and everything is working as expected. Then, run the following command:\n\nTerminal\nnpm i next@canary\nFeatures available in canary\n\nThe following features are currently available in canary:\n\nCaching:\n\n\"use cache\"\ncacheLife\ncacheTag\ncacheComponents\n\nAuthentication:\n\nforbidden\nunauthorized\nforbidden.js\nunauthorized.js\nauthInterrupts\nVersion guides\nSee the version guides for in-depth upgrade instructions.\nVersion 16\nUpgrade your Next.js Application from Version 15 to 16.\nVersion 15\nUpgrade your Next.js Application from Version 14 to 15.\nVersion 14\nUpgrade your Next.js Application from Version 13 to 14.\nPrevious\nDeploying\nNext\nGuides\n\nWas this helpful?\n\nsupported.\nSend"
  }
]
</file>

<file path="output/prisma/docs.json">
[
  {
    "title": "Reference | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference",
    "html": "ORM\nReference\n\nThe reference section of the documentation is a collection of reference pages that describe the Prisma ORM APIs and database implementations.\n\nIn this section​\nPrisma Client API\n\nIf Prisma ORM's Rust engine binaries cause large bundle sizes, slow builds, or deployment issues (for example, in serverless or edge environments), you can use it without them using this configuration of your generator block:\n\nPrisma Schema\n\ndatasource\n\nPrisma CLI\n\nThis document describes the Prisma CLI commands, arguments, and options.\n\nErrors\n\nFor more information about how to work with exceptions and error codes, see Handling exceptions and errors.\n\nEnvironment variables\n\nThis document describes different environment variables and their use cases.\n\nPrisma Config\n\nOverview\n\nDatabase features matrix\n\nThis page gives an overview of the features which are provided by the databases that Prisma ORM supports. Additionally, it explains how each of these features can be used in Prisma ORM with pointers to further documentation.\n\nSupported databases\n\nPrisma ORM currently supports the following databases.\n\nConnection URLs\n\nPrisma ORM needs a connection URL to be able to connect to your database, e.g. when sending queries with Prisma Client or when changing the database schema with Prisma Migrate.\n\nSystem requirements\n\nThis page provides an overview of the system requirements for Prisma ORM.\n\nPreview features"
  },
  {
    "title": "Prisma Schema API | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-schema-reference",
    "html": "ORMReference\nPrisma schema reference\ndatasource​\n\nDefines a data source in the Prisma schema.\n\nFields​\n\nA datasource block accepts the following fields:\n\nName\tRequired\tType\tDescription\nprovider\tYes\tString (postgresql, mysql, sqlite, sqlserver, mongodb, cockroachdb)\tDescribes which data source connectors to use.\nurl\tYes\tString (URL)\tConnection URL including authentication info. Most connectors use the syntax provided by the database.\nshadowDatabaseUrl\tNo\tString (URL)\tConnection URL to the shadow database used by Prisma Migrate. Allows you to use a cloud-hosted database as the shadow database.\ndirectUrl\tNo\tString (URL)\tConnection URL for direct connection to the database.\n\nIf you use a connection pooler URL in the url argument (for example, if you use Prisma Accelerate or pgBouncer), Prisma CLI commands that require a direct connection to the database use the URL in the directUrl argument.\n\nThe directUrl property is supported by Prisma Studio from version 5.1.0 upwards.\n\nThe directUrl property is not needed when using Prisma Postgres database.\nrelationMode\tNo\tString (foreignKeys, prisma)\tSets whether referential integrity is enforced by foreign keys in the database or emulated in the Prisma Client.\n\nIn preview in versions 3.1.1 and later. The field is named relationMode in versions 4.5.0 and later, and was previously named referentialIntegrity.\nextensions\tNo\tList of strings (PostgreSQL extension names)\tAllows you to represent PostgreSQL extensions in your schema. Available in preview for PostgreSQL only in Prisma ORM versions 4.5.0 and later.\n\nThe following providers are available:\n\nsqlite\npostgresql\nmysql\nsqlserver\nmongodb\ncockroachdb\nRemarks​\nYou can only have one datasource block in a schema.\ndatasource db is convention - however, you can give your data source any name - for example, datasource mysql or datasource data.\nExamples​\nSpecify a PostgreSQL data source​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 5432\nDatabase name: mydb\nSchema name: public\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"postgresql://johndoe:mypassword@localhost:5432/mydb?schema=public\"\n\n}\n\n\nLearn more about PostgreSQL connection strings here.\n\nSpecify a PostgreSQL data source via an environment variable​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 5432\nDatabase name: mydb\nSchema name: public\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\nWhen running a Prisma CLI command that needs the database connection URL (e.g. prisma generate), you need to make sure that the DATABASE_URL environment variable is set.\n\nOne way to do so is by creating a \n.env\n file with the following contents. Note that the file must be in the same directory as your schema.prisma file to automatically picked up the Prisma CLI.\n\nDATABASE_URL=postgresql://johndoe:mypassword@localhost:5432/mydb?schema=public\n\nSpecify a MySQL data source​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 3306\nDatabase name: mydb\ndatasource db {\n\n  provider = \"mysql\"\n\n  url      = \"mysql://johndoe:mypassword@localhost:3306/mydb\"\n\n}\n\n\nLearn more about MySQL connection strings here.\n\nSpecify a MongoDB data source​\nUser: root\nPassword: password\nHost: cluster1.test1.mongodb.net\nPort: N/A\nDatabase name: testing\ndatasource db {\n\n  provider = \"mongodb\"\n\n  url      = \"mongodb+srv://root:password@cluster1.test1.mongodb.net/testing?retryWrites=true&w=majority\"\n\n}\n\n\nLearn more about MongoDB connection strings here.\n\nSpecify a SQLite data source​\n\nIn this example, the target database is located in a file called dev.db:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:./dev.db\"\n\n}\n\n\nLearn more about SQLite connection strings here.\n\nSpecify a CockroachDB data source​\n\nIn this example, the target database is available with the following credentials:\n\nUser: johndoe\nPassword: mypassword\nHost: localhost\nPort: 26257\nDatabase name: mydb\nSchema name: public\ndatasource db {\n\n  provider = \"cockroachdb\"\n\n  url      = \"postgresql://johndoe:mypassword@localhost:26257/mydb?schema=public\"\n\n}\n\n\nThe format for connection strings is the same as for PostgreSQL. Learn more about PostgreSQL connection strings here.\n\ngenerator​\n\nDefines a generator in the Prisma schema.\n\nFields for prisma-client-js provider​\n\nThis is the default generator for Prisma ORM 6.x and earlier versions. Learn more about generators.\n\nA generator block accepts the following fields:\n\nName\tRequired\tType\tDescription\nprovider\tYes\tprisma-client-js\tDescribes which generator to use. This can point to a file that implements a generator or specify a built-in generator directly.\noutput\tNo\tString (file path)\tDetermines the location for the generated client, learn more. Default: node_modules/.prisma/client\npreviewFeatures\tNo\tList of Enums\tUse intellisense to see list of currently available Preview features (Ctrl+Space in Visual Studio Code) Default: none\nengineType\tNo\tEnum (library or binary)\tDefines the query engine type to download and use. Default: library\nbinaryTargets\tNo\tList of Enums (see below)\tSpecify the OS on which the Prisma Client will run to ensure compatibility of the query engine. Default: native\nmoduleFormat\tNo\tEnum (cjs or esm)\tDefines the module format of the generated Prisma Client. This field is available only with prisma-client generator.\nIMPORTANT\n\nWe recommend defining a custom output path, adding the path to .gitignore, and then making sure to run prisma generate via a custom build script or postinstall hook.\n\nFields for prisma-client provider​\n\nThe ESM-first client generator that offers greater control and flexibility across different JavaScript environments. It generates plain TypeScript code into a custom directory, providing full visibility over the generated code. Learn more about the new prisma-client generator.\n\nNOTE\n\nThe prisma-client generator will be the default generator in Prisma ORM 7.0 and we recommend migrating to it as soon as possible. It has been Generally Available since v6.16.0\n.\n\nA generator block accepts the following fields:\n\nName\tRequired\tType\tDescription\nprovider\tYes\tprisma-client\tDescribes which generator to use. This can point to a file that implements a generator or specify a built-in generator directly.\noutput\tYes\tString (file path)\tDetermines the location for the generated client, learn more.\npreviewFeatures\tNo\tList of Enums\tUse intellisense to see list of currently available Preview features (Ctrl+Space in Visual Studio Code) Default: none\nruntime\tNo\tEnum (nodejs, deno, bun, workerd (alias cloudflare), vercel-edge (alias edge-light), react-native)\tTarget runtime environment. Default: nodejs\nmoduleFormat\tNo\tEnum (esm or cjs)\tDetermines whether the generated code supports ESM (uses import) or CommonJS (uses require(...)) modules. We always recommend esm unless you have a good reason to use cjs. Default: Inferred from environment.\ngeneratedFileExtension\tNo\tEnum (ts or mts or cts)\tFile extension for generated TypeScript files. Default: ts\nimportFileExtension\tNo\tEnum (ts,mts,cts,js,mjs,cjs, empty (for bare imports))\tFile extension used in import statements Default: Inferred from environment.\nbinaryTargets options​\n\nThe following tables list all supported operating systems with the name of platform to specify in binaryTargets.\n\nUnless specified otherwise, the default supported CPU architecture is x86_64.\n\nmacOS​\nBuild OS\tPrisma engine build name\nmacOS Intel x86_64\tdarwin\nmacOS ARM64\tdarwin-arm64\nWindows​\nBuild OS\tPrisma engine build name\nWindows\twindows\nLinux (Alpine on x86_64 architectures)​\nBuild OS\tPrisma engine build name\tOpenSSL\nAlpine (3.17 and newer)\tlinux-musl-openssl-3.0.x*\t3.0.x\nAlpine (3.16 and older)\tlinux-musl\t1.1.x\n\n* Available in Prisma ORM versions 4.8.0 and later.\n\nLinux (Alpine on ARM64 architectures)​\nBuild OS\tPrisma engine build name\tOpenSSL\nAlpine (3.17 and newer)\tlinux-musl-arm64-openssl-3.0.x*\t3.0.x\nAlpine (3.16 and older)\tlinux-musl-arm64-openssl-1.1.x*\t1.1.x\n\n* Available in Prisma ORM versions 4.10.0 and later.\n\nLinux (Debian), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nDebian 8 (Jessie)\tdebian-openssl-1.0.x\t1.0.x\nDebian 9 (Stretch)\tdebian-openssl-1.1.x\t1.1.x\nDebian 10 (Buster)\tdebian-openssl-1.1.x\t1.1.x\nDebian 11 (Bullseye)\tdebian-openssl-1.1.x\t1.1.x\nDebian 12 (Bookworm)\tdebian-openssl-3.0.x\t3.0.x\nLinux (Ubuntu), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nUbuntu 14.04 (trusty)\tdebian-openssl-1.0.x\t1.0.x\nUbuntu 16.04 (xenial)\tdebian-openssl-1.0.x\t1.0.x\nUbuntu 18.04 (bionic)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 19.04 (disco)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 20.04 (focal)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 21.04 (hirsute)\tdebian-openssl-1.1.x\t1.1.x\nUbuntu 22.04 (jammy)\tdebian-openssl-3.0.x\t3.0.x\nUbuntu 23.04 (lunar)\tdebian-openssl-3.0.x\t3.0.x\nLinux (CentOS), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nCentOS 7\trhel-openssl-1.0.x\t1.0.x\nCentOS 8\trhel-openssl-1.1.x\t1.1.x\nLinux (Fedora), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nFedora 28\trhel-openssl-1.1.x\t1.1.x\nFedora 29\trhel-openssl-1.1.x\t1.1.x\nFedora 30\trhel-openssl-1.1.x\t1.1.x\nFedora 36\trhel-openssl-3.0.x\t3.0.x\nFedora 37\trhel-openssl-3.0.x\t3.0.x\nFedora 38\trhel-openssl-3.0.x\t3.0.x\nLinux (Linux Mint), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nLinux Mint 18\tdebian-openssl-1.0.x\t1.0.x\nLinux Mint 19\tdebian-openssl-1.1.x\t1.1.x\nLinux Mint 20\tdebian-openssl-1.1.x\t1.1.x\nLinux Mint 21\tdebian-openssl-3.0.x\t3.0.x\nLinux (Arch Linux), x86_64​\nBuild OS\tPrisma engine build name\tOpenSSL\nArch Linux 2019.09.01\tdebian-openssl-1.1.x\t1.1.x\nArch Linux 2023.04.23\tdebian-openssl-3.0.x\t3.0.x\nLinux ARM64 (all major distros but Alpine)​\nBuild OS\tPrisma engine build name\tOpenSSL\nLinux ARM64 glibc-based distro\tlinux-arm64-openssl-1.0.x\t1.0.x\nLinux ARM64 glibc-based distro\tlinux-arm64-openssl-1.1.x\t1.1.x\nLinux ARM64 glibc-based distro\tlinux-arm64-openssl-3.0.x\t3.0.x\nExamples​\nSpecify the prisma-client-js generator with the default output, previewFeatures, engineType and binaryTargets​\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\n\nNote that the above generator definition is equivalent to the following because it uses the default values for output, engineType and binaryTargets (and implicitly previewFeatures):\n\ngenerator client {\n\n  provider      = \"prisma-client-js\"\n\n  output        = \"node_modules/.prisma/client\"\n\n  engineType    = \"library\"\n\n  binaryTargets = [\"native\"]\n\n}\n\nSpecify a custom output location for Prisma Client​\n\nThis example shows how to define a custom output location of the generated asset to override the default one.\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output   = \"../src/generated/client\"\n\n}\n\nSpecify custom binaryTargets to ensure compatibility with the OS​\n\nThis example shows how to configure Prisma Client to run on Ubuntu 19.04 (disco) based on the table above.\n\ngenerator client {\n\n  provider      = \"prisma-client-js\"\n\n  binaryTargets = [\"debian-openssl-1.1.x\"]\n\n}\n\nSpecify a provider pointing to some custom generator implementation​\n\nThis example shows how to use a custom generator that's located in a directory called my-generator.\n\ngenerator client {\n\n  provider = \"./my-generator\"\n\n}\n\nmodel​\n\nDefines a Prisma model .\n\nRemarks​\nEvery record of a model must be uniquely identifiable. You must define at least one of the following attributes per model:\n@unique\n@@unique\n@id\n@@id\nNaming conventions​\nModel names must adhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\nModel names must start with a letter and are typically spelled in PascalCase\nModel names should use the singular form (for example, User instead of user, users or Users)\nPrisma ORM has a number of reserved words that are being used by Prisma ORM internally and therefore cannot be used as a model name. You can find the reserved words here\n and here\n.\n\nNote: You can use the @@map attribute to map a model (for example, User) to a table with a different name that does not match model naming conventions (for example, users).\n\nOrder of fields​\nIn version 2.3.0 and later, introspection lists model fields in the same order as the corresponding columns in the database. Relation fields are listed after scalar fields.\nExamples​\nA model named User with two scalar fields​\nRelational databases\nMongoDB\nmodel User {\n\n  email String  @unique // `email` can not be optional because it's the only unique field on the model\n\n  name  String?\n\n}\n\nmodel fields​\n\nFields are properties of models.\n\nRemarks​\nNaming conventions​\nMust start with a letter\nTypically spelled in camelCase\nMust adhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\n\nNote: You can use the @map attribute to map a field name to a column with a different name that does not match field naming conventions: e.g. myField @map(\"my_field\").\n\nmodel field scalar types​\n\nThe data source connector determines what native database type each of Prisma ORM scalar type maps to. Similarly, the generator determines what type in the target programming language each of these types map to.\n\nPrisma models also have model field types that define relations between models.\n\nString​\n\nVariable length text.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\ttext\nSQL Server\tnvarchar(1000)\nMySQL\tvarchar(191)\nMongoDB\tString\nSQLite\tTEXT\nCockroachDB\tSTRING\nPostgreSQL​\nNative database type\tNative database type attribute\tNotes\ntext\t@db.Text\t\nchar(x)\t@db.Char(x)\t\nvarchar(x)\t@db.VarChar(x)\t\nbit(x)\t@db.Bit(x)\t\nvarbit\t@db.VarBit\t\nuuid\t@db.Uuid\t\nxml\t@db.Xml\t\ninet\t@db.Inet\t\ncitext\t@db.Citext\tOnly available if Citext extension is enabled.\nMySQL​\nNative database type\tNative database type attribute\nVARCHAR(x)\t@db.VarChar(x)\nTEXT\t@db.Text\nCHAR(x)\t@db.Char(x)\nTINYTEXT\t@db.TinyText\nMEDIUMTEXT\t@db.MediumText\nLONGTEXT\t@db.LongText\n\nYou can use Prisma Migrate to map @db.Bit(1) to String:\n\nmodel Model {\n\n  /* ... */\n\n  myField String @db.Bit(1)\n\n}\n\nMongoDB​\n\nString\n\nNative database type attribute\tNotes\n@db.String\t\n@db.ObjectId\tRequired if the underlying BSON type is OBJECT_ID (ID fields, relation scalars)\nMicrosoft SQL Server​\nNative database type\tNative database type attribute\nchar(x)\t@db.Char(x)\nnchar(x)\t@db.NChar(x)\nvarchar(x)\t@db.VarChar(x)\nnvarchar(x)\t@db.NVarChar(x)\ntext\t@db.Text\nntext\t@db.NText\nxml\t@db.Xml\nuniqueidentifier\t@db.UniqueIdentifier\nSQLite​\n\nTEXT\n\nCockroachDB​\nNative database type\tNative database type attribute\tNotes\nSTRING(x) | TEXT(x) | VARCHAR(x)\t@db.String(x)\t\nCHAR(x)\t@db.Char(x)\t\n\"char\"\t@db.CatalogSingleChar\t\nBIT(x)\t@db.Bit(x)\t\nVARBIT\t@db.VarBit\t\nUUID\t@db.Uuid\t\nINET\t@db.Inet\t\n\nNote that the xml and citext types supported in PostgreSQL are not currently supported in CockroachDB.\n\nClients​\nPrisma Client JS\nstring\nBoolean​\n\nTrue or false value.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tboolean\nSQL Server\tbit\nMySQL\tTINYINT(1)\nMongoDB\tBool\nSQLite\tINTEGER\nCockroachDB\tBOOL\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\nboolean\t@db.Boolean\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nTINYINT(1)\t@db.TinyInt(1)\tTINYINT maps to Int if the max length is greater than 1 (for example, TINYINT(2)) or the default value is anything other than 1, 0, or NULL\nBIT(1)\t@db.Bit\t\nMongoDB​\n\nBool\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nbit\t@db.Bit\t\nSQLite​\n\nINTEGER\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nBOOL\t@db.Bool\t\nClients​\nPrisma Client JS\nboolean\nInt​\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tinteger\nSQL Server\tint\nMySQL\tINT\nMongoDB\tInt\nSQLite\tINTEGER\nCockroachDB\tINT\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ninteger | int, int4\t@db.Integer\t\nsmallint | int2\t@db.SmallInt\t\nsmallserial | serial2\t@db.SmallInt @default(autoincrement())\t\nserial | serial4\t@db.Int @default(autoincrement())\t\noid\t@db.Oid\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nINT\t@db.Int\t\nINT UNSIGNED\t@db.UnsignedInt\t\nSMALLINT\t@db.SmallInt\t\nSMALLINT UNSIGNED\t@db.UnsignedSmallInt\t\nMEDIUMINT\t@db.MediumInt\t\nMEDIUMINT UNSIGNED\t@db.UnsignedMediumInt\t\nTINYINT\t@db.TinyInt\tTINYINT maps to Int if the max length is greater than 1 (for example, TINYINT(2)) or the default value is anything other than 1, 0, or NULL. TINYINT(1) maps to Boolean.\nTINYINT UNSIGNED\t@db.UnsignedTinyInt\tTINYINT(1) UNSIGNED maps to Int, not Boolean\nYEAR\t@db.Year\t\nMongoDB​\n\nInt\n\nNative database type attribute\tNotes\n@db.Int\t\n@db.Long\t\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nint\t@db.Int\t\nsmallint\t@db.SmallInt\t\ntinyint\t@db.TinyInt\t\nbit\t@db.Bit\t\nSQLite​\n\nINTEGER\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nINTEGER | INT | INT8\t@db.Int8\tNote that this differs from PostgreSQL, where integer and int are aliases for int4 and map to @db.Integer\nINT4\t@db.Int4\t\nINT2 | SMALLINT\t@db.Int2\t\nSMALLSERIAL | SERIAL2\t@db.Int2 @default(autoincrement())\t\nSERIAL | SERIAL4\t@db.Int4 @default(autoincrement())\t\nSERIAL8 | BIGSERIAL\t@db.Int8 @default(autoincrement())\t\nClients​\nPrisma Client JS\nnumber\nBigInt​\n\nBigInt is available in version 2.17.0\n and later.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tbigint\nSQL Server\tint\nMySQL\tBIGINT\nMongoDB\tLong\nSQLite\tINTEGER\nCockroachDB\tINTEGER\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\nbigint | int8\t@db.BigInt\t\nbigserial | serial8\t@db.BigInt @default(autoincrement())\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nBIGINT\t@db.BigInt\t\nSERIAL\t@db.UnsignedBigInt @default(autoincrement())\t\nMongoDB​\n\nLong\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nbigint\t@db.BigInt\t\nSQLite​\n\nINTEGER\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nBIGINT | INT | INT8\t@db.Int8\tNote that this differs from PostgreSQL, where int is an alias for int4\nbigserial | serial8\t@db.Int8 @default(autoincrement())\t\nClients​\nClient\tType\tDescription\nPrisma Client JS\t\nBigInt\n\tSee examples of working with BigInt\nFloat​\n\nFloating point number.\n\nFloat maps to Double in 2.17.0\n and later - see release notes\n and Video: Changes to the default mapping of Float in Prisma ORM 2.17.0\n for more information about this change.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tdouble precision\nSQL Server\tfloat(53)\nMySQL\tDOUBLE\nMongoDB\tDouble\nSQLite\tREAL\nCockroachDB\tDOUBLE PRECISION\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ndouble precision\t@db.DoublePrecision\t\nreal\t@db.Real\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nFLOAT\t@db.Float\t\nDOUBLE\t@db.Double\t\nMongoDB​\n\nDouble\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\nfloat\t@db.Float\nmoney\t@db.Money\nsmallmoney\t@db.SmallMoney\nreal\t@db.Real\nSQLite connector​\n\nREAL\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nDOUBLE PRECISION | FLOAT8\t@db.Float8\t\nREAL | FLOAT4 | FLOAT\t@db.Float4\t\nClients​\nPrisma Client JS\nnumber\nDecimal​\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tdecimal(65,30)\nSQL Server\tdecimal(32,16)\nMySQL\tDECIMAL(65,30)\nMongoDB\tNot supported\n\nSQLite\tDECIMAL\nCockroachDB\tDECIMAL\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ndecimal | numeric\t@db.Decimal(p, s)†\t\nmoney\t@db.Money\t\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nMySQL​\nNative database types\tNative database type attribute\tNotes\nDECIMAL | NUMERIC\t@db.Decimal(p, s)†\t\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nMongoDB​\n\nNot supported\n.\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\ndecimal | numeric\t@db.Decimal(p, s)†\t\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nSQLite​\n\nDECIMAL (changed from REAL in 2.17.0)\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nDECIMAL | DEC | NUMERIC\t@db.Decimal(p, s)†\t\nmoney\tNot yet\tPostgreSQL's money type is not yet supported by CockroachDB\n† p (precision), the maximum total number of decimal digits to be stored. s (scale), the number of decimal digits that are stored to the right of the decimal point.\nClients​\nClient\tType\tDescription\nPrisma Client JS\t\nDecimal\n\tSee examples of working with Decimal\nDateTime​\nRemarks​\nPrisma Client returns all DateTime as native \nDate\n objects.\nCurrently, Prisma ORM does not support\n zero dates\n (0000-00-00 00:00:00, 0000-00-00, 00:00:00) in MySQL.\nThere currently is a bug\n that doesn't allow you to pass in DateTime values as strings and produces a runtime error when you do. DateTime values need to be passed as \nDate\n objects (i.e. new Date('2024-12-04') instead of '2024-12-04').\n\nYou can find more info and examples in this section: Working with DateTime.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\ttimestamp(3)\nSQL Server\tdatetime2\nMySQL\tDATETIME(3)\nMongoDB\tTimestamp\nSQLite\tNUMERIC\nCockroachDB\tTIMESTAMP\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\ntimestamp(x)\t@db.Timestamp(x)\t\ntimestamptz(x)\t@db.Timestamptz(x)\t\ndate\t@db.Date\t\ntime(x)\t@db.Time(x)\t\ntimetz(x)\t@db.Timetz(x)\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nDATETIME(x)\t@db.DateTime(x)\t\nDATE(x)\t@db.Date(x)\t\nTIME(x)\t@db.Time(x)\t\nTIMESTAMP(x)\t@db.Timestamp(x)\t\n\nYou can also use MySQL's YEAR type with Int:\n\nyearField     Int    @db.Year\n\nMongoDB​\n\nTimestamp\n\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\ndate\t@db.Date\t\ntime\t@db.Time\t\ndatetime\t@db.DateTime\t\ndatetime2\t@db.DateTime2\t\nsmalldatetime\t@db.SmallDateTime\t\ndatetimeoffset\t@db.DateTimeOffset\t\nSQLite​\n\nNUMERIC or STRING. If the underlying data type is STRING, you must use one of the following formats:\n\nRFC 3339\n (1996-12-19T16:39:57-08:00)\nRFC 2822\n (Tue, 1 Jul 2003 10:52:37 +0200)\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nTIMESTAMP(x)\t@db.Timestamp(x)\t\nTIMESTAMPTZ(x)\t@db.Timestamptz(x)\t\nDATE\t@db.Date\t\nTIME(x)\t@db.Time(x)\t\nTIMETZ(x)\t@db.Timetz(x)\t\nClients​\nPrisma Client JS\nDate\nJson​\n\nA JSON object.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tjsonb\nSQL Server\tNot supported\n\nMySQL\tJSON\nMongoDB\tA valid\nBSON\nobject (Relaxed mode)\n\nSQLite\tJSONB\nCockroachDB\tJSONB\nPostgreSQL​\nNative database types\tNative database type attribute\tNotes\njson\t@db.Json\t\njsonb\t@db.JsonB\t\nMySQL​\nNative database types\tNative database type attribute\tNotes\nJSON\t@db.Json\t\nMongoDB​\n\nA valid\nBSON\nobject (Relaxed mode)\n\nMicrosoft SQL Server​\n\nMicrosoft SQL Server does not have a specific data type for JSON. However, there are a number of built-in functions for reading and modifying JSON\n.\n\nSQLite​\n\nNot supported\n\nCockroachDB​\nNative database types\tNative database type attribute\tNotes\nJSON | JSONB\t@db.JsonB\t\nClients​\nPrisma Client JS\nobject\nBytes​\n\nBytes is available in version 2.17.0\n and later.\n\nDefault type mappings​\nConnector\tDefault mapping\nPostgreSQL\tbytea\nSQL Server\tvarbinary\nMySQL\tLONGBLOB\nMongoDB\tBinData\nSQLite\tBLOB\nCockroachDB\tBYTES\nPostgreSQL​\nNative database types\tNative database type attribute\nbytea\t@db.ByteA\nMySQL​\nNative database types\tNative database type attribute\tNotes\nLONGBLOB\t@db.LongBlob\t\nBINARY\t@db.Binary\t\nVARBINARY\t@db.VarBinary\t\nTINYBLOB\t@db.TinyBlob\t\nBLOB\t@db.Blob\t\nMEDIUMBLOB\t@db.MediumBlob\t\nBIT\t@db.Bit\t\nMongoDB​\n\nBinData\n\nNative database type attribute\tNotes\n@db.ObjectId\tRequired if the underlying BSON type is OBJECT_ID (ID fields, relation scalars)\n@db.BinData\t\nMicrosoft SQL Server​\nNative database types\tNative database type attribute\tNotes\nbinary\t@db.Binary\t\nvarbinary\t@db.VarBinary\t\nimage\t@db.Image\t\nSQLite​\n\nBLOB\n\nCockroachDB​\nNative database types\tNative database type attribute\nBYTES | BYTEA | BLOB\t@db.Bytes\nClients​\nClient\tType\tDescription\nPrisma Client JS\t\nUint8Array\n\tSee examples of working with Bytes\nPrisma Client JS (before v6)\t\nBuffer\n\tSee examples of working with Bytes\nUnsupported​\nWARNING\n\nNot supported by MongoDB\nThe MongoDB connector does not support the Unsupported type.\n\nThe Unsupported type was introduced in 2.17.0\n and allows you to represent data types in the Prisma schema that are not supported by Prisma Client. Fields of type Unsupported can be created during Introspection with prisma db pull or written by hand, and created in the database with Prisma Migrate or db push.\n\nRemarks​\n\nFields with Unsupported types are not available in the generated client.\n\nIf a model contains a required Unsupported type, prisma.model.create(..), prisma.model.update(...) and prisma.model.upsert(...) are not available in Prisma Client.\n\nWhen you introspect a database that contains unsupported types, Prisma ORM will provide the following warning:\n\n*** WARNING ***\n\n\n\nThese fields are not supported by Prisma Client, because Prisma does not currently support their types.\n\n* Model \"Post\", field: \"circle\", original data type: \"circle\"\n\nExamples​\nmodel Star {\n\n  id       Int                    @id @default(autoincrement())\n\n  position Unsupported(\"circle\")?\n\n  example1 Unsupported(\"circle\")\n\n  circle   Unsupported(\"circle\")? @default(dbgenerated(\"'<(10,4),11>'::circle\"))\n\n}\n\nmodel field type modifiers​\n[] modifier​\n\nMakes a field a list.\n\nRemarks​\nCannot be optional (for example Post[]?).\nRelational databases​\nScalar lists (arrays) are only supported in the data model if your database natively supports them. Currently, scalar lists are therefore only supported when using PostgreSQL or CockroachDB (since MySQL and SQLite don't natively support scalar lists).\nMongoDB​\nScalar lists are supported\nExamples​\nDefine a scalar list​\nRelational databases\nMongoDB\nmodel User {\n\n  id             Int      @id @default(autoincrement())\n\n  favoriteColors String[]\n\n}\n\nDefine a scalar list with a default value​\n\nAvailable in version 4.0.0 and later.\n\nRelational databases\nMongoDB\nmodel User {\n\n  id             Int      @id @default(autoincrement())\n\n  favoriteColors String[] @default([\"red\", \"blue\", \"green\"])\n\n}\n\n? modifier​\n\nMakes a field optional.\n\nRemarks​\nCannot be used with a list field (for example, Posts[])\nExamples​\nOptional name field​\nmodel User {\n\n  id   Int     @id @default(autoincrement())\n\n  name String?\n\n}\n\nAttributes​\n\nAttributes modify the behavior of a field or block (e.g. models). There are two ways to add attributes to your data model:\n\nField attributes are prefixed with @\nBlock attributes are prefixed with @@\n\nSome attributes take arguments. Arguments in attributes are always named, but in most cases the argument name can be omitted.\n\nNote: The leading underscore in a signature means the argument name can be omitted.\n\n@id​\n\nDefines a single-field ID on the model.\n\nRemarks​\nGeneral​\nCannot be defined on a relation field\nCannot be optional\nRelational databases​\n\nCorresponding database construct: PRIMARY KEY\n\nCan be annotated with a @default attribute that uses functions to auto-generate an ID:\n\nautoincrement()\ncuid()\nuuid()\nulid()\n\nCan be defined on any scalar field (String, Int, enum)\n\nMongoDB​\n\nCorresponding database construct: Any valid BSON type, except arrays\n\nEvery model must define an @id field\n\nThe underlying ID field name is always\n_id\n, and must be mapped with @map(\"_id\")\n\nCan be defined on any scalar field (String, Int, enum) unless you want to use ObjectId in your database\n\nTo use an \nObjectId\n as your ID, you must:\n\nUse the String or Bytes field type\n\nAnnotate your field with @db.ObjectId:\n\nid   String  @db.ObjectId  @map(\"_id\")\n\n\nOptionally, annotate your field with a @default attribute that uses the auto() function to auto-generate an ObjectId\n\nid   String  @db.ObjectId  @map(\"_id\") @default(auto())\n\n\ncuid(), uuid() and ulid() are supported but do not generate a valid ObjectId - use auto() instead for @id\n\nautoincrement() is not supported\n\nArguments​\nName\tRequired\tType\tDescription\nmap\tNo\tString\tThe name of the underlying primary key constraint in the database.\n\nNot supported for MySQL or MongoDB.\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the ID are stored in the database. The available options are Asc and Desc.\n\nSQL Server only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the ID is clustered or non-clustered. Defaults to true.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\nSignature​\n@id(map: String?, length: number?, sort: String?, clustered: Boolean?)\n\n\nNote: Before version 4.0.0, or 3.5.0 with the extendedIndexes Preview feature enabled, the signature was:\n\n@id(map: String?)\n\n\nNote: Before version 3.0.0, the signature was:\n\n@id\n\nExamples​\n\nIn most cases, you want your database to create the ID. To do this, annotate the ID field with the @default attribute and initialize the field with a function.\n\nGenerate autoincrementing integers as IDs (Relational databases only)​\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n}\n\nGenerate ObjectId as IDs (MongoDB only)​\nmodel User {\n\n  id   String @id @default(auto()) @map(\"_id\") @db.ObjectId\n\n  name String\n\n}\n\nGenerate cuid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(cuid())\n\n  name String\n\n}\n\nGenerate uuid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(uuid())\n\n  name String\n\n}\n\nGenerate ulid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(ulid())\n\n  name String\n\n}\n\nSingle-field IDs without default values​\n\nIn the following example, id does not have a default value:\n\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id\n\n  name String\n\n}\n\n\nNote that in the above case, you must provide your own ID values when creating new records for the User model using Prisma Client, e.g.:\n\nconst newUser = await prisma.user.create({\n\n  data: {\n\n    id: 1,\n\n    name: \"Alice\",\n\n  },\n\n});\n\nSpecify an ID on relation scalar field without a default value​\n\nIn the following example, authorId is a both a relation scalar and the ID of Profile:\n\nRelational databases\nMongoDB\nmodel Profile {\n\n  authorId Int    @id\n\n  author   User   @relation(fields: [authorId], references: [id])\n\n  bio      String\n\n}\n\n\n\nmodel User {\n\n  id      Int      @id\n\n  email   String   @unique\n\n  name    String?\n\n  profile Profile?\n\n}\n\n\nIn this scenario, you cannot create a Profile only - you must use Prisma Client's nested writes create a User or connect the profile to an existing user.\n\nThe following example creates a user and a profile:\n\nconst userWithProfile = await prisma.user.create({\n\n  data: {\n\n    id: 3,\n\n    email: \"bob@prisma.io\",\n\n    name: \"Bob Prismo\",\n\n    profile: {\n\n      create: {\n\n        bio: \"Hello, I'm Bob Prismo and I love apples, blue nail varnish, and the sound of buzzing mosquitoes.\",\n\n      },\n\n    },\n\n  },\n\n});\n\n\nThe following example connects a new profile to a user:\n\nconst profileWithUser = await prisma.profile.create({\n\n  data: {\n\n    bio: \"Hello, I'm Bob and I like nothing at all. Just nothing.\",\n\n    author: {\n\n      connect: {\n\n        id: 22,\n\n      },\n\n    },\n\n  },\n\n});\n\n@@id​\nWARNING\n\nNot supported by MongoDB\nThe MongoDB connector does not support composite IDs.\n\nDefines a multi-field ID (composite ID) on the model.\n\nRemarks​\nCorresponding database type: PRIMARY KEY\nCan be annotated with a @default attribute that uses functions to auto-generate an ID\nCannot be optional\nCan be defined on any scalar field (String, Int, enum)\nCannot be defined on a relation field\nThe name of the composite ID field in Prisma Client has the following pattern: field1_field2_field3\nArguments​\nName\tRequired\tType\tDescription\nfields\tYes\tFieldReference[]\tA list of field names - for example, [\"firstname\", \"lastname\"]\nname\tNo\tString\tThe name that Prisma Client will expose for the argument covering all fields, e.g. fullName in fullName: { firstName: \"First\", lastName: \"Last\"}\nmap\tNo\tString\tThe name of the underlying primary key constraint in the database.\n\nNot supported for MySQL.\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the ID are stored in the database. The available options are Asc and Desc.\n\nSQL Server only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the ID is clustered or non-clustered. Defaults to true.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\n\nThe name of the fields argument on the @@id attribute can be omitted:\n\n@@id(fields: [title, author])\n\n@@id([title, author])\n\nSignature​\n@@id(_ fields: FieldReference[], name: String?, map: String?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@@id(_ fields: FieldReference[])\n\nExamples​\nSpecify a multi-field ID on two String fields (Relational databases only)​\nmodel User {\n\n  firstName String\n\n  lastName  String\n\n  email     String  @unique\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@id([firstName, lastName])\n\n}\n\n\nWhen you create a user, you must provide a unique combination of firstName and lastName:\n\nconst user = await prisma.user.create({\n\n  data: {\n\n    firstName: \"Alice\",\n\n    lastName: \"Smith\",\n\n  },\n\n});\n\n\nTo retrieve a user, use the generated composite ID field (firstName_lastName):\n\nconst user = await prisma.user.findUnique({\n\n  where: {\n\n    firstName_lastName: {\n\n      firstName: \"Alice\",\n\n      lastName: \"Smith\",\n\n    },\n\n  },\n\n});\n\nSpecify a multi-field ID on two String fields and one Boolean field (Relational databases only)​\nmodel User {\n\n  firstName String\n\n  lastName  String\n\n  email     String  @unique\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@id([firstName, lastName, isAdmin])\n\n}\n\n\nWhen creating new User records, you now must provide a unique combination of values for firstName, lastName and isAdmin:\n\nconst user = await prisma.user.create({\n\n  data: {\n\n    firstName: \"Alice\",\n\n    lastName: \"Smith\",\n\n    isAdmin: true,\n\n  },\n\n});\n\nSpecify a multi-field ID that includes a relation field (Relational databases only)​\nmodel Post {\n\n  title     String\n\n  published Boolean @default(false)\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int\n\n\n\n  @@id([authorId, title])\n\n}\n\n\n\nmodel User {\n\n  id    Int     @default(autoincrement())\n\n  email String  @unique\n\n  name  String?\n\n  posts Post[]\n\n}\n\n\nWhen creating new Post records, you now must provide a unique combination of values for authorId (foreign key) and title:\n\nconst post = await prisma.post.create({\n\n  data: {\n\n    title: \"Hello World\",\n\n    author: {\n\n      connect: {\n\n        email: \"alice@prisma.io\",\n\n      },\n\n    },\n\n  },\n\n});\n\n@default​\n\nDefines a default value for a field.\n\nRemarks​\nDefault values that cannot yet be represented in the Prisma schema are represented by the dbgenerated() function when you use introspection.\nDefault values are not allowed on relation fields in the Prisma schema. Note however that you can still define default values on the fields backing a relation (the ones listed in the fields argument in the @relation attribute). A default value on the field backing a relation will mean that relation is populated automatically for you.\nDefault values can be used with scalar lists in databases that natively support them.\nRelational databases​\nCorresponding database construct: DEFAULT\nDefault values can be a static value (4, \"hello\") or one of the following functions:\nautoincrement()\nsequence() (CockroachDB only)\ndbgenerated(...)\ncuid()\ncuid(2)\nuuid()\nuuid(4)\nuuid(7)\nulid()\nnanoid()\nnow()\nDefault values that cannot yet be represented in the Prisma schema are represented by the dbgenerated(...) function when you use introspection.\nDefault values are not allowed on relation fields in the Prisma schema. Note however that you can still define default values on the fields backing a relation (the ones listed in the fields argument in the @relation attribute). A default value on the field backing a relation will mean that relation is populated automatically for you.\nDefault values can be used with scalar lists in databases that natively support them.\nJSON data. Note that JSON needs to be enclosed with double-quotes inside the @default attribute, e.g.: @default(\"[]\"). If you want to provide a JSON object, you need to enclose it with double-quotes and then escape any internal double quotes using a backslash, e.g.: @default(\"{ \\\"hello\\\": \\\"world\\\" }\").\nMongoDB​\nDefault values can be a static value (4, \"hello\") or one of the following functions:\nauto() (can only be used with @db.ObjectId to generate an ObjectId in MongoDB)\ncuid()\nuuid()\nulid()\nnow()\nArguments​\nName\tRequired\tType\tDescription\nvalue\tYes\tAn expression (e.g. 5, true, now())\t\nmap\tNo\tString\tSQL Server only.\n\nThe name of the value argument on the @default attribute can be omitted:\n\nid Int @id @default(value: autoincrement())\n\nid Int @id @default(autoincrement())\n\nSignature​\n@default(_ value: Expression, map: String?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@default(_ value: Expression)\n\nExamples​\nDefault value for an Int​\nRelational databases\nMongoDB\nmodel User {\n\n  email        String @unique\n\n  profileViews Int    @default(0)\n\n}\n\nDefault value for a Float​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String @unique\n\n  number Float  @default(1.1)\n\n}\n\nDefault value for Decimal​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String  @unique\n\n  number Decimal @default(22.99)\n\n}\n\nDefault value for BigInt​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String @unique\n\n  number BigInt @default(34534535435353)\n\n}\n\nDefault value for a String​\nRelational databases\nMongoDB\nmodel User {\n\n  email String @unique\n\n  name  String @default(\"\")\n\n}\n\nDefault value for a Boolean​\nRelational databases\nMongoDB\nmodel User {\n\n  email   String  @unique\n\n  isAdmin Boolean @default(false)\n\n}\n\nDefault value for a DateTime​\n\nNote that static default values for DateTime are based on the ISO 8601\n standard.\n\nRelational databases\nMongoDB\nmodel User {\n\n  email String   @unique\n\n  data  DateTime @default(\"2020-03-19T14:21:00+02:00\")\n\n}\n\nDefault value for a Bytes​\nRelational databases\nMongoDB\nmodel User {\n\n  email  String @unique\n\n  secret Bytes  @default(\"SGVsbG8gd29ybGQ=\")\n\n}\n\nDefault value for an enum​\nRelational databases\nMongoDB\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\nmodel User {\n\n  id      Int      @id @default(autoincrement())\n\n  email   String   @unique\n\n  name    String?\n\n  role    Role     @default(USER)\n\n  posts   Post[]\n\n  profile Profile?\n\n}\n\nDefault values for scalar lists​\nRelational databases\nMongoDB\nmodel User {\n\n  id             Int      @id @default(autoincrement())\n\n  posts          Post[]\n\n  favoriteColors String[] @default([\"red\", \"yellow\", \"purple\"])\n\n  roles          Role[]   @default([USER, DEVELOPER])\n\n}\n\n\n\nenum Role {\n\n  USER\n\n  DEVELOPER\n\n  ADMIN\n\n}\n\n@unique​\n\nDefines a unique constraint for this field.\n\nRemarks​\nGeneral​\nA field annotated with @unique can be optional or required\nA field annotated with @unique must be required if it represents the only unique constraint on a model without an @id / @@id\nA model can have any number of unique constraints\nCan be defined on any scalar field\nCannot be defined on a relation field\nRelational databases​\nCorresponding database construct: UNIQUE\nNULL values are considered to be distinct (multiple rows with NULL values in the same column are allowed)\nAdding a unique constraint automatically adds a corresponding unique index to the specified column(s).\nMongoDB​\nEnforced by a unique index in MongoDB\nArguments​\nName\tRequired\tType\tDescription\nmap\tNo\tString\t\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the constraint are stored in the database. The available options are Asc and Desc.\n\nIn preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the constraint is clustered or non-clustered. Defaults to false.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\n¹ Can be required by some of the index and field types.\nSignature​\n@unique(map: String?, length: number?, sort: String?)\n\n\nNote: Before version 4.0.0, or 3.5.0 with the extendedIndexes Preview feature enabled, the signature was:\n\n@unique(map: String?)\n\n\nNote: Before version 3.0.0, the signature was:\n\n@unique\n\nExamples​\nSpecify a unique attribute on a required String field​\nRelational databases\nMongoDB\nmodel User {\n\n  email String @unique\n\n  name  String\n\n}\n\nSpecify a unique attribute on an optional String field​\nRelational databases\nMongoDB\nmodel User {\n\n  id    Int     @id @default(autoincrement())\n\n  email String? @unique\n\n  name  String\n\n}\n\nSpecify a unique attribute on relation scalar field authorId​\nRelational databases\nMongoDB\nmodel Post {\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int     @unique\n\n  title     String\n\n  published Boolean @default(false)\n\n}\n\n\n\nmodel User {\n\n  id    Int     @id @default(autoincrement())\n\n  email String? @unique\n\n  name  String\n\n  Post  Post[]\n\n}\n\nSpecify a unique attribute with cuid() values as default values​\nRelational databases\nMongoDB\nmodel User {\n\n  token String @unique @default(cuid())\n\n  name  String\n\n}\n\n@@unique​\n\nDefines a compound unique constraint for the specified fields.\n\nRemarks​\nGeneral​\n\nAll fields that make up the unique constraint must be mandatory fields. The following model is not valid because id could be null:\n\nmodel User {\n\n  firstname Int\n\n  lastname  Int\n\n  id        Int?\n\n\n\n  @@unique([firstname, lastname, id])\n\n}\n\n\nThe reason for this behavior is that all connectors consider null values to be distinct, which means that two rows that look identical are considered unique:\n\n firstname  | lastname | id\n\n -----------+----------+------\n\n John       | Smith    | null\n\n John       | Smith    | null\n\n\nA model can have any number of @@unique blocks\n\nRelational databases​\nCorresponding database construct: UNIQUE\nA @@unique block is required if it represents the only unique constraint on a model without an @id / @@id\nAdding a unique constraint automatically adds a corresponding unique index to the specified column(s)\nMongoDB​\nEnforced by a compound index in MongoDB\nA @@unique block cannot be used as the only unique identifier for a model - MongoDB requires an @id field\nArguments​\nName\tRequired\tType\tDescription\nfields\tYes\tFieldReference[]\tA list of field names - for example, [\"firstname\", \"lastname\"]. Fields must be mandatory - see remarks.\nname\tNo\tString\tThe name of the unique combination of fields - defaults to fieldName1_fieldName2_fieldName3\nmap\tNo\tString\t\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the constraint are stored in the database. The available options are Asc and Desc.\n\nIn preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the constraint is clustered or non-clustered. Defaults to false.\n\nSQL Server only. In preview in versions 3.13.0 and later, and in general availability in versions 4.0.0 and later.\n\nThe name of the fields argument on the @@unique attribute can be omitted:\n\n@@unique(fields: [title, author])\n\n@@unique([title, author])\n\n@@unique(fields: [title, author], name: \"titleAuthor\")\n\n\nThe length and sort arguments are added to the relevant field names:\n\n@@unique(fields: [title(length:10), author])\n\n@@unique([title(sort: Desc), author(sort: Asc)])\n\nSignature​\n@@unique(_ fields: FieldReference[], name: String?, map: String?)\n\n\nNote: Before version 4.0.0, or before version 3.5.0 with the extendedIndexes Preview feature enabled, the signature was:\n\n@@unique(_ fields: FieldReference[], name: String?, map: String?)\n\n\nNote: Before version 3.0.0, the signature was:\n\n@@unique(_ fields: FieldReference[], name: String?)\n\nExamples​\nSpecify a multi-field unique attribute on two String fields​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int     @default(autoincrement())\n\n  firstName String\n\n  lastName  String\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@unique([firstName, lastName])\n\n}\n\n\nTo retrieve a user, use the generated field name (firstname_lastname):\n\nconst user = await prisma.user.findUnique({\n\n  where: {\n\n    firstName_lastName: {\n\n      firstName: \"Alice\",\n\n      lastName: \"Smith\",\n\n      isAdmin: true,\n\n    },\n\n  },\n\n});\n\nSpecify a multi-field unique attribute on two String fields and one Boolean field​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int     @default(autoincrement())\n\n  firstName String\n\n  lastName  String\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@unique([firstName, lastName, isAdmin])\n\n}\n\nSpecify a multi-field unique attribute that includes a relation field​\nRelational databases\nMongoDB\nmodel Post {\n\n  id        Int     @default(autoincrement())\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int\n\n  title     String\n\n  published Boolean @default(false)\n\n\n\n  @@unique([authorId, title])\n\n}\n\n\n\nmodel User {\n\n  id    Int    @id @default(autoincrement())\n\n  email String @unique\n\n  posts Post[]\n\n}\n\nSpecify a custom name for a multi-field unique attribute​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int     @default(autoincrement())\n\n  firstName String\n\n  lastName  String\n\n  isAdmin   Boolean @default(false)\n\n\n\n  @@unique(fields: [firstName, lastName, isAdmin], name: \"admin_identifier\")\n\n}\n\n\nTo retrieve a user, use the custom field name (admin_identifier):\n\nconst user = await prisma.user.findUnique({\n\n  where: {\n\n    admin_identifier: {\n\n      firstName: \"Alice\",\n\n      lastName: \"Smith\",\n\n      isAdmin: true,\n\n    },\n\n  },\n\n});\n\n@@index​\n\nDefines an index in the database.\n\nRemarks​\nRelational databases​\nCorresponding database construct: INDEX\nThere are some additional index configuration options that cannot be provided via the Prisma schema yet. These include:\nPostgreSQL and CockroachDB:\nDefine index fields as expressions (e.g. CREATE INDEX title ON public.\"Post\"((lower(title)) text_ops);)\nDefine partial indexes with WHERE\nCreate indexes concurrently with CONCURRENTLY\nINFO\n\nWhile you cannot configure these option in your Prisma schema, you can still configure them on the database-level directly.\n\nMongoDB​\nIn version 3.12.0 and later, you can define an index on a field of a composite type using the syntax @@index([compositeType.field]). See Defining composite type indexes for more details.\nArguments​\nName\tRequired\tType\tDescription\nfields\tYes\tFieldReference[]\tA list of field names - for example, [\"firstname\", \"lastname\"]\nname\tNo\tString\tThe name that Prisma Client will expose for the argument covering all fields, e.g. fullName in fullName: { firstName: \"First\", lastName: \"Last\"}\nmap\tNo\tmap\tThe name of the index in the underlying database (Prisma generates an index name that respects identifier length limits if you do not specify a name. Prisma uses the following naming convention: tablename.field1_field2_field3_unique)\nlength\tNo\tnumber\tAllows you to specify a maximum length for the subpart of the value to be indexed.\n\nMySQL only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nsort\tNo\tString\tAllows you to specify in what order the entries of the index or constraint are stored in the database. The available options are asc and desc.\n\nIn preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\nclustered\tNo\tBoolean\tDefines whether the index is clustered or non-clustered. Defaults to false.\n\nSQL Server only. In preview in versions 3.5.0 and later, and in general availability in versions 4.0.0 and later.\ntype\tNo\tidentifier\tAllows you to specify an index access method. Defaults to BTree.\n\nPostgreSQL and CockroachDB only. In preview with the Hash index access method in versions 3.6.0 and later, and with the Gist, Gin, SpGist and Brin methods added in 3.14.0. In general availability in versions 4.0.0 and later.\nops\tNo\tidentifier or a function\tAllows you to define the index operators for certain index types.\n\nPostgreSQL only. In preview in versions 3.14.0 and later, and in general availability in versions 4.0.0 and later.\n\nThe name of the fields argument on the @@index attribute can be omitted:\n\n@@index(fields: [title, author])\n\n@@index([title, author])\n\n\nThe length and sort arguments are added to the relevant field names:\n\n@@index(fields: [title(length:10), author])\n\n@@index([title(sort: Asc), author(sort: Desc)])\n\nSignature​\n@@index(_ fields: FieldReference[], map: String?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@@index(_ fields: FieldReference[], name: String?)\n\n\nThe old name argument will still be accepted to avoid a breaking change.\n\nExamples​\n\nAssume you want to add an index for the title field of the Post model\n\nDefine a single-column index (Relational databases only)​\nmodel Post {\n\n  id      Int     @id @default(autoincrement())\n\n  title   String\n\n  content String?\n\n\n\n  @@index([title])\n\n}\n\nDefine a multi-column index (Relational databases only)​\nmodel Post {\n\n  id      Int     @id @default(autoincrement())\n\n  title   String\n\n  content String?\n\n\n\n  @@index([title, content])\n\n}\n\nDefine an index with a name (Relational databases only)​\nmodel Post {\n\n  id      Int     @id @default(autoincrement())\n\n  title   String\n\n  content String?\n\n\n\n  @@index(fields: [title, content], name: \"main_index\")\n\n}\n\nDefine an index on a composite type field (Relational databases only)​\ntype Address {\n\n  street String\n\n  number Int\n\n}\n\n\n\nmodel User {\n\n  id      Int     @id\n\n  email   String\n\n  address Address\n\n\n\n  @@index([address.number])\n\n}\n\n@relation​\n\nDefines meta information about the relation. Learn more.\n\nRemarks​\nRelational databases​\nCorresponding database constructs: FOREIGN KEY / REFERENCES\nMongoDB​\nIf your model's primary key is of type ObjectId in the underlying database, both the primary key and the foreign key must have the @db.ObjectId attribute\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tSometimes (e.g. to disambiguate a relation)\tDefines the name of the relationship. In an m-n-relation, it also determines the name of the underlying relation table.\t\"CategoryOnPost\", \"MyRelation\"\nfields\tFieldReference[]\tOn annotated relation fields\tA list of fields of the current model\t[\"authorId\"], [\"authorFirstName, authorLastName\"]\nreferences\tFieldReference[]\tOn annotated relation fields\tA list of fields of the model on the other side of the relation\t[\"id\"], [\"firstName, lastName\"]\nmap\tString\tNo\tDefines a custom name for the foreign key in the database.\t[\"id\"], [\"firstName, lastName\"]\nonUpdate\tEnum. See Types of referential actions for values.\tNo\tDefines the referential action to perform when a referenced entry in the referenced model is being updated.\tCascade, NoAction\nonDelete\tEnum. See Types of referential actions for values.\tNo\tDefines the referential action to perform when a referenced entry in the referenced model is being deleted.\tCascade, NoAction\n\nThe name of the name argument on the @relation attribute can be omitted (references is required):\n\n@relation(name: \"UserOnPost\", references: [id])\n\n@relation(\"UserOnPost\", references: [id])\n\n\n\n// or\n\n\n\n@relation(name: \"UserOnPost\")\n\n@relation(\"UserOnPost\")\n\nSignature​\n@relation(_ name: String?, fields: FieldReference[]?, references: FieldReference[]?, onDelete: ReferentialAction?, onUpdate: ReferentialAction?, map: String?)\n\n\nWith SQLite, the signature changes to:\n\n@relation(_ name: String?, fields: FieldReference[]?, references: FieldReference[]?, onDelete: ReferentialAction?, onUpdate: ReferentialAction?)\n\n\nNote: Until version 3.0.0, the signature was:\n\n@relation(_ name: String?, fields: FieldReference[]?, references: FieldReference[]?)\n\nExamples​\n\nSee: The @relation attribute.\n\n@map​\n\nMaps a field name or enum value from the Prisma schema to a column or document field with a different name in the database. If you do not use @map, the Prisma field name matches the column name or document field name exactly.\n\nSee Using custom model and field names to see how @map and @@map changes the generated Prisma Client.\n\nRemarks​\nGeneral​\n@map does not rename the columns / fields in the database\n@map does change the field names in the generated client\nMongoDB​\n\nYour @id field must include @map(\"_id\"). For example:\n\nmodel User {\n\n  id String @default(auto()) @map(\"_id\") @db.ObjectId\n\n}\n\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tYes\tThe database column (relational databases) or document field (MongoDB) name.\t\"comments\", \"someFieldName\"\n\nThe name of the name argument on the @map attribute can be omitted:\n\n@map(name: \"is_admin\")\n\n@map(\"users\")\n\nSignature​\n@map(_ name: String)\n\nExamples​\nMap the firstName field to a column called first_name​\nRelational databases\nMongoDB\nmodel User {\n\n  id        Int    @id @default(autoincrement())\n\n  firstName String @map(\"first_name\")\n\n}\n\n\nThe generated client:\n\nawait prisma.user.create({\n\n  data: {\n\n    firstName: \"Yewande\", // first_name --> firstName\n\n  },\n\n});\n\nMap an enum named ADMIN to a database enum named admin​\nenum Role {\n\n  ADMIN    @map(\"admin\")\n\n  CUSTOMER\n\n}\n\n@@map​\n\nMaps the Prisma schema model name to a table (relational databases) or collection (MongoDB) with a different name, or an enum name to a different underlying enum in the database. If you do not use @@map, the model name matches the table (relational databases) or collection (MongoDB) name exactly.\n\nSee Using custom model and field names to see how @map and @@map changes the generated Prisma Client.\n\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tYes\tThe database table (relational databases) or collection (MongoDB) name.\t\"comments\", \"someTableOrCollectionName\"\n\nThe name of the name argument on the @@map attribute can be omitted\n\n@@map(name: \"users\")\n\n@@map(\"users\")\n\nSignature​\n@@map(_ name: String)\n\nExamples​\nMap the User model to a database table/collection named users​\nRelational databases\nMongoDB\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n\n\n  @@map(\"users\")\n\n}\n\n\nThe generated client:\n\nawait prisma.user.create({\n\n  // users --> user\n\n  data: {\n\n    name: \"Yewande\",\n\n  },\n\n});\n\nMap the Role enum to a native enum in the database named _Role its values to lowercase values in the database​\nenum Role {\n\n  ADMIN    @map(\"admin\")\n\n  CUSTOMER @map(\"customer\")\n\n\n\n  @@map(\"_Role\")\n\n}\n\n@updatedAt​\n\nAutomatically stores the time when a record was last updated. If you do not supply a time yourself, Prisma Client will automatically set the value for fields with this attribute.\n\nRemarks​\nCompatible with DateTime fields\nImplemented at Prisma ORM level\nWARNING\n\nIn versions before 4.4.0\n, if you're also using now(), the time might differ from the @updatedAt values if your database and app have different time zones. This happens because @updatedAt operates at the Prisma ORM level, while now() operates at the database level.\n\nNOTE\n\nIf you pass an empty update clause, the @updatedAt value will remain unchanged. For example:\n\nawait prisma.user.update({\n\n  where: {\n\n    id: 1,\n\n  },\n\n  data: {}, //<- Empty update clause\n\n});\n\nArguments​\n\nN/A\n\nSignature​\n@updatedAt\n\nExamples​\nRelational databases\nMongoDB\nmodel Post {\n\n  id        String   @id\n\n  updatedAt DateTime @updatedAt\n\n}\n\n@ignore​\n\nAdd @ignore to a field that you want to exclude from Prisma Client (for example, a field that you do not want Prisma Client users to update). Ignored fields are excluded from the generated Prisma Client. The model's create method is disabled when doing this for required fields with no @default (because the database cannot create an entry without that data).\n\nRemarks​\nIn 2.17.0\n and later, Prisma ORM automatically adds @ignore to fields that refer to invalid models when you introspect.\nExamples​\n\nThe following example demonstrates manually adding @ignore to exclude the email field from Prisma Client:\n\nschema.prisma\nmodel User {\n\n  id    Int    @id\n\n  name  String\n\n  email String @ignore // this field will be excluded\n\n}\n\n@@ignore​\n\nAdd @@ignore to a model that you want to exclude from Prisma Client (for example, a model that you do not want Prisma users to update). Ignored models are excluded from the generated Prisma Client.\n\nRemarks​\nIn 2.17.0\n and later, Prisma ORM adds @@ignore to an invalid model. (It also adds @ignore to relations pointing to such a model)\nExamples​\n\nIn the following example, the Post model is invalid because it does not have a unique identifier. Use @@ignore to exclude it from the generated Prisma Client API:\n\nschema.prisma\n/// The underlying table does not contain a valid unique identifier and can therefore currently not be handled by Prisma Client.\n\nmodel Post {\n\n  id       Int  @default(autoincrement()) // no unique identifier\n\n  author   User @relation(fields: [authorId], references: [id])\n\n  authorId Int\n\n\n\n  @@ignore\n\n}\n\n\nIn the following example, the Post model is invalid because it does not have a unique identifier, and the posts relation field on User is invalid because it refers to the invalid Post model. Use @@ignore on the Post model and @ignore on the posts relation field in User to exclude both the model and the relation field from the generated Prisma Client API:\n\nschema.prisma\n/// The underlying table does not contain a valid unique identifier and can therefore currently not be handled by Prisma Client.\n\nmodel Post {\n\n  id       Int  @default(autoincrement()) // no unique identifier\n\n  author   User @relation(fields: [authorId], references: [id])\n\n  authorId Int\n\n\n\n  @@ignore\n\n}\n\n\n\nmodel User {\n\n  id    Int     @id @default(autoincrement())\n\n  name  String?\n\n  posts Post[]  @ignore\n\n}\n\n@@schema​\n\nAdd @@schema to a model to specify which schema in your database should contain the table associated with that model. Learn more about adding multiple schema's here.\n\nNOTE\n\nMultiple database schema support is only available with the PostgreSQL, CockroachDB, and SQL Server connectors.\n\nArguments​\nName\tType\tRequired\tDescription\tExample\nname\tString\tYes\tThe name of the database schema.\t\"base\", \"auth\"\n\nThe name of the name argument on the @@schema attribute can be omitted\n\n@@schema(name: \"auth\")\n\n@@schema(\"auth\")\n\nSignature​\n@@schema(_ name: String)\n\nExamples​\nMap the User model to a database schema named auth​\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n}\n\n\n\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n  schemas  = [\"auth\"]\n\n}\n\n\n\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n\n\n  @@schema(\"auth\")\n\n}\n\nINFO\n\nFor more information about using the multiSchema feature, refer to this guide.\n\n@shardKey​\nNOTE\n\nThis features requires the shardKeys Preview feature flag on your generator:\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output = \"../generated/prisma\"\n\n  previewFeatures = [\"shardKeys\"]\n\n}\n\n\nThe @shardKey attribute is only compatible with PlanetScale\n databases. It enables you define a shard key\n on a field of your model:\n\nmodel User {\n\n  id     String @default(uuid())\n\n  region String @shardKey\n\n}\n\n@@shardKey​\nNOTE\n\nThis features requires the shardKeys Preview feature flag on your generator:\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output = \"../generated/prisma\"\n\n  previewFeatures = [\"shardKeys\"]\n\n}\n\n\nThe @shardKey attribute is only compatible with PlanetScale\n databases. It enables you define a shard key\n on multiple fields of your model:\n\nmodel User {\n\n  id         String @default(uuid())\n\n  country    String\n\n  customerId String\n\n  @@shardKey([country, customerId])\n\n}\n\nAttribute functions​\nauto()​\nWARNING\nThis function is available on MongoDB only.\n\nRepresents default values that are automatically generated by the database.\n\nRemarks​\nMongoDB​\n\nUsed to generate an ObjectId for @id fields:\n\nid  String  @map(\"_id\") @db.ObjectId @default(auto())\n\nRelational databases​\n\nThe auto() function is not available on relational databases.\n\nExample​\nGenerate ObjectId (MongoDB only)​\nmodel User {\n\n  id   String  @id @default(auto()) @map(\"_id\") @db.ObjectId\n\n  name String?\n\n}\n\nautoincrement()​\nWARNING\n\nNot supported by MongoDB\nThe MongoDB connector does not support the autoincrement() function.\n\nCreate a sequence of integers in the underlying database and assign the incremented values to the ID values of the created records based on the sequence.\n\nRemarks​\n\nCompatible with Int on most databases (BigInt on CockroachDB)\n\nImplemented on the database-level, meaning that it manifests in the database schema and can be recognized through introspection. Database implementations:\n\nDatabase\tImplementation\nPostgreSQL\t\nSERIAL\n type\nMySQL\t\nAUTO_INCREMENT\n attribute\nSQLite\t\nAUTOINCREMENT\n keyword\nCockroachDB\t\nSERIAL\n type\nExamples​\nGenerate autoincrementing integers as IDs (Relational databases only)​\nmodel User {\n\n  id   Int    @id @default(autoincrement())\n\n  name String\n\n}\n\nsequence()​\nINFO\n\nOnly supported by CockroachDB\nThe sequence function is only supported by CockroachDB connector.\n\nCreate a sequence of integers in the underlying database and assign the incremented values to the values of the created records based on the sequence.\n\nOptional arguments​\nArgument\tExample\nvirtual\t@default(sequence(virtual))\nVirtual sequences are sequences that do not generate monotonically increasing values and instead produce values like those generated by the built-in function unique_rowid().\ncache\t@default(sequence(cache: 20))\nThe number of sequence values to cache in memory for reuse in the session. A cache size of 1 means that there is no cache, and cache sizes of less than 1 are not valid.\nincrement\t@default(sequence(increment: 4))\nThe new value by which the sequence is incremented. A negative number creates a descending sequence. A positive number creates an ascending sequence.\nminValue\t@default(sequence(minValue: 10))\nThe new minimum value of the sequence.\nmaxValue\t@default(sequence(maxValue: 3030303))\nThe new maximum value of the sequence.\nstart\t@default(sequence(start: 2))\nThe value the sequence starts at, if it's restarted or if the sequence hits the maxValue.\nExamples​\nGenerate sequencing integers as IDs​\nmodel User {\n\n  id   Int    @id @default(sequence(maxValue: 4294967295))\n\n  name String\n\n}\n\ncuid()​\n\nGenerate a globally unique identifier based on the \ncuid\n spec.\n\nIf you'd like to use \ncuid2\n values, you can pass 2 as an argument to the cuid function: cuid(2).\n\nRemarks​\nCompatible with String.\nImplemented by Prisma ORM and therefore not \"visible\" in the underlying database schema. You can still use cuid() when using introspection by manually changing your Prisma schema and generating Prisma Client, in that case the values will be generated by Prisma's query engine.\nSince the length of cuid() output is undefined per the cuid creator, a safe field size is 30 characters, in order to allow for enough characters for very large values. If you set the field size as less than 30, and then a larger value is generated by cuid(), you might see Prisma Client errors such as Error: The provided value for the column is too long for the column's type.\nFor MongoDB: cuid() does not generate a valid ObjectId. You can use @db.ObjectId syntax if you want to use ObjectId in the underlying database. However, you can still use cuid() if your _id field is not of type ObjectId.\nExamples​\nGenerate cuid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(cuid())\n\n  name String\n\n}\n\nGenerate cuid(2) values as IDs based on the cuid2 spec​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(cuid(2))\n\n  name String\n\n}\n\nuuid()​\n\nGenerate a globally unique identifier based on the UUID\n spec. Prisma ORM supports versions 4 (default) and 7.\n\nRemarks​\nCompatible with String.\nImplemented by Prisma ORM and therefore not \"visible\" in the underlying database schema. You can still use uuid() when using introspection by manually changing your Prisma schema and generating Prisma Client, in that case the values will be generated by Prisma ORM's query engine.\nFor relational databases: If you do not want to use Prisma ORM's uuid() function, you can use the native database function with dbgenerated.\nFor MongoDB: uuid() does not generate a valid ObjectId. You can use @db.ObjectId syntax if you want to use ObjectId in the underlying database. However, you can still use uuid() if your _id field is not of type ObjectId.\nExamples​\nGenerate uuid() values as IDs using UUID v4​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(uuid())\n\n  name String\n\n}\n\nGenerate uuid(7) values as IDs using UUID v7​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(uuid(7))\n\n  name String\n\n}\n\nulid()​\n\nGenerate a universally unique lexicographically sortable identifier based on the ULID\n spec.\n\nRemarks​\nulid() will produce 128-bit random identifier represented as a 26-character long alphanumeric string, e.g.: 01ARZ3NDEKTSV4RRFFQ69G5FAV\nExamples​\nGenerate ulid() values as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(ulid())\n\n  name String\n\n}\n\nnanoid()​\n\nGenerated values based on the Nano ID\n spec. nanoid() accepts an integer value between 2 and 255 that specifies the length of the generate ID value, e.g. nanoid(16) will generated ID with 16 characters. If you don't provide a value to the nanoid() function, the default value is 21.\n\nINFO\n\nNano ID is quite comparable to UUID v4 (random-based). It has a similar number of random bits in the ID (126 in Nano ID and 122 in UUID), so it has a similar collision probability:\n\nFor there to be a one in a billion chance of duplication, 103 trillion version 4 IDs must be generated.\n\nThere are two main differences between Nano ID and UUID v4:\n\nNano ID uses a bigger alphabet, so a similar number of random bits are packed in just 21 symbols instead of 36.\nNano ID code is 4 times smaller than uuid/v4 package: 130 bytes instead of 423.\nRemarks​\nCompatible with String.\nImplemented by Prisma ORM and therefore not \"visible\" in the underlying database schema. You can still use uuid() when using introspection by manually changing your Prisma schema and generating Prisma Client, in that case the values will be generated by Prisma ORM's query engine.\nFor MongoDB: nanoid() does not generate a valid ObjectId. You can use @db.ObjectId syntax if you want to use ObjectId in the underlying database. However, you can still use nanoid() if your _id field is not of type ObjectId.\nExamples​\nGenerate nanoid() values with 21 characters as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(nanoid())\n\n  name String\n\n}\n\nGenerate nanoid() values with 16 characters as IDs​\nRelational databases\nMongoDB\nmodel User {\n\n  id   String @id @default(nanoid(16))\n\n  name String\n\n}\n\nnow()​\n\nSet a timestamp of the time when a record is created.\n\nRemarks​\nGeneral​\nCompatible with DateTime\nWARNING\n\nIn versions before 4.4.0\n, if you're also using @updatedAt, the time might differ from the now() values if your database and app have different time zones. This happens because @updatedAt operates at the Prisma ORM level, while now() operates at the database level.\n\nRelational databases​\n\nImplemented on the database-level, meaning that it manifests in the database schema and can be recognized through introspection. Database implementations:\n\nDatabase\tImplementation\nPostgreSQL\t\nCURRENT_TIMESTAMP\n and aliases like now()\nMySQL\t\nCURRENT_TIMESTAMP\n and aliases like now()\nSQLite\tCURRENT_TIMESTAMP and aliases like date('now')\nCockroachDB\t\nCURRENT_TIMESTAMP\n and aliases like now()\nMongoDB​\nImplemented at Prisma ORM level\nExamples​\nSet current timestamp value when a record is created​\nRelational databases\nMongoDB\nmodel User {\n\n  id        String   @id\n\n  createdAt DateTime @default(now())\n\n}\n\ndbgenerated(...)​\n\nRepresents default values that cannot be expressed in the Prisma schema (such as random()).\n\nRemarks​\nRelational databases​\n\nCompatible with any scalar type\n\nCan not be an empty string dbgenerated(\"\") in 2.21.0\n and later\n\nAccepts a String value in 2.17.0\n and later, which allows you to:\n\nSet default values for Unsupported types\nOverride default value behavior for supported types\n\nString values in dbgenerated(...) might not match what the DB returns as the default value, because values such as strings may be explicitly cast (e.g. 'hello'::STRING). When a mismatch is present, Prisma Migrate indicates a migration is still needed. You can use prisma db pull to infer the correct value to resolve the discrepancy. (Related issue\n)\n\nExamples​\nSet default value for Unsupported type​\ncircle     Unsupported(\"circle\")?   @default(dbgenerated(\"'<(10,4),11>'::circle\"))\n\nOverride default value behavior for supported types​\n\nYou can also use dbgenerated(...) to set the default value for supported types. For example, in PostgreSQL you can generate UUIDs at the database level rather than rely on Prisma ORM's uuid():\n\nmodel User {\n\n  id   String  @id @default(dbgenerated(\"gen_random_uuid()\")) @db.Uuid\n\n  id   String  @id @default(uuid()) @db.Uuid\n\n  test String?\n\n}\n\nINFO\n\nNote: \ngen_random_uuid()\nis a PostgreSQL function\n. To use it in PostgreSQL versions 12.13 and earlier, you must enable the pgcrypto extension.\n\nIn Prisma ORM versions 4.5.0 and later, you can declare the pgcrypto extension in your Prisma schema with the postgresqlExtensions preview feature.\n\nAttribute argument types​\nFieldReference[]​\n\nAn array of field names: [id], [firstName, lastName]\n\nString​\n\nA variable length text in double quotes: \"\", \"Hello World\", \"Alice\"\n\nExpression​\n\nAn expression that can be evaluated by Prisma ORM: 42.0, \"\", Bob, now(), cuid()\n\nenum​\nWARNING\n\nNot supported Microsoft SQL Server\nThe Microsoft SQL Server connector does not support the enum type.\n\nDefines an enum .\n\nRemarks​\nEnums are natively supported by PostgreSQL\n and MySQL\nEnums are implemented and enforced at Prisma ORM level in SQLite and MongoDB\nNaming conventions​\nEnum names must start with a letter (they are typically spelled in PascalCase\n)\nEnums must use the singular form (e.g. Role instead of role, roles or Roles).\nMust adhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\nExamples​\nSpecify an enum with two possible values​\nRelational databases\nMongoDB\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\n\n\nmodel User {\n\n  id   Int  @id @default(autoincrement())\n\n  role Role\n\n}\n\nSpecify an enum with two possible values and set a default value​\nRelational databases\nMongoDB\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\n\n\nmodel User {\n\n  id   Int  @id @default(autoincrement())\n\n  role Role @default(USER)\n\n}\n\ntype​\nWARNING\n\nComposite types are available for MongoDB only.\n\nINFO\n\nComposite types are available in versions 3.12.0 and later, and in versions 3.10.0 and later if you enable the mongodb Preview feature flag.\n\nDefines a composite type .\n\nNaming conventions​\n\nType names must:\n\nstart with a letter (they are typically spelled in PascalCase\n)\nadhere to the following regular expression: [A-Za-z][A-Za-z0-9_]*\nExamples​\nDefine a Product model with a list of Photo composite types​\nmodel Product {\n\n  id     String  @id @default(auto()) @map(\"_id\") @db.ObjectId\n\n  name   String\n\n  photos Photo[]\n\n}\n\n\n\ntype Photo {\n\n  height Int\n\n  width  Int\n\n  url    String\n\n}\n"
  },
  {
    "title": "Prisma Client API | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-client-reference",
    "html": "ORMReference\nPrisma Client API reference\nUSE PRISMA ORM WITHOUT RUST BINARIES\n\nIf Prisma ORM's Rust engine binaries cause large bundle sizes, slow builds, or deployment issues (for example, in serverless or edge environments), you can use it without them using this configuration of your generator block:\n\ngenerator client {\n\n  provider   = \"prisma-client-js\" // or \"prisma-client\"\n\n  engineType = \"client\"\n\n}\n\n\nPrisma ORM without Rust binaries has been Generally Available since v6.16.0\n.\n\nNote that you need to use a driver adapter in this case.\n\nWhen using this architecture:\n\nNo Rust query engine binary is downloaded or shipped.\nThe database connection pool is maintained by the native JS database driver you install (e.g., @prisma/adapter-pg for PostgreSQL).\n\nThis setup can simplify deployments in serverless or edge runtimes. Learn more in the docs here.\n\nCurious why we moved away from the Rust engine? Take a look at why we transitioned from Rust binary engines to an all-TypeScript approach for a faster, lighter Prisma ORM in this blog post.\n\nThe Prisma Client API reference documentation is based on the following schema:\n\nmodel User {\n\n  id           Int              @id @default(autoincrement())\n\n  name         String?\n\n  email        String           @unique\n\n  profileViews Int              @default(0)\n\n  role         Role             @default(USER)\n\n  coinflips    Boolean[]\n\n  posts        Post[]\n\n  city         String\n\n  country      String\n\n  profile      ExtendedProfile?\n\n  pets         Json\n\n}\n\n\n\nmodel ExtendedProfile {\n\n  id     Int     @id @default(autoincrement())\n\n  userId Int?    @unique\n\n  bio    String?\n\n  User   User?   @relation(fields: [userId], references: [id])\n\n}\n\n\n\nmodel Post {\n\n  id        Int     @id @default(autoincrement())\n\n  title     String\n\n  published Boolean @default(true)\n\n  author    User    @relation(fields: [authorId], references: [id])\n\n  authorId  Int\n\n  comments  Json\n\n  views     Int     @default(0)\n\n  likes     Int     @default(0)\n\n}\n\n\n\nenum Role {\n\n  USER\n\n  ADMIN\n\n}\n\n\nAll example generated types (such as UserSelect and UserWhereUniqueInput) are based on the User model.\n\nPrismaClient​\n\nThis section describes the PrismaClient constructor and its parameters.\n\nRemarks​\nParameters are validated at runtime.\ndatasources​\n\nProgrammatically overrides properties of the datasource block in the schema.prisma file - for example, as part of an integration test. See also: Data sources\n\nFrom version 5.2.0 and upwards, you can also use the datasourceUrl property to programmatically override the database connection string.\n\nProperties​\nExample property\tExample value\tDescription\ndb\t{ url: 'file:./dev_qa.db' }\tThe database connection URL.\nRemarks​\nYou must re-generate Prisma Client each time you add or rename a data source. Datasource names are included in the generated client.\nIf you named your datasource block something else in the schema, replace db with the name of your datasource block.\nExamples​\nProgrammatically override a datasource url​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  datasources: {\n\n    db: {\n\n      url: 'file:./dev_qa.db',\n\n    },\n\n  },\n\n});\n\n\nBased on the following datasource block:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\ndatasourceUrl​\n\nProgrammatically overrides the datasource block in the schema.prisma file.\n\nProperty​\nOption\tExample value\tDescription\nDatabase connection string\t'file:./dev_qa.db'\tThe database connection URL.\nExamples​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  datasourceUrl: 'postgresql://johndoe:randompassword@localhost:5432/mydb',\n\n});\n\nlog​\n\nDetermines the type and level of logging. See also: Logging\n\nOptions​\nOption\tExample\nArray of log levels\t[ \"info\", \"query\" ]\nArray of log definitions\t[ { level: \"info\", emit: \"event\" }, { level: \"warn\", emit: \"stdout\" }]\nLog levels​\nName\tExample\nquery\tLogs all queries run by Prisma.\n\nFor relational databases this logs all SQL queries. Example:\nprisma:query SELECT \"public\".\"User\".\"id\", \"public\".\"User\".\"email\" FROM \"public\".\"User\" WHERE (\"public\".\"User\".\"id\") IN (SELECT \"t0\".\"id\" FROM \"public\".\"User\" AS \"t0\" INNER JOIN \"public\".\"Post\" AS \"j0\" ON (\"j0\".\"authorId\") = (\"t0\".\"id\") WHERE (\"j0\".\"views\" > $1 AND \"t0\".\"id\" IS NOT NULL)) OFFSET $2\n\nFor MongoDB this logs queries using the \nmongosh\nshell\n format. Example:\nprisma:query db.User.deleteMany({ _id: ( $in: [ “6221ce49f756b0721fc00542”, ], }, })\ninfo\tExample:\nprisma:info Started http server on http://127.0.0.1:58471\nwarn\tWarnings.\nerror\tErrors.\nEmit formats​\nName\tDescription\nstdout\tSee: stdout\n\nevent\tRaises an event that you can subscribe to.\nEvent types​\n\nThe query event type:\n\nindex.d.ts\nexport type QueryEvent = {\n\n  timestamp: Date;\n\n  query: string; // Query sent to the database\n\n  params: string; // Query parameters\n\n  duration: number; // Time elapsed (in milliseconds) between client issuing query and database responding - not only time taken to run query\n\n  target: string;\n\n};\n\n\nNote that for MongoDB, the params and duration fields will be undefined.\n\nAll other log level event types:\n\nindex.d.ts\nexport type LogEvent = {\n\n  timestamp: Date;\n\n  message: string;\n\n  target: string;\n\n};\n\nExamples​\nLog query and info to stdout​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({ log: ['query', 'info'] });\n\n\n\nasync function main() {\n\n  const countUsers = await prisma.user.count({});\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nLog a query event to console​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  log: [{ level: 'query', emit: 'event' }],\n\n});\n\n\n\nprisma.$on('query', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nasync function main() {\n\n  const countUsers = await prisma.user.count({});\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nLog info, warn, and error events to console​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({\n\n  log: [\n\n    { level: 'warn', emit: 'event' },\n\n    { level: 'info', emit: 'event' },\n\n    { level: 'error', emit: 'event' },\n\n  ],\n\n});\n\n\n\nprisma.$on('warn', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nprisma.$on('info', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nprisma.$on('error', (e) => {\n\n  console.log(e);\n\n});\n\n\n\nasync function main() {\n\n  const countUsers = await prisma.user.count({});\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nerrorFormat​\n\nDetermines the level and formatting of errors returned by Prisma Client.\n\nError formats​\nName\tDescription\nundefined\tIf it's not defined, the default is colorless.\npretty\tEnables pretty error formatting.\ncolorless (default)\tEnables colorless error formatting.\nminimal\tEnables minimal error formatting.\nExamples​\nNo error formatting​\nconst prisma = new PrismaClient({\n\n  // Defaults to colorless\n\n});\n\npretty error formatting​\nconst prisma = new PrismaClient({\n\n  errorFormat: 'pretty',\n\n});\n\ncolorless error formatting​\nconst prisma = new PrismaClient({\n\n  errorFormat: 'colorless',\n\n});\n\nminimal error formatting​\nconst prisma = new PrismaClient({\n\n  errorFormat: 'minimal',\n\n});\n\nadapter​\n\nDefines an instance of a driver adapter. See also Database drivers .\n\nINFO\n\nThis is available from version 5.4.0 and newer as a Preview feature behind the driverAdapters feature flag. It has been Generally Available since 6.16.0.\n\nExample​\n\nThe example below uses the Neon driver adapter\n\nimport { PrismaNeon } from '@prisma/adapter-neon';\n\nimport { PrismaClient } from '@prisma/client';\n\nimport dotenv from 'dotenv';\n\n\n\ndotenv.config();\n\nconst connectionString = `${process.env.DATABASE_URL}`;\n\n\n\nconst adapter = new PrismaNeon({ connectionString });\n\nconst prisma = new PrismaClient({ adapter });\n\nrejectOnNotFound​\nINFO\n\nNote: rejectOnNotFound was removed in v5.0.0.\n\nDeprecated: rejectOnNotFound is deprecated in v4.0.0. From v4.0.0, use the queries findUniqueOrThrow or findFirstOrThrow.\n\nUse the rejectOnNotFound parameter to configure findUnique() and/or findFirst to throw an error if the record was not found. By default, both operations return null if the record is not found.\n\nRemarks​\nYou can configure rejectOnNotFound on a per-request level for both findUnique() and findFirst\nOptions​\nOption\tDescription\nRejectOnNotFound\tEnable globally (true / false) or throw a custom error.\nRejectPerOperation\tEnable per operation (true / false) or throw a custom error per operation, per model.\nExamples​\nEnable globally for findUnique() and findFirst​\nconst prisma = new PrismaClient({\n\n  rejectOnNotFound: true,\n\n});\n\nEnable globally for a specific operation​\nconst prisma = new PrismaClient({\n\n  rejectOnNotFound: {\n\n    findUnique: true,\n\n  },\n\n});\n\nThrow a custom error per model and operation if record is not found​\nconst prisma = new PrismaClient({\n\n  rejectOnNotFound: {\n\n    findFirst: {\n\n      User: (err) => new Error('User error'),\n\n      Post: (err) => new Error('Post error!'),\n\n    },\n\n    findUnique: {\n\n      User: (err) => new Error('User error'),\n\n      Post: (err) => new Error('Post error!'),\n\n    },\n\n  },\n\n});\n\ntransactionOptions​\nINFO\n\nNote: transactionOptions was introduced in v5.10.0.\n\nAllows to set transaction options globally on the constructor level.\n\nRemarks​\nThe transaction levels can be overridden on a per-transaction level.\nOptions​\nOption\tDescription\nmaxWait\tThe maximum amount of time Prisma Client will wait to acquire a transaction from the database. The default value is 2 seconds.\ntimeout\tThe maximum amount of time the interactive transaction can run before being canceled and rolled back. The default value is 5 seconds.\nisolationLevel\tSets the transaction isolation level. By default this is set to the value currently configured in your database. The available can vary depending on the database you use.\nExample​\nconst prisma = new PrismaClient({\n\n  transactionOptions: {\n\n    isolationLevel: Prisma.TransactionIsolationLevel.Serializable,\n\n    maxWait: 5000, // default: 2000\n\n    timeout: 10000, // default: 5000\n\n  },\n\n});\n\nModel queries​\n\nUse model queries to perform CRUD operations on your models. See also: CRUD\n\nNote: It's a best practice to always validate and sanitize any untrusted user data before passing it into Prisma queries. Failure to do so can lead to SQL injection or other injection vulnerabilities if the type checks are bypassed. Make sure user-supplied values cannot inadvertently bypass critical checks. We strongly recommend performing type checking and input validation at the application layer. For more details, see Custom Validation section.\n\nfindUnique()​\n\nfindUnique() query lets you retrieve a single database record:\n\nBy ID\nBy a unique attribute\n\nfindUnique() replaced findOne in version 2.12.0\n.\n\nRemarks​\nPrisma Client's dataloader automatically batches findUnique() queries with the same select and where parameters.\nIf you want the query to throw an error if the record is not found, then consider using findUniqueOrThrow instead.\nYou cannot use filter conditions (e.g. equals, contains, not) to filter fields of the JSON data type. Using filter conditions will likely result in a null response for that field.\nOptions​\nName\tExample type (User)\tRequired\tDescription\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ title: \"Hello world\" }\tUse select and include to determine which fields to return.\nnull\tnull\tRecord not found\nExamples​\nGet the User record with an id of 42​\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    id: 42,\n\n  },\n\n});\n\nGet the User record with an email of alice@prisma.io​\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    email: 'alice@prisma.io',\n\n  },\n\n});\n\nGet the User record with firstName of Alice and lastName of Smith (@@unique)​\nExpand for example User model with a @@unique block\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    fullname: {\n\n      // name property of @@unique attribute - default is firstname_lastname\n\n      firstName: 'Alice',\n\n      lastName: 'Smith',\n\n    },\n\n  },\n\n});\n\nGet the User record with firstName of Alice and lastName of Smith (@@id)​\nExpand for example User model with an @@id block\nconst result = await prisma.user.findUnique({\n\n  where: {\n\n    firstName_lastName: {\n\n      firstName: 'Alice',\n\n      lastName: 'Smith',\n\n    },\n\n  },\n\n});\n\nfindUniqueOrThrow()​\n\nfindUniqueOrThrow() retrieves a single record in the same way as findUnique(). However, if the query does not find the requested record, it throws a PrismaClientKnownRequestError.\n\nNote that before Prisma v6, it would throw a NotFoundError: No User found error.\n\nHere’s an example of its usage:\n\nawait prisma.user.findUniqueOrThrow({\n\n  where: { id: 1 },\n\n});\n\n\nfindUniqueOrThrow() differs from findUnique() as follows:\n\nIts return type is non-nullable. For example, post.findUnique() can return post or null, but post.findUniqueOrThrow() always returns post.\n\nIt is not compatible with sequential operations in the $transaction API. If the query throws a PrismaClientKnownRequestError, then the API will not roll back any operations in the array of calls. As a workaround, you can use interactive transactions with the $transaction API, as follows:\n\n $transaction(async (prisma) => {\n\n   await prisma.model.create({ data: { ... });\n\n   await prisma.model.findUniqueOrThrow();\n\n })\n\nfindFirst()​\n\nfindFirst returns the first record in a list that matches your criteria.\n\nRemarks​\nIf you want the query to throw an error if the record is not found, then consider using findFirstOrThrow instead.\nOptions​\nName\tExample type (User)\tRequired\tDescription\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0.\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<UserOrderByInput>, UserOrderByInput>\tNo\tLets you order the returned list by any property.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\tSpecifies which properties to include on the returned object.\nJavaScript object (plain)\t{ title: \"Hello world\" }\tUse select and include to determine which fields to return.\nnull\tnull\tRecord not found\nRemarks​\nfindFirst calls findMany behind the scenes and accepts the same query options.\nPassing in a negative take value when you use a findFirst query reverses the order of the list.\nExamples​\n\nSee Filter conditions and operators for examples of how to filter results.\n\nGet the first User record where the name is Alice​\nconst user = await prisma.user.findFirst({\n\n  where: { name: 'Alice' },\n\n});\n\nGet the first Post record where the title starts with A test, reverse the list with take​\nimport { PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({});\n\n\n\nasync function main() {\n\n  const a = await prisma.post.create({\n\n    data: {\n\n      title: 'A test 1',\n\n    },\n\n  });\n\n\n\n  const b = await prisma.post.create({\n\n    data: {\n\n      title: 'A test 2',\n\n    },\n\n  });\n\n\n\n  const c = await prisma.post.findFirst({\n\n    where: {\n\n      title: {\n\n        startsWith: 'A test',\n\n      },\n\n    },\n\n    orderBy: {\n\n      title: 'asc',\n\n    },\n\n    take: -1, // Reverse the list\n\n  });\n\n}\n\n\n\nmain();\n\nfindFirstOrThrow()​\n\nfindFirstOrThrow() retrieves a single data record in the same way as findFirst(). However, if the query does not find a record, it throws a PrismaClientKnownRequestError.\n\nNote that before Prisma v6, it would throw a NotFoundError: No User found error.\n\nfindFirstOrThrow() differs from findFirst() as follows:\n\nIts return type is non-nullable. For example, post.findFirst() can return post or null, but post.findFirstOrThrow always returns post.\n\nIt is not compatible with sequential operations in the $transaction API. If the query returns PrismaClientKnownRequestError, then the API will not roll back any operations in the array of calls. As a workaround, you can use interactive transactions with the $transaction API, as follows:\n\nprisma.$transaction(async (tx) => {\n\n  await tx.model.create({ data: { ... });\n\n  await tx.model.findFirstOrThrow();\n\n})\n\nfindMany()​\n\nfindMany returns a list of records.\n\nOptions​\nName\tType\tRequired\tDescription\nselect\tXOR<PostSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<PostInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<PostOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<PostOrder\nByInput>, PostOrderByInput>\tNo\tLets you order the returned list by any property.\ncursor\tUserWhereUniqueInput\tNo\tSpecifies the position for the list (the value typically specifies an id or another unique value).\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\ndistinct\tEnumerable<UserDistinctFieldEnum>\tNo\tLets you filter out duplicate rows by a specific field - for example, return only distinct Post titles.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript array object (typed)\tUser[]\t\nJavaScript array object (plain)\t[{ title: \"Hello world\" }]\tUse select and include to determine which fields to return.\nEmpty array\t[]\tNo matching records found.\nExamples​\n\nSee Filter conditions and operators for examples of how to filter results.\n\nGet all User records where the name is Alice​\nconst user = await prisma.user.findMany({\n\n  where: { name: 'Alice' },\n\n});\n\ncreate()​\n\ncreate creates a new database record.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserCreateInput,\nUserUncheckedCreateInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. It also includes relation fields which lets you perform (transactional) nested inserts. Fields that are marked as optional or have default values in the datamodel are optional.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tUse select and include to determine which fields to return.\nRemarks​\nYou can also perform a nested create - for example, add a User and two Post records at the same time.\nExamples​\nCreate a single new record with the only required field email​\nconst user = await prisma.user.create({\n\n  data: { email: 'alice@prisma.io' },\n\n});\n\nCreate multiple new records​\n\nIn most cases, you can carry out batch inserts with the createMany() or createManyAndReturn() queries. However, there are scenarios where create() is the best option to insert multiple records.\n\nThe following example results in two INSERT statements:\n\nimport { Prisma, PrismaClient } from '@prisma/client';\n\n\n\nconst prisma = new PrismaClient({ log: ['query'] });\n\n\n\nasync function main() {\n\n  let users: Prisma.UserCreateInput[] = [\n\n    {\n\n      email: 'ariana@prisma.io',\n\n      name: 'Ari',\n\n      profileViews: 20,\n\n      coinflips: [true, false, false],\n\n      role: 'ADMIN',\n\n    },\n\n    {\n\n      email: 'elsa@prisma.io',\n\n      name: 'Elsa',\n\n      profileViews: 20,\n\n      coinflips: [true, false, false],\n\n      role: 'ADMIN',\n\n    },\n\n  ];\n\n\n\n  await Promise.all(\n\n    users.map(async (user) => {\n\n      await prisma.user.create({\n\n        data: user,\n\n      });\n\n    })\n\n  );\n\n}\n\n\n\nmain()\n\n  .then(async () => {\n\n    await prisma.$disconnect();\n\n  })\n\n  .catch(async (e) => {\n\n    console.error(e);\n\n    await prisma.$disconnect();\n\n    process.exit(1);\n\n  });\n\nShow CLI results\nprisma:query BEGIN\n\nprisma:query INSERT INTO \"public\".\"User\" (\"name\",\"email\",\"profileViews\",\"role\",\"coinflips\") VALUES ($1,$2,$3,$4,$5) RETURNING \"public\".\"User\".\"id\"\n\nprisma:query SELECT \"public\".\"User\".\"id\", \"public\".\"User\".\"name\", \"public\".\"User\".\"email\", \"public\".\"User\".\"profileViews\", \"public\".\"User\".\"role\", \"public\".\"User\".\"coinflips\" FROM \"public\".\"User\" WHERE \"public\".\"User\".\"id\" = $1 LIMIT $2 OFFSET $3\n\nprisma:query INSERT INTO \"public\".\"User\" (\"name\",\"email\",\"profileViews\",\"role\",\"coinflips\") VALUES ($1,$2,$3,$4,$5) RETURNING \"public\".\"User\".\"id\"\n\nprisma:query COMMIT\n\nprisma:query SELECT \"public\".\"User\".\"id\", \"public\".\"User\".\"name\", \"public\".\"User\".\"email\", \"public\".\"User\".\"profileViews\", \"public\".\"User\".\"role\", \"public\".\"User\".\"coinflips\" FROM \"public\".\"User\" WHERE \"public\".\"User\".\"id\" = $1 LIMIT $2 OFFSET $3\n\nprisma:query COMMIT\n\nupdate()​\n\nupdate updates an existing database record.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserUpdateInput\nUserUncheckedUpdateInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional.\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0.\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tUse select and include to determine which fields to return.\nPrismaClientKnownRequestError (code P2025)\t\tThrown if the record to update does not exist. See Error reference\nRemarks​\nTo perform arithmetic operations on update (add, subtract, multiply, divide), use atomic updates to prevent race conditions.\nYou can also perform a nested update - for example, update a user and that user's posts at the same time.\nExamples​\nUpdate the email of the User record with id of 1 to alice@prisma.io​\nconst user = await prisma.user.update({\n\n  where: { id: 1 },\n\n  data: { email: 'alice@prisma.io' },\n\n});\n\nupsert()​\nINFO\n\nThis section covers the usage of the upsert() operation. To learn about using nested upsert queries within update(), reference the linked documentation.\n\nupsert does the following:\n\nIf an existing database record satisfies the where condition, it updates that record\nIf no database record satisfies the where condition, it creates a new database record\nOptions​\nName\tType\tRequired\tDescription\ncreate\tXOR<UserCreateInput,\nUserUncheckedCreateInput>\tYes\tWraps all the fields of the model so that they can be provided when creating new records. It also includes relation fields which lets you perform (transactional) nested inserts. Fields that are marked as optional or have default values in the datamodel are optional.\nupdate\tXOR<UserUpdateInput,\nUserUncheckedUpdateInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional.\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\t\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tUse select and include to determine which fields to return.\nRemarks​\nTo perform arithmetic operations on update (add, subtract, multiply, divide), use atomic updates to prevent race conditions.\nIf two or more upsert operations happen at the same time and the record doesn't already exist, then a race condition might happen. As a result, one or more of the upsert operations might throw a unique key constraint error. Your application code can catch this error and retry the operation. Learn more.\nFrom version 4.6.0, Prisma ORM hands over upsert queries to the database where possible. Learn more.\nExamples​\nUpdate (if exists) or create a new User record with an email of alice@prisma.io​\nconst user = await prisma.user.upsert({\n\n  where: { id: 1 },\n\n  update: { email: 'alice@prisma.io' },\n\n  create: { email: 'alice@prisma.io' },\n\n});\n\nUnique key constraint errors on upserts​\nProblem​\n\nIf multiple upsert operations happen at the same time and the record doesn't already exist, then one or more of the operations might return a unique key constraint error.\n\nCause​\n\nWhen Prisma Client does an upsert, it first checks whether that record already exists in the database. To make this check, Prisma Client performs a read operation with the where clause from the upsert operation. This has two possible outcomes, as follows:\n\nIf the record does not exist, then Prisma Client creates that record.\nIf the record exists, then Prisma Client updates it.\n\nWhen your application tries to perform two or more concurrent upsert operations, then a race condition might happen where two or more operations do not find the record and therefore try to create that record. In this situation, one of the operations successfully creates the new record but the other operations fail and return a unique key constraint error.\n\nSolution​\n\nHandle the P2002 error in your application code. When it occurs, retry the upsert operation to update the row.\n\nDatabase upserts​\n\nWhere possible, Prisma Client hands over an upsert query to the database. This is called a database upsert.\n\nDatabase upserts have the following advantages:\n\nThey are faster than upserts handled by Prisma Client\nUnique key constraint errors cannot happen\n\nPrisma Client uses a database upsert automatically when specific criteria are met. When these criteria are not met, Prisma Client handles the upsert.\n\nTo use a database upsert, Prisma Client sends the SQL construction INSERT ... ON CONFLICT SET .. WHERE to the database.\n\nDatabase upsert prerequisites​\n\nPrisma Client can use database upserts if your stack meets the following criteria:\n\nYou use Prisma ORM version 4.6.0 or later\nYour application uses a CockroachDB, PostgreSQL, or SQLite data source\nDatabase upsert query criteria​\n\nPrisma Client uses a database upsert for an upsert query when the query meets the following criteria:\n\nThere are no nested queries in the upsert's create and update options\nThe query does not include a selection that uses a nested read\nThe query modifies only one model\nThere is only one unique field in the upsert's where option\nThe unique field in the where option and the unique field in the create option have the same value\n\nIf your query does not meet these criteria, then Prisma Client handles the upsert itself.\n\nDatabase upsert examples​\n\nThe following examples use this schema:\n\nmodel User {\n\n  id           Int    @id\n\n  profileViews Int\n\n  userName     String @unique\n\n  email        String\n\n\n\n  @@unique([id, profileViews])\n\n}\n\n\nThe following upsert query meets all of the criteria, so Prisma Client uses a database upsert.\n\nprisma.user.upsert({\n\n  where: {\n\n    userName: 'Alice',\n\n  },\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'Alice',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\n\nIn this situation, Prisma uses the following SQL query:\n\nINSERT INTO \"public\".\"User\" (\"id\",\"profileViews\",\"userName\",\"email\") VALUES ($1,$2,$3,$4)\n\nON CONFLICT (\"userName\") DO UPDATE\n\nSET \"email\" = $5 WHERE (\"public\".\"User\".\"userName\" = $6 AND 1=1) RETURNING \"public\".\"User\".\"id\", \"public\".\"User\".\"profileViews\", \"public\".\"User\".\"userName\", \"public\".\"User\".\"email\"\n\n\nThe following query has multiple unique values in the where clause, so Prisma Client does not use a database upsert:\n\nprisma.User.upsert({\n\n  where: {\n\n    userName: 'Alice',\n\n    profileViews: 1,\n\n    id: 1,\n\n  },\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'Alice',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\n\nIn the following query, the values for userName in the where and create options are different, so Prisma Client does not use a database upsert.\n\nprisma.User.upsert({\n\n  where: {\n\n    userName: 'Alice',\n\n  },\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'AliceS',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\n\nIn the following query, the selection on the title field in posts is a nested read, so Prisma Client does not use a database upsert.\n\nprisma.user.upsert({\n\n  select: {\n\n    email: true,\n\n    id: true,\n\n    posts: {\n\n      select: {\n\n        title: true,\n\n      },\n\n    },\n\n  },\n\n  where: {\n\n    userName: 'Alice',\n\n  },\n\n\n\n  create: {\n\n    id: 1,\n\n    profileViews: 1,\n\n    userName: 'Alice',\n\n    email: 'alice@prisma.io',\n\n  },\n\n  update: {\n\n    email: 'updated@example.com',\n\n  },\n\n});\n\ndelete()​\n\ndelete deletes an existing database record. You can delete a record:\n\nBy ID\nBy a unique attribute\n\nTo delete records that match a certain criteria, use deleteMany with a filter.\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereUniqueInput\tYes\tWraps all fields of a model so that a record can be selected (learn more).\nBefore version 4.5.0, this type only wraps unique fields of a model.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned object.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned object.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned object. In Preview since 5.13.0\nrelationLoadStrategy\t'join' or 'query'\tNo\tDefault: join. Specifies the load strategy for a relation query. Only available in combination with include (or select on a relation field). In Preview since 5.9.0.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript object (typed)\tUser\tThe User record that was deleted.\nJavaScript object (plain)\t{ name: \"Alice Wonderland\" }\tData from the User record that was deleted. Use select and include to determine which fields to return.\nPrismaClientKnownRequestError (code P2025)\t\tThrown if the record to delete does not exist. See Error reference\nRemarks​\nTo delete multiple records based on some criteria (for example, all User records with a prisma.io email address, use deleteMany)\nExamples​\nDelete the User record with an id of 1​\nconst user = await prisma.user.delete({\n\n  where: { id: 1 },\n\n});\n\nDelete the User record where email equals elsa@prisma.io​\n\nThe following query deletes a specific user record and uses select to return the name and email of the deleted user:\n\nconst deleteUser = await prisma.user.delete({\n\n  where: {\n\n    email: 'elsa@prisma.io',\n\n  },\n\n  select: {\n\n    email: true,\n\n    name: true,\n\n  },\n\n});\n\nShow CLI results\n{ \"email\": \"elsa@prisma.io\", \"name\": \"Elsa\" }\n\ncreateMany()​\n\ncreateMany creates multiple records in a transaction.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tEnumerable<UserCreateManyInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. Fields that are marked as optional or have default values in the datamodel are optional.\nskipDuplicates?\tboolean\tNo\tDo not insert records with unique fields or ID fields that already exist. Only supported by databases that support \nON CONFLICT DO NOTHING\n. This excludes MongoDB and SQLServer\nReturn type​\nReturn type\tExample\tDescription\nBatchPayload\t{ count: 3 }\tA count of the number of records created.\nRemarks​\nAs of Prisma ORM version 5.12.0, createMany() is now supported by SQLite.\nThe skipDuplicates option is not supported by MongoDB, SQLServer, or SQLite.\nYou cannot create or connect relations by using nested create, createMany, connect, connectOrCreate queries inside a top-level createMany() query. See here for a workaround.\nYou can use a nested createMany query inside an update() or create() query - for example, add a User and two Post records with a nested createMany at the same time.\nExamples​\nCreate several new users​\nconst users = await prisma.user.createMany({\n\n  data: [\n\n    { name: 'Sonali', email: 'sonali@prisma.io' },\n\n    { name: 'Alex', email: 'alex@prisma.io' },\n\n  ],\n\n});\n\ncreateManyAndReturn()​\n\ncreateManyAndReturn creates multiple records and returns the resulting objects.\n\nINFO\n\nThis feature is available in Prisma ORM version 5.14.0 and later for PostgreSQL, CockroachDB and SQLite.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tEnumerable<UserCreateManyInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. Fields that are marked as optional or have default values in the datamodel are optional.\nselect\tXOR<UserSelect, null>\tNo\tSpecifies which properties to include on the returned objects.\nomit\tXOR<UserOmit, null>\tNo\tSpecifies which properties to exclude on the returned objects. In Preview since 5.13.0. Mutually exclusive with select.\ninclude\tXOR<UserInclude, null>\tNo\tSpecifies which relations should be eagerly loaded on the returned objects.\nskipDuplicates?\tboolean\tNo\tDo not insert records with unique fields or ID fields that already exist. Only supported by databases that support \nON CONFLICT DO NOTHING\n. This excludes MongoDB and SQLServer\nRemarks​\nThe skipDuplicates option is not supported by SQLite.\nNote that the order of elements returned by createManyAndReturn is not guaranteed.\nYou cannot create or connect relations by using nested create, createMany, connect, connectOrCreate queries inside a top-level createManyAndReturn() query. See here for a workaround.\nWhen relations are included via include, a separate query is generated per relation.\nrelationLoadStrategy: join is not supported.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript array object (typed)\tUser[]\t\nJavaScript array object (plain)\t[{ name: \"Sonali\" }]\tUse select, omit and include to determine which fields to return.\nExamples​\nCreate and return several new users​\nconst users = await prisma.user.createManyAndReturn({\n\n  data: [\n\n    { name: 'Sonali', email: 'sonali@prisma.io' },\n\n    { name: 'Alex', email: 'alex@prisma.io' },\n\n  ],\n\n})\n\nShow CLI results\n[\n\n  { \"id\": 0, \"name\": \"Sonali\", \"email\": \"sonali@prisma.io\", \"profileViews\": 0 },\n\n  { \"id\": 1, \"name\": \"Alex\", \"email\": \"alex@prisma.io\", \"profileViews\": 0  }\n\n]\n\nupdateMany()​\n\nupdateMany updates a batch of existing database records in bulk and returns the number of updated records.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserUpdateManyMutationInput,\nUserUncheckedUpdateManyInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional on data.\nwhere\tUserWhereInput\tNo\tWraps all fields of a model so that the list can be filtered by any property. If you do not filter the list, all records will be updated.\nlimit\tnumber\tNo\tLimits the number of records to update.\nReturn type​\nReturn type\tExample\tDescription\nBatchPayload\t{ count: 4 }\tThe count of updated records.\nexport type BatchPayload = {\n\n  count: number;\n\n};\n\nExamples​\nUpdate all User records where the name is Alice to ALICE​\nconst updatedUserCount = await prisma.user.updateMany({\n\n  where: { name: 'Alice' },\n\n  data: { name: 'ALICE' },\n\n});\n\nUpdate all User records where the email contains prisma.io and at least one related Post has more than 10 likes​\nconst updatedUserCount = await prisma.user.updateMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n    posts: {\n\n      some: {\n\n        likes: {\n\n          gt: 10,\n\n        },\n\n      },\n\n    },\n\n  },\n\n  data: {\n\n    role: 'USER',\n\n  },\n\n});\n\nUpdate User records where the email contains prisma.io, but limit to 5 records updated.​\nconst updatedUserCount = await prisma.user.updateMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n  },\n\n  data: {\n\n    role: 'USER',\n\n  },\n\n  limit: 5,\n\n});\n\nupdateManyAndReturn()​\nINFO\n\nThis feature is available in Prisma ORM version 6.2.0 and later for PostgreSQL, CockroachDB and SQLite.\n\nupdateManyAndReturn updates multiple records and returns the resulting objects.\n\nOptions​\nName\tType\tRequired\tDescription\ndata\tXOR<UserUpdateManyMutationInput,\nUserUncheckedUpdateManyInput>\tYes\tWraps all the fields of the model so that they can be provided when updating an existing record. Fields that are marked as optional or have default values in the datamodel are optional on data.\nwhere\tUserWhereInput\tNo\tWraps all fields of a model so that the list can be filtered by any property. If you do not filter the list, all records will be updated.\nReturn type​\nReturn type\tExample\tDescription\nJavaScript array object (typed)\tUser[]\t\nJavaScript array object (plain)\t[{ name: \"Sonali\" }]\tUse select, omit and include to determine which fields to return.\nExamples​\nUpdate and return multiple users​\nconst users = await prisma.user.updateManyAndReturn({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    }\n\n  },\n\n  data: {\n\n    role: 'ADMIN'\n\n  },\n\n})\n\nShow CLI results\n[\n\n  { \"id\": 0, \"name\": \"Sonali\", \"email\": \"sonali@prisma.io\", \"role\": \"ADMIN\", \"profileViews\": 0 },\n\n  { \"id\": 1, \"name\": \"Alex\", \"email\": \"alex@prisma.io\", \"role\": \"ADMIN\", \"profileViews\": 0  }\n\n]\n\ndeleteMany()​\n\ndeleteMany deletes multiple records in a transaction.\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all fields of a model so that the list can be filtered by any field.\nlimit\tInt\tNo\tLimits the number of records deleted.\nReturn type​\nReturn type\tExample\tDescription\nBatchPayload\t{ count: 4 }\tThe count of deleted records.\nexport type BatchPayload = {\n\n  count: number;\n\n};\n\nExamples​\nDelete all User records​\nconst deletedUserCount = await prisma.user.deleteMany({});\n\nDelete all User records where the name is Alice​\nconst deletedUserCount = await prisma.user.deleteMany({\n\n  where: { name: 'Alice' },\n\n});\n\nDelete all User records where the email contains prisma.io, but limit to 5 records deleted.​\nconst deletedUserCount = await prisma.user.deleteMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n  },\n\n  limit: 5,\n\n});\n\n\nSee Filter conditions and operators for examples of how to filter the records to delete.\n\ncount()​\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<PostOrder\nByInput>, PostOrderByInput>\tNo\tLets you order the returned list by any property.\ncursor\tUserWhereUniqueInput\tNo\tSpecifies the position for the list (the value typically specifies an id or another unique value).\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\nReturn type​\nReturn type\tExample\tDescription\nnumber\t29\tThe count of records.\nUserCountAggregateOutputType\t{ _all: 27, name: 10 }\tReturned if select is used.\nExamples​\nCount all User records​\nconst result = await prisma.user.count();\n\nCount all User records with at least one published Post​\nconst result = await prisma.user.count({\n\n  where: {\n\n    post: {\n\n      some: {\n\n        published: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nUse select to perform three separate counts​\n\nThe following query returns:\n\nA count of all records (_all)\nA count of all records with non-null name fields\nA count of all records with non-null city fields\nconst c = await prisma.user.count({\n\n  select: {\n\n    _all: true,\n\n    city: true,\n\n    name: true,\n\n  },\n\n});\n\naggregate()​\n\nSee also: Aggregation, grouping, and summarizing\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<UserOrderByInput>,\nUserOrderByInput>\tNo\tLets you order the returned list by any property.\ncursor\tUserWhereUniqueInput\tNo\tSpecifies the position for the list (the value typically specifies an id or another unique value).\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\n_count\ttrue\tNo\tReturns a count of matching records or non-null fields.\n_avg\tUserAvgAggregateInputType\tNo\tReturns an average of all values of the specified field.\n_sum\tUserSumAggregateInputType\tNo\tReturns the sum of all values of the specified field.\n_min\tUserMinAggregateInputType\tNo\tReturns the smallest available value of the specified field.\n_max\tUserMaxAggregateInputType\tNo\tReturns the largest available value of the specified field.\nExamples​\nReturn _min, _max, and _count of profileViews of all User records​\nconst minMaxAge = await prisma.user.aggregate({\n\n  _count: {\n\n    _all: true,\n\n  },\n\n  _max: {\n\n    profileViews: true,\n\n  },\n\n  _min: {\n\n    profileViews: true,\n\n  },\n\n});\n\nShow CLI results\nReturn _sum of all profileViews for all User records​\nconst setValue = await prisma.user.aggregate({\n\n  _sum: {\n\n    profileViews: true,\n\n  },\n\n});\n\nShow CLI results\ngroupBy()​\n\nSee also: Aggregation, grouping, and summarizing\n\nOptions​\nName\tType\tRequired\tDescription\nwhere\tUserWhereInput\tNo\tWraps all model fields in a type so that the list can be filtered by any property.\norderBy\tXOR<Enumerable<UserOrderByInput>,\nUserOrderByInput>\tNo\tLets you order the returned list by any property that is also present in by.\nby\tArray<UserScalarFieldEnum> | string\tNo\tSpecifies the field or combination of fields to group records by.\nhaving\tUserScalarWhereWithAggregatesInput\tNo\tAllows you to filter groups by an aggregate value - for example, only return groups having an average age less than 50.\ntake\tnumber\tNo\tSpecifies how many objects should be returned in the list (as seen from the beginning (positive value) or end (negative value) either of the list or from the cursor position if mentioned)\nskip\tnumber\tNo\tSpecifies how many of the returned objects in the list should be skipped.\n_count\ttrue | UserCountAggregateInputType\tNo\tReturns a count of matching records or non-null fields.\n_avg\tUserAvgAggregateInputType\tNo\tReturns an average of all values of the specified field.\n_sum\tUserSumAggregateInputType\tNo\tReturns the sum of all values of the specified field.\n_min\tUserMinAggregateInputType\tNo\tReturns the smallest available value of the specified field.\n_max\tUserMaxAggregateInputType\tNo\tReturns the largest available value of the specified field.\nExamples​\nGroup by country/city where the average profileViews is greater than 200, and return the _sum of profileViews for each group​\n\nThe query also returns a count of _all records in each group, and all records with non-null city field values in each group.\n\nconst groupUsers = await prisma.user.groupBy({\n\n  by: ['country', 'city'],\n\n  _count: {\n\n    _all: true,\n\n    city: true,\n\n  },\n\n  _sum: {\n\n    profileViews: true,\n\n  },\n\n  orderBy: {\n\n    country: 'desc',\n\n  },\n\n  having: {\n\n    profileViews: {\n\n      _avg: {\n\n        gt: 200,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\n[\n\n  {\n\n    country: 'Denmark',\n\n    city: 'Copenhagen',\n\n    _sum: { profileViews: 490 },\n\n    _count: {\n\n      _all: 70,\n\n      city: 8,\n\n    },\n\n  },\n\n  {\n\n    country: 'Sweden',\n\n    city: 'Stockholm',\n\n    _sum: { profileViews: 500 },\n\n    _count: {\n\n      _all: 50,\n\n      city: 3,\n\n    },\n\n  },\n\n];\n\nfindRaw()​\n\nSee: Using Raw SQL (findRaw()).\n\naggregateRaw()​\n\nSee: Using Raw SQL (aggregateRaw()).\n\nModel query options​\nselect​\n\nselect defines which fields are included in the object that Prisma Client returns. See: Select fields and include relations .\n\nRemarks​\nYou cannot combine select and include on the same level.\nIn 3.0.1\n and later, you can select a _count of relations.\nExamples​\nSelect the name and profileViews fields of a single User record​\nconst result = await prisma.user.findUnique({\n\n  where: { id: 1 },\n\n  select: {\n\n    name: true,\n\n    profileViews: true,\n\n  },\n\n});\n\nShow CLI results\nSelect the email and role fields of a multiple User records​\nconst result = await prisma.user.findMany({\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n});\n\nShow CLI results\nSelect a _count of relations​\nconst usersWithCount = await prisma.user.findMany({\n\n  select: {\n\n    _count: {\n\n      select: { posts: true },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nSelect the 'id' and 'title' fields of related Post records​\nconst result = await prisma.user.findMany({\n\n  select: {\n\n    id: true,\n\n    name: true,\n\n    posts: {\n\n      select: {\n\n        id: true,\n\n        title: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\ninclude inside select​\nconst result = await prisma.user.findMany({\n\n  select: {\n\n    id: true,\n\n    name: true,\n\n    posts: {\n\n      include: {\n\n        author: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nGenerated types for select​\n\nThe following example demonstrates how to use the validator with select:\n\nconst selectNameEmailNotPosts = Prisma.validator<Prisma.UserSelect>()({\n\n  name: true,\n\n  email: true,\n\n  posts: false,\n\n});\n\ninclude​\n\ninclude defines which relations are included in the result that Prisma Client returns. See: Select fields and include relations .\n\nRemarks​\nIn 3.0.1\n and later, you can include a _count of relations\nExamples​\nInclude the posts and profile relation when loading User records​\nconst users = await prisma.user.findMany({\n\n  include: {\n\n    posts: true, // Returns all fields for all posts\n\n    profile: true, // Returns all Profile fields\n\n  },\n\n});\n\nInclude the posts relation on the returned objects when creating a new User record with two Post records​\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    posts: {\n\n      create: [{ title: 'This is my first post' }, { title: 'Here comes a second post' }],\n\n    },\n\n  },\n\n  include: { posts: true }, // Returns all fields for all posts\n\n});\n\nGenerated types for include​\n\nThe following example demonstrates how to use the validator with include:\n\nconst includePosts = Prisma.validator<Prisma.UserInclude>()({\n\n  posts: true,\n\n});\n\nInclude a _count of relations​\nconst usersWithCount = await prisma.user.findMany({\n\n  include: {\n\n    _count: {\n\n      select: { posts: true },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nomit​\n\nomit defines which fields are excluded in the object that Prisma Client returns.\n\nRemarks​\nYou cannot combine omit and select since they serve opposite purposes\nomit was released into General Availability with Prisma ORM 6.2.0. It was available via the omitApi Preview feature in Prisma ORM versions 5.13.0 through 6.1.0.\nExamples​\nOmit the password field from all User records​\nconst result = await prisma.user.findMany({\n\n  omit: {\n\n    password: true,\n\n  },\n\n});\n\nShow CLI results\nOmit the title fields from all User's posts relation​\nconst results = await prisma.user.findMany({\n\n  omit: {\n\n    password: true,\n\n  },\n\n  include: {\n\n    posts: {\n\n      omit: {\n\n        title: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nGenerated types for omit​\n\nThe following example demonstrates how to use the validator with omit:\n\nconst omitPassword = Prisma.validator<Prisma.UserOmit>()({\n\n  password: true,\n\n});\n\nrelationLoadStrategy (Preview)​\n\nrelationLoadStrategy specifies how a relation should be loaded from the database. It has two possible values:\n\njoin (default): Uses a database-level LATERAL JOIN (PostgreSQL) or correlated subqueries (MySQL) and fetches all data with a single query to the database.\nquery: Sends multiple queries to the database (one per table) and joins them on the application level.\n\nNote: Once relationLoadStrategy moves from Preview into General Availability, join will universally become the default for all relation queries.\n\nYou can learn more about join strategies here.\n\nBecause the relationLoadStrategy option is currently in Preview, you need to enable it via the relationJoins preview feature flag in your Prisma schema file:\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"relationJoins\"]\n\n}\n\n\nAfter adding this flag, you need to run prisma generate again to re-generate Prisma Client. The relationJoins feature is currently available on PostgreSQL, CockroachDB and MySQL.\n\nRemarks​\nIn most situations, the default join strategy will be more effective. Use query if you want to save resources on your database server or if you profiling shows that the application-level join is more performant.\nYou can only specify the relationLoadStrategy on the top-level in your query. The top-level choice will affect all nested sub-queries.\nExamples​\nLoad the posts relation via a database-level JOIN when using include​\nconst users = await prisma.user.findMany({\n\n  relationLoadStrategy: 'join',\n\n  include: {\n\n    posts: true,\n\n  },\n\n});\n\nLoad the posts relation via a database-level JOIN when using select​\nconst users = await prisma.user.findMany({\n\n  relationLoadStrategy: 'join',\n\n  select: {\n\n    posts: true,\n\n  },\n\n});\n\nwhere​\n\nwhere defines one or more filters, and can be used to filter on record properties (like a user's email address) or related record properties (like a user's top 10 most recent post titles).\n\nExamples​\nconst results = await prisma.user.findMany({\n\n  where: {\n\n    email: {\n\n      endsWith: 'prisma.io',\n\n    },\n\n  },\n\n});\n\nGenerated types for where​\n\nThe following examples demonstrate how to use the validator with where:\n\nUserWhereInput\n\n// UserWhereInput\n\nconst whereNameIs = Prisma.validator<Prisma.UserWhereInput>()({\n\n  name: 'Rich',\n\n});\n\n\n\n// It can be combined with conditional operators too\n\nconst whereNameIs = Prisma.validator<Prisma.UserWhereInput>()({\n\n  name: 'Rich',\n\n  AND: [\n\n    {\n\n      email: {\n\n        contains: 'rich@boop.com',\n\n      },\n\n    },\n\n  ],\n\n});\n\n\nUserWhereUniqueInput This type works by exposing any unique fields on the model. A field assigned @id is considered unique, as is one assigned @unique.\n\nFrom version 4.5.0, this type exposes all fields on the model. This means that when you filter for a single record based on a unique field, you can check additional non-unique and unique fields at the same time. Learn more.\n\n// UserWhereUniqueInput\n\nconst whereEmailIsUnique = Prisma.validator<Prisma.UserWhereUniqueInput>()({\n\n  email: 'rich@boop.com',\n\n})\n\n\nPostScalarWhereInput\n\nconst whereScalarTitleIs = Prisma.validator<Prisma.PostScalarWhereInput>()({\n\n  title: 'boop',\n\n});\n\n\nPostUpdateWithWhereUniqueWithoutAuthorInput - This type accepts a unique where field (an @id or another assigned @unique) and updates any field on the Post model except the Author. The Author is the scalar field on the Post model.\n\nconst updatePostByIdWithoutAuthor =\n\n  Prisma.validator<Prisma.PostUpdateWithWhereUniqueWithoutAuthorInput>()({\n\n    where: {\n\n      id: 1,\n\n    },\n\n    data: {\n\n      content: 'This is some updated content',\n\n      published: true,\n\n      title: 'This is a new title',\n\n    },\n\n  });\n\n\nPostUpsertWithWhereUniqueWithoutAuthorInput - This type will update the Post records title field where the id matches, if it doesn't exist it will create it instead.\n\nconst updatePostTitleOrCreateIfNotExist =\n\n  Prisma.validator<Prisma.PostUpsertWithWhereUniqueWithoutAuthorInput>()({\n\n    where: {\n\n      id: 1,\n\n    },\n\n    update: {\n\n      title: 'This is a new title',\n\n    },\n\n    create: {\n\n      id: 1,\n\n      title: 'If the title doesnt exist, then create one with this text',\n\n    },\n\n  });\n\n\nPostUpdateManyWithWhereWithoutAuthorInput - This type will update all Post records where published is set to false.\n\nconst publishAllPosts = Prisma.validator<Prisma.PostUpdateManyWithWhereWithoutAuthorInput>()({\n\n  where: {\n\n    published: {\n\n      equals: false,\n\n    },\n\n  },\n\n  data: {\n\n    published: true,\n\n  },\n\n});\n\norderBy​\n\nSorts a list of records. See also: Sorting\n\nRemarks​\n\nIn 2.16.0\n and later, you can order by relation fields - for example, order posts by the author's name.\n\nIn 3.5.0\n and later, in PostgreSQL you can order by relevance. For details, see Sort by relevance.\n\nIn 4.1.0\n and later, you can sort null records first or last. For details, see Sort with nulls first or last.\n\nInputs for sort argument​\nName\tDescription\nasc\tSort ascending (A → Z)\ndesc\tSort descending (Z → A)\nInputs for nulls argument​\n\nNote:\n\nThis argument is optional.\nIt is for use on optional scalar fields only. If you try to sort by nulls on a required or relation field, Prisma Client throws a P2009 error.\nIt is available in version 4.1.0 and later, as a preview feature. See sort with nulls first or last for details of how to enable the feature.\nName\tDescription\nfirst\tSort with null values first.\nlast\tSort with null values last.\nExamples​\nSort User by email field​\n\nThe following example returns all User records sorted by email ascending:\n\nconst users = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'asc',\n\n  },\n\n});\n\n\nThe following example returns all User records sorted by email descending:\n\nconst users = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'desc',\n\n  },\n\n});\n\nSort Post by the related User record's name​\n\nThe following query orders posts by user name:\n\nconst posts = await prisma.post.findMany({\n\n  orderBy: {\n\n    author: {\n\n      name: 'asc',\n\n    },\n\n  },\n\n});\n\nSort Post by the related User record's name, with null records first​\n\nThe following query orders posts by user name, with null records first:\n\nconst posts = await prisma.post.findMany({\n\n  orderBy: {\n\n    author: {\n\n      name: { sort: 'asc', nulls: 'first' },\n\n    },\n\n  },\n\n});\n\nSort Post by relevance of the title​\nINFO\n\nFor PostgreSQL, this feature is still in Preview. Enable the fullTextSearchPostgres feature flag in order to use it.\n\nThe following query orders posts by relevance of the search term 'database' to the title:\n\nconst posts = await prisma.post.findMany({\n\n  orderBy: {\n\n    _relevance: {\n\n      fields: ['title'],\n\n      search: 'database',\n\n      sort: 'asc'\n\n    },\n\n})\n\nSort User by the posts count​\n\nThe following query orders users by post count:\n\nconst getActiveusers = await prisma.user.findMany({\n\n  orderBy: {\n\n    posts: {\n\n      count: 'desc',\n\n    },\n\n  },\n\n});\n\nSort User by multiple fields - email and role​\n\nThe following example sorts users by two fields - first email, then role:\n\nconst users = await prisma.user.findMany({\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n  orderBy: [\n\n    {\n\n      email: 'desc',\n\n    },\n\n    {\n\n      role: 'desc',\n\n    },\n\n  ],\n\n});\n\nShow CLI results\n\nThe order of sorting parameters matters - the following query sorts by role, then email. Note the difference in the results:\n\nconst users = await prisma.user.findMany({\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n  orderBy: [\n\n    {\n\n      role: 'desc',\n\n    },\n\n    {\n\n      email: 'desc',\n\n    },\n\n  ],\n\n});\n\nShow CLI results\nSort User by email, select name and email​\n\nThe following example returns all the name and email fields of all User records, sorted by email:\n\nconst users3 = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'asc',\n\n  },\n\n  select: {\n\n    name: true,\n\n    email: true,\n\n  },\n\n});\n\nShow CLI results\nSort User records by email and sort nested Post records by title​\n\nThe following example:\n\nReturns all User records sorted by email\nFor each User record, returns the title field of all nested Post records sorted by title\nconst usersWithPosts = await prisma.user.findMany({\n\n  orderBy: {\n\n    email: 'asc',\n\n  },\n\n  include: {\n\n    posts: {\n\n      select: {\n\n        title: true,\n\n      },\n\n      orderBy: {\n\n        title: 'asc',\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nSort one user's nested list of Post records​\n\nThe following example retrieves a single User record by ID, as well as a list of nested Post records sorted by title:\n\nconst userWithPosts = await prisma.user.findUnique({\n\n  where: {\n\n    id: 1,\n\n  },\n\n  include: {\n\n    posts: {\n\n      orderBy: {\n\n        title: 'desc',\n\n      },\n\n      select: {\n\n        title: true,\n\n        published: true,\n\n      },\n\n    },\n\n  },\n\n});\n\nShow CLI results\nSort by enum​\n\nThe following sorts all User records by role (an enum):\n\nconst sort = await prisma.user.findMany({\n\n  orderBy: {\n\n    role: 'desc',\n\n  },\n\n  select: {\n\n    email: true,\n\n    role: true,\n\n  },\n\n});\n\nShow CLI results\nGenerated types for orderBy​\n\nThe following examples demonstrate how to use the validator with orderBy:\n\nUserOrderByInput\nconst orderEmailsByDescending = Prisma.validator<Prisma.UserOrderByInput>()({\n\n  email: 'desc',\n\n});\n\ndistinct​\n\nDeduplicate a list of records from findMany or findFirst. See also: Aggregation, grouping, and summarizing\n\nExamples​\nSelect distinct on a single field​\n\nThe following example returns all distinct city fields, and selects only the city and country fields:\n\nconst distinctCities = await prisma.user.findMany({\n\n  select: {\n\n    city: true,\n\n    country: true,\n\n  },\n\n  distinct: ['city'],\n\n});\n\nShow CLI results\n[\n\n  { city: 'Paris', country: 'France' },\n\n  { city: 'Lyon', country: 'France' },\n\n];\n\nSelect distinct on multiple fields​\n\nThe following example returns all distinct city and country field combinations, and selects only the city and country fields:\n\nconst distinctCitiesAndCountries = await prisma.user.findMany({\n\n  select: {\n\n    city: true,\n\n    country: true,\n\n  },\n\n  distinct: ['city', 'country'],\n\n});\n\nShow CLI results\n[\n\n  { city: 'Paris', country: 'France' },\n\n  { city: 'Paris', country: 'Denmark' },\n\n  { city: 'Lyon', country: 'France' },\n\n];\n\n\nNote that there is now a \"Paris, Denmark\" in addition to \"Paris, France\":\n\nSelect distinct in combination with a filter​\n\nThe following example returns all distinct city and country field combinations where the user's email contains \"prisma.io\", and selects only the city and country fields:\n\nconst distinctCitiesAndCountries = await prisma.user.findMany({\n\n  where: {\n\n    email: {\n\n      contains: 'prisma.io',\n\n    },\n\n  },\n\n  select: {\n\n    city: true,\n\n    country: true,\n\n  },\n\n  distinct: ['city', 'country'],\n\n});\n\nShow CLI results\nnativeDistinct​\n\nEnabling nativeDistinct in your Prisma schema pushes the distinct operation to the database layer (where supported). This can significantly improve performance. However, note that:\n\nSome databases may not fully support DISTINCT on certain field combinations.\nBehavior can differ among providers.\n\nTo enable nativeDistinct:\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"nativeDistinct\"]\n\n}\n\n\nSee Preview Features for more details.\n\nNested queries​\ncreate​\n\nA nested create query adds a new related record or set of records to a parent record. See: Working with relations\n\nRemarks​\ncreate is available as a nested query when you create() (prisma.user.create(...)) a new parent record or update() (prisma.user.update(...)) an existing parent record.\nYou can use a nested create or a nested createMany to create multiple related records. If you require the skipDuplicates query option you should use createMany.\nExamples​\nCreate a new User record with a new Profile record​\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    profile: {\n\n      create: { bio: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nCreate a new Profile record with a new User record​\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    user: {\n\n      create: { email: 'alice@prisma.io' },\n\n    },\n\n  },\n\n})\n\nCreate a new User record with a new Post record​\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    posts: {\n\n      create: { title: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nCreate a new User record with two new Post records​\n\nBecause it's a one-to-many relation, you can also create multiple Post records at once by passing an array to create:\n\nconst user = await prisma.user.create({\n\n  data: {\n\n    email: 'alice@prisma.io',\n\n    posts: {\n\n      create: [\n\n        {\n\n          title: 'This is my first post',\n\n        },\n\n        {\n\n          title: 'Here comes a second post',\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\n\nNote: You can also use a nested createMany to achieve the same result.\n\nUpdate an existing User record by creating a new Profile record​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      create: { bio: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by creating a new Post record​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      create: { title: 'Hello World' },\n\n    },\n\n  },\n\n})\n\ncreateMany​\n\nA nested createMany query adds a new set of records to a parent record. See: Working with relations\n\nRemarks​\ncreateMany is available as a nested query when you create() (prisma.user.create(...)) a new parent record or update() (prisma.user.update(...)) an existing parent record.\nAvailable in the context of a one-to-many relation — for example, you can prisma.user.create(...) a user and use a nested createMany to create multiple posts (posts have one user).\nNot available in the context of a many-to-many relation — for example, you cannot prisma.post.create(...) a post and use a nested createMany to create categories (many posts have many categories).\nYou cannot nest an additional create or createMany.\nAllows setting foreign keys directly — for example, setting the categoryId on a post.\nAs of Prisma ORM version 5.12.0, nested createMany is supported by SQLite.\nYou can use a nested create or a nested createMany to create multiple related records - if you do not need the skipDuplicates query option, you should probably use create.\nOptions​\nName\tType\tRequired\tDescription\ndata\tEnumerable<UserCreateManyInput>\tYes\tWraps all the model fields in a type so that they can be provided when creating new records. Fields that are marked as optional or have default values in the datamodel are optional.\nskipDuplicates?\tboolean\tNo\tDo not insert records with unique fields or ID fields that already exist. Only supported by databases that support \nON CONFLICT DO NOTHING\n. This excludes MongoDB and SQLServer\nExamples​\nUpdate a User and multiple new related Post records​\nconst user = await prisma.user.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    name: 'Elliott',\n\n    posts: {\n\n      createMany: {\n\n        data: [{ title: 'My first post' }, { title: 'My second post' }],\n\n      },\n\n    },\n\n  },\n\n});\n\nset​\n\nset overwrites the value of a relation - for example, replacing a list of Post records with a different list. See: Working with relations\n\nExamples​\nUpdate an existing User record by disconnecting any previous Post records and connecting two other existing ones​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      set: [{ id: 32 }, { id: 42 }],\n\n    },\n\n  },\n\n});\n\nconnect​\n\nA nested connect query connects a record to an existing related record by specifying an ID or unique identifier. See: Working with relations\n\nRemarks​\n\nconnect is available as a nested query when you create a new parent record or update an existing parent record.\n\nIf the related record does not exist, Prisma Client throws an exception:\n\nThe required connected records were not found. Expected 1 records to be connected, found 0.\n\n\nWhen using set and connect together, the order in which they are applied significantly impacts the result. If set is used before connect, the connected records will only reflect the final state established by the connect operation, as set clears all existing connections before connect establishes new ones. Conversely, if connect is applied before set, the set operation will override the connect action by clearing all connected records and replacing them with its own specified state.\n\nExamples​\nCreate a new Profile record and connect it to an existing User record via unique field​\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    user: {\n\n      connect: { email: 'alice@prisma.io' },\n\n    },\n\n  },\n\n});\n\nCreate a new Profile record and connect it to an existing User record via an ID field​\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    user: {\n\n      connect: { id: 42 }, // sets userId of Profile record\n\n    },\n\n  },\n\n});\n\n\nIn 2.11.0\n and later, you can set the foreign key directly:\n\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'Hello World',\n\n    userId: 42,\n\n  },\n\n});\n\n\nHowever, you can't use both the direct approach and the connect approach in the same query. See this issue comment\n for details.\n\nCreate a new Post record and connect it to an existing User record​\nconst user = await prisma.post.create({\n\n  data: {\n\n    title: 'Hello World',\n\n    author: {\n\n      connect: { email: 'alice@prisma.io' },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connecting it to an existing Profile record​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      connect: { id: 24 },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connecting it to two existing Post records​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      connect: [{ id: 24 }, { id: 42 }],\n\n    },\n\n  },\n\n});\n\nconnectOrCreate​\n\nconnectOrCreate either connects a record to an existing related record by ID or unique identifier or creates a new related record if the record does not exist. See: Working with relations\n\nRemarks​\n\nMultiple connectOrCreate queries that run as concurrent transactions can result in a race condition. Consider the following example, where two queries attempt to connectOrCreate a blog post tag named computing at the same time (tag names must be unique):\n\nQuery A\nQuery B\nconst createPost = await prisma.post.create({\n\n  data: {\n\n    title: 'How to create a compiler',\n\n    content: '...',\n\n    author: {\n\n      connect: {\n\n        id: 9,\n\n      },\n\n    },\n\n    tags: {\n\n      connectOrCreate: {\n\n        create: {\n\n          name: 'computing',\n\n        },\n\n        where: {\n\n          name: 'computing',\n\n        },\n\n      },\n\n    },\n\n  },\n\n})\n\n\nIf query A and query B overlap in the following way, query A results in an exception:\n\nQuery A (Fail ❌)\tQuery B (Success ✅)\nQuery hits server, starts transaction A\tQuery hits server, starts transaction B\n\tFind record where tagName equals computing, record not found\nFind record where tagName equals computing, record not found\t\n\tCreate record where tagName equals computing and connect\nCreate record where tagName equals computing\t\nUnique violation, record already created by transaction B\t\n\nTo work around this scenario, we recommend catching the unique violation exception (PrismaClientKnownRequestError, error P2002) and retrying failed queries.\n\nExamples​\nCreate a new Profile record, then connect it to an existing User record or create a new User​\n\nThe following example:\n\nCreates a Profile\nAttempts to connect the profile to a User where the email address is alice@prisma.io\nCreates a new user if a matching user does not exist\nconst user = await prisma.profile.create({\n\n  data: {\n\n    bio: 'The coolest Alice on the planet',\n\n    user: {\n\n      connectOrCreate: {\n\n        where:  { email: 'alice@prisma.io' },\n\n        create: { email: 'alice@prisma.io'}\n\n    },\n\n  },\n\n})\n\nCreate a new Post record and connect it to an existing User record, or create a new User​\nconst user = await prisma.post.create({\n\n  data: {\n\n    title: 'Hello World',\n\n    author: {\n\n      connectOrCreate: {\n\n        where: { email: 'alice@prisma.io' },\n\n        create: { email: 'alice@prisma.io' },\n\n      },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connecting it to an existing Profile record, or creating a new Profile record​\n\nThe following example:\n\nAttempts to connect the user to a Profile with an id of 20\nCreates a new profile if a matching profile does not exist\nconst updateUser = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      connectOrCreate: {\n\n        where: { id: 20 },\n\n        create: {\n\n          bio: 'The coolest Alice in town',\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by connect it to two existing Post records, or creating two new Post records​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      connectOrCreate: [\n\n        {\n\n          where: { id: 32 },\n\n          create: { title: 'This is my first post' },\n\n        },\n\n        {\n\n          where: { id: 19 },\n\n          create: { title: 'This is my second post' },\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\ndisconnect​\n\nA nested disconnect query breaks the connection between a parent record and a related record, but does not delete either record. See: Working with relations\n\nRemarks​\n\ndisconnect is only available if the relation is optional.\n\nIf the relationship you are attempting to disconnect does not exist:\n\n(In 2.21.0 and later\n), the operation does nothing\n\n(Before 2.21.0\n) Prisma Client throws an exception if the provided ID or unique identifier is not connected:\n\nThe records for relation `PostToUser` between the `User` and `Post` models are not connected.\n\nExamples​\nUpdate an existing User record by disconnecting the Profile record it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'bob@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      disconnect: true,\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by disconnecting two Post records it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      disconnect: [{ id: 44 }, { id: 46 }],\n\n    },\n\n  },\n\n});\n\nupdate​\n\nA nested update query updates one or more related records where the parent record's ID is n. See: Working with relations\n\nRemarks​\n\nNested update queries are only available in the context of a top-level update query (for example, prisma.user.update(...)).\n\nIf the parent record does not exist, Prisma Client throws an exception:\n\nAssertionError(\"Expected a valid parent ID to be present for nested update to-one case.\")\n\n\nIf the related record that you want to update does not exist, Prisma Client throws an exception:\n\nAssertionError(\"Expected a valid parent ID to be present for nested update to-one case.\")\n\nExamples​\nUpdate an existing User record by updating the Profile record it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      update: { bio: 'Hello World' },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by updating two Post records it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      update: [\n\n        {\n\n          data: { published: true },\n\n          where: { id: 32 },\n\n        },\n\n        {\n\n          data: { published: true },\n\n          where: { id: 23 },\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\nupsert​\nINFO\n\nThis section covers the usage of nested upsert within update(). To learn about the upsert() operation, reference the linked documentation.\n\nA nested upsert query updates a related record if it exists, or creates a new related record.\n\nExamples​\nUpdate an existing User record by updating the Profile record it's connected to or creating a new one (upsert)​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      upsert: {\n\n        create: { bio: 'Hello World' },\n\n        update: { bio: 'Hello World' },\n\n      },\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by updating two Post record it's connected to or creating new ones (upsert)​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      upsert: [\n\n        {\n\n          create: { title: 'This is my first post' },\n\n          update: { title: 'This is my first post' },\n\n          where: { id: 32 },\n\n        },\n\n        {\n\n          create: { title: 'This is my second post' },\n\n          update: { title: 'This is my second post' },\n\n          where: { id: 23 },\n\n        },\n\n      ],\n\n    },\n\n  },\n\n});\n\ndelete​\n\nA nested delete query deletes a related record. The parent record is not deleted.\n\nRemarks​\ndelete is only available if the relation is optional.\nExamples​\nUpdate an existing User record by deleting the Profile record it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    profile: {\n\n      delete: true,\n\n    },\n\n  },\n\n});\n\nUpdate an existing User record by deleting two Post records it's connected to​\nconst user = await prisma.user.update({\n\n  where: { email: 'alice@prisma.io' },\n\n  data: {\n\n    posts: {\n\n      delete: [{ id: 34 }, { id: 36 }],\n\n    },\n\n  },\n\n});\n\nupdateMany​\n\nA nested updateMany updates a list of related records and supports filtering - for example, you can update a user's unpublished posts.\n\nExamples​\nUpdate all unpublished posts belonging to a specific user​\nconst result = await prisma.user.update({\n\n  where: {\n\n    id: 2,\n\n  },\n\n  data: {\n\n    posts: {\n\n      updateMany: {\n\n        where: {\n\n          published: false,\n\n        },\n\n        data: {\n\n          likes: 0,\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\ndeleteMany​\n\nA nested deleteMany deletes related records and supports filtering. For example, you can delete a user's posts while updating other properties of that user.\n\nExamples​\nDelete all posts belonging to a specific user as part of an update​\nconst result = await prisma.user.update({\n\n  where: {\n\n    id: 2,\n\n  },\n\n  data: {\n\n    name: 'Updated name',\n\n    posts: {\n\n      deleteMany: {},\n\n    },\n\n  },\n\n});\n\nFilter conditions and operators​\nequals​\n\nValue equals n.\n\nExamples​\n\nReturn all users where name equals \"Eleanor\"\n\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    name: {\n\n      equals: 'Eleanor',\n\n    },\n\n  },\n\n});\n\n\nYou can also exclude the equals:\n\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    name: 'Eleanor',\n\n  },\n\n});\n\n\nReturn all products with a quantity lower than the \"warn quantity\" threshold\n\nThis example compares fields of the same model which is available as of version 4.3.0.\n\nconst productsWithLowQuantity = await prisma.product.findMany({\n\n  where: {\n\n    quantity: {\n\n      lte: prisma.product.fields.warnQuantity\n\n    },\n\n  },\n\n});\n\n\nReturn all users that have blue and green as their favorite colors\n\nThis example finds users that have set their favoriteColors field to ['blue', 'green'].\n\nNote that when using equals, order of elements matters. That is to say ['blue', 'green'] is not equal to ['green', 'blue']\n\nconst favoriteColorFriends = await prisma.user.findMany({\n\n  where: {\n\n    favoriteColors: {\n\n      equals: ['blue', 'green'],\n\n    },\n\n  },\n\n});\n\nnot​\n\nValue does not equal n.\n\nExamples​\nReturn all users where name does not equal \"Eleanor\"​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    name: {\n\n      not: 'Eleanor',\n\n    },\n\n  },\n\n});\n\nWARNING\n\nnot will return all items that do not match a given value. However, if the column is nullable, NULL values will not be returned. If you require null values to be returned, use an OR operator to include NULL values.\n\nReturn all users where name does not equal \"Eleanor\" including users where name is NULL​\nawait prisma.user.findMany({\n\n  where: {\n\n    OR: [\n\n      { name: { not: 'Eleanor' } },\n\n      { name: null }\n\n    ]\n\n  }\n\n})\n\nin​\n\nValue n exists in list.\n\nNOTE\n\nnull values are not returned. For example, if you combine in and NOT to return a user whose name is not in the list, users with null value names are not returned.\n\nExamples​\nGet User records where the id can be found in the following list: [22, 91, 14, 2, 5]​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    id: { in: [22, 91, 14, 2, 5] },\n\n  },\n\n});\n\nGet User records where the name can be found in the following list: ['Saqui', 'Clementine', 'Bob']​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    name: { in: ['Saqui', 'Clementine', 'Bob'] },\n\n  },\n\n});\n\nGet User records where name is not present in the list​\n\nThe following example combines in and NOT. You can also use notIn.\n\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    NOT: {\n\n      name: { in: ['Saqui', 'Clementine', 'Bob'] },\n\n    },\n\n  },\n\n});\n\nGet a User record where at least one Post has at least one specified Category​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    // Find users where..\n\n    posts: {\n\n      some: {\n\n        // ..at least one (some) posts..\n\n        categories: {\n\n          some: {\n\n            // .. have at least one category ..\n\n            name: {\n\n              in: ['Food', 'Introductions'], // .. with a name that matches one of the following.\n\n            },\n\n          },\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\nnotIn​\n\nValue n does not exist in list.\n\nRemarks​\nnull values are not returned.\nExamples​\nGet User records where the id can not be found in the following list: [22, 91, 14, 2, 5]​\nconst getUser = await prisma.user.findMany({\n\n  where: {\n\n    id: { notIn: [22, 91, 14, 2, 5] },\n\n  },\n\n});\n\nlt​\n\nValue n is less than x.\n\nExamples​\nGet all Post records where likes is less than 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      lt: 9,\n\n    },\n\n  },\n\n});\n\nlte​\n\nValue n is less than or equal to x.\n\nExamples​\nGet all Post records where likes is less or equal to 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      lte: 9,\n\n    },\n\n  },\n\n});\n\ngt​\n\nValue n is greater than x.\n\nExamples​\nGet all Post records where likes is greater than 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      gt: 9,\n\n    },\n\n  },\n\n});\n\ngte​\n\nValue n is greater than or equal to x.\n\nExamples​\nGet all Post records where likes is greater than or equal to 9​\nconst getPosts = await prisma.post.findMany({\n\n  where: {\n\n    likes: {\n\n      gte: 9,\n\n    },\n\n  },\n\n});\n\nExamples​\nGet all Post records where date_created is greater than March 19th, 2020​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    date_created: {\n\n      gte: new Date('2020-03-19T14:21:00+0200') /* Includes time offset for UTC */,\n\n    },\n\n  },\n\n});\n\ncontains​\n\nValue n contains x.\n\nExamples​\nCount all Post records where content contains databases​\nconst result = await prisma.post.count({\n\n  where: {\n\n    content: {\n\n      contains: 'databases',\n\n    },\n\n  },\n\n});\n\nCount all Post records where content does not contain databases​\nconst result = await prisma.post.count({\n\n  where: {\n\n    NOT: {\n\n      content: {\n\n        contains: 'databases',\n\n      },\n\n    },\n\n  },\n\n});\n\nsearch​\n\nUse Full-Text Search to search within a String field.\n\nINFO\n\nFor PostgreSQL, this feature is still in Preview. Enable the fullTextSearchPostgres feature flag in order to use it.\n\nExamples​\nFind all posts with a title that contains cat or dog.​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      search: 'cat | dog',\n\n    },\n\n  },\n\n});\n\nFind all posts with a title that contains cat and dog.​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      search: 'cat & dog',\n\n    },\n\n  },\n\n});\n\nFind all posts with a title that doesn't contain cat.​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      search: '!cat',\n\n    },\n\n  },\n\n});\n\nmode​\nRemarks​\nSupported by the PostgreSQL and MongoDB connectors only\nExamples​\nGet all Post records where title contains prisma, in a case insensitive way​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      contains: 'prisma',\n\n      mode: 'insensitive',\n\n    },\n\n  },\n\n});\n\nstartsWith​\nExamples​\nGet all Post records where title starts with Pr (such as Prisma)​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    title: {\n\n      startsWith: 'Pr',\n\n    },\n\n  },\n\n});\n\nendsWith​\nGet all User records where email ends with prisma.io​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    email: {\n\n      endsWith: 'prisma.io',\n\n    },\n\n  },\n\n});\n\nAND​\n\nAll conditions must return true. Alternatively, pass a list of objects into the where clause - the AND operator is not required.\n\nExamples​\nGet all Post records where the content field contains Prisma and published is false​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    AND: [\n\n      {\n\n        content: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        published: {\n\n          equals: false,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\nGet all Post records where the content field contains Prisma and published is false (no AND)​\n\nThe following format returns the same results as the previous example without the AND operator:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    content: {\n\n      contains: 'Prisma',\n\n    },\n\n    published: {\n\n      equals: false,\n\n    },\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, and published is false​\n\nThe following example combines OR and AND:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    AND: {\n\n      published: false,\n\n    },\n\n  },\n\n});\n\nOR​\n\nOne or more conditions must return true.\n\nExamples​\nGet all Post records where the title field contains Prisma or databases​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, but not SQL​\n\nThe following example combines OR and NOT:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    NOT: {\n\n      title: {\n\n        contains: 'SQL',\n\n      },\n\n    },\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, and published is false​\n\nThe following example combines OR and AND:\n\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    AND: {\n\n      published: false,\n\n    },\n\n  },\n\n});\n\nNOT​\n\nAll conditions must return false.\n\nExamples​\nGet all Post records where the title does not contain SQL​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    NOT: {\n\n      title: {\n\n        contains: 'SQL',\n\n      },\n\n    },\n\n  },\n\n});\n\nGet all Post records where the title field contains Prisma or databases, but not SQL, and the related User record' email address does not contain sarah​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    OR: [\n\n      {\n\n        title: {\n\n          contains: 'Prisma',\n\n        },\n\n      },\n\n      {\n\n        title: {\n\n          contains: 'databases',\n\n        },\n\n      },\n\n    ],\n\n    NOT: {\n\n      title: {\n\n        contains: 'SQL',\n\n      },\n\n    },\n\n    user: {\n\n      NOT: {\n\n        email: {\n\n          contains: 'sarah',\n\n        },\n\n      },\n\n    },\n\n  },\n\n  include: {\n\n    user: true,\n\n  },\n\n});\n\nRelation filters​\nsome​\n\nReturns all records where one or more (\"some\") related records match filtering criteria.\n\nRemarks​\nYou can use some without parameters to return all records with at least one relation\nExamples​\nGet all User records where some posts mention Prisma​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n      some: {\n\n        content: {\n\n          contains: \"Prisma\"\n\n        }\n\n      }\n\n    }\n\n  }\n\n}\n\nevery​\n\nReturns all records where all (\"every\") related records match filtering criteria.\n\nExamples​\nGet all User records where all posts are published​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n      every: {\n\n        published: true\n\n      },\n\n    }\n\n  }\n\n}\n\nnone​\n\nReturns all records where zero related records match filtering criteria.\n\nRemarks​\nYou can use none without parameters to return all records with no relations\nExamples​\nGet all User records with zero posts​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n        none: {} // User has no posts\n\n    }\n\n  }\n\n}\n\nGet all User records with zero published posts​\nconst result = await prisma.user.findMany({\n\n  where: {\n\n    post: {\n\n        none: {\n\n          published: true\n\n        }\n\n    }\n\n  }\n\n}\n\nis​\n\nReturns all records where related record matches filtering criteria (for example, user's name is Bob).\n\nExamples​\nGet all Post records where user's name is \"Bob\"​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    user: {\n\n        is: {\n\n          name: \"Bob\"\n\n        },\n\n    }\n\n  }\n\n}\n\nisNot​\n\nReturns all records where the related record does not match the filtering criteria (for example, user's name isNot Bob).\n\nExamples​\nGet all Post records where user's name is NOT \"Bob\"​\nconst result = await prisma.post.findMany({\n\n  where: {\n\n    user: {\n\n        isNot: {\n\n          name: \"Bob\"\n\n        },\n\n    }\n\n  }\n\n}\n\nScalar list methods​\nset​\n\nUse set to overwrite the value of a scalar list field.\n\nRemarks​\n\nset is optional - you can set the value directly:\n\ntags: ['computers', 'books'];\n\nExamples​\nSet the value of tags to a list of string values​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      set: ['computing', 'books'],\n\n    },\n\n  },\n\n});\n\nSet tags to a list of values without using the set keyword​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: ['computing', 'books'],\n\n  },\n\n});\n\nSet the value of tags to a single string value​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      set: 'computing',\n\n    },\n\n  },\n\n});\n\npush​\n\npush is available in version 2.20.0\n and later. Use push to add one value or multiple values to a scalar list field.\n\nRemarks​\nAvailable for PostgreSQL and MongoDB only.\nYou can push a list of values or only a single value.\nExamples​\nAdd a computing item to the tags list​\nconst addTag = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      push: 'computing',\n\n    },\n\n  },\n\n});\n\nconst addTag = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      push: ['computing', 'genetics'],\n\n    },\n\n  },\n\n});\n\nunset​\nWARNING\n\nThis method is available on MongoDB only in versions 3.11.1\n and later.\n\nUse unset to unset the value of a scalar list. Unlike set: null, unset removes the list entirely.\n\nExamples​\nUnset the value of tags​\nconst setTags = await prisma.post.update({\n\n  where: {\n\n    id: 9,\n\n  },\n\n  data: {\n\n    tags: {\n\n      unset: true,\n\n    },\n\n  },\n\n});\n\nScalar list filters​\n\nScalar list filters allow you to filter by the contents of a list / array field.\n\nWARNING\n\nAvailable for:\n\nPostgreSQL in versions 2.15.0\n and later\nCockroachDB in versions 3.9.0\n and later\nMongoDB in versions 3.11.0\n and later\nRemarks​\nScalar list / array filters ignore NULL values . Using isEmpty or NOT does not return records with NULL value lists / arrays, and { equals: null } results in an error.\nhas​\n\nThe given value exists in the list.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes \"databases\":\n\nconst posts = await client.post.findMany({\n\n  where: {\n\n    tags: {\n\n      has: 'databases',\n\n    },\n\n  },\n\n});\n\n\nThe following query returns all Post records where the tags list does not include \"databases\":\n\nconst posts = await client.post.findMany({\n\n  where: {\n\n    NOT: {\n\n      tags: {\n\n        has: 'databases',\n\n      },\n\n    },\n\n  },\n\n});\n\nhasEvery​\n\nEvery value exists in the list.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes at least \"databases\" and \"typescript\":\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      hasEvery: ['databases', 'typescript'],\n\n    },\n\n  },\n\n});\n\nhasSome​\n\nAt least one value exists in the list.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes \"databases\" or \"typescript\":\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      hasSome: ['databases', 'typescript'],\n\n    },\n\n  },\n\n});\n\nisEmpty​\n\nThe list is empty.\n\nExamples​\n\nThe following query returns all Post records that have no tags:\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      isEmpty: true,\n\n    },\n\n  },\n\n});\n\nisSet​\nWARNING\n\nThis filter is available on MongoDB only in versions 3.11.1\n and later.\n\nFilter lists to include only results that have been set (either set to a value, or explicitly set to null). Setting this filter to true will exclude undefined results that are not set at all.\n\nExamples​\n\nThe following query returns all Post records where the tags have been set to either null or a value:\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      isSet: true,\n\n    },\n\n  },\n\n});\n\nequals​\n\nThe list matches the given value exactly.\n\nExamples​\n\nThe following query returns all Post records where the tags list includes \"databases\" and \"typescript\" only:\n\nconst posts = await prisma.post.findMany({\n\n  where: {\n\n    tags: {\n\n      equals: ['databases', 'typescript'],\n\n    },\n\n  },\n\n});\n\nComposite type methods​\nWARNING\n\nAvailable for MongoDB only in Prisma 3.10.0 and later.\n\nComposite type methods allow you to create, update and delete composite types.\n\nset​\n\nUse set to overwrite the value of a composite type.\n\nRemarks​\nThe set keyword is optional - you can set the value directly:\nphotos: [\n\n  { height: 100, width: 200, url: '1.jpg' },\n\n  { height: 100, width: 200, url: '2.jpg' },\n\n];\n\nExamples​\nSet the shippingAddress composite type within a new order​\nconst order = await prisma.order.create({\n\n  data: {\n\n    // Normal relation\n\n    product: { connect: { id: 'some-object-id' } },\n\n    color: 'Red',\n\n    size: 'Large',\n\n    // Composite type\n\n    shippingAddress: {\n\n      set: {\n\n        street: '1084 Candycane Lane',\n\n        city: 'Silverlake',\n\n        zip: '84323',\n\n      },\n\n    },\n\n  },\n\n});\n\nSet an optional composite type to null​\nconst order = await prisma.order.create({\n\n  data: {\n\n    // Embedded optional type, set to null\n\n    billingAddress: {\n\n      set: null,\n\n    },\n\n  },\n\n});\n\nunset​\n\nUse unset to unset the value of a composite type. Unlike set: null, this removes the field entirely from the MongoDB document.\n\nExamples​\nRemove the billingAddress from an order​\nconst order = await prisma.order.update({\n\n  where: {\n\n    id: 'some-object-id',\n\n  },\n\n  data: {\n\n    billingAddress: {\n\n      // Unset the billing address\n\n      // Removes \"billingAddress\" field from order\n\n      unset: true,\n\n    },\n\n  },\n\n});\n\nupdate​\n\nUse update to update fields within a required composite type.\n\nRemarks​\n\nThe update method cannot be used on optional types. Instead, use upsert\n\nExamples​\nUpdate the zip field of a shippingAddress composite type​\nconst order = await prisma.order.update({\n\n  where: {\n\n    id: 'some-object-id',\n\n  },\n\n  data: {\n\n    shippingAddress: {\n\n      // Update just the zip field\n\n      update: {\n\n        zip: '41232',\n\n      },\n\n    },\n\n  },\n\n});\n\nupsert​\n\nUse upsert to update an existing optional composite type if it exists, and otherwise set the composite type.\n\nRemarks​\n\nThe upsert method cannot be used on required types. Instead, use update\n\nExamples​\nCreate a new billingAddress if it doesn't exist, and otherwise update it​\nconst order = await prisma.order.update({\n\n  where: {\n\n    id: 'some-object-id',\n\n  },\n\n  data: {\n\n    billingAddress: {\n\n      // Create the address if it doesn't exist,\n\n      // otherwise update it\n\n      upsert: {\n\n        set: {\n\n          street: '1084 Candycane Lane',\n\n          city: 'Silverlake',\n\n          zip: '84323',\n\n        },\n\n        update: {\n\n          zip: '84323',\n\n        },\n\n      },\n\n    },\n\n  },\n\n});\n\npush​\n\nUse push to push values to the end of a list of composite types.\n\nExamples​\nAdd a new photo to the photos list​\nconst product = prisma.product.update({\n\n  where: {\n\n    id: 10,\n\n  },\n\n  data: {\n\n    photos: {\n\n      // Push a photo to the end of the photos list\n\n      push: [{ height: 100, width: 200, url: '1.jpg' }],\n\n    },\n\n  },\n\n});\n\nComposite type filters​\nWARNING\n\nAvailable for MongoDB only in Prisma 3.11.0 and later.\n\nComposite type filters allow you to filter the contents of composite types.\n\nequals​\n\nUse equals to filter results by matching a composite type or a list of composite types. Requires all required fields of the composite type to match.\n\nRemarks​\n\nWhen matching optional fields, you need to distinguish between undefined (missing) fields of the document, and fields that have been explicitly set to null:\n\nIf you omit an optional field, it will match undefined fields, but not fields that have been set to null\nIf you filter for null values of an optional field with equals: { ... exampleField: null ... }, then it will match only documents where the field has been set to null, and not undefined fields\n\nThe ordering of fields and lists matters when using equals:\n\nFor fields, { \"a\": \"1\", \"b\": \"2\" } and { \"b\": \"2\", \"a\": \"1\" } are not considered equal\nFor lists, [ { \"a\": 1 }, { \"a\": 2 } ] and [ { \"a\": 2 }, { \"a\": 1 } ] are not considered equal\nExamples​\nFind orders that exactly match the given shippingAddress​\nconst orders = await prisma.order.findMany({\n\n  where: {\n\n    shippingAddress: {\n\n      equals: {\n\n        street: '555 Candy Cane Lane',\n\n        city: 'Wonderland',\n\n        zip: '52337',\n\n      },\n\n    },\n\n  },\n\n});\n\nFind products with photos that match all of a list of urls​\nconst product = prisma.product.findMany({\n\n  where: {\n\n    equals: {\n\n      photos: [{ url: '1.jpg' }, { url: '2.jpg' }],\n\n    },\n\n  },\n\n});\n\nis​\n\nUse is to filter results by matching specific fields within composite types.\n\nExamples​\nFind orders with a shippingAddress that matches the given street name​\nconst orders = await prisma.order.findMany({\n\n  where: {\n\n    shippingAddress: {\n\n      is: {\n\n        street: '555 Candy Cane Lane',\n\n      },\n\n    },\n\n  },\n\n});\n\nisNot​\n\nUse isNot to filter results for composite type fields that do not match.\n\nExamples​\nFind orders with a shippingAddress that does not match the given zip code​\nconst orders = await prisma.order.findMany({\n\n  where: {\n\n    shippingAddress: {\n\n      isNot: {\n\n        zip: '52337',\n\n      },\n\n    },\n\n  },\n\n});\n\nisEmpty​\n\nUse isEmpty to filter results for an empty list of composite types.\n\nExamples​\nFind products with no photos​\nconst product = prisma.product.findMany({\n\n  where: {\n\n    photos: {\n\n      isEmpty: true,\n\n    },\n\n  },\n\n});\n\nevery​\n\nUse every to filter for lists of composite types where every item in the list matches the condition\n\nExamples​\nFind the first product where every photo has a height of 200​\nconst product = await prisma.product.findFirst({\n\n  where: {\n\n    photos: {\n\n      every: {\n\n        height: 200,\n\n      }\n\n    }\n\n  },\n\n})\n\nsome​\n\nUse some to filter for lists of composite types where one or more items in the list match the condition.\n\nExamples​\nFind the first product where one or more photos have a url of 2.jpg​\nconst product = await prisma.product.findFirst({\n\n  where: {\n\n    photos: {\n\n      some: {\n\n         url: \"2.jpg\",\n\n      }\n\n    }\n\n  },\n\n})\n\nnone​\n\nUse none to filter for lists of composite types where no items in the list match the condition.\n\nExamples​\nFind the first product where no photos have a url of 2.jpg​\nconst product = await prisma.product.findFirst({\n\n  where: {\n\n    photos: {\n\n      none: {\n\n         url: \"2.jpg\",\n\n      }\n\n    }\n\n  },\n\n})\n\nAtomic number operations​\n\nAtomic operations on update is available for number field types (Float and Int). This feature allows you to update a field based on its current value (such as subtracting or dividing) without risking a race condition.\n\nOverview: Race conditions\nOperators​\nOption\tDescription\nincrement\tAdds n to the current value.\ndecrement\tSubtacts n from the current value.\nmultiply\tMultiplies the current value by n.\ndivide\tDivides the current value by n.\nset\tSets the current field value. Identical to { myField : n }.\nRemarks​\nYou can only perform one atomic update per field, per query.\nIf a field is null, it will not be updated by increment, decrement, multiply, or divide.\nExamples​\nIncrement all view and likes fields of all Post records by 1​\nconst updatePosts = await prisma.post.updateMany({\n\n  data: {\n\n    views: {\n\n      increment: 1,\n\n    },\n\n    likes: {\n\n      increment: 1,\n\n    },\n\n  },\n\n});\n\nSet all views fields of all Post records to 0​\nconst updatePosts = await prisma.post.updateMany({\n\n  data: {\n\n    views: {\n\n      set: 0,\n\n    },\n\n  },\n\n});\n\n\nCan also be written as:\n\nconst updatePosts = await prisma.post.updateMany({\n\n  data: {\n\n    views: 0,\n\n  },\n\n});\n\nJson filters​\n\nFor use cases and advanced examples, see: Working with Json fields.\n\nWARNING\n\nSupported by PostgreSQL and MySQL with different syntaxes for the path option. PostgreSQL does not support filtering on object key values in arrays.\n\nThe examples in this section assumes that the value of the pet field is:\n\n{\n\n  \"favorites\": {\n\n    \"catBreed\": \"Turkish van\",\n\n    \"dogBreed\": \"Rottweiler\",\n\n    \"sanctuaries\": [\"RSPCA\", \"Alley Cat Allies\"],\n\n    \"treats\": [\n\n      { \"name\": \"Dreamies\", \"manufacturer\": \"Mars Inc\" },\n\n      { \"name\": \"Treatos\", \"manufacturer\": \"The Dog People\" }\n\n    ]\n\n  },\n\n  \"fostered\": {\n\n    \"cats\": [\"Bob\", \"Alice\", \"Svetlana the Magnificent\", \"Queenie\"]\n\n  },\n\n  \"owned\": {\n\n    \"cats\": [\"Elliott\"]\n\n  }\n\n}\n\nRemarks​\nThe implementation of Json filtering differs between database connectors\nFiltering is case sensitive in PostgreSQL and does not yet support mode\npath​\n\npath represents the location of a specific key. The following query returns all users where the nested favourites > dogBreed key equals \"Rottweiler\".\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'dogBreed'],\n\n      equals: 'Rottweiler',\n\n    },\n\n  },\n\n});\n\n\nThe following query returns all users where the nested owned > cats array contains \"Elliott\".\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['owned', 'cats'],\n\n      array_contains: ['Elliott'],\n\n    },\n\n  },\n\n});\n\nWARNING\n\nFiltering by the key values of objects inside an array (below) is only supported by the MySQL connector.\n\nThe following query returns all users where the nested favorites > treats array contains an object where the name value is \"Dreamies\":\n\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: '$.favorites.treats[*].name',\n\n      array_contains: 'Dreamies',\n\n    },\n\n  },\n\n});\n\nstring_contains​\n\nThe following query returns all users where the nested favorites > catBreed key value contains \"Van\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_contains: 'Van',\n\n    },\n\n  },\n\n});\n\nstring_starts_with​\n\nThe following query returns all users where the nested favorites > catBreed key value starts with \"Turkish\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_starts_with: 'Turkish',\n\n    },\n\n  },\n\n});\n\nstring_ends_with​\n\nThe following query returns all users where the nested favorites > catBreed key value ends with \"Van\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_ends_with: 'Van',\n\n    },\n\n  },\n\n});\n\nmode​\n\nSpecify whether the the string filtering should be case sensitive (default) or case insensitive.\n\nThe following query returns all users where the nested favorites > catBreed key value contains \"Van\" or \"van\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['favorites', 'catBreed'],\n\n      string_contains: 'Van',\n\n      mode: \"insensitive\",\n\n    },\n\n  },\n\n});\n\narray_contains​\n\nThe following query returns all users where the sanctuaries array contains the value \"RSPCA\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_contains: ['RSPCA'],\n\n    },\n\n  },\n\n});\n\nINFO\n\nNote: In PostgreSQL, the value of array_contains must be an array and not a string, even if the array only contains a single value.\n\nThe following query returns all users where the sanctuaries array contains all the values in the given array:\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_contains: ['RSPCA', 'Alley Cat Allies'],\n\n    },\n\n  },\n\n});\n\narray_starts_with​\n\nThe following query returns all users where the sanctuaries array starts with the value \"RSPCA\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_starts_with: 'RSPCA',\n\n    },\n\n  },\n\n});\n\narray_ends_with​\n\nThe following query returns all users where the sanctuaries array ends with the value \"Alley Cat Allies\":\n\nPostgreSQL\nMySQL\nconst getUsers = await prisma.user.findMany({\n\n  where: {\n\n    pets: {\n\n      path: ['sanctuaries'],\n\n      array_ends_with: 'Alley Cat Allies',\n\n    },\n\n  },\n\n});\n\nClient methods​\n\nNote: Client-level methods are prefixed by $.\n\nRemarks​\n$on and $use client methods do not exist on extended client instances which are extended using $extends\nWARNING\n\nIn extended clients, Client methods do not necessarily exist. If you are extending your client, make sure to check for existence before using Client methods like $transaction or $connect.\n\nIn addition, if you are using $on or $use, you will need to use these client methods before extending your client as these methods do not exist on extended clients. For $use specifically we recommend transitioning to use query extensions.\n\n$disconnect()​\n\nThe $disconnect() method closes the database connections that were established when $connect was called and stops the process that was running Prisma ORM's query engine. See Connection management for an overview of $connect() and $disconnect().\n\nRemarks​\n$disconnect() returns a Promise, so you should call it inside an async function with the await keyword.\n$connect()​\n\nThe $connect() method establishes a physical connection to the database via Prisma ORM's query engine. See Connection management for an overview of $connect() and $disconnect().\n\nRemarks​\n$connect() returns a Promise, so you should call it inside an async function with the await keyword.\n$on()​\nWARNING\n\n$on is not available in extended clients. Please either migrate to client extensions or use the $on method prior to extending your client.\n\nThe $on() method allows you to subscribe to logging events or the exit hook.\n\n$use()​\nWARNING\n\n$use is not available in extended clients. Please either migrate to query extensions or use the $use method prior to extending your client.\n\nThe $use() method adds proxy :\n\nprisma.$use(async (params, next) => {\n\n  console.log('This is proxy!');\n\n  // Modify or interrogate params here\n\n\n\n  return next(params);\n\n});\n\nnext​\n\nnext represents the \"next level\" in the proxy stack, which could be the next proxy or the Prisma Query, depending on where in the stack you are.\n\nparams​\n\nparams is an object with information to use in your proxy.\n\nParameter\tDescription\naction\tThe query type - for example, create or findMany.\nargs\tArguments that were passed into the query - for example, where, data, or orderBy\ndataPath\tPopulated if you use the fluent API.\nmodel\tThe model type - for example, Post or User.\nrunInTransaction\tReturns true if the query ran in the context of a transaction.\nTIP\n\nIf you need the model property as a string, use: String(params.model)\n\nExample parameter values:\n\n{\n\n  args: { where: { id: 15 } },\n\n  dataPath: [ 'select', 'author', 'select', 'posts' ],\n\n  runInTransaction: false,\n\n  action: 'findMany',\n\n  model: 'Post'\n\n}\n\nExamples​\n\nSee proxy examples.\n\n$queryRawTyped​\n\nSee: Using Raw SQL ($queryRawTyped).\n\n$queryRaw​\n\nSee: Using Raw SQL ($queryRaw).\n\n$queryRawUnsafe()​\n\nSee: Using Raw SQL ($queryRawUnsafe()).\n\n$executeRaw​\n\nSee: Using Raw SQL ($executeRaw).\n\n$executeRawUnsafe()​\n\nSee: Using Raw SQL ($executeRawUnsafe()).\n\n$runCommandRaw()​\n\nSee: Using Raw SQL ($runCommandRaw()).\n\n$transaction()​\n\nSee: Transactions.\n\n$metrics​\n\nPrisma Client metrics give you a detailed insight into how Prisma Client interacts with your database. You can use this insight to help diagnose performance issues with your application. Learn more: Metrics.\n\nPrisma Client metrics has the following methods:\n\n$metrics.json(): Retrieves Prisma Client metrics in JSON format.\n$metrics.prometheus(): Retrieves Prisma Client metrics in Prometheus format.\n$extends​\n\nWith $extends, you can create and use Prisma Client extensions to add functionality to Prisma Client in the following ways:\n\nmodel: add custom methods to your models\nclient: add custom methods to your client\nquery: create custom Prisma Client queries\nresult: add custom fields to your query results\n\nLearn more: Prisma Client extensions.\n\nUtility types​\n\nUtility types are helper functions and types that live on the Prisma namespace. They are useful for keeping your application type safe.\n\nPrisma.validator​\n\nThe validator helps you create re-usable query parameters based on your schema models while making sure that the objects you create are valid. See also: Using Prisma.validator\n\nThere are two ways you can use the validator:\n\nUsing generated Prisma Client types​\n\nUsing types provides a type-level approach to validate data:\n\nPrisma.validator<GeneratedType>({ args });\n\nUsing a \"selector\"​\n\nWhen using the selector pattern, you use an existing Prisma Client instance to create a validator. This pattern allows you to select the model, operation, and query option to validate against.\n\nYou can also use an instance of Prisma Client that has been extended using a Prisma Client extension.\n\nPrisma.validator(PrismaClientInstance, '<model>', '<operation>', '<query option>')({ args });\n\nExamples​\n\nThe following example shows how you can extract and validate the input for the create operation you can reuse within your app:\n\nimport { Prisma } from '@prisma/client';\n\n\n\nconst validateUserAndPostInput = (name, email, postTitle) => {\n\n  return Prisma.validator<Prisma.UserCreateInput>()({\n\n    name,\n\n    email,\n\n    posts: {\n\n      create: {\n\n        title: postTitle,\n\n      },\n\n    },\n\n  });\n\n};\n\n\nHere is an alternative syntax for the same operation:\n\nimport { Prisma } from '@prisma/client';\n\nimport prisma from './prisma';\n\n\n\nconst validateUserAndPostInput = (name, email, postTitle) => {\n\n  return Prisma.validator(\n\n    prisma,\n\n    'user',\n\n    'create',\n\n    'data'\n\n  )({\n\n    name,\n\n    email,\n\n    posts: {\n\n      create: {\n\n        title: postTitle,\n\n      },\n\n    },\n\n  });\n\n};\n\nCompare columns in the same table​\n\nYou can compare columns in the same table directly, for non-unique filters.\n\nThis feature was moved to general availability in version 5.0.0 and was available via the fieldReference Preview feature from Prisma ORM versions 4.3.0 to 4.16.2.\n\nINFO\n\nIn the following situations, you must use raw queries to compare columns in the same table:\n\nIf you use a version earlier than 4.3.0\nIf you want to use a unique filter, such as findUnique or findUniqueOrThrow\nIf you want to compare a field with a unique constraint\nIf you want to use one of the following operators to compare a JSON field in MySQL or MariaDB with another field: gt, gte, lt, or lte. Note that you can use these operators to compare the JSON field with a scalar value. This limitation applies only if you try to compare a JSON field with another field.\n\nTo compare columns in the same table, use the <model>.fields property. In the following example, the query returns all records where the value in the prisma.product.quantity field is less than or equal to the value in the prisma.product.warnQuantity field.\n\nprisma.product.findMany({\n\n  where: { quantity: { lte: prisma.product.fields.warnQuantity } },\n\n});\n\nINFO\n\nfields is a special property of every model. It contains the list of fields for that model.\n\nConsiderations​\nFields must be of the same type​\n\nYou can only make comparisons on fields of the same type. For example, the following causes an error:\n\nawait prisma.order.findMany({\n\n  where: {\n\n    id: { equals: prisma.order.fields.due },\n\n    // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    // Type error: id is a string, while amountDue is an integer\n\n  },\n\n});\n\nFields must be in the same model​\n\nYou can only make comparisons with the fields property on fields in the same model. The following example does not work:\n\nawait prisma.order.findMany({\n\n  where: {\n\n    id: { equals: prisma.user.fields.name },\n\n    // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n    // Type error: name is a field on the User model, not Order\n\n  },\n\n});\n\n\nHowever, you can compare fields in separate models with standard queries.\n\nIn groupBy model queries, put your referenced fields in the by argument​\n\nIf you use the groupBy model query with the having option, then you must put your referenced fields in the by argument.\n\nThe following example works:\n\nprisma.user.groupBy({\n\n  by: ['id', 'name'],\n\n  having: { id: { equals: prisma.user.fields.name } },\n\n});\n\n\nThe following example does not work, because name is not in the by argument:\n\nprisma.user.groupBy({\n\n  by: ['id'],\n\n  having: { id: { equals: prisma.user.fields.name } },\n\n  // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  // name is not in the 'by' argument\n\n});\n\nSearch for fields in scalar lists​\n\nIf your data source supports scalar lists (for example in PostgreSQL), then you can search for all records where a specific field is in a list of fields. To do so, reference the scalar list with the in and notIn filters. For example:\n\nawait prisma.user.findMany({\n\n  where: {\n\n    // find all users where 'name' is in a list of tags\n\n    name: { in: prisma.user.fields.tags },\n\n  },\n\n});\n\nFilter on non-unique fields with UserWhereUniqueInput​\n\nFrom version 5.0.0, the generated type UserWhereUniqueInput on where exposes all fields on the model, not just unique fields. This was available under the extendedWhereUnique Preview flag between versions 4.5.0 to 4.16.2\n\nYou must specify at least one unique field in your where statement outside of boolean operators, and you can specify any number of additional unique and non-unique fields. You can use this to add filters to any operation that returns a single record. For example, you can use this feature for the following:\n\nOptimistic concurrency control on updates\nPermission checks\nSoft deletes\n\nFrom version 4.6.0, you can use this feature to filter on optional one-to-one nested reads.\n\nOptimistic concurrency control on updates​\n\nYou can filter on non-unique fields to perform optimistic concurrency control on update operations.\n\nTo perform optimistic concurrency control, we recommend that you use a version field to check whether the data in a record or related record has changed while your code executes. Before version 4.5.0, you could not evaluate the version field in an update operation, because the field is non-unique. From version 4.5.0, you can evaluate the version field.\n\nIn the following example, updateOne and updateTwo first read the same record and then attempt to update it. The database only executes these updates if the value in version is the same as the value when it did the initial read. When the database executes the first of these updates (which might be updateOne or updateTwo, depending on timing), it increments the value in version. This means that the database does not execute the second update because the value in version has changed.\n\nmodel User {\n\n  id      Int    @id @default(autoincrement())\n\n  email   String @unique\n\n  city    String\n\n  version Int\n\n}\n\nfunction updateOne() {\n\n  const user = await prisma.user.findUnique({ id: 1 });\n\n\n\n  await prisma.user.update({\n\n    where: { id: user.id, version: user.version },\n\n    data: { city: 'Berlin', version: { increment: 1 } },\n\n  });\n\n}\n\n\n\nfunction updateTwo() {\n\n  const user = await prisma.user.findUnique({ id: 1 });\n\n\n\n  await prisma.user.update({\n\n    where: { id: user.id, version: user.version },\n\n    data: { city: 'New York', version: { increment: 1 } },\n\n  });\n\n}\n\n\n\nfunction main() {\n\n  await Promise.allSettled([updateOne(), updateTwo()]);\n\n}\n\nPermission checks​\n\nYou can filter on non-unique fields to check permissions during an update.\n\nIn the following example, a user wants to update a post title. The where statement checks the value in authorId to confirm that the user is the author of the post. The application only updates the post title if the user is the post author.\n\nawait prisma.post.update({\n\n  where: { id: 1, authorId: 1 },\n\n  data: { title: 'Updated post title' },\n\n});\n\nSoft deletes​\n\nYou can filter on non-unique fields to handle soft deletes.\n\nIn the following example, we do not want to return a post if it is soft-deleted. The operation only returns the post if the value in isDeleted is false.\n\nprisma.Post.findUnique({ where: { id: postId, isDeleted: false } });\n\nUserWhereUniqueInput considerations​\nBoolean operators with UserWhereUniqueInput​\n\nWith UserWhereUniqueInput, you must specify at least one unique field outside of the boolean operators AND, OR, NOT. You can still use these boolean operators in conjunction with any other unique fields or non-unique fields in your filter.\n\nIn the following example, we test id, a unique field, in conjunction with email. This is valid.\n\nawait prisma.user.update({\n\n  where: { id: 1, OR: [{ email: \"bob@prisma.io\" }, { email: \"alice@prisma.io\" }] },\n\n        // ^^^ Valid: the expression specifies a unique field (`id`) outside of any boolean operators\n\n  data: { ... }\n\n})\n\n\n\n// SQL equivalent:\n\n// WHERE id = 1 AND (email = \"bob@prisma.io\" OR email = \"alice@prisma.io\")\n\n\nThe following example is not valid, because there is no unique field outside of any boolean operators:\n\nawait prisma.user.update({\n\n  where: { OR: [{ email: \"bob@prisma.io\" }, { email: \"alice@prisma.io\" }] },\n\n        // ^^^ Invalid: the expressions does not contain a unique field outside of boolean operators\n\n  data: { ... }\n\n})\n\nOne-to-one relations​\n\nFrom version 4.5.0, you can filter on non-unique fields in the following operations on one-to-one relations:\n\nNested update\nNested upsert\nNested disconnect\nNested delete\n\nPrisma Client automatically uses a unique filter to select the appropriate related record. As a result, you do not need to specify a unique filter in your where statement with a WhereUniqueInput generated type. Instead, the where statement has a WhereInput generated type. You can use this to filter without the restrictions of WhereUniqueInput.\n\nNested update example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      // Before Prisma version 4.5.0\n\n      update: { field: \"updated\" }\n\n      // From Prisma version 4.5.0, you can also do the following:\n\n      update: { where: { /*WhereInput*/ }, data: { field: \"updated\" } } }\n\n    }\n\n  }\n\n})\n\nNested upsert example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      upsert: {\n\n        where: { /* WhereInput */ } // new argument from Prisma 4.5.0\n\n        create: { /* CreateInput */ },\n\n        update: { /* CreateInput */ },\n\n      }\n\n    }\n\n  }\n\n})\n\nNested disconnect example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      // Before Prisma version 4.5.0\n\n      disconnect: true\n\n      // From Prisma version 4.5.0, you can also do the following:\n\n      disconnect: { /* WhereInput */ }\n\n    }\n\n  }\n\n})\n\nNested delete example​\nawait prisma.user.update({\n\n  where: { id: 1, },\n\n  data: {\n\n    to_one: {\n\n      // Before Prisma version 4.5.0\n\n      delete: true\n\n      // From Prisma version 4.5.0, you can also do the following:\n\n      delete: { /* WhereInput */ }\n\n    }\n\n  }\n\n})\n\nPrismaPromise behavior​\n\nAll Prisma Client queries return an instance of PrismaPromise. This is a \"thenable\"\n, meaning a PrismaPromise only executes when you call await or .then() or .catch(). This behavior is different from a regular JavaScript \nPromise\n, which starts executing immediately.\n\nFor example:\n\nconst findPostOperation = prisma.post.findMany({}); // Query not yet executed\n\n\n\nfindPostOperation.then(); // Prisma Client now executes the query\n\n// or\n\nawait findPostOperation; // Prisma Client now executes the query\n\n\nWhen using the $transaction API, this behavior makes it possible for Prisma Client to pass all the queries on to the query engine as a single transaction."
  },
  {
    "title": "Prisma CLI reference | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-cli-reference",
    "html": "ORMReference\nPrisma CLI reference\n\nThis document describes the Prisma CLI commands, arguments, and options.\n\nCommands​\nversion (-v)​\n\nThe version command outputs information about your current prisma version, platform, and engine binaries.\n\nOptions​\n\nThe version command recognizes the following options to modify its behavior:\n\nOption\tRequired\tDescription\n--json\tNo\tOutputs version information in JSON format.\nExamples​\nOutput version information​\nprisma version\n\nShow CLI results\nEnvironment variables loaded from .env\n\nprisma               : 2.21.0-dev.4\n\n@prisma/client       : 2.21.0-dev.4\n\nCurrent platform     : windows\n\nQuery Engine         : query-engine 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\query-engine-windows.exe)\n\nMigration Engine     : migration-engine-cli 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\migration-engine-windows.exe)\n\nFormat Binary        : prisma-fmt 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\n\nDefault Engines Hash : 60ba6551f29b17d7d6ce479e5733c70d9c00860e\n\nStudio               : 0.365.0\n\nOutput version information (-v)​\nprisma -v\n\nShow CLI results\nEnvironment variables loaded from .env\n\nprisma               : 2.21.0-dev.4\n\n@prisma/client       : 2.21.0-dev.4\n\nCurrent platform     : windows\n\nQuery Engine         : query-engine 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\query-engine-windows.exe)\n\nMigration Engine     : migration-engine-cli 2fb8f444d9cdf7c0beee7b041194b42d7a9ce1e6 (at C:\\Users\\veroh\\AppData\\Roaming\\npm\\node_modules\\@prisma\\cli\\migration-engine-windows.exe)\n\nFormat Binary        : prisma-fmt 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\@prisma\\engines\\prisma-fmt-windows.exe)\n\nDefault Engines Hash : 60ba6551f29b17d7d6ce479e5733c70d9c00860e\n\nStudio               : 0.365.0\n\nOutput version information as JSON​\nprisma version --json\n\nShow CLI results\nEnvironment variables loaded from .env\n\n{\n\n  \"prisma\": \"2.21.0-dev.4\",\n\n  \"@prisma/client\": \"2.21.0-dev.4\",\n\n  \"current-platform\": \"windows\",\n\n  \"query-engine\": \"query-engine 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\\\@prisma\\\\engines\\\\query-engine-windows.exe)\",\n\n  \"migration-engine\": \"migration-engine-cli 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\\\@prisma\\\\engines\\\\migration-engine-windows.exe)\",\n\n  \"format-binary\": \"prisma-fmt 60ba6551f29b17d7d6ce479e5733c70d9c00860e (at node_modules\\\\@prisma\\\\engines\\\\prisma-fmt-windows.exe)\",\n\n  \"default-engines-hash\": \"60ba6551f29b17d7d6ce479e5733c70d9c00860e\",\n\n  \"studio\": \"0.365.0\"\n\n}\n\ninit​\n\nBootstraps a fresh Prisma ORM project within the current directory.\n\nThe init command does not interpret any existing files. Instead, it creates a prisma directory containing a bare-bones schema.prisma file within your current directory.\n\nBy default, the project sets up a local Prisma Postgres instance but you can choose a different database using the --datasource-provider option.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--datasource-provider\tNo\tSpecifies the value for the provider field in the datasource block. Options are prisma+postgres, sqlite, postgresql, mysql, sqlserver, mongodb and cockroachdb.\tpostgresql\n--db\tNo\tShorthand syntax for --datasource-provider prisma+postgres; creates a new Prisma Postgres instance. Requires authentication in the PDP Console.\t\n--prompt (or --vibe)\tNo\tScaffolds a Prisma schema based on the prompt and deploys it to a fresh Prisma Postgres instance. Requires authentication in the PDP Console.\t\n--url\tNo\tDefine a custom datasource url.\t\n--generator-provider\tNo\tDefine the generator provider to use.\tprisma-client-js\n--preview-feature\tNo\tDefine the Preview features to use. To define multiple Preview features, you have to provide the flag multiple times for each Preview feature. See examples.\t\n--output\tNo\tSpecifies the output location for the generated client.\t../generated/prisma\n--with-model\tNo\tAdds a simple User model to the initial Prisma schema. Available since version 5.14.0.\t\nExamples​\n\nRun prisma init\n\nprisma init\n\nShow CLI results\n✔ Your Prisma schema was created at prisma/schema.prisma.\n\nYou can now open it in your favorite editor.\n\n\n\nNext steps:\n\n1. Set the DATABASE_URL in the .env file to point to your existing database. If your database has no tables yet, read https://pris.ly/d/getting-started\n\n2. Set the provider of the datasource block in schema.prisma to match your database: postgresql, mysql, sqlite, sqlserver, mongodb or cockroachdb.\n\n3. Run prisma db pull to turn your database schema into a Prisma schema.\n\n4. Run prisma generate to generate Prisma Client. You can then start querying your database.\n\n\n\nMore information in our documentation:\n\nhttps://pris.ly/d/getting-started\n\n\nNext, run the prisma dev command to interact with your local Prisma Postgres instance (e.g. to run migrations or execute queries).\n\nRun prisma init --datasource-provider sqlite\n\nprisma init --datasource-provider sqlite\n\n\nThe command output contains helpful information on how to use the generated files and begin using Prisma ORM with your project.\n\nRun prisma init --db\n\nprisma init --db\n\n\nThe command creates a new Prisma Postgres instance. Note that it requires you to be authenticated with the PDP Console, If you run it for the first time without being authenticated, the command will open the browser for you to log into Console.\n\nRun prisma init --prompt \"Simple habit tracker application\"\n\nprisma init --prompt \"Simple habit tracker application\"\n\n\nThe command scaffolds a Prisma schema and deploys it to a fresh Prisma Postgres instance. Note that it requires you to be authenticated with the PDP Console, If you run it for the first time without being authenticated, the command will open the browser for you to log into Console.\n\nRun prisma init --preview-feature\n\nprisma init --preview-feature metrics\n\nShow Prisma schema results\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"metrics\"]\n\n}\n\nprisma init --preview-feature view --preview-feature metrics\n\nShow Prisma schema results\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"views\", \"metrics\"]\n\n}\n\nGenerated Assets​\n\nprisma/schema.prisma\n\nAn initial schema.prisma file to define your schema in:\n\n// This is your Prisma schema file,\n\n// learn more about it in the docs: https://pris.ly/d/prisma-schema\n\n\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n  output   = \"../generated/prisma\"\n\n}\n\n\n\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n.env\n\nA file to define environment variables for your project:\n\n# Environment variables declared in this file are automatically made available to Prisma.\n\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server, MongoDB and CockroachDB.\n\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\n\n\nDATABASE_URL=\"file:./dev.db\"\n\n\n.gitignore\n\nA file to specify what folders/files git should ignore in your project.\n\nnode_modules\n\n# Keep environment variables out of version control\n\n.env\n\n\n\n/generated/prisma\n\n\nRun prisma init --url mysql://user:password@localhost:3306/mydb\n\nThe init command with the --url argument allows you to specify a custom datasource URL during Prisma initialization, instead of relying on a placeholder database URL:\n\nprisma init --url mysql://user:password@localhost:3306/mydb\n\nGenerated Assets​\n\nprisma/schema.prisma\n\nA minimal schema.prisma file to define your schema in:\n\n// This is your Prisma schema file,\n\n// learn more about it in the docs: https://pris.ly/d/prisma-schema\n\n\n\ndatasource db {\n\n  provider = \"mysql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\n\n.env\n\nA file to define environment variables for your project:\n\n# Environment variables declared in this file are automatically made available to Prisma.\n\n# See the documentation for more detail: https://pris.ly/d/prisma-schema#using-environment-variables\n\n\n\n# Prisma supports the native connection string format for PostgreSQL, MySQL, SQLite, SQL Server, MongoDB and CockroachDB.\n\n# See the documentation for all the connection string options: https://pris.ly/d/connection-strings\n\n\n\nDATABASE_URL=\"mysql://user:password@localhost:3306/mydb\"\n\ngenerate​\n\nThe generate command generates assets like Prisma Client based on the generator and data model blocks defined in your prisma/schema.prisma file.\n\nThe generate command is most often used to generate Prisma Client with the prisma-client-js generator. This does three things:\n\nSearches the current directory and parent directories to find the applicable npm project. It will create a package.json file in the current directory if it cannot find one.\nInstalls the @prisma/client into the npm project if it is not already present.\nInspects the current directory to find a Prisma Schema to process. It will then generate a customized Prisma Client\n for your project.\nPrerequisites​\n\nTo use the generate command, you must add a generator definition in your schema.prisma file. The prisma-client-js generator, used to generate Prisma Client, can be added by including the following in your schema.prisma file:\n\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--data-proxy\tNo\tThe generate command will generate Prisma Client for use with Prisma Accelerate prior to Prisma 5.0.0. Mutually exclusive with --accelerate and --no-engine.\t\n--accelerate\tNo\tThe generate command will generate Prisma Client for use with Prisma Accelerate. Mutually exclusive with --data-proxy and --no-engine. Available in Prisma 5.1.0 and later.\t\n--no-engine\tNo\tThe generate command will generate Prisma Client without an accompanied engine for use with Prisma Accelerate. Mutually exclusive with --data-proxy and --accelerate. Available in Prisma ORM 5.2.0 and later.\t\n--no-hints\tNo\tThe generate command will generate Prisma Client without usage hints, surveys or info banners being printed to the terminal. Available in Prisma ORM 5.16.0 and later.\t\n--allow-no-models\tNo\tThe generate command will generate Prisma Client without generating any models.\t\n--watch\tNo\tThe generate command will continue to watch the schema.prisma file and re-generate Prisma Client on file changes.\t\nWARNING\n\nDeprecation Warning\n\nAs of Prisma 5.2.0, --data-proxy and --accelerate are deprecated in favor of --no-engine as Prisma Client no longer requires an option to work with Prisma Accelerate. All options are available and work similarly, but we recommend --no-engine as it prevents an engine from being downloaded which will greatly impact the size of apps deployed to serverless and edge functions.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\t\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\t\n--generator\tNo\tSpecifies which generator to use to generate assets. This option may be provided multiple times to include multiple generators. By default, all generators in the target schema will be run.\t\t\nExamples​\nGenerate Prisma Client using the default schema.prisma path​\nprisma generate\n\nShow CLI results\n✔ Generated Prisma Client to ./node_modules/.prisma/client in 61ms\n\n\n\nYou can now start using Prisma Client in your code:\n\n\n\nimport { PrismaClient } from '@prisma/client'\n\n// or const { PrismaClient } = require('@prisma/client')\n\n\n\nconst prisma = new PrismaClient()\n\n\n\nExplore the full API: https://pris.ly/d/client\n\nGenerate Prisma Client using a non-default schema.prisma path​\nprisma generate --schema=./alternative/schema.prisma\n\nContinue watching the schema.prisma file for changes to automatically re-generate Prisma Client​\nprisma generate --watch\n\nShow CLI results\nWatching... /home/prismauser/prisma/prisma-play/prisma/schema.prisma\n\n\n\n✔ Generated Prisma Client to ./node_modules/.prisma/client in 45ms\n\nRun the generate command with only a specific generator​\nprisma generate --generator client\n\nRun the generate command with multiple specific generators​\nprisma generate --generator client --generator zod_schemas\n\nGenerated Assets​\n\nThe prisma-client-js generator creates a customized client for working with your database within the ./node_modules/.prisma/client directory by default - you can customize the output folder.\n\nvalidate​\n\nValidates the Prisma Schema Language of the Prisma schema file.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\nExamples​\nValidate a schema without errors​\nprisma validate\n\nShow CLI results\nValidate a schema with validation errors​\nprisma validate\n\nShow CLI results\nformat​\n\nFormats the Prisma schema file, which includes validating, formatting, and persisting the schema.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\n--check\tNo\tFails if any files are unformatted. This can be used in CI to detect if the schema is formatted correctly\t\nExamples​\nValidate a schema without errors​\nprisma format\n\nShow CLI results\nFormatting a schema with validation errors​\nprisma format\n\nShow CLI results\ndebug​\n\nPrints information for debugging and bug reports.\n\nINFO\n\nThis is available from version 5.6.0 and newer.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\n--help / --h\tNo\tDisplays the help message\t\nExample​\nprisma debug\n\nShow CLI results\n\nIf you're using an older version of Prisma, you can use this command by running:\n\nnpx prisma@latest debug\n\ndev​\n\nThe dev command starts a local Prisma Postgres database that you can run Prisma ORM commands against. It is useful for development and testing purposes and also allows you to switch to Prisma Postgres in production easily.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--name (or -n)\tNo\tEnables targeting a specific database instance. Learn more.\t\n--port (or -p)\tNo\tMain port number the local Prisma Postgres HTTP server will listen on.\t51213\n--db-port (or -P)\tNo\tPort number the local Prisma Postgres database server will listen on.\t51214\n--shadow-db-port\tNo\tPort number the shadow database server will listen on.\t51215\n--debug\tNo\tEnable debug logging.\tfalse\nExamples​\n\nRun prisma dev\n\nprisma dev\n\nShow CLI results\n$ npx prisma dev\n\nFetching latest updates for this subcommand...\n\n✔ Great Success! 😉👍\n\n\n\nYour prisma dev server default is ready and listening on ports 63567-63569.\n\n\n\n╭──────────────────────────────╮\n\n│[q]uit [h]ttp url [t]cp urls│\n\n╰──────────────────────────────╯\n\ndev stop​\n\nStops one or more local Prisma Postgres databases:\n\nnpx prisma dev stop <glob>\n\n\n<glob> is a placeholder for a glob pattern to specify which local Prisma Postgres instances should be stopped, for example:\n\nnpx prisma dev stop mydb # stops a DB called `mydb`\n\n\nTo stop all databases that begin with mydb (e.g. mydb-dev and mydb-prod), you can use a glob:\n\nnpx prisma dev stop mydb* # stops all DBs starting with `mydb`\n\ndev rm​\n\nRemoves the data of one or more local Prisma Postgres databases from your file system:\n\nnpx prisma dev rm <glob>\n\n\n<glob> is a placeholder for a glob pattern to specify which local Prisma Postgres instances should be removed, for example:\n\nnpx prisma dev stop mydb # stops a DB called `mydb`\n\n\nTo stop all databases that begin with mydb (e.g. mydb-dev and mydb-prod), you can use a glob:\n\nnpx prisma dev stop mydb* # stops all DBs starting with `mydb`\n\ndb​\ndb pull​\n\nThe db pull command connects to your database and adds Prisma models to your Prisma schema that reflect the current database schema.\n\nWARNING\n\nWarning: The command will overwrite the current schema.prisma file with the new schema. Some manual changes or customization can be lost. Be sure to back up your current schema.prisma file (or commit your current state to version control to be able to revert any changes) before running db pull if it contains important modifications.\n\nINFO\n\nIntrospection with the db pull command on the MongoDB connector samples the data instead of reading a schema.\n\nPrerequisites​\n\nBefore using the db pull command, you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--force\tNo\tForce overwrite of manual changes made to schema. The generated schema will be based on the introspected schema only.\t\n--print\tNo\tPrints the created schema.prisma to the screen instead of writing it to the filesystem.\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma, ./prisma/schema.prisma\nExamples​\nAnalyze the database and write its schema to the schema.prisma file​\nprisma db pull\n\nShow CLI results\nIntrospecting based on datasource defined in schema.prisma …\n\n\n\n✔ Introspected 2 models and wrote them into schema.prisma in 38ms\n\n\n\nRun prisma generate to generate Prisma Client.\n\nSpecify an alternative schema.prisma file to read and write to​\nprisma db pull --schema=./alternative/schema.prisma\n\nShow CLI results\nIntrospecting based on datasource defined in alternative/schema.prisma …\n\n\n\n✔ Introspected 2 models and wrote them into alternative/schema.prisma in 60ms\n\n\n\nRun prisma generate to generate Prisma Client.\n\nDisplay the generated schema.prisma file instead of writing it to the filesystem​\nprisma db pull --print\n\nShow CLI results\ngenerator client {\n\n  provider = \"prisma-client-js\"\n\n}\n\n\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:./hello-prisma.db\"\n\n}\n\n\n\nmodel User {\n\n  email   String    @unique\n\n  name    String?\n\n  user_id Int       @id @default(autoincrement())\n\n  post    Post[]\n\n  profile Profile[]\n\n}\n\n\n\nmodel Post {\n\n  content   String?\n\n  post_id   Int     @id @default(autoincrement())\n\n  title     String\n\n  author    User?   @relation(fields: [author_id], references: [user_id])\n\n  author_id Int?\n\n}\n\n\n\nmodel Profile {\n\n  bio        String?\n\n  profile_id Int     @id @default(autoincrement())\n\n  user       User    @relation(fields: [user_id], references: [user_id])\n\n  user_id    Int     @unique\n\n}\n\ndb push​\n\nThe db push command pushes the state of your Prisma schema to the database without using migrations. It creates the database if the database does not exist.\n\nThis command is a good choice when you do not need to version schema changes, such as during prototyping and local development.\n\nSee also:\n\nConceptual overview of db push and when to use it over Prisma Migrate\nSchema prototyping with db push\nPrerequisites​\n\nBefore using the db push command, you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\nOptions\tRequired\tDescription\n--skip-generate\tNo\tSkip generation of artifacts such as Prisma Client\n--force-reset\tNo\tResets the database and then updates the schema - useful if you need to start from scratch due to unexecutable migrations.\n--accept-data-loss\tNo\tIgnore data loss warnings. This option is required if as a result of making the schema changes, data may be lost.\n--help / --h\tNo\tDisplays the help message\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\n\nPush the schema:\n\nprisma db push\n\n\nPush the schema, accepting data loss:\n\nprisma db push --accept-data-loss\n\n\nPush the schema with a custom schema location:\n\nprisma db push --schema=/tmp/schema.prisma\n\ndb seed​\n\ndb seed changed from Preview to Generally Available (GA) in 3.0.1.\n\nSee Seeding your database\n\nOptions​\nOptions\tRequired\tDescription\n--help / --h\tNo\tDisplays the help message\n--\tNo\tAllows the use of custom arguments defined in a seed file\n\nThe -- argument/ delimiter\n/ double-dash is available from version 4.15.0 or later.\n\nExamples​\nprisma db seed\n\ndb execute​\nINFO\n\nThe db execute command is Generally Available in versions 3.13.0 and later. If you're using a version between 3.9.0 and 3.13.0, it is available behind a --preview-feature CLI flag.\n\nWARNING\n\nThis command is currently not supported on MongoDB.\n\nThis command applies a SQL script to the database without interacting with the Prisma migrations table. The script takes two inputs:\n\nthe SQL script, which can be provided either on standard input or in a file\nthe data source, which can either be the URL of the data source or the path to your Prisma schema file\n\nThe output of the command is connector-specific, and is not meant for returning data, but only to report success or failure.\n\nSee also:\n\nMigration troubleshooting in production\nPrerequisites​\n\nBefore using the db execute command, if you do not use the --url option you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\n\nOne of the following data source inputs is required:\n\nOptions\tDescription\n--url\tURL of the data source to run the command on\n--schema\tPath to a Prisma schema file, uses the URL in the datasource block\n\nOne of the following script inputs is required:\n\nOptions\tDescription\n--stdin\tUse the terminal standard input as the script to be executed\n--file\tPath to a file. The content will be sent as the script to be executed\n\nOther options:\n\nOptions\tRequired\tDescription\n--help\tNo\tDisplays the help message.\nExamples​\n\nTake the content of a SQL file located at ./script.sql and execute it on the database specified by the URL in the datasource block of your schema.prisma file:\n\nprisma db execute --file ./script.sql --schema schema.prisma\n\n\nTake the SQL script from standard input and execute it on the database specified by the data source URL given in the DATABASE_URL environment variable:\n\necho 'TRUNCATE TABLE dev;' | prisma db execute --stdin --url=\"$DATABASE_URL\"\n\nPrisma Migrate​\n\nPrisma Migrate changed from Preview to Generally Available (GA) in 2.19.0.\n\nINFO\n\nDoes not apply for MongoDB\nInstead of migrate dev and related commands, db push is used for MongoDB.\n\nmigrate dev​\n\nFor use in development environments only, requires shadow database\n\nThe migrate dev command:\n\nReruns the existing migration history in the shadow database in order to detect schema drift (edited or deleted migration file, or a manual changes to the database schema)\nApplies pending migrations to the shadow database (for example, new migrations created by colleagues)\nGenerates a new migration from any changes you made to the Prisma schema before running migrate dev\nApplies all unapplied migrations to the development database and updates the _prisma_migrations table\nTriggers the generation of artifacts (for example, Prisma Client)\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nSee also:\n\nConceptual overview of Prisma Migrate\nDeveloping with Prisma Migrate\nOptions​\nOption\tRequired\tDescription\tDefault\n--create-only\tNo\tCreates a new migration but does not apply it. This also works if you haven't made any changes to your schema (in that case, an empty migration is created). Run migrate dev to apply migration.\t\n--skip-seed\tNo\tSkip triggering seed\t\n--skip-generate\tNo\tSkip triggering generators (for example, Prisma Client)\t\n--name / -n\tNo\tName the migration (e.g. prisma migrate dev --name added_job_title)\t\n--help / -h\tNo\tDisplays the help message\t\nINFO\n\nIf a schema drift is detected while running prisma migrate dev using --create-only, you will be prompted to reset your database.\n\nArguments​\nArgument\tRequired\tDescription\tDefault\n--name\tNo\tThe name of the migration. If no name is provided, the CLI will prompt you.\t\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\n\nApply all migrations, then create and apply any new migrations:\n\nprisma migrate dev\n\n\nApply all migrations and create a new migration if there are schema changes, but do not apply it:\n\nprisma migrate dev --create-only\n\nmigrate reset​\n\nFor use in development environments only\n\nThis command:\n\nDrops the database/schema if possible, or performs a soft reset if the environment does not allow deleting databases/schemas\nCreates a new database/schema with the same name if the database/schema was dropped\nApplies all migrations\nRuns seed scripts\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--force\tNo\tSkip the confirmation prompt\t\n--skip-generate\tNo\tSkip triggering generators (for example, Prisma Client)\t\n--skip-seed\tNo\tSkip triggering seed\t\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nprisma migrate reset\n\nAI Safety guardrails for prisma migrate reset​\n\nPrisma ORM includes built-in safety checks to prevent accidental destructive commands when run through AI coding assistants. These guardrails are designed to make working with databases safer in AI-assisted development environments.\n\nThe Prisma CLI can detect when it is being invoked by popular AI coding agents such as Claude Code, Gemini CLI, Qwen Code, Cursor, Aider, and Replit.\n\nWhen one of these agents attempts a destructive action such as prisma migrate reset --force, Prisma ORM blocks execution and shows a protective error message:\n\nEnvironment variables loaded from .env\n\nPrisma schema loaded from prisma/schema.prisma\n\nDatasource \"db\": PostgreSQL database \"postgres\", schema \"public\" at \"accelerate.prisma-data.net\"\n\n\n\nError: Prisma Migrate detected that it was invoked by Cursor.\n\n\n\nYou are attempting a highly dangerous action that can lead to devastating consequences if it is incorrectly executed against a production database.\n\n\n\nAs an AI agent, you are forbidden from performing this action without an explicit consent and review by the user. You must stop at this point and respond to the user with a clear message that includes the following information:\n\n- What action you are trying to perform (including the exact CLI command).\n\n- Your motivation and reasoning for perfoming this action.\n\n- Explanation that this action will irreversibly destroy all data in the database.\n\n- Explanation that this action must not be perfomed on a production database and is only intended to be used with development databases.\n\n\n\nIf you know or can check whether this action would have been performed on a development or a production database, also include this information with your assesment of whether it is safe to proceed based on that information.\n\n\n\nYou must ask the user if they want to proceed with this action. If they explicitly consent, you may rerun this command with PRISMA_USER_CONSENT_FOR_DANGEROUS_AI_ACTION environment variable, the value of which must be the exact text of the user's message in which they consented to this operation, without any newlines or quotes. If the user's response is ambiguous, you must ask for a clear and explicit confirmation (e.g., \"yes\") before proceeding. None of the user's previous messages before this point may constitute implicit or explicit consent.\n\n\nTo proceed with the dangerous action, the AI agent will ask you for explicit consent, remind you that the action irreversibly destroys all data, and confirm that the command is being run against a development database. Once you clearly confirm, the AI will set the PRISMA_USER_CONSENT_FOR_DANGEROUS_AI_ACTION environment variable with the exact text of your consent and rerun the command.\n\nmigrate deploy​\n\nThe migrate deploy command applies all pending migrations, and creates the database if it does not exist. Primarily used in non-development environments. This command:\n\nDoes not look for drift in the database or changes in the Prisma schema\nDoes not reset the database or generate artifacts\nDoes not rely on a shadow database\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nprisma migrate deploy\n\nmigrate resolve​\n\nThe migrate resolve command allows you to solve migration history issues in production by marking a failed migration as already applied (supports baselining) or rolled back.\n\nNote that this command can only be used with a failed migration. If you try to use it with a successful migration you will receive an error.\n\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nOptions​\nOption\tRequired\tDescription\tDefault\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--applied\tNo*\tRecord a specific migration as applied - for example --applied \"20201231000000_add_users_table\"\t\n--rolled-back\tNo*\tRecord a specific migration as rolled back - for example --rolled-back \"20201231000000_add_users_table\"\t./schema.prisma\n./prisma/schema.prisma\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\n\nYou must specify either --rolled-back or --applied.\n\nExamples​\nprisma migrate resolve --applied 20201231000000_add_users_table\n\nprisma migrate resolve --rolled-back 20201231000000_add_users_table\n\nmigrate status​\n\nThe prisma migrate status command looks up the migrations in ./prisma/migrations/* folder and the entries in the _prisma_migrations table and compiles information about the state of the migrations in your database.\n\nWARNING\n\nThis command is not supported on MongoDB. Use db push instead.\n\nFor example:\n\nStatus\n\n3 migrations found in prisma/migrations\n\n\n\nYour local migration history and the migrations table from your database are different:\n\n\n\nThe last common migration is: 20201127134938_new_migration\n\n\n\nThe migration have not yet been applied:\n\n20201208100950_test_migration\n\n\n\nThe migrations from the database are not found locally in prisma/migrations:\n\n20201208100950_new_migration\n\n\nIn versions 4.3.0 and later, prisma migrate status exits with exit code 1 in the following cases:\n\na database connection error occurs\nthere are migration files in the migrations directory that have not been applied to the database\nthe migration history in the migrations directory has diverged from the state of the database\nno migration table is found\nfailed migrations are found\nOptions​\nOption\tRequired\tDescription\tDefault\n--help / --h\tNo\tDisplays the help message\t\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nprisma migrate status\n\nmigrate diff​\nINFO\n\nThis command is only partially supported for MongoDB. See the command options below for details.\n\nThis command compares two database schema sources and outputs a description of a migration taking the first to the state of the second.\n\nThe output can be given either as a human-readable summary (the default) or an executable script.\n\nWARNING\n\nThe migrate diff command can only compare database features that are supported by Prisma. If two databases differ only in unsupported features, such as views or triggers, then migrate diff will not show any difference between them.\n\nThe format of the command is:\n\nprisma migrate diff --from-... <source1> --to-... <source2>\n\n\nwhere the --from-... and --to-... options are selected based on the type of database schema source. The supported types of sources are:\n\nlive databases\nmigration histories\nPrisma schema data models\nan empty schema\n\nBoth schema sources must use the same database provider. For example, a diff comparing a PostgreSQL data source with a SQLite data source is not supported.\n\nSee also:\n\nMigration troubleshooting in production\nPrerequisites​\n\nBefore using the migrate diff command, if you are using the --from-schema-datasource or --to-schema-datasource you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\n\nOne of the following --from-... options is required:\n\nOptions\tDescription\tNotes\n--from-url\tA data source URL\t\n--from-migrations\tPath to the Prisma Migrate migrations directory\tNot supported in MongoDB\n--from-schema-datamodel\tPath to a Prisma schema file, uses the data model for the diff\t\n--from-schema-datasource\tPath to a Prisma schema file, uses the URL in the datasource block for the diff\t\n--from-empty\tAssume that you the data model you are migrating from is empty\t\n--from-local-d1\tPath to a local D1 instance (learn more)\tAvailable since 5.12.0\n\nOne of the following --to-... options is required:\n\nOptions\tDescription\tNotes\n--to-url\tA data source URL\t\n--to-migrations\tPath to the Prisma Migrate migrations directory\tNot supported in MongoDB\n--to-schema-datamodel\tPath to a Prisma schema file, uses the data model for the diff\t\n--to-schema-datasource\tPath to a Prisma schema file, uses the URL in the datasource block for the diff\t\n--to-empty\tAssume that you the data model you are migrating to is empty\t\n--to-local-d1\tPath to a local D1 instance (learn more)\tAvailable since 5.12.0\n\nOther options:\n\nOptions\tRequired\tDescription\tNotes\n--shadow-database-url\tNo\tURL for the shadow database\tOnly required if using --to-migrations or --from-migrations\n--script\tNo\tOutputs a SQL script instead of the default human-readable summary\tNot supported in MongoDB\n-o, --output\tNo\tWrites to a file instead of stdout\tAvailable since 5.12.1\n\n--exit-code\tNo\tChange the exit code behavior to signal if the diff is empty or not (Empty: 0, Error: 1, Not empty: 2). Default behavior is Success: 0, Error: 1.\t\n--help\tNo\tDisplays the help message.\t\nExamples​\n\nCompare two databases specified by their data source URL, and output the default human-readable summary:\n\nprisma migrate diff \\\n\n  --from-url \"$DATABASE_URL\" \\\n\n  --to-url \"postgresql://login:password@localhost:5432/db2\"\n\n\nCompare the state of a database with a URL of $DATABASE_URL to the schema defined by the migrations in the ./prisma/migrations directory, and output the differences to a script script.sql:\n\nprisma migrate diff \\\n\n --from-url \"$DATABASE_URL\" \\\n\n --to-migrations ./prisma/migrations \\\n\n --shadow-database-url $SHADOW_DATABASE_URL \\\n\n --script > script.sql\n\nPrisma Data Platform​\nplatform (Early Access)​\n\nThe platform command provides access to the Prisma Data Platform through the Prisma CLI starting in version 5.10.0 or later.\n\nAuthentication:\nplatform auth login: Opens a browser window for login or account creation.\nplatform auth logout: Logs out of the platform.\nplatform auth show: Displays information about the currently authenticated user.\nWorkspace Management:\nplatform workspace show: Lists all workspaces available to your account.\nProject Management:\nplatform project show: Lists all projects within the specified workspace.\nplatform project create: Creates a new project within the specified workspace.\nplatform project delete: Deletes the specified project.\nEnvironment Management:\nplatform environment show: Lists all environments for the specified project.\nplatform environment create: Creates a new environment within the specified project.\nplatform environment delete: Deletes the specified environment.\nAPI Key Management:\nplatform apikey show: Lists all API keys for the specified environment.\nplatform apikey create: Creates a new API key for the specified environment.\nplatform apikey delete: Deletes the specified API key.\nPrisma Accelerate:\nplatform accelerate enable: Enables Prisma Accelerate for the specified environment.\nplatform accelerate disable: Disables Prisma Accelerate for the specified environment.\n\nYou can find the complete list of available commands with the arguments here.\n\nmcp​\n\nStarts the Prisma MCP server.\n\nStudio​\nstudio​\n\nThe studio command allows you to interact with and manage your data interactively. It does this by starting a local web server with a web app configured with your project's data schema and records.\n\nPrerequisites​\n\nBefore using the studio command, you must define a valid datasource within your schema.prisma file.\n\nFor example, the following datasource defines a SQLite database file within the current directory:\n\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:my-database.db\"\n\n}\n\nOptions​\n\nThe studio command recognizes the following options:\n\nOption\tRequired\tDescription\tDefault\n-b, --browser\tNo\tThe browser to auto-open Studio in.\t<your-default-browser>\n-h, --help\tNo\tShow all available options and exit\t\n-p, --port\tNo\tThe port number to start Studio on.\t5555\nArguments​\nArgument\tRequired\tDescription\tDefault\n--schema\tNo\tSpecifies the path to the desired schema.prisma file to be processed instead of the default path. Both absolute and relative paths are supported.\t./schema.prisma\n./prisma/schema.prisma\nExamples​\nStart Studio on the default port and open a new browser tab to it​\nprisma studio\n\nStart Studio on a different port and open a new browser tab to it​\nprisma studio --port 7777\n\nStart Studio and open a Firefox tab to it​\nprisma studio --browser firefox\n\nStart Studio without opening a new browser tab to it​\nprisma studio --browser none\n\npackage.json entry options​\nschema​\n\nThe path to the desired schema.prisma file can be specified with the prisma.schema entry in the package.json file. The path defines the file the Prisma CLI should use when you run any of the CLI commands. Both absolute and relative paths are supported.\n\n\"package.json\"\n{\n\n  \"name\": \"my-project\",\n\n  \"version\": \"1.0.0\",\n\n  \"prisma\": {\n\n    \"schema\": \"./custom-path-to-schema/schema.prisma\"\n\n  }\n\n}\n\n\nThis is available from version 2.7.0 and later.\n\nseed​\n\nThe command used to populate the datasource is specified in the prisma.seed entry in the package.json file. It is used when prisma db seed is invoked or triggered.\n\nSee Seeding your database\n\n\"package.json\"\n{\n\n  \"name\": \"my-project\",\n\n  \"version\": \"1.0.0\",\n\n  \"prisma\": {\n\n    \"seed\": \"node ./prisma/seed.js\"\n\n  }\n\n}\n\n\nThis is available from version 3.0.1 and later.\n\nUsing a HTTP proxy for the CLI​\n\nPrisma CLI supports custom HTTP proxies\n. This is particularly relevant when being behind a corporate firewall.\n\nTo activate usage of the proxy, provide either of the following environment variables:\n\nHTTP_PROXY or http_proxy: Proxy URL for http traffic, for example http://localhost:8080\nHTTPS_PROXY or https_proxy: Proxy URL for https traffic, for example https://localhost:8080\nnpx create-db​\n\nThe create-db command provisions a temporary Prisma Postgres database with a single command. This is a standalone utility that can be invoked using npx. It's ideal for quickly testing, prototyping, or integrating with Prisma Postgres.\n\nYou can run the following variants:\n\nCommand\tDescription\nnpx create-db@latest\tCreates a temporary Prisma Postgres database.\nnpx create-pg@latest\tAlias for npx create-db.\nnpx create-postgres@latest\tAlias for npx create-db.\n\nEach database created with these commands:\n\nIs available for 24 hours by default.\nCan be claimed for free to make it permanent using the URL displayed in the CLI output.\n\nFor full usage details, options (such as --region and --interactive), and examples, see the documentation."
  },
  {
    "title": "Errors | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/error-reference",
    "html": "ORMReference\nError message reference\n\nFor more information about how to work with exceptions and error codes, see Handling exceptions and errors.\n\nPrisma Client error types​\n\nPrisma Client throws different kinds of errors. The following lists the exception types, and their documented data fields:\n\nPrismaClientKnownRequestError​\n\nPrisma Client throws a PrismaClientKnownRequestError exception if the query engine returns a known error related to the request - for example, a unique constraint violation.\n\nProperty\tDescription\ncode\tA Prisma-specific error code.\nmeta\tAdditional information about the error - for example, the field that caused the error: { target: [ 'email' ] }\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientUnknownRequestError​\n\nPrisma Client throws a PrismaClientUnknownRequestError exception if the query engine returns an error related to a request that does not have an error code.\n\nProperty\tDescription\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientRustPanicError​\n\nPrisma Client throws a PrismaClientRustPanicError exception if the underlying engine crashes and exits with a non-zero exit code. In this case, Prisma Client or the whole Node process must be restarted.\n\nProperty\tDescription\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientInitializationError​\n\nPrisma Client throws a PrismaClientInitializationError exception if something goes wrong when the query engine is started and the connection to the database is created. This happens either:\n\nWhen prisma.$connect() is called OR\nWhen the first query is executed\n\nErrors that can occur include:\n\nThe provided credentials for the database are invalid\nThere is no database server running under the provided hostname and port\nThe port that the query engine HTTP server wants to bind to is already taken\nA missing or inaccessible environment variable\nThe query engine binary for the current platform could not be found (generator block)\nProperty\tDescription\nerrorCode\tA Prisma-specific error code.\nmessage\tError message associated with error code.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nPrismaClientValidationError​\n\nPrisma Client throws a PrismaClientValidationError exception if validation fails - for example:\n\nMissing field - for example, an empty data: {} property when creating a new record\nIncorrect field type provided (for example, setting a Boolean field to \"Hello, I like cheese and gold!\")\nProperty\tDescription\nmessage\tError message.\nclientVersion\tVersion of Prisma Client (for example, 2.19.0)\nError codes​\nCommon​\nP1000​\n\n\"Authentication failed against database server at {database_host}, the provided database credentials for {database_user} are not valid. Please make sure to provide valid database credentials for the database server at {database_host}.\"\n\nP1001​\n\n\"Can't reach database server at {database_host}:{database_port} Please make sure your database server is running at {database_host}:{database_port}.\"\n\nP1002​\n\n\"The database server at {database_host}:{database_port} was reached but timed out. Please try again. Please make sure your database server is running at {database_host}:{database_port}. \"\n\nP1003​\n\n\"Database {database_file_name} does not exist at {database_file_path}\"\n\n\"Database {database_name}.{database_schema_name} does not exist on the database server at {database_host}:{database_port}.\"\n\n\"Database {database_name} does not exist on the database server at {database_host}:{database_port}.\"\n\nP1008​\n\n\"Operations timed out after {time}\"\n\nP1009​\n\n\"Database {database_name} already exists on the database server at {database_host}:{database_port}\"\n\nP1010​\n\n\"User {database_user} was denied access on the database {database_name}\"\n\nP1011​\n\n\"Error opening a TLS connection: {message}\"\n\nP1012​\n\nNote: If you get error code P1012 after you upgrade Prisma ORM to version 4.0.0 or later, see the version 4.0.0 upgrade guide. A schema that was valid before version 4.0.0 might be invalid in version 4.0.0 and later. The upgrade guide explains how to update your schema to make it valid.\n\n\"{full_error}\"\n\nPossible P1012 error messages:\n\n\"Argument {} is missing.\"\n\"Function {} takes arguments, but received .\"\n\"Argument {} is missing in attribute @{}.\"\n\"Argument {} is missing in data source block {}.\"\n\"Argument {} is missing in generator block {}.\"\n\"Error parsing attribute @{}: \"\n\"Attribute @{} is defined twice.\"\n\"The model with database name {} could not be defined because another model with this name exists: {}\"\n\"{} is a reserved scalar type name and can not be used.\"\n\"The {} cannot be defined because a with that name already exists.\"\n\"Key {} is already defined in .\"\n\"Argument {} is already specified as unnamed argument.\"\n\"Argument {} is already specified.\"\n\"No such argument.\"\"\n\"Field {} is already defined on model {}.\"\n\"Field {} in model {} can't be a list. The current connector does not support lists of primitive types.\"\n\"The index name {} is declared multiple times. With the current connector index names have to be globally unique.\"\n\"Value {} is already defined on enum {}.\"\n\"Attribute not known: @{}.\"\n\"Function not known: {}.\"\n\"Datasource provider not known: {}.\"\n\"shadowDatabaseUrl is the same as url for datasource {}. Please specify a different database as shadow database.\"\n\"The preview feature {} is not known. Expected one of: \"\n\"{} is not a valid value for .\"\n\"Type {} is neither a built-in type, nor refers to another model, custom type, or enum.\"\n\"Type {} is not a built-in type.\"\n\"Unexpected token. Expected one of: \"\n\"Environment variable not found: .\"\n\"Expected a value, but received value {}.\"\n\"Expected a value, but failed while parsing {}: .\"\n\"Error validating model {}: \"\n\"Error validating field {} in model {}: \"\n\"Error validating datasource {datasource}: {message}\"\n\"Error validating enum {}: \"\n\"Error validating: \"\nP1013​\n\n\"The provided database string is invalid. {details}\"\n\nP1014​\n\n\"The underlying {kind} for model {model} does not exist.\"\n\nP1015​\n\n\"Your Prisma schema is using features that are not supported for the version of the database.\nDatabase version: {database_version}\nErrors:\n{errors}\"\n\nP1016​\n\n\"Your raw query had an incorrect number of parameters. Expected: {expected}, actual: {actual}.\"\n\nP1017​\n\n\"Server has closed the connection.\"\n\nPrisma Client (Query Engine)​\nP2000​\n\n\"The provided value for the column is too long for the column's type. Column: {column_name}\"\n\nP2001​\n\n\"The record searched for in the where condition ({model_name}.{argument_name} = {argument_value}) does not exist\"\n\nP2002​\n\n\"Unique constraint failed on the {constraint}\"\n\nP2003​\n\n\"Foreign key constraint failed on the field: {field_name}\"\n\nP2004​\n\n\"A constraint failed on the database: {database_error}\"\n\nP2005​\n\n\"The value {field_value} stored in the database for the field {field_name} is invalid for the field's type\"\n\nP2006​\n\n\"The provided value {field_value} for {model_name} field {field_name} is not valid\"\n\nP2007​\n\n\"Data validation error {database_error}\"\n\nP2008​\n\n\"Failed to parse the query {query_parsing_error} at {query_position}\"\n\nP2009​\n\n\"Failed to validate the query: {query_validation_error} at {query_position}\"\n\nP2010​\n\n\"Raw query failed. Code: {code}. Message: {message}\"\n\nP2011​\n\n\"Null constraint violation on the {constraint}\"\n\nP2012​\n\n\"Missing a required value at {path}\"\n\nP2013​\n\n\"Missing the required argument {argument_name} for field {field_name} on {object_name}.\"\n\nP2014​\n\n\"The change you are trying to make would violate the required relation '{relation_name}' between the {model_a_name} and {model_b_name} models.\"\n\nP2015​\n\n\"A related record could not be found. {details}\"\n\nP2016​\n\n\"Query interpretation error. {details}\"\n\nP2017​\n\n\"The records for relation {relation_name} between the {parent_name} and {child_name} models are not connected.\"\n\nP2018​\n\n\"The required connected records were not found. {details}\"\n\nP2019​\n\n\"Input error. {details}\"\n\nP2020​\n\n\"Value out of range for the type. {details}\"\n\nP2021​\n\n\"The table {table} does not exist in the current database.\"\n\nP2022​\n\n\"The column {column} does not exist in the current database.\"\n\nP2023​\n\n\"Inconsistent column data: {message}\"\n\nP2024​\n\n\"Timed out fetching a new connection from the connection pool. (More info: http://pris.ly/d/connection-pool\n (Current connection pool timeout: {timeout}, connection limit: {connection_limit})\"\n\nP2025​\n\n\"An operation failed because it depends on one or more records that were required but not found. {cause}\"\n\nP2026​\n\n\"The current database provider doesn't support a feature that the query used: {feature}\"\n\nP2027​\n\n\"Multiple errors occurred on the database during query execution: {errors}\"\n\nP2028​\n\n\"Transaction API error: {error}\"\n\nP2029​\n\n\"Query parameter limit exceeded error: {message}\"\n\nP2030​\n\n\"Cannot find a fulltext index to use for the search, try adding a @@fulltext([Fields...]) to your schema\"\n\nP2031​\n\n\"Prisma needs to perform transactions, which requires your MongoDB server to be run as a replica set. See details: https://pris.ly/d/mongodb-replica-set\n\"\n\nP2033​\n\n\"A number used in the query does not fit into a 64 bit signed integer. Consider using BigInt as field type if you're trying to store large integers\"\n\nP2034​\n\n\"Transaction failed due to a write conflict or a deadlock. Please retry your transaction\"\n\nP2035​\n\n\"Assertion violation on the database: {database_error}\"\n\nP2036​\n\n\"Error in external connector (id {id})\"\n\nP2037​\n\n\"Too many database connections opened: {message}\"\n\nPrisma Migrate (Schema Engine)​\nWARNING\n\nThe Schema Engine was previously called Migration Engine. This change was introduced in version 5.0.0\n.\n\nP3000​\n\n\"Failed to create database: {database_error}\"\n\nP3001​\n\n\"Migration possible with destructive changes and possible data loss: {migration_engine_destructive_details}\"\n\nP3002​\n\n\"The attempted migration was rolled back: {database_error}\"\n\nP3003​\n\n\"The format of migrations changed, the saved migrations are no longer valid. To solve this problem, please follow the steps at: https://pris.ly/d/migrate\n\"\n\nP3004​\n\n\"The {database_name} database is a system database, it should not be altered with prisma migrate. Please connect to another database.\"\n\nP3005​\n\n\"The database schema is not empty. Read more about how to baseline an existing production database: https://pris.ly/d/migrate-baseline\n\"\n\nP3006​\n\n\"Migration {migration_name} failed to apply cleanly to the shadow database.\n{error_code}Error:\n{inner_error}\"\n\nP3007​\n\n\"Some of the requested preview features are not yet allowed in schema engine. Please remove them from your data model before using migrations. (blocked: {list_of_blocked_features})\"\n\nP3008​\n\n\"The migration {migration_name} is already recorded as applied in the database.\"\n\nP3009​\n\n\"migrate found failed migrations in the target database, new migrations will not be applied. Read more about how to resolve migration issues in a production database: https://pris.ly/d/migrate-resolve\n\n{details}\"\n\nP3010​\n\n\"The name of the migration is too long. It must not be longer than 200 characters (bytes).\"\n\nP3011​\n\n\"Migration {migration_name} cannot be rolled back because it was never applied to the database. Hint: did you pass in the whole migration name? (example: \"20201207184859_initial_migration\")\"\n\nP3012​\n\n\"Migration {migration_name} cannot be rolled back because it is not in a failed state.\"\n\nP3013​\n\n\"Datasource provider arrays are no longer supported in migrate. Please change your datasource to use a single provider. Read more at https://pris.ly/multi-provider-deprecation\n\"\n\nP3014​\n\n\"Prisma Migrate could not create the shadow database. Please make sure the database user has permission to create databases. Read more about the shadow database (and workarounds) at https://pris.ly/d/migrate-shadow\n.\n\nOriginal error: {error_code}\n{inner_error}\"\n\nP3015​\n\n\"Could not find the migration file at {migration_file_path}. Please delete the directory or restore the migration file.\"\n\nP3016​\n\n\"The fallback method for database resets failed, meaning Migrate could not clean up the database entirely. Original error: {error_code}\n{inner_error}\"\n\nP3017​\n\n\"The migration {migration_name} could not be found. Please make sure that the migration exists, and that you included the whole name of the directory. (example: \"20201207184859_initial_migration\")\"\n\nP3018​\n\n\"A migration failed to apply. New migrations cannot be applied before the error is recovered from. Read more about how to resolve migration issues in a production database: https://pris.ly/d/migrate-resolve\n\n\nMigration name: {migration_name}\n\nDatabase error code: {database_error_code}\n\nDatabase error:\n{database_error} \"\n\nP3019​\n\n\"The datasource provider {provider} specified in your schema does not match the one specified in the migration_lock.toml, {expected_provider}. Please remove your current migration directory and start a new migration history with prisma migrate dev. Read more: https://pris.ly/d/migrate-provider-switch\n\"\n\nP3020​\n\n\"The automatic creation of shadow databases is disabled on Azure SQL. Please set up a shadow database using the shadowDatabaseUrl datasource attribute.\nRead the docs page for more details: https://pris.ly/d/migrate-shadow\n\"\n\nP3021​\n\n\"Foreign keys cannot be created on this database. Learn more how to handle this: https://pris.ly/d/migrate-no-foreign-keys\n\"\n\nP3022​\n\n\"Direct execution of DDL (Data Definition Language) SQL statements is disabled on this database. Please read more here about how to handle this: https://pris.ly/d/migrate-no-direct-ddl\n\"\n\nP3023​\n\n\"For the current database, externalTables & externalEnums in your prisma config must contain only fully qualified identifiers (e.g. schema_name.table_name).\"\n\nP3024​\n\n\"For the current database, externalTables & externalEnums in your prisma config must contain only simple identifiers without a schema name.\"\n\nprisma db pull​\nP4000​\n\n\"Introspection operation failed to produce a schema file: {introspection_error}\"\n\nP4001​\n\n\"The introspected database was empty.\"\n\nP4002​\n\n\"The schema of the introspected database was inconsistent: {explanation}\"\n\nPrisma Accelerate​\n\nPrisma Accelerate-related errors start with P6xxx except for P5011.\n\nP6000 (ServerError)​\n\nGeneric error to catch all other errors.\n\nP6001 (InvalidDataSource)​\n\nThe URL is malformed; for instance, it does not use the prisma:// protocol.\n\nP6002 (Unauthorized)​\n\nThe API Key in the connection string is invalid.\n\nP6003 (PlanLimitReached)​\n\nThe included usage of the current plan has been exceeded. This can only occur on the free plan.\n\nP6004 (QueryTimeout)​\n\nThe global timeout of Accelerate has been exceeded. You can find the limit here.\n\nAlso see the troubleshooting guide for more information.\n\nP6005 (InvalidParameters)​\n\nThe user supplied invalid parameters. Currently only relevant for transaction methods. For example, setting a timeout that is too high. You can find the limit here.\n\nP6006 (VersionNotSupported)​\n\nThe chosen Prisma version is not compatible with Accelerate. This may occur when a user uses an unstable development version that we occasionally prune.\n\nP6008 (ConnectionError|EngineStartError)​\n\nThe engine failed to start. For example, it couldn't establish a connection to the database.\n\nAlso see the troubleshooting guide for more information.\n\nP6009 (ResponseSizeLimitExceeded)​\n\nThe global response size limit of Accelerate has been exceeded. You can find the limit here.\n\nAlso see the troubleshooting guide for more information.\n\nP6010 (ProjectDisabledError)​\n\nYour accelerate project is disabled. Please enable it again to use it.\n\nP5011 (Too Many Requests)​\n\nThis error indicates that the request volume exceeded. Implement a back-off strategy and try again later. For assistance with expected high workloads, contact support."
  },
  {
    "title": "Prisma environment variables | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/environment-variables-reference",
    "html": "ORMReference\nEnvironment variables reference\n\nThis document describes different environment variables and their use cases.\n\nPrisma Client​\nDEBUG​\n\nDEBUG is used to enable debugging output in Prisma Client.\n\nExample setting Prisma Client level debugging output:\n\n# enable only `prisma:client`-level debugging output\n\nexport DEBUG=\"prisma:client\"\n\n\nSee Debugging for more information.\n\nNO_COLOR​\n\nNO_COLOR if truthy\n will activate the colorless setting for error formatting and strip colors from error messages.\n\nSee Formatting via environment variables for more information.\n\nPrisma Studio​\nBROWSER​\n\nBROWSER is for Prisma Studio to force which browser it should be open in, if not set it will open in the default browser.\n\nBROWSER=firefox prisma studio --port 5555\n\n\nAlternatively you can set this when starting Studio from the CLI as well:\n\nprisma studio --browser firefox\n\n\nSee Studio documentation for more information.\n\nPrisma CLI​\nPRISMA_HIDE_PREVIEW_FLAG_WARNINGS​\n\nPRISMA_HIDE_PREVIEW_FLAG_WARNINGS hides the warning message that states that a preview feature flag can be removed. It is a truthy value.\n\nPRISMA_HIDE_UPDATE_MESSAGE​\n\nPRISMA_HIDE_UPDATE_MESSAGE is used to hide the update notification message that is shown when a newer Prisma CLI version is available. It's a truthy value.\n\nPRISMA_GENERATE_SKIP_AUTOINSTALL​\n\nPRISMA_GENERATE_SKIP_AUTOINSTALL can be set to a truthy value to skip the auto-install of prisma CLI and @prisma/client dependencies (if they are missing), if the prisma-client-js generator is defined in the Prisma Schema, when using the prisma generate command.\n\nPRISMA_SKIP_POSTINSTALL_GENERATE​\n\nPRISMA_SKIP_POSTINSTALL_GENERATE can be set to a truthy value to skip the auto-generation of Prisma Client when its postinstall hook is triggered by a package manager. The postinstall hook of the @prisma/client package is triggered when the package is installed, or its version is updated.\n\nPRISMA_DISABLE_WARNINGS​\n\nDisables all CLI warnings generated by logger.warn.\n\nPRISMA_GENERATE_NO_ENGINE​\nINFO\n\nThis environment variable is available since version 5.2.0\n\nPRISMA_GENERATE_NO_ENGINE can be set to a truthy value to generate a Prisma Client without an included query engine in order to reduce deployed application size when paired with Prisma Accelerate.\n\nPRISMA_SCHEMA_DISABLE_ADVISORY_LOCK​\nINFO\n\nThis environment variable is available since version 5.3.0\n\nPRISMA_SCHEMA_DISABLE_ADVISORY_LOCK can be set to a truthy value to disable the advisory locking used by Prisma Migrate. This might be needed, depending on the database configuration, for example, for a Percona-XtraDB-Cluster or MariaDB Galera Cluster.\n\nProxy environment variables​\n\nThe Prisma CLI supports custom HTTP(S) proxies to download the Prisma engines. These can be helpful to use when working behind a corporate firewall. See Using a HTTP proxy for the CLI for more information.\n\nNO_PROXY​\n\nNO_PROXY is a comma-separated list of hostnames or IP addresses that do not require a proxy.\n\nNO_PROXY=myhostname.com,10.11.12.0/16,172.30.0.0/16\n\nHTTP_PROXY​\n\nHTTP_PROXY is set with the hostname or IP address of a proxy server.\n\nHTTP_PROXY=http://proxy.example.com\n\nHTTPS_PROXY​\n\nHTTPS_PROXY is set with the hostname or IP address of a proxy server.\n\nHTTPS_PROXY=https://proxy.example.com\n\nEngine environment variables​\nConfiguring Query Engine Type​\nPRISMA_CLI_QUERY_ENGINE_TYPE​\n\nPRISMA_CLI_QUERY_ENGINE_TYPE is used to define the query engine type Prisma CLI downloads and uses. Defaults to library, but can be set to binary:\n\nPRISMA_CLI_QUERY_ENGINE_TYPE=binary\n\nPRISMA_CLIENT_ENGINE_TYPE​\n\nPRISMA_CLIENT_ENGINE_TYPE is used to define the query engine type Prisma Client downloads and uses. Defaults to library, but can be set to binary:\n\nPRISMA_CLIENT_ENGINE_TYPE=binary\n\n\nNote: You need to generate your Prisma Client after setting this variable for the configuration to take effect and the libraries to be downloaded. Otherwise, Prisma Client will be missing the appropriate query engine library and you will have to define their location using PRISMA_QUERY_ENGINE_LIBRARY.\n\nIt is the environment variable equivalent for the engineType property of the generator block which enables you to define the same setting in your Prisma Schema.\n\nDownloading Engines​\nPRISMA_ENGINES_MIRROR​\n\nPRISMA_ENGINES_MIRROR can be used to specify a custom CDN (or server) endpoint to download the engines files for the CLI/Client. The default value is https://binaries.prisma.sh, where Prisma hosts the engine files.\n\nPRISMA_ENGINES_MIRROR=https://example.org/custom-engines/\n\n\nSee Prisma engines for a conceptual overview of how to use this environment variable.\n\nNote: This environment variable used to be available as PRISMA_BINARIES_MIRROR, which was deprecated in Prisma ORM 3.0.1. It is discouraged to use anymore and will be removed in the future.\n\nPRISMA_ENGINES_CHECKSUM_IGNORE_MISSING​\nINFO\n\nThis environment variable is available since version 4.16.0\n\nPRISMA_ENGINES_CHECKSUM_IGNORE_MISSING can be can be set to a truthy value to ignore problems around downloading & verifying the integrity (via a checksum file) of the Prisma ORM engines. This is particularly useful when deploying to an offline system environment where the checksum file cannot be downloaded.\n\nPRISMA_ENGINES_CHECKSUM_IGNORE_MISSING=1\n\n\nNote: we might change the overall download behavior in a future release in a way that this environment variable will not be needed anymore in a offline environment case.\n\nCustom engine file locations​\n\nBy default, all engine files are downloaded when you install Prisma CLI, copied when generating Prisma Client, and put into known locations. There are however situations where you may want to use a custom engine file from custom locations:\n\nPRISMA_QUERY_ENGINE_BINARY​\n\nPRISMA_QUERY_ENGINE_BINARY is used to set a custom location for your own query engine binary.\n\nPRISMA_QUERY_ENGINE_BINARY=custom/query-engine-<target>\n\n# Example: ./prisma/binaries/query-engine-linux-arm64-openssl-1.0.x\n\n\nFor Prisma CLI it allows you to define the query engine file to be used.\nFor Prisma Client, on build time (during prisma generate), it defines where the query engine file will be copied from into Prisma Client. At run time (when using the generated Client) it can be used to define the specific query engine file to be used instead of the included one.\n\nNote: This can only have an effect if the engine type of CLI or Client are set to binary. If the engine type is library (the default), use PRISMA_QUERY_ENGINE_LIBARY instead.\n\nPRISMA_QUERY_ENGINE_LIBRARY​\n\nPRISMA_QUERY_ENGINE_LIBRARY is used to set a custom location for your own query engine library.\n\nPRISMA_QUERY_ENGINE_LIBRARY=custom/libquery_engine-<target>.so.node\n\n# Example: ./prisma/binaries/libquery_engine-linux-arm64-openssl-1.0.x.so.node\n\n\nFor Prisma CLI it allows you to define the query engine file to be used.\nFor Prisma Client, on build time (during prisma generate), it defines where the query engine file will be copied from into Prisma Client. At run time (when using the generated Client) it can be used to define the specific query engine file to be used instead of the included one.\n\nNote: This can only have an effect if the engine type of CLI or Client are set to library (the default)\n\nPRISMA_SCHEMA_ENGINE_BINARY​\n\nPRISMA_SCHEMA_ENGINE_BINARY is used to set a custom location for your Schema engine binary.\n\nPRISMA_SCHEMA_ENGINE_BINARY=custom/my-schema-engine-unix\n\nPRISMA_MIGRATION_ENGINE_BINARY​\nWARNING\n\nDeprecated: PRISMA_MIGRATION_ENGINE_BINARY variable is deprecated in 5.0.0\n because Migration engine was renamed to Schema Engine.\n\nPRISMA_MIGRATION_ENGINE_BINARY is used to set a custom location for your own migration engine binary.\n\nPRISMA_MIGRATION_ENGINE_BINARY=custom/my-migration-engine-unix\n\nPRISMA_INTROSPECTION_ENGINE_BINARY​\n\nPRISMA_INTROSPECTION_ENGINE_BINARY is used to set a custom location for your own introspection engine binary.\n\nPRISMA_INTROSPECTION_ENGINE_BINARY=custom/my-introspection-engine-unix\n\nWARNING\n\nThe Introspection Engine is served by the Migration Engine from 4.9.0\n. Therefore, the PRISMA_INTROSPECTION_ENGINE environment variable will not be used.\n\nPRISMA_FMT_BINARY​\nDANGER\n\nThis functionality has been removed in Prisma CLI version 4.10.0. It only works in earlier versions.\n\nPRISMA_FMT_BINARY is used to set a custom location for your own format engine binary.\n\nPRISMA_FMT_BINARY=custom/my-custom-format-engine-unix\n\nWARNING\n\nThe PRISMA_FMT_BINARY variable is used in versions 4.2.0\n or lower.\n\nCLI Binary Targets​\nPRISMA_CLI_BINARY_TARGETS​\n\nPRISMA_CLI_BINARY_TARGETS can be used to specify one or more binary targets that Prisma CLI will download during installation (so it must be provided during npm install of Prisma CLI and does not affect runtime of Prisma CLI or Prisma Client).\n\nUse PRISMA_CLI_BINARY_TARGETS if you 1) deploy to a specific platform via an upload of a local project that includes dependencies, and 2) your local environment is different from the target (e.g. AWS Lambda with Node.js 20+ is rhel-openssl-3.0.x, and your local environment might be macOS arm64 darwin-arm64). Using the PRISMA_CLI_BINARY_TARGETS environment variable ensures that the target engine files are also downloaded.\n\nPRISMA_CLI_BINARY_TARGETS=darwin-arm64,rhel-openssl-3.0.x npm install\n\n\nThis is the Prisma CLI equivalent for the binaryTargets property of the generator block, which enables you to define the same setting for Prisma Client.\n\nNote: For Node.js versions earlier than 20, the openssl version was 1.0.x instead of 3.0.x. This is most obvious in AWS Lambda deployments, where the binary target would be rhel-openssl-1.0.x instead of rhel-openssl-3.0.x."
  },
  {
    "title": "Reference documentation for the prisma config file | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/prisma-config-reference",
    "html": "ORMReference\nPrisma Config reference\nOverview​\n\nThe Prisma Config file configures the Prisma CLI, including subcommands like migrate and studio, using TypeScript.\n\nYou can define your config in either of two ways:\n\nUsing the defineConfig helper:\n\nimport path from \"node:path\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n  migrations: { \n\n    path: path.join(\"db\", \"migrations\"),\n\n  },\n\n  views: { \n\n    path: path.join(\"db\", \"views\"),\n\n  },\n\n  typedSql: { \n\n  path: path.join(\"db\", \"queries\"),\n\n  },\n\n  engine: \"classic\",\n\n  datasource: { \n\n    url: env(\"DATABASE_URL\") \n\n  }\n\n});\n\n\nUsing TypeScript's satisfies operator with the PrismaConfig type:\n\nimport path from \"node:path\";\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {\n\n  schema: path.join(\"db\", \"schema.prisma\"),\n\n  migrations: {\n\n    path: path.join(\"db\", \"migrations\"),\n\n  },\n\n  views: {\n\n    path: path.join(\"db\", \"views\"),\n\n  },\n\n  typedSql: {\n\n    path: path.join(\"db\", \"queries\"),\n\n  },\n\n  engine: \"classic\",\n\n  datasource: { \n\n    url: env(\"DATABASE_URL\") \n\n  }\n\n} satisfies PrismaConfig;\n\nConfiguration interface​\n\nHere is a simplified version of the PrismaConfig type:\n\nexport declare type PrismaConfig = {\n\n\n\n  // Whether features with an unstable API are enabled.\n\n  experimental: {\n\n    adapter: boolean;\n\n    externalTables: boolean;\n\n    studio: boolean;\n\n  },\n\n\n\n  // The path to the schema file, or path to a folder that shall be recursively searched for *.prisma files.\n\n  schema?: string;\n\n\n\n  // The Driver Adapter used for Prisma CLI.\n\n  adapter?: () => Promise<SqlMigrationAwareDriverAdapterFactory>;\n\n\n\n  // Configuration for Prisma Studio.\n\n  studio?: {\n\n    adapter: () => Promise<SqlMigrationAwareDriverAdapterFactory>;\n\n  };\n\n\n\n  // Configuration for Prisma migrations.\n\n  migrations?: {\n\n    path: string;\n\n    seed: string;\n\n    initShadowDb: string;\n\n  };\n\n\n\n  // Configuration for the database view entities.\n\n  views?: {\n\n    path: string;\n\n  };\n\n\n\n  // Configuration for the `typedSql` preview feature.\n\n  typedSql?: {\n\n    path: string;\n\n  };\n\n  // Depending on the choice, you must provide either a `datasource` object or driver adapter\n\n  engine: 'classic' | 'js'\n\n  \n\n  // If using the classic engine, datasource sets the database url, shadowDatabaseUrl, or directURL\n\n  datasource?: {\n\n    url: string;\n\n    directUrl?: string;\n\n    shadowDatabaseUrl?: string;\n\n  }\n\n  \n\n};\n\nSupported file extensions​\n\nPrisma Config files can be named as prisma.config.* or .config/prisma.* with the extensions js, ts, mjs, cjs, mts, or cts. Other extensions are supported to ensure compatibility with different TypeScript compiler settings.\n\nRECOMMENDATION\nUse prisma.config.ts for small TypeScript projects.\nUse .config/prisma.ts for larger TypeScript projects with multiple configuration files (following the \n.config\ndirectory proposal\n).\nOptions reference​\nschema​\n\nConfigures how Prisma ORM locates and loads your schema file(s). Can be a file or folder path. Relative paths are resolved relative to the prisma.config.ts file location. See here for more info about schema location options.\n\nProperty\tType\tRequired\tDefault\nschema\tstring\tNo\t./prisma/schema.prisma and ./schema.prisma\nadapter​\n\nA function that returns a Prisma driver adapter instance which is used by the Prisma CLI to run migrations. The function should return a Promise that resolves to a valid Prisma driver adapter.\n\nProperty\tType\tRequired\tDefault\nadapter\t() => Promise<SqlMigrationAwareDriverAdapterFactory>\tNo\tnone\n\nExample using the Prisma ORM D1 driver adapter:\n\nimport path from \"node:path\";\n\nimport type { PrismaConfig } from \"prisma\";\n\nimport { PrismaD1 } from \"@prisma/adapter-d1\";\n\n\n\nexport default {\n\n  experimental: {\n\n    adapter: true\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n  async adapter() {\n\n    return new PrismaD1({\n\n      CLOUDFLARE_D1_TOKEN: process.env.CLOUDFLARE_D1_TOKEN,\n\n      CLOUDFLARE_ACCOUNT_ID: process.env.CLOUDFLARE_ACCOUNT_ID,\n\n      CLOUDFLARE_DATABASE_ID: process.env.CLOUDFLARE_DATABASE_ID,\n\n    });\n\n  },\n\n} satisfies PrismaConfig;\n\nNOTE\n\nAs of Prisma ORM v6.11.0\n, the D1 adapter has been renamed from PrismaD1HTTP to PrismaD1.\n\nstudio​\n\nConfigures how Prisma Studio connects to your database. See sub-options below for details.\n\nProperty\tType\tRequired\tDefault\nstudio\tobject\tNo\tnone\nstudio.adapter​\n\nA function that returns a Prisma driver adapter instance. The function receives an env parameter containing environment variables and should return a Promise that resolves to a valid Prisma driver adapter.\n\nProperty\tType\tRequired\tDefault\nstudio.adapter\t(env: Env) => Promise<SqlMigrationAwareDriverAdapterFactory>\tNo\tnone\n\nExample using the Prisma ORM LibSQL driver adapter:\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {\n\n  experimental: {\n\n    studio: true\n\n  },\n\n  studio: {\n\n    adapter: async (env: Env) => {\n\n      const { PrismaLibSQL } = await import(\"@prisma/adapter-libsql\");\n\n      const { createClient } = await import(\"@libsql/client\");\n\n\n\n      const libsql = createClient({\n\n        url: env.DOTENV_PRISMA_STUDIO_LIBSQL_DATABASE_URL,\n\n      });\n\n      return new PrismaLibSQL(libsql);\n\n    },\n\n  },\n\n} satisfies PrismaConfig;\n\ntables.external and enums.external​\n\nThese options declare tables and enums in your database that are managed externally (not by Prisma Migrate). You can still query them with Prisma Client, but they will be ignored by migrations.\n\nProperty\tType\tRequired\tDefault\ntables.external\tstring[]\tNo\t[]\nenums.external\tstring[]\tNo\t[]\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  experimental: {\n\n    externalTables: true,\n\n  },\n\n  tables: {\n\n    external: [\"public.users\"],\n\n  },\n\n  enums: {\n\n    external: [\"public.role\"],\n\n  },\n\n});\n\n\nLearn more about the externalTables feature here.\n\nmigrations.path​\n\nThe path to the directory where Prisma should store migration files, and look for them.\n\nProperty\tType\tRequired\tDefault\nmigrations.path\tstring\tNo\tnone\nmigrations.seed​\n\nThis option allows you to define a script that Prisma runs to seed your database after running migrations or using the npx prisma db seed command. The string should be a command that can be executed in your terminal, such as with node, ts-node, or tsx.\n\nProperty\tType\tRequired\tDefault\nmigrations.seed\tstring\tNo\tnone\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  migrations: {\n\n    seed: `tsx db/seed.ts`,\n\n  },\n\n});\n\nmigrations.initShadowDb​\n\nThis option allows you to define SQL statements that Prisma runs on the shadow database before creating migrations. It is useful when working with external managed tables, as Prisma needs to know about the structure of these tables to correctly generate migrations.\n\nProperty\tType\tRequired\tDefault\nmigrations.initShadowDb\tstring\tNo\tnone\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  experimental: {\n\n    externalTables: true,\n\n  },\n\n  tables: {\n\n    external: [\"public.users\"],\n\n  },\n\n  migrations: {\n\n    initShadowDb: `\n\n      CREATE TABLE public.users (id SERIAL PRIMARY KEY);\n\n    `,\n\n  },\n\n});\n\n\nLearn more about the externalTables feature here.\n\nviews.path​\n\nThe path to the directory where Prisma should look for the SQL view definitions.\n\nProperty\tType\tRequired\tDefault\nviews.path\tstring\tNo\tnone\ntypedSql.path​\n\nThe path to the directory where Prisma should look for the SQL files used for generating typings via typedSql.\n\nProperty\tType\tRequired\tDefault\ntypedSql.path\tstring\tNo\tnone\nexperimental​\n\nEnables specific experimental features in the Prisma CLI.\n\nProperty\tType\tRequired\tDefault\nadapter\tboolean\tNo\tfalse\nexternalTables\tboolean\tNo\tfalse\nstudio\tboolean\tNo\tfalse\n\nExample:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({\n\n  experimental: {\n\n    adapter: true,\n\n    externalTables: true,\n\n    studio: true,\n\n  },\n\n  schema: \"prisma/schema.prisma\",\n\n});\n\nNOTE\n\nIf you use features like adapter, studio or externalTables without enabling the corresponding experimental flag, Prisma will throw an error:\n\nFailed to load config file \"~\" as a TypeScript/JavaScript module. Error: Error: The `studio` configuration requires `experimental.studio` to be set to `true`.\n\nengine​\n\nConfigure the schema engine your project should use.\n\nProperty\tType\tRequired\tDefault\nengine\tclassic or js\tNo\tclassic\n\nBy default it is set to use the classic engine, which requires that datasource be set in your prisma.config.ts.\n\nimport path from \"node:path\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\nexport default defineConfig({\n\n  engine: \"classic\",\n\n  datasource: {\n\n      url: env('DATABASE_URL'),\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n});\n\ndatasource.url​\n\nConnection URL including authentication info. Most connectors use the syntax provided by the database.\n\nProperty\tType\tRequired\tDefault\ndatasource.url\tstring\tYes\t''\ndatasource.shadowDatabaseUrl​\n\nConnection URL to the shadow database used by Prisma Migrate. Allows you to use a cloud-hosted database as the shadow database\n\nProperty\tType\tRequired\tDefault\ndatasource.shadowDatabaseUrl\tstring\tNo\t''\ndatasource.directUrl​\n\nConnection URL for direct connection to the database.\n\nIf you use a connection pooler URL in the url argument (for example, if you use Prisma Accelerate or pgBouncer), Prisma CLI commands that require a direct connection to the database use the URL in the directUrl argument.\n\nThe directUrl property is supported by Prisma Studio from version 5.1.0 upwards.\n\nThe directUrl property is not needed when using Prisma Postgres database.\n\nProperty\tType\tRequired\tDefault\ndatasource.directUrl\tstring\tNo\t''\nCommon patterns​\nSetting up your project​\n\nTo get started with Prisma Config, create a prisma.config.ts file in your project root. You can use either of these approaches:\n\nUsing defineConfig:\n\nimport { defineConfig } from \"prisma/config\";\n\n\n\nexport default defineConfig({});\n\n\nUsing TypeScript types:\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {} satisfies PrismaConfig;\n\nUsing environment variables​\n\nWhen using prisma.config.ts, environment variables from .env files are not automatically loaded. Using tsx, you can pass a --env-file flag and that will automatically add those values to process.env\n\nIf using Node or Deno:\n\ntsx --env-file=.env src/index.ts\n\ntsx watch --env-file=.env --env-file=.local.env src/index.ts\n\ntsx --env-file=.env ./prisma/seed.ts\n\n\nFor Bun, .env files are automatically loaded.\n\nFor accessing environment variables within prisma.config.ts, use the env() helper function to provide a type-safe way of accessing that variable:\n\nimport path from \"node:path\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\n\n\ntype Env = {\n\n  DATABASE_URL: string\n\n}\n\nexport default defineConfig({\n\n  engine: \"classic\",\n\n  datasource: {\n\n      url: env<Env>('DATABASE_URL'),\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n});\n\n\nFor releases of Node before v20, you'll need to:\n\nInstall the dotenv package:\nnpm install dotenv\n\nImport dotenv/config in your config file:\nimport \"dotenv/config\";\n\nimport { defineConfig, env } from \"prisma/config\";\n\n\n\ntype Env = {\n\n  DATABASE_URL: string\n\n}\n\nexport default defineConfig({\n\n  engine: \"classic\",\n\n  datasource: {\n\n      url: env<Env>('DATABASE_URL'),\n\n  },\n\n  schema: path.join(\"prisma\", \"schema.prisma\"),\n\n});\n\nUsing multi-file schemas​\n\nIf you want to split your Prisma schema into multiple files, you need to specify the path to your Prisma schema folder via the schema property:\n\nimport path from \"node:path\";\n\nimport type { PrismaConfig } from \"prisma\";\n\n\n\nexport default {\n\n  schema: path.join(\"prisma\", \"schema\"),\n\n} satisfies PrismaConfig;\n\n\nIn that case, your migrations directory must be located next to the .prisma file that defines the datasource block.\n\nFor example, assuming schema.prisma defines the datasource, here's how how need to place the migrations folder:\n\n# `migrations` and `schema.prisma` are on the same level\n\n.\n\n├── migrations\n\n├── models\n\n│   ├── posts.prisma\n\n│   └── users.prisma\n\n└── schema.prisma\n\nPath resolution​\n\nPrisma CLI commands such as prisma validate or prisma migrate use prisma.config.ts (or .config/prisma.ts) to locate your Prisma schema and other resources.\n\nKey rules:\n\nPaths defined in the config file (e.g., schema, migrations) are always resolved relative to the location of the config file, not where you run the CLI command from.\nThe CLI must first find the config file itself, which depends on how Prisma is installed and the package manager used.\nBehavior with pnpm prisma​\n\nWhen Prisma is installed locally and run via pnpm prisma, the config file is detected automatically whether you run the command from the project root or a subdirectory.\n\nExample project tree:\n\n.\n\n├── node_modules\n\n├── package.json\n\n├── prisma-custom\n\n│   └── schema.prisma\n\n├── prisma.config.ts\n\n└── src\n\n\nExample run from the project root:\n\npnpm prisma validate\n\n# → Loaded Prisma config from ./prisma.config.ts\n\n# → Prisma schema loaded from prisma-custom/schema.prisma\n\n\nExample run from a subdirectory:\n\ncd src\n\npnpm prisma validate\n\n# → Still finds prisma.config.ts and resolves schema correctly\n\nBehavior with npm exec prisma or bun prisma​\n\nWhen running via npm exec prisma or bun prisma, the CLI only detects the config file if the command is run from the project root (where package.json declares Prisma).\n\nExample run from the project root:\n\nnpm exec prisma validate\n\n# → Works as expected\n\n\nRun from a subdirectory (fails):\n\ncd src\n\nnpm exec prisma validate\n\n# → Error: Could not find Prisma Schema...\n\n\nTo fix this, you can use the --config flag:\n\nnpm exec prisma -- --config ../prisma.config.ts validate\n\nGlobal Prisma installations​\n\nIf Prisma is installed globally (npm i -g prisma), it may not find your prisma.config.ts or prisma/config module by default. To avoid issues:\n\nPrefer local Prisma installations in your project.\nOr use prisma/config locally and pass --config to point to your config file.\nMonorepos​\nIf Prisma is installed in the workspace root, pnpm prisma will detect the config file from subdirectories.\nIf Prisma is installed in a subpackage (e.g., ./packages/db), run commands from that package directory or deeper.\nCustom config location​\n\nYou can specify a custom location for your config file when running Prisma CLI commands:\n\nprisma validate --config ./path/to/myconfig.ts\n"
  },
  {
    "title": "Database features matrix | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/database-features",
    "html": "ORMReference\nDatabase features matrix\n\nThis page gives an overview of the features which are provided by the databases that Prisma ORM supports. Additionally, it explains how each of these features can be used in Prisma ORM with pointers to further documentation.\n\nRelational database features​\n\nThis section describes which database features exist on the relational databases that are currently supported by Prisma ORM. The Prisma schema column indicates how a certain feature can be represented in the Prisma schema and links to its documentation. Note that database features can be used in Prisma Client even though they might not yet be representable in the Prisma schema.\n\nNOTE\n\nThese features are only for relational databases. Supported features for NoSQL databases, like MongoDB, can be found below.\n\nConstraints​\nConstraint\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nPRIMARY KEY\t✔️\t@id and @@id\t✔️\t✔️\nFOREIGN KEY\t✔️\tRelation fields\t✔️\t✔️\nUNIQUE\t✔️*\t@unique and @@unique\t✔️\t✔️\nCHECK\t✔️†\tNot yet\t✔️\tNot yet\nNOT NULL\t✔️\t?\t✔️\t✔️\nDEFAULT\t✔️\t@default\t✔️\t✔️\nEXCLUDE\t✔️‡\tNot yet\t✔️\tNot yet\n\n* Caveats apply when using the UNIQUE constraint with Microsoft SQL Server † Only supported in MySQL in version 8 and higher\n. ‡ Only supported in PostgreSQL.\n\nReferential Actions (Delete and Update behaviors for foreign key references)​\nDeletion behavior\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nCASCADE\t✔️\t✔️\t✔️\t✔️\nRESTRICT\t✔️*\t✔️\t✔️\t✔️\nNO ACTION\t✔️\t✔️\t✔️\t✔️\nSET DEFAULT\t✔️\t✔️\t✔️\t✔️\nSET NULL\t✔️\t✔️\t✔️\t✔️\n\n* RESTRICT is not supported in Microsoft SQL Server.\n\nIndexes​\nIndex\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nUNIQUE\t✔️\t@unique and @@unique\t✔️\t✔️\nUSING\tPostgreSQL only\ttype\t✔️\t✔️\nWHERE\t✔️\tNot yet\t✔️\tNot yet\n(expression)\t✔️\tNot yet\t✔️\tNot yet\nINCLUDE\tPostgreSQL and Microsoft SQL Server only\tNot yet\t✔️\tNot yet\n\nAlgorithm specified via USING:\n\nIndex type (Algorithm)\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nB-tree\t✔️\t✔️†\t✔️\tNot yet\nHash\t✔️\t✔️†\t✔️\tNot yet\nGiST\t✔️*\t✔️†\t✔️*\tNot yet\nGIN\t✔️*\t✔️†\t✔️*\tNot yet\nBRIN\t✔️*\t✔️†\t✔️*\tNot yet\nSP-GiST\t✔️*\t✔️†\t✔️*\tNot yet\n* Not supported for MySQL and SQLite\n† Available with the PostgreSQL connector only in Prisma ORM versions 4.0.0 and later.\nMisc​\nFeature\tSupported\tPrisma schema\tPrisma Client\tPrisma Migrate\nAutoincrementing IDs\t✔️\tautoincrement()\t✔️\t✔️\nArrays\tPostgreSQL only\t[]\t✔️\t✔️\nEnums\t✔️*†\tenum\t✔️\t✔️\nNative database types\t✔️\t✔️\t✔️\tNot yet\nSQL Views\t✔️\tNot yet\tNot yet\tNot yet\nJSON support\t✔️†\t✔️\t✔️\t✔️\nFuzzy/Phrase full text search\t✔️‡\tNot yet\tNot yet\tNot yet\nTable inheritance\tPostgreSQL and Microsoft SQL Server only\tNot yet\t✔️\tNot yet\nAuthorization and user management\t✔️‡\tNot yet\tNot yet\tNot yet\n* Not supported by Microsoft SQL Server\n† JSON and Enum types are supported in SQLite as of Prisma ORM 6.2.0.\n‡ Not supported by SQLite\nNoSQL database features​\n\nThis section describes which database features exist on the NoSQL databases that are currently supported by Prisma ORM.\n\nMongoDB​\n\nThe following table lists common MongoDB features and describes the level of support offered by Prisma ORM:\n\nFeature\tSupported by Prisma ORM\tNotes\nEmbedded documents\t✔️\t\nTransactions\t✔️\t\nIndexes\t✔️ with caveats\tIndexes can only be introspected if the field they refer to includes at least some data.\nAutoincrementing IDs\tNo\t\nCompound IDs\tNo\tMongoDB does not support composite IDs (@@id)\nGenerated ObjectId\t✔️\tSee: Defining IDs for MongoDB\nArrays\t✔️\t\nEnums\t✔️\tImplemented at Prisma ORM level\nNative database types\t✔️\tSee: Field mapping reference\nJSON support\t✔️\tAdvanced Json field filtering is not yet supported.\nDBrefs\tNo\t\nChange streams\tNo\t\nDirect access to the aggregation pipeline\tNo\t"
  },
  {
    "title": "Databases supported by Prisma ORM | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/supported-databases",
    "html": "ORMReference\nSupported databases\n\nPrisma ORM currently supports the following databases.\n\nSee also: System requirements.\n\nAn asterisk (*) indicates that the version number is not relevant; either all versions are supported, there is not a public version number, etc.\n\nSelf-hosted databases​\nDatabase\tVersion\nCockroachDB\t21.2.4+\nMariaDB\t10.0+\nMariaDB\t11.0+\nMicrosoft SQL Server\t2017\nMicrosoft SQL Server\t2019\nMicrosoft SQL Server\t2022\nMongoDB\t4.2+\nMySQL\t5.6\nMySQL\t5.7\nMySQL\t8.0\nMySQL\t8.4\nPostgreSQL\t9.6\nPostgreSQL\t10\nPostgreSQL\t11\nPostgreSQL\t12\nPostgreSQL\t13\nPostgreSQL\t14\nPostgreSQL\t15\nPostgreSQL\t16\nPostgreSQL\t17\nSQLite\t*\n\nNote that a fixed version of SQLite is shipped with every Prisma ORM release.\n\nManaged databases​\nDatabase\tVersion\nAWS Aurora\t*\nAWS Aurora Serverless ¹\t*\nAzure SQL\t*\nCockroachDB-as-a-Service\t*\nMongoDB Atlas\t*\nNeon Serverless Postgres\t*\nPlanetScale\t*\nCloudflare D1 (Preview)\t*\nAiven (MySQL & Postgres)\t*\n¹ This does not include support for Data API for Aurora Serverless\n.\t"
  },
  {
    "title": "Connection URLs (Reference) | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/connection-urls",
    "html": "ORMReference\nConnection URLs\n\nPrisma ORM needs a connection URL to be able to connect to your database, e.g. when sending queries with Prisma Client or when changing the database schema with Prisma Migrate.\n\nThe connection URL is provided via the url field of a datasource block in your Prisma schema. It usually consists of the following components (except for SQLite and Prisma Postgres):\n\nUser: The name of your database user\nPassword: The password for your database user\nHost: The IP or domain name of the machine where your database server is running\nPort: The port on which your database server is running\nDatabase name: The name of the database you want to use\n\nMake sure you have this information at hand when getting started with Prisma ORM. If you don't have a database server running yet, you can either use a local SQLite database file (see the Quickstart) or setup a free PostgreSQL database with Prisma Postgres.\n\nFormat​\n\nThe format of the connection URL depends on the database connector you're using. Prisma ORM generally supports the standard formats for each database. You can find out more about the connection URL of your database on the dedicated docs page:\n\nPostgreSQL\nMySQL\nSQLite\nMongoDB\nMicrosoft SQL Server\nCockroachDB\nSpecial characters​\n\nFor MySQL, PostgreSQL and CockroachDB you must percentage-encode special characters\n in any part of your connection URL - including passwords. For example, p@$$w0rd becomes p%40%24%24w0rd.\n\nFor Microsoft SQL Server, you must escape special characters in any part of your connection string.\n\nExamples​\n\nHere are examples for the connection URLs of the databases Prisma ORM supports:\n\nPrisma Postgres​\n\nPrisma Postgres is a managed PostgreSQL service running on unikernels. There are several ways to connect to Prisma Postgres:\n\nvia direct TCP connections (lets you connect via any ORM or database tool)\nvia Prisma Accelerate (only supported with Prisma ORM)\nlocally\n\nThe connection string formats of these are covered below.\n\nDirect TCP​\n\nWhen you connect to Prisma Postgres via direct TCP, your connection string looks as follows:\n\nDATABASE_URL=\"postgres://USER:PASSWORD@db.prisma.io:5432/?sslmode=require\"\n\n\nThe USER and PASSWORD values are provided when you generate credentials for your Prisma Postgres instance in the Prisma Console. Here is an example with sample values:\n\nDATABASE_URL=\"postgres://2f9881cc7eef46f094ac913df34c1fb441502fe66cbe28cc48998d4e6b20336b:sk_QZ3u8fMPFfBzOID4ol-mV@db.prisma.io:5432/?sslmode=require\"\n\nVia Prisma Accelerate (HTTP)​\n\nWhen connecting via Prisma Accelerate, the connection string doesn't require a user/password like a conventional connection string does. Instead, authentication works via an API key:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"prisma+postgres://accelerate.prisma-data.net/?api_key=API_KEY\"\n\n} \n\n\nIn this snippet, API_KEY is a placeholder for the API key you are receiving when setting up a new Prismas Postgres instance via the Prisma Console. Here is an example for what a real connection URL to Prisma Postgres may look like:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"prisma+postgres://accelerate.prisma-data.net/?api_key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhcGlfa2V5IjoiMGNkZTFlMjQtNzhiYi00NTY4LTkyM2EtNWUwOTEzZWUyNjU1IiwidGVuYW50X2lkIjoiNzEyZWRlZTc1Y2U2MDk2ZjI4NDg3YjE4NWMyYzA2OTNhNGMxNzJkMjhhOWFlNGUwZTYxNWE4NWIxZWY1YjBkMCIsImludGVybmFsX3NlY3JldCI6IjA4MzQ2Y2RlLWI5ZjktNDQ4Yy04NThmLTMxNjg4ODEzNmEzZCJ9.N1Za6q6NfInzHvRkud6Ojt_-RFg18a0601vdYWGKOrk\"\n\n}\n\nLocal Prisma Postgres​\n\nThe connection string for connecting to a local Prisma Postgres instance mirrors the structure of a remote instance via Accelerate:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"prisma+postgres://accelerate.prisma-data.net/?api_key=API_KEY\"\n\n} \n\n\nHowever, in this case the API_KEY doesn't provide authentication details. Instead, it encodes information about the local Prisma Postgres instance. You can obtain a local connection string via the prisma dev command.\n\nPostgreSQL​\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = \"postgresql://janedoe:mypassword@localhost:5432/mydb?schema=sample\"\n\n}\n\nMySQL​\nschema.prisma\ndatasource db {\n\n  provider = \"mysql\"\n\n  url      = \"mysql://janedoe:mypassword@localhost:3306/mydb\"\n\n}\n\nMicrosoft SQL Server​\nschema.prisma\ndatasource db {\n\n  provider = \"sqlserver\"\n\n  url      = \"sqlserver://localhost:1433;initial catalog=sample;user=sa;password=mypassword;\"\n\n}\n\nSQLite​\nschema.prisma\ndatasource db {\n\n  provider = \"sqlite\"\n\n  url      = \"file:./dev.db\"\n\n}\n\nCockroachDB​\nschema.prisma\ndatasource db {\n\n  provider = \"cockroachdb\"\n\n  url      = \"postgresql://janedoe:mypassword@localhost:26257/mydb?schema=public\"\n\n}\n\nMongoDB​\nschema.prisma\ndatasource db {\n\n  provider = \"mongodb\"\n\n  url      = \"mongodb+srv://root:<password>@cluster0.ab1cd.mongodb.net/myDatabase?retryWrites=true&w=majority\"\n\n}\n\n.env​\n\nYou can also provide the connection URL as an environment variable:\n\nschema.prisma\ndatasource db {\n\n  provider = \"postgresql\"\n\n  url      = env(\"DATABASE_URL\")\n\n}\n\n\nYou can then either set the environment variable in your terminal or by providing a dotenv\n file named .env. This will automatically be picked up by the Prisma CLI.\n\nPrisma ORM reads the connection URL from the dotenv file in the following situations:\n\nWhen it updates the schema during build time\nWhen it connects to the database during run time\nDATABASE_URL=postgresql://janedoe:mypassword@localhost:5432/mydb\n"
  },
  {
    "title": "System requirements (Reference) | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/system-requirements",
    "html": "ORMReference\nSystem requirements\n\nThis page provides an overview of the system requirements for Prisma ORM.\n\nSystem requirements​\n\nThis section lists the software that Prisma ORM requires and the supported operating systems, along with runtime dependency requirements for specific operating systems.\n\nSoftware requirements​\n\nThe latest version of Prisma ORM requires the following software:\n\nTool\tMinimum required version\nNode.js\t18.8 / 20.9 / 22.11\nTypeScript (optional)\t5.1.X\nYarn (optional)\t1.19.2\nPrisma ORM supports and tests all Active LTS and Maintenance LTS Node.js releases. Releases that are not in these states like\nCurrent\n, and also odd-numbered versions\n probably also work, but are not recommended for production use.\nTypeScript is only required for TypeScript users.\nWhen using Yarn 1, 1.19.2 is the minimum version compatible with Prisma Client.\n\nSee also: Supported database versions\n\nExpand for earlier versions\nOperating systems​\n\nPrisma ORM is supported on macOS, Windows and most Linux distributions.\n\nLinux runtime dependencies​\n\nPrisma ORM requires the following system libraries to be installed to work:\n\nOpenSSL 1.0.x, 1.1.x or 3.x\nzlib (libz.so.1)\nlibgcc (libgcc_s.so.1)\nC standard library (glibc on most Linux distributions or musl libc on Alpine Linux)\n\nThe following two tables show the supported Linux distro families, OpenSSL versions and C standard libraries for each CPU architecture.\n\nOn AMD64 (x86_64) architecture:\n\nDistro family\tOpenSSL version\tlibc version\nAlpine\t1.1.x, 3.x\tmusl 1.2.x\nRHEL\t1.0.x, 1.1.x, 3.x\tglibc 2.17+\nDebian or others\t1.0.x\tglibc 2.19+\nDebian or others\t1.1.x, 3.x\tglibc 2.24+\n\nOn ARM64 (aarch64) architecture:\n\nDistro family\tOpenSSL version\tlibc version\nAlpine\t1.1.x, 3.x\tmusl 1.2.x\nRHEL\t1.0.x, 1.1.x, 3.x\tglibc 2.24+\nDebian or others\t1.0.x, 1.1.x, 3.x\tglibc 2.24+\n\nWhen Prisma ORM can not resolve the OpenSSL version on a system (e.g. because it is not installed), it will default to OpenSSL 1.1.x.\n\nSystems that can run the supported Node.js versions will most likely have zlib and libgcc available. One notable exception is Google's Distroless images, where libz.so.1 needs to be copied from a compatible Debian system.\n\nWindows runtime dependencies​\n\nOn Windows Microsoft Visual C++ Redistributable 2015\n or newer must be installed (which is by default the case on most modern installations).\n\nmacOS runtime dependencies​\n\nPrisma ORM supports macOS 10.15 or newer. There are no additional platform-specific requirements on macOS other than what is listed for all platforms in the Software requirements section.\n\nTroubleshooting​\n\nThere are some common problems caused by using outdated versions of the system requirements:\n\nUnable to build a TypeScript project with @prisma/client​\nProblem​\n\nYou see the following error when you try type-checking a project after you run prisma generate.\n\n./node_modules/.prisma/client/index.d.ts:10:33\n\nType error: Type expected.\n\n8 | export type PrismaPromise<A> = Promise<A> & {[prisma]: true}\n\n9 | type UnwrapTuple<Tuple extends readonly unknown[]> = {\n\n> 10 | [K in keyof Tuple]: K extends `${number}` ? Tuple[K] extends PrismaPromise<infer X> ? X : never : never\n\n| ^\n\n11 | };\n\n12 |\n\n13 |\n\nSolution​\n\nUpgrade the TypeScript dependency in your project to a version supported by Prisma ORM. npm install -D typescript.\n\nUnable to use groupBy preview feature​\nProblem​\n\nYou see the following console error when you attempt to run an app that uses the groupBy preview feature:\n\nserver.ts:6:25 - error TS2615: Type of property 'OR' circularly references itself in mapped type '{ [K in keyof { AND?: Enumerable<ProductScalarWhereWithAggregatesInput>; OR?: Enumerable<ProductScalarWhereWithAggregatesInput>; ... 4 more ...; category?: string | StringWithAggregatesFilter; }]: Or<...> extends 1 ? { ...; }[K] extends infer TK ? GetHavingFields<...> : never : {} extends FieldPaths<...> ? never : K...'.\n\n6 const grouped = await prisma.product.groupBy({\n\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n7 by: ['category']\n\n~~~~~~~~~~~~~~~~~~~~\n\n8 });\n\n~~~~\n\nserver.ts:6:48 - error TS2554: Expected 0 arguments, but got 1.\n\n6 const grouped = await prisma.product.groupBy({\n\n~\n\n7 by: ['category']\n\n~~~~~~~~~~~~~~~~~~~~\n\n8 });\n\n~~~\n\nSolution​\n\nUpgrade the TypeScript dependency in your project to a version supported by Prisma ORM. npm install -D typescript."
  },
  {
    "title": "Preview features (Reference) | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/preview-features",
    "html": "ORMReference\nPreview features\n\nSome Prisma ORM features are released as Previews. Share your feedback on all Preview features on GitHub\n. For information about available preview features and how to enable them, see:\n\nPrisma Client and Prisma schema preview features\nPrisma CLI preview features\n\nFor information regarding upgrading Prisma ORM and enabling Preview features see Upgrading to use Preview features."
  },
  {
    "title": "Prisma CLI Preview features | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/preview-features/cli-preview-features",
    "html": "ORMReferencePreview features\nPrisma CLI Preview features\n\nWhen we release a new Prisma CLI feature, it often starts in Preview so that you can test it and submit your feedback. After we improve the feature with your feedback and are satisfied with the internal test results, we promote the feature to general availability.\n\nFor more information, see ORM releases and maturity levels.\n\nCurrently active Preview features​\n\nThere are currently no Preview features for Prisma CLI.\n\nPreview features promoted to general availability​\n\nIn the list below, you can find a history of Prisma CLI features that were in Preview and are now in general availability. The features are sorted by the most recent version in which they were promoted to general availability.\n\nFeatures\tReleased in Preview\tReleased in general availability\nprisma migrate diff\t3.9.0\n\t3.13.0\n\nprisma db execute\t3.9.0\n\t3.13.0\n\nprisma db push\t2.10.0\n\t2.22.0\n\nprisma migrate\t2.13.0\n\t2.19.0"
  },
  {
    "title": "Prisma Client & Prisma schema | Prisma Documentation",
    "url": "https://www.prisma.io/docs/orm/reference/preview-features/client-preview-features",
    "html": "ORMReferencePreview features\nPrisma Client & Prisma schema\n\nWhen we release a new Prisma Client or Prisma schema feature, it often starts in Preview so that you can test it and submit your feedback. After we improve the feature with your feedback and are satisfied with the internal test results, we promote the feature to general availability.\n\nFor more information, see ORM releases and maturity levels.\n\nCurrently active Preview features​\n\nThe following Preview feature flags are available for Prisma Client and Prisma schema:\n\nFeature\tReleased into Preview\tFeedback issue\nmetrics\t3.15.0\n\tSubmit feedback\n\nviews\t4.9.0\n\tSubmit feedback\n\nrelationJoins\t5.7.0\n\tSubmit feedback\n\nnativeDistinct\t5.7.0\n\tSubmit feedback\n\ntypedSql\t5.19.0\n\tSubmit feedback\n\nstrictUndefinedChecks\t5.20.0\n\tSubmit feedback\n\nfullTextSearchPostgres\t6.0.0\n\tSubmit feedback\n\nshardKeys\t6.10.0\n\tSubmit feedback\n\nTo enable a Preview feature, add the feature flag to the generator block in your schema.prisma file. Share your feedback on all Preview features on GitHub\n.\n\nEnabling a Prisma Client Preview feature​\n\nTo enable a Prisma Client Preview feature:\n\nAdd the Preview feature flag to the generator block:\n\ngenerator client {\n\n  provider        = \"prisma-client-js\"\n\n  previewFeatures = [\"relationJoins\"]\n\n}\n\n\nRe-generate Prisma Client:\n\nnpx prisma generate\n\n\nIf you are using Visual Studio Code and the Preview feature is not available in your .ts file after generating Prisma Client, run the TypeScript: Restart TS server command.\n\nPreview features promoted to General Availability​\n\nIn the list below, you can find a history of Prisma Client and Prisma schema features that were in Preview and are now in general availability. The features are sorted by the most recent version in which they were promoted to general availability.\n\nFeature\tReleased into Preview\tReleased into General Availability\ndriverAdapters\t5.4.0\n\t6.16.0\n\nqueryCompiler\t6.7.0\n\t6.16.0\n\nmultiSchema\t4.3.0\n\t6.13.0\n\nprismaSchemaFolder\t5.15.0\n\t6.7.0\n\nomitApi\t5.13.0\n\t6.2.0\n\njsonProtocol\t4.11.0\n\t5.0.0\n\nextendedWhereUnique\t4.5.0\n\t5.0.0\n\nfieldReference\t4.3.0\n\t5.0.0\n\nclientExtensions\t4.7.0\n\t4.16.0\n\nfilteredRelationCount\t4.3.0\n\t4.16.0\n\ntracing\t4.2.0\n\t6.1.0\n\norderByNulls\t4.1.0\n\t4.16.0\n\nreferentialIntegrity\t3.1.1\n\t4.7.0\n\ninteractiveTransactions\t2.29.0\n\t4.7.0\n\nwith Prisma Accelerate 5.1.1\n\nextendedIndexes\t3.5.0\n\t4.0.0\n\nfilterJson\t2.23.0\n\t4.0.0\n\nimprovedQueryRaw\t3.14.0\n\t4.0.0\n\ncockroachdb\t3.9.0\n\nmigrations in 3.11.0\n\t3.14.0\n\nmongodb\t2.27.0\n\nintrospection in 3.2.0\n\nembedded docs in 3.4.0\n\nraw queries in 3.9.0\n\nfilters/ordering in embedded docs in 3.11.0\n\t3.12.0\n\nmicrosoftSqlServer\t2.10.0\n\t3.0.1\n\nnamedConstraints\t2.29.0\n\t3.0.1\n\nreferentialActions\t2.26.0\n\t3.0.1\n\norderByAggregateGroup\t2.21.0\n\t3.0.1\n\norderByRelation\t2.16.0\n\naggregates in 2.19.0\n\t3.0.1\n\nselectRelationCount\t2.20.0\n\t3.0.1\n\nnapi\t2.20.0\n\t3.0.1\n\ngroupBy\t2.14.0\n\t2.20.0\n\ncreateMany\t2.16.0\n\t2.20.0\n\nnativeTypes\t2.11.0\n\t2.17.0\n\nuncheckedScalarInputs\t2.11.0\n\t2.15.0\n\ntransactionApi\t2.1.0\n\t2.11.0\n\nconnectOrCreate\t2.1.0\n\t2.11.0\n\natomicNumberOperations\t2.6.0\n\t2.10.0\n\ninsensitiveFilters (PostgreSQL)\t2.5.0\n\t2.8.0\n\nproxys\t2.3.0\n\t2.5.0\n\naggregateApi\t2.2.0\n\t2.5.0\n\ndistinct\t2.3.0\n\t2.5.0"
  }
]
</file>

<file path="output/react/reference.json">
[
  {
    "title": "React Reference Overview – React",
    "url": "https://react.dev/reference/react",
    "html": "API REFERENCE\nReact Reference Overview\n\nThis section provides detailed reference documentation for working with React. For an introduction to React, please visit the Learn section.\n\nThe React reference documentation is broken down into functional subsections:\n\nReact \n\nProgrammatic React features:\n\nHooks - Use different React features from your components.\nComponents - Built-in components that you can use in your JSX.\nAPIs - APIs that are useful for defining components.\nDirectives - Provide instructions to bundlers compatible with React Server Components.\nReact DOM \n\nReact-dom contains features that are only supported for web applications (which run in the browser DOM environment). This section is broken into the following:\n\nHooks - Hooks for web applications which run in the browser DOM environment.\nComponents - React supports all of the browser built-in HTML and SVG components.\nAPIs - The react-dom package contains methods supported only in web applications.\nClient APIs - The react-dom/client APIs let you render React components on the client (in the browser).\nServer APIs - The react-dom/server APIs let you render React components to HTML on the server.\nReact Compiler \n\nThe React Compiler is a build-time optimization tool that automatically memoizes your React components and values:\n\nConfiguration - Configuration options for React Compiler.\nDirectives - Function-level directives to control compilation.\nCompiling Libraries - Guide for shipping pre-compiled library code.\nESLint Plugin React Hooks \n\nThe ESLint plugin for React Hooks helps enforce the Rules of React:\n\nLints - Detailed documentation for each lint with examples.\nRules of React \n\nReact has idioms — or rules — for how to express patterns in a way that is easy to understand and yields high-quality applications:\n\nComponents and Hooks must be pure – Purity makes your code easier to understand, debug, and allows React to automatically optimize your components and hooks correctly.\nReact calls Components and Hooks – React is responsible for rendering components and hooks when necessary to optimize the user experience.\nRules of Hooks – Hooks are defined using JavaScript functions, but they represent a special type of reusable UI logic with restrictions on where they can be called.\nLegacy APIs \nLegacy APIs - Exported from the react package, but not recommended for use in newly written code.\nNEXT\nHooks"
  },
  {
    "title": "Built-in React Hooks – React",
    "url": "https://react.dev/reference/react/hooks",
    "html": "API REFERENCE\nBuilt-in React Hooks\n\nHooks let you use different React features from your components. You can either use the built-in Hooks or combine them to build your own. This page lists all built-in Hooks in React.\n\nState Hooks \n\nState lets a component “remember” information like user input. For example, a form component can use state to store the input value, while an image gallery component can use state to store the selected image index.\n\nTo add state to a component, use one of these Hooks:\n\nuseState declares a state variable that you can update directly.\nuseReducer declares a state variable with the update logic inside a reducer function.\nfunction ImageGallery() {\n\n  const [index, setIndex] = useState(0);\n\n  // ...\nContext Hooks \n\nContext lets a component receive information from distant parents without passing it as props. For example, your app’s top-level component can pass the current UI theme to all components below, no matter how deep.\n\nuseContext reads and subscribes to a context.\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\nRef Hooks \n\nRefs let a component hold some information that isn’t used for rendering, like a DOM node or a timeout ID. Unlike with state, updating a ref does not re-render your component. Refs are an “escape hatch” from the React paradigm. They are useful when you need to work with non-React systems, such as the built-in browser APIs.\n\nuseRef declares a ref. You can hold any value in it, but most often it’s used to hold a DOM node.\nuseImperativeHandle lets you customize the ref exposed by your component. This is rarely used.\nfunction Form() {\n\n  const inputRef = useRef(null);\n\n  // ...\nEffect Hooks \n\nEffects let a component connect to and synchronize with external systems. This includes dealing with network, browser DOM, animations, widgets written using a different UI library, and other non-React code.\n\nuseEffect connects a component to an external system.\nfunction ChatRoom({ roomId }) {\n\n  useEffect(() => {\n\n    const connection = createConnection(roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]);\n\n  // ...\n\nEffects are an “escape hatch” from the React paradigm. Don’t use Effects to orchestrate the data flow of your application. If you’re not interacting with an external system, you might not need an Effect.\n\nThere are two rarely used variations of useEffect with differences in timing:\n\nuseLayoutEffect fires before the browser repaints the screen. You can measure layout here.\nuseInsertionEffect fires before React makes changes to the DOM. Libraries can insert dynamic CSS here.\nPerformance Hooks \n\nA common way to optimize re-rendering performance is to skip unnecessary work. For example, you can tell React to reuse a cached calculation or to skip a re-render if the data has not changed since the previous render.\n\nTo skip calculations and unnecessary re-rendering, use one of these Hooks:\n\nuseMemo lets you cache the result of an expensive calculation.\nuseCallback lets you cache a function definition before passing it down to an optimized component.\nfunction TodoList({ todos, tab, theme }) {\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  // ...\n\n}\n\nSometimes, you can’t skip re-rendering because the screen actually needs to update. In that case, you can improve performance by separating blocking updates that must be synchronous (like typing into an input) from non-blocking updates which don’t need to block the user interface (like updating a chart).\n\nTo prioritize rendering, use one of these Hooks:\n\nuseTransition lets you mark a state transition as non-blocking and allow other updates to interrupt it.\nuseDeferredValue lets you defer updating a non-critical part of the UI and let other parts update first.\nOther Hooks \n\nThese Hooks are mostly useful to library authors and aren’t commonly used in the application code.\n\nuseDebugValue lets you customize the label React DevTools displays for your custom Hook.\nuseId lets a component associate a unique ID with itself. Typically used with accessibility APIs.\nuseSyncExternalStore lets a component subscribe to an external store.\nuseActionState allows you to manage state of actions.\nYour own Hooks \n\nYou can also define your own custom Hooks as JavaScript functions.\n\nPREVIOUS\nOverview\nNEXT\nuseActionState"
  },
  {
    "title": "useActionState – React",
    "url": "https://react.dev/reference/react/useActionState",
    "html": "API REFERENCE\nHOOKS\nuseActionState\n\nuseActionState is a Hook that allows you to update state based on the result of a form action.\n\nconst [state, formAction, isPending] = useActionState(fn, initialState, permalink?);\nNote\n\nIn earlier React Canary versions, this API was part of React DOM and called useFormState.\n\nReference\nuseActionState(action, initialState, permalink?)\nUsage\nUsing information returned by a form action\nTroubleshooting\nMy action can no longer read the submitted form data\nReference \nuseActionState(action, initialState, permalink?) \n\nCall useActionState at the top level of your component to create component state that is updated when a form action is invoked. You pass useActionState an existing form action function as well as an initial state, and it returns a new action that you use in your form, along with the latest form state and whether the Action is still pending. The latest form state is also passed to the function that you provided.\n\nimport { useActionState } from \"react\";\n\n\n\nasync function increment(previousState, formData) {\n\n  return previousState + 1;\n\n}\n\n\n\nfunction StatefulForm({}) {\n\n  const [state, formAction] = useActionState(increment, 0);\n\n  return (\n\n    <form>\n\n      {state}\n\n      <button formAction={formAction}>Increment</button>\n\n    </form>\n\n  )\n\n}\n\nThe form state is the value returned by the action when the form was last submitted. If the form has not yet been submitted, it is the initial state that you pass.\n\nIf used with a Server Function, useActionState allows the server’s response from submitting the form to be shown even before hydration has completed.\n\nSee more examples below.\n\nParameters \nfn: The function to be called when the form is submitted or button pressed. When the function is called, it will receive the previous state of the form (initially the initialState that you pass, subsequently its previous return value) as its initial argument, followed by the arguments that a form action normally receives.\ninitialState: The value you want the state to be initially. It can be any serializable value. This argument is ignored after the action is first invoked.\noptional permalink: A string containing the unique page URL that this form modifies. For use on pages with dynamic content (eg: feeds) in conjunction with progressive enhancement: if fn is a server function and the form is submitted before the JavaScript bundle loads, the browser will navigate to the specified permalink URL, rather than the current page’s URL. Ensure that the same form component is rendered on the destination page (including the same action fn and permalink) so that React knows how to pass the state through. Once the form has been hydrated, this parameter has no effect.\nReturns \n\nuseActionState returns an array with the following values:\n\nThe current state. During the first render, it will match the initialState you have passed. After the action is invoked, it will match the value returned by the action.\nA new action that you can pass as the action prop to your form component or formAction prop to any button component within the form. The action can also be called manually within startTransition.\nThe isPending flag that tells you whether there is a pending Transition.\nCaveats \nWhen used with a framework that supports React Server Components, useActionState lets you make forms interactive before JavaScript has executed on the client. When used without Server Components, it is equivalent to component local state.\nThe function passed to useActionState receives an extra argument, the previous or initial state, as its first argument. This makes its signature different than if it were used directly as a form action without using useActionState.\nUsage \nUsing information returned by a form action \n\nCall useActionState at the top level of your component to access the return value of an action from the last time a form was submitted.\n\nimport { useActionState } from 'react';\n\nimport { action } from './actions.js';\n\n\n\nfunction MyComponent() {\n\n  const [state, formAction] = useActionState(action, null);\n\n  // ...\n\n  return (\n\n    <form action={formAction}>\n\n      {/* ... */}\n\n    </form>\n\n  );\n\n}\n\nuseActionState returns an array with the following items:\n\nThe current state of the form, which is initially set to the initial state you provided, and after the form is submitted is set to the return value of the action you provided.\nA new action that you pass to <form> as its action prop or call manually within startTransition.\nA pending state that you can utilise while your action is processing.\n\nWhen the form is submitted, the action function that you provided will be called. Its return value will become the new current state of the form.\n\nThe action that you provide will also receive a new first argument, namely the current state of the form. The first time the form is submitted, this will be the initial state you provided, while with subsequent submissions, it will be the return value from the last time the action was called. The rest of the arguments are the same as if useActionState had not been used.\n\nfunction action(currentState, formData) {\n\n  // ...\n\n  return 'next state';\n\n}\nDisplay information after submitting a form\n1. Display form errors\n2. Display structured information after submitting a form\nExample 1 of 2: Display form errors \n\nTo display messages such as an error message or toast that’s returned by a Server Function, wrap the action in a call to useActionState.\n\nApp.js\nactions.js\nReload\nClear\nFork\nimport { useActionState, useState } from \"react\";\nimport { addToCart } from \"./actions.js\";\n\nfunction AddToCartForm({itemID, itemTitle}) {\n  const [message, formAction, isPending] = useActionState(addToCart, null);\n  return (\n    <form action={formAction}>\n      <h2>{itemTitle}</h2>\n      <input type=\"hidden\" name=\"itemID\" value={itemID} />\n      <button type=\"submit\">Add to Cart</button>\n      {isPending ? \"Loading...\" : message}\n    </form>\n  );\n}\n\nexport default function App() {\n  return (\n    <>\n      <AddToCartForm itemID=\"1\" itemTitle=\"JavaScript: The Definitive Guide\" />\n      <AddToCartForm itemID=\"2\" itemTitle=\"JavaScript: The Good Parts\" />\n    </>\n  )\n}\n\n\nShow more\nNext Example\nTroubleshooting \nMy action can no longer read the submitted form data \n\nWhen you wrap an action with useActionState, it gets an extra argument as its first argument. The submitted form data is therefore its second argument instead of its first as it would usually be. The new first argument that gets added is the current state of the form.\n\nfunction action(currentState, formData) {\n\n  // ...\n\n}\nPREVIOUS\nHooks\nNEXT\nuseCallback"
  },
  {
    "title": "useCallback – React",
    "url": "https://react.dev/reference/react/useCallback",
    "html": "API REFERENCE\nHOOKS\nuseCallback\n\nuseCallback is a React Hook that lets you cache a function definition between re-renders.\n\nconst cachedFn = useCallback(fn, dependencies)\nNote\n\nReact Compiler automatically memoizes values and functions, reducing the need for manual useCallback calls. You can use the compiler to handle memoization automatically.\n\nReference\nuseCallback(fn, dependencies)\nUsage\nSkipping re-rendering of components\nUpdating state from a memoized callback\nPreventing an Effect from firing too often\nOptimizing a custom Hook\nTroubleshooting\nEvery time my component renders, useCallback returns a different function\nI need to call useCallback for each list item in a loop, but it’s not allowed\nReference \nuseCallback(fn, dependencies) \n\nCall useCallback at the top level of your component to cache a function definition between re-renders:\n\nimport { useCallback } from 'react';\n\n\n\nexport default function ProductPage({ productId, referrer, theme }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]);\n\nSee more examples below.\n\nParameters \n\nfn: The function value that you want to cache. It can take any arguments and return any values. React will return (not call!) your function back to you during the initial render. On next renders, React will give you the same function again if the dependencies have not changed since the last render. Otherwise, it will give you the function that you have passed during the current render, and store it in case it can be reused later. React will not call your function. The function is returned to you so you can decide when and whether to call it.\n\ndependencies: The list of all reactive values referenced inside of the fn code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison algorithm.\n\nReturns \n\nOn the initial render, useCallback returns the fn function you have passed.\n\nDuring subsequent renders, it will either return an already stored fn function from the last render (if the dependencies haven’t changed), or return the fn function you have passed during this render.\n\nCaveats \nuseCallback is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nReact will not throw away the cached function unless there is a specific reason to do that. For example, in development, React throws away the cache when you edit the file of your component. Both in development and in production, React will throw away the cache if your component suspends during the initial mount. In the future, React may add more features that take advantage of throwing away the cache—for example, if React adds built-in support for virtualized lists in the future, it would make sense to throw away the cache for items that scroll out of the virtualized table viewport. This should match your expectations if you rely on useCallback as a performance optimization. Otherwise, a state variable or a ref may be more appropriate.\nUsage \nSkipping re-rendering of components \n\nWhen you optimize rendering performance, you will sometimes need to cache the functions that you pass to child components. Let’s first look at the syntax for how to do this, and then see in which cases it’s useful.\n\nTo cache a function between re-renders of your component, wrap its definition into the useCallback Hook:\n\nimport { useCallback } from 'react';\n\n\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]);\n\n  // ...\n\nYou need to pass two things to useCallback:\n\nA function definition that you want to cache between re-renders.\nA list of dependencies including every value within your component that’s used inside your function.\n\nOn the initial render, the returned function you’ll get from useCallback will be the function you passed.\n\nOn the following renders, React will compare the dependencies with the dependencies you passed during the previous render. If none of the dependencies have changed (compared with Object.is), useCallback will return the same function as before. Otherwise, useCallback will return the function you passed on this render.\n\nIn other words, useCallback caches a function between re-renders until its dependencies change.\n\nLet’s walk through an example to see when this is useful.\n\nSay you’re passing a handleSubmit function down from the ProductPage to the ShippingForm component:\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  // ...\n\n  return (\n\n    <div className={theme}>\n\n      <ShippingForm onSubmit={handleSubmit} />\n\n    </div>\n\n  );\n\nYou’ve noticed that toggling the theme prop freezes the app for a moment, but if you remove <ShippingForm /> from your JSX, it feels fast. This tells you that it’s worth trying to optimize the ShippingForm component.\n\nBy default, when a component re-renders, React re-renders all of its children recursively. This is why, when ProductPage re-renders with a different theme, the ShippingForm component also re-renders. This is fine for components that don’t require much calculation to re-render. But if you verified a re-render is slow, you can tell ShippingForm to skip re-rendering when its props are the same as on last render by wrapping it in memo:\n\nimport { memo } from 'react';\n\n\n\nconst ShippingForm = memo(function ShippingForm({ onSubmit }) {\n\n  // ...\n\n});\n\nWith this change, ShippingForm will skip re-rendering if all of its props are the same as on the last render. This is when caching a function becomes important! Let’s say you defined handleSubmit without useCallback:\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  // Every time the theme changes, this will be a different function...\n\n  function handleSubmit(orderDetails) {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }\n\n\n\n  return (\n\n    <div className={theme}>\n\n      {/* ... so ShippingForm's props will never be the same, and it will re-render every time */}\n\n      <ShippingForm onSubmit={handleSubmit} />\n\n    </div>\n\n  );\n\n}\n\nIn JavaScript, a function () {} or () => {} always creates a different function, similar to how the {} object literal always creates a new object. Normally, this wouldn’t be a problem, but it means that ShippingForm props will never be the same, and your memo optimization won’t work. This is where useCallback comes in handy:\n\nfunction ProductPage({ productId, referrer, theme }) {\n\n  // Tell React to cache your function between re-renders...\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]); // ...so as long as these dependencies don't change...\n\n\n\n  return (\n\n    <div className={theme}>\n\n      {/* ...ShippingForm will receive the same props and can skip re-rendering */}\n\n      <ShippingForm onSubmit={handleSubmit} />\n\n    </div>\n\n  );\n\n}\n\nBy wrapping handleSubmit in useCallback, you ensure that it’s the same function between the re-renders (until dependencies change). You don’t have to wrap a function in useCallback unless you do it for some specific reason. In this example, the reason is that you pass it to a component wrapped in memo, and this lets it skip re-rendering. There are other reasons you might need useCallback which are described further on this page.\n\nNote\n\nYou should only rely on useCallback as a performance optimization. If your code doesn’t work without it, find the underlying problem and fix it first. Then you may add useCallback back.\n\nDEEP DIVE\nHow is useCallback related to useMemo? \nShow Details\nDEEP DIVE\nShould you add useCallback everywhere? \nShow Details\nThe difference between useCallback and declaring a function directly\n1. Skipping re-rendering with useCallback and memo\n2. Always re-rendering a component\nExample 1 of 2: Skipping re-rendering with useCallback and memo \n\nIn this example, the ShippingForm component is artificially slowed down so that you can see what happens when a React component you’re rendering is genuinely slow. Try incrementing the counter and toggling the theme.\n\nIncrementing the counter feels slow because it forces the slowed down ShippingForm to re-render. That’s expected because the counter has changed, and so you need to reflect the user’s new choice on the screen.\n\nNext, try toggling the theme. Thanks to useCallback together with memo, it’s fast despite the artificial slowdown! ShippingForm skipped re-rendering because the handleSubmit function has not changed. The handleSubmit function has not changed because both productId and referrer (your useCallback dependencies) haven’t changed since last render.\n\nApp.js\nProductPage.js\nShippingForm.js\nReload\nClear\nFork\nimport { useCallback } from 'react';\nimport ShippingForm from './ShippingForm.js';\n\nexport default function ProductPage({ productId, referrer, theme }) {\n  const handleSubmit = useCallback((orderDetails) => {\n    post('/product/' + productId + '/buy', {\n      referrer,\n      orderDetails,\n    });\n  }, [productId, referrer]);\n\n  return (\n    <div className={theme}>\n      <ShippingForm onSubmit={handleSubmit} />\n    </div>\n  );\n}\n\nfunction post(url, data) {\n  // Imagine this sends a request...\n  console.log('POST /' + url);\n  console.log(data);\n}\n\n\nShow more\nNext Example\nUpdating state from a memoized callback \n\nSometimes, you might need to update state based on previous state from a memoized callback.\n\nThis handleAddTodo function specifies todos as a dependency because it computes the next todos from it:\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState([]);\n\n\n\n  const handleAddTodo = useCallback((text) => {\n\n    const newTodo = { id: nextId++, text };\n\n    setTodos([...todos, newTodo]);\n\n  }, [todos]);\n\n  // ...\n\nYou’ll usually want memoized functions to have as few dependencies as possible. When you read some state only to calculate the next state, you can remove that dependency by passing an updater function instead:\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState([]);\n\n\n\n  const handleAddTodo = useCallback((text) => {\n\n    const newTodo = { id: nextId++, text };\n\n    setTodos(todos => [...todos, newTodo]);\n\n  }, []); // ✅ No need for the todos dependency\n\n  // ...\n\nHere, instead of making todos a dependency and reading it inside, you pass an instruction about how to update the state (todos => [...todos, newTodo]) to React. Read more about updater functions.\n\nPreventing an Effect from firing too often \n\nSometimes, you might want to call a function from inside an Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  function createOptions() {\n\n    return {\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    };\n\n  }\n\n\n\n  useEffect(() => {\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    // ...\n\nThis creates a problem. Every reactive value must be declared as a dependency of your Effect. However, if you declare createOptions as a dependency, it will cause your Effect to constantly reconnect to the chat room:\n\n  useEffect(() => {\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [createOptions]); // 🔴 Problem: This dependency changes on every render\n\n  // ...\n\nTo solve this, you can wrap the function you need to call from an Effect into useCallback:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const createOptions = useCallback(() => {\n\n    return {\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    };\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n\n\n  useEffect(() => {\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [createOptions]); // ✅ Only changes when createOptions changes\n\n  // ...\n\nThis ensures that the createOptions function is the same between re-renders if the roomId is the same. However, it’s even better to remove the need for a function dependency. Move your function inside the Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  useEffect(() => {\n\n    function createOptions() { // ✅ No need for useCallback or function dependencies!\n\n      return {\n\n        serverUrl: 'https://localhost:1234',\n\n        roomId: roomId\n\n      };\n\n    }\n\n\n\n    const options = createOptions();\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n  // ...\n\nNow your code is simpler and doesn’t need useCallback. Learn more about removing Effect dependencies.\n\nOptimizing a custom Hook \n\nIf you’re writing a custom Hook, it’s recommended to wrap any functions that it returns into useCallback:\n\nfunction useRouter() {\n\n  const { dispatch } = useContext(RouterStateContext);\n\n\n\n  const navigate = useCallback((url) => {\n\n    dispatch({ type: 'navigate', url });\n\n  }, [dispatch]);\n\n\n\n  const goBack = useCallback(() => {\n\n    dispatch({ type: 'back' });\n\n  }, [dispatch]);\n\n\n\n  return {\n\n    navigate,\n\n    goBack,\n\n  };\n\n}\n\nThis ensures that the consumers of your Hook can optimize their own code when needed.\n\nTroubleshooting \nEvery time my component renders, useCallback returns a different function \n\nMake sure you’ve specified the dependency array as a second argument!\n\nIf you forget the dependency array, useCallback will return a new function every time:\n\nfunction ProductPage({ productId, referrer }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }); // 🔴 Returns a new function every time: no dependency array\n\n  // ...\n\nThis is the corrected version passing the dependency array as a second argument:\n\nfunction ProductPage({ productId, referrer }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails,\n\n    });\n\n  }, [productId, referrer]); // ✅ Does not return a new function unnecessarily\n\n  // ...\n\nIf this doesn’t help, then the problem is that at least one of your dependencies is different from the previous render. You can debug this problem by manually logging your dependencies to the console:\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    // ..\n\n  }, [productId, referrer]);\n\n\n\n  console.log([productId, referrer]);\n\nYou can then right-click on the arrays from different re-renders in the console and select “Store as a global variable” for both of them. Assuming the first one got saved as temp1 and the second one got saved as temp2, you can then use the browser console to check whether each dependency in both arrays is the same:\n\nObject.is(temp1[0], temp2[0]); // Is the first dependency the same between the arrays?\n\nObject.is(temp1[1], temp2[1]); // Is the second dependency the same between the arrays?\n\nObject.is(temp1[2], temp2[2]); // ... and so on for every dependency ...\n\nWhen you find which dependency is breaking memoization, either find a way to remove it, or memoize it as well.\n\nI need to call useCallback for each list item in a loop, but it’s not allowed \n\nSuppose the Chart component is wrapped in memo. You want to skip re-rendering every Chart in the list when the ReportList component re-renders. However, you can’t call useCallback in a loop:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item => {\n\n        // 🔴 You can't call useCallback in a loop like this:\n\n        const handleClick = useCallback(() => {\n\n          sendReport(item)\n\n        }, [item]);\n\n\n\n        return (\n\n          <figure key={item.id}>\n\n            <Chart onClick={handleClick} />\n\n          </figure>\n\n        );\n\n      })}\n\n    </article>\n\n  );\n\n}\n\nInstead, extract a component for an individual item, and put useCallback there:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item =>\n\n        <Report key={item.id} item={item} />\n\n      )}\n\n    </article>\n\n  );\n\n}\n\n\n\nfunction Report({ item }) {\n\n  // ✅ Call useCallback at the top level:\n\n  const handleClick = useCallback(() => {\n\n    sendReport(item)\n\n  }, [item]);\n\n\n\n  return (\n\n    <figure>\n\n      <Chart onClick={handleClick} />\n\n    </figure>\n\n  );\n\n}\n\nAlternatively, you could remove useCallback in the last snippet and instead wrap Report itself in memo. If the item prop does not change, Report will skip re-rendering, so Chart will skip re-rendering too:\n\nfunction ReportList({ items }) {\n\n  // ...\n\n}\n\n\n\nconst Report = memo(function Report({ item }) {\n\n  function handleClick() {\n\n    sendReport(item);\n\n  }\n\n\n\n  return (\n\n    <figure>\n\n      <Chart onClick={handleClick} />\n\n    </figure>\n\n  );\n\n});\nPREVIOUS\nuseActionState\nNEXT\nuseContext"
  },
  {
    "title": "useContext – React",
    "url": "https://react.dev/reference/react/useContext",
    "html": "API REFERENCE\nHOOKS\nuseContext\n\nuseContext is a React Hook that lets you read and subscribe to context from your component.\n\nconst value = useContext(SomeContext)\nReference\nuseContext(SomeContext)\nUsage\nPassing data deeply into the tree\nUpdating data passed via context\nSpecifying a fallback default value\nOverriding context for a part of the tree\nOptimizing re-renders when passing objects and functions\nTroubleshooting\nMy component doesn’t see the value from my provider\nI am always getting undefined from my context although the default value is different\nReference \nuseContext(SomeContext) \n\nCall useContext at the top level of your component to read and subscribe to context.\n\nimport { useContext } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\nSee more examples below.\n\nParameters \nSomeContext: The context that you’ve previously created with createContext. The context itself does not hold the information, it only represents the kind of information you can provide or read from components.\nReturns \n\nuseContext returns the context value for the calling component. It is determined as the value passed to the closest SomeContext above the calling component in the tree. If there is no such provider, then the returned value will be the defaultValue you have passed to createContext for that context. The returned value is always up-to-date. React automatically re-renders components that read some context if it changes.\n\nCaveats \nuseContext() call in a component is not affected by providers returned from the same component. The corresponding <Context> needs to be above the component doing the useContext() call.\nReact automatically re-renders all the children that use a particular context starting from the provider that receives a different value. The previous and the next values are compared with the Object.is comparison. Skipping re-renders with memo does not prevent the children receiving fresh context values.\nIf your build system produces duplicates modules in the output (which can happen with symlinks), this can break context. Passing something via context only works if SomeContext that you use to provide context and SomeContext that you use to read it are exactly the same object, as determined by a === comparison.\nUsage \nPassing data deeply into the tree \n\nCall useContext at the top level of your component to read and subscribe to context.\n\nimport { useContext } from 'react';\n\n\n\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\nuseContext returns the context value for the context you passed. To determine the context value, React searches the component tree and finds the closest context provider above for that particular context.\n\nTo pass context to a Button, wrap it or one of its parent components into the corresponding context provider:\n\nfunction MyPage() {\n\n  return (\n\n    <ThemeContext value=\"dark\">\n\n      <Form />\n\n    </ThemeContext>\n\n  );\n\n}\n\n\n\nfunction Form() {\n\n  // ... renders buttons inside ...\n\n}\n\nIt doesn’t matter how many layers of components there are between the provider and the Button. When a Button anywhere inside of Form calls useContext(ThemeContext), it will receive \"dark\" as the value.\n\nPitfall\n\nuseContext() always looks for the closest provider above the component that calls it. It searches upwards and does not consider providers in the component from which you’re calling useContext().\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nUpdating data passed via context \n\nOften, you’ll want the context to change over time. To update context, combine it with state. Declare a state variable in the parent component, and pass the current state down as the context value to the provider.\n\nfunction MyPage() {\n\n  const [theme, setTheme] = useState('dark');\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <Form />\n\n      <Button onClick={() => {\n\n        setTheme('light');\n\n      }}>\n\n        Switch to light theme\n\n      </Button>\n\n    </ThemeContext>\n\n  );\n\n}\n\nNow any Button inside of the provider will receive the current theme value. If you call setTheme to update the theme value that you pass to the provider, all Button components will re-render with the new 'light' value.\n\nExamples of updating context\n1. Updating a value via context\n2. Updating an object via context\n3. Multiple contexts\n4. Extracting providers to a component\n5. Scaling up with context and a reducer\nExample 1 of 5: Updating a value via context \n\nIn this example, the MyApp component holds a state variable which is then passed to the ThemeContext provider. Checking the “Dark mode” checkbox updates the state. Changing the provided value re-renders all the components using that context.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext, useState } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  const [theme, setTheme] = useState('light');\n  return (\n    <ThemeContext value={theme}>\n      <Form />\n      <label>\n        <input\n          type=\"checkbox\"\n          checked={theme === 'dark'}\n          onChange={(e) => {\n            setTheme(e.target.checked ? 'dark' : 'light')\n          }}\n        />\n        Use dark mode\n      </label>\n    </ThemeContext>\n  )\n}\n\nfunction Form({ children }) {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\n\nNote that value=\"dark\" passes the \"dark\" string, but value={theme} passes the value of the JavaScript theme variable with JSX curly braces. Curly braces also let you pass context values that aren’t strings.\n\nNext Example\nSpecifying a fallback default value \n\nIf React can’t find any providers of that particular context in the parent tree, the context value returned by useContext() will be equal to the default value that you specified when you created that context:\n\nconst ThemeContext = createContext(null);\n\nThe default value never changes. If you want to update context, use it with state as described above.\n\nOften, instead of null, there is some more meaningful value you can use as a default, for example:\n\nconst ThemeContext = createContext('light');\n\nThis way, if you accidentally render some component without a corresponding provider, it won’t break. This also helps your components work well in a test environment without setting up a lot of providers in the tests.\n\nIn the example below, the “Toggle theme” button is always light because it’s outside any theme context provider and the default context theme value is 'light'. Try editing the default theme to be 'dark'.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext, useState } from 'react';\n\nconst ThemeContext = createContext('light');\n\nexport default function MyApp() {\n  const [theme, setTheme] = useState('light');\n  return (\n    <>\n      <ThemeContext value={theme}>\n        <Form />\n      </ThemeContext>\n      <Button onClick={() => {\n        setTheme(theme === 'dark' ? 'light' : 'dark');\n      }}>\n        Toggle theme\n      </Button>\n    </>\n  )\n}\n\nfunction Form({ children }) {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children, onClick }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className} onClick={onClick}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nOverriding context for a part of the tree \n\nYou can override the context for a part of the tree by wrapping that part in a provider with a different value.\n\n<ThemeContext value=\"dark\">\n\n  ...\n\n  <ThemeContext value=\"light\">\n\n    <Footer />\n\n  </ThemeContext>\n\n  ...\n\n</ThemeContext>\n\nYou can nest and override providers as many times as you need.\n\nExamples of overriding context\n1. Overriding a theme\n2. Automatically nested headings\nExample 1 of 2: Overriding a theme \n\nHere, the button inside the Footer receives a different context value (\"light\") than the buttons outside (\"dark\").\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n      <ThemeContext value=\"light\">\n        <Footer />\n      </ThemeContext>\n    </Panel>\n  );\n}\n\nfunction Footer() {\n  return (\n    <footer>\n      <Button>Settings</Button>\n    </footer>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      {title && <h1>{title}</h1>}\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nNext Example\nOptimizing re-renders when passing objects and functions \n\nYou can pass any values via context, including objects and functions.\n\nfunction MyApp() {\n\n  const [currentUser, setCurrentUser] = useState(null);\n\n\n\n  function login(response) {\n\n    storeCredentials(response.credentials);\n\n    setCurrentUser(response.user);\n\n  }\n\n\n\n  return (\n\n    <AuthContext value={{ currentUser, login }}>\n\n      <Page />\n\n    </AuthContext>\n\n  );\n\n}\n\nHere, the context value is a JavaScript object with two properties, one of which is a function. Whenever MyApp re-renders (for example, on a route update), this will be a different object pointing at a different function, so React will also have to re-render all components deep in the tree that call useContext(AuthContext).\n\nIn smaller apps, this is not a problem. However, there is no need to re-render them if the underlying data, like currentUser, has not changed. To help React take advantage of that fact, you may wrap the login function with useCallback and wrap the object creation into useMemo. This is a performance optimization:\n\nimport { useCallback, useMemo } from 'react';\n\n\n\nfunction MyApp() {\n\n  const [currentUser, setCurrentUser] = useState(null);\n\n\n\n  const login = useCallback((response) => {\n\n    storeCredentials(response.credentials);\n\n    setCurrentUser(response.user);\n\n  }, []);\n\n\n\n  const contextValue = useMemo(() => ({\n\n    currentUser,\n\n    login\n\n  }), [currentUser, login]);\n\n\n\n  return (\n\n    <AuthContext value={contextValue}>\n\n      <Page />\n\n    </AuthContext>\n\n  );\n\n}\n\nAs a result of this change, even if MyApp needs to re-render, the components calling useContext(AuthContext) won’t need to re-render unless currentUser has changed.\n\nRead more about useMemo and useCallback.\n\nTroubleshooting \nMy component doesn’t see the value from my provider \n\nThere are a few common ways that this can happen:\n\nYou’re rendering <SomeContext> in the same component (or below) as where you’re calling useContext(). Move <SomeContext> above and outside the component calling useContext().\nYou may have forgotten to wrap your component with <SomeContext>, or you might have put it in a different part of the tree than you thought. Check whether the hierarchy is right using React DevTools.\nYou might be running into some build issue with your tooling that causes SomeContext as seen from the providing component and SomeContext as seen by the reading component to be two different objects. This can happen if you use symlinks, for example. You can verify this by assigning them to globals like window.SomeContext1 and window.SomeContext2 and then checking whether window.SomeContext1 === window.SomeContext2 in the console. If they’re not the same, fix that issue on the build tool level.\nI am always getting undefined from my context although the default value is different \n\nYou might have a provider without a value in the tree:\n\n// 🚩 Doesn't work: no value prop\n\n<ThemeContext>\n\n   <Button />\n\n</ThemeContext>\n\nIf you forget to specify value, it’s like passing value={undefined}.\n\nYou may have also mistakingly used a different prop name by mistake:\n\n// 🚩 Doesn't work: prop should be called \"value\"\n\n<ThemeContext theme={theme}>\n\n   <Button />\n\n</ThemeContext>\n\nIn both of these cases you should see a warning from React in the console. To fix them, call the prop value:\n\n// ✅ Passing the value prop\n\n<ThemeContext value={theme}>\n\n   <Button />\n\n</ThemeContext>\n\nNote that the default value from your createContext(defaultValue) call is only used if there is no matching provider above at all. If there is a <SomeContext value={undefined}> component somewhere in the parent tree, the component calling useContext(SomeContext) will receive undefined as the context value.\n\nPREVIOUS\nuseCallback\nNEXT\nuseDebugValue"
  },
  {
    "title": "useDeferredValue – React",
    "url": "https://react.dev/reference/react/useDeferredValue",
    "html": "API REFERENCE\nHOOKS\nuseDeferredValue\n\nuseDeferredValue is a React Hook that lets you defer updating a part of the UI.\n\nconst deferredValue = useDeferredValue(value)\nReference\nuseDeferredValue(value, initialValue?)\nUsage\nShowing stale content while fresh content is loading\nIndicating that the content is stale\nDeferring re-rendering for a part of the UI\nReference \nuseDeferredValue(value, initialValue?) \n\nCall useDeferredValue at the top level of your component to get a deferred version of that value.\n\nimport { useState, useDeferredValue } from 'react';\n\n\n\nfunction SearchPage() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \nvalue: The value you want to defer. It can have any type.\noptional initialValue: A value to use during the initial render of a component. If this option is omitted, useDeferredValue will not defer during the initial render, because there’s no previous version of value that it can render instead.\nReturns \ncurrentValue: During the initial render, the returned deferred value will be the initialValue, or the same as the value you provided. During updates, React will first attempt a re-render with the old value (so it will return the old value), and then try another re-render in the background with the new value (so it will return the updated value).\nCaveats \n\nWhen an update is inside a Transition, useDeferredValue always returns the new value and does not spawn a deferred render, since the update is already deferred.\n\nThe values you pass to useDeferredValue should either be primitive values (like strings and numbers) or objects created outside of rendering. If you create a new object during rendering and immediately pass it to useDeferredValue, it will be different on every render, causing unnecessary background re-renders.\n\nWhen useDeferredValue receives a different value (compared with Object.is), in addition to the current render (when it still uses the previous value), it schedules a re-render in the background with the new value. The background re-render is interruptible: if there’s another update to the value, React will restart the background re-render from scratch. For example, if the user is typing into an input faster than a chart receiving its deferred value can re-render, the chart will only re-render after the user stops typing.\n\nuseDeferredValue is integrated with <Suspense>. If the background update caused by a new value suspends the UI, the user will not see the fallback. They will see the old deferred value until the data loads.\n\nuseDeferredValue does not by itself prevent extra network requests.\n\nThere is no fixed delay caused by useDeferredValue itself. As soon as React finishes the original re-render, React will immediately start working on the background re-render with the new deferred value. Any updates caused by events (like typing) will interrupt the background re-render and get prioritized over it.\n\nThe background re-render caused by useDeferredValue does not fire Effects until it’s committed to the screen. If the background re-render suspends, its Effects will run after the data loads and the UI updates.\n\nUsage \nShowing stale content while fresh content is loading \n\nCall useDeferredValue at the top level of your component to defer updating some part of your UI.\n\nimport { useState, useDeferredValue } from 'react';\n\n\n\nfunction SearchPage() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  // ...\n\n}\n\nDuring the initial render, the deferred value will be the same as the value you provided.\n\nDuring updates, the deferred value will “lag behind” the latest value. In particular, React will first re-render without updating the deferred value, and then try to re-render with the newly received value in the background.\n\nLet’s walk through an example to see when this is useful.\n\nNote\n\nThis example assumes you use a Suspense-enabled data source:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a Promise with use\n\nLearn more about Suspense and its limitations.\n\nIn this example, the SearchResults component suspends while fetching the search results. Try typing \"a\", waiting for the results, and then editing it to \"ab\". The results for \"a\" get replaced by the loading fallback.\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <SearchResults query={query} />\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nA common alternative UI pattern is to defer updating the list of results and to keep showing the previous results until the new results are ready. Call useDeferredValue to pass a deferred version of the query down:\n\nexport default function App() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  return (\n\n    <>\n\n      <label>\n\n        Search albums:\n\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n\n      </label>\n\n      <Suspense fallback={<h2>Loading...</h2>}>\n\n        <SearchResults query={deferredQuery} />\n\n      </Suspense>\n\n    </>\n\n  );\n\n}\n\nThe query will update immediately, so the input will display the new value. However, the deferredQuery will keep its previous value until the data has loaded, so SearchResults will show the stale results for a bit.\n\nEnter \"a\" in the example below, wait for the results to load, and then edit the input to \"ab\". Notice how instead of the Suspense fallback, you now see the stale result list until the new results have loaded:\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState, useDeferredValue } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  const deferredQuery = useDeferredValue(query);\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <SearchResults query={deferredQuery} />\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\nDEEP DIVE\nHow does deferring a value work under the hood? \nShow Details\nIndicating that the content is stale \n\nIn the example above, there is no indication that the result list for the latest query is still loading. This can be confusing to the user if the new results take a while to load. To make it more obvious to the user that the result list does not match the latest query, you can add a visual indication when the stale result list is displayed:\n\n<div style={{\n\n  opacity: query !== deferredQuery ? 0.5 : 1,\n\n}}>\n\n  <SearchResults query={deferredQuery} />\n\n</div>\n\nWith this change, as soon as you start typing, the stale result list gets slightly dimmed until the new result list loads. You can also add a CSS transition to delay dimming so that it feels gradual, like in the example below:\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState, useDeferredValue } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  const deferredQuery = useDeferredValue(query);\n  const isStale = query !== deferredQuery;\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <div style={{\n          opacity: isStale ? 0.5 : 1,\n          transition: isStale ? 'opacity 0.2s 0.2s linear' : 'opacity 0s 0s linear'\n        }}>\n          <SearchResults query={deferredQuery} />\n        </div>\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\nDeferring re-rendering for a part of the UI \n\nYou can also apply useDeferredValue as a performance optimization. It is useful when a part of your UI is slow to re-render, there’s no easy way to optimize it, and you want to prevent it from blocking the rest of the UI.\n\nImagine you have a text field and a component (like a chart or a long list) that re-renders on every keystroke:\n\nfunction App() {\n\n  const [text, setText] = useState('');\n\n  return (\n\n    <>\n\n      <input value={text} onChange={e => setText(e.target.value)} />\n\n      <SlowList text={text} />\n\n    </>\n\n  );\n\n}\n\nFirst, optimize SlowList to skip re-rendering when its props are the same. To do this, wrap it in memo:\n\nconst SlowList = memo(function SlowList({ text }) {\n\n  // ...\n\n});\n\nHowever, this only helps if the SlowList props are the same as during the previous render. The problem you’re facing now is that it’s slow when they’re different, and when you actually need to show different visual output.\n\nConcretely, the main performance problem is that whenever you type into the input, the SlowList receives new props, and re-rendering its entire tree makes the typing feel janky. In this case, useDeferredValue lets you prioritize updating the input (which must be fast) over updating the result list (which is allowed to be slower):\n\nfunction App() {\n\n  const [text, setText] = useState('');\n\n  const deferredText = useDeferredValue(text);\n\n  return (\n\n    <>\n\n      <input value={text} onChange={e => setText(e.target.value)} />\n\n      <SlowList text={deferredText} />\n\n    </>\n\n  );\n\n}\n\nThis does not make re-rendering of the SlowList faster. However, it tells React that re-rendering the list can be deprioritized so that it doesn’t block the keystrokes. The list will “lag behind” the input and then “catch up”. Like before, React will attempt to update the list as soon as possible, but will not block the user from typing.\n\nThe difference between useDeferredValue and unoptimized re-rendering\n1. Deferred re-rendering of the list\n2. Unoptimized re-rendering of the list\nExample 1 of 2: Deferred re-rendering of the list \n\nIn this example, each item in the SlowList component is artificially slowed down so that you can see how useDeferredValue lets you keep the input responsive. Type into the input and notice that typing feels snappy while the list “lags behind” it.\n\nApp.js\nSlowList.js\nReload\nClear\nFork\nimport { useState, useDeferredValue } from 'react';\nimport SlowList from './SlowList.js';\n\nexport default function App() {\n  const [text, setText] = useState('');\n  const deferredText = useDeferredValue(text);\n  return (\n    <>\n      <input value={text} onChange={e => setText(e.target.value)} />\n      <SlowList text={deferredText} />\n    </>\n  );\n}\n\n\nNext Example\nPitfall\n\nThis optimization requires SlowList to be wrapped in memo. This is because whenever the text changes, React needs to be able to re-render the parent component quickly. During that re-render, deferredText still has its previous value, so SlowList is able to skip re-rendering (its props have not changed). Without memo, it would have to re-render anyway, defeating the point of the optimization.\n\nDEEP DIVE\nHow is deferring a value different from debouncing and throttling? \nShow Details\nPREVIOUS\nuseDebugValue\nNEXT\nuseEffect"
  },
  {
    "title": "useDebugValue – React",
    "url": "https://react.dev/reference/react/useDebugValue",
    "html": "API REFERENCE\nHOOKS\nuseDebugValue\n\nuseDebugValue is a React Hook that lets you add a label to a custom Hook in React DevTools.\n\nuseDebugValue(value, format?)\nReference\nuseDebugValue(value, format?)\nUsage\nAdding a label to a custom Hook\nDeferring formatting of a debug value\nReference \nuseDebugValue(value, format?) \n\nCall useDebugValue at the top level of your custom Hook to display a readable debug value:\n\nimport { useDebugValue } from 'react';\n\n\n\nfunction useOnlineStatus() {\n\n  // ...\n\n  useDebugValue(isOnline ? 'Online' : 'Offline');\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \nvalue: The value you want to display in React DevTools. It can have any type.\noptional format: A formatting function. When the component is inspected, React DevTools will call the formatting function with the value as the argument, and then display the returned formatted value (which may have any type). If you don’t specify the formatting function, the original value itself will be displayed.\nReturns \n\nuseDebugValue does not return anything.\n\nUsage \nAdding a label to a custom Hook \n\nCall useDebugValue at the top level of your custom Hook to display a readable debug value for React DevTools.\n\nimport { useDebugValue } from 'react';\n\n\n\nfunction useOnlineStatus() {\n\n  // ...\n\n  useDebugValue(isOnline ? 'Online' : 'Offline');\n\n  // ...\n\n}\n\nThis gives components calling useOnlineStatus a label like OnlineStatus: \"Online\" when you inspect them:\n\nWithout the useDebugValue call, only the underlying data (in this example, true) would be displayed.\n\nApp.js\nuseOnlineStatus.js\nReload\nClear\nFork\nimport { useSyncExternalStore, useDebugValue } from 'react';\n\nexport function useOnlineStatus() {\n  const isOnline = useSyncExternalStore(subscribe, () => navigator.onLine, () => true);\n  useDebugValue(isOnline ? 'Online' : 'Offline');\n  return isOnline;\n}\n\nfunction subscribe(callback) {\n  window.addEventListener('online', callback);\n  window.addEventListener('offline', callback);\n  return () => {\n    window.removeEventListener('online', callback);\n    window.removeEventListener('offline', callback);\n  };\n}\n\n\nShow more\nNote\n\nDon’t add debug values to every custom Hook. It’s most valuable for custom Hooks that are part of shared libraries and that have a complex internal data structure that’s difficult to inspect.\n\nDeferring formatting of a debug value \n\nYou can also pass a formatting function as the second argument to useDebugValue:\n\nuseDebugValue(date, date => date.toDateString());\n\nYour formatting function will receive the debug value as a parameter and should return a formatted display value. When your component is inspected, React DevTools will call this function and display its result.\n\nThis lets you avoid running potentially expensive formatting logic unless the component is actually inspected. For example, if date is a Date value, this avoids calling toDateString() on it for every render.\n\nPREVIOUS\nuseContext\nNEXT\nuseDeferredValue"
  },
  {
    "title": "useEffect – React",
    "url": "https://react.dev/reference/react/useEffect",
    "html": "API REFERENCE\nHOOKS\nuseEffect\n\nuseEffect is a React Hook that lets you synchronize a component with an external system.\n\nuseEffect(setup, dependencies?)\nReference\nuseEffect(setup, dependencies?)\nUsage\nConnecting to an external system\nWrapping Effects in custom Hooks\nControlling a non-React widget\nFetching data with Effects\nSpecifying reactive dependencies\nUpdating state based on previous state from an Effect\nRemoving unnecessary object dependencies\nRemoving unnecessary function dependencies\nReading the latest props and state from an Effect\nDisplaying different content on the server and the client\nTroubleshooting\nMy Effect runs twice when the component mounts\nMy Effect runs after every re-render\nMy Effect keeps re-running in an infinite cycle\nMy cleanup logic runs even though my component didn’t unmount\nMy Effect does something visual, and I see a flicker before it runs\nReference \nuseEffect(setup, dependencies?) \n\nCall useEffect at the top level of your component to declare an Effect:\n\nimport { useState, useEffect } from 'react';\n\nimport { createConnection } from './chat.js';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => {\n\n      connection.disconnect();\n\n    };\n\n  }, [serverUrl, roomId]);\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \n\nsetup: The function with your Effect’s logic. Your setup function may also optionally return a cleanup function. When your component is added to the DOM, React will run your setup function. After every re-render with changed dependencies, React will first run the cleanup function (if you provided it) with the old values, and then run your setup function with the new values. After your component is removed from the DOM, React will run your cleanup function.\n\noptional dependencies: The list of all reactive values referenced inside of the setup code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison. If you omit this argument, your Effect will re-run after every re-render of the component. See the difference between passing an array of dependencies, an empty array, and no dependencies at all.\n\nReturns \n\nuseEffect returns undefined.\n\nCaveats \n\nuseEffect is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\n\nIf you’re not trying to synchronize with some external system, you probably don’t need an Effect.\n\nWhen Strict Mode is on, React will run one extra development-only setup+cleanup cycle before the first real setup. This is a stress-test that ensures that your cleanup logic “mirrors” your setup logic and that it stops or undoes whatever the setup is doing. If this causes a problem, implement the cleanup function.\n\nIf some of your dependencies are objects or functions defined inside the component, there is a risk that they will cause the Effect to re-run more often than needed. To fix this, remove unnecessary object and function dependencies. You can also extract state updates and non-reactive logic outside of your Effect.\n\nIf your Effect wasn’t caused by an interaction (like a click), React will generally let the browser paint the updated screen first before running your Effect. If your Effect is doing something visual (for example, positioning a tooltip), and the delay is noticeable (for example, it flickers), replace useEffect with useLayoutEffect.\n\nIf your Effect is caused by an interaction (like a click), React may run your Effect before the browser paints the updated screen. This ensures that the result of the Effect can be observed by the event system. Usually, this works as expected. However, if you must defer the work until after paint, such as an alert(), you can use setTimeout. See reactwg/react-18/128 for more information.\n\nEven if your Effect was caused by an interaction (like a click), React may allow the browser to repaint the screen before processing the state updates inside your Effect. Usually, this works as expected. However, if you must block the browser from repainting the screen, you need to replace useEffect with useLayoutEffect.\n\nEffects only run on the client. They don’t run during server rendering.\n\nUsage \nConnecting to an external system \n\nSome components need to stay connected to the network, some browser API, or a third-party library, while they are displayed on the page. These systems aren’t controlled by React, so they are called external.\n\nTo connect your component to some external system, call useEffect at the top level of your component:\n\nimport { useState, useEffect } from 'react';\n\nimport { createConnection } from './chat.js';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useEffect(() => {\n\n  \tconst connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n  \treturn () => {\n\n      connection.disconnect();\n\n  \t};\n\n  }, [serverUrl, roomId]);\n\n  // ...\n\n}\n\nYou need to pass two arguments to useEffect:\n\nA setup function with setup code that connects to that system.\nIt should return a cleanup function with cleanup code that disconnects from that system.\nA list of dependencies including every value from your component used inside of those functions.\n\nReact calls your setup and cleanup functions whenever it’s necessary, which may happen multiple times:\n\nYour setup code runs when your component is added to the page (mounts).\nAfter every re-render of your component where the dependencies have changed:\nFirst, your cleanup code runs with the old props and state.\nThen, your setup code runs with the new props and state.\nYour cleanup code runs one final time after your component is removed from the page (unmounts).\n\nLet’s illustrate this sequence for the example above.\n\nWhen the ChatRoom component above gets added to the page, it will connect to the chat room with the initial serverUrl and roomId. If either serverUrl or roomId change as a result of a re-render (say, if the user picks a different chat room in a dropdown), your Effect will disconnect from the previous room, and connect to the next one. When the ChatRoom component is removed from the page, your Effect will disconnect one last time.\n\nTo help you find bugs, in development React runs setup and cleanup one extra time before the setup. This is a stress-test that verifies your Effect’s logic is implemented correctly. If this causes visible issues, your cleanup function is missing some logic. The cleanup function should stop or undo whatever the setup function was doing. The rule of thumb is that the user shouldn’t be able to distinguish between the setup being called once (as in production) and a setup → cleanup → setup sequence (as in development). See common solutions.\n\nTry to write every Effect as an independent process and think about a single setup/cleanup cycle at a time. It shouldn’t matter whether your component is mounting, updating, or unmounting. When your cleanup logic correctly “mirrors” the setup logic, your Effect is resilient to running setup and cleanup as often as needed.\n\nNote\n\nAn Effect lets you keep your component synchronized with some external system (like a chat service). Here, external system means any piece of code that’s not controlled by React, such as:\n\nA timer managed with setInterval() and clearInterval().\nAn event subscription using window.addEventListener() and window.removeEventListener().\nA third-party animation library with an API like animation.start() and animation.reset().\n\nIf you’re not connecting to any external system, you probably don’t need an Effect.\n\nExamples of connecting to an external system\n1. Connecting to a chat server\n2. Listening to a global browser event\n3. Triggering an animation\n4. Controlling a modal dialog\n5. Tracking element visibility\nExample 1 of 5: Connecting to a chat server \n\nIn this example, the ChatRoom component uses an Effect to stay connected to an external system defined in chat.js. Press “Open chat” to make the ChatRoom component appear. This sandbox runs in development mode, so there is an extra connect-and-disconnect cycle, as explained here. Try changing the roomId and serverUrl using the dropdown and the input, and see how the Effect re-connects to the chat. Press “Close chat” to see the Effect disconnect one last time.\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nfunction ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  useEffect(() => {\n    const connection = createConnection(serverUrl, roomId);\n    connection.connect();\n    return () => {\n      connection.disconnect();\n    };\n  }, [roomId, serverUrl]);\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  const [show, setShow] = useState(false);\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <button onClick={() => setShow(!show)}>\n        {show ? 'Close chat' : 'Open chat'}\n      </button>\n      {show && <hr />}\n      {show && <ChatRoom roomId={roomId} />}\n    </>\n  );\n}\n\n\nShow more\nNext Example\nWrapping Effects in custom Hooks \n\nEffects are an “escape hatch”: you use them when you need to “step outside React” and when there is no better built-in solution for your use case. If you find yourself often needing to manually write Effects, it’s usually a sign that you need to extract some custom Hooks for common behaviors your components rely on.\n\nFor example, this useChatRoom custom Hook “hides” the logic of your Effect behind a more declarative API:\n\nfunction useChatRoom({ serverUrl, roomId }) {\n\n  useEffect(() => {\n\n    const options = {\n\n      serverUrl: serverUrl,\n\n      roomId: roomId\n\n    };\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId, serverUrl]);\n\n}\n\nThen you can use it from any component like this:\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useChatRoom({\n\n    roomId: roomId,\n\n    serverUrl: serverUrl\n\n  });\n\n  // ...\n\nThere are also many excellent custom Hooks for every purpose available in the React ecosystem.\n\nLearn more about wrapping Effects in custom Hooks.\n\nExamples of wrapping Effects in custom Hooks\n1. Custom useChatRoom Hook\n2. Custom useWindowListener Hook\n3. Custom useIntersectionObserver Hook\nExample 1 of 3: Custom useChatRoom Hook \n\nThis example is identical to one of the earlier examples, but the logic is extracted to a custom Hook.\n\nApp.js\nuseChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport { useChatRoom } from './useChatRoom.js';\n\nfunction ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  useChatRoom({\n    roomId: roomId,\n    serverUrl: serverUrl\n  });\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  const [show, setShow] = useState(false);\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <button onClick={() => setShow(!show)}>\n        {show ? 'Close chat' : 'Open chat'}\n      </button>\n      {show && <hr />}\n      {show && <ChatRoom roomId={roomId} />}\n    </>\n  );\n}\n\n\nShow more\nNext Example\nControlling a non-React widget \n\nSometimes, you want to keep an external system synchronized to some prop or state of your component.\n\nFor example, if you have a third-party map widget or a video player component written without React, you can use an Effect to call methods on it that make its state match the current state of your React component. This Effect creates an instance of a MapWidget class defined in map-widget.js. When you change the zoomLevel prop of the Map component, the Effect calls the setZoom() on the class instance to keep it synchronized:\n\nApp.js\nMap.js\nmap-widget.js\nReload\nClear\nFork\nimport { useRef, useEffect } from 'react';\nimport { MapWidget } from './map-widget.js';\n\nexport default function Map({ zoomLevel }) {\n  const containerRef = useRef(null);\n  const mapRef = useRef(null);\n\n  useEffect(() => {\n    if (mapRef.current === null) {\n      mapRef.current = new MapWidget(containerRef.current);\n    }\n\n    const map = mapRef.current;\n    map.setZoom(zoomLevel);\n  }, [zoomLevel]);\n\n  return (\n    <div\n      style={{ width: 200, height: 200 }}\n      ref={containerRef}\n    />\n  );\n}\n\n\nShow more\n\nIn this example, a cleanup function is not needed because the MapWidget class manages only the DOM node that was passed to it. After the Map React component is removed from the tree, both the DOM node and the MapWidget class instance will be automatically garbage-collected by the browser JavaScript engine.\n\nFetching data with Effects \n\nYou can use an Effect to fetch data for your component. Note that if you use a framework, using your framework’s data fetching mechanism will be a lot more efficient than writing Effects manually.\n\nIf you want to fetch data from an Effect manually, your code might look like this:\n\nimport { useState, useEffect } from 'react';\n\nimport { fetchBio } from './api.js';\n\n\n\nexport default function Page() {\n\n  const [person, setPerson] = useState('Alice');\n\n  const [bio, setBio] = useState(null);\n\n\n\n  useEffect(() => {\n\n    let ignore = false;\n\n    setBio(null);\n\n    fetchBio(person).then(result => {\n\n      if (!ignore) {\n\n        setBio(result);\n\n      }\n\n    });\n\n    return () => {\n\n      ignore = true;\n\n    };\n\n  }, [person]);\n\n\n\n  // ...\n\nNote the ignore variable which is initialized to false, and is set to true during cleanup. This ensures your code doesn’t suffer from “race conditions”: network responses may arrive in a different order than you sent them.\n\nApp.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { fetchBio } from './api.js';\n\nexport default function Page() {\n  const [person, setPerson] = useState('Alice');\n  const [bio, setBio] = useState(null);\n  useEffect(() => {\n    let ignore = false;\n    setBio(null);\n    fetchBio(person).then(result => {\n      if (!ignore) {\n        setBio(result);\n      }\n    });\n    return () => {\n      ignore = true;\n    }\n  }, [person]);\n\n  return (\n    <>\n      <select value={person} onChange={e => {\n        setPerson(e.target.value);\n      }}>\n        <option value=\"Alice\">Alice</option>\n        <option value=\"Bob\">Bob</option>\n        <option value=\"Taylor\">Taylor</option>\n      </select>\n      <hr />\n      <p><i>{bio ?? 'Loading...'}</i></p>\n    </>\n  );\n}\n\n\nShow more\n\nYou can also rewrite using the async / await syntax, but you still need to provide a cleanup function:\n\nApp.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { fetchBio } from './api.js';\n\nexport default function Page() {\n  const [person, setPerson] = useState('Alice');\n  const [bio, setBio] = useState(null);\n  useEffect(() => {\n    async function startFetching() {\n      setBio(null);\n      const result = await fetchBio(person);\n      if (!ignore) {\n        setBio(result);\n      }\n    }\n\n    let ignore = false;\n    startFetching();\n    return () => {\n      ignore = true;\n    }\n  }, [person]);\n\n  return (\n    <>\n      <select value={person} onChange={e => {\n        setPerson(e.target.value);\n      }}>\n        <option value=\"Alice\">Alice</option>\n        <option value=\"Bob\">Bob</option>\n        <option value=\"Taylor\">Taylor</option>\n      </select>\n      <hr />\n      <p><i>{bio ?? 'Loading...'}</i></p>\n    </>\n  );\n}\n\n\nShow more\n\nWriting data fetching directly in Effects gets repetitive and makes it difficult to add optimizations like caching and server rendering later. It’s easier to use a custom Hook—either your own or maintained by the community.\n\nDEEP DIVE\nWhat are good alternatives to data fetching in Effects? \nShow Details\nSpecifying reactive dependencies \n\nNotice that you can’t “choose” the dependencies of your Effect. Every reactive value used by your Effect’s code must be declared as a dependency. Your Effect’s dependency list is determined by the surrounding code:\n\nfunction ChatRoom({ roomId }) { // This is a reactive value\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234'); // This is a reactive value too\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId); // This Effect reads these reactive values\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [serverUrl, roomId]); // ✅ So you must specify them as dependencies of your Effect\n\n  // ...\n\n}\n\nIf either serverUrl or roomId change, your Effect will reconnect to the chat using the new values.\n\nReactive values include props and all variables and functions declared directly inside of your component. Since roomId and serverUrl are reactive values, you can’t remove them from the dependencies. If you try to omit them and your linter is correctly configured for React, the linter will flag this as a mistake you need to fix:\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  \n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, []); // 🔴 React Hook useEffect has missing dependencies: 'roomId' and 'serverUrl'\n\n  // ...\n\n}\n\nTo remove a dependency, you need to “prove” to the linter that it doesn’t need to be a dependency. For example, you can move serverUrl out of your component to prove that it’s not reactive and won’t change on re-renders:\n\nconst serverUrl = 'https://localhost:1234'; // Not a reactive value anymore\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nNow that serverUrl is not a reactive value (and can’t change on a re-render), it doesn’t need to be a dependency. If your Effect’s code doesn’t use any reactive values, its dependency list should be empty ([]):\n\nconst serverUrl = 'https://localhost:1234'; // Not a reactive value anymore\n\nconst roomId = 'music'; // Not a reactive value anymore\n\n\n\nfunction ChatRoom() {\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, []); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nAn Effect with empty dependencies doesn’t re-run when any of your component’s props or state change.\n\nPitfall\n\nIf you have an existing codebase, you might have some Effects that suppress the linter like this:\n\nuseEffect(() => {\n\n  // ...\n\n  // 🔴 Avoid suppressing the linter like this:\n\n  // eslint-ignore-next-line react-hooks/exhaustive-deps\n\n}, []);\n\nWhen dependencies don’t match the code, there is a high risk of introducing bugs. By suppressing the linter, you “lie” to React about the values your Effect depends on. Instead, prove they’re unnecessary.\n\nExamples of passing reactive dependencies\n1. Passing a dependency array\n2. Passing an empty dependency array\n3. Passing no dependency array at all\nExample 1 of 3: Passing a dependency array \n\nIf you specify the dependencies, your Effect runs after the initial render and after re-renders with changed dependencies.\n\nuseEffect(() => {\n\n  // ...\n\n}, [a, b]); // Runs again if a or b are different\n\nIn the below example, serverUrl and roomId are reactive values, so they both must be specified as dependencies. As a result, selecting a different room in the dropdown or editing the server URL input causes the chat to re-connect. However, since message isn’t used in the Effect (and so it isn’t a dependency), editing the message doesn’t re-connect to the chat.\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nfunction ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n  const [message, setMessage] = useState('');\n\n  useEffect(() => {\n    const connection = createConnection(serverUrl, roomId);\n    connection.connect();\n    return () => {\n      connection.disconnect();\n    };\n  }, [serverUrl, roomId]);\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n      <label>\n        Your message:{' '}\n        <input value={message} onChange={e => setMessage(e.target.value)} />\n      </label>\n    </>\n  );\n}\n\nexport default function App() {\n  const [show, setShow] = useState(false);\n  const [roomId, setRoomId] = useState('general');\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n        <button onClick={() => setShow(!show)}>\n          {show ? 'Close chat' : 'Open chat'}\n        </button>\n      </label>\n      {show && <hr />}\n      {show && <ChatRoom roomId={roomId}/>}\n    </>\n  );\n}\n\n\nShow more\nNext Example\nUpdating state based on previous state from an Effect \n\nWhen you want to update state based on previous state from an Effect, you might run into a problem:\n\nfunction Counter() {\n\n  const [count, setCount] = useState(0);\n\n\n\n  useEffect(() => {\n\n    const intervalId = setInterval(() => {\n\n      setCount(count + 1); // You want to increment the counter every second...\n\n    }, 1000)\n\n    return () => clearInterval(intervalId);\n\n  }, [count]); // 🚩 ... but specifying `count` as a dependency always resets the interval.\n\n  // ...\n\n}\n\nSince count is a reactive value, it must be specified in the list of dependencies. However, that causes the Effect to cleanup and setup again every time the count changes. This is not ideal.\n\nTo fix this, pass the c => c + 1 state updater to setCount:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\n\nexport default function Counter() {\n  const [count, setCount] = useState(0);\n\n  useEffect(() => {\n    const intervalId = setInterval(() => {\n      setCount(c => c + 1); // ✅ Pass a state updater\n    }, 1000);\n    return () => clearInterval(intervalId);\n  }, []); // ✅ Now count is not a dependency\n\n  return <h1>{count}</h1>;\n}\n\n\n\nNow that you’re passing c => c + 1 instead of count + 1, your Effect no longer needs to depend on count. As a result of this fix, it won’t need to cleanup and setup the interval again every time the count changes.\n\nRemoving unnecessary object dependencies \n\nIf your Effect depends on an object or a function created during rendering, it might run too often. For example, this Effect re-connects after every render because the options object is different for every render:\n\nconst serverUrl = 'https://localhost:1234';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const options = { // 🚩 This object is created from scratch on every re-render\n\n    serverUrl: serverUrl,\n\n    roomId: roomId\n\n  };\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(options); // It's used inside the Effect\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [options]); // 🚩 As a result, these dependencies are always different on a re-render\n\n  // ...\n\nAvoid using an object created during rendering as a dependency. Instead, create the object inside the Effect:\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nconst serverUrl = 'https://localhost:1234';\n\nfunction ChatRoom({ roomId }) {\n  const [message, setMessage] = useState('');\n\n  useEffect(() => {\n    const options = {\n      serverUrl: serverUrl,\n      roomId: roomId\n    };\n    const connection = createConnection(options);\n    connection.connect();\n    return () => connection.disconnect();\n  }, [roomId]);\n\n  return (\n    <>\n      <h1>Welcome to the {roomId} room!</h1>\n      <input value={message} onChange={e => setMessage(e.target.value)} />\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <hr />\n      <ChatRoom roomId={roomId} />\n    </>\n  );\n}\n\n\nShow more\n\nNow that you create the options object inside the Effect, the Effect itself only depends on the roomId string.\n\nWith this fix, typing into the input doesn’t reconnect the chat. Unlike an object which gets re-created, a string like roomId doesn’t change unless you set it to another value. Read more about removing dependencies.\n\nRemoving unnecessary function dependencies \n\nIf your Effect depends on an object or a function created during rendering, it might run too often. For example, this Effect re-connects after every render because the createOptions function is different for every render:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  function createOptions() { // 🚩 This function is created from scratch on every re-render\n\n    return {\n\n      serverUrl: serverUrl,\n\n      roomId: roomId\n\n    };\n\n  }\n\n\n\n  useEffect(() => {\n\n    const options = createOptions(); // It's used inside the Effect\n\n    const connection = createConnection();\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [createOptions]); // 🚩 As a result, these dependencies are always different on a re-render\n\n  // ...\n\nBy itself, creating a function from scratch on every re-render is not a problem. You don’t need to optimize that. However, if you use it as a dependency of your Effect, it will cause your Effect to re-run after every re-render.\n\nAvoid using a function created during rendering as a dependency. Instead, declare it inside the Effect:\n\nApp.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nconst serverUrl = 'https://localhost:1234';\n\nfunction ChatRoom({ roomId }) {\n  const [message, setMessage] = useState('');\n\n  useEffect(() => {\n    function createOptions() {\n      return {\n        serverUrl: serverUrl,\n        roomId: roomId\n      };\n    }\n\n    const options = createOptions();\n    const connection = createConnection(options);\n    connection.connect();\n    return () => connection.disconnect();\n  }, [roomId]);\n\n  return (\n    <>\n      <h1>Welcome to the {roomId} room!</h1>\n      <input value={message} onChange={e => setMessage(e.target.value)} />\n    </>\n  );\n}\n\nexport default function App() {\n  const [roomId, setRoomId] = useState('general');\n  return (\n    <>\n      <label>\n        Choose the chat room:{' '}\n        <select\n          value={roomId}\n          onChange={e => setRoomId(e.target.value)}\n        >\n          <option value=\"general\">general</option>\n          <option value=\"travel\">travel</option>\n          <option value=\"music\">music</option>\n        </select>\n      </label>\n      <hr />\n      <ChatRoom roomId={roomId} />\n    </>\n  );\n}\n\n\nShow more\n\nNow that you define the createOptions function inside the Effect, the Effect itself only depends on the roomId string. With this fix, typing into the input doesn’t reconnect the chat. Unlike a function which gets re-created, a string like roomId doesn’t change unless you set it to another value. Read more about removing dependencies.\n\nReading the latest props and state from an Effect \n\nBy default, when you read a reactive value from an Effect, you have to add it as a dependency. This ensures that your Effect “reacts” to every change of that value. For most dependencies, that’s the behavior you want.\n\nHowever, sometimes you’ll want to read the latest props and state from an Effect without “reacting” to them. For example, imagine you want to log the number of the items in the shopping cart for every page visit:\n\nfunction Page({ url, shoppingCart }) {\n\n  useEffect(() => {\n\n    logVisit(url, shoppingCart.length);\n\n  }, [url, shoppingCart]); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nWhat if you want to log a new page visit after every url change, but not if only the shoppingCart changes? You can’t exclude shoppingCart from dependencies without breaking the reactivity rules. However, you can express that you don’t want a piece of code to “react” to changes even though it is called from inside an Effect. Declare an Effect Event with the useEffectEvent Hook, and move the code reading shoppingCart inside of it:\n\nfunction Page({ url, shoppingCart }) {\n\n  const onVisit = useEffectEvent(visitedUrl => {\n\n    logVisit(visitedUrl, shoppingCart.length)\n\n  });\n\n\n\n  useEffect(() => {\n\n    onVisit(url);\n\n  }, [url]); // ✅ All dependencies declared\n\n  // ...\n\n}\n\nEffect Events are not reactive and must always be omitted from dependencies of your Effect. This is what lets you put non-reactive code (where you can read the latest value of some props and state) inside of them. By reading shoppingCart inside of onVisit, you ensure that shoppingCart won’t re-run your Effect.\n\nRead more about how Effect Events let you separate reactive and non-reactive code.\n\nDisplaying different content on the server and the client \n\nIf your app uses server rendering (either directly or via a framework), your component will render in two different environments. On the server, it will render to produce the initial HTML. On the client, React will run the rendering code again so that it can attach your event handlers to that HTML. This is why, for hydration to work, your initial render output must be identical on the client and the server.\n\nIn rare cases, you might need to display different content on the client. For example, if your app reads some data from localStorage, it can’t possibly do that on the server. Here is how you could implement this:\n\nfunction MyComponent() {\n\n  const [didMount, setDidMount] = useState(false);\n\n\n\n  useEffect(() => {\n\n    setDidMount(true);\n\n  }, []);\n\n\n\n  if (didMount) {\n\n    // ... return client-only JSX ...\n\n  }  else {\n\n    // ... return initial JSX ...\n\n  }\n\n}\n\nWhile the app is loading, the user will see the initial render output. Then, when it’s loaded and hydrated, your Effect will run and set didMount to true, triggering a re-render. This will switch to the client-only render output. Effects don’t run on the server, so this is why didMount was false during the initial server render.\n\nUse this pattern sparingly. Keep in mind that users with a slow connection will see the initial content for quite a bit of time—potentially, many seconds—so you don’t want to make jarring changes to your component’s appearance. In many cases, you can avoid the need for this by conditionally showing different things with CSS.\n\nTroubleshooting \nMy Effect runs twice when the component mounts \n\nWhen Strict Mode is on, in development, React runs setup and cleanup one extra time before the actual setup.\n\nThis is a stress-test that verifies your Effect’s logic is implemented correctly. If this causes visible issues, your cleanup function is missing some logic. The cleanup function should stop or undo whatever the setup function was doing. The rule of thumb is that the user shouldn’t be able to distinguish between the setup being called once (as in production) and a setup → cleanup → setup sequence (as in development).\n\nRead more about how this helps find bugs and how to fix your logic.\n\nMy Effect runs after every re-render \n\nFirst, check that you haven’t forgotten to specify the dependency array:\n\nuseEffect(() => {\n\n  // ...\n\n}); // 🚩 No dependency array: re-runs after every render!\n\nIf you’ve specified the dependency array but your Effect still re-runs in a loop, it’s because one of your dependencies is different on every re-render.\n\nYou can debug this problem by manually logging your dependencies to the console:\n\n  useEffect(() => {\n\n    // ..\n\n  }, [serverUrl, roomId]);\n\n\n\n  console.log([serverUrl, roomId]);\n\nYou can then right-click on the arrays from different re-renders in the console and select “Store as a global variable” for both of them. Assuming the first one got saved as temp1 and the second one got saved as temp2, you can then use the browser console to check whether each dependency in both arrays is the same:\n\nObject.is(temp1[0], temp2[0]); // Is the first dependency the same between the arrays?\n\nObject.is(temp1[1], temp2[1]); // Is the second dependency the same between the arrays?\n\nObject.is(temp1[2], temp2[2]); // ... and so on for every dependency ...\n\nWhen you find the dependency that is different on every re-render, you can usually fix it in one of these ways:\n\nUpdating state based on previous state from an Effect\nRemoving unnecessary object dependencies\nRemoving unnecessary function dependencies\nReading the latest props and state from an Effect\n\nAs a last resort (if these methods didn’t help), wrap its creation with useMemo or useCallback (for functions).\n\nMy Effect keeps re-running in an infinite cycle \n\nIf your Effect runs in an infinite cycle, these two things must be true:\n\nYour Effect is updating some state.\nThat state leads to a re-render, which causes the Effect’s dependencies to change.\n\nBefore you start fixing the problem, ask yourself whether your Effect is connecting to some external system (like DOM, network, a third-party widget, and so on). Why does your Effect need to set state? Does it synchronize with that external system? Or are you trying to manage your application’s data flow with it?\n\nIf there is no external system, consider whether removing the Effect altogether would simplify your logic.\n\nIf you’re genuinely synchronizing with some external system, think about why and under what conditions your Effect should update the state. Has something changed that affects your component’s visual output? If you need to keep track of some data that isn’t used by rendering, a ref (which doesn’t trigger re-renders) might be more appropriate. Verify your Effect doesn’t update the state (and trigger re-renders) more than needed.\n\nFinally, if your Effect is updating the state at the right time, but there is still a loop, it’s because that state update leads to one of the Effect’s dependencies changing. Read how to debug dependency changes.\n\nMy cleanup logic runs even though my component didn’t unmount \n\nThe cleanup function runs not only during unmount, but before every re-render with changed dependencies. Additionally, in development, React runs setup+cleanup one extra time immediately after component mounts.\n\nIf you have cleanup code without corresponding setup code, it’s usually a code smell:\n\nuseEffect(() => {\n\n  // 🔴 Avoid: Cleanup logic without corresponding setup logic\n\n  return () => {\n\n    doSomething();\n\n  };\n\n}, []);\n\nYour cleanup logic should be “symmetrical” to the setup logic, and should stop or undo whatever setup did:\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => {\n\n      connection.disconnect();\n\n    };\n\n  }, [serverUrl, roomId]);\n\nLearn how the Effect lifecycle is different from the component’s lifecycle.\n\nMy Effect does something visual, and I see a flicker before it runs \n\nIf your Effect must block the browser from painting the screen, replace useEffect with useLayoutEffect. Note that this shouldn’t be needed for the vast majority of Effects. You’ll only need this if it’s crucial to run your Effect before the browser paint: for example, to measure and position a tooltip before the user sees it.\n\nPREVIOUS\nuseDeferredValue\nNEXT\nuseEffectEvent"
  },
  {
    "title": "useEffectEvent – React",
    "url": "https://react.dev/reference/react/useEffectEvent",
    "html": "API REFERENCE\nHOOKS\nuseEffectEvent\n\nuseEffectEvent is a React Hook that lets you extract non-reactive logic from your Effects into a reusable function called an Effect Event.\n\nconst onSomething = useEffectEvent(callback)\nReference\nuseEffectEvent(callback)\nUsage\nReading the latest props and state\nReference \nuseEffectEvent(callback) \n\nCall useEffectEvent at the top level of your component to declare an Effect Event. Effect Events are functions you can call inside Effects, such as useEffect:\n\nimport { useEffectEvent, useEffect } from 'react';\n\n\n\nfunction ChatRoom({ roomId, theme }) {\n\n  const onConnected = useEffectEvent(() => {\n\n    showNotification('Connected!', theme);\n\n  });\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.on('connected', () => {\n\n      onConnected();\n\n    });\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]);\n\n\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \ncallback: A function containing the logic for your Effect Event. When you define an Effect Event with useEffectEvent, the callback always accesses the latest values from props and state when it is invoked. This helps avoid issues with stale closures.\nReturns \n\nReturns an Effect Event function. You can call this function inside useEffect, useLayoutEffect, or useInsertionEffect.\n\nCaveats \nOnly call inside Effects: Effect Events should only be called within Effects. Define them just before the Effect that uses them. Do not pass them to other components or hooks. The eslint-plugin-react-hooks linter (version 6.1.1 or higher) will enforce this restriction to prevent calling Effect Events in the wrong context.\nNot a dependency shortcut: Do not use useEffectEvent to avoid specifying dependencies in your Effect’s dependency array. This can hide bugs and make your code harder to understand. Prefer explicit dependencies or use refs to compare previous values if needed.\nUse for non-reactive logic: Only use useEffectEvent to extract logic that does not depend on changing values.\nUsage \nReading the latest props and state \n\nTypically, when you access a reactive value inside an Effect, you must include it in the dependency array. This makes sure your Effect runs again whenever that value changes, which is usually the desired behavior.\n\nBut in some cases, you may want to read the most recent props or state inside an Effect without causing the Effect to re-run when those values change.\n\nTo read the latest props or state in your Effect, without making those values reactive, include them in an Effect Event.\n\nimport { useEffect, useContext, useEffectEvent } from 'react';\n\n\n\nfunction Page({ url }) {\n\n  const { items } = useContext(ShoppingCartContext);\n\n  const numberOfItems = items.length;\n\n\n\n  const onNavigate = useEffectEvent((visitedUrl) => {\n\n    logVisit(visitedUrl, numberOfItems);\n\n  });\n\n\n\n  useEffect(() => {\n\n    onNavigate(url);\n\n  }, [url]);\n\n\n\n  // ...\n\n}\n\nIn this example, the Effect should re-run after a render when url changes (to log the new page visit), but it should not re-run when numberOfItems changes. By wrapping the logging logic in an Effect Event, numberOfItems becomes non-reactive. It’s always read from the latest value without triggering the Effect.\n\nYou can pass reactive values like url as arguments to the Effect Event to keep them reactive while accessing the latest non-reactive values inside the event.\n\nPREVIOUS\nuseEffect\nNEXT\nuseId"
  },
  {
    "title": "useId – React",
    "url": "https://react.dev/reference/react/useId",
    "html": "API REFERENCE\nHOOKS\nuseId\n\nuseId is a React Hook for generating unique IDs that can be passed to accessibility attributes.\n\nconst id = useId()\nReference\nuseId()\nUsage\nGenerating unique IDs for accessibility attributes\nGenerating IDs for several related elements\nSpecifying a shared prefix for all generated IDs\nUsing the same ID prefix on the client and the server\nReference \nuseId() \n\nCall useId at the top level of your component to generate a unique ID:\n\nimport { useId } from 'react';\n\n\n\nfunction PasswordField() {\n\n  const passwordHintId = useId();\n\n  // ...\n\nSee more examples below.\n\nParameters \n\nuseId does not take any parameters.\n\nReturns \n\nuseId returns a unique ID string associated with this particular useId call in this particular component.\n\nCaveats \n\nuseId is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\n\nuseId should not be used to generate keys in a list. Keys should be generated from your data.\n\nuseId currently cannot be used in async Server Components.\n\nUsage \nPitfall\n\nDo not call useId to generate keys in a list. Keys should be generated from your data.\n\nGenerating unique IDs for accessibility attributes \n\nCall useId at the top level of your component to generate a unique ID:\n\nimport { useId } from 'react';\n\n\n\nfunction PasswordField() {\n\n  const passwordHintId = useId();\n\n  // ...\n\nYou can then pass the generated ID to different attributes:\n\n<>\n\n  <input type=\"password\" aria-describedby={passwordHintId} />\n\n  <p id={passwordHintId}>\n\n</>\n\nLet’s walk through an example to see when this is useful.\n\nHTML accessibility attributes like aria-describedby let you specify that two tags are related to each other. For example, you can specify that an element (like an input) is described by another element (like a paragraph).\n\nIn regular HTML, you would write it like this:\n\n<label>\n\n  Password:\n\n  <input\n\n    type=\"password\"\n\n    aria-describedby=\"password-hint\"\n\n  />\n\n</label>\n\n<p id=\"password-hint\">\n\n  The password should contain at least 18 characters\n\n</p>\n\nHowever, hardcoding IDs like this is not a good practice in React. A component may be rendered more than once on the page—but IDs have to be unique! Instead of hardcoding an ID, generate a unique ID with useId:\n\nimport { useId } from 'react';\n\n\n\nfunction PasswordField() {\n\n  const passwordHintId = useId();\n\n  return (\n\n    <>\n\n      <label>\n\n        Password:\n\n        <input\n\n          type=\"password\"\n\n          aria-describedby={passwordHintId}\n\n        />\n\n      </label>\n\n      <p id={passwordHintId}>\n\n        The password should contain at least 18 characters\n\n      </p>\n\n    </>\n\n  );\n\n}\n\nNow, even if PasswordField appears multiple times on the screen, the generated IDs won’t clash.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useId } from 'react';\n\nfunction PasswordField() {\n  const passwordHintId = useId();\n  return (\n    <>\n      <label>\n        Password:\n        <input\n          type=\"password\"\n          aria-describedby={passwordHintId}\n        />\n      </label>\n      <p id={passwordHintId}>\n        The password should contain at least 18 characters\n      </p>\n    </>\n  );\n}\n\nexport default function App() {\n  return (\n    <>\n      <h2>Choose password</h2>\n      <PasswordField />\n      <h2>Confirm password</h2>\n      <PasswordField />\n    </>\n  );\n}\n\n\nShow more\n\nWatch this video to see the difference in the user experience with assistive technologies.\n\nPitfall\n\nWith server rendering, useId requires an identical component tree on the server and the client. If the trees you render on the server and the client don’t match exactly, the generated IDs won’t match.\n\nDEEP DIVE\nWhy is useId better than an incrementing counter? \nShow Details\nGenerating IDs for several related elements \n\nIf you need to give IDs to multiple related elements, you can call useId to generate a shared prefix for them:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useId } from 'react';\n\nexport default function Form() {\n  const id = useId();\n  return (\n    <form>\n      <label htmlFor={id + '-firstName'}>First Name:</label>\n      <input id={id + '-firstName'} type=\"text\" />\n      <hr />\n      <label htmlFor={id + '-lastName'}>Last Name:</label>\n      <input id={id + '-lastName'} type=\"text\" />\n    </form>\n  );\n}\n\n\n\nThis lets you avoid calling useId for every single element that needs a unique ID.\n\nSpecifying a shared prefix for all generated IDs \n\nIf you render multiple independent React applications on a single page, pass identifierPrefix as an option to your createRoot or hydrateRoot calls. This ensures that the IDs generated by the two different apps never clash because every identifier generated with useId will start with the distinct prefix you’ve specified.\n\nindex.js\nindex.html\nApp.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport App from './App.js';\nimport './styles.css';\n\nconst root1 = createRoot(document.getElementById('root1'), {\n  identifierPrefix: 'my-first-app-'\n});\nroot1.render(<App />);\n\nconst root2 = createRoot(document.getElementById('root2'), {\n  identifierPrefix: 'my-second-app-'\n});\nroot2.render(<App />);\n\n\nUsing the same ID prefix on the client and the server \n\nIf you render multiple independent React apps on the same page, and some of these apps are server-rendered, make sure that the identifierPrefix you pass to the hydrateRoot call on the client side is the same as the identifierPrefix you pass to the server APIs such as renderToPipeableStream.\n\n// Server\n\nimport { renderToPipeableStream } from 'react-dom/server';\n\n\n\nconst { pipe } = renderToPipeableStream(\n\n  <App />,\n\n  { identifierPrefix: 'react-app1' }\n\n);\n// Client\n\nimport { hydrateRoot } from 'react-dom/client';\n\n\n\nconst domNode = document.getElementById('root');\n\nconst root = hydrateRoot(\n\n  domNode,\n\n  reactNode,\n\n  { identifierPrefix: 'react-app1' }\n\n);\n\nYou do not need to pass identifierPrefix if you only have one React app on the page.\n\nPREVIOUS\nuseEffectEvent\nNEXT\nuseImperativeHandle"
  },
  {
    "title": "useImperativeHandle – React",
    "url": "https://react.dev/reference/react/useImperativeHandle",
    "html": "API REFERENCE\nHOOKS\nuseImperativeHandle\n\nuseImperativeHandle is a React Hook that lets you customize the handle exposed as a ref.\n\nuseImperativeHandle(ref, createHandle, dependencies?)\nReference\nuseImperativeHandle(ref, createHandle, dependencies?)\nUsage\nExposing a custom ref handle to the parent component\nExposing your own imperative methods\nReference \nuseImperativeHandle(ref, createHandle, dependencies?) \n\nCall useImperativeHandle at the top level of your component to customize the ref handle it exposes:\n\nimport { useImperativeHandle } from 'react';\n\n\n\nfunction MyInput({ ref }) {\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      // ... your methods ...\n\n    };\n\n  }, []);\n\n  // ...\n\nSee more examples below.\n\nParameters \n\nref: The ref you received as a prop to the MyInput component.\n\ncreateHandle: A function that takes no arguments and returns the ref handle you want to expose. That ref handle can have any type. Usually, you will return an object with the methods you want to expose.\n\noptional dependencies: The list of all reactive values referenced inside of the createHandle code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison. If a re-render resulted in a change to some dependency, or if you omitted this argument, your createHandle function will re-execute, and the newly created handle will be assigned to the ref.\n\nNote\n\nStarting with React 19, ref is available as a prop. In React 18 and earlier, it was necessary to get the ref from forwardRef.\n\nReturns \n\nuseImperativeHandle returns undefined.\n\nUsage \nExposing a custom ref handle to the parent component \n\nTo expose a DOM node to the parent element, pass in the ref prop to the node.\n\nfunction MyInput({ ref }) {\n\n  return <input ref={ref} />;\n\n};\n\nWith the code above, a ref to MyInput will receive the <input> DOM node. However, you can expose a custom value instead. To customize the exposed handle, call useImperativeHandle at the top level of your component:\n\nimport { useImperativeHandle } from 'react';\n\n\n\nfunction MyInput({ ref }) {\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      // ... your methods ...\n\n    };\n\n  }, []);\n\n\n\n  return <input />;\n\n};\n\nNote that in the code above, the ref is no longer passed to the <input>.\n\nFor example, suppose you don’t want to expose the entire <input> DOM node, but you want to expose two of its methods: focus and scrollIntoView. To do this, keep the real browser DOM in a separate ref. Then use useImperativeHandle to expose a handle with only the methods that you want the parent component to call:\n\nimport { useRef, useImperativeHandle } from 'react';\n\n\n\nfunction MyInput({ ref }) {\n\n  const inputRef = useRef(null);\n\n\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      focus() {\n\n        inputRef.current.focus();\n\n      },\n\n      scrollIntoView() {\n\n        inputRef.current.scrollIntoView();\n\n      },\n\n    };\n\n  }, []);\n\n\n\n  return <input ref={inputRef} />;\n\n};\n\nNow, if the parent component gets a ref to MyInput, it will be able to call the focus and scrollIntoView methods on it. However, it will not have full access to the underlying <input> DOM node.\n\nApp.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport MyInput from './MyInput.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n    // This won't work because the DOM node isn't exposed:\n    // ref.current.style.opacity = 0.5;\n  }\n\n  return (\n    <form>\n      <MyInput placeholder=\"Enter your name\" ref={ref} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\nExposing your own imperative methods \n\nThe methods you expose via an imperative handle don’t have to match the DOM methods exactly. For example, this Post component exposes a scrollAndFocusAddComment method via an imperative handle. This lets the parent Page scroll the list of comments and focus the input field when you click the button:\n\nApp.js\nPost.js\nCommentList.js\nAddComment.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport Post from './Post.js';\n\nexport default function Page() {\n  const postRef = useRef(null);\n\n  function handleClick() {\n    postRef.current.scrollAndFocusAddComment();\n  }\n\n  return (\n    <>\n      <button onClick={handleClick}>\n        Write a comment\n      </button>\n      <Post ref={postRef} />\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\nDo not overuse refs. You should only use refs for imperative behaviors that you can’t express as props: for example, scrolling to a node, focusing a node, triggering an animation, selecting text, and so on.\n\nIf you can express something as a prop, you should not use a ref. For example, instead of exposing an imperative handle like { open, close } from a Modal component, it is better to take isOpen as a prop like <Modal isOpen={isOpen} />. Effects can help you expose imperative behaviors via props.\n\nPREVIOUS\nuseId\nNEXT\nuseInsertionEffect"
  },
  {
    "title": "useInsertionEffect – React",
    "url": "https://react.dev/reference/react/useInsertionEffect",
    "html": "API REFERENCE\nHOOKS\nuseInsertionEffect\nPitfall\n\nuseInsertionEffect is for CSS-in-JS library authors. Unless you are working on a CSS-in-JS library and need a place to inject the styles, you probably want useEffect or useLayoutEffect instead.\n\nuseInsertionEffect allows inserting elements into the DOM before any layout Effects fire.\n\nuseInsertionEffect(setup, dependencies?)\nReference\nuseInsertionEffect(setup, dependencies?)\nUsage\nInjecting dynamic styles from CSS-in-JS libraries\nReference \nuseInsertionEffect(setup, dependencies?) \n\nCall useInsertionEffect to insert styles before any Effects fire that may need to read layout:\n\nimport { useInsertionEffect } from 'react';\n\n\n\n// Inside your CSS-in-JS library\n\nfunction useCSS(rule) {\n\n  useInsertionEffect(() => {\n\n    // ... inject <style> tags here ...\n\n  });\n\n  return rule;\n\n}\n\nSee more examples below.\n\nParameters \n\nsetup: The function with your Effect’s logic. Your setup function may also optionally return a cleanup function. When your component is added to the DOM, but before any layout Effects fire, React will run your setup function. After every re-render with changed dependencies, React will first run the cleanup function (if you provided it) with the old values, and then run your setup function with the new values. When your component is removed from the DOM, React will run your cleanup function.\n\noptional dependencies: The list of all reactive values referenced inside of the setup code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison algorithm. If you don’t specify the dependencies at all, your Effect will re-run after every re-render of the component.\n\nReturns \n\nuseInsertionEffect returns undefined.\n\nCaveats \nEffects only run on the client. They don’t run during server rendering.\nYou can’t update state from inside useInsertionEffect.\nBy the time useInsertionEffect runs, refs are not attached yet.\nuseInsertionEffect may run either before or after the DOM has been updated. You shouldn’t rely on the DOM being updated at any particular time.\nUnlike other types of Effects, which fire cleanup for every Effect and then setup for every Effect, useInsertionEffect will fire both cleanup and setup one component at a time. This results in an “interleaving” of the cleanup and setup functions.\nUsage \nInjecting dynamic styles from CSS-in-JS libraries \n\nTraditionally, you would style React components using plain CSS.\n\n// In your JS file:\n\n<button className=\"success\" />\n\n\n\n// In your CSS file:\n\n.success { color: green; }\n\nSome teams prefer to author styles directly in JavaScript code instead of writing CSS files. This usually requires using a CSS-in-JS library or a tool. There are three common approaches to CSS-in-JS:\n\nStatic extraction to CSS files with a compiler\nInline styles, e.g. <div style={{ opacity: 1 }}>\nRuntime injection of <style> tags\n\nIf you use CSS-in-JS, we recommend a combination of the first two approaches (CSS files for static styles, inline styles for dynamic styles). We don’t recommend runtime <style> tag injection for two reasons:\n\nRuntime injection forces the browser to recalculate the styles a lot more often.\nRuntime injection can be very slow if it happens at the wrong time in the React lifecycle.\n\nThe first problem is not solvable, but useInsertionEffect helps you solve the second problem.\n\nCall useInsertionEffect to insert the styles before any layout Effects fire:\n\n// Inside your CSS-in-JS library\n\nlet isInserted = new Set();\n\nfunction useCSS(rule) {\n\n  useInsertionEffect(() => {\n\n    // As explained earlier, we don't recommend runtime injection of <style> tags.\n\n    // But if you have to do it, then it's important to do in useInsertionEffect.\n\n    if (!isInserted.has(rule)) {\n\n      isInserted.add(rule);\n\n      document.head.appendChild(getStyleForRule(rule));\n\n    }\n\n  });\n\n  return rule;\n\n}\n\n\n\nfunction Button() {\n\n  const className = useCSS('...');\n\n  return <div className={className} />;\n\n}\n\nSimilarly to useEffect, useInsertionEffect does not run on the server. If you need to collect which CSS rules have been used on the server, you can do it during rendering:\n\nlet collectedRulesSet = new Set();\n\n\n\nfunction useCSS(rule) {\n\n  if (typeof window === 'undefined') {\n\n    collectedRulesSet.add(rule);\n\n  }\n\n  useInsertionEffect(() => {\n\n    // ...\n\n  });\n\n  return rule;\n\n}\n\nRead more about upgrading CSS-in-JS libraries with runtime injection to useInsertionEffect.\n\nDEEP DIVE\nHow is this better than injecting styles during rendering or useLayoutEffect? \nShow Details\nPREVIOUS\nuseImperativeHandle\nNEXT\nuseLayoutEffect"
  },
  {
    "title": "useLayoutEffect – React",
    "url": "https://react.dev/reference/react/useLayoutEffect",
    "html": "API REFERENCE\nHOOKS\nuseLayoutEffect\nPitfall\n\nuseLayoutEffect can hurt performance. Prefer useEffect when possible.\n\nuseLayoutEffect is a version of useEffect that fires before the browser repaints the screen.\n\nuseLayoutEffect(setup, dependencies?)\nReference\nuseLayoutEffect(setup, dependencies?)\nUsage\nMeasuring layout before the browser repaints the screen\nTroubleshooting\nI’m getting an error: “useLayoutEffect does nothing on the server”\nReference \nuseLayoutEffect(setup, dependencies?) \n\nCall useLayoutEffect to perform the layout measurements before the browser repaints the screen:\n\nimport { useState, useRef, useLayoutEffect } from 'react';\n\n\n\nfunction Tooltip() {\n\n  const ref = useRef(null);\n\n  const [tooltipHeight, setTooltipHeight] = useState(0);\n\n\n\n  useLayoutEffect(() => {\n\n    const { height } = ref.current.getBoundingClientRect();\n\n    setTooltipHeight(height);\n\n  }, []);\n\n  // ...\n\nSee more examples below.\n\nParameters \n\nsetup: The function with your Effect’s logic. Your setup function may also optionally return a cleanup function. Before your component is added to the DOM, React will run your setup function. After every re-render with changed dependencies, React will first run the cleanup function (if you provided it) with the old values, and then run your setup function with the new values. Before your component is removed from the DOM, React will run your cleanup function.\n\noptional dependencies: The list of all reactive values referenced inside of the setup code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison. If you omit this argument, your Effect will re-run after every re-render of the component.\n\nReturns \n\nuseLayoutEffect returns undefined.\n\nCaveats \n\nuseLayoutEffect is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a component and move the Effect there.\n\nWhen Strict Mode is on, React will run one extra development-only setup+cleanup cycle before the first real setup. This is a stress-test that ensures that your cleanup logic “mirrors” your setup logic and that it stops or undoes whatever the setup is doing. If this causes a problem, implement the cleanup function.\n\nIf some of your dependencies are objects or functions defined inside the component, there is a risk that they will cause the Effect to re-run more often than needed. To fix this, remove unnecessary object and function dependencies. You can also extract state updates and non-reactive logic outside of your Effect.\n\nEffects only run on the client. They don’t run during server rendering.\n\nThe code inside useLayoutEffect and all state updates scheduled from it block the browser from repainting the screen. When used excessively, this makes your app slow. When possible, prefer useEffect.\n\nIf you trigger a state update inside useLayoutEffect, React will execute all remaining Effects immediately including useEffect.\n\nUsage \nMeasuring layout before the browser repaints the screen \n\nMost components don’t need to know their position and size on the screen to decide what to render. They only return some JSX. Then the browser calculates their layout (position and size) and repaints the screen.\n\nSometimes, that’s not enough. Imagine a tooltip that appears next to some element on hover. If there’s enough space, the tooltip should appear above the element, but if it doesn’t fit, it should appear below. In order to render the tooltip at the right final position, you need to know its height (i.e. whether it fits at the top).\n\nTo do this, you need to render in two passes:\n\nRender the tooltip anywhere (even with a wrong position).\nMeasure its height and decide where to place the tooltip.\nRender the tooltip again in the correct place.\n\nAll of this needs to happen before the browser repaints the screen. You don’t want the user to see the tooltip moving. Call useLayoutEffect to perform the layout measurements before the browser repaints the screen:\n\nfunction Tooltip() {\n\n  const ref = useRef(null);\n\n  const [tooltipHeight, setTooltipHeight] = useState(0); // You don't know real height yet\n\n\n\n  useLayoutEffect(() => {\n\n    const { height } = ref.current.getBoundingClientRect();\n\n    setTooltipHeight(height); // Re-render now that you know the real height\n\n  }, []);\n\n\n\n  // ...use tooltipHeight in the rendering logic below...\n\n}\n\nHere’s how this works step by step:\n\nTooltip renders with the initial tooltipHeight = 0 (so the tooltip may be wrongly positioned).\nReact places it in the DOM and runs the code in useLayoutEffect.\nYour useLayoutEffect measures the height of the tooltip content and triggers an immediate re-render.\nTooltip renders again with the real tooltipHeight (so the tooltip is correctly positioned).\nReact updates it in the DOM, and the browser finally displays the tooltip.\n\nHover over the buttons below and see how the tooltip adjusts its position depending on whether it fits:\n\nApp.js\nButtonWithTooltip.js\nTooltip.js\nTooltipContainer.js\nReload\nClear\nFork\nimport { useRef, useLayoutEffect, useState } from 'react';\nimport { createPortal } from 'react-dom';\nimport TooltipContainer from './TooltipContainer.js';\n\nexport default function Tooltip({ children, targetRect }) {\n  const ref = useRef(null);\n  const [tooltipHeight, setTooltipHeight] = useState(0);\n\n  useLayoutEffect(() => {\n    const { height } = ref.current.getBoundingClientRect();\n    setTooltipHeight(height);\n    console.log('Measured tooltip height: ' + height);\n  }, []);\n\n  let tooltipX = 0;\n  let tooltipY = 0;\n  if (targetRect !== null) {\n    tooltipX = targetRect.left;\n    tooltipY = targetRect.top - tooltipHeight;\n    if (tooltipY < 0) {\n      // It doesn't fit above, so place below.\n      tooltipY = targetRect.bottom;\n    }\n  }\n\n  return createPortal(\n    <TooltipContainer x={tooltipX} y={tooltipY} contentRef={ref}>\n      {children}\n    </TooltipContainer>,\n    document.body\n  );\n}\n\n\nShow more\n\nNotice that even though the Tooltip component has to render in two passes (first, with tooltipHeight initialized to 0 and then with the real measured height), you only see the final result. This is why you need useLayoutEffect instead of useEffect for this example. Let’s look at the difference in detail below.\n\nuseLayoutEffect vs useEffect\n1. useLayoutEffect blocks the browser from repainting\n2. useEffect does not block the browser\nExample 1 of 2: useLayoutEffect blocks the browser from repainting \n\nReact guarantees that the code inside useLayoutEffect and any state updates scheduled inside it will be processed before the browser repaints the screen. This lets you render the tooltip, measure it, and re-render the tooltip again without the user noticing the first extra render. In other words, useLayoutEffect blocks the browser from painting.\n\nApp.js\nButtonWithTooltip.js\nTooltip.js\nTooltipContainer.js\nReload\nClear\nFork\nimport { useRef, useLayoutEffect, useState } from 'react';\nimport { createPortal } from 'react-dom';\nimport TooltipContainer from './TooltipContainer.js';\n\nexport default function Tooltip({ children, targetRect }) {\n  const ref = useRef(null);\n  const [tooltipHeight, setTooltipHeight] = useState(0);\n\n  useLayoutEffect(() => {\n    const { height } = ref.current.getBoundingClientRect();\n    setTooltipHeight(height);\n  }, []);\n\n  let tooltipX = 0;\n  let tooltipY = 0;\n  if (targetRect !== null) {\n    tooltipX = targetRect.left;\n    tooltipY = targetRect.top - tooltipHeight;\n    if (tooltipY < 0) {\n      // It doesn't fit above, so place below.\n      tooltipY = targetRect.bottom;\n    }\n  }\n\n  return createPortal(\n    <TooltipContainer x={tooltipX} y={tooltipY} contentRef={ref}>\n      {children}\n    </TooltipContainer>,\n    document.body\n  );\n}\n\n\nShow more\nNext Example\nNote\n\nRendering in two passes and blocking the browser hurts performance. Try to avoid this when you can.\n\nTroubleshooting \nI’m getting an error: “useLayoutEffect does nothing on the server” \n\nThe purpose of useLayoutEffect is to let your component use layout information for rendering:\n\nRender the initial content.\nMeasure the layout before the browser repaints the screen.\nRender the final content using the layout information you’ve read.\n\nWhen you or your framework uses server rendering, your React app renders to HTML on the server for the initial render. This lets you show the initial HTML before the JavaScript code loads.\n\nThe problem is that on the server, there is no layout information.\n\nIn the earlier example, the useLayoutEffect call in the Tooltip component lets it position itself correctly (either above or below content) depending on the content height. If you tried to render Tooltip as a part of the initial server HTML, this would be impossible to determine. On the server, there is no layout yet! So, even if you rendered it on the server, its position would “jump” on the client after the JavaScript loads and runs.\n\nUsually, components that rely on layout information don’t need to render on the server anyway. For example, it probably doesn’t make sense to show a Tooltip during the initial render. It is triggered by a client interaction.\n\nHowever, if you’re running into this problem, you have a few different options:\n\nReplace useLayoutEffect with useEffect. This tells React that it’s okay to display the initial render result without blocking the paint (because the original HTML will become visible before your Effect runs).\n\nAlternatively, mark your component as client-only. This tells React to replace its content up to the closest <Suspense> boundary with a loading fallback (for example, a spinner or a glimmer) during server rendering.\n\nAlternatively, you can render a component with useLayoutEffect only after hydration. Keep a boolean isMounted state that’s initialized to false, and set it to true inside a useEffect call. Your rendering logic can then be like return isMounted ? <RealContent /> : <FallbackContent />. On the server and during the hydration, the user will see FallbackContent which should not call useLayoutEffect. Then React will replace it with RealContent which runs on the client only and can include useLayoutEffect calls.\n\nIf you synchronize your component with an external data store and rely on useLayoutEffect for different reasons than measuring layout, consider useSyncExternalStore instead which supports server rendering.\n\nPREVIOUS\nuseInsertionEffect\nNEXT\nuseMemo"
  },
  {
    "title": "useMemo – React",
    "url": "https://react.dev/reference/react/useMemo",
    "html": "API REFERENCE\nHOOKS\nuseMemo\n\nuseMemo is a React Hook that lets you cache the result of a calculation between re-renders.\n\nconst cachedValue = useMemo(calculateValue, dependencies)\nNote\n\nReact Compiler automatically memoizes values and functions, reducing the need for manual useMemo calls. You can use the compiler to handle memoization automatically.\n\nReference\nuseMemo(calculateValue, dependencies)\nUsage\nSkipping expensive recalculations\nSkipping re-rendering of components\nPreventing an Effect from firing too often\nMemoizing a dependency of another Hook\nMemoizing a function\nTroubleshooting\nMy calculation runs twice on every re-render\nMy useMemo call is supposed to return an object, but returns undefined\nEvery time my component renders, the calculation in useMemo re-runs\nI need to call useMemo for each list item in a loop, but it’s not allowed\nReference \nuseMemo(calculateValue, dependencies) \n\nCall useMemo at the top level of your component to cache a calculation between re-renders:\n\nimport { useMemo } from 'react';\n\n\n\nfunction TodoList({ todos, tab }) {\n\n  const visibleTodos = useMemo(\n\n    () => filterTodos(todos, tab),\n\n    [todos, tab]\n\n  );\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \n\ncalculateValue: The function calculating the value that you want to cache. It should be pure, should take no arguments, and should return a value of any type. React will call your function during the initial render. On next renders, React will return the same value again if the dependencies have not changed since the last render. Otherwise, it will call calculateValue, return its result, and store it so it can be reused later.\n\ndependencies: The list of all reactive values referenced inside of the calculateValue code. Reactive values include props, state, and all the variables and functions declared directly inside your component body. If your linter is configured for React, it will verify that every reactive value is correctly specified as a dependency. The list of dependencies must have a constant number of items and be written inline like [dep1, dep2, dep3]. React will compare each dependency with its previous value using the Object.is comparison.\n\nReturns \n\nOn the initial render, useMemo returns the result of calling calculateValue with no arguments.\n\nDuring next renders, it will either return an already stored value from the last render (if the dependencies haven’t changed), or call calculateValue again, and return the result that calculateValue has returned.\n\nCaveats \nuseMemo is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nIn Strict Mode, React will call your calculation function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your calculation function is pure (as it should be), this should not affect your logic. The result from one of the calls will be ignored.\nReact will not throw away the cached value unless there is a specific reason to do that. For example, in development, React throws away the cache when you edit the file of your component. Both in development and in production, React will throw away the cache if your component suspends during the initial mount. In the future, React may add more features that take advantage of throwing away the cache—for example, if React adds built-in support for virtualized lists in the future, it would make sense to throw away the cache for items that scroll out of the virtualized table viewport. This should be fine if you rely on useMemo solely as a performance optimization. Otherwise, a state variable or a ref may be more appropriate.\nNote\n\nCaching return values like this is also known as memoization, which is why this Hook is called useMemo.\n\nUsage \nSkipping expensive recalculations \n\nTo cache a calculation between re-renders, wrap it in a useMemo call at the top level of your component:\n\nimport { useMemo } from 'react';\n\n\n\nfunction TodoList({ todos, tab, theme }) {\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  // ...\n\n}\n\nYou need to pass two things to useMemo:\n\nA calculation function that takes no arguments, like () =>, and returns what you wanted to calculate.\nA list of dependencies including every value within your component that’s used inside your calculation.\n\nOn the initial render, the value you’ll get from useMemo will be the result of calling your calculation.\n\nOn every subsequent render, React will compare the dependencies with the dependencies you passed during the last render. If none of the dependencies have changed (compared with Object.is), useMemo will return the value you already calculated before. Otherwise, React will re-run your calculation and return the new value.\n\nIn other words, useMemo caches a calculation result between re-renders until its dependencies change.\n\nLet’s walk through an example to see when this is useful.\n\nBy default, React will re-run the entire body of your component every time that it re-renders. For example, if this TodoList updates its state or receives new props from its parent, the filterTodos function will re-run:\n\nfunction TodoList({ todos, tab, theme }) {\n\n  const visibleTodos = filterTodos(todos, tab);\n\n  // ...\n\n}\n\nUsually, this isn’t a problem because most calculations are very fast. However, if you’re filtering or transforming a large array, or doing some expensive computation, you might want to skip doing it again if data hasn’t changed. If both todos and tab are the same as they were during the last render, wrapping the calculation in useMemo like earlier lets you reuse visibleTodos you’ve already calculated before.\n\nThis type of caching is called memoization.\n\nNote\n\nYou should only rely on useMemo as a performance optimization. If your code doesn’t work without it, find the underlying problem and fix it first. Then you may add useMemo to improve performance.\n\nDEEP DIVE\nHow to tell if a calculation is expensive? \nShow Details\nDEEP DIVE\nShould you add useMemo everywhere? \nShow Details\nThe difference between useMemo and calculating a value directly\n1. Skipping recalculation with useMemo\n2. Always recalculating a value\nExample 1 of 2: Skipping recalculation with useMemo \n\nIn this example, the filterTodos implementation is artificially slowed down so that you can see what happens when some JavaScript function you’re calling during rendering is genuinely slow. Try switching the tabs and toggling the theme.\n\nSwitching the tabs feels slow because it forces the slowed down filterTodos to re-execute. That’s expected because the tab has changed, and so the entire calculation needs to re-run. (If you’re curious why it runs twice, it’s explained here.)\n\nToggle the theme. Thanks to useMemo, it’s fast despite the artificial slowdown! The slow filterTodos call was skipped because both todos and tab (which you pass as dependencies to useMemo) haven’t changed since the last render.\n\nApp.js\nTodoList.js\nutils.js\nReload\nClear\nFork\nimport { useMemo } from 'react';\nimport { filterTodos } from './utils.js'\n\nexport default function TodoList({ todos, theme, tab }) {\n  const visibleTodos = useMemo(\n    () => filterTodos(todos, tab),\n    [todos, tab]\n  );\n  return (\n    <div className={theme}>\n      <p><b>Note: <code>filterTodos</code> is artificially slowed down!</b></p>\n      <ul>\n        {visibleTodos.map(todo => (\n          <li key={todo.id}>\n            {todo.completed ?\n              <s>{todo.text}</s> :\n              todo.text\n            }\n          </li>\n        ))}\n      </ul>\n    </div>\n  );\n}\n\n\nShow more\nNext Example\nSkipping re-rendering of components \n\nIn some cases, useMemo can also help you optimize performance of re-rendering child components. To illustrate this, let’s say this TodoList component passes the visibleTodos as a prop to the child List component:\n\nexport default function TodoList({ todos, tab, theme }) {\n\n  // ...\n\n  return (\n\n    <div className={theme}>\n\n      <List items={visibleTodos} />\n\n    </div>\n\n  );\n\n}\n\nYou’ve noticed that toggling the theme prop freezes the app for a moment, but if you remove <List /> from your JSX, it feels fast. This tells you that it’s worth trying to optimize the List component.\n\nBy default, when a component re-renders, React re-renders all of its children recursively. This is why, when TodoList re-renders with a different theme, the List component also re-renders. This is fine for components that don’t require much calculation to re-render. But if you’ve verified that a re-render is slow, you can tell List to skip re-rendering when its props are the same as on last render by wrapping it in memo:\n\nimport { memo } from 'react';\n\n\n\nconst List = memo(function List({ items }) {\n\n  // ...\n\n});\n\nWith this change, List will skip re-rendering if all of its props are the same as on the last render. This is where caching the calculation becomes important! Imagine that you calculated visibleTodos without useMemo:\n\nexport default function TodoList({ todos, tab, theme }) {\n\n  // Every time the theme changes, this will be a different array...\n\n  const visibleTodos = filterTodos(todos, tab);\n\n  return (\n\n    <div className={theme}>\n\n      {/* ... so List's props will never be the same, and it will re-render every time */}\n\n      <List items={visibleTodos} />\n\n    </div>\n\n  );\n\n}\n\nIn the above example, the filterTodos function always creates a different array, similar to how the {} object literal always creates a new object. Normally, this wouldn’t be a problem, but it means that List props will never be the same, and your memo optimization won’t work. This is where useMemo comes in handy:\n\nexport default function TodoList({ todos, tab, theme }) {\n\n  // Tell React to cache your calculation between re-renders...\n\n  const visibleTodos = useMemo(\n\n    () => filterTodos(todos, tab),\n\n    [todos, tab] // ...so as long as these dependencies don't change...\n\n  );\n\n  return (\n\n    <div className={theme}>\n\n      {/* ...List will receive the same props and can skip re-rendering */}\n\n      <List items={visibleTodos} />\n\n    </div>\n\n  );\n\n}\n\nBy wrapping the visibleTodos calculation in useMemo, you ensure that it has the same value between the re-renders (until dependencies change). You don’t have to wrap a calculation in useMemo unless you do it for some specific reason. In this example, the reason is that you pass it to a component wrapped in memo, and this lets it skip re-rendering. There are a few other reasons to add useMemo which are described further on this page.\n\nDEEP DIVE\nMemoizing individual JSX nodes \nShow Details\nThe difference between skipping re-renders and always re-rendering\n1. Skipping re-rendering with useMemo and memo\n2. Always re-rendering a component\nExample 1 of 2: Skipping re-rendering with useMemo and memo \n\nIn this example, the List component is artificially slowed down so that you can see what happens when a React component you’re rendering is genuinely slow. Try switching the tabs and toggling the theme.\n\nSwitching the tabs feels slow because it forces the slowed down List to re-render. That’s expected because the tab has changed, and so you need to reflect the user’s new choice on the screen.\n\nNext, try toggling the theme. Thanks to useMemo together with memo, it’s fast despite the artificial slowdown! The List skipped re-rendering because the visibleTodos array has not changed since the last render. The visibleTodos array has not changed because both todos and tab (which you pass as dependencies to useMemo) haven’t changed since the last render.\n\nApp.js\nTodoList.js\nList.js\nutils.js\nReload\nClear\nFork\nimport { useMemo } from 'react';\nimport List from './List.js';\nimport { filterTodos } from './utils.js'\n\nexport default function TodoList({ todos, theme, tab }) {\n  const visibleTodos = useMemo(\n    () => filterTodos(todos, tab),\n    [todos, tab]\n  );\n  return (\n    <div className={theme}>\n      <p><b>Note: <code>List</code> is artificially slowed down!</b></p>\n      <List items={visibleTodos} />\n    </div>\n  );\n}\n\n\nShow more\nNext Example\nPreventing an Effect from firing too often \n\nSometimes, you might want to use a value inside an Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const options = {\n\n    serverUrl: 'https://localhost:1234',\n\n    roomId: roomId\n\n  }\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    // ...\n\nThis creates a problem. Every reactive value must be declared as a dependency of your Effect. However, if you declare options as a dependency, it will cause your Effect to constantly reconnect to the chat room:\n\n  useEffect(() => {\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [options]); // 🔴 Problem: This dependency changes on every render\n\n  // ...\n\nTo solve this, you can wrap the object you need to call from an Effect in useMemo:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  const options = useMemo(() => {\n\n    return {\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    };\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [options]); // ✅ Only changes when options changes\n\n  // ...\n\nThis ensures that the options object is the same between re-renders if useMemo returns the cached object.\n\nHowever, since useMemo is performance optimization, not a semantic guarantee, React may throw away the cached value if there is a specific reason to do that. This will also cause the effect to re-fire, so it’s even better to remove the need for a function dependency by moving your object inside the Effect:\n\nfunction ChatRoom({ roomId }) {\n\n  const [message, setMessage] = useState('');\n\n\n\n  useEffect(() => {\n\n    const options = { // ✅ No need for useMemo or object dependencies!\n\n      serverUrl: 'https://localhost:1234',\n\n      roomId: roomId\n\n    }\n\n\n\n    const connection = createConnection(options);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]); // ✅ Only changes when roomId changes\n\n  // ...\n\nNow your code is simpler and doesn’t need useMemo. Learn more about removing Effect dependencies.\n\nMemoizing a dependency of another Hook \n\nSuppose you have a calculation that depends on an object created directly in the component body:\n\nfunction Dropdown({ allItems, text }) {\n\n  const searchOptions = { matchMode: 'whole-word', text };\n\n\n\n  const visibleItems = useMemo(() => {\n\n    return searchItems(allItems, searchOptions);\n\n  }, [allItems, searchOptions]); // 🚩 Caution: Dependency on an object created in the component body\n\n  // ...\n\nDepending on an object like this defeats the point of memoization. When a component re-renders, all of the code directly inside the component body runs again. The lines of code creating the searchOptions object will also run on every re-render. Since searchOptions is a dependency of your useMemo call, and it’s different every time, React knows the dependencies are different, and recalculate searchItems every time.\n\nTo fix this, you could memoize the searchOptions object itself before passing it as a dependency:\n\nfunction Dropdown({ allItems, text }) {\n\n  const searchOptions = useMemo(() => {\n\n    return { matchMode: 'whole-word', text };\n\n  }, [text]); // ✅ Only changes when text changes\n\n\n\n  const visibleItems = useMemo(() => {\n\n    return searchItems(allItems, searchOptions);\n\n  }, [allItems, searchOptions]); // ✅ Only changes when allItems or searchOptions changes\n\n  // ...\n\nIn the example above, if the text did not change, the searchOptions object also won’t change. However, an even better fix is to move the searchOptions object declaration inside of the useMemo calculation function:\n\nfunction Dropdown({ allItems, text }) {\n\n  const visibleItems = useMemo(() => {\n\n    const searchOptions = { matchMode: 'whole-word', text };\n\n    return searchItems(allItems, searchOptions);\n\n  }, [allItems, text]); // ✅ Only changes when allItems or text changes\n\n  // ...\n\nNow your calculation depends on text directly (which is a string and can’t “accidentally” become different).\n\nMemoizing a function \n\nSuppose the Form component is wrapped in memo. You want to pass a function to it as a prop:\n\nexport default function ProductPage({ productId, referrer }) {\n\n  function handleSubmit(orderDetails) {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails\n\n    });\n\n  }\n\n\n\n  return <Form onSubmit={handleSubmit} />;\n\n}\n\nJust as {} creates a different object, function declarations like function() {} and expressions like () => {} produce a different function on every re-render. By itself, creating a new function is not a problem. This is not something to avoid! However, if the Form component is memoized, presumably you want to skip re-rendering it when no props have changed. A prop that is always different would defeat the point of memoization.\n\nTo memoize a function with useMemo, your calculation function would have to return another function:\n\nexport default function Page({ productId, referrer }) {\n\n  const handleSubmit = useMemo(() => {\n\n    return (orderDetails) => {\n\n      post('/product/' + productId + '/buy', {\n\n        referrer,\n\n        orderDetails\n\n      });\n\n    };\n\n  }, [productId, referrer]);\n\n\n\n  return <Form onSubmit={handleSubmit} />;\n\n}\n\nThis looks clunky! Memoizing functions is common enough that React has a built-in Hook specifically for that. Wrap your functions into useCallback instead of useMemo to avoid having to write an extra nested function:\n\nexport default function Page({ productId, referrer }) {\n\n  const handleSubmit = useCallback((orderDetails) => {\n\n    post('/product/' + productId + '/buy', {\n\n      referrer,\n\n      orderDetails\n\n    });\n\n  }, [productId, referrer]);\n\n\n\n  return <Form onSubmit={handleSubmit} />;\n\n}\n\nThe two examples above are completely equivalent. The only benefit to useCallback is that it lets you avoid writing an extra nested function inside. It doesn’t do anything else. Read more about useCallback.\n\nTroubleshooting \nMy calculation runs twice on every re-render \n\nIn Strict Mode, React will call some of your functions twice instead of once:\n\nfunction TodoList({ todos, tab }) {\n\n  // This component function will run twice for every render.\n\n\n\n  const visibleTodos = useMemo(() => {\n\n    // This calculation will run twice if any of the dependencies change.\n\n    return filterTodos(todos, tab);\n\n  }, [todos, tab]);\n\n\n\n  // ...\n\nThis is expected and shouldn’t break your code.\n\nThis development-only behavior helps you keep components pure. React uses the result of one of the calls, and ignores the result of the other call. As long as your component and calculation functions are pure, this shouldn’t affect your logic. However, if they are accidentally impure, this helps you notice and fix the mistake.\n\nFor example, this impure calculation function mutates an array you received as a prop:\n\n  const visibleTodos = useMemo(() => {\n\n    // 🚩 Mistake: mutating a prop\n\n    todos.push({ id: 'last', text: 'Go for a walk!' });\n\n    const filtered = filterTodos(todos, tab);\n\n    return filtered;\n\n  }, [todos, tab]);\n\nReact calls your function twice, so you’d notice the todo is added twice. Your calculation shouldn’t change any existing objects, but it’s okay to change any new objects you created during the calculation. For example, if the filterTodos function always returns a different array, you can mutate that array instead:\n\n  const visibleTodos = useMemo(() => {\n\n    const filtered = filterTodos(todos, tab);\n\n    // ✅ Correct: mutating an object you created during the calculation\n\n    filtered.push({ id: 'last', text: 'Go for a walk!' });\n\n    return filtered;\n\n  }, [todos, tab]);\n\nRead keeping components pure to learn more about purity.\n\nAlso, check out the guides on updating objects and updating arrays without mutation.\n\nMy useMemo call is supposed to return an object, but returns undefined \n\nThis code doesn’t work:\n\n  // 🔴 You can't return an object from an arrow function with () => {\n\n  const searchOptions = useMemo(() => {\n\n    matchMode: 'whole-word',\n\n    text: text\n\n  }, [text]);\n\nIn JavaScript, () => { starts the arrow function body, so the { brace is not a part of your object. This is why it doesn’t return an object, and leads to mistakes. You could fix it by adding parentheses like ({ and }):\n\n  // This works, but is easy for someone to break again\n\n  const searchOptions = useMemo(() => ({\n\n    matchMode: 'whole-word',\n\n    text: text\n\n  }), [text]);\n\nHowever, this is still confusing and too easy for someone to break by removing the parentheses.\n\nTo avoid this mistake, write a return statement explicitly:\n\n  // ✅ This works and is explicit\n\n  const searchOptions = useMemo(() => {\n\n    return {\n\n      matchMode: 'whole-word',\n\n      text: text\n\n    };\n\n  }, [text]);\nEvery time my component renders, the calculation in useMemo re-runs \n\nMake sure you’ve specified the dependency array as a second argument!\n\nIf you forget the dependency array, useMemo will re-run the calculation every time:\n\nfunction TodoList({ todos, tab }) {\n\n  // 🔴 Recalculates every time: no dependency array\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab));\n\n  // ...\n\nThis is the corrected version passing the dependency array as a second argument:\n\nfunction TodoList({ todos, tab }) {\n\n  // ✅ Does not recalculate unnecessarily\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  // ...\n\nIf this doesn’t help, then the problem is that at least one of your dependencies is different from the previous render. You can debug this problem by manually logging your dependencies to the console:\n\n  const visibleTodos = useMemo(() => filterTodos(todos, tab), [todos, tab]);\n\n  console.log([todos, tab]);\n\nYou can then right-click on the arrays from different re-renders in the console and select “Store as a global variable” for both of them. Assuming the first one got saved as temp1 and the second one got saved as temp2, you can then use the browser console to check whether each dependency in both arrays is the same:\n\nObject.is(temp1[0], temp2[0]); // Is the first dependency the same between the arrays?\n\nObject.is(temp1[1], temp2[1]); // Is the second dependency the same between the arrays?\n\nObject.is(temp1[2], temp2[2]); // ... and so on for every dependency ...\n\nWhen you find which dependency breaks memoization, either find a way to remove it, or memoize it as well.\n\nI need to call useMemo for each list item in a loop, but it’s not allowed \n\nSuppose the Chart component is wrapped in memo. You want to skip re-rendering every Chart in the list when the ReportList component re-renders. However, you can’t call useMemo in a loop:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item => {\n\n        // 🔴 You can't call useMemo in a loop like this:\n\n        const data = useMemo(() => calculateReport(item), [item]);\n\n        return (\n\n          <figure key={item.id}>\n\n            <Chart data={data} />\n\n          </figure>\n\n        );\n\n      })}\n\n    </article>\n\n  );\n\n}\n\nInstead, extract a component for each item and memoize data for individual items:\n\nfunction ReportList({ items }) {\n\n  return (\n\n    <article>\n\n      {items.map(item =>\n\n        <Report key={item.id} item={item} />\n\n      )}\n\n    </article>\n\n  );\n\n}\n\n\n\nfunction Report({ item }) {\n\n  // ✅ Call useMemo at the top level:\n\n  const data = useMemo(() => calculateReport(item), [item]);\n\n  return (\n\n    <figure>\n\n      <Chart data={data} />\n\n    </figure>\n\n  );\n\n}\n\nAlternatively, you could remove useMemo and instead wrap Report itself in memo. If the item prop does not change, Report will skip re-rendering, so Chart will skip re-rendering too:\n\nfunction ReportList({ items }) {\n\n  // ...\n\n}\n\n\n\nconst Report = memo(function Report({ item }) {\n\n  const data = calculateReport(item);\n\n  return (\n\n    <figure>\n\n      <Chart data={data} />\n\n    </figure>\n\n  );\n\n});\nPREVIOUS\nuseLayoutEffect\nNEXT\nuseOptimistic"
  },
  {
    "title": "useOptimistic – React",
    "url": "https://react.dev/reference/react/useOptimistic",
    "html": "API REFERENCE\nHOOKS\nuseOptimistic\n\nuseOptimistic is a React Hook that lets you optimistically update the UI.\n\n  const [optimisticState, addOptimistic] = useOptimistic(state, updateFn);\nReference\nuseOptimistic(state, updateFn)\nUsage\nOptimistically updating forms\nReference \nuseOptimistic(state, updateFn) \n\nuseOptimistic is a React Hook that lets you show a different state while an async action is underway. It accepts some state as an argument and returns a copy of that state that can be different during the duration of an async action such as a network request. You provide a function that takes the current state and the input to the action, and returns the optimistic state to be used while the action is pending.\n\nThis state is called the “optimistic” state because it is usually used to immediately present the user with the result of performing an action, even though the action actually takes time to complete.\n\nimport { useOptimistic } from 'react';\n\n\n\nfunction AppContainer() {\n\n  const [optimisticState, addOptimistic] = useOptimistic(\n\n    state,\n\n    // updateFn\n\n    (currentState, optimisticValue) => {\n\n      // merge and return new state\n\n      // with optimistic value\n\n    }\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \nstate: the value to be returned initially and whenever no action is pending.\nupdateFn(currentState, optimisticValue): a function that takes the current state and the optimistic value passed to addOptimistic and returns the resulting optimistic state. It must be a pure function. updateFn takes in two parameters. The currentState and the optimisticValue. The return value will be the merged value of the currentState and optimisticValue.\nReturns \noptimisticState: The resulting optimistic state. It is equal to state unless an action is pending, in which case it is equal to the value returned by updateFn.\naddOptimistic: addOptimistic is the dispatching function to call when you have an optimistic update. It takes one argument, optimisticValue, of any type and will call the updateFn with state and optimisticValue.\nUsage \nOptimistically updating forms \n\nThe useOptimistic Hook provides a way to optimistically update the user interface before a background operation, like a network request, completes. In the context of forms, this technique helps to make apps feel more responsive. When a user submits a form, instead of waiting for the server’s response to reflect the changes, the interface is immediately updated with the expected outcome.\n\nFor example, when a user types a message into the form and hits the “Send” button, the useOptimistic Hook allows the message to immediately appear in the list with a “Sending…” label, even before the message is actually sent to a server. This “optimistic” approach gives the impression of speed and responsiveness. The form then attempts to truly send the message in the background. Once the server confirms the message has been received, the “Sending…” label is removed.\n\nApp.js\nactions.js\nReload\nClear\nFork\nimport { useOptimistic, useState, useRef, startTransition } from \"react\";\nimport { deliverMessage } from \"./actions.js\";\n\nfunction Thread({ messages, sendMessageAction }) {\n  const formRef = useRef();\n  function formAction(formData) {\n    addOptimisticMessage(formData.get(\"message\"));\n    formRef.current.reset();\n    startTransition(async () => {\n      await sendMessageAction(formData);\n    });\n  }\n  const [optimisticMessages, addOptimisticMessage] = useOptimistic(\n    messages,\n    (state, newMessage) => [\n      {\n        text: newMessage,\n        sending: true\n      },\n      ...state,\n    ]\n  );\n\n  return (\n    <>\n      <form action={formAction} ref={formRef}>\n        <input type=\"text\" name=\"message\" placeholder=\"Hello!\" />\n        <button type=\"submit\">Send</button>\n      </form>\n      {optimisticMessages.map((message, index) => (\n        <div key={index}>\n          {message.text}\n          {!!message.sending && <small> (Sending...)</small>}\n        </div>\n      ))}\n      \n    </>\n  );\n}\n\nexport default function App() {\n  const [messages, setMessages] = useState([\n    { text: \"Hello there!\", sending: false, key: 1 }\n  ]);\n  async function sendMessageAction(formData) {\n    const sentMessage = await deliverMessage(formData.get(\"message\"));\n    startTransition(() => {\n      setMessages((messages) => [{ text: sentMessage }, ...messages]);\n    })\n  }\n  return <Thread messages={messages} sendMessageAction={sendMessageAction} />;\n}\n\n\nShow more\nPREVIOUS\nuseMemo\nNEXT\nuseReducer"
  },
  {
    "title": "useReducer – React",
    "url": "https://react.dev/reference/react/useReducer",
    "html": "API REFERENCE\nHOOKS\nuseReducer\n\nuseReducer is a React Hook that lets you add a reducer to your component.\n\nconst [state, dispatch] = useReducer(reducer, initialArg, init?)\nReference\nuseReducer(reducer, initialArg, init?)\ndispatch function\nUsage\nAdding a reducer to a component\nWriting the reducer function\nAvoiding recreating the initial state\nTroubleshooting\nI’ve dispatched an action, but logging gives me the old state value\nI’ve dispatched an action, but the screen doesn’t update\nA part of my reducer state becomes undefined after dispatching\nMy entire reducer state becomes undefined after dispatching\nI’m getting an error: “Too many re-renders”\nMy reducer or initializer function runs twice\nReference \nuseReducer(reducer, initialArg, init?) \n\nCall useReducer at the top level of your component to manage its state with a reducer.\n\nimport { useReducer } from 'react';\n\n\n\nfunction reducer(state, action) {\n\n  // ...\n\n}\n\n\n\nfunction MyComponent() {\n\n  const [state, dispatch] = useReducer(reducer, { age: 42 });\n\n  // ...\n\nSee more examples below.\n\nParameters \nreducer: The reducer function that specifies how the state gets updated. It must be pure, should take the state and action as arguments, and should return the next state. State and action can be of any types.\ninitialArg: The value from which the initial state is calculated. It can be a value of any type. How the initial state is calculated from it depends on the next init argument.\noptional init: The initializer function that should return the initial state. If it’s not specified, the initial state is set to initialArg. Otherwise, the initial state is set to the result of calling init(initialArg).\nReturns \n\nuseReducer returns an array with exactly two values:\n\nThe current state. During the first render, it’s set to init(initialArg) or initialArg (if there’s no init).\nThe dispatch function that lets you update the state to a different value and trigger a re-render.\nCaveats \nuseReducer is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nThe dispatch function has a stable identity, so you will often see it omitted from Effect dependencies, but including it will not cause the Effect to fire. If the linter lets you omit a dependency without errors, it is safe to do. Learn more about removing Effect dependencies.\nIn Strict Mode, React will call your reducer and initializer twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your reducer and initializer are pure (as they should be), this should not affect your logic. The result from one of the calls is ignored.\ndispatch function \n\nThe dispatch function returned by useReducer lets you update the state to a different value and trigger a re-render. You need to pass the action as the only argument to the dispatch function:\n\nconst [state, dispatch] = useReducer(reducer, { age: 42 });\n\n\n\nfunction handleClick() {\n\n  dispatch({ type: 'incremented_age' });\n\n  // ...\n\nReact will set the next state to the result of calling the reducer function you’ve provided with the current state and the action you’ve passed to dispatch.\n\nParameters \naction: The action performed by the user. It can be a value of any type. By convention, an action is usually an object with a type property identifying it and, optionally, other properties with additional information.\nReturns \n\ndispatch functions do not have a return value.\n\nCaveats \n\nThe dispatch function only updates the state variable for the next render. If you read the state variable after calling the dispatch function, you will still get the old value that was on the screen before your call.\n\nIf the new value you provide is identical to the current state, as determined by an Object.is comparison, React will skip re-rendering the component and its children. This is an optimization. React may still need to call your component before ignoring the result, but it shouldn’t affect your code.\n\nReact batches state updates. It updates the screen after all the event handlers have run and have called their set functions. This prevents multiple re-renders during a single event. In the rare case that you need to force React to update the screen earlier, for example to access the DOM, you can use flushSync.\n\nUsage \nAdding a reducer to a component \n\nCall useReducer at the top level of your component to manage state with a reducer.\n\nimport { useReducer } from 'react';\n\n\n\nfunction reducer(state, action) {\n\n  // ...\n\n}\n\n\n\nfunction MyComponent() {\n\n  const [state, dispatch] = useReducer(reducer, { age: 42 });\n\n  // ...\n\nuseReducer returns an array with exactly two items:\n\nThe current state of this state variable, initially set to the initial state you provided.\nThe dispatch function that lets you change it in response to interaction.\n\nTo update what’s on the screen, call dispatch with an object representing what the user did, called an action:\n\nfunction handleClick() {\n\n  dispatch({ type: 'incremented_age' });\n\n}\n\nReact will pass the current state and the action to your reducer function. Your reducer will calculate and return the next state. React will store that next state, render your component with it, and update the UI.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useReducer } from 'react';\n\nfunction reducer(state, action) {\n  if (action.type === 'incremented_age') {\n    return {\n      age: state.age + 1\n    };\n  }\n  throw Error('Unknown action.');\n}\n\nexport default function Counter() {\n  const [state, dispatch] = useReducer(reducer, { age: 42 });\n\n  return (\n    <>\n      <button onClick={() => {\n        dispatch({ type: 'incremented_age' })\n      }}>\n        Increment age\n      </button>\n      <p>Hello! You are {state.age}.</p>\n    </>\n  );\n}\n\n\nShow more\n\nuseReducer is very similar to useState, but it lets you move the state update logic from event handlers into a single function outside of your component. Read more about choosing between useState and useReducer.\n\nWriting the reducer function \n\nA reducer function is declared like this:\n\nfunction reducer(state, action) {\n\n  // ...\n\n}\n\nThen you need to fill in the code that will calculate and return the next state. By convention, it is common to write it as a switch statement. For each case in the switch, calculate and return some next state.\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      return {\n\n        name: state.name,\n\n        age: state.age + 1\n\n      };\n\n    }\n\n    case 'changed_name': {\n\n      return {\n\n        name: action.nextName,\n\n        age: state.age\n\n      };\n\n    }\n\n  }\n\n  throw Error('Unknown action: ' + action.type);\n\n}\n\nActions can have any shape. By convention, it’s common to pass objects with a type property identifying the action. It should include the minimal necessary information that the reducer needs to compute the next state.\n\nfunction Form() {\n\n  const [state, dispatch] = useReducer(reducer, { name: 'Taylor', age: 42 });\n\n  \n\n  function handleButtonClick() {\n\n    dispatch({ type: 'incremented_age' });\n\n  }\n\n\n\n  function handleInputChange(e) {\n\n    dispatch({\n\n      type: 'changed_name',\n\n      nextName: e.target.value\n\n    });\n\n  }\n\n  // ...\n\nThe action type names are local to your component. Each action describes a single interaction, even if that leads to multiple changes in data. The shape of the state is arbitrary, but usually it’ll be an object or an array.\n\nRead extracting state logic into a reducer to learn more.\n\nPitfall\n\nState is read-only. Don’t modify any objects or arrays in state:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // 🚩 Don't mutate an object in state like this:\n\n      state.age = state.age + 1;\n\n      return state;\n\n    }\n\nInstead, always return new objects from your reducer:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // ✅ Instead, return a new object\n\n      return {\n\n        ...state,\n\n        age: state.age + 1\n\n      };\n\n    }\n\nRead updating objects in state and updating arrays in state to learn more.\n\nBasic useReducer examples\n1. Form (object)\n2. Todo list (array)\n3. Writing concise update logic with Immer\nExample 1 of 3: Form (object) \n\nIn this example, the reducer manages a state object with two fields: name and age.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useReducer } from 'react';\n\nfunction reducer(state, action) {\n  switch (action.type) {\n    case 'incremented_age': {\n      return {\n        name: state.name,\n        age: state.age + 1\n      };\n    }\n    case 'changed_name': {\n      return {\n        name: action.nextName,\n        age: state.age\n      };\n    }\n  }\n  throw Error('Unknown action: ' + action.type);\n}\n\nconst initialState = { name: 'Taylor', age: 42 };\n\nexport default function Form() {\n  const [state, dispatch] = useReducer(reducer, initialState);\n\n  function handleButtonClick() {\n    dispatch({ type: 'incremented_age' });\n  }\n\n  function handleInputChange(e) {\n    dispatch({\n      type: 'changed_name',\n      nextName: e.target.value\n    }); \n  }\n\n  return (\n    <>\n      <input\n        value={state.name}\n        onChange={handleInputChange}\n      />\n      <button onClick={handleButtonClick}>\n        Increment age\n      </button>\n      <p>Hello, {state.name}. You are {state.age}.</p>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nAvoiding recreating the initial state \n\nReact saves the initial state once and ignores it on the next renders.\n\nfunction createInitialState(username) {\n\n  // ...\n\n}\n\n\n\nfunction TodoList({ username }) {\n\n  const [state, dispatch] = useReducer(reducer, createInitialState(username));\n\n  // ...\n\nAlthough the result of createInitialState(username) is only used for the initial render, you’re still calling this function on every render. This can be wasteful if it’s creating large arrays or performing expensive calculations.\n\nTo solve this, you may pass it as an initializer function to useReducer as the third argument instead:\n\nfunction createInitialState(username) {\n\n  // ...\n\n}\n\n\n\nfunction TodoList({ username }) {\n\n  const [state, dispatch] = useReducer(reducer, username, createInitialState);\n\n  // ...\n\nNotice that you’re passing createInitialState, which is the function itself, and not createInitialState(), which is the result of calling it. This way, the initial state does not get re-created after initialization.\n\nIn the above example, createInitialState takes a username argument. If your initializer doesn’t need any information to compute the initial state, you may pass null as the second argument to useReducer.\n\nThe difference between passing an initializer and passing the initial state directly\n1. Passing the initializer function\n2. Passing the initial state directly\nExample 1 of 2: Passing the initializer function \n\nThis example passes the initializer function, so the createInitialState function only runs during initialization. It does not run when component re-renders, such as when you type into the input.\n\nTodoList.js\nReload\nClear\nFork\nimport { useReducer } from 'react';\n\nfunction createInitialState(username) {\n  const initialTodos = [];\n  for (let i = 0; i < 50; i++) {\n    initialTodos.push({\n      id: i,\n      text: username + \"'s task #\" + (i + 1)\n    });\n  }\n  return {\n    draft: '',\n    todos: initialTodos,\n  };\n}\n\nfunction reducer(state, action) {\n  switch (action.type) {\n    case 'changed_draft': {\n      return {\n        draft: action.nextDraft,\n        todos: state.todos,\n      };\n    };\n    case 'added_todo': {\n      return {\n        draft: '',\n        todos: [{\n          id: state.todos.length,\n          text: state.draft\n        }, ...state.todos]\n      }\n    }\n  }\n  throw Error('Unknown action: ' + action.type);\n}\n\nexport default function TodoList({ username }) {\n  const [state, dispatch] = useReducer(\n    reducer,\n    username,\n    createInitialState\n  );\n  return (\n    <>\n      <input\n        value={state.draft}\n        onChange={e => {\n          dispatch({\n            type: 'changed_draft',\n            nextDraft: e.target.value\n          })\n        }}\n      />\n      <button onClick={() => {\n        dispatch({ type: 'added_todo' });\n      }}>Add</button>\n      <ul>\n        {state.todos.map(item => (\n          <li key={item.id}>\n            {item.text}\n          </li>\n        ))}\n      </ul>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nTroubleshooting \nI’ve dispatched an action, but logging gives me the old state value \n\nCalling the dispatch function does not change state in the running code:\n\nfunction handleClick() {\n\n  console.log(state.age);  // 42\n\n\n\n  dispatch({ type: 'incremented_age' }); // Request a re-render with 43\n\n  console.log(state.age);  // Still 42!\n\n\n\n  setTimeout(() => {\n\n    console.log(state.age); // Also 42!\n\n  }, 5000);\n\n}\n\nThis is because states behaves like a snapshot. Updating state requests another render with the new state value, but does not affect the state JavaScript variable in your already-running event handler.\n\nIf you need to guess the next state value, you can calculate it manually by calling the reducer yourself:\n\nconst action = { type: 'incremented_age' };\n\ndispatch(action);\n\n\n\nconst nextState = reducer(state, action);\n\nconsole.log(state);     // { age: 42 }\n\nconsole.log(nextState); // { age: 43 }\nI’ve dispatched an action, but the screen doesn’t update \n\nReact will ignore your update if the next state is equal to the previous state, as determined by an Object.is comparison. This usually happens when you change an object or an array in state directly:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // 🚩 Wrong: mutating existing object\n\n      state.age++;\n\n      return state;\n\n    }\n\n    case 'changed_name': {\n\n      // 🚩 Wrong: mutating existing object\n\n      state.name = action.nextName;\n\n      return state;\n\n    }\n\n    // ...\n\n  }\n\n}\n\nYou mutated an existing state object and returned it, so React ignored the update. To fix this, you need to ensure that you’re always updating objects in state and updating arrays in state instead of mutating them:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // ✅ Correct: creating a new object\n\n      return {\n\n        ...state,\n\n        age: state.age + 1\n\n      };\n\n    }\n\n    case 'changed_name': {\n\n      // ✅ Correct: creating a new object\n\n      return {\n\n        ...state,\n\n        name: action.nextName\n\n      };\n\n    }\n\n    // ...\n\n  }\n\n}\nA part of my reducer state becomes undefined after dispatching \n\nMake sure that every case branch copies all of the existing fields when returning the new state:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      return {\n\n        ...state, // Don't forget this!\n\n        age: state.age + 1\n\n      };\n\n    }\n\n    // ...\n\nWithout ...state above, the returned next state would only contain the age field and nothing else.\n\nMy entire reducer state becomes undefined after dispatching \n\nIf your state unexpectedly becomes undefined, you’re likely forgetting to return state in one of the cases, or your action type doesn’t match any of the case statements. To find why, throw an error outside the switch:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'incremented_age': {\n\n      // ...\n\n    }\n\n    case 'edited_name': {\n\n      // ...\n\n    }\n\n  }\n\n  throw Error('Unknown action: ' + action.type);\n\n}\n\nYou can also use a static type checker like TypeScript to catch such mistakes.\n\nI’m getting an error: “Too many re-renders” \n\nYou might get an error that says: Too many re-renders. React limits the number of renders to prevent an infinite loop. Typically, this means that you’re unconditionally dispatching an action during render, so your component enters a loop: render, dispatch (which causes a render), render, dispatch (which causes a render), and so on. Very often, this is caused by a mistake in specifying an event handler:\n\n// 🚩 Wrong: calls the handler during render\n\nreturn <button onClick={handleClick()}>Click me</button>\n\n\n\n// ✅ Correct: passes down the event handler\n\nreturn <button onClick={handleClick}>Click me</button>\n\n\n\n// ✅ Correct: passes down an inline function\n\nreturn <button onClick={(e) => handleClick(e)}>Click me</button>\n\nIf you can’t find the cause of this error, click on the arrow next to the error in the console and look through the JavaScript stack to find the specific dispatch function call responsible for the error.\n\nMy reducer or initializer function runs twice \n\nIn Strict Mode, React will call your reducer and initializer functions twice. This shouldn’t break your code.\n\nThis development-only behavior helps you keep components pure. React uses the result of one of the calls, and ignores the result of the other call. As long as your component, initializer, and reducer functions are pure, this shouldn’t affect your logic. However, if they are accidentally impure, this helps you notice the mistakes.\n\nFor example, this impure reducer function mutates an array in state:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'added_todo': {\n\n      // 🚩 Mistake: mutating state\n\n      state.todos.push({ id: nextId++, text: action.text });\n\n      return state;\n\n    }\n\n    // ...\n\n  }\n\n}\n\nBecause React calls your reducer function twice, you’ll see the todo was added twice, so you’ll know that there is a mistake. In this example, you can fix the mistake by replacing the array instead of mutating it:\n\nfunction reducer(state, action) {\n\n  switch (action.type) {\n\n    case 'added_todo': {\n\n      // ✅ Correct: replacing with new state\n\n      return {\n\n        ...state,\n\n        todos: [\n\n          ...state.todos,\n\n          { id: nextId++, text: action.text }\n\n        ]\n\n      };\n\n    }\n\n    // ...\n\n  }\n\n}\n\nNow that this reducer function is pure, calling it an extra time doesn’t make a difference in behavior. This is why React calling it twice helps you find mistakes. Only component, initializer, and reducer functions need to be pure. Event handlers don’t need to be pure, so React will never call your event handlers twice.\n\nRead keeping components pure to learn more.\n\nPREVIOUS\nuseOptimistic\nNEXT\nuseRef"
  },
  {
    "title": "useRef – React",
    "url": "https://react.dev/reference/react/useRef",
    "html": "API REFERENCE\nHOOKS\nuseRef\n\nuseRef is a React Hook that lets you reference a value that’s not needed for rendering.\n\nconst ref = useRef(initialValue)\nReference\nuseRef(initialValue)\nUsage\nReferencing a value with a ref\nManipulating the DOM with a ref\nAvoiding recreating the ref contents\nTroubleshooting\nI can’t get a ref to a custom component\nReference \nuseRef(initialValue) \n\nCall useRef at the top level of your component to declare a ref.\n\nimport { useRef } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const intervalRef = useRef(0);\n\n  const inputRef = useRef(null);\n\n  // ...\n\nSee more examples below.\n\nParameters \ninitialValue: The value you want the ref object’s current property to be initially. It can be a value of any type. This argument is ignored after the initial render.\nReturns \n\nuseRef returns an object with a single property:\n\ncurrent: Initially, it’s set to the initialValue you have passed. You can later set it to something else. If you pass the ref object to React as a ref attribute to a JSX node, React will set its current property.\n\nOn the next renders, useRef will return the same object.\n\nCaveats \nYou can mutate the ref.current property. Unlike state, it is mutable. However, if it holds an object that is used for rendering (for example, a piece of your state), then you shouldn’t mutate that object.\nWhen you change the ref.current property, React does not re-render your component. React is not aware of when you change it because a ref is a plain JavaScript object.\nDo not write or read ref.current during rendering, except for initialization. This makes your component’s behavior unpredictable.\nIn Strict Mode, React will call your component function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. Each ref object will be created twice, but one of the versions will be discarded. If your component function is pure (as it should be), this should not affect the behavior.\nUsage \nReferencing a value with a ref \n\nCall useRef at the top level of your component to declare one or more refs.\n\nimport { useRef } from 'react';\n\n\n\nfunction Stopwatch() {\n\n  const intervalRef = useRef(0);\n\n  // ...\n\nuseRef returns a ref object with a single current property initially set to the initial value you provided.\n\nOn the next renders, useRef will return the same object. You can change its current property to store information and read it later. This might remind you of state, but there is an important difference.\n\nChanging a ref does not trigger a re-render. This means refs are perfect for storing information that doesn’t affect the visual output of your component. For example, if you need to store an interval ID and retrieve it later, you can put it in a ref. To update the value inside the ref, you need to manually change its current property:\n\nfunction handleStartClick() {\n\n  const intervalId = setInterval(() => {\n\n    // ...\n\n  }, 1000);\n\n  intervalRef.current = intervalId;\n\n}\n\nLater, you can read that interval ID from the ref so that you can call clear that interval:\n\nfunction handleStopClick() {\n\n  const intervalId = intervalRef.current;\n\n  clearInterval(intervalId);\n\n}\n\nBy using a ref, you ensure that:\n\nYou can store information between re-renders (unlike regular variables, which reset on every render).\nChanging it does not trigger a re-render (unlike state variables, which trigger a re-render).\nThe information is local to each copy of your component (unlike the variables outside, which are shared).\n\nChanging a ref does not trigger a re-render, so refs are not appropriate for storing information you want to display on the screen. Use state for that instead. Read more about choosing between useRef and useState.\n\nExamples of referencing a value with useRef\n1. Click counter\n2. A stopwatch\nExample 1 of 2: Click counter \n\nThis component uses a ref to keep track of how many times the button was clicked. Note that it’s okay to use a ref instead of state here because the click count is only read and written in an event handler.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useRef } from 'react';\n\nexport default function Counter() {\n  let ref = useRef(0);\n\n  function handleClick() {\n    ref.current = ref.current + 1;\n    alert('You clicked ' + ref.current + ' times!');\n  }\n\n  return (\n    <button onClick={handleClick}>\n      Click me!\n    </button>\n  );\n}\n\n\nShow more\n\nIf you show {ref.current} in the JSX, the number won’t update on click. This is because setting ref.current does not trigger a re-render. Information that’s used for rendering should be state instead.\n\nNext Example\nPitfall\n\nDo not write or read ref.current during rendering.\n\nReact expects that the body of your component behaves like a pure function:\n\nIf the inputs (props, state, and context) are the same, it should return exactly the same JSX.\nCalling it in a different order or with different arguments should not affect the results of other calls.\n\nReading or writing a ref during rendering breaks these expectations.\n\nfunction MyComponent() {\n\n  // ...\n\n  // 🚩 Don't write a ref during rendering\n\n  myRef.current = 123;\n\n  // ...\n\n  // 🚩 Don't read a ref during rendering\n\n  return <h1>{myOtherRef.current}</h1>;\n\n}\n\nYou can read or write refs from event handlers or effects instead.\n\nfunction MyComponent() {\n\n  // ...\n\n  useEffect(() => {\n\n    // ✅ You can read or write refs in effects\n\n    myRef.current = 123;\n\n  });\n\n  // ...\n\n  function handleClick() {\n\n    // ✅ You can read or write refs in event handlers\n\n    doSomething(myOtherRef.current);\n\n  }\n\n  // ...\n\n}\n\nIf you have to read or write something during rendering, use state instead.\n\nWhen you break these rules, your component might still work, but most of the newer features we’re adding to React will rely on these expectations. Read more about keeping your components pure.\n\nManipulating the DOM with a ref \n\nIt’s particularly common to use a ref to manipulate the DOM. React has built-in support for this.\n\nFirst, declare a ref object with an initial value of null:\n\nimport { useRef } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const inputRef = useRef(null);\n\n  // ...\n\nThen pass your ref object as the ref attribute to the JSX of the DOM node you want to manipulate:\n\n  // ...\n\n  return <input ref={inputRef} />;\n\nAfter React creates the DOM node and puts it on the screen, React will set the current property of your ref object to that DOM node. Now you can access the <input>’s DOM node and call methods like focus():\n\n  function handleClick() {\n\n    inputRef.current.focus();\n\n  }\n\nReact will set the current property back to null when the node is removed from the screen.\n\nRead more about manipulating the DOM with refs.\n\nExamples of manipulating the DOM with useRef\n1. Focusing a text input\n2. Scrolling an image into view\n3. Playing and pausing a video\n4. Exposing a ref to your own component\nExample 1 of 4: Focusing a text input \n\nIn this example, clicking the button will focus the input:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useRef } from 'react';\n\nexport default function Form() {\n  const inputRef = useRef(null);\n\n  function handleClick() {\n    inputRef.current.focus();\n  }\n\n  return (\n    <>\n      <input ref={inputRef} />\n      <button onClick={handleClick}>\n        Focus the input\n      </button>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nAvoiding recreating the ref contents \n\nReact saves the initial ref value once and ignores it on the next renders.\n\nfunction Video() {\n\n  const playerRef = useRef(new VideoPlayer());\n\n  // ...\n\nAlthough the result of new VideoPlayer() is only used for the initial render, you’re still calling this function on every render. This can be wasteful if it’s creating expensive objects.\n\nTo solve it, you may initialize the ref like this instead:\n\nfunction Video() {\n\n  const playerRef = useRef(null);\n\n  if (playerRef.current === null) {\n\n    playerRef.current = new VideoPlayer();\n\n  }\n\n  // ...\n\nNormally, writing or reading ref.current during render is not allowed. However, it’s fine in this case because the result is always the same, and the condition only executes during initialization so it’s fully predictable.\n\nDEEP DIVE\nHow to avoid null checks when initializing useRef later \nShow Details\nTroubleshooting \nI can’t get a ref to a custom component \n\nIf you try to pass a ref to your own component like this:\n\nconst inputRef = useRef(null);\n\n\n\nreturn <MyInput ref={inputRef} />;\n\nYou might get an error in the console:\n\nConsole\nTypeError: Cannot read properties of null\n\nBy default, your own components don’t expose refs to the DOM nodes inside them.\n\nTo fix this, find the component that you want to get a ref to:\n\nexport default function MyInput({ value, onChange }) {\n\n  return (\n\n    <input\n\n      value={value}\n\n      onChange={onChange}\n\n    />\n\n  );\n\n}\n\nAnd then add ref to the list of props your component accepts and pass ref as a prop to the relevant child built-in component like this:\n\nfunction MyInput({ value, onChange, ref }) {\n\n  return (\n\n    <input\n\n      value={value}\n\n      onChange={onChange}\n\n      ref={ref}\n\n    />\n\n  );\n\n};\n\n\n\nexport default MyInput;\n\nThen the parent component can get a ref to it.\n\nRead more about accessing another component’s DOM nodes.\n\nPREVIOUS\nuseReducer\nNEXT\nuseState"
  },
  {
    "title": "useState – React",
    "url": "https://react.dev/reference/react/useState",
    "html": "API REFERENCE\nHOOKS\nuseState\n\nuseState is a React Hook that lets you add a state variable to your component.\n\nconst [state, setState] = useState(initialState)\nReference\nuseState(initialState)\nset functions, like setSomething(nextState)\nUsage\nAdding state to a component\nUpdating state based on the previous state\nUpdating objects and arrays in state\nAvoiding recreating the initial state\nResetting state with a key\nStoring information from previous renders\nTroubleshooting\nI’ve updated the state, but logging gives me the old value\nI’ve updated the state, but the screen doesn’t update\nI’m getting an error: “Too many re-renders”\nMy initializer or updater function runs twice\nI’m trying to set state to a function, but it gets called instead\nReference \nuseState(initialState) \n\nCall useState at the top level of your component to declare a state variable.\n\nimport { useState } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const [age, setAge] = useState(28);\n\n  const [name, setName] = useState('Taylor');\n\n  const [todos, setTodos] = useState(() => createTodos());\n\n  // ...\n\nThe convention is to name state variables like [something, setSomething] using array destructuring.\n\nSee more examples below.\n\nParameters \ninitialState: The value you want the state to be initially. It can be a value of any type, but there is a special behavior for functions. This argument is ignored after the initial render.\nIf you pass a function as initialState, it will be treated as an initializer function. It should be pure, should take no arguments, and should return a value of any type. React will call your initializer function when initializing the component, and store its return value as the initial state. See an example below.\nReturns \n\nuseState returns an array with exactly two values:\n\nThe current state. During the first render, it will match the initialState you have passed.\nThe set function that lets you update the state to a different value and trigger a re-render.\nCaveats \nuseState is a Hook, so you can only call it at the top level of your component or your own Hooks. You can’t call it inside loops or conditions. If you need that, extract a new component and move the state into it.\nIn Strict Mode, React will call your initializer function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your initializer function is pure (as it should be), this should not affect the behavior. The result from one of the calls will be ignored.\nset functions, like setSomething(nextState) \n\nThe set function returned by useState lets you update the state to a different value and trigger a re-render. You can pass the next state directly, or a function that calculates it from the previous state:\n\nconst [name, setName] = useState('Edward');\n\n\n\nfunction handleClick() {\n\n  setName('Taylor');\n\n  setAge(a => a + 1);\n\n  // ...\nParameters \nnextState: The value that you want the state to be. It can be a value of any type, but there is a special behavior for functions.\nIf you pass a function as nextState, it will be treated as an updater function. It must be pure, should take the pending state as its only argument, and should return the next state. React will put your updater function in a queue and re-render your component. During the next render, React will calculate the next state by applying all of the queued updaters to the previous state. See an example below.\nReturns \n\nset functions do not have a return value.\n\nCaveats \n\nThe set function only updates the state variable for the next render. If you read the state variable after calling the set function, you will still get the old value that was on the screen before your call.\n\nIf the new value you provide is identical to the current state, as determined by an Object.is comparison, React will skip re-rendering the component and its children. This is an optimization. Although in some cases React may still need to call your component before skipping the children, it shouldn’t affect your code.\n\nReact batches state updates. It updates the screen after all the event handlers have run and have called their set functions. This prevents multiple re-renders during a single event. In the rare case that you need to force React to update the screen earlier, for example to access the DOM, you can use flushSync.\n\nThe set function has a stable identity, so you will often see it omitted from Effect dependencies, but including it will not cause the Effect to fire. If the linter lets you omit a dependency without errors, it is safe to do. Learn more about removing Effect dependencies.\n\nCalling the set function during rendering is only allowed from within the currently rendering component. React will discard its output and immediately attempt to render it again with the new state. This pattern is rarely needed, but you can use it to store information from the previous renders. See an example below.\n\nIn Strict Mode, React will call your updater function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your updater function is pure (as it should be), this should not affect the behavior. The result from one of the calls will be ignored.\n\nUsage \nAdding state to a component \n\nCall useState at the top level of your component to declare one or more state variables.\n\nimport { useState } from 'react';\n\n\n\nfunction MyComponent() {\n\n  const [age, setAge] = useState(42);\n\n  const [name, setName] = useState('Taylor');\n\n  // ...\n\nThe convention is to name state variables like [something, setSomething] using array destructuring.\n\nuseState returns an array with exactly two items:\n\nThe current state of this state variable, initially set to the initial state you provided.\nThe set function that lets you change it to any other value in response to interaction.\n\nTo update what’s on the screen, call the set function with some next state:\n\nfunction handleClick() {\n\n  setName('Robin');\n\n}\n\nReact will store the next state, render your component again with the new values, and update the UI.\n\nPitfall\n\nCalling the set function does not change the current state in the already executing code:\n\nfunction handleClick() {\n\n  setName('Robin');\n\n  console.log(name); // Still \"Taylor\"!\n\n}\n\nIt only affects what useState will return starting from the next render.\n\nBasic useState examples\n1. Counter (number)\n2. Text field (string)\n3. Checkbox (boolean)\n4. Form (two variables)\nExample 1 of 4: Counter (number) \n\nIn this example, the count state variable holds a number. Clicking the button increments it.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [count, setCount] = useState(0);\n\n  function handleClick() {\n    setCount(count + 1);\n  }\n\n  return (\n    <button onClick={handleClick}>\n      You pressed me {count} times\n    </button>\n  );\n}\n\n\nNext Example\nUpdating state based on the previous state \n\nSuppose the age is 42. This handler calls setAge(age + 1) three times:\n\nfunction handleClick() {\n\n  setAge(age + 1); // setAge(42 + 1)\n\n  setAge(age + 1); // setAge(42 + 1)\n\n  setAge(age + 1); // setAge(42 + 1)\n\n}\n\nHowever, after one click, age will only be 43 rather than 45! This is because calling the set function does not update the age state variable in the already running code. So each setAge(age + 1) call becomes setAge(43).\n\nTo solve this problem, you may pass an updater function to setAge instead of the next state:\n\nfunction handleClick() {\n\n  setAge(a => a + 1); // setAge(42 => 43)\n\n  setAge(a => a + 1); // setAge(43 => 44)\n\n  setAge(a => a + 1); // setAge(44 => 45)\n\n}\n\nHere, a => a + 1 is your updater function. It takes the pending state and calculates the next state from it.\n\nReact puts your updater functions in a queue. Then, during the next render, it will call them in the same order:\n\na => a + 1 will receive 42 as the pending state and return 43 as the next state.\na => a + 1 will receive 43 as the pending state and return 44 as the next state.\na => a + 1 will receive 44 as the pending state and return 45 as the next state.\n\nThere are no other queued updates, so React will store 45 as the current state in the end.\n\nBy convention, it’s common to name the pending state argument for the first letter of the state variable name, like a for age. However, you may also call it like prevAge or something else that you find clearer.\n\nReact may call your updaters twice in development to verify that they are pure.\n\nDEEP DIVE\nIs using an updater always preferred? \nShow Details\nThe difference between passing an updater and passing the next state directly\n1. Passing the updater function\n2. Passing the next state directly\nExample 1 of 2: Passing the updater function \n\nThis example passes the updater function, so the “+3” button works.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [age, setAge] = useState(42);\n\n  function increment() {\n    setAge(a => a + 1);\n  }\n\n  return (\n    <>\n      <h1>Your age: {age}</h1>\n      <button onClick={() => {\n        increment();\n        increment();\n        increment();\n      }}>+3</button>\n      <button onClick={() => {\n        increment();\n      }}>+1</button>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nUpdating objects and arrays in state \n\nYou can put objects and arrays into state. In React, state is considered read-only, so you should replace it rather than mutate your existing objects. For example, if you have a form object in state, don’t mutate it:\n\n// 🚩 Don't mutate an object in state like this:\n\nform.firstName = 'Taylor';\n\nInstead, replace the whole object by creating a new one:\n\n// ✅ Replace state with a new object\n\nsetForm({\n\n  ...form,\n\n  firstName: 'Taylor'\n\n});\n\nRead updating objects in state and updating arrays in state to learn more.\n\nExamples of objects and arrays in state\n1. Form (object)\n2. Form (nested object)\n3. List (array)\n4. Writing concise update logic with Immer\nExample 1 of 4: Form (object) \n\nIn this example, the form state variable holds an object. Each input has a change handler that calls setForm with the next state of the entire form. The { ...form } spread syntax ensures that the state object is replaced rather than mutated.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Form() {\n  const [form, setForm] = useState({\n    firstName: 'Barbara',\n    lastName: 'Hepworth',\n    email: 'bhepworth@sculpture.com',\n  });\n\n  return (\n    <>\n      <label>\n        First name:\n        <input\n          value={form.firstName}\n          onChange={e => {\n            setForm({\n              ...form,\n              firstName: e.target.value\n            });\n          }}\n        />\n      </label>\n      <label>\n        Last name:\n        <input\n          value={form.lastName}\n          onChange={e => {\n            setForm({\n              ...form,\n              lastName: e.target.value\n            });\n          }}\n        />\n      </label>\n      <label>\n        Email:\n        <input\n          value={form.email}\n          onChange={e => {\n            setForm({\n              ...form,\n              email: e.target.value\n            });\n          }}\n        />\n      </label>\n      <p>\n        {form.firstName}{' '}\n        {form.lastName}{' '}\n        ({form.email})\n      </p>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nAvoiding recreating the initial state \n\nReact saves the initial state once and ignores it on the next renders.\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState(createInitialTodos());\n\n  // ...\n\nAlthough the result of createInitialTodos() is only used for the initial render, you’re still calling this function on every render. This can be wasteful if it’s creating large arrays or performing expensive calculations.\n\nTo solve this, you may pass it as an initializer function to useState instead:\n\nfunction TodoList() {\n\n  const [todos, setTodos] = useState(createInitialTodos);\n\n  // ...\n\nNotice that you’re passing createInitialTodos, which is the function itself, and not createInitialTodos(), which is the result of calling it. If you pass a function to useState, React will only call it during initialization.\n\nReact may call your initializers twice in development to verify that they are pure.\n\nThe difference between passing an initializer and passing the initial state directly\n1. Passing the initializer function\n2. Passing the initial state directly\nExample 1 of 2: Passing the initializer function \n\nThis example passes the initializer function, so the createInitialTodos function only runs during initialization. It does not run when component re-renders, such as when you type into the input.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nfunction createInitialTodos() {\n  const initialTodos = [];\n  for (let i = 0; i < 50; i++) {\n    initialTodos.push({\n      id: i,\n      text: 'Item ' + (i + 1)\n    });\n  }\n  return initialTodos;\n}\n\nexport default function TodoList() {\n  const [todos, setTodos] = useState(createInitialTodos);\n  const [text, setText] = useState('');\n\n  return (\n    <>\n      <input\n        value={text}\n        onChange={e => setText(e.target.value)}\n      />\n      <button onClick={() => {\n        setText('');\n        setTodos([{\n          id: todos.length,\n          text: text\n        }, ...todos]);\n      }}>Add</button>\n      <ul>\n        {todos.map(item => (\n          <li key={item.id}>\n            {item.text}\n          </li>\n        ))}\n      </ul>\n    </>\n  );\n}\n\n\nShow more\nNext Example\nResetting state with a key \n\nYou’ll often encounter the key attribute when rendering lists. However, it also serves another purpose.\n\nYou can reset a component’s state by passing a different key to a component. In this example, the Reset button changes the version state variable, which we pass as a key to the Form. When the key changes, React re-creates the Form component (and all of its children) from scratch, so its state gets reset.\n\nRead preserving and resetting state to learn more.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function App() {\n  const [version, setVersion] = useState(0);\n\n  function handleReset() {\n    setVersion(version + 1);\n  }\n\n  return (\n    <>\n      <button onClick={handleReset}>Reset</button>\n      <Form key={version} />\n    </>\n  );\n}\n\nfunction Form() {\n  const [name, setName] = useState('Taylor');\n\n  return (\n    <>\n      <input\n        value={name}\n        onChange={e => setName(e.target.value)}\n      />\n      <p>Hello, {name}.</p>\n    </>\n  );\n}\n\n\nShow more\nStoring information from previous renders \n\nUsually, you will update state in event handlers. However, in rare cases you might want to adjust state in response to rendering — for example, you might want to change a state variable when a prop changes.\n\nIn most cases, you don’t need this:\n\nIf the value you need can be computed entirely from the current props or other state, remove that redundant state altogether. If you’re worried about recomputing too often, the useMemo Hook can help.\nIf you want to reset the entire component tree’s state, pass a different key to your component.\nIf you can, update all the relevant state in the event handlers.\n\nIn the rare case that none of these apply, there is a pattern you can use to update state based on the values that have been rendered so far, by calling a set function while your component is rendering.\n\nHere’s an example. This CountLabel component displays the count prop passed to it:\n\nexport default function CountLabel({ count }) {\n\n  return <h1>{count}</h1>\n\n}\n\nSay you want to show whether the counter has increased or decreased since the last change. The count prop doesn’t tell you this — you need to keep track of its previous value. Add the prevCount state variable to track it. Add another state variable called trend to hold whether the count has increased or decreased. Compare prevCount with count, and if they’re not equal, update both prevCount and trend. Now you can show both the current count prop and how it has changed since the last render.\n\nApp.js\nCountLabel.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function CountLabel({ count }) {\n  const [prevCount, setPrevCount] = useState(count);\n  const [trend, setTrend] = useState(null);\n  if (prevCount !== count) {\n    setPrevCount(count);\n    setTrend(count > prevCount ? 'increasing' : 'decreasing');\n  }\n  return (\n    <>\n      <h1>{count}</h1>\n      {trend && <p>The count is {trend}</p>}\n    </>\n  );\n}\n\n\nShow more\n\nNote that if you call a set function while rendering, it must be inside a condition like prevCount !== count, and there must be a call like setPrevCount(count) inside of the condition. Otherwise, your component would re-render in a loop until it crashes. Also, you can only update the state of the currently rendering component like this. Calling the set function of another component during rendering is an error. Finally, your set call should still update state without mutation — this doesn’t mean you can break other rules of pure functions.\n\nThis pattern can be hard to understand and is usually best avoided. However, it’s better than updating state in an effect. When you call the set function during render, React will re-render that component immediately after your component exits with a return statement, and before rendering the children. This way, children don’t need to render twice. The rest of your component function will still execute (and the result will be thrown away). If your condition is below all the Hook calls, you may add an early return; to restart rendering earlier.\n\nTroubleshooting \nI’ve updated the state, but logging gives me the old value \n\nCalling the set function does not change state in the running code:\n\nfunction handleClick() {\n\n  console.log(count);  // 0\n\n\n\n  setCount(count + 1); // Request a re-render with 1\n\n  console.log(count);  // Still 0!\n\n\n\n  setTimeout(() => {\n\n    console.log(count); // Also 0!\n\n  }, 5000);\n\n}\n\nThis is because states behaves like a snapshot. Updating state requests another render with the new state value, but does not affect the count JavaScript variable in your already-running event handler.\n\nIf you need to use the next state, you can save it in a variable before passing it to the set function:\n\nconst nextCount = count + 1;\n\nsetCount(nextCount);\n\n\n\nconsole.log(count);     // 0\n\nconsole.log(nextCount); // 1\nI’ve updated the state, but the screen doesn’t update \n\nReact will ignore your update if the next state is equal to the previous state, as determined by an Object.is comparison. This usually happens when you change an object or an array in state directly:\n\nobj.x = 10;  // 🚩 Wrong: mutating existing object\n\nsetObj(obj); // 🚩 Doesn't do anything\n\nYou mutated an existing obj object and passed it back to setObj, so React ignored the update. To fix this, you need to ensure that you’re always replacing objects and arrays in state instead of mutating them:\n\n// ✅ Correct: creating a new object\n\nsetObj({\n\n  ...obj,\n\n  x: 10\n\n});\nI’m getting an error: “Too many re-renders” \n\nYou might get an error that says: Too many re-renders. React limits the number of renders to prevent an infinite loop. Typically, this means that you’re unconditionally setting state during render, so your component enters a loop: render, set state (which causes a render), render, set state (which causes a render), and so on. Very often, this is caused by a mistake in specifying an event handler:\n\n// 🚩 Wrong: calls the handler during render\n\nreturn <button onClick={handleClick()}>Click me</button>\n\n\n\n// ✅ Correct: passes down the event handler\n\nreturn <button onClick={handleClick}>Click me</button>\n\n\n\n// ✅ Correct: passes down an inline function\n\nreturn <button onClick={(e) => handleClick(e)}>Click me</button>\n\nIf you can’t find the cause of this error, click on the arrow next to the error in the console and look through the JavaScript stack to find the specific set function call responsible for the error.\n\nMy initializer or updater function runs twice \n\nIn Strict Mode, React will call some of your functions twice instead of once:\n\nfunction TodoList() {\n\n  // This component function will run twice for every render.\n\n\n\n  const [todos, setTodos] = useState(() => {\n\n    // This initializer function will run twice during initialization.\n\n    return createTodos();\n\n  });\n\n\n\n  function handleClick() {\n\n    setTodos(prevTodos => {\n\n      // This updater function will run twice for every click.\n\n      return [...prevTodos, createTodo()];\n\n    });\n\n  }\n\n  // ...\n\nThis is expected and shouldn’t break your code.\n\nThis development-only behavior helps you keep components pure. React uses the result of one of the calls, and ignores the result of the other call. As long as your component, initializer, and updater functions are pure, this shouldn’t affect your logic. However, if they are accidentally impure, this helps you notice the mistakes.\n\nFor example, this impure updater function mutates an array in state:\n\nsetTodos(prevTodos => {\n\n  // 🚩 Mistake: mutating state\n\n  prevTodos.push(createTodo());\n\n});\n\nBecause React calls your updater function twice, you’ll see the todo was added twice, so you’ll know that there is a mistake. In this example, you can fix the mistake by replacing the array instead of mutating it:\n\nsetTodos(prevTodos => {\n\n  // ✅ Correct: replacing with new state\n\n  return [...prevTodos, createTodo()];\n\n});\n\nNow that this updater function is pure, calling it an extra time doesn’t make a difference in behavior. This is why React calling it twice helps you find mistakes. Only component, initializer, and updater functions need to be pure. Event handlers don’t need to be pure, so React will never call your event handlers twice.\n\nRead keeping components pure to learn more.\n\nI’m trying to set state to a function, but it gets called instead \n\nYou can’t put a function into state like this:\n\nconst [fn, setFn] = useState(someFunction);\n\n\n\nfunction handleClick() {\n\n  setFn(someOtherFunction);\n\n}\n\nBecause you’re passing a function, React assumes that someFunction is an initializer function, and that someOtherFunction is an updater function, so it tries to call them and store the result. To actually store a function, you have to put () => before them in both cases. Then React will store the functions you pass.\n\nconst [fn, setFn] = useState(() => someFunction);\n\n\n\nfunction handleClick() {\n\n  setFn(() => someOtherFunction);\n\n}\nPREVIOUS\nuseRef\nNEXT\nuseSyncExternalStore"
  },
  {
    "title": "useSyncExternalStore – React",
    "url": "https://react.dev/reference/react/useSyncExternalStore",
    "html": "API REFERENCE\nHOOKS\nuseSyncExternalStore\n\nuseSyncExternalStore is a React Hook that lets you subscribe to an external store.\n\nconst snapshot = useSyncExternalStore(subscribe, getSnapshot, getServerSnapshot?)\nReference\nuseSyncExternalStore(subscribe, getSnapshot, getServerSnapshot?)\nUsage\nSubscribing to an external store\nSubscribing to a browser API\nExtracting the logic to a custom Hook\nAdding support for server rendering\nTroubleshooting\nI’m getting an error: “The result of getSnapshot should be cached”\nMy subscribe function gets called after every re-render\nReference \nuseSyncExternalStore(subscribe, getSnapshot, getServerSnapshot?) \n\nCall useSyncExternalStore at the top level of your component to read a value from an external data store.\n\nimport { useSyncExternalStore } from 'react';\n\nimport { todosStore } from './todoStore.js';\n\n\n\nfunction TodosApp() {\n\n  const todos = useSyncExternalStore(todosStore.subscribe, todosStore.getSnapshot);\n\n  // ...\n\n}\n\nIt returns the snapshot of the data in the store. You need to pass two functions as arguments:\n\nThe subscribe function should subscribe to the store and return a function that unsubscribes.\nThe getSnapshot function should read a snapshot of the data from the store.\n\nSee more examples below.\n\nParameters \n\nsubscribe: A function that takes a single callback argument and subscribes it to the store. When the store changes, it should invoke the provided callback, which will cause React to re-call getSnapshot and (if needed) re-render the component. The subscribe function should return a function that cleans up the subscription.\n\ngetSnapshot: A function that returns a snapshot of the data in the store that’s needed by the component. While the store has not changed, repeated calls to getSnapshot must return the same value. If the store changes and the returned value is different (as compared by Object.is), React re-renders the component.\n\noptional getServerSnapshot: A function that returns the initial snapshot of the data in the store. It will be used only during server rendering and during hydration of server-rendered content on the client. The server snapshot must be the same between the client and the server, and is usually serialized and passed from the server to the client. If you omit this argument, rendering the component on the server will throw an error.\n\nReturns \n\nThe current snapshot of the store which you can use in your rendering logic.\n\nCaveats \n\nThe store snapshot returned by getSnapshot must be immutable. If the underlying store has mutable data, return a new immutable snapshot if the data has changed. Otherwise, return a cached last snapshot.\n\nIf a different subscribe function is passed during a re-render, React will re-subscribe to the store using the newly passed subscribe function. You can prevent this by declaring subscribe outside the component.\n\nIf the store is mutated during a non-blocking Transition update, React will fall back to performing that update as blocking. Specifically, for every Transition update, React will call getSnapshot a second time just before applying changes to the DOM. If it returns a different value than when it was called originally, React will restart the update from scratch, this time applying it as a blocking update, to ensure that every component on screen is reflecting the same version of the store.\n\nIt’s not recommended to suspend a render based on a store value returned by useSyncExternalStore. The reason is that mutations to the external store cannot be marked as non-blocking Transition updates, so they will trigger the nearest Suspense fallback, replacing already-rendered content on screen with a loading spinner, which typically makes a poor UX.\n\nFor example, the following are discouraged:\n\nconst LazyProductDetailPage = lazy(() => import('./ProductDetailPage.js'));\n\n\n\nfunction ShoppingApp() {\n\n  const selectedProductId = useSyncExternalStore(...);\n\n\n\n  // ❌ Calling `use` with a Promise dependent on `selectedProductId`\n\n  const data = use(fetchItem(selectedProductId))\n\n\n\n  // ❌ Conditionally rendering a lazy component based on `selectedProductId`\n\n  return selectedProductId != null ? <LazyProductDetailPage /> : <FeaturedProducts />;\n\n}\nUsage \nSubscribing to an external store \n\nMost of your React components will only read data from their props, state, and context. However, sometimes a component needs to read some data from some store outside of React that changes over time. This includes:\n\nThird-party state management libraries that hold state outside of React.\nBrowser APIs that expose a mutable value and events to subscribe to its changes.\n\nCall useSyncExternalStore at the top level of your component to read a value from an external data store.\n\nimport { useSyncExternalStore } from 'react';\n\nimport { todosStore } from './todoStore.js';\n\n\n\nfunction TodosApp() {\n\n  const todos = useSyncExternalStore(todosStore.subscribe, todosStore.getSnapshot);\n\n  // ...\n\n}\n\nIt returns the snapshot of the data in the store. You need to pass two functions as arguments:\n\nThe subscribe function should subscribe to the store and return a function that unsubscribes.\nThe getSnapshot function should read a snapshot of the data from the store.\n\nReact will use these functions to keep your component subscribed to the store and re-render it on changes.\n\nFor example, in the sandbox below, todosStore is implemented as an external store that stores data outside of React. The TodosApp component connects to that external store with the useSyncExternalStore Hook.\n\nApp.js\ntodoStore.js\nReload\nClear\nFork\nimport { useSyncExternalStore } from 'react';\nimport { todosStore } from './todoStore.js';\n\nexport default function TodosApp() {\n  const todos = useSyncExternalStore(todosStore.subscribe, todosStore.getSnapshot);\n  return (\n    <>\n      <button onClick={() => todosStore.addTodo()}>Add todo</button>\n      <hr />\n      <ul>\n        {todos.map(todo => (\n          <li key={todo.id}>{todo.text}</li>\n        ))}\n      </ul>\n    </>\n  );\n}\n\n\nShow more\nNote\n\nWhen possible, we recommend using built-in React state with useState and useReducer instead. The useSyncExternalStore API is mostly useful if you need to integrate with existing non-React code.\n\nSubscribing to a browser API \n\nAnother reason to add useSyncExternalStore is when you want to subscribe to some value exposed by the browser that changes over time. For example, suppose that you want your component to display whether the network connection is active. The browser exposes this information via a property called navigator.onLine.\n\nThis value can change without React’s knowledge, so you should read it with useSyncExternalStore.\n\nimport { useSyncExternalStore } from 'react';\n\n\n\nfunction ChatIndicator() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n  // ...\n\n}\n\nTo implement the getSnapshot function, read the current value from the browser API:\n\nfunction getSnapshot() {\n\n  return navigator.onLine;\n\n}\n\nNext, you need to implement the subscribe function. For example, when navigator.onLine changes, the browser fires the online and offline events on the window object. You need to subscribe the callback argument to the corresponding events, and then return a function that cleans up the subscriptions:\n\nfunction subscribe(callback) {\n\n  window.addEventListener('online', callback);\n\n  window.addEventListener('offline', callback);\n\n  return () => {\n\n    window.removeEventListener('online', callback);\n\n    window.removeEventListener('offline', callback);\n\n  };\n\n}\n\nNow React knows how to read the value from the external navigator.onLine API and how to subscribe to its changes. Disconnect your device from the network and notice that the component re-renders in response:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useSyncExternalStore } from 'react';\n\nexport default function ChatIndicator() {\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n  return <h1>{isOnline ? '✅ Online' : '❌ Disconnected'}</h1>;\n}\n\nfunction getSnapshot() {\n  return navigator.onLine;\n}\n\nfunction subscribe(callback) {\n  window.addEventListener('online', callback);\n  window.addEventListener('offline', callback);\n  return () => {\n    window.removeEventListener('online', callback);\n    window.removeEventListener('offline', callback);\n  };\n}\n\n\nShow more\nExtracting the logic to a custom Hook \n\nUsually you won’t write useSyncExternalStore directly in your components. Instead, you’ll typically call it from your own custom Hook. This lets you use the same external store from different components.\n\nFor example, this custom useOnlineStatus Hook tracks whether the network is online:\n\nimport { useSyncExternalStore } from 'react';\n\n\n\nexport function useOnlineStatus() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n  return isOnline;\n\n}\n\n\n\nfunction getSnapshot() {\n\n  // ...\n\n}\n\n\n\nfunction subscribe(callback) {\n\n  // ...\n\n}\n\nNow different components can call useOnlineStatus without repeating the underlying implementation:\n\nApp.js\nuseOnlineStatus.js\nReload\nClear\nFork\nimport { useOnlineStatus } from './useOnlineStatus.js';\n\nfunction StatusBar() {\n  const isOnline = useOnlineStatus();\n  return <h1>{isOnline ? '✅ Online' : '❌ Disconnected'}</h1>;\n}\n\nfunction SaveButton() {\n  const isOnline = useOnlineStatus();\n\n  function handleSaveClick() {\n    console.log('✅ Progress saved');\n  }\n\n  return (\n    <button disabled={!isOnline} onClick={handleSaveClick}>\n      {isOnline ? 'Save progress' : 'Reconnecting...'}\n    </button>\n  );\n}\n\nexport default function App() {\n  return (\n    <>\n      <SaveButton />\n      <StatusBar />\n    </>\n  );\n}\n\n\nShow more\nAdding support for server rendering \n\nIf your React app uses server rendering, your React components will also run outside the browser environment to generate the initial HTML. This creates a few challenges when connecting to an external store:\n\nIf you’re connecting to a browser-only API, it won’t work because it does not exist on the server.\nIf you’re connecting to a third-party data store, you’ll need its data to match between the server and client.\n\nTo solve these issues, pass a getServerSnapshot function as the third argument to useSyncExternalStore:\n\nimport { useSyncExternalStore } from 'react';\n\n\n\nexport function useOnlineStatus() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot, getServerSnapshot);\n\n  return isOnline;\n\n}\n\n\n\nfunction getSnapshot() {\n\n  return navigator.onLine;\n\n}\n\n\n\nfunction getServerSnapshot() {\n\n  return true; // Always show \"Online\" for server-generated HTML\n\n}\n\n\n\nfunction subscribe(callback) {\n\n  // ...\n\n}\n\nThe getServerSnapshot function is similar to getSnapshot, but it runs only in two situations:\n\nIt runs on the server when generating the HTML.\nIt runs on the client during hydration, i.e. when React takes the server HTML and makes it interactive.\n\nThis lets you provide the initial snapshot value which will be used before the app becomes interactive. If there is no meaningful initial value for the server rendering, omit this argument to force rendering on the client.\n\nNote\n\nMake sure that getServerSnapshot returns the same exact data on the initial client render as it returned on the server. For example, if getServerSnapshot returned some prepopulated store content on the server, you need to transfer this content to the client. One way to do this is to emit a <script> tag during server rendering that sets a global like window.MY_STORE_DATA, and read from that global on the client in getServerSnapshot. Your external store should provide instructions on how to do that.\n\nTroubleshooting \nI’m getting an error: “The result of getSnapshot should be cached” \n\nThis error means your getSnapshot function returns a new object every time it’s called, for example:\n\nfunction getSnapshot() {\n\n  // 🔴 Do not return always different objects from getSnapshot\n\n  return {\n\n    todos: myStore.todos\n\n  };\n\n}\n\nReact will re-render the component if getSnapshot return value is different from the last time. This is why, if you always return a different value, you will enter an infinite loop and get this error.\n\nYour getSnapshot object should only return a different object if something has actually changed. If your store contains immutable data, you can return that data directly:\n\nfunction getSnapshot() {\n\n  // ✅ You can return immutable data\n\n  return myStore.todos;\n\n}\n\nIf your store data is mutable, your getSnapshot function should return an immutable snapshot of it. This means it does need to create new objects, but it shouldn’t do this for every single call. Instead, it should store the last calculated snapshot, and return the same snapshot as the last time if the data in the store has not changed. How you determine whether mutable data has changed depends on your mutable store.\n\nMy subscribe function gets called after every re-render \n\nThis subscribe function is defined inside a component so it is different on every re-render:\n\nfunction ChatIndicator() {\n\n  // 🚩 Always a different function, so React will resubscribe on every re-render\n\n  function subscribe() {\n\n    // ...\n\n  }\n\n  \n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n\n\n  // ...\n\n}\n\nReact will resubscribe to your store if you pass a different subscribe function between re-renders. If this causes performance issues and you’d like to avoid resubscribing, move the subscribe function outside:\n\n// ✅ Always the same function, so React won't need to resubscribe\n\nfunction subscribe() {\n\n  // ...\n\n}\n\n\n\nfunction ChatIndicator() {\n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n  // ...\n\n}\n\nAlternatively, wrap subscribe into useCallback to only resubscribe when some argument changes:\n\nfunction ChatIndicator({ userId }) {\n\n  // ✅ Same function as long as userId doesn't change\n\n  const subscribe = useCallback(() => {\n\n    // ...\n\n  }, [userId]);\n\n  \n\n  const isOnline = useSyncExternalStore(subscribe, getSnapshot);\n\n\n\n  // ...\n\n}\nPREVIOUS\nuseState\nNEXT\nuseTransition"
  },
  {
    "title": "useTransition – React",
    "url": "https://react.dev/reference/react/useTransition",
    "html": "API REFERENCE\nHOOKS\nuseTransition\n\nuseTransition is a React Hook that lets you render a part of the UI in the background.\n\nconst [isPending, startTransition] = useTransition()\nReference\nuseTransition()\nstartTransition(action)\nUsage\nPerform non-blocking updates with Actions\nExposing action prop from components\nDisplaying a pending visual state\nPreventing unwanted loading indicators\nBuilding a Suspense-enabled router\nDisplaying an error to users with an error boundary\nTroubleshooting\nUpdating an input in a Transition doesn’t work\nReact doesn’t treat my state update as a Transition\nReact doesn’t treat my state update after await as a Transition\nI want to call useTransition from outside a component\nThe function I pass to startTransition executes immediately\nMy state updates in Transitions are out of order\nReference \nuseTransition() \n\nCall useTransition at the top level of your component to mark some state updates as Transitions.\n\nimport { useTransition } from 'react';\n\n\n\nfunction TabContainer() {\n\n  const [isPending, startTransition] = useTransition();\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \n\nuseTransition does not take any parameters.\n\nReturns \n\nuseTransition returns an array with exactly two items:\n\nThe isPending flag that tells you whether there is a pending Transition.\nThe startTransition function that lets you mark updates as a Transition.\nstartTransition(action) \n\nThe startTransition function returned by useTransition lets you mark an update as a Transition.\n\nfunction TabContainer() {\n\n  const [isPending, startTransition] = useTransition();\n\n  const [tab, setTab] = useState('about');\n\n\n\n  function selectTab(nextTab) {\n\n    startTransition(() => {\n\n      setTab(nextTab);\n\n    });\n\n  }\n\n  // ...\n\n}\nNote\nFunctions called in startTransition are called “Actions”. \n\nThe function passed to startTransition is called an “Action”. By convention, any callback called inside startTransition (such as a callback prop) should be named action or include the “Action” suffix:\n\nfunction SubmitButton({ submitAction }) {\n\n  const [isPending, startTransition] = useTransition();\n\n\n\n  return (\n\n    <button\n\n      disabled={isPending}\n\n      onClick={() => {\n\n        startTransition(async () => {\n\n          await submitAction();\n\n        });\n\n      }}\n\n    >\n\n      Submit\n\n    </button>\n\n  );\n\n}\nParameters \naction: A function that updates some state by calling one or more set functions. React calls action immediately with no parameters and marks all state updates scheduled synchronously during the action function call as Transitions. Any async calls that are awaited in the action will be included in the Transition, but currently require wrapping any set functions after the await in an additional startTransition (see Troubleshooting). State updates marked as Transitions will be non-blocking and will not display unwanted loading indicators.\nReturns \n\nstartTransition does not return anything.\n\nCaveats \n\nuseTransition is a Hook, so it can only be called inside components or custom Hooks. If you need to start a Transition somewhere else (for example, from a data library), call the standalone startTransition instead.\n\nYou can wrap an update into a Transition only if you have access to the set function of that state. If you want to start a Transition in response to some prop or a custom Hook value, try useDeferredValue instead.\n\nThe function you pass to startTransition is called immediately, marking all state updates that happen while it executes as Transitions. If you try to perform state updates in a setTimeout, for example, they won’t be marked as Transitions.\n\nYou must wrap any state updates after any async requests in another startTransition to mark them as Transitions. This is a known limitation that we will fix in the future (see Troubleshooting).\n\nThe startTransition function has a stable identity, so you will often see it omitted from Effect dependencies, but including it will not cause the Effect to fire. If the linter lets you omit a dependency without errors, it is safe to do. Learn more about removing Effect dependencies.\n\nA state update marked as a Transition will be interrupted by other state updates. For example, if you update a chart component inside a Transition, but then start typing into an input while the chart is in the middle of a re-render, React will restart the rendering work on the chart component after handling the input update.\n\nTransition updates can’t be used to control text inputs.\n\nIf there are multiple ongoing Transitions, React currently batches them together. This is a limitation that may be removed in a future release.\n\nUsage \nPerform non-blocking updates with Actions \n\nCall useTransition at the top of your component to create Actions, and access the pending state:\n\nimport {useState, useTransition} from 'react';\n\n\n\nfunction CheckoutForm() {\n\n  const [isPending, startTransition] = useTransition();\n\n  // ...\n\n}\n\nuseTransition returns an array with exactly two items:\n\nThe isPending flag that tells you whether there is a pending Transition.\nThe startTransition function that lets you create an Action.\n\nTo start a Transition, pass a function to startTransition like this:\n\nimport {useState, useTransition} from 'react';\n\nimport {updateQuantity} from './api';\n\n\n\nfunction CheckoutForm() {\n\n  const [isPending, startTransition] = useTransition();\n\n  const [quantity, setQuantity] = useState(1);\n\n\n\n  function onSubmit(newQuantity) {\n\n    startTransition(async function () {\n\n      const savedQuantity = await updateQuantity(newQuantity);\n\n      startTransition(() => {\n\n        setQuantity(savedQuantity);\n\n      });\n\n    });\n\n  }\n\n  // ...\n\n}\n\nThe function passed to startTransition is called the “Action”. You can update state and (optionally) perform side effects within an Action, and the work will be done in the background without blocking user interactions on the page. A Transition can include multiple Actions, and while a Transition is in progress, your UI stays responsive. For example, if the user clicks a tab but then changes their mind and clicks another tab, the second click will be immediately handled without waiting for the first update to finish.\n\nTo give the user feedback about in-progress Transitions, the isPending state switches to true at the first call to startTransition, and stays true until all Actions complete and the final state is shown to the user. Transitions ensure side effects in Actions to complete in order to prevent unwanted loading indicators, and you can provide immediate feedback while the Transition is in progress with useOptimistic.\n\nThe difference between Actions and regular event handling\n1. Updating the quantity in an Action\n2. Updating the quantity without an Action\nExample 1 of 2: Updating the quantity in an Action \n\nIn this example, the updateQuantity function simulates a request to the server to update the item’s quantity in the cart. This function is artificially slowed down so that it takes at least a second to complete the request.\n\nUpdate the quantity multiple times quickly. Notice that the pending “Total” state is shown while any requests are in progress, and the “Total” updates only after the final request is complete. Because the update is in an Action, the “quantity” can continue to be updated while the request is in progress.\n\nApp.js\nItem.js\nTotal.js\napi.js\nReload\nClear\nFork\nimport { useState, useTransition } from \"react\";\nimport { updateQuantity } from \"./api\";\nimport Item from \"./Item\";\nimport Total from \"./Total\";\n\nexport default function App({}) {\n  const [quantity, setQuantity] = useState(1);\n  const [isPending, startTransition] = useTransition();\n\n  const updateQuantityAction = async newQuantity => {\n    // To access the pending state of a transition,\n    // call startTransition again.\n    startTransition(async () => {\n      const savedQuantity = await updateQuantity(newQuantity);\n      startTransition(() => {\n        setQuantity(savedQuantity);\n      });\n    });\n  };\n\n  return (\n    <div>\n      <h1>Checkout</h1>\n      <Item action={updateQuantityAction}/>\n      <hr />\n      <Total quantity={quantity} isPending={isPending} />\n    </div>\n  );\n}\n\n\nShow more\n\nThis is a basic example to demonstrate how Actions work, but this example does not handle requests completing out of order. When updating the quantity multiple times, it’s possible for the previous requests to finish after later requests causing the quantity to update out of order. This is a known limitation that we will fix in the future (see Troubleshooting below).\n\nFor common use cases, React provides built-in abstractions such as:\n\nuseActionState\n<form> actions\nServer Functions\n\nThese solutions handle request ordering for you. When using Transitions to build your own custom hooks or libraries that manage async state transitions, you have greater control over the request ordering, but you must handle it yourself.\n\nNext Example\nExposing action prop from components \n\nYou can expose an action prop from a component to allow a parent to call an Action.\n\nFor example, this TabButton component wraps its onClick logic in an action prop:\n\nexport default function TabButton({ action, children, isActive }) {\n\n  const [isPending, startTransition] = useTransition();\n\n  if (isActive) {\n\n    return <b>{children}</b>\n\n  }\n\n  return (\n\n    <button onClick={() => {\n\n      startTransition(async () => {\n\n        // await the action that's passed in.\n\n        // This allows it to be either sync or async.\n\n        await action();\n\n      });\n\n    }}>\n\n      {children}\n\n    </button>\n\n  );\n\n}\n\nBecause the parent component updates its state inside the action, that state update gets marked as a Transition. This means you can click on “Posts” and then immediately click “Contact” and it does not block user interactions:\n\nApp.js\nTabButton.js\nAboutTab.js\nPostsTab.js\nContactTab.js\nReload\nClear\nFork\nimport { useTransition } from 'react';\n\nexport default function TabButton({ action, children, isActive }) {\n  const [isPending, startTransition] = useTransition();\n  if (isActive) {\n    return <b>{children}</b>\n  }\n  if (isPending) {\n    return <b className=\"pending\">{children}</b>;\n  }\n  return (\n    <button onClick={async () => {\n      startTransition(async () => {\n        // await the action that's passed in.\n        // This allows it to be either sync or async.\n        await action();\n      });\n    }}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nNote\n\nWhen exposing an action prop from a component, you should await it inside the transition.\n\nThis allows the action callback to be either synchronous or asynchronous without requiring an additional startTransition to wrap the await in the action.\n\nDisplaying a pending visual state \n\nYou can use the isPending boolean value returned by useTransition to indicate to the user that a Transition is in progress. For example, the tab button can have a special “pending” visual state:\n\nfunction TabButton({ action, children, isActive }) {\n\n  const [isPending, startTransition] = useTransition();\n\n  // ...\n\n  if (isPending) {\n\n    return <b className=\"pending\">{children}</b>;\n\n  }\n\n  // ...\n\nNotice how clicking “Posts” now feels more responsive because the tab button itself updates right away:\n\nApp.js\nTabButton.js\nAboutTab.js\nPostsTab.js\nContactTab.js\nReload\nClear\nFork\nimport { useTransition } from 'react';\n\nexport default function TabButton({ action, children, isActive }) {\n  const [isPending, startTransition] = useTransition();\n  if (isActive) {\n    return <b>{children}</b>\n  }\n  if (isPending) {\n    return <b className=\"pending\">{children}</b>;\n  }\n  return (\n    <button onClick={() => {\n      startTransition(async () => {\n        await action();\n      });\n    }}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\nPreventing unwanted loading indicators \n\nIn this example, the PostsTab component fetches some data using use. When you click the “Posts” tab, the PostsTab component suspends, causing the closest loading fallback to appear:\n\nApp.js\nTabButton.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport AboutTab from './AboutTab.js';\nimport PostsTab from './PostsTab.js';\nimport ContactTab from './ContactTab.js';\n\nexport default function TabContainer() {\n  const [tab, setTab] = useState('about');\n  return (\n    <Suspense fallback={<h1>🌀 Loading...</h1>}>\n      <TabButton\n        isActive={tab === 'about'}\n        action={() => setTab('about')}\n      >\n        About\n      </TabButton>\n      <TabButton\n        isActive={tab === 'posts'}\n        action={() => setTab('posts')}\n      >\n        Posts\n      </TabButton>\n      <TabButton\n        isActive={tab === 'contact'}\n        action={() => setTab('contact')}\n      >\n        Contact\n      </TabButton>\n      <hr />\n      {tab === 'about' && <AboutTab />}\n      {tab === 'posts' && <PostsTab />}\n      {tab === 'contact' && <ContactTab />}\n    </Suspense>\n  );\n}\n\n\nShow more\n\nHiding the entire tab container to show a loading indicator leads to a jarring user experience. If you add useTransition to TabButton, you can instead display the pending state in the tab button instead.\n\nNotice that clicking “Posts” no longer replaces the entire tab container with a spinner:\n\nApp.js\nTabButton.js\nReload\nClear\nFork\nimport { useTransition } from 'react';\n\nexport default function TabButton({ action, children, isActive }) {\n  const [isPending, startTransition] = useTransition();\n  if (isActive) {\n    return <b>{children}</b>\n  }\n  if (isPending) {\n    return <b className=\"pending\">{children}</b>;\n  }\n  return (\n    <button onClick={() => {\n      startTransition(async () => {\n        await action();\n      });\n    }}>\n      {children}\n    </button>\n  );\n}\n\n\nShow more\n\nRead more about using Transitions with Suspense.\n\nNote\n\nTransitions only “wait” long enough to avoid hiding already revealed content (like the tab container). If the Posts tab had a nested <Suspense> boundary, the Transition would not “wait” for it.\n\nBuilding a Suspense-enabled router \n\nIf you’re building a React framework or a router, we recommend marking page navigations as Transitions.\n\nfunction Router() {\n\n  const [page, setPage] = useState('/');\n\n  const [isPending, startTransition] = useTransition();\n\n\n\n  function navigate(url) {\n\n    startTransition(() => {\n\n      setPage(url);\n\n    });\n\n  }\n\n  // ...\n\nThis is recommended for three reasons:\n\nTransitions are interruptible, which lets the user click away without waiting for the re-render to complete.\nTransitions prevent unwanted loading indicators, which lets the user avoid jarring jumps on navigation.\nTransitions wait for all pending actions which lets the user wait for side effects to complete before the new page is shown.\n\nHere is a simplified router example using Transitions for navigations.\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, useState, useTransition } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n  const [isPending, startTransition] = useTransition();\n\n  function navigate(url) {\n    startTransition(() => {\n      setPage(url);\n    });\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout isPending={isPending}>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\nNote\n\nSuspense-enabled routers are expected to wrap the navigation updates into Transitions by default.\n\nDisplaying an error to users with an error boundary \n\nIf a function passed to startTransition throws an error, you can display an error to your user with an error boundary. To use an error boundary, wrap the component where you are calling the useTransition in an error boundary. Once the function passed to startTransition errors, the fallback for the error boundary will be displayed.\n\nAddCommentContainer.js\nReload\nClear\nFork\nimport { useTransition } from \"react\";\nimport { ErrorBoundary } from \"react-error-boundary\";\n\nexport function AddCommentContainer() {\n  return (\n    <ErrorBoundary fallback={<p>⚠️Something went wrong</p>}>\n      <AddCommentButton />\n    </ErrorBoundary>\n  );\n}\n\nfunction addComment(comment) {\n  // For demonstration purposes to show Error Boundary\n  if (comment == null) {\n    throw new Error(\"Example Error: An error thrown to trigger error boundary\");\n  }\n}\n\nfunction AddCommentButton() {\n  const [pending, startTransition] = useTransition();\n\n  return (\n    <button\n      disabled={pending}\n      onClick={() => {\n        startTransition(() => {\n          // Intentionally not passing a comment\n          // so error gets thrown\n          addComment();\n        });\n      }}\n    >\n      Add comment\n    </button>\n  );\n}\n\n\nShow more\nTroubleshooting \nUpdating an input in a Transition doesn’t work \n\nYou can’t use a Transition for a state variable that controls an input:\n\nconst [text, setText] = useState('');\n\n// ...\n\nfunction handleChange(e) {\n\n  // ❌ Can't use Transitions for controlled input state\n\n  startTransition(() => {\n\n    setText(e.target.value);\n\n  });\n\n}\n\n// ...\n\nreturn <input value={text} onChange={handleChange} />;\n\nThis is because Transitions are non-blocking, but updating an input in response to the change event should happen synchronously. If you want to run a Transition in response to typing, you have two options:\n\nYou can declare two separate state variables: one for the input state (which always updates synchronously), and one that you will update in a Transition. This lets you control the input using the synchronous state, and pass the Transition state variable (which will “lag behind” the input) to the rest of your rendering logic.\nAlternatively, you can have one state variable, and add useDeferredValue which will “lag behind” the real value. It will trigger non-blocking re-renders to “catch up” with the new value automatically.\nReact doesn’t treat my state update as a Transition \n\nWhen you wrap a state update in a Transition, make sure that it happens during the startTransition call:\n\nstartTransition(() => {\n\n  // ✅ Setting state *during* startTransition call\n\n  setPage('/about');\n\n});\n\nThe function you pass to startTransition must be synchronous. You can’t mark an update as a Transition like this:\n\nstartTransition(() => {\n\n  // ❌ Setting state *after* startTransition call\n\n  setTimeout(() => {\n\n    setPage('/about');\n\n  }, 1000);\n\n});\n\nInstead, you could do this:\n\nsetTimeout(() => {\n\n  startTransition(() => {\n\n    // ✅ Setting state *during* startTransition call\n\n    setPage('/about');\n\n  });\n\n}, 1000);\nReact doesn’t treat my state update after await as a Transition \n\nWhen you use await inside a startTransition function, the state updates that happen after the await are not marked as Transitions. You must wrap state updates after each await in a startTransition call:\n\nstartTransition(async () => {\n\n  await someAsyncFunction();\n\n  // ❌ Not using startTransition after await\n\n  setPage('/about');\n\n});\n\nHowever, this works instead:\n\nstartTransition(async () => {\n\n  await someAsyncFunction();\n\n  // ✅ Using startTransition *after* await\n\n  startTransition(() => {\n\n    setPage('/about');\n\n  });\n\n});\n\nThis is a JavaScript limitation due to React losing the scope of the async context. In the future, when AsyncContext is available, this limitation will be removed.\n\nI want to call useTransition from outside a component \n\nYou can’t call useTransition outside a component because it’s a Hook. In this case, use the standalone startTransition method instead. It works the same way, but it doesn’t provide the isPending indicator.\n\nThe function I pass to startTransition executes immediately \n\nIf you run this code, it will print 1, 2, 3:\n\nconsole.log(1);\n\nstartTransition(() => {\n\n  console.log(2);\n\n  setPage('/about');\n\n});\n\nconsole.log(3);\n\nIt is expected to print 1, 2, 3. The function you pass to startTransition does not get delayed. Unlike with the browser setTimeout, it does not run the callback later. React executes your function immediately, but any state updates scheduled while it is running are marked as Transitions. You can imagine that it works like this:\n\n// A simplified version of how React works\n\n\n\nlet isInsideTransition = false;\n\n\n\nfunction startTransition(scope) {\n\n  isInsideTransition = true;\n\n  scope();\n\n  isInsideTransition = false;\n\n}\n\n\n\nfunction setState() {\n\n  if (isInsideTransition) {\n\n    // ... schedule a Transition state update ...\n\n  } else {\n\n    // ... schedule an urgent state update ...\n\n  }\n\n}\nMy state updates in Transitions are out of order \n\nIf you await inside startTransition, you might see the updates happen out of order.\n\nIn this example, the updateQuantity function simulates a request to the server to update the item’s quantity in the cart. This function artificially returns every other request after the previous to simulate race conditions for network requests.\n\nTry updating the quantity once, then update it quickly multiple times. You might see the incorrect total:\n\nApp.js\nItem.js\nTotal.js\napi.js\nReload\nClear\nFork\nimport { useState, useTransition } from \"react\";\nimport { updateQuantity } from \"./api\";\nimport Item from \"./Item\";\nimport Total from \"./Total\";\n\nexport default function App({}) {\n  const [quantity, setQuantity] = useState(1);\n  const [isPending, startTransition] = useTransition();\n  // Store the actual quantity in separate state to show the mismatch.\n  const [clientQuantity, setClientQuantity] = useState(1);\n\n  const updateQuantityAction = newQuantity => {\n    setClientQuantity(newQuantity);\n\n    // Access the pending state of the transition,\n    // by wrapping in startTransition again.\n    startTransition(async () => {\n      const savedQuantity = await updateQuantity(newQuantity);\n      startTransition(() => {\n        setQuantity(savedQuantity);\n      });\n    });\n  };\n\n  return (\n    <div>\n      <h1>Checkout</h1>\n      <Item action={updateQuantityAction}/>\n      <hr />\n      <Total clientQuantity={clientQuantity} savedQuantity={quantity} isPending={isPending} />\n    </div>\n  );\n}\n\n\nShow more\n\nWhen clicking multiple times, it’s possible for previous requests to finish after later requests. When this happens, React currently has no way to know the intended order. This is because the updates are scheduled asynchronously, and React loses context of the order across the async boundary.\n\nThis is expected, because Actions within a Transition do not guarantee execution order. For common use cases, React provides higher-level abstractions like useActionState and <form> actions that handle ordering for you. For advanced use cases, you’ll need to implement your own queuing and abort logic to handle this.\n\nExample of useActionState handling execution order:\n\nApp.js\nItem.js\nTotal.js\napi.js\nReload\nClear\nFork\nimport { useState, useActionState } from \"react\";\nimport { updateQuantity } from \"./api\";\nimport Item from \"./Item\";\nimport Total from \"./Total\";\n\nexport default function App({}) {\n  // Store the actual quantity in separate state to show the mismatch.\n  const [clientQuantity, setClientQuantity] = useState(1);\n  const [quantity, updateQuantityAction, isPending] = useActionState(\n    async (prevState, payload) => {\n      setClientQuantity(payload);\n      const savedQuantity = await updateQuantity(payload);\n      return savedQuantity; // Return the new quantity to update the state\n    },\n    1 // Initial quantity\n  );\n\n  return (\n    <div>\n      <h1>Checkout</h1>\n      <Item action={updateQuantityAction}/>\n      <hr />\n      <Total clientQuantity={clientQuantity} savedQuantity={quantity} isPending={isPending} />\n    </div>\n  );\n}\n\n\nShow more\nPREVIOUS\nuseSyncExternalStore\nNEXT\nComponents"
  },
  {
    "title": "Built-in React Components – React",
    "url": "https://react.dev/reference/react/components",
    "html": "API REFERENCE\nBuilt-in React Components\n\nReact exposes a few built-in components that you can use in your JSX.\n\nBuilt-in components \n<Fragment>, alternatively written as <>...</>, lets you group multiple JSX nodes together.\n<Profiler> lets you measure rendering performance of a React tree programmatically.\n<Suspense> lets you display a fallback while the child components are loading.\n<StrictMode> enables extra development-only checks that help you find bugs early.\n<Activity> lets you hide and restore the UI and internal state of its children.\nYour own components \n\nYou can also define your own components as JavaScript functions.\n\nPREVIOUS\nuseTransition\nNEXT\n<Fragment> (<>)"
  },
  {
    "title": "<Fragment> (<>...</>) – React",
    "url": "https://react.dev/reference/react/Fragment",
    "html": "API REFERENCE\nCOMPONENTS\n<Fragment> (<>...</>)\n\n<Fragment>, often used via <>...</> syntax, lets you group elements without a wrapper node.\n\nCanary\nFragments can also accept refs, which enable interacting with underlying DOM nodes without adding wrapper elements. See reference and usage below.\n<>\n\n  <OneChild />\n\n  <AnotherChild />\n\n</>\nReference\n<Fragment>\nCanary only FragmentInstance\nUsage\nReturning multiple elements\nAssigning multiple elements to a variable\nGrouping elements with text\nRendering a list of Fragments\nCanary only Using Fragment refs for DOM interaction\nCanary only Tracking visibility with Fragment refs\nCanary only Focus management with Fragment refs\nReference \n<Fragment> \n\nWrap elements in <Fragment> to group them together in situations where you need a single element. Grouping elements in Fragment has no effect on the resulting DOM; it is the same as if the elements were not grouped. The empty JSX tag <></> is shorthand for <Fragment></Fragment> in most cases.\n\nProps \noptional key: Fragments declared with the explicit <Fragment> syntax may have keys.\nCanary only optional ref: A ref object (e.g. from useRef) or callback function. React provides a FragmentInstance as the ref value that implements methods for interacting with the DOM nodes wrapped by the Fragment.\nCanary only FragmentInstance \n\nWhen you pass a ref to a fragment, React provides a FragmentInstance object with methods for interacting with the DOM nodes wrapped by the fragment:\n\nEvent handling methods:\n\naddEventListener(type, listener, options?): Adds an event listener to all first-level DOM children of the Fragment.\nremoveEventListener(type, listener, options?): Removes an event listener from all first-level DOM children of the Fragment.\ndispatchEvent(event): Dispatches an event to a virtual child of the Fragment to call any added listeners and can bubble to the DOM parent.\n\nLayout methods:\n\ncompareDocumentPosition(otherNode): Compares the document position of the Fragment with another node.\nIf the Fragment has children, the native compareDocumentPosition value is returned.\nEmpty Fragments will attempt to compare positioning within the React tree and include Node.DOCUMENT_POSITION_IMPLEMENTATION_SPECIFIC.\nElements that have a different relationship in the React tree and DOM tree due to portaling or other insertions are Node.DOCUMENT_POSITION_IMPLEMENTATION_SPECIFIC.\ngetClientRects(): Returns a flat array of DOMRect objects representing the bounding rectangles of all children.\ngetRootNode(): Returns the root node containing the Fragment’s parent DOM node.\n\nFocus management methods:\n\nfocus(options?): Focuses the first focusable DOM node in the Fragment. Focus is attempted on nested children depth-first.\nfocusLast(options?): Focuses the last focusable DOM node in the Fragment. Focus is attempted on nested children depth-first.\nblur(): Removes focus if document.activeElement is within the Fragment.\n\nObserver methods:\n\nobserveUsing(observer): Starts observing the Fragment’s DOM children with an IntersectionObserver or ResizeObserver.\nunobserveUsing(observer): Stops observing the Fragment’s DOM children with the specified observer.\nCaveats \n\nIf you want to pass key to a Fragment, you can’t use the <>...</> syntax. You have to explicitly import Fragment from 'react' and render <Fragment key={yourKey}>...</Fragment>.\n\nReact does not reset state when you go from rendering <><Child /></> to [<Child />] or back, or when you go from rendering <><Child /></> to <Child /> and back. This only works a single level deep: for example, going from <><><Child /></></> to <Child /> resets the state. See the precise semantics here.\n\nCanary only If you want to pass ref to a Fragment, you can’t use the <>...</> syntax. You have to explicitly import Fragment from 'react' and render <Fragment ref={yourRef}>...</Fragment>.\n\nUsage \nReturning multiple elements \n\nUse Fragment, or the equivalent <>...</> syntax, to group multiple elements together. You can use it to put multiple elements in any place where a single element can go. For example, a component can only return one element, but by using a Fragment you can group multiple elements together and then return them as a group:\n\nfunction Post() {\n\n  return (\n\n    <>\n\n      <PostTitle />\n\n      <PostBody />\n\n    </>\n\n  );\n\n}\n\nFragments are useful because grouping elements with a Fragment has no effect on layout or styles, unlike if you wrapped the elements in another container like a DOM element. If you inspect this example with the browser tools, you’ll see that all <h1> and <article> DOM nodes appear as siblings without wrappers around them:\n\nApp.js\nDownload\nReload\nClear\nFork\nexport default function Blog() {\n  return (\n    <>\n      <Post title=\"An update\" body=\"It's been a while since I posted...\" />\n      <Post title=\"My new blog\" body=\"I am starting a new blog!\" />\n    </>\n  )\n}\n\nfunction Post({ title, body }) {\n  return (\n    <>\n      <PostTitle title={title} />\n      <PostBody body={body} />\n    </>\n  );\n}\n\nfunction PostTitle({ title }) {\n  return <h1>{title}</h1>\n}\n\nfunction PostBody({ body }) {\n  return (\n    <article>\n      <p>{body}</p>\n    </article>\n  );\n}\n\n\nShow more\nDEEP DIVE\nHow to write a Fragment without the special syntax? \nShow Details\nAssigning multiple elements to a variable \n\nLike any other element, you can assign Fragment elements to variables, pass them as props, and so on:\n\nfunction CloseDialog() {\n\n  const buttons = (\n\n    <>\n\n      <OKButton />\n\n      <CancelButton />\n\n    </>\n\n  );\n\n  return (\n\n    <AlertDialog buttons={buttons}>\n\n      Are you sure you want to leave this page?\n\n    </AlertDialog>\n\n  );\n\n}\nGrouping elements with text \n\nYou can use Fragment to group text together with components:\n\nfunction DateRangePicker({ start, end }) {\n\n  return (\n\n    <>\n\n      From\n\n      <DatePicker date={start} />\n\n      to\n\n      <DatePicker date={end} />\n\n    </>\n\n  );\n\n}\nRendering a list of Fragments \n\nHere’s a situation where you need to write Fragment explicitly instead of using the <></> syntax. When you render multiple elements in a loop, you need to assign a key to each element. If the elements within the loop are Fragments, you need to use the normal JSX element syntax in order to provide the key attribute:\n\nfunction Blog() {\n\n  return posts.map(post =>\n\n    <Fragment key={post.id}>\n\n      <PostTitle title={post.title} />\n\n      <PostBody body={post.body} />\n\n    </Fragment>\n\n  );\n\n}\n\nYou can inspect the DOM to verify that there are no wrapper elements around the Fragment children:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Fragment } from 'react';\n\nconst posts = [\n  { id: 1, title: 'An update', body: \"It's been a while since I posted...\" },\n  { id: 2, title: 'My new blog', body: 'I am starting a new blog!' }\n];\n\nexport default function Blog() {\n  return posts.map(post =>\n    <Fragment key={post.id}>\n      <PostTitle title={post.title} />\n      <PostBody body={post.body} />\n    </Fragment>\n  );\n}\n\nfunction PostTitle({ title }) {\n  return <h1>{title}</h1>\n}\n\nfunction PostBody({ body }) {\n  return (\n    <article>\n      <p>{body}</p>\n    </article>\n  );\n}\n\n\nShow more\nCanary only Using Fragment refs for DOM interaction \n\nFragment refs allow you to interact with the DOM nodes wrapped by a Fragment without adding extra wrapper elements. This is useful for event handling, visibility tracking, focus management, and replacing deprecated patterns like ReactDOM.findDOMNode().\n\nimport { Fragment } from 'react';\n\n\n\nfunction ClickableFragment({ children, onClick }) {\n\n  return (\n\n    <Fragment ref={fragmentInstance => {\n\n      fragmentInstance.addEventListener('click', handleClick);\n\n      return () => fragmentInstance.removeEventListener('click', handleClick);\n\n    }}>\n\n      {children}\n\n    </Fragment>\n\n  );\n\n}\nCanary only Tracking visibility with Fragment refs \n\nFragment refs are useful for visibility tracking and intersection observation. This enables you to monitor when content becomes visible without requiring the child Components to expose refs:\n\nimport { Fragment, useRef, useLayoutEffect } from 'react';\n\n\n\nfunction VisibilityObserverFragment({ threshold = 0.5, onVisibilityChange, children }) {\n\n  const fragmentRef = useRef(null);\n\n\n\n  useLayoutEffect(() => {\n\n    const observer = new IntersectionObserver(\n\n      (entries) => {\n\n        onVisibilityChange(entries.some(entry => entry.isIntersecting))\n\n      },\n\n      { threshold }\n\n    );\n\n    \n\n    fragmentRef.current.observeUsing(observer);\n\n    return () => fragmentRef.current.unobserveUsing(observer);\n\n  }, [threshold, onVisibilityChange]);\n\n\n\n  return (\n\n    <Fragment ref={fragmentRef}>\n\n      {children}\n\n    </Fragment>\n\n  );\n\n}\n\n\n\nfunction MyComponent() {\n\n  const handleVisibilityChange = (isVisible) => {\n\n    console.log('Component is', isVisible ? 'visible' : 'hidden');\n\n  };\n\n\n\n  return (\n\n    <VisibilityObserverFragment onVisibilityChange={handleVisibilityChange}>\n\n      <SomeThirdPartyComponent />\n\n      <AnotherComponent />\n\n    </VisibilityObserverFragment>\n\n  );\n\n}\n\nThis pattern is an alternative to Effect-based visibility logging, which is an anti-pattern in most cases. Relying on Effects alone does not guarantee that the rendered Component is observable by the user.\n\nCanary only Focus management with Fragment refs \n\nFragment refs provide focus management methods that work across all DOM nodes within the Fragment:\n\nimport { Fragment, useRef } from 'react';\n\n\n\nfunction FocusFragment({ children }) {\n\n  return (\n\n    <Fragment ref={(fragmentInstance) => fragmentInstance?.focus()}>\n\n      {children}\n\n    </Fragment>\n\n  );\n\n}\n\nThe focus() method focuses the first focusable element within the Fragment, while focusLast() focuses the last focusable element.\n\nPREVIOUS\nComponents\nNEXT\n<Profiler>"
  },
  {
    "title": "<Profiler> – React",
    "url": "https://react.dev/reference/react/Profiler",
    "html": "API REFERENCE\nCOMPONENTS\n<Profiler>\n\n<Profiler> lets you measure rendering performance of a React tree programmatically.\n\n<Profiler id=\"App\" onRender={onRender}>\n\n  <App />\n\n</Profiler>\nReference\n<Profiler>\nonRender callback\nUsage\nMeasuring rendering performance programmatically\nMeasuring different parts of the application\nReference \n<Profiler> \n\nWrap a component tree in a <Profiler> to measure its rendering performance.\n\n<Profiler id=\"App\" onRender={onRender}>\n\n  <App />\n\n</Profiler>\nProps \nid: A string identifying the part of the UI you are measuring.\nonRender: An onRender callback that React calls every time components within the profiled tree update. It receives information about what was rendered and how much time it took.\nCaveats \nProfiling adds some additional overhead, so it is disabled in the production build by default. To opt into production profiling, you need to enable a special production build with profiling enabled.\nonRender callback \n\nReact will call your onRender callback with information about what was rendered.\n\nfunction onRender(id, phase, actualDuration, baseDuration, startTime, commitTime) {\n\n  // Aggregate or log render timings...\n\n}\nParameters \nid: The string id prop of the <Profiler> tree that has just committed. This lets you identify which part of the tree was committed if you are using multiple profilers.\nphase: \"mount\", \"update\" or \"nested-update\". This lets you know whether the tree has just been mounted for the first time or re-rendered due to a change in props, state, or Hooks.\nactualDuration: The number of milliseconds spent rendering the <Profiler> and its descendants for the current update. This indicates how well the subtree makes use of memoization (e.g. memo and useMemo). Ideally this value should decrease significantly after the initial mount as many of the descendants will only need to re-render if their specific props change.\nbaseDuration: The number of milliseconds estimating how much time it would take to re-render the entire <Profiler> subtree without any optimizations. It is calculated by summing up the most recent render durations of each component in the tree. This value estimates a worst-case cost of rendering (e.g. the initial mount or a tree with no memoization). Compare actualDuration against it to see if memoization is working.\nstartTime: A numeric timestamp for when React began rendering the current update.\ncommitTime: A numeric timestamp for when React committed the current update. This value is shared between all profilers in a commit, enabling them to be grouped if desirable.\nUsage \nMeasuring rendering performance programmatically \n\nWrap the <Profiler> component around a React tree to measure its rendering performance.\n\n<App>\n\n  <Profiler id=\"Sidebar\" onRender={onRender}>\n\n    <Sidebar />\n\n  </Profiler>\n\n  <PageContent />\n\n</App>\n\nIt requires two props: an id (string) and an onRender callback (function) which React calls any time a component within the tree “commits” an update.\n\nPitfall\n\nProfiling adds some additional overhead, so it is disabled in the production build by default. To opt into production profiling, you need to enable a special production build with profiling enabled.\n\nNote\n\n<Profiler> lets you gather measurements programmatically. If you’re looking for an interactive profiler, try the Profiler tab in React Developer Tools. It exposes similar functionality as a browser extension.\n\nComponents wrapped in <Profiler> will also be marked in the Component tracks of React Performance tracks even in profiling builds.\nIn development builds, all components are marked in the Components track regardless of whether they’re wrapped in <Profiler>.\n\nMeasuring different parts of the application \n\nYou can use multiple <Profiler> components to measure different parts of your application:\n\n<App>\n\n  <Profiler id=\"Sidebar\" onRender={onRender}>\n\n    <Sidebar />\n\n  </Profiler>\n\n  <Profiler id=\"Content\" onRender={onRender}>\n\n    <Content />\n\n  </Profiler>\n\n</App>\n\nYou can also nest <Profiler> components:\n\n<App>\n\n  <Profiler id=\"Sidebar\" onRender={onRender}>\n\n    <Sidebar />\n\n  </Profiler>\n\n  <Profiler id=\"Content\" onRender={onRender}>\n\n    <Content>\n\n      <Profiler id=\"Editor\" onRender={onRender}>\n\n        <Editor />\n\n      </Profiler>\n\n      <Preview />\n\n    </Content>\n\n  </Profiler>\n\n</App>\n\nAlthough <Profiler> is a lightweight component, it should be used only when necessary. Each use adds some CPU and memory overhead to an application.\n\nPREVIOUS\n<Fragment> (<>)\nNEXT\n<StrictMode>"
  },
  {
    "title": "<StrictMode> – React",
    "url": "https://react.dev/reference/react/StrictMode",
    "html": "API REFERENCE\nCOMPONENTS\n<StrictMode>\n\n<StrictMode> lets you find common bugs in your components early during development.\n\n<StrictMode>\n\n  <App />\n\n</StrictMode>\nReference\n<StrictMode>\nUsage\nEnabling Strict Mode for entire app\nEnabling Strict Mode for a part of the app\nFixing bugs found by double rendering in development\nFixing bugs found by re-running Effects in development\nFixing bugs found by re-running ref callbacks in development\nFixing deprecation warnings enabled by Strict Mode\nReference \n<StrictMode> \n\nUse StrictMode to enable additional development behaviors and warnings for the component tree inside:\n\nimport { StrictMode } from 'react';\n\nimport { createRoot } from 'react-dom/client';\n\n\n\nconst root = createRoot(document.getElementById('root'));\n\nroot.render(\n\n  <StrictMode>\n\n    <App />\n\n  </StrictMode>\n\n);\n\nSee more examples below.\n\nStrict Mode enables the following development-only behaviors:\n\nYour components will re-render an extra time to find bugs caused by impure rendering.\nYour components will re-run Effects an extra time to find bugs caused by missing Effect cleanup.\nYour components will re-run refs callbacks an extra time to find bugs caused by missing ref cleanup.\nYour components will be checked for usage of deprecated APIs.\nProps \n\nStrictMode accepts no props.\n\nCaveats \nThere is no way to opt out of Strict Mode inside a tree wrapped in <StrictMode>. This gives you confidence that all components inside <StrictMode> are checked. If two teams working on a product disagree whether they find the checks valuable, they need to either reach consensus or move <StrictMode> down in the tree.\nUsage \nEnabling Strict Mode for entire app \n\nStrict Mode enables extra development-only checks for the entire component tree inside the <StrictMode> component. These checks help you find common bugs in your components early in the development process.\n\nTo enable Strict Mode for your entire app, wrap your root component with <StrictMode> when you render it:\n\nimport { StrictMode } from 'react';\n\nimport { createRoot } from 'react-dom/client';\n\n\n\nconst root = createRoot(document.getElementById('root'));\n\nroot.render(\n\n  <StrictMode>\n\n    <App />\n\n  </StrictMode>\n\n);\n\nWe recommend wrapping your entire app in Strict Mode, especially for newly created apps. If you use a framework that calls createRoot for you, check its documentation for how to enable Strict Mode.\n\nAlthough the Strict Mode checks only run in development, they help you find bugs that already exist in your code but can be tricky to reliably reproduce in production. Strict Mode lets you fix bugs before your users report them.\n\nNote\n\nStrict Mode enables the following checks in development:\n\nYour components will re-render an extra time to find bugs caused by impure rendering.\nYour components will re-run Effects an extra time to find bugs caused by missing Effect cleanup.\nYour components will re-run ref callbacks an extra time to find bugs caused by missing ref cleanup.\nYour components will be checked for usage of deprecated APIs.\n\nAll of these checks are development-only and do not impact the production build.\n\nEnabling Strict Mode for a part of the app \n\nYou can also enable Strict Mode for any part of your application:\n\nimport { StrictMode } from 'react';\n\n\n\nfunction App() {\n\n  return (\n\n    <>\n\n      <Header />\n\n      <StrictMode>\n\n        <main>\n\n          <Sidebar />\n\n          <Content />\n\n        </main>\n\n      </StrictMode>\n\n      <Footer />\n\n    </>\n\n  );\n\n}\n\nIn this example, Strict Mode checks will not run against the Header and Footer components. However, they will run on Sidebar and Content, as well as all of the components inside them, no matter how deep.\n\nNote\n\nWhen StrictMode is enabled for a part of the app, React will only enable behaviors that are possible in production. For example, if <StrictMode> is not enabled at the root of the app, it will not re-run Effects an extra time on initial mount, since this would cause child effects to double fire without the parent effects, which cannot happen in production.\n\nFixing bugs found by double rendering in development \n\nReact assumes that every component you write is a pure function. This means that React components you write must always return the same JSX given the same inputs (props, state, and context).\n\nComponents breaking this rule behave unpredictably and cause bugs. To help you find accidentally impure code, Strict Mode calls some of your functions (only the ones that should be pure) twice in development. This includes:\n\nYour component function body (only top-level logic, so this doesn’t include code inside event handlers)\nFunctions that you pass to useState, set functions, useMemo, or useReducer\nSome class component methods like constructor, render, shouldComponentUpdate (see the whole list)\n\nIf a function is pure, running it twice does not change its behavior because a pure function produces the same result every time. However, if a function is impure (for example, it mutates the data it receives), running it twice tends to be noticeable (that’s what makes it impure!) This helps you spot and fix the bug early.\n\nHere is an example to illustrate how double rendering in Strict Mode helps you find bugs early.\n\nThis StoryTray component takes an array of stories and adds one last “Create Story” item at the end:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nexport default function StoryTray({ stories }) {\n  const items = stories;\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul>\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\n\nThere is a mistake in the code above. However, it is easy to miss because the initial output appears correct.\n\nThis mistake will become more noticeable if the StoryTray component re-renders multiple times. For example, let’s make the StoryTray re-render with a different background color whenever you hover over it:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function StoryTray({ stories }) {\n  const [isHover, setIsHover] = useState(false);\n  const items = stories;\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul\n      onPointerEnter={() => setIsHover(true)}\n      onPointerLeave={() => setIsHover(false)}\n      style={{\n        backgroundColor: isHover ? '#ddd' : '#fff'\n      }}\n    >\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\nShow more\n\nNotice how every time you hover over the StoryTray component, “Create Story” gets added to the list again. The intention of the code was to add it once at the end. But StoryTray directly modifies the stories array from the props. Every time StoryTray renders, it adds “Create Story” again at the end of the same array. In other words, StoryTray is not a pure function—running it multiple times produces different results.\n\nTo fix this problem, you can make a copy of the array, and modify that copy instead of the original one:\n\nexport default function StoryTray({ stories }) {\n\n  const items = stories.slice(); // Clone the array\n\n  // ✅ Good: Pushing into a new array\n\n  items.push({ id: 'create', label: 'Create Story' });\n\nThis would make the StoryTray function pure. Each time it is called, it would only modify a new copy of the array, and would not affect any external objects or variables. This solves the bug, but you had to make the component re-render more often before it became obvious that something is wrong with its behavior.\n\nIn the original example, the bug wasn’t obvious. Now let’s wrap the original (buggy) code in <StrictMode>:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nexport default function StoryTray({ stories }) {\n  const items = stories;\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul>\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\n\nStrict Mode always calls your rendering function twice, so you can see the mistake right away (“Create Story” appears twice). This lets you notice such mistakes early in the process. When you fix your component to render in Strict Mode, you also fix many possible future production bugs like the hover functionality from before:\n\nindex.js\nApp.js\nStoryTray.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function StoryTray({ stories }) {\n  const [isHover, setIsHover] = useState(false);\n  const items = stories.slice(); // Clone the array\n  items.push({ id: 'create', label: 'Create Story' });\n  return (\n    <ul\n      onPointerEnter={() => setIsHover(true)}\n      onPointerLeave={() => setIsHover(false)}\n      style={{\n        backgroundColor: isHover ? '#ddd' : '#fff'\n      }}\n    >\n      {items.map(story => (\n        <li key={story.id}>\n          {story.label}\n        </li>\n      ))}\n    </ul>\n  );\n}\n\n\nShow more\n\nWithout Strict Mode, it was easy to miss the bug until you added more re-renders. Strict Mode made the same bug appear right away. Strict Mode helps you find bugs before you push them to your team and to your users.\n\nRead more about keeping components pure.\n\nNote\n\nIf you have React DevTools installed, any console.log calls during the second render call will appear slightly dimmed. React DevTools also offers a setting (off by default) to suppress them completely.\n\nFixing bugs found by re-running Effects in development \n\nStrict Mode can also help find bugs in Effects.\n\nEvery Effect has some setup code and may have some cleanup code. Normally, React calls setup when the component mounts (is added to the screen) and calls cleanup when the component unmounts (is removed from the screen). React then calls cleanup and setup again if its dependencies changed since the last render.\n\nWhen Strict Mode is on, React will also run one extra setup+cleanup cycle in development for every Effect. This may feel surprising, but it helps reveal subtle bugs that are hard to catch manually.\n\nHere is an example to illustrate how re-running Effects in Strict Mode helps you find bugs early.\n\nConsider this example that connects a component to a chat:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(<App />);\n\n\n\nThere is an issue with this code, but it might not be immediately clear.\n\nTo make the issue more obvious, let’s implement a feature. In the example below, roomId is not hardcoded. Instead, the user can select the roomId that they want to connect to from a dropdown. Click “Open chat” and then select different chat rooms one by one. Keep track of the number of active connections in the console:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(<App />);\n\n\n\nYou’ll notice that the number of open connections always keeps growing. In a real app, this would cause performance and network problems. The issue is that your Effect is missing a cleanup function:\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => connection.disconnect();\n\n  }, [roomId]);\n\nNow that your Effect “cleans up” after itself and destroys the outdated connections, the leak is solved. However, notice that the problem did not become visible until you’ve added more features (the select box).\n\nIn the original example, the bug wasn’t obvious. Now let’s wrap the original (buggy) code in <StrictMode>:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { StrictMode } from 'react';\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(\n  <StrictMode>\n    <App />\n  </StrictMode>\n);\n\n\n\nWith Strict Mode, you immediately see that there is a problem (the number of active connections jumps to 2). Strict Mode runs an extra setup+cleanup cycle for every Effect. This Effect has no cleanup logic, so it creates an extra connection but doesn’t destroy it. This is a hint that you’re missing a cleanup function.\n\nStrict Mode lets you notice such mistakes early in the process. When you fix your Effect by adding a cleanup function in Strict Mode, you also fix many possible future production bugs like the select box from before:\n\nindex.js\nApp.js\nchat.js\nReload\nClear\nFork\nimport { StrictMode } from 'react';\nimport { createRoot } from 'react-dom/client';\nimport './styles.css';\n\nimport App from './App';\n\nconst root = createRoot(document.getElementById(\"root\"));\nroot.render(\n  <StrictMode>\n    <App />\n  </StrictMode>\n);\n\n\n\nNotice how the active connection count in the console doesn’t keep growing anymore.\n\nWithout Strict Mode, it was easy to miss that your Effect needed cleanup. By running setup → cleanup → setup instead of setup for your Effect in development, Strict Mode made the missing cleanup logic more noticeable.\n\nRead more about implementing Effect cleanup.\n\nFixing bugs found by re-running ref callbacks in development \n\nStrict Mode can also help find bugs in callbacks refs.\n\nEvery callback ref has some setup code and may have some cleanup code. Normally, React calls setup when the element is created (is added to the DOM) and calls cleanup when the element is removed (is removed from the DOM).\n\nWhen Strict Mode is on, React will also run one extra setup+cleanup cycle in development for every callback ref. This may feel surprising, but it helps reveal subtle bugs that are hard to catch manually.\n\nConsider this example, which allows you to select an animal and then scroll to one of them. Notice when you switch from “Cats” to “Dogs”, the console logs show that the number of animals in the list keeps growing, and the “Scroll to” buttons stop working:\n\nindex.js\nApp.js\nReload\nClear\nFork\nimport { useRef, useState } from \"react\";\n\nexport default function CatFriends() {\n  const itemsRef = useRef([]);\n  const [catList, setCatList] = useState(setupCatList);\n  const [cat, setCat] = useState('neo');\n\n  function scrollToCat(index) {\n    const list = itemsRef.current;\n    const {node} = list[index];\n    node.scrollIntoView({\n      behavior: \"smooth\",\n      block: \"nearest\",\n      inline: \"center\",\n    });\n  }\n\n  const cats = catList.filter(c => c.type === cat)\n\n  return (\n    <>\n      <nav>\n        <button onClick={() => setCat('neo')}>Neo</button>\n        <button onClick={() => setCat('millie')}>Millie</button>\n      </nav>\n      <hr />\n      <nav>\n        <span>Scroll to:</span>{cats.map((cat, index) => (\n          <button key={cat.src} onClick={() => scrollToCat(index)}>\n            {index}\n          </button>\n        ))}\n      </nav>\n      <div>\n        <ul>\n          {cats.map((cat) => (\n            <li\n              key={cat.src}\n              ref={(node) => {\n                const list = itemsRef.current;\n                const item = {cat: cat, node};\n                list.push(item);\n                console.log(`✅ Adding cat to the map. Total cats: ${list.length}`);\n                if (list.length > 10) {\n                  console.log('❌ Too many cats in the list!');\n                }\n                return () => {\n                  // 🚩 No cleanup, this is a bug!\n                }\n              }}\n            >\n              <img src={cat.src} />\n            </li>\n          ))}\n        </ul>\n      </div>\n    </>\n  );\n}\n\nfunction setupCatList() {\n  const catList = [];\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'neo', src: \"https://placecats.com/neo/320/240?\" + i});\n  }\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'millie', src: \"https://placecats.com/millie/320/240?\" + i});\n  }\n\n  return catList;\n}\n\n\nShow more\n\nThis is a production bug! Since the ref callback doesn’t remove animals from the list in the cleanup, the list of animals keeps growing. This is a memory leak that can cause performance problems in a real app, and breaks the behavior of the app.\n\nThe issue is the ref callback doesn’t cleanup after itself:\n\n<li\n\n  ref={node => {\n\n    const list = itemsRef.current;\n\n    const item = {animal, node};\n\n    list.push(item);\n\n    return () => {\n\n      // 🚩 No cleanup, this is a bug!\n\n    }\n\n  }}\n\n</li>\n\nNow let’s wrap the original (buggy) code in <StrictMode>:\n\nindex.js\nApp.js\nReload\nClear\nFork\nimport { useRef, useState } from \"react\";\n\nexport default function CatFriends() {\n  const itemsRef = useRef([]);\n  const [catList, setCatList] = useState(setupCatList);\n  const [cat, setCat] = useState('neo');\n\n  function scrollToCat(index) {\n    const list = itemsRef.current;\n    const {node} = list[index];\n    node.scrollIntoView({\n      behavior: \"smooth\",\n      block: \"nearest\",\n      inline: \"center\",\n    });\n  }\n\n  const cats = catList.filter(c => c.type === cat)\n\n  return (\n    <>\n      <nav>\n        <button onClick={() => setCat('neo')}>Neo</button>\n        <button onClick={() => setCat('millie')}>Millie</button>\n      </nav>\n      <hr />\n      <nav>\n        <span>Scroll to:</span>{cats.map((cat, index) => (\n          <button key={cat.src} onClick={() => scrollToCat(index)}>\n            {index}\n          </button>\n        ))}\n      </nav>\n      <div>\n        <ul>\n          {cats.map((cat) => (\n            <li\n              key={cat.src}\n              ref={(node) => {\n                const list = itemsRef.current;\n                const item = {cat: cat, node};\n                list.push(item);\n                console.log(`✅ Adding cat to the map. Total cats: ${list.length}`);\n                if (list.length > 10) {\n                  console.log('❌ Too many cats in the list!');\n                }\n                return () => {\n                  // 🚩 No cleanup, this is a bug!\n                }\n              }}\n            >\n              <img src={cat.src} />\n            </li>\n          ))}\n        </ul>\n      </div>\n    </>\n  );\n}\n\nfunction setupCatList() {\n  const catList = [];\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'neo', src: \"https://placecats.com/neo/320/240?\" + i});\n  }\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'millie', src: \"https://placecats.com/millie/320/240?\" + i});\n  }\n\n  return catList;\n}\n\n\nShow more\n\nWith Strict Mode, you immediately see that there is a problem. Strict Mode runs an extra setup+cleanup cycle for every callback ref. This callback ref has no cleanup logic, so it adds refs but doesn’t remove them. This is a hint that you’re missing a cleanup function.\n\nStrict Mode lets you eagerly find mistakes in callback refs. When you fix your callback by adding a cleanup function in Strict Mode, you also fix many possible future production bugs like the “Scroll to” bug from before:\n\nindex.js\nApp.js\nReload\nClear\nFork\nimport { useRef, useState } from \"react\";\n\nexport default function CatFriends() {\n  const itemsRef = useRef([]);\n  const [catList, setCatList] = useState(setupCatList);\n  const [cat, setCat] = useState('neo');\n\n  function scrollToCat(index) {\n    const list = itemsRef.current;\n    const {node} = list[index];\n    node.scrollIntoView({\n      behavior: \"smooth\",\n      block: \"nearest\",\n      inline: \"center\",\n    });\n  }\n\n  const cats = catList.filter(c => c.type === cat)\n\n  return (\n    <>\n      <nav>\n        <button onClick={() => setCat('neo')}>Neo</button>\n        <button onClick={() => setCat('millie')}>Millie</button>\n      </nav>\n      <hr />\n      <nav>\n        <span>Scroll to:</span>{cats.map((cat, index) => (\n          <button key={cat.src} onClick={() => scrollToCat(index)}>\n            {index}\n          </button>\n        ))}\n      </nav>\n      <div>\n        <ul>\n          {cats.map((cat) => (\n            <li\n              key={cat.src}\n              ref={(node) => {\n                const list = itemsRef.current;\n                const item = {cat: cat, node};\n                list.push(item);\n                console.log(`✅ Adding cat to the map. Total cats: ${list.length}`);\n                if (list.length > 10) {\n                  console.log('❌ Too many cats in the list!');\n                }\n                return () => {\n                  list.splice(list.indexOf(item), 1);\n                  console.log(`❌ Removing cat from the map. Total cats: ${itemsRef.current.length}`);\n                }\n              }}\n            >\n              <img src={cat.src} />\n            </li>\n          ))}\n        </ul>\n      </div>\n    </>\n  );\n}\n\nfunction setupCatList() {\n  const catList = [];\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'neo', src: \"https://placecats.com/neo/320/240?\" + i});\n  }\n  for (let i = 0; i < 10; i++) {\n    catList.push({type: 'millie', src: \"https://placecats.com/millie/320/240?\" + i});\n  }\n\n  return catList;\n}\n\n\nShow more\n\nNow on inital mount in StrictMode, the ref callbacks are all setup, cleaned up, and setup again:\n\n...\n\n✅ Adding animal to the map. Total animals: 10\n\n...\n\n❌ Removing animal from the map. Total animals: 0\n\n...\n\n✅ Adding animal to the map. Total animals: 10\n\nThis is expected. Strict Mode confirms that the ref callbacks are cleaned up correctly, so the size never grows above the expected amount. After the fix, there are no memory leaks, and all the features work as expected.\n\nWithout Strict Mode, it was easy to miss the bug until you clicked around to app to notice broken features. Strict Mode made the bugs appear right away, before you push them to production.\n\nFixing deprecation warnings enabled by Strict Mode \n\nReact warns if some component anywhere inside a <StrictMode> tree uses one of these deprecated APIs:\n\nUNSAFE_ class lifecycle methods like UNSAFE_componentWillMount. See alternatives.\n\nThese APIs are primarily used in older class components so they rarely appear in modern apps.\n\nPREVIOUS\n<Profiler>\nNEXT\n<Suspense>"
  },
  {
    "title": "<Suspense> – React",
    "url": "https://react.dev/reference/react/Suspense",
    "html": "API REFERENCE\nCOMPONENTS\n<Suspense>\n\n<Suspense> lets you display a fallback until its children have finished loading.\n\n<Suspense fallback={<Loading />}>\n\n  <SomeComponent />\n\n</Suspense>\nReference\n<Suspense>\nUsage\nDisplaying a fallback while content is loading\nRevealing content together at once\nRevealing nested content as it loads\nShowing stale content while fresh content is loading\nPreventing already revealed content from hiding\nIndicating that a Transition is happening\nResetting Suspense boundaries on navigation\nProviding a fallback for server errors and client-only content\nTroubleshooting\nHow do I prevent the UI from being replaced by a fallback during an update?\nReference \n<Suspense> \nProps \nchildren: The actual UI you intend to render. If children suspends while rendering, the Suspense boundary will switch to rendering fallback.\nfallback: An alternate UI to render in place of the actual UI if it has not finished loading. Any valid React node is accepted, though in practice, a fallback is a lightweight placeholder view, such as a loading spinner or skeleton. Suspense will automatically switch to fallback when children suspends, and back to children when the data is ready. If fallback suspends while rendering, it will activate the closest parent Suspense boundary.\nCaveats \nReact does not preserve any state for renders that got suspended before they were able to mount for the first time. When the component has loaded, React will retry rendering the suspended tree from scratch.\nIf Suspense was displaying content for the tree, but then it suspended again, the fallback will be shown again unless the update causing it was caused by startTransition or useDeferredValue.\nIf React needs to hide the already visible content because it suspended again, it will clean up layout Effects in the content tree. When the content is ready to be shown again, React will fire the layout Effects again. This ensures that Effects measuring the DOM layout don’t try to do this while the content is hidden.\nReact includes under-the-hood optimizations like Streaming Server Rendering and Selective Hydration that are integrated with Suspense. Read an architectural overview and watch a technical talk to learn more.\nUsage \nDisplaying a fallback while content is loading \n\nYou can wrap any part of your application with a Suspense boundary:\n\n<Suspense fallback={<Loading />}>\n\n  <Albums />\n\n</Suspense>\n\nReact will display your loading fallback until all the code and data needed by the children has been loaded.\n\nIn the example below, the Albums component suspends while fetching the list of albums. Until it’s ready to render, React switches the closest Suspense boundary above to show the fallback—your Loading component. Then, when the data loads, React hides the Loading fallback and renders the Albums component with data.\n\nArtistPage.js\nAlbums.js\nReload\nClear\nFork\nimport { Suspense } from 'react';\nimport Albums from './Albums.js';\n\nexport default function ArtistPage({ artist }) {\n  return (\n    <>\n      <h1>{artist.name}</h1>\n      <Suspense fallback={<Loading />}>\n        <Albums artistId={artist.id} />\n      </Suspense>\n    </>\n  );\n}\n\nfunction Loading() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\nNote\n\nOnly Suspense-enabled data sources will activate the Suspense component. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a cached Promise with use\n\nSuspense does not detect when data is fetched inside an Effect or event handler.\n\nThe exact way you would load data in the Albums component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nRevealing content together at once \n\nBy default, the whole tree inside Suspense is treated as a single unit. For example, even if only one of these components suspends waiting for some data, all of them together will be replaced by the loading indicator:\n\n<Suspense fallback={<Loading />}>\n\n  <Biography />\n\n  <Panel>\n\n    <Albums />\n\n  </Panel>\n\n</Suspense>\n\nThen, after all of them are ready to be displayed, they will all appear together at once.\n\nIn the example below, both Biography and Albums fetch some data. However, because they are grouped under a single Suspense boundary, these components always “pop in” together at the same time.\n\nArtistPage.js\nPanel.js\nBiography.js\nAlbums.js\nReload\nClear\nFork\nimport { Suspense } from 'react';\nimport Albums from './Albums.js';\nimport Biography from './Biography.js';\nimport Panel from './Panel.js';\n\nexport default function ArtistPage({ artist }) {\n  return (\n    <>\n      <h1>{artist.name}</h1>\n      <Suspense fallback={<Loading />}>\n        <Biography artistId={artist.id} />\n        <Panel>\n          <Albums artistId={artist.id} />\n        </Panel>\n      </Suspense>\n    </>\n  );\n}\n\nfunction Loading() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\n\nComponents that load data don’t have to be direct children of the Suspense boundary. For example, you can move Biography and Albums into a new Details component. This doesn’t change the behavior. Biography and Albums share the same closest parent Suspense boundary, so their reveal is coordinated together.\n\n<Suspense fallback={<Loading />}>\n\n  <Details artistId={artist.id} />\n\n</Suspense>\n\n\n\nfunction Details({ artistId }) {\n\n  return (\n\n    <>\n\n      <Biography artistId={artistId} />\n\n      <Panel>\n\n        <Albums artistId={artistId} />\n\n      </Panel>\n\n    </>\n\n  );\n\n}\nRevealing nested content as it loads \n\nWhen a component suspends, the closest parent Suspense component shows the fallback. This lets you nest multiple Suspense components to create a loading sequence. Each Suspense boundary’s fallback will be filled in as the next level of content becomes available. For example, you can give the album list its own fallback:\n\n<Suspense fallback={<BigSpinner />}>\n\n  <Biography />\n\n  <Suspense fallback={<AlbumsGlimmer />}>\n\n    <Panel>\n\n      <Albums />\n\n    </Panel>\n\n  </Suspense>\n\n</Suspense>\n\nWith this change, displaying the Biography doesn’t need to “wait” for the Albums to load.\n\nThe sequence will be:\n\nIf Biography hasn’t loaded yet, BigSpinner is shown in place of the entire content area.\nOnce Biography finishes loading, BigSpinner is replaced by the content.\nIf Albums hasn’t loaded yet, AlbumsGlimmer is shown in place of Albums and its parent Panel.\nFinally, once Albums finishes loading, it replaces AlbumsGlimmer.\nArtistPage.js\nPanel.js\nBiography.js\nAlbums.js\nReload\nClear\nFork\nimport { Suspense } from 'react';\nimport Albums from './Albums.js';\nimport Biography from './Biography.js';\nimport Panel from './Panel.js';\n\nexport default function ArtistPage({ artist }) {\n  return (\n    <>\n      <h1>{artist.name}</h1>\n      <Suspense fallback={<BigSpinner />}>\n        <Biography artistId={artist.id} />\n        <Suspense fallback={<AlbumsGlimmer />}>\n          <Panel>\n            <Albums artistId={artist.id} />\n          </Panel>\n        </Suspense>\n      </Suspense>\n    </>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\nfunction AlbumsGlimmer() {\n  return (\n    <div className=\"glimmer-panel\">\n      <div className=\"glimmer-line\" />\n      <div className=\"glimmer-line\" />\n      <div className=\"glimmer-line\" />\n    </div>\n  );\n}\n\n\nShow more\n\nSuspense boundaries let you coordinate which parts of your UI should always “pop in” together at the same time, and which parts should progressively reveal more content in a sequence of loading states. You can add, move, or delete Suspense boundaries in any place in the tree without affecting the rest of your app’s behavior.\n\nDon’t put a Suspense boundary around every component. Suspense boundaries should not be more granular than the loading sequence that you want the user to experience. If you work with a designer, ask them where the loading states should be placed—it’s likely that they’ve already included them in their design wireframes.\n\nShowing stale content while fresh content is loading \n\nIn this example, the SearchResults component suspends while fetching the search results. Type \"a\", wait for the results, and then edit it to \"ab\". The results for \"a\" will get replaced by the loading fallback.\n\nApp.js\nSearchResults.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <SearchResults query={query} />\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nA common alternative UI pattern is to defer updating the list and to keep showing the previous results until the new results are ready. The useDeferredValue Hook lets you pass a deferred version of the query down:\n\nexport default function App() {\n\n  const [query, setQuery] = useState('');\n\n  const deferredQuery = useDeferredValue(query);\n\n  return (\n\n    <>\n\n      <label>\n\n        Search albums:\n\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n\n      </label>\n\n      <Suspense fallback={<h2>Loading...</h2>}>\n\n        <SearchResults query={deferredQuery} />\n\n      </Suspense>\n\n    </>\n\n  );\n\n}\n\nThe query will update immediately, so the input will display the new value. However, the deferredQuery will keep its previous value until the data has loaded, so SearchResults will show the stale results for a bit.\n\nTo make it more obvious to the user, you can add a visual indication when the stale result list is displayed:\n\n<div style={{\n\n  opacity: query !== deferredQuery ? 0.5 : 1 \n\n}}>\n\n  <SearchResults query={deferredQuery} />\n\n</div>\n\nEnter \"a\" in the example below, wait for the results to load, and then edit the input to \"ab\". Notice how instead of the Suspense fallback, you now see the dimmed stale result list until the new results have loaded:\n\nApp.js\nReload\nClear\nFork\nimport { Suspense, useState, useDeferredValue } from 'react';\nimport SearchResults from './SearchResults.js';\n\nexport default function App() {\n  const [query, setQuery] = useState('');\n  const deferredQuery = useDeferredValue(query);\n  const isStale = query !== deferredQuery;\n  return (\n    <>\n      <label>\n        Search albums:\n        <input value={query} onChange={e => setQuery(e.target.value)} />\n      </label>\n      <Suspense fallback={<h2>Loading...</h2>}>\n        <div style={{ opacity: isStale ? 0.5 : 1 }}>\n          <SearchResults query={deferredQuery} />\n        </div>\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\nNote\n\nBoth deferred values and Transitions let you avoid showing Suspense fallback in favor of inline indicators. Transitions mark the whole update as non-urgent so they are typically used by frameworks and router libraries for navigation. Deferred values, on the other hand, are mostly useful in application code where you want to mark a part of UI as non-urgent and let it “lag behind” the rest of the UI.\n\nPreventing already revealed content from hiding \n\nWhen a component suspends, the closest parent Suspense boundary switches to showing the fallback. This can lead to a jarring user experience if it was already displaying some content. Try pressing this button:\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, useState } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n\n  function navigate(url) {\n    setPage(url);\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\n\nWhen you pressed the button, the Router component rendered ArtistPage instead of IndexPage. A component inside ArtistPage suspended, so the closest Suspense boundary started showing the fallback. The closest Suspense boundary was near the root, so the whole site layout got replaced by BigSpinner.\n\nTo prevent this, you can mark the navigation state update as a Transition with startTransition:\n\nfunction Router() {\n\n  const [page, setPage] = useState('/');\n\n\n\n  function navigate(url) {\n\n    startTransition(() => {\n\n      setPage(url);      \n\n    });\n\n  }\n\n  // ...\n\nThis tells React that the state transition is not urgent, and it’s better to keep showing the previous page instead of hiding any already revealed content. Now clicking the button “waits” for the Biography to load:\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, startTransition, useState } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n\n  function navigate(url) {\n    startTransition(() => {\n      setPage(url);\n    });\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\n\nA Transition doesn’t wait for all content to load. It only waits long enough to avoid hiding already revealed content. For example, the website Layout was already revealed, so it would be bad to hide it behind a loading spinner. However, the nested Suspense boundary around Albums is new, so the Transition doesn’t wait for it.\n\nNote\n\nSuspense-enabled routers are expected to wrap the navigation updates into Transitions by default.\n\nIndicating that a Transition is happening \n\nIn the above example, once you click the button, there is no visual indication that a navigation is in progress. To add an indicator, you can replace startTransition with useTransition which gives you a boolean isPending value. In the example below, it’s used to change the website header styling while a Transition is happening:\n\nApp.js\nLayout.js\nIndexPage.js\nArtistPage.js\nAlbums.js\nBiography.js\nPanel.js\nReload\nClear\nFork\nimport { Suspense, useState, useTransition } from 'react';\nimport IndexPage from './IndexPage.js';\nimport ArtistPage from './ArtistPage.js';\nimport Layout from './Layout.js';\n\nexport default function App() {\n  return (\n    <Suspense fallback={<BigSpinner />}>\n      <Router />\n    </Suspense>\n  );\n}\n\nfunction Router() {\n  const [page, setPage] = useState('/');\n  const [isPending, startTransition] = useTransition();\n\n  function navigate(url) {\n    startTransition(() => {\n      setPage(url);\n    });\n  }\n\n  let content;\n  if (page === '/') {\n    content = (\n      <IndexPage navigate={navigate} />\n    );\n  } else if (page === '/the-beatles') {\n    content = (\n      <ArtistPage\n        artist={{\n          id: 'the-beatles',\n          name: 'The Beatles',\n        }}\n      />\n    );\n  }\n  return (\n    <Layout isPending={isPending}>\n      {content}\n    </Layout>\n  );\n}\n\nfunction BigSpinner() {\n  return <h2>🌀 Loading...</h2>;\n}\n\n\nShow more\nResetting Suspense boundaries on navigation \n\nDuring a Transition, React will avoid hiding already revealed content. However, if you navigate to a route with different parameters, you might want to tell React it is different content. You can express this with a key:\n\n<ProfilePage key={queryParams.id} />\n\nImagine you’re navigating within a user’s profile page, and something suspends. If that update is wrapped in a Transition, it will not trigger the fallback for already visible content. That’s the expected behavior.\n\nHowever, now imagine you’re navigating between two different user profiles. In that case, it makes sense to show the fallback. For example, one user’s timeline is different content from another user’s timeline. By specifying a key, you ensure that React treats different users’ profiles as different components, and resets the Suspense boundaries during navigation. Suspense-integrated routers should do this automatically.\n\nProviding a fallback for server errors and client-only content \n\nIf you use one of the streaming server rendering APIs (or a framework that relies on them), React will also use your <Suspense> boundaries to handle errors on the server. If a component throws an error on the server, React will not abort the server render. Instead, it will find the closest <Suspense> component above it and include its fallback (such as a spinner) into the generated server HTML. The user will see a spinner at first.\n\nOn the client, React will attempt to render the same component again. If it errors on the client too, React will throw the error and display the closest Error Boundary. However, if it does not error on the client, React will not display the error to the user since the content was eventually displayed successfully.\n\nYou can use this to opt out some components from rendering on the server. To do this, throw an error in the server environment and then wrap them in a <Suspense> boundary to replace their HTML with fallbacks:\n\n<Suspense fallback={<Loading />}>\n\n  <Chat />\n\n</Suspense>\n\n\n\nfunction Chat() {\n\n  if (typeof window === 'undefined') {\n\n    throw Error('Chat should only render on the client.');\n\n  }\n\n  // ...\n\n}\n\nThe server HTML will include the loading indicator. It will be replaced by the Chat component on the client.\n\nTroubleshooting \nHow do I prevent the UI from being replaced by a fallback during an update? \n\nReplacing visible UI with a fallback creates a jarring user experience. This can happen when an update causes a component to suspend, and the nearest Suspense boundary is already showing content to the user.\n\nTo prevent this from happening, mark the update as non-urgent using startTransition. During a Transition, React will wait until enough data has loaded to prevent an unwanted fallback from appearing:\n\nfunction handleNextPageClick() {\n\n  // If this update suspends, don't hide the already displayed content\n\n  startTransition(() => {\n\n    setCurrentPage(currentPage + 1);\n\n  });\n\n}\n\nThis will avoid hiding existing content. However, any newly rendered Suspense boundaries will still immediately display fallbacks to avoid blocking the UI and let the user see the content as it becomes available.\n\nReact will only prevent unwanted fallbacks during non-urgent updates. It will not delay a render if it’s the result of an urgent update. You must opt in with an API like startTransition or useDeferredValue.\n\nIf your router is integrated with Suspense, it should wrap its updates into startTransition automatically.\n\nPREVIOUS\n<StrictMode>\nNEXT\n<Activity>"
  },
  {
    "title": "<Activity> – React",
    "url": "https://react.dev/reference/react/Activity",
    "html": "API REFERENCE\nCOMPONENTS\n<Activity>\n\n<Activity> lets you hide and restore the UI and internal state of its children.\n\n<Activity mode={visibility}>\n\n  <Sidebar />\n\n</Activity>\nReference\n<Activity>\nUsage\nRestoring the state of hidden components\nRestoring the DOM of hidden components\nPre-rendering content that’s likely to become visible\nSpeeding up interactions during page load\nTroubleshooting\nMy hidden components have unwanted side effects\nMy hidden components have Effects that aren’t running\nReference \n<Activity> \n\nYou can use Activity to hide part of your application:\n\n<Activity mode={isShowingSidebar ? \"visible\" : \"hidden\"}>\n\n  <Sidebar />\n\n</Activity>\n\nWhen an Activity boundary is hidden, React will visually hide its children using the display: \"none\" CSS property. It will also destroy their Effects, cleaning up any active subscriptions.\n\nWhile hidden, children still re-render in response to new props, albeit at a lower priority than the rest of the content.\n\nWhen the boundary becomes visible again, React will reveal the children with their previous state restored, and re-create their Effects.\n\nIn this way, Activity can be thought of as a mechanism for rendering “background activity”. Rather than completely discarding content that’s likely to become visible again, you can use Activity to maintain and restore that content’s UI and internal state, while ensuring that your hidden content has no unwanted side effects.\n\nSee more examples below.\n\nProps \nchildren: The UI you intend to show and hide.\nmode: A string value of either 'visible' or 'hidden'. If omitted, defaults to 'visible'.\nCaveats \nIf an Activity is rendered inside of a ViewTransition, and it becomes visible as a result of an update caused by startTransition, it will activate the ViewTransition’s enter animation. If it becomes hidden, it will activate its exit animation.\nAn Activity that just renders text will not render anything rather than rendering hidden text, because there’s no corresponding DOM element to apply visibility changes to. For example, <Activity mode=\"hidden\"><ComponentThatJustReturnsText /></Activity> will not produce any output in the DOM for const ComponentThatJustReturnsText = () => \"Hello, World!\".\nUsage \nRestoring the state of hidden components \n\nIn React, when you want to conditionally show or hide a component, you typically mount or unmount it based on that condition:\n\n{isShowingSidebar && (\n\n  <Sidebar />\n\n)}\n\nBut unmounting a component destroys its internal state, which is not always what you want.\n\nWhen you hide a component using an Activity boundary instead, React will “save” its state for later:\n\n<Activity mode={isShowingSidebar ? \"visible\" : \"hidden\"}>\n\n  <Sidebar />\n\n</Activity>\n\nThis makes it possible to hide and then later restore components in the state they were previously in.\n\nThe following example has a sidebar with an expandable section. You can press “Overview” to reveal the three subitems below it. The main app area also has a button that hides and shows the sidebar.\n\nTry expanding the Overview section, and then toggling the sidebar closed then open:\n\nApp.js\nSidebar.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport Sidebar from './Sidebar.js';\n\nexport default function App() {\n  const [isShowingSidebar, setIsShowingSidebar] = useState(true);\n\n  return (\n    <>\n      {isShowingSidebar && (\n        <Sidebar />\n      )}\n\n      <main>\n        <button onClick={() => setIsShowingSidebar(!isShowingSidebar)}>\n          Toggle sidebar\n        </button>\n        <h1>Main content</h1>\n      </main>\n    </>\n  );\n}\n\n\nShow more\n\nThe Overview section always starts out collapsed. Because we unmount the sidebar when isShowingSidebar flips to false, all its internal state is lost.\n\nThis is a perfect use case for Activity. We can preserve the internal state of our sidebar, even when visually hiding it.\n\nLet’s replace the conditional rendering of our sidebar with an Activity boundary:\n\n// Before\n\n{isShowingSidebar && (\n\n  <Sidebar />\n\n)}\n\n\n\n// After\n\n<Activity mode={isShowingSidebar ? 'visible' : 'hidden'}>\n\n  <Sidebar />\n\n</Activity>\n\nand check out the new behavior:\n\nApp.js\nSidebar.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\n\nimport Sidebar from './Sidebar.js';\n\nexport default function App() {\n  const [isShowingSidebar, setIsShowingSidebar] = useState(true);\n\n  return (\n    <>\n      <Activity mode={isShowingSidebar ? 'visible' : 'hidden'}>\n        <Sidebar />\n      </Activity>\n\n      <main>\n        <button onClick={() => setIsShowingSidebar(!isShowingSidebar)}>\n          Toggle sidebar\n        </button>\n        <h1>Main content</h1>\n      </main>\n    </>\n  );\n}\n\n\nShow more\n\nOur sidebar’s internal state is now restored, without any changes to its implementation.\n\nRestoring the DOM of hidden components \n\nSince Activity boundaries hide their children using display: none, their children’s DOM is also preserved when hidden. This makes them great for maintaining ephemeral state in parts of the UI that the user is likely to interact with again.\n\nIn this example, the Contact tab has a <textarea> where the user can enter a message. If you enter some text, change to the Home tab, then change back to the Contact tab, the draft message is lost:\n\nApp.js\nTabButton.js\nHome.js\nContact.js\nReload\nClear\nFork\nexport default function Contact() {\n  return (\n    <div>\n      <p>Send me a message!</p>\n\n      <textarea />\n\n      <p>You can find me online here:</p>\n      <ul>\n        <li>admin@mysite.com</li>\n        <li>+123456789</li>\n      </ul>\n    </div>\n  );\n}\n\n\n\nThis is because we’re fully unmounting Contact in App. When the Contact tab unmounts, the <textarea> element’s internal DOM state is lost.\n\nIf we switch to using an Activity boundary to show and hide the active tab, we can preserve the state of each tab’s DOM. Try entering text and switching tabs again, and you’ll see the draft message is no longer reset:\n\nApp.js\nTabButton.js\nHome.js\nContact.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Contact from './Contact.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('contact');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'contact'}\n        onClick={() => setActiveTab('contact')}\n      >\n        Contact\n      </TabButton>\n\n      <hr />\n\n      <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n        <Home />\n      </Activity>\n      <Activity mode={activeTab === 'contact' ? 'visible' : 'hidden'}>\n        <Contact />\n      </Activity>\n    </>\n  );\n}\n\n\nShow more\n\nAgain, the Activity boundary let us preserve the Contact tab’s internal state without changing its implementation.\n\nPre-rendering content that’s likely to become visible \n\nSo far, we’ve seen how Activity can hide some content that the user has interacted with, without discarding that content’s ephemeral state.\n\nBut Activity boundaries can also be used to prepare content that the user has yet to see for the first time:\n\n<Activity mode=\"hidden\">\n\n  <SlowComponent />\n\n</Activity>\n\nWhen an Activity boundary is hidden during its initial render, its children won’t be visible on the page — but they will still be rendered, albeit at a lower priority than the visible content, and without mounting their Effects.\n\nThis pre-rendering allows the children to load any code or data they need ahead of time, so that later, when the Activity boundary becomes visible, the children can appear faster with reduced loading times.\n\nLet’s look at an example.\n\nIn this demo, the Posts tab loads some data. If you press it, you’ll see a Suspense fallback displayed while the data is being fetched:\n\nApp.js\nHome.js\nPosts.js\nReload\nClear\nFork\nimport { useState, Suspense } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Posts from './Posts.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('home');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'posts'}\n        onClick={() => setActiveTab('posts')}\n      >\n        Posts\n      </TabButton>\n\n      <hr />\n\n      <Suspense fallback={<h1>🌀 Loading...</h1>}>\n        {activeTab === 'home' && <Home />}\n        {activeTab === 'posts' && <Posts />}\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nThis is because App doesn’t mount Posts until its tab is active.\n\nIf we update App to use an Activity boundary to show and hide the active tab, Posts will be pre-rendered when the app first loads, allowing it to fetch its data before it becomes visible.\n\nTry clicking the Posts tab now:\n\nApp.js\nHome.js\nPosts.js\nReload\nClear\nFork\nimport { Activity, useState, Suspense } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Posts from './Posts.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('home');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'posts'}\n        onClick={() => setActiveTab('posts')}\n      >\n        Posts\n      </TabButton>\n\n      <hr />\n\n      <Suspense fallback={<h1>🌀 Loading...</h1>}>\n        <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n          <Home />\n        </Activity>\n        <Activity mode={activeTab === 'posts' ? 'visible' : 'hidden'}>\n          <Posts />\n        </Activity>\n      </Suspense>\n    </>\n  );\n}\n\n\nShow more\n\nPosts was able to prepare itself for a faster render, thanks to the hidden Activity boundary.\n\nPre-rendering components with hidden Activity boundaries is a powerful way to reduce loading times for parts of the UI that the user is likely to interact with next.\n\nNote\n\nOnly Suspense-enabled data sources will be fetched during pre-rendering. They include:\n\nData fetching with Suspense-enabled frameworks like Relay and Next.js\nLazy-loading component code with lazy\nReading the value of a cached Promise with use\n\nActivity does not detect data that is fetched inside an Effect.\n\nThe exact way you would load data in the Posts component above depends on your framework. If you use a Suspense-enabled framework, you’ll find the details in its data fetching documentation.\n\nSuspense-enabled data fetching without the use of an opinionated framework is not yet supported. The requirements for implementing a Suspense-enabled data source are unstable and undocumented. An official API for integrating data sources with Suspense will be released in a future version of React.\n\nSpeeding up interactions during page load \n\nReact includes an under-the-hood performance optimization called Selective Hydration. It works by hydrating your app’s initial HTML in chunks, enabling some components to become interactive even if other components on the page haven’t loaded their code or data yet.\n\nSuspense boundaries participate in Selective Hydration, because they naturally divide your component tree into units that are independent from one another:\n\nfunction Page() {\n\n  return (\n\n    <>\n\n      <MessageComposer />\n\n\n\n      <Suspense fallback=\"Loading chats...\">\n\n        <Chats />\n\n      </Suspense>\n\n    </>\n\n  )\n\n}\n\nHere, MessageComposer can be fully hydrated during the initial render of the page, even before Chats is mounted and starts to fetch its data.\n\nSo by breaking up your component tree into discrete units, Suspense allows React to hydrate your app’s server-rendered HTML in chunks, enabling parts of your app to become interactive as fast as possible.\n\nBut what about pages that don’t use Suspense?\n\nTake this tabs example:\n\nfunction Page() {\n\n  const [activeTab, setActiveTab] = useState('home');\n\n\n\n  return (\n\n    <>\n\n      <TabButton onClick={() => setActiveTab('home')}>\n\n        Home\n\n      </TabButton>\n\n      <TabButton onClick={() => setActiveTab('video')}>\n\n        Video\n\n      </TabButton>\n\n\n\n      {activeTab === 'home' && (\n\n        <Home />\n\n      )}\n\n      {activeTab === 'video' && (\n\n        <Video />\n\n      )}\n\n    </>\n\n  )\n\n}\n\nHere, React must hydrate the entire page all at once. If Home or Video are slower to render, they could make the tab buttons feel unresponsive during hydration.\n\nAdding Suspense around the active tab would solve this:\n\nfunction Page() {\n\n  const [activeTab, setActiveTab] = useState('home');\n\n\n\n  return (\n\n    <>\n\n      <TabButton onClick={() => setActiveTab('home')}>\n\n        Home\n\n      </TabButton>\n\n      <TabButton onClick={() => setActiveTab('video')}>\n\n        Video\n\n      </TabButton>\n\n\n\n      <Suspense fallback={<Placeholder />}>\n\n        {activeTab === 'home' && (\n\n          <Home />\n\n        )}\n\n        {activeTab === 'video' && (\n\n          <Video />\n\n        )}\n\n      </Suspense>\n\n    </>\n\n  )\n\n}\n\n…but it would also change the UI, since the Placeholder fallback would be displayed on the initial render.\n\nInstead, we can use Activity. Since Activity boundaries show and hide their children, they already naturally divide the component tree into independent units. And just like Suspense, this feature allows them to participate in Selective Hydration.\n\nLet’s update our example to use Activity boundaries around the active tab:\n\nfunction Page() {\n\n  const [activeTab, setActiveTab] = useState('home');\n\n\n\n  return (\n\n    <>\n\n      <TabButton onClick={() => setActiveTab('home')}>\n\n        Home\n\n      </TabButton>\n\n      <TabButton onClick={() => setActiveTab('video')}>\n\n        Video\n\n      </TabButton>\n\n\n\n      <Activity mode={activeTab === \"home\" ? \"visible\" : \"hidden\"}>\n\n        <Home />\n\n      </Activity>\n\n      <Activity mode={activeTab === \"video\" ? \"visible\" : \"hidden\"}>\n\n        <Video />\n\n      </Activity>\n\n    </>\n\n  )\n\n}\n\nNow our initial server-rendered HTML looks the same as it did in the original version, but thanks to Activity, React can hydrate the tab buttons first, before it even mounts Home or Video.\n\nThus, in addition to hiding and showing content, Activity boundaries help improve your app’s performance during hydration by letting React know which parts of your page can become interactive in isolation.\n\nAnd even if your page doesn’t ever hide part of its content, you can still add always-visible Activity boundaries to improve hydration performance:\n\nfunction Page() {\n\n  return (\n\n    <>\n\n      <Post />\n\n\n\n      <Activity>\n\n        <Comments />\n\n      </Activity>\n\n    </>\n\n  );\n\n}\nTroubleshooting \nMy hidden components have unwanted side effects \n\nAn Activity boundary hides its content by setting display: none on its children and cleaning up any of their Effects. So, most well-behaved React components that properly clean up their side effects will already be robust to being hidden by Activity.\n\nBut there are some situations where a hidden component behaves differently than an unmounted one. Most notably, since a hidden component’s DOM is not destroyed, any side effects from that DOM will persist, even after the component is hidden.\n\nAs an example, consider a <video> tag. Typically it doesn’t require any cleanup, because even if you’re playing a video, unmounting the tag stops the video and audio from playing in the browser. Try playing the video and then pressing Home in this demo:\n\nApp.js\nHome.js\nVideo.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Video from './Video.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('video');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'video'}\n        onClick={() => setActiveTab('video')}\n      >\n        Video\n      </TabButton>\n\n      <hr />\n\n      {activeTab === 'home' && <Home />}\n      {activeTab === 'video' && <Video />}\n    </>\n  );\n}\n\n\nShow more\n\nThe video stops playing as expected.\n\nNow, let’s say we wanted to preserve the timecode where the user last watched, so that when they tab back to the video, it doesn’t start over from the beginning again.\n\nThis is a great use case for Activity!\n\nLet’s update App to hide the inactive tab with a hidden Activity boundary instead of unmounting it, and see how the demo behaves this time:\n\nApp.js\nHome.js\nVideo.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Video from './Video.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('video');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'video'}\n        onClick={() => setActiveTab('video')}\n      >\n        Video\n      </TabButton>\n\n      <hr />\n\n      <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n        <Home />\n      </Activity>\n      <Activity mode={activeTab === 'video' ? 'visible' : 'hidden'}>\n        <Video />\n      </Activity>\n    </>\n  );\n}\n\n\nShow more\n\nWhoops! The video and audio continue to play even after it’s been hidden, because the tab’s <video> element is still in the DOM.\n\nTo fix this, we can add an Effect with a cleanup function that pauses the video:\n\nexport default function VideoTab() {\n\n  const ref = useRef();\n\n\n\n  useLayoutEffect(() => {\n\n    const videoRef = ref.current;\n\n\n\n    return () => {\n\n      videoRef.pause()\n\n    }\n\n  }, []);\n\n\n\n  return (\n\n    <video\n\n      ref={ref}\n\n      controls\n\n      playsInline\n\n      src=\"...\"\n\n    />\n\n\n\n  );\n\n}\n\nWe call useLayoutEffect instead of useEffect because conceptually the clean-up code is tied to the component’s UI being visually hidden. If we used a regular effect, the code could be delayed by (say) a re-suspending Suspense boundary or a View Transition.\n\nLet’s see the new behavior. Try playing the video, switching to the Home tab, then back to the Video tab:\n\nApp.js\nHome.js\nVideo.js\nReload\nClear\nFork\nimport { Activity, useState } from 'react';\nimport TabButton from './TabButton.js';\nimport Home from './Home.js';\nimport Video from './Video.js';\n\nexport default function App() {\n  const [activeTab, setActiveTab] = useState('video');\n\n  return (\n    <>\n      <TabButton\n        isActive={activeTab === 'home'}\n        onClick={() => setActiveTab('home')}\n      >\n        Home\n      </TabButton>\n      <TabButton\n        isActive={activeTab === 'video'}\n        onClick={() => setActiveTab('video')}\n      >\n        Video\n      </TabButton>\n\n      <hr />\n\n      <Activity mode={activeTab === 'home' ? 'visible' : 'hidden'}>\n        <Home />\n      </Activity>\n      <Activity mode={activeTab === 'video' ? 'visible' : 'hidden'}>\n        <Video />\n      </Activity>\n    </>\n  );\n}\n\n\nShow more\n\nIt works great! Our cleanup function ensures that the video stops playing if it’s ever hidden by an Activity boundary, and even better, because the <video> tag is never destroyed, the timecode is preserved, and the video itself doesn’t need to be initialized or downloaded again when the user switches back to keep watching it.\n\nThis is a great example of using Activity to preserve ephemeral DOM state for parts of the UI that become hidden, but the user is likely to interact with again soon.\n\nOur example illustrates that for certain tags like <video>, unmounting and hiding have different behavior. If a component renders DOM that has a side effect, and you want to prevent that side effect when an Activity boundary hides it, add an Effect with a return function to clean it up.\n\nThe most common cases of this will be from the following tags:\n\n<video>\n<audio>\n<iframe>\n\nTypically, though, most of your React components should already be robust to being hidden by an Activity boundary. And conceptually, you should think of “hidden” Activities as being unmounted.\n\nTo eagerly discover other Effects that don’t have proper cleanup, which is important not only for Activity boundaries but for many other behaviors in React, we recommend using <StrictMode>.\n\nMy hidden components have Effects that aren’t running \n\nWhen an <Activity> is “hidden”, all its children’s Effects are cleaned up. Conceptually, the children are unmounted, but React saves their state for later. This is a feature of Activity because it means subscriptions won’t be active for hidden parts of the UI, reducing the amount of work needed for hidden content.\n\nIf you’re relying on an Effect mounting to clean up a component’s side effects, refactor the Effect to do the work in the returned cleanup function instead.\n\nTo eagerly find problematic Effects, we recommend adding <StrictMode> which will eagerly perform Activity unmounts and mounts to catch any unexpected side-effects.\n\nPREVIOUS\n<Suspense>\nNEXT\n<ViewTransition>"
  },
  {
    "title": "<ViewTransition> – React",
    "url": "https://react.dev/reference/react/ViewTransition",
    "html": "API REFERENCE\nCOMPONENTS\n<ViewTransition>\nCanary\n\nThe <ViewTransition /> API is currently only available in React’s Canary and Experimental channels.\n\nLearn more about React’s release channels here.\n\n<ViewTransition> lets you animate elements that update inside a Transition.\n\nimport {ViewTransition} from 'react';\n\n\n\n<ViewTransition>\n\n  <div>...</div>\n\n</ViewTransition>\nReference\n<ViewTransition>\nView Transition Class\nStyling View Transitions\nUsage\nAnimating an element on enter/exit\nAnimating a shared element\nAnimating reorder of items in a list\nAnimating from Suspense content\nOpting-out of an animation\nCustomizing animations\nCustomizing animations with types\nBuilding View Transition enabled routers\nTroubleshooting\nMy <ViewTransition> is not activating\nI’m getting an error “There are two <ViewTransition name=%s> components with the same name mounted at the same time.”\nReference \n<ViewTransition> \n\nWrap elements in <ViewTransition> to animate them when they update inside a Transition. React uses the following heuristics to determine if a View Transition activates for an animation:\n\nenter: If a ViewTransition itself gets inserted in this Transition, then this will activate.\nexit: If a ViewTransition itself gets deleted in this Transition, then this will activate.\nupdate: If a ViewTransition has any DOM mutations inside it that React is doing (such as a prop changing) or if the ViewTransition boundary itself changes size or position due to an immediate sibling. If there are nested ViewTransition then the mutation applies to them and not the parent.\nshare: If a named ViewTransition is inside a deleted subtree and another named ViewTransition with the same name is part of an inserted subtree in the same Transition, they form a Shared Element Transition, and it animates from the deleted one to the inserted one.\n\nBy default, <ViewTransition> animates with a smooth cross-fade (the browser default view transition). You can customize the animation by providing a View Transition Class to the <ViewTransition> component. You can  customize animations for each kind of trigger (see Styling View Transitions).\n\nDEEP DIVE\nHow does <ViewTransition> work? \nShow Details\nProps \n\nBy default, <ViewTransition> animates with a smooth cross-fade. You can customize the animation, or specify a shared element transition, with these props:\n\noptional enter: A string or object. The View Transition Class to apply when enter is activated.\noptional exit: A string or object. The View Transition Class to apply when exit is activated.\noptional update: A string or object. The View Transition Class to apply when an update is activated.\noptional share: A string or object. The View Transition Class to apply when a shared element is activated.\noptional default: A string or object. The View Transition Class used when no other matching activation prop is found.\noptional name: A string or object. The name of the View Transition used for shared element transitions. If not provided, React will use a unique name for each View Transition to prevent unexpected animations.\nCallback \n\nThese callbacks allow you to adjust the animation imperatively using the animate APIs:\n\noptional onEnter: A function. React calls onEnter after an “enter” animation.\noptional onExit: A function. React calls onExit after an “exit” animation.\noptional onShare: A function. React calls onShare after a “share” animation.\noptional onUpdate: A function. React calls onUpdate after an “update” animation.\n\nEach callback receives as arguments:\n\nelement: The DOM element that was animated.\ntypes: The Transition Types included in the animation.\nView Transition Class \n\nThe View Transition Class is the CSS class name(s) applied by React during the transition when the ViewTransition activates. It can be a string or an object.\n\nstring: the class added on the child elements when activated. If 'none' is provided, no class will be added.\nobject: the class added on the child elements will be the key matching View Transition type added with addTransitionType. The object can also specify a default to use if no matching type is found.\n\nThe value 'none' can be used to prevent a View Transition from activating for a specific trigger.\n\nStyling View Transitions \nNote\n\nIn many early examples of View Transitions around the web, you’ll have seen using a view-transition-name and then style it using ::view-transition-...(my-name) selectors. We don’t recommend that for styling. Instead, we normally recommend using a View Transition Class instead.\n\nTo customize the animation for a <ViewTransition> you can provide a View Transition Class to one of the activation props. The View Transition Class is a CSS class name that React applies to the child elements when the ViewTransition activates.\n\nFor example, to customize an “enter” animation, provide a class name to the enter prop:\n\n<ViewTransition enter=\"slide-in\">\n\nWhen the <ViewTransition> activates an “enter” animation, React will add the class name slide-in. Then you can refer to this class using view transition pseudo selectors to build reusable animations:\n\n::view-transition-group(.slide-in) {\n\n  \n\n}\n\n::view-transition-old(.slide-in) {\n\n\n\n}\n\n::view-transition-new(.slide-in) {\n\n\n\n}\n\nIn the future, CSS libraries may add built-in animations using View Transition Classes to make this easier to use.\n\nCaveats \nBy default, setState updates immediately and does not activate <ViewTransition>, only updates wrapped in a Transition. You can also use <Suspense> to opt-in to a Transition to reveal content.\n<ViewTransition> creates an image that can be moved around, scaled and cross-faded. Unlike Layout Animations you may have seen in React Native or Motion, this means that not every individual Element inside of it animates its position. This can lead to better performance and a more continuous feeling, smooth animation compared to animating every individual piece. However, it can also lose continuity in things that should be moving by themselves. So you might have to add more <ViewTransition> boundaries manually as a result.\nMany users may prefer not having animations on the page. React doesn’t automatically disable animations for this case. We recommend that using the @media (prefers-reduced-motion) media query to disable animations or tone them down based on user preference. In the future, CSS libraries may have this built-in to their presets.\nCurrently, <ViewTransition> only works in the DOM. We’re working on adding support for React Native and other platforms.\nUsage \nAnimating an element on enter/exit \n\nEnter/Exit Transitions trigger when a <ViewTransition> is added or removed by a component in a transition:\n\nfunction Child() {\n\n  return (\n\n    <ViewTransition>\n\n      <div>Hi</div>\n\n    </ViewTransition>\n\n  );\n\n}\n\n\n\nfunction Parent() {\n\n  const [show, setShow] = useState();\n\n  if (show) {\n\n    return <Child />;\n\n  }\n\n  return null;\n\n}\n\nWhen setShow is called, show switches to true and the Child component is rendered. When setShow is called inside startTransition, and Child renders a ViewTransition before any other DOM nodes, an enter animation is triggered.\n\nWhen show switches back to false, an exit animation is triggered.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from 'react';\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition>\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\n<ViewTransition> only activates if it is placed before any DOM node. If Child instead looked like this, no animation would trigger:\n\nfunction Component() {\n\n  return <ViewTransition>Hi</ViewTransition>;\n\n}\nAnimating a shared element \n\nNormally, we don’t recommend assigning a name to a <ViewTransition> and instead let React assign it an automatic name. The reason you might want to assign a name is to animate between completely different components when one tree unmounts and another tree mounts at the same time. To preserve continuity.\n\n<ViewTransition name={UNIQUE_NAME}>\n\n  <Child />\n\n</ViewTransition>\n\nWhen one tree unmounts and another mounts, if there’s a pair where the same name exists in the unmounting tree and the mounting tree, they trigger the “share” animation on both. It animates from the unmounting side to the mounting side.\n\nUnlike an exit/enter animation this can be deeply inside the deleted/mounted tree. If a <ViewTransition> would also be eligible for exit/enter, then the “share” animation takes precedence.\n\nIf Transition first unmounts one side and then leads to a <Suspense> fallback being shown before eventually the new name being mounted, then no shared element transition happens.\n\nApp.js\nVideo.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from \"react\";\nimport {Video, Thumbnail, FullscreenVideo} from \"./Video\";\nimport videos from \"./data\";\n\nexport default function Component() {\n  const [fullscreen, setFullscreen] = useState(false);\n  if (fullscreen) {\n    return <FullscreenVideo\n      video={videos[0]}\n      onExit={() => startTransition(() => setFullscreen(false))}\n    />\n  }\n  return <Video\n    video={videos[0]}\n    onClick={() => startTransition(() => setFullscreen(true))}\n  />\n}\n\n\nShow more\nNote\n\nIf either the mounted or unmounted side of a pair is outside the viewport, then no pair is formed. This ensures that it doesn’t fly in or out of the viewport when something is scrolled. Instead it’s treated as a regular enter/exit by itself.\n\nThis does not happen if the same Component instance changes position, which triggers an “update”. Those animate regardless if one position is outside the viewport.\n\nThere’s currently a quirk where if a deeply nested unmounted <ViewTransition> is inside the viewport but the mounted side is not within the viewport, then the unmounted side animates as its own “exit” animation even if it’s deeply nested instead of as part of the parent animation.\n\nPitfall\n\nIt’s important that there’s only one thing with the same name mounted at a time in the entire app. Therefore it’s important to use unique namespaces for the name to avoid conflicts. To ensure you can do this you might want to add a constant in a separate module that you import.\n\nexport const MY_NAME = \"my-globally-unique-name\";\n\nimport {MY_NAME} from './shared-name';\n\n...\n\n<ViewTransition name={MY_NAME}>\nAnimating reorder of items in a list \nitems.map(item => <Component key={item.id} item={item} />)\n\nWhen reordering a list, without updating the content, the “update” animation triggers on each <ViewTransition> in the list if they’re outside a DOM node. Similar to enter/exit animations.\n\nThis means that this will trigger the animation on this <ViewTransition>:\n\nfunction Component() {\n\n  return <ViewTransition><div>...</div></ViewTransition>;\n\n}\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from \"react\";\nimport {Video} from \"./Video\";\nimport videos from \"./data\";\n\nexport default function Component() {\n  const [orderedVideos, setOrderedVideos] = useState(videos);\n  const reorder = () => {\n    startTransition(() => {\n      setOrderedVideos((prev) => {\n        return [...prev.sort(() => Math.random() - 0.5)];\n      });\n    });\n  };\n  return (\n    <>\n      <button onClick={reorder}>🎲</button>\n      <div className=\"listContainer\">\n        {orderedVideos.map((video, i) => {\n          return (\n            <ViewTransition key={video.title}>\n              <Video video={video} />\n            </ViewTransition>\n          );\n        })}\n      </div>\n    </>\n  );\n}\n\n\nShow more\n\nHowever, this wouldn’t animate each individual item:\n\nfunction Component() {\n\n  return <div><ViewTransition>...</ViewTransition></div>;\n\n}\n\nInstead, any parent <ViewTransition> would cross-fade. If there is no parent <ViewTransition> then there’s no animation in that case.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from \"react\";\nimport {Video} from \"./Video\";\nimport videos from \"./data\";\n\nexport default function Component() {\n  const [orderedVideos, setOrderedVideos] = useState(videos);\n  const reorder = () => {\n    startTransition(() => {\n      setOrderedVideos((prev) => {\n        return [...prev.sort(() => Math.random() - 0.5)];\n      });\n    });\n  };\n  return (\n    <>\n      <button onClick={reorder}>🎲</button>\n      <ViewTransition>\n        <div className=\"listContainer\">\n          {orderedVideos.map((video, i) => {\n            return <Video video={video} key={video.title} />;\n          })}\n        </div>\n      </ViewTransition>\n    </>\n  );\n}\n\n\nShow more\n\nThis means you might want to avoid wrapper elements in lists where you want to allow the Component to control its own reorder animation:\n\nitems.map(item => <div><Component key={item.id} item={item} /></div>)\n\nThe above rule also applies if one of the items updates to resize, which then causes the siblings to resize, it’ll also animate its sibling <ViewTransition> but only if they’re immediate siblings.\n\nThis means that during an update, which causes a lot of re-layout, it doesn’t individually animate every <ViewTransition> on the page. That would lead to a lot of noisy animations which distracts from the actual change. Therefore React is more conservative about when an individual animation triggers.\n\nPitfall\n\nIt’s important to properly use keys to preserve identity when reordering lists. It might seem like you could use “name”, shared element transitions, to animate reorders but that would not trigger if one side was outside the viewport. To animate a reorder you often want to show that it went to a position outside the viewport.\n\nAnimating from Suspense content \n\nJust like any Transition, React waits for data and new CSS (<link rel=\"stylesheet\" precedence=\"...\">) before running the animation. In addition to this, ViewTransitions also wait up to 500ms for new fonts to load before starting the animation to avoid them flickering in later. For the same reason, an image wrapped in ViewTransition will wait for the image to load.\n\nIf it’s inside a new Suspense boundary instance, then the fallback is shown first. After the Suspense boundary fully loads, it triggers the <ViewTransition> to animate the reveal to the content.\n\nCurrently, this only happens for client-side Transition. In the future, this will also animate Suspense boundary for streaming SSR when content from the server suspends during the initial load.\n\nThere are two ways to animate Suspense boundaries depending on where you place the <ViewTransition>:\n\nUpdate:\n\n<ViewTransition>\n\n  <Suspense fallback={<A />}>\n\n    <B />\n\n  </Suspense>\n\n</ViewTransition>\n\nIn this scenario when the content goes from A to B, it’ll be treated as an “update” and apply that class if appropriate. Both A and B will get the same view-transition-name and therefore they’re acting as a cross-fade by default.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition,\n  Suspense\n} from 'react';\nimport {Video, VideoPlaceholder} from \"./Video\";\nimport {useLazyVideoData} from \"./data\"\n\nfunction LazyVideo() {\n  const video = useLazyVideoData();\n  return (\n    <Video video={video}/>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n      {showItem ? (\n        <ViewTransition>\n          <Suspense fallback={<VideoPlaceholder />}>\n            <LazyVideo />\n          </Suspense>\n        </ViewTransition>\n      ) : null}\n    </>\n  );\n}\n\n\nShow more\n\nEnter/Exit:\n\n<Suspense fallback={<ViewTransition><A /></ViewTransition>}>\n\n  <ViewTransition><B /></ViewTransition>\n\n</Suspense>\n\nIn this scenario, these are two separate ViewTransition instances each with their own view-transition-name. This will be treated as an “exit” of the <A> and an “enter” of the <B>.\n\nYou can achieve different effects depending on where you choose to place the <ViewTransition> boundary.\n\nOpting-out of an animation \n\nSometimes you’re wrapping a large existing component, like a whole page, and you want to animate some updates, such as changing the theme. However, you don’t want it to opt-in all updates inside the whole page to cross-fade when they’re updating. Especially if you’re incrementally adding more animations.\n\nYou can use the class “none” to opt-out of an animation. By wrapping your children in a “none” you can disable animations for updates to them while the parent still triggers.\n\n<ViewTransition>\n\n  <div className={theme}>\n\n    <ViewTransition update=\"none\">\n\n      {children}\n\n    </ViewTransition>\n\n  </div>\n\n</ViewTransition>\n\nThis will only animate if the theme changes and not if only the children update. The children can still opt-in again with their own <ViewTransition> but at least it’s manual again.\n\nCustomizing animations \n\nBy default, <ViewTransition> includes the default cross-fade from the browser.\n\nTo customize animations, you can provide props to the <ViewTransition> component to specify which animations to use, based on how the <ViewTransition> activates.\n\nFor example, we can slow down the default cross fade animation:\n\n<ViewTransition default=\"slow-fade\">\n\n  <Video />\n\n</ViewTransition>\n\nAnd define slow-fade in CSS using view transition classes:\n\n::view-transition-old(.slow-fade) {\n\n    animation-duration: 500ms;\n\n}\n\n\n\n::view-transition-new(.slow-fade) {\n\n    animation-duration: 500ms;\n\n}\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from 'react';\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition default=\"slow-fade\">\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\n\nIn addition to setting the default, you can also provide configurations for enter, exit, update, and share animations.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  useState,\n  startTransition\n} from 'react';\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition enter=\"slide-in\" exit=\"slide-out\">\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <button\n        onClick={() => {\n          startTransition(() => {\n            setShowItem((prev) => !prev);\n          });\n        }}\n      >{showItem ? '➖' : '➕'}</button>\n\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\nCustomizing animations with types \n\nYou can use the addTransitionType API to add a class name to the child elements when a specific transition type is activated for a specific activation trigger. This allows you to customize the animation for each type of transition.\n\nFor example, to customize the animation for all forward and backward navigations:\n\n<ViewTransition default={{\n\n  'navigation-back': 'slide-right',\n\n  'navigation-forward': 'slide-left',\n\n }}>\n\n  <div>...</div>\n\n</ViewTransition>\n\n \n\n// in your router:\n\nstartTransition(() => {\n\n  addTransitionType('navigation-' + navigationType);\n\n});\n\nWhen the ViewTransition activates a “navigation-back” animation, React will add the class name “slide-right”. When the ViewTransition activates a “navigation-forward” animation, React will add the class name “slide-left”.\n\nIn the future, routers and other libraries may add support for standard view-transition types and styles.\n\nApp.js\nReload\nClear\nFork\nimport {\n  ViewTransition,\n  addTransitionType,\n  useState,\n  startTransition,\n} from \"react\";\nimport {Video} from \"./Video\";\nimport videos from \"./data\"\n\nfunction Item() {\n  return (\n    <ViewTransition enter={\n        {\n          \"add-video-back\": \"slide-in-back\",\n          \"add-video-forward\": \"slide-in-forward\"\n        }\n      }\n      exit={\n        {\n          \"remove-video-back\": \"slide-in-forward\",\n          \"remove-video-forward\": \"slide-in-back\"\n        }\n      }>\n      <Video video={videos[0]}/>\n    </ViewTransition>\n  );\n}\n\nexport default function Component() {\n  const [showItem, setShowItem] = useState(false);\n  return (\n    <>\n      <div className=\"button-container\">\n        <button\n          onClick={() => {\n            startTransition(() => {\n              if (showItem) {\n                addTransitionType(\"remove-video-back\")\n              } else {\n                addTransitionType(\"add-video-back\")\n              }\n              setShowItem((prev) => !prev);\n            });\n          }}\n        >⬅️</button>\n        <button\n          onClick={() => {\n            startTransition(() => {\n              if (showItem) {\n                addTransitionType(\"remove-video-forward\")\n              } else {\n                addTransitionType(\"add-video-forward\")\n              }\n              setShowItem((prev) => !prev);\n            });\n          }}\n        >➡️</button>\n      </div>\n      {showItem ? <Item /> : null}\n    </>\n  );\n}\n\n\nShow more\nBuilding View Transition enabled routers \n\nReact waits for any pending Navigation to finish to ensure that scroll restoration happens within the animation. If the Navigation is blocked on React, your router must unblock in useLayoutEffect since useEffect would lead to a deadlock.\n\nIf a startTransition is started from the legacy popstate event, such as during a “back”-navigation then it must finish synchronously to ensure scroll and form restoration works correctly. This is in conflict with running a View Transition animation. Therefore, React will skip animations from popstate. Therefore animations won’t run for the back button. You can fix this by upgrading your router to use the Navigation API.\n\nTroubleshooting \nMy <ViewTransition> is not activating \n\n<ViewTransition> only activates if it is placed before any DOM node:\n\nfunction Component() {\n\n  return (\n\n    <div>\n\n      <ViewTransition>Hi</ViewTransition>\n\n    </div>\n\n  );\n\n}\n\nTo fix, ensure that the <ViewTransition> comes before any other DOM nodes:\n\nfunction Component() {\n\n  return (\n\n    <ViewTransition>\n\n      <div>Hi</div>\n\n    </ViewTransition>\n\n  );\n\n}\nI’m getting an error “There are two <ViewTransition name=%s> components with the same name mounted at the same time.” \n\nThis error occurs when two <ViewTransition> components with the same name are mounted at the same time:\n\nfunction Item() {\n\n  // 🚩 All items will get the same \"name\".\n\n  return <ViewTransition name=\"item\">...</ViewTransition>;\n\n}\n\n\n\nfunction ItemList({items}) {\n\n  return (\n\n    <>\n\n      {item.map(item => <Item key={item.id} />)}\n\n    </>\n\n  );\n\n}\n\nThis will cause the View Transition to error. In development, React detects this issue to surface it and logs two errors:\n\nConsole\nThere are two <ViewTransition name=%s> components with the same name mounted at the same time. This is not supported and will cause View Transitions to error. Try to use a more unique name e.g. by using a namespace prefix and adding the id of an item to the name.\n    at Item\n    at ItemList\nThe existing <ViewTransition name=%s> duplicate has this stack trace.\n    at Item\n    at ItemList\n\nTo fix, ensure that there’s only one <ViewTransition> with the same name mounted at a time in the entire app by ensuring the name is unique, or adding an id to the name:\n\nfunction Item({id}) {\n\n  // ✅ All items will get the same \"name\".\n\n  return <ViewTransition name={`item-${id}`}>...</ViewTransition>;\n\n}\n\n\n\nfunction ItemList({items}) {\n\n  return (\n\n    <>\n\n      {item.map(item => <Item key={item.id} item={item} />)}\n\n    </>\n\n  );\n\n}\nPREVIOUS\n<Activity>\nNEXT\nAPIs"
  },
  {
    "title": "Built-in React APIs – React",
    "url": "https://react.dev/reference/react/apis",
    "html": "API REFERENCE\nBuilt-in React APIs\n\nIn addition to Hooks and Components, the react package exports a few other APIs that are useful for defining components. This page lists all the remaining modern React APIs.\n\ncreateContext lets you define and provide context to the child components. Used with useContext.\nlazy lets you defer loading a component’s code until it’s rendered for the first time.\nmemo lets your component skip re-renders with same props. Used with useMemo and useCallback.\nstartTransition lets you mark a state update as non-urgent. Similar to useTransition.\nact lets you wrap renders and interactions in tests to ensure updates have processed before making assertions.\nResource APIs \n\nResources can be accessed by a component without having them as part of their state. For example, a component can read a message from a Promise or read styling information from a context.\n\nTo read a value from a resource, use this API:\n\nuse lets you read the value of a resource like a Promise or context.\nfunction MessageComponent({ messagePromise }) {\n\n  const message = use(messagePromise);\n\n  const theme = use(ThemeContext);\n\n  // ...\n\n}\nPREVIOUS\n<ViewTransition>\nNEXT\nact"
  },
  {
    "title": "act – React",
    "url": "https://react.dev/reference/react/act",
    "html": "API REFERENCE\nAPIS\nact\n\nact is a test helper to apply pending React updates before making assertions.\n\nawait act(async actFn)\n\nTo prepare a component for assertions, wrap the code rendering it and performing updates inside an await act() call. This makes your test run closer to how React works in the browser.\n\nNote\n\nYou might find using act() directly a bit too verbose. To avoid some of the boilerplate, you could use a library like React Testing Library, whose helpers are wrapped with act().\n\nReference\nawait act(async actFn)\nUsage\nRendering components in tests\nDispatching events in tests\nTroubleshooting\nI’m getting an error: “The current testing environment is not configured to support act”(…)”\nReference \nawait act(async actFn) \n\nWhen writing UI tests, tasks like rendering, user events, or data fetching can be considered as “units” of interaction with a user interface. React provides a helper called act() that makes sure all updates related to these “units” have been processed and applied to the DOM before you make any assertions.\n\nThe name act comes from the Arrange-Act-Assert pattern.\n\nit ('renders with button disabled', async () => {\n\n  await act(async () => {\n\n    root.render(<TestComponent />)\n\n  });\n\n  expect(container.querySelector('button')).toBeDisabled();\n\n});\nNote\n\nWe recommend using act with await and an async function. Although the sync version works in many cases, it doesn’t work in all cases and due to the way React schedules updates internally, it’s difficult to predict when you can use the sync version.\n\nWe will deprecate and remove the sync version in the future.\n\nParameters \nasync actFn: An async function wrapping renders or interactions for components being tested. Any updates triggered within the actFn, are added to an internal act queue, which are then flushed together to process and apply any changes to the DOM. Since it is async, React will also run any code that crosses an async boundary, and flush any updates scheduled.\nReturns \n\nact does not return anything.\n\nUsage \n\nWhen testing a component, you can use act to make assertions about its output.\n\nFor example, let’s say we have this Counter component, the usage examples below show how to test it:\n\nfunction Counter() {\n\n  const [count, setCount] = useState(0);\n\n  const handleClick = () => {\n\n    setCount(prev => prev + 1);\n\n  }\n\n\n\n  useEffect(() => {\n\n    document.title = `You clicked ${count} times`;\n\n  }, [count]);\n\n\n\n  return (\n\n    <div>\n\n      <p>You clicked {count} times</p>\n\n      <button onClick={handleClick}>\n\n        Click me\n\n      </button>\n\n    </div>\n\n  )\n\n}\nRendering components in tests \n\nTo test the render output of a component, wrap the render inside act():\n\nimport {act} from 'react';\n\nimport ReactDOMClient from 'react-dom/client';\n\nimport Counter from './Counter';\n\n\n\nit('can render and update a counter', async () => {\n\n  container = document.createElement('div');\n\n  document.body.appendChild(container);\n\n  \n\n  // ✅ Render the component inside act().\n\n  await act(() => {\n\n    ReactDOMClient.createRoot(container).render(<Counter />);\n\n  });\n\n  \n\n  const button = container.querySelector('button');\n\n  const label = container.querySelector('p');\n\n  expect(label.textContent).toBe('You clicked 0 times');\n\n  expect(document.title).toBe('You clicked 0 times');\n\n});\n\nHere, we create a container, append it to the document, and render the Counter component inside act(). This ensures that the component is rendered and its effects are applied before making assertions.\n\nUsing act ensures that all updates have been applied before we make assertions.\n\nDispatching events in tests \n\nTo test events, wrap the event dispatch inside act():\n\nimport {act} from 'react';\n\nimport ReactDOMClient from 'react-dom/client';\n\nimport Counter from './Counter';\n\n\n\nit.only('can render and update a counter', async () => {\n\n  const container = document.createElement('div');\n\n  document.body.appendChild(container);\n\n  \n\n  await act( async () => {\n\n    ReactDOMClient.createRoot(container).render(<Counter />);\n\n  });\n\n  \n\n  // ✅ Dispatch the event inside act().\n\n  await act(async () => {\n\n    button.dispatchEvent(new MouseEvent('click', { bubbles: true }));\n\n  });\n\n\n\n  const button = container.querySelector('button');\n\n  const label = container.querySelector('p');\n\n  expect(label.textContent).toBe('You clicked 1 times');\n\n  expect(document.title).toBe('You clicked 1 times');\n\n});\n\nHere, we render the component with act, and then dispatch the event inside another act(). This ensures that all updates from the event are applied before making assertions.\n\nPitfall\n\nDon’t forget that dispatching DOM events only works when the DOM container is added to the document. You can use a library like React Testing Library to reduce the boilerplate code.\n\nTroubleshooting \nI’m getting an error: “The current testing environment is not configured to support act”(…)” \n\nUsing act requires setting global.IS_REACT_ACT_ENVIRONMENT=true in your test environment. This is to ensure that act is only used in the correct environment.\n\nIf you don’t set the global, you will see an error like this:\n\nConsole\nWarning: The current testing environment is not configured to support act(…)\n\nTo fix, add this to your global setup file for React tests:\n\nglobal.IS_REACT_ACT_ENVIRONMENT=true\nNote\n\nIn testing frameworks like React Testing Library, IS_REACT_ACT_ENVIRONMENT is already set for you.\n\nPREVIOUS\nAPIs\nNEXT\naddTransitionType"
  },
  {
    "title": "addTransitionType – React",
    "url": "https://react.dev/reference/react/addTransitionType",
    "html": "API REFERENCE\nAPIS\naddTransitionType\nCanary\n\nThe addTransitionType API is currently only available in React’s Canary and Experimental channels.\n\nLearn more about React’s release channels here.\n\naddTransitionType lets you specify the cause of a transition.\n\nstartTransition(() => {\n\n  addTransitionType('my-transition-type');\n\n  setState(newState);\n\n});\nReference\naddTransitionType\nUsage\nAdding the cause of a transition\nCustomize animations using browser view transition types\nCustomize animations using View Transition Class\nCustomize animations using ViewTransition events\nReference \naddTransitionType \nParameters \ntype: The type of transition to add. This can be any string.\nReturns \n\nstartTransition does not return anything.\n\nCaveats \nIf multiple transitions are combined, all Transition Types are collected. You can also add more than one type to a Transition.\nTransition Types are reset after each commit. This means a <Suspense> fallback will associate the types after a startTransition, but revealing the content does not.\nUsage \nAdding the cause of a transition \n\nCall addTransitionType inside of startTransition to indicate the cause of a transition:\n\nimport { startTransition, addTransitionType } from 'react';\n\n\n\nfunction Submit({action) {\n\n  function handleClick() {\n\n    startTransition(() => {\n\n      addTransitionType('submit-click');\n\n      action();\n\n    });\n\n  }\n\n\n\n  return <button onClick={handleClick}>Click me</button>;\n\n}\n\nWhen you call addTransitionType inside the scope of startTransition, React will associate submit-click as one of the causes for the Transition.\n\nCurrently, Transition Types can be used to customize different animations based on what caused the Transition. You have three different ways to choose from for how to use them:\n\nCustomize animations using browser view transition types\nCustomize animations using View Transition Class\nCustomize animations using ViewTransition events\n\nIn the future, we plan to support more use cases for using the cause of a transition.\n\nCustomize animations using browser view transition types \n\nWhen a ViewTransition activates from a transition, React adds all the Transition Types as browser view transition types to the element.\n\nThis allows you to customize different animations based on CSS scopes:\n\nfunction Component() {\n\n  return (\n\n    <ViewTransition>\n\n      <div>Hello</div>\n\n    </ViewTransition>\n\n  );\n\n}\n\n\n\nstartTransition(() => {\n\n  addTransitionType('my-transition-type');\n\n  setShow(true);\n\n});\n:root:active-view-transition-type(my-transition-type) {\n\n  &::view-transition-...(...) {\n\n    ...\n\n  }\n\n}\nCustomize animations using View Transition Class \n\nYou can customize animations for an activated ViewTransition based on type by passing an object to the View Transition Class:\n\nfunction Component() {\n\n  return (\n\n    <ViewTransition enter={{\n\n      'my-transition-type': 'my-transition-class',\n\n    }}>\n\n      <div>Hello</div>\n\n    </ViewTransition>\n\n  );\n\n}\n\n\n\n// ...\n\nstartTransition(() => {\n\n  addTransitionType('my-transition-type');\n\n  setState(newState);\n\n});\n\nIf multiple types match, then they’re joined together. If no types match then the special “default” entry is used instead. If any type has the value “none” then that wins and the ViewTransition is disabled (not assigned a name).\n\nThese can be combined with enter/exit/update/layout/share props to match based on kind of trigger and Transition Type.\n\n<ViewTransition enter={{\n\n  'navigation-back': 'enter-right',\n\n  'navigation-forward': 'enter-left',\n\n}}\n\nexit={{\n\n  'navigation-back': 'exit-right',\n\n  'navigation-forward': 'exit-left',\n\n}}>\nCustomize animations using ViewTransition events \n\nYou can imperatively customize animations for an activated ViewTransition based on type using View Transition events:\n\n<ViewTransition onUpdate={(inst, types) => {\n\n  if (types.includes('navigation-back')) {\n\n    ...\n\n  } else if (types.includes('navigation-forward')) {\n\n    ...\n\n  } else {\n\n    ...\n\n  }\n\n}}>\n\nThis allows you to pick different imperative Animations based on the cause.\n\nPREVIOUS\nact\nNEXT\ncache"
  },
  {
    "title": "cache – React",
    "url": "https://react.dev/reference/react/cache",
    "html": "API REFERENCE\nAPIS\ncache\nReact Server Components\n\ncache is only for use with React Server Components.\n\ncache lets you cache the result of a data fetch or computation.\n\nconst cachedFn = cache(fn);\nReference\ncache(fn)\nUsage\nCache an expensive computation\nShare a snapshot of data\nPreload data\nTroubleshooting\nMy memoized function still runs even though I’ve called it with the same arguments\nReference \ncache(fn) \n\nCall cache outside of any components to create a version of the function with caching.\n\nimport {cache} from 'react';\n\nimport calculateMetrics from 'lib/metrics';\n\n\n\nconst getMetrics = cache(calculateMetrics);\n\n\n\nfunction Chart({data}) {\n\n  const report = getMetrics(data);\n\n  // ...\n\n}\n\nWhen getMetrics is first called with data, getMetrics will call calculateMetrics(data) and store the result in cache. If getMetrics is called again with the same data, it will return the cached result instead of calling calculateMetrics(data) again.\n\nSee more examples below.\n\nParameters \nfn: The function you want to cache results for. fn can take any arguments and return any value.\nReturns \n\ncache returns a cached version of fn with the same type signature. It does not call fn in the process.\n\nWhen calling cachedFn with given arguments, it first checks if a cached result exists in the cache. If a cached result exists, it returns the result. If not, it calls fn with the arguments, stores the result in the cache, and returns the result. The only time fn is called is when there is a cache miss.\n\nNote\n\nThe optimization of caching return values based on inputs is known as memoization. We refer to the function returned from cache as a memoized function.\n\nCaveats \nReact will invalidate the cache for all memoized functions for each server request.\nEach call to cache creates a new function. This means that calling cache with the same function multiple times will return different memoized functions that do not share the same cache.\ncachedFn will also cache errors. If fn throws an error for certain arguments, it will be cached, and the same error is re-thrown when cachedFn is called with those same arguments.\ncache is for use in Server Components only.\nUsage \nCache an expensive computation \n\nUse cache to skip duplicate work.\n\nimport {cache} from 'react';\n\nimport calculateUserMetrics from 'lib/user';\n\n\n\nconst getUserMetrics = cache(calculateUserMetrics);\n\n\n\nfunction Profile({user}) {\n\n  const metrics = getUserMetrics(user);\n\n  // ...\n\n}\n\n\n\nfunction TeamReport({users}) {\n\n  for (let user in users) {\n\n    const metrics = getUserMetrics(user);\n\n    // ...\n\n  }\n\n  // ...\n\n}\n\nIf the same user object is rendered in both Profile and TeamReport, the two components can share work and only call calculateUserMetrics once for that user.\n\nAssume Profile is rendered first. It will call getUserMetrics, and check if there is a cached result. Since it is the first time getUserMetrics is called with that user, there will be a cache miss. getUserMetrics will then call calculateUserMetrics with that user and write the result to cache.\n\nWhen TeamReport renders its list of users and reaches the same user object, it will call getUserMetrics and read the result from cache.\n\nIf calculateUserMetrics can be aborted by passing an AbortSignal, you can use cacheSignal() to cancel the expensive computation if React has finished rendering. calculateUserMetrics may already handle cancellation internally by using cacheSignal directly.\n\nPitfall\nCalling different memoized functions will read from different caches. \n\nTo access the same cache, components must call the same memoized function.\n\n// Temperature.js\n\nimport {cache} from 'react';\n\nimport {calculateWeekReport} from './report';\n\n\n\nexport function Temperature({cityData}) {\n\n  // 🚩 Wrong: Calling `cache` in component creates new `getWeekReport` for each render\n\n  const getWeekReport = cache(calculateWeekReport);\n\n  const report = getWeekReport(cityData);\n\n  // ...\n\n}\n// Precipitation.js\n\nimport {cache} from 'react';\n\nimport {calculateWeekReport} from './report';\n\n\n\n// 🚩 Wrong: `getWeekReport` is only accessible for `Precipitation` component.\n\nconst getWeekReport = cache(calculateWeekReport);\n\n\n\nexport function Precipitation({cityData}) {\n\n  const report = getWeekReport(cityData);\n\n  // ...\n\n}\n\nIn the above example, Precipitation and Temperature each call cache to create a new memoized function with their own cache look-up. If both components render for the same cityData, they will do duplicate work to call calculateWeekReport.\n\nIn addition, Temperature creates a new memoized function each time the component is rendered which doesn’t allow for any cache sharing.\n\nTo maximize cache hits and reduce work, the two components should call the same memoized function to access the same cache. Instead, define the memoized function in a dedicated module that can be import-ed across components.\n\n// getWeekReport.js\n\nimport {cache} from 'react';\n\nimport {calculateWeekReport} from './report';\n\n\n\nexport default cache(calculateWeekReport);\n// Temperature.js\n\nimport getWeekReport from './getWeekReport';\n\n\n\nexport default function Temperature({cityData}) {\n\n\tconst report = getWeekReport(cityData);\n\n  // ...\n\n}\n// Precipitation.js\n\nimport getWeekReport from './getWeekReport';\n\n\n\nexport default function Precipitation({cityData}) {\n\n  const report = getWeekReport(cityData);\n\n  // ...\n\n}\n\nHere, both components call the same memoized function exported from ./getWeekReport.js to read and write to the same cache.\n\nShare a snapshot of data \n\nTo share a snapshot of data between components, call cache with a data-fetching function like fetch. When multiple components make the same data fetch, only one request is made and the data returned is cached and shared across components. All components refer to the same snapshot of data across the server render.\n\nimport {cache} from 'react';\n\nimport {fetchTemperature} from './api.js';\n\n\n\nconst getTemperature = cache(async (city) => {\n\n\treturn await fetchTemperature(city);\n\n});\n\n\n\nasync function AnimatedWeatherCard({city}) {\n\n\tconst temperature = await getTemperature(city);\n\n\t// ...\n\n}\n\n\n\nasync function MinimalWeatherCard({city}) {\n\n\tconst temperature = await getTemperature(city);\n\n\t// ...\n\n}\n\nIf AnimatedWeatherCard and MinimalWeatherCard both render for the same city, they will receive the same snapshot of data from the memoized function.\n\nIf AnimatedWeatherCard and MinimalWeatherCard supply different city arguments to getTemperature, then fetchTemperature will be called twice and each call site will receive different data.\n\nThe city acts as a cache key.\n\nNote\n\nAsynchronous rendering is only supported for Server Components.\n\nasync function AnimatedWeatherCard({city}) {\n\n\tconst temperature = await getTemperature(city);\n\n\t// ...\n\n}\n\nTo render components that use asynchronous data in Client Components, see use() documentation.\n\nPreload data \n\nBy caching a long-running data fetch, you can kick off asynchronous work prior to rendering the component.\n\nconst getUser = cache(async (id) => {\n\n  return await db.user.query(id);\n\n});\n\n\n\nasync function Profile({id}) {\n\n  const user = await getUser(id);\n\n  return (\n\n    <section>\n\n      <img src={user.profilePic} />\n\n      <h2>{user.name}</h2>\n\n    </section>\n\n  );\n\n}\n\n\n\nfunction Page({id}) {\n\n  // ✅ Good: start fetching the user data\n\n  getUser(id);\n\n  // ... some computational work\n\n  return (\n\n    <>\n\n      <Profile id={id} />\n\n    </>\n\n  );\n\n}\n\nWhen rendering Page, the component calls getUser but note that it doesn’t use the returned data. This early getUser call kicks off the asynchronous database query that occurs while Page is doing other computational work and rendering children.\n\nWhen rendering Profile, we call getUser again. If the initial getUser call has already returned and cached the user data, when Profile asks and waits for this data, it can simply read from the cache without requiring another remote procedure call. If the  initial data request hasn’t been completed, preloading data in this pattern reduces delay in data-fetching.\n\nDEEP DIVE\nCaching asynchronous work \nShow Details\nPitfall\nCalling a memoized function outside of a component will not use the cache. \nimport {cache} from 'react';\n\n\n\nconst getUser = cache(async (userId) => {\n\n  return await db.user.query(userId);\n\n});\n\n\n\n// 🚩 Wrong: Calling memoized function outside of component will not memoize.\n\ngetUser('demo-id');\n\n\n\nasync function DemoProfile() {\n\n  // ✅ Good: `getUser` will memoize.\n\n  const user = await getUser('demo-id');\n\n  return <Profile user={user} />;\n\n}\n\nReact only provides cache access to the memoized function in a component. When calling getUser outside of a component, it will still evaluate the function but not read or update the cache.\n\nThis is because cache access is provided through a context which is only accessible from a component.\n\nDEEP DIVE\nWhen should I use cache, memo, or useMemo? \nShow Details\nTroubleshooting \nMy memoized function still runs even though I’ve called it with the same arguments \n\nSee prior mentioned pitfalls\n\nCalling different memoized functions will read from different caches.\nCalling a memoized function outside of a component will not use the cache.\n\nIf none of the above apply, it may be a problem with how React checks if something exists in cache.\n\nIf your arguments are not primitives (ex. objects, functions, arrays), ensure you’re passing the same object reference.\n\nWhen calling a memoized function, React will look up the input arguments to see if a result is already cached. React will use shallow equality of the arguments to determine if there is a cache hit.\n\nimport {cache} from 'react';\n\n\n\nconst calculateNorm = cache((vector) => {\n\n  // ...\n\n});\n\n\n\nfunction MapMarker(props) {\n\n  // 🚩 Wrong: props is an object that changes every render.\n\n  const length = calculateNorm(props);\n\n  // ...\n\n}\n\n\n\nfunction App() {\n\n  return (\n\n    <>\n\n      <MapMarker x={10} y={10} z={10} />\n\n      <MapMarker x={10} y={10} z={10} />\n\n    </>\n\n  );\n\n}\n\nIn this case the two MapMarkers look like they’re doing the same work and calling calculateNorm with the same value of {x: 10, y: 10, z:10}. Even though the objects contain the same values, they are not the same object reference as each component creates its own props object.\n\nReact will call Object.is on the input to verify if there is a cache hit.\n\nimport {cache} from 'react';\n\n\n\nconst calculateNorm = cache((x, y, z) => {\n\n  // ...\n\n});\n\n\n\nfunction MapMarker(props) {\n\n  // ✅ Good: Pass primitives to memoized function\n\n  const length = calculateNorm(props.x, props.y, props.z);\n\n  // ...\n\n}\n\n\n\nfunction App() {\n\n  return (\n\n    <>\n\n      <MapMarker x={10} y={10} z={10} />\n\n      <MapMarker x={10} y={10} z={10} />\n\n    </>\n\n  );\n\n}\n\nOne way to address this could be to pass the vector dimensions to calculateNorm. This works because the dimensions themselves are primitives.\n\nAnother solution may be to pass the vector object itself as a prop to the component. We’ll need to pass the same object to both component instances.\n\nimport {cache} from 'react';\n\n\n\nconst calculateNorm = cache((vector) => {\n\n  // ...\n\n});\n\n\n\nfunction MapMarker(props) {\n\n  // ✅ Good: Pass the same `vector` object\n\n  const length = calculateNorm(props.vector);\n\n  // ...\n\n}\n\n\n\nfunction App() {\n\n  const vector = [10, 10, 10];\n\n  return (\n\n    <>\n\n      <MapMarker vector={vector} />\n\n      <MapMarker vector={vector} />\n\n    </>\n\n  );\n\n}\nPREVIOUS\naddTransitionType\nNEXT\ncacheSignal"
  },
  {
    "title": "cacheSignal – React",
    "url": "https://react.dev/reference/react/cacheSignal",
    "html": "API REFERENCE\nAPIS\ncacheSignal\nReact Server Components\n\ncacheSignal is currently only used with React Server Components.\n\ncacheSignal allows you to know when the cache() lifetime is over.\n\nconst signal = cacheSignal();\nReference\ncacheSignal\nUsage\nCancel in-flight requests\nIgnore errors after React has finished rendering\nReference \ncacheSignal \n\nCall cacheSignal to get an AbortSignal.\n\nimport {cacheSignal} from 'react';\n\nasync function Component() {\n\n  await fetch(url, { signal: cacheSignal() });\n\n}\n\nWhen React has finished rendering, the AbortSignal will be aborted. This allows you to cancel any in-flight work that is no longer needed.\nRendering is considered finished when:\n\nReact has successfully completed rendering\nthe render was aborted\nthe render has failed\nParameters \n\nThis function does not accept any parameters.\n\nReturns \n\ncacheSignal returns an AbortSignal if called during rendering. Otherwise cacheSignal() returns null.\n\nCaveats \ncacheSignal is currently for use in React Server Components only. In Client Components, it will always return null. In the future it will also be used for Client Component when a client cache refreshes or invalidates. You should not assume it’ll always be null on the client.\nIf called outside of rendering, cacheSignal will return null to make it clear that the current scope isn’t cached forever.\nUsage \nCancel in-flight requests \n\nCall cacheSignal to abort in-flight requests.\n\nimport {cache, cacheSignal} from 'react';\n\nconst dedupedFetch = cache(fetch);\n\nasync function Component() {\n\n  await dedupedFetch(url, { signal: cacheSignal() });\n\n}\nPitfall\n\nYou can’t use cacheSignal to abort async work that was started outside of rendering e.g.\n\nimport {cacheSignal} from 'react';\n\n// 🚩 Pitfall: The request will not actually be aborted if the rendering of `Component` is finished.\n\nconst response = fetch(url, { signal: cacheSignal() });\n\nasync function Component() {\n\n  await response;\n\n}\nIgnore errors after React has finished rendering \n\nIf a function throws, it may be due to cancellation (e.g. the Database connection has been closed). You can use the aborted property to check if the error was due to cancellation or a real error. You may want to ignore errors that were due to cancellation.\n\nimport {cacheSignal} from \"react\";\n\nimport {queryDatabase, logError} from \"./database\";\n\n\n\nasync function getData(id) {\n\n  try {\n\n     return await queryDatabase(id);\n\n  } catch (x) {\n\n     if (!cacheSignal()?.aborted) {\n\n        // only log if it's a real error and not due to cancellation\n\n       logError(x);\n\n     }\n\n     return null;\n\n  }\n\n}\n\n\n\nasync function Component({id}) {\n\n  const data = await getData(id);\n\n  if (data === null) {\n\n    return <div>No data available</div>;\n\n  }\n\n  return <div>{data.name}</div>;\n\n}\nPREVIOUS\ncache\nNEXT\ncaptureOwnerStack"
  },
  {
    "title": "captureOwnerStack – React",
    "url": "https://react.dev/reference/react/captureOwnerStack",
    "html": "API REFERENCE\nAPIS\ncaptureOwnerStack\n\ncaptureOwnerStack reads the current Owner Stack in development and returns it as a string if available.\n\nconst stack = captureOwnerStack();\nReference\ncaptureOwnerStack()\nUsage\nEnhance a custom error overlay\nTroubleshooting\nThe Owner Stack is null\ncaptureOwnerStack is not available\nReference \ncaptureOwnerStack() \n\nCall captureOwnerStack to get the current Owner Stack.\n\nimport * as React from 'react';\n\n\n\nfunction Component() {\n\n  if (process.env.NODE_ENV !== 'production') {\n\n    const ownerStack = React.captureOwnerStack();\n\n    console.log(ownerStack);\n\n  }\n\n}\nParameters \n\ncaptureOwnerStack does not take any parameters.\n\nReturns \n\ncaptureOwnerStack returns string | null.\n\nOwner Stacks are available in\n\nComponent render\nEffects (e.g. useEffect)\nReact’s event handlers (e.g. <button onClick={...} />)\nReact error handlers (React Root options onCaughtError, onRecoverableError, and onUncaughtError)\n\nIf no Owner Stack is available, null is returned (see Troubleshooting: The Owner Stack is null).\n\nCaveats \nOwner Stacks are only available in development. captureOwnerStack will always return null outside of development.\nDEEP DIVE\nOwner Stack vs Component Stack \nShow Details\nUsage \nEnhance a custom error overlay \nimport { captureOwnerStack } from \"react\";\n\nimport { instrumentedConsoleError } from \"./errorOverlay\";\n\n\n\nconst originalConsoleError = console.error;\n\nconsole.error = function patchedConsoleError(...args) {\n\n  originalConsoleError.apply(console, args);\n\n  const ownerStack = captureOwnerStack();\n\n  onConsoleError({\n\n    // Keep in mind that in a real application, console.error can be\n\n    // called with multiple arguments which you should account for.\n\n    consoleMessage: args[0],\n\n    ownerStack,\n\n  });\n\n};\n\nIf you intercept console.error calls to highlight them in an error overlay, you can call captureOwnerStack to include the Owner Stack.\n\nindex.js\nerrorOverlay.js\nApp.js\nReload\nClear\nFork\nimport { captureOwnerStack } from \"react\";\nimport { createRoot } from \"react-dom/client\";\nimport App from './App';\nimport { onConsoleError } from \"./errorOverlay\";\nimport './styles.css';\n\nconst originalConsoleError = console.error;\nconsole.error = function patchedConsoleError(...args) {\n  originalConsoleError.apply(console, args);\n  const ownerStack = captureOwnerStack();\n  onConsoleError({\n    // Keep in mind that in a real application, console.error can be\n    // called with multiple arguments which you should account for.\n    consoleMessage: args[0],\n    ownerStack,\n  });\n};\n\nconst container = document.getElementById(\"root\");\ncreateRoot(container).render(<App />);\n\n\nShow more\nTroubleshooting \nThe Owner Stack is null \n\nThe call of captureOwnerStack happened outside of a React controlled function e.g. in a setTimeout callback, after a fetch call or in a custom DOM event handler. During render, Effects, React event handlers, and React error handlers (e.g. hydrateRoot#options.onCaughtError) Owner Stacks should be available.\n\nIn the example below, clicking the button will log an empty Owner Stack because captureOwnerStack was called during a custom DOM event handler. The Owner Stack must be captured earlier e.g. by moving the call of captureOwnerStack into the Effect body.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport {captureOwnerStack, useEffect} from 'react';\n\nexport default function App() {\n  useEffect(() => {\n    // Should call `captureOwnerStack` here.\n    function handleEvent() {\n      // Calling it in a custom DOM event handler is too late.\n      // The Owner Stack will be `null` at this point.\n      console.log('Owner Stack: ', captureOwnerStack());\n    }\n\n    document.addEventListener('click', handleEvent);\n\n    return () => {\n      document.removeEventListener('click', handleEvent);\n    }\n  })\n\n  return <button>Click me to see that Owner Stacks are not available in custom DOM event handlers</button>;\n}\n\n\nShow more\ncaptureOwnerStack is not available \n\ncaptureOwnerStack is only exported in development builds. It will be undefined in production builds. If captureOwnerStack is used in files that are bundled for production and development, you should conditionally access it from a namespace import.\n\n// Don't use named imports of `captureOwnerStack` in files that are bundled for development and production.\n\nimport {captureOwnerStack} from 'react';\n\n// Use a namespace import instead and access `captureOwnerStack` conditionally.\n\nimport * as React from 'react';\n\n\n\nif (process.env.NODE_ENV !== 'production') {\n\n  const ownerStack = React.captureOwnerStack();\n\n  console.log('Owner Stack', ownerStack);\n\n}\nPREVIOUS\ncacheSignal\nNEXT\ncreateContext"
  },
  {
    "title": "createContext – React",
    "url": "https://react.dev/reference/react/createContext",
    "html": "API REFERENCE\nAPIS\ncreateContext\n\ncreateContext lets you create a context that components can provide or read.\n\nconst SomeContext = createContext(defaultValue)\nReference\ncreateContext(defaultValue)\nSomeContext Provider\nSomeContext.Consumer\nUsage\nCreating context\nImporting and exporting context from a file\nTroubleshooting\nI can’t find a way to change the context value\nReference \ncreateContext(defaultValue) \n\nCall createContext outside of any components to create a context.\n\nimport { createContext } from 'react';\n\n\n\nconst ThemeContext = createContext('light');\n\nSee more examples below.\n\nParameters \ndefaultValue: The value that you want the context to have when there is no matching context provider in the tree above the component that reads context. If you don’t have any meaningful default value, specify null. The default value is meant as a “last resort” fallback. It is static and never changes over time.\nReturns \n\ncreateContext returns a context object.\n\nThe context object itself does not hold any information. It represents which context other components read or provide. Typically, you will use SomeContext in components above to specify the context value, and call useContext(SomeContext) in components below to read it. The context object has a few properties:\n\nSomeContext lets you provide the context value to components.\nSomeContext.Consumer is an alternative and rarely used way to read the context value.\nSomeContext.Provider is a legacy way to provide the context value before React 19.\nSomeContext Provider \n\nWrap your components into a context provider to specify the value of this context for all components inside:\n\nfunction App() {\n\n  const [theme, setTheme] = useState('light');\n\n  // ...\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <Page />\n\n    </ThemeContext>\n\n  );\n\n}\nNote\n\nStarting in React 19, you can render <SomeContext> as a provider.\n\nIn older versions of React, use <SomeContext.Provider>.\n\nProps \nvalue: The value that you want to pass to all the components reading this context inside this provider, no matter how deep. The context value can be of any type. A component calling useContext(SomeContext) inside of the provider receives the value of the innermost corresponding context provider above it.\nSomeContext.Consumer \n\nBefore useContext existed, there was an older way to read context:\n\nfunction Button() {\n\n  // 🟡 Legacy way (not recommended)\n\n  return (\n\n    <ThemeContext.Consumer>\n\n      {theme => (\n\n        <button className={theme} />\n\n      )}\n\n    </ThemeContext.Consumer>\n\n  );\n\n}\n\nAlthough this older way still works, newly written code should read context with useContext() instead:\n\nfunction Button() {\n\n  // ✅ Recommended way\n\n  const theme = useContext(ThemeContext);\n\n  return <button className={theme} />;\n\n}\nProps \nchildren: A function. React will call the function you pass with the current context value determined by the same algorithm as useContext() does, and render the result you return from this function. React will also re-run this function and update the UI whenever the context from the parent components changes.\nUsage \nCreating context \n\nContext lets components pass information deep down without explicitly passing props.\n\nCall createContext outside any components to create one or more contexts.\n\nimport { createContext } from 'react';\n\n\n\nconst ThemeContext = createContext('light');\n\nconst AuthContext = createContext(null);\n\ncreateContext returns a context object. Components can read context by passing it to useContext():\n\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\n}\n\n\n\nfunction Profile() {\n\n  const currentUser = useContext(AuthContext);\n\n  // ...\n\n}\n\nBy default, the values they receive will be the default values you have specified when creating the contexts. However, by itself this isn’t useful because the default values never change.\n\nContext is useful because you can provide other, dynamic values from your components:\n\nfunction App() {\n\n  const [theme, setTheme] = useState('dark');\n\n  const [currentUser, setCurrentUser] = useState({ name: 'Taylor' });\n\n\n\n  // ...\n\n\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <AuthContext value={currentUser}>\n\n        <Page />\n\n      </AuthContext>\n\n    </ThemeContext>\n\n  );\n\n}\n\nNow the Page component and any components inside it, no matter how deep, will “see” the passed context values. If the passed context values change, React will re-render the components reading the context as well.\n\nRead more about reading and providing context and see examples.\n\nImporting and exporting context from a file \n\nOften, components in different files will need access to the same context. This is why it’s common to declare contexts in a separate file. Then you can use the export statement to make context available for other files:\n\n// Contexts.js\n\nimport { createContext } from 'react';\n\n\n\nexport const ThemeContext = createContext('light');\n\nexport const AuthContext = createContext(null);\n\nComponents declared in other files can then use the import statement to read or provide this context:\n\n// Button.js\n\nimport { ThemeContext } from './Contexts.js';\n\n\n\nfunction Button() {\n\n  const theme = useContext(ThemeContext);\n\n  // ...\n\n}\n// App.js\n\nimport { ThemeContext, AuthContext } from './Contexts.js';\n\n\n\nfunction App() {\n\n  // ...\n\n  return (\n\n    <ThemeContext value={theme}>\n\n      <AuthContext value={currentUser}>\n\n        <Page />\n\n      </AuthContext>\n\n    </ThemeContext>\n\n  );\n\n}\n\nThis works similar to importing and exporting components.\n\nTroubleshooting \nI can’t find a way to change the context value \n\nCode like this specifies the default context value:\n\nconst ThemeContext = createContext('light');\n\nThis value never changes. React only uses this value as a fallback if it can’t find a matching provider above.\n\nTo make context change over time, add state and wrap components in a context provider.\n\nPREVIOUS\ncaptureOwnerStack\nNEXT\nlazy"
  },
  {
    "title": "lazy – React",
    "url": "https://react.dev/reference/react/lazy",
    "html": "API REFERENCE\nAPIS\nlazy\n\nlazy lets you defer loading component’s code until it is rendered for the first time.\n\nconst SomeComponent = lazy(load)\nReference\nlazy(load)\nload function\nUsage\nLazy-loading components with Suspense\nTroubleshooting\nMy lazy component’s state gets reset unexpectedly\nReference \nlazy(load) \n\nCall lazy outside your components to declare a lazy-loaded React component:\n\nimport { lazy } from 'react';\n\n\n\nconst MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\nSee more examples below.\n\nParameters \nload: A function that returns a Promise or another thenable (a Promise-like object with a then method). React will not call load until the first time you attempt to render the returned component. After React first calls load, it will wait for it to resolve, and then render the resolved value’s .default as a React component. Both the returned Promise and the Promise’s resolved value will be cached, so React will not call load more than once. If the Promise rejects, React will throw the rejection reason for the nearest Error Boundary to handle.\nReturns \n\nlazy returns a React component you can render in your tree. While the code for the lazy component is still loading, attempting to render it will suspend. Use <Suspense> to display a loading indicator while it’s loading.\n\nload function \nParameters \n\nload receives no parameters.\n\nReturns \n\nYou need to return a Promise or some other thenable (a Promise-like object with a then method). It needs to eventually resolve to an object whose .default property is a valid React component type, such as a function, memo, or a forwardRef component.\n\nUsage \nLazy-loading components with Suspense \n\nUsually, you import components with the static import declaration:\n\nimport MarkdownPreview from './MarkdownPreview.js';\n\nTo defer loading this component’s code until it’s rendered for the first time, replace this import with:\n\nimport { lazy } from 'react';\n\n\n\nconst MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\nThis code relies on dynamic import(), which might require support from your bundler or framework. Using this pattern requires that the lazy component you’re importing was exported as the default export.\n\nNow that your component’s code loads on demand, you also need to specify what should be displayed while it is loading. You can do this by wrapping the lazy component or any of its parents into a <Suspense> boundary:\n\n<Suspense fallback={<Loading />}>\n\n  <h2>Preview</h2>\n\n  <MarkdownPreview />\n\n</Suspense>\n\nIn this example, the code for MarkdownPreview won’t be loaded until you attempt to render it. If MarkdownPreview hasn’t loaded yet, Loading will be shown in its place. Try ticking the checkbox:\n\nApp.js\nLoading.js\nMarkdownPreview.js\nReload\nClear\nFork\nimport { useState, Suspense, lazy } from 'react';\nimport Loading from './Loading.js';\n\nconst MarkdownPreview = lazy(() => delayForDemo(import('./MarkdownPreview.js')));\n\nexport default function MarkdownEditor() {\n  const [showPreview, setShowPreview] = useState(false);\n  const [markdown, setMarkdown] = useState('Hello, **world**!');\n  return (\n    <>\n      <textarea value={markdown} onChange={e => setMarkdown(e.target.value)} />\n      <label>\n        <input type=\"checkbox\" checked={showPreview} onChange={e => setShowPreview(e.target.checked)} />\n        Show preview\n      </label>\n      <hr />\n      {showPreview && (\n        <Suspense fallback={<Loading />}>\n          <h2>Preview</h2>\n          <MarkdownPreview markdown={markdown} />\n        </Suspense>\n      )}\n    </>\n  );\n}\n\n// Add a fixed delay so you can see the loading state\nfunction delayForDemo(promise) {\n  return new Promise(resolve => {\n    setTimeout(resolve, 2000);\n  }).then(() => promise);\n}\n\n\nShow more\n\nThis demo loads with an artificial delay. The next time you untick and tick the checkbox, Preview will be cached, so there will be no loading state. To see the loading state again, click “Reset” on the sandbox.\n\nLearn more about managing loading states with Suspense.\n\nTroubleshooting \nMy lazy component’s state gets reset unexpectedly \n\nDo not declare lazy components inside other components:\n\nimport { lazy } from 'react';\n\n\n\nfunction Editor() {\n\n  // 🔴 Bad: This will cause all state to be reset on re-renders\n\n  const MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\n  // ...\n\n}\n\nInstead, always declare them at the top level of your module:\n\nimport { lazy } from 'react';\n\n\n\n// ✅ Good: Declare lazy components outside of your components\n\nconst MarkdownPreview = lazy(() => import('./MarkdownPreview.js'));\n\n\n\nfunction Editor() {\n\n  // ...\n\n}\nPREVIOUS\ncreateContext\nNEXT\nmemo"
  },
  {
    "title": "memo – React",
    "url": "https://react.dev/reference/react/memo",
    "html": "API REFERENCE\nAPIS\nmemo\n\nmemo lets you skip re-rendering a component when its props are unchanged.\n\nconst MemoizedComponent = memo(SomeComponent, arePropsEqual?)\nNote\n\nReact Compiler automatically applies the equivalent of memo to all components, reducing the need for manual memoization. You can use the compiler to handle component memoization automatically.\n\nReference\nmemo(Component, arePropsEqual?)\nUsage\nSkipping re-rendering when props are unchanged\nUpdating a memoized component using state\nUpdating a memoized component using a context\nMinimizing props changes\nSpecifying a custom comparison function\nDo I still need React.memo if I use React Compiler?\nTroubleshooting\nMy component re-renders when a prop is an object, array, or function\nReference \nmemo(Component, arePropsEqual?) \n\nWrap a component in memo to get a memoized version of that component. This memoized version of your component will usually not be re-rendered when its parent component is re-rendered as long as its props have not changed. But React may still re-render it: memoization is a performance optimization, not a guarantee.\n\nimport { memo } from 'react';\n\n\n\nconst SomeComponent = memo(function SomeComponent(props) {\n\n  // ...\n\n});\n\nSee more examples below.\n\nParameters \n\nComponent: The component that you want to memoize. The memo does not modify this component, but returns a new, memoized component instead. Any valid React component, including functions and forwardRef components, is accepted.\n\noptional arePropsEqual: A function that accepts two arguments: the component’s previous props, and its new props. It should return true if the old and new props are equal: that is, if the component will render the same output and behave in the same way with the new props as with the old. Otherwise it should return false. Usually, you will not specify this function. By default, React will compare each prop with Object.is.\n\nReturns \n\nmemo returns a new React component. It behaves the same as the component provided to memo except that React will not always re-render it when its parent is being re-rendered unless its props have changed.\n\nUsage \nSkipping re-rendering when props are unchanged \n\nReact normally re-renders a component whenever its parent re-renders. With memo, you can create a component that React will not re-render when its parent re-renders so long as its new props are the same as the old props. Such a component is said to be memoized.\n\nTo memoize a component, wrap it in memo and use the value that it returns in place of your original component:\n\nconst Greeting = memo(function Greeting({ name }) {\n\n  return <h1>Hello, {name}!</h1>;\n\n});\n\n\n\nexport default Greeting;\n\nA React component should always have pure rendering logic. This means that it must return the same output if its props, state, and context haven’t changed. By using memo, you are telling React that your component complies with this requirement, so React doesn’t need to re-render as long as its props haven’t changed. Even with memo, your component will re-render if its own state changes or if a context that it’s using changes.\n\nIn this example, notice that the Greeting component re-renders whenever name is changed (because that’s one of its props), but not when address is changed (because it’s not passed to Greeting as a prop):\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { memo, useState } from 'react';\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n  return <h3>Hello{name && ', '}{name}!</h3>;\n});\n\n\nShow more\nNote\n\nYou should only rely on memo as a performance optimization. If your code doesn’t work without it, find the underlying problem and fix it first. Then you may add memo to improve performance.\n\nDEEP DIVE\nShould you add memo everywhere? \nShow Details\nUpdating a memoized component using state \n\nEven when a component is memoized, it will still re-render when its own state changes. Memoization only has to do with props that are passed to the component from its parent.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { memo, useState } from 'react';\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log('Greeting was rendered at', new Date().toLocaleTimeString());\n  const [greeting, setGreeting] = useState('Hello');\n  return (\n    <>\n      <h3>{greeting}{name && ', '}{name}!</h3>\n      <GreetingSelector value={greeting} onChange={setGreeting} />\n    </>\n  );\n});\n\nfunction GreetingSelector({ value, onChange }) {\n  return (\n    <>\n      <label>\n        <input\n          type=\"radio\"\n          checked={value === 'Hello'}\n          onChange={e => onChange('Hello')}\n        />\n        Regular greeting\n      </label>\n      <label>\n        <input\n          type=\"radio\"\n          checked={value === 'Hello and welcome'}\n          onChange={e => onChange('Hello and welcome')}\n        />\n        Enthusiastic greeting\n      </label>\n    </>\n  );\n}\n\n\nShow more\n\nIf you set a state variable to its current value, React will skip re-rendering your component even without memo. You may still see your component function being called an extra time, but the result will be discarded.\n\nUpdating a memoized component using a context \n\nEven when a component is memoized, it will still re-render when a context that it’s using changes. Memoization only has to do with props that are passed to the component from its parent.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, memo, useContext, useState } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  const [theme, setTheme] = useState('dark');\n\n  function handleClick() {\n    setTheme(theme === 'dark' ? 'light' : 'dark');\n  }\n\n  return (\n    <ThemeContext value={theme}>\n      <button onClick={handleClick}>\n        Switch theme\n      </button>\n      <Greeting name=\"Taylor\" />\n    </ThemeContext>\n  );\n}\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n  const theme = useContext(ThemeContext);\n  return (\n    <h3 className={theme}>Hello, {name}!</h3>\n  );\n});\n\n\nShow more\n\nTo make your component re-render only when a part of some context changes, split your component in two. Read what you need from the context in the outer component, and pass it down to a memoized child as a prop.\n\nMinimizing props changes \n\nWhen you use memo, your component re-renders whenever any prop is not shallowly equal to what it was previously. This means that React compares every prop in your component with its previous value using the Object.is comparison. Note that Object.is(3, 3) is true, but Object.is({}, {}) is false.\n\nTo get the most out of memo, minimize the times that the props change. For example, if the prop is an object, prevent the parent component from re-creating that object every time by using useMemo:\n\nfunction Page() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n\n\n  const person = useMemo(\n\n    () => ({ name, age }),\n\n    [name, age]\n\n  );\n\n\n\n  return <Profile person={person} />;\n\n}\n\n\n\nconst Profile = memo(function Profile({ person }) {\n\n  // ...\n\n});\n\nA better way to minimize props changes is to make sure the component accepts the minimum necessary information in its props. For example, it could accept individual values instead of a whole object:\n\nfunction Page() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n  return <Profile name={name} age={age} />;\n\n}\n\n\n\nconst Profile = memo(function Profile({ name, age }) {\n\n  // ...\n\n});\n\nEven individual values can sometimes be projected to ones that change less frequently. For example, here a component accepts a boolean indicating the presence of a value rather than the value itself:\n\nfunction GroupsLanding({ person }) {\n\n  const hasGroups = person.groups !== null;\n\n  return <CallToAction hasGroups={hasGroups} />;\n\n}\n\n\n\nconst CallToAction = memo(function CallToAction({ hasGroups }) {\n\n  // ...\n\n});\n\nWhen you need to pass a function to memoized component, either declare it outside your component so that it never changes, or useCallback to cache its definition between re-renders.\n\nSpecifying a custom comparison function \n\nIn rare cases it may be infeasible to minimize the props changes of a memoized component. In that case, you can provide a custom comparison function, which React will use to compare the old and new props instead of using shallow equality. This function is passed as a second argument to memo. It should return true only if the new props would result in the same output as the old props; otherwise it should return false.\n\nconst Chart = memo(function Chart({ dataPoints }) {\n\n  // ...\n\n}, arePropsEqual);\n\n\n\nfunction arePropsEqual(oldProps, newProps) {\n\n  return (\n\n    oldProps.dataPoints.length === newProps.dataPoints.length &&\n\n    oldProps.dataPoints.every((oldPoint, index) => {\n\n      const newPoint = newProps.dataPoints[index];\n\n      return oldPoint.x === newPoint.x && oldPoint.y === newPoint.y;\n\n    })\n\n  );\n\n}\n\nIf you do this, use the Performance panel in your browser developer tools to make sure that your comparison function is actually faster than re-rendering the component. You might be surprised.\n\nWhen you do performance measurements, make sure that React is running in the production mode.\n\nPitfall\n\nIf you provide a custom arePropsEqual implementation, you must compare every prop, including functions. Functions often close over the props and state of parent components. If you return true when oldProps.onClick !== newProps.onClick, your component will keep “seeing” the props and state from a previous render inside its onClick handler, leading to very confusing bugs.\n\nAvoid doing deep equality checks inside arePropsEqual unless you are 100% sure that the data structure you’re working with has a known limited depth. Deep equality checks can become incredibly slow and can freeze your app for many seconds if someone changes the data structure later.\n\nDo I still need React.memo if I use React Compiler? \n\nWhen you enable React Compiler, you typically don’t need React.memo anymore. The compiler automatically optimizes component re-rendering for you.\n\nHere’s how it works:\n\nWithout React Compiler, you need React.memo to prevent unnecessary re-renders:\n\n// Parent re-renders every second\n\nfunction Parent() {\n\n  const [seconds, setSeconds] = useState(0);\n\n\n\n  useEffect(() => {\n\n    const interval = setInterval(() => {\n\n      setSeconds(s => s + 1);\n\n    }, 1000);\n\n    return () => clearInterval(interval);\n\n  }, []);\n\n\n\n  return (\n\n    <>\n\n      <h1>Seconds: {seconds}</h1>\n\n      <ExpensiveChild name=\"John\" />\n\n    </>\n\n  );\n\n}\n\n\n\n// Without memo, this re-renders every second even though props don't change\n\nconst ExpensiveChild = memo(function ExpensiveChild({ name }) {\n\n  console.log('ExpensiveChild rendered');\n\n  return <div>Hello, {name}!</div>;\n\n});\n\nWith React Compiler enabled, the same optimization happens automatically:\n\n// No memo needed - compiler prevents re-renders automatically\n\nfunction ExpensiveChild({ name }) {\n\n  console.log('ExpensiveChild rendered');\n\n  return <div>Hello, {name}!</div>;\n\n}\n\nHere’s the key part of what the React Compiler generates:\n\nfunction Parent() {\n\n  const $ = _c(7);\n\n  const [seconds, setSeconds] = useState(0);\n\n  // ... other code ...\n\n\n\n  let t3;\n\n  if ($[4] === Symbol.for(\"react.memo_cache_sentinel\")) {\n\n    t3 = <ExpensiveChild name=\"John\" />;\n\n    $[4] = t3;\n\n  } else {\n\n    t3 = $[4];\n\n  }\n\n  // ... return statement ...\n\n}\n\nNotice the highlighted lines: The compiler wraps <ExpensiveChild name=\"John\" /> in a cache check. Since the name prop is always \"John\", this JSX is created once and reused on every parent re-render. This is exactly what React.memo does - it prevents the child from re-rendering when its props haven’t changed.\n\nThe React Compiler automatically:\n\nTracks that the name prop passed to ExpensiveChild hasn’t changed\nReuses the previously created JSX for <ExpensiveChild name=\"John\" />\nSkips re-rendering ExpensiveChild entirely\n\nThis means you can safely remove React.memo from your components when using React Compiler. The compiler provides the same optimization automatically, making your code cleaner and easier to maintain.\n\nNote\n\nThe compiler’s optimization is actually more comprehensive than React.memo. It also memoizes intermediate values and expensive computations within your components, similar to combining React.memo with useMemo throughout your component tree.\n\nTroubleshooting \nMy component re-renders when a prop is an object, array, or function \n\nReact compares old and new props by shallow equality: that is, it considers whether each new prop is reference-equal to the old prop. If you create a new object or array each time the parent is re-rendered, even if the individual elements are each the same, React will still consider it to be changed. Similarly, if you create a new function when rendering the parent component, React will consider it to have changed even if the function has the same definition. To avoid this, simplify props or memoize props in the parent component.\n\nPREVIOUS\nlazy\nNEXT\nstartTransition"
  },
  {
    "title": "startTransition – React",
    "url": "https://react.dev/reference/react/startTransition",
    "html": "API REFERENCE\nAPIS\nstartTransition\n\nstartTransition lets you render a part of the UI in the background.\n\nstartTransition(action)\nReference\nstartTransition(action)\nUsage\nMarking a state update as a non-blocking Transition\nReference \nstartTransition(action) \n\nThe startTransition function lets you mark a state update as a Transition.\n\nimport { startTransition } from 'react';\n\n\n\nfunction TabContainer() {\n\n  const [tab, setTab] = useState('about');\n\n\n\n  function selectTab(nextTab) {\n\n    startTransition(() => {\n\n      setTab(nextTab);\n\n    });\n\n  }\n\n  // ...\n\n}\n\nSee more examples below.\n\nParameters \naction: A function that updates some state by calling one or more set functions. React calls action immediately with no parameters and marks all state updates scheduled synchronously during the action function call as Transitions. Any async calls awaited in the action will be included in the transition, but currently require wrapping any set functions after the await in an additional startTransition (see Troubleshooting). State updates marked as Transitions will be non-blocking and will not display unwanted loading indicators..\nReturns \n\nstartTransition does not return anything.\n\nCaveats \n\nstartTransition does not provide a way to track whether a Transition is pending. To show a pending indicator while the Transition is ongoing, you need useTransition instead.\n\nYou can wrap an update into a Transition only if you have access to the set function of that state. If you want to start a Transition in response to some prop or a custom Hook return value, try useDeferredValue instead.\n\nThe function you pass to startTransition is called immediately, marking all state updates that happen while it executes as Transitions. If you try to perform state updates in a setTimeout, for example, they won’t be marked as Transitions.\n\nYou must wrap any state updates after any async requests in another startTransition to mark them as Transitions. This is a known limitation that we will fix in the future (see Troubleshooting).\n\nA state update marked as a Transition will be interrupted by other state updates. For example, if you update a chart component inside a Transition, but then start typing into an input while the chart is in the middle of a re-render, React will restart the rendering work on the chart component after handling the input state update.\n\nTransition updates can’t be used to control text inputs.\n\nIf there are multiple ongoing Transitions, React currently batches them together. This is a limitation that may be removed in a future release.\n\nUsage \nMarking a state update as a non-blocking Transition \n\nYou can mark a state update as a Transition by wrapping it in a startTransition call:\n\nimport { startTransition } from 'react';\n\n\n\nfunction TabContainer() {\n\n  const [tab, setTab] = useState('about');\n\n\n\n  function selectTab(nextTab) {\n\n    startTransition(() => {\n\n      setTab(nextTab);\n\n    });\n\n  }\n\n  // ...\n\n}\n\nTransitions let you keep the user interface updates responsive even on slow devices.\n\nWith a Transition, your UI stays responsive in the middle of a re-render. For example, if the user clicks a tab but then change their mind and click another tab, they can do that without waiting for the first re-render to finish.\n\nNote\n\nstartTransition is very similar to useTransition, except that it does not provide the isPending flag to track whether a Transition is ongoing. You can call startTransition when useTransition is not available. For example, startTransition works outside components, such as from a data library.\n\nLearn about Transitions and see examples on the useTransition page.\n\nPREVIOUS\nmemo\nNEXT\nuse"
  },
  {
    "title": "use – React",
    "url": "https://react.dev/reference/react/use",
    "html": "API REFERENCE\nAPIS\nuse\n\nuse is a React API that lets you read the value of a resource like a Promise or context.\n\nconst value = use(resource);\nReference\nuse(resource)\nUsage\nReading context with use\nStreaming data from the server to the client\nDealing with rejected Promises\nTroubleshooting\n“Suspense Exception: This is not a real error!”\nReference \nuse(resource) \n\nCall use in your component to read the value of a resource like a Promise or context.\n\nimport { use } from 'react';\n\n\n\nfunction MessageComponent({ messagePromise }) {\n\n  const message = use(messagePromise);\n\n  const theme = use(ThemeContext);\n\n  // ...\n\nUnlike React Hooks, use can be called within loops and conditional statements like if. Like React Hooks, the function that calls use must be a Component or Hook.\n\nWhen called with a Promise, the use API integrates with Suspense and Error Boundaries. The component calling use suspends while the Promise passed to use is pending. If the component that calls use is wrapped in a Suspense boundary, the fallback will be displayed.  Once the Promise is resolved, the Suspense fallback is replaced by the rendered components using the data returned by the use API. If the Promise passed to use is rejected, the fallback of the nearest Error Boundary will be displayed.\n\nSee more examples below.\n\nParameters \nresource: this is the source of the data you want to read a value from. A resource can be a Promise or a context.\nReturns \n\nThe use API returns the value that was read from the resource like the resolved value of a Promise or context.\n\nCaveats \nThe use API must be called inside a Component or a Hook.\nWhen fetching data in a Server Component, prefer async and await over use. async and await pick up rendering from the point where await was invoked, whereas use re-renders the component after the data is resolved.\nPrefer creating Promises in Server Components and passing them to Client Components over creating Promises in Client Components. Promises created in Client Components are recreated on every render. Promises passed from a Server Component to a Client Component are stable across re-renders. See this example.\nUsage \nReading context with use \n\nWhen a context is passed to use, it works similarly to useContext. While useContext must be called at the top level of your component, use can be called inside conditionals like if and loops like for. use is preferred over useContext because it is more flexible.\n\nimport { use } from 'react';\n\n\n\nfunction Button() {\n\n  const theme = use(ThemeContext);\n\n  // ...\n\nuse returns the context value for the context you passed. To determine the context value, React searches the component tree and finds the closest context provider above for that particular context.\n\nTo pass context to a Button, wrap it or one of its parent components into the corresponding context provider.\n\nfunction MyPage() {\n\n  return (\n\n    <ThemeContext value=\"dark\">\n\n      <Form />\n\n    </ThemeContext>\n\n  );\n\n}\n\n\n\nfunction Form() {\n\n  // ... renders buttons inside ...\n\n}\n\nIt doesn’t matter how many layers of components there are between the provider and the Button. When a Button anywhere inside of Form calls use(ThemeContext), it will receive \"dark\" as the value.\n\nUnlike useContext, use can be called in conditionals and loops like if.\n\nfunction HorizontalRule({ show }) {\n\n  if (show) {\n\n    const theme = use(ThemeContext);\n\n    return <hr className={theme} />;\n\n  }\n\n  return false;\n\n}\n\nuse is called from inside a if statement, allowing you to conditionally read values from a Context.\n\nPitfall\n\nLike useContext, use(context) always looks for the closest context provider above the component that calls it. It searches upwards and does not consider context providers in the component from which you’re calling use(context).\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, use } from 'react';\n\nconst ThemeContext = createContext(null);\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button show={true}>Sign up</Button>\n      <Button show={false}>Log in</Button>\n    </Panel>\n  );\n}\n\nfunction Panel({ title, children }) {\n  const theme = use(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ show, children }) {\n  if (show) {\n    const theme = use(ThemeContext);\n    const className = 'button-' + theme;\n    return (\n      <button className={className}>\n        {children}\n      </button>\n    );\n  }\n  return false\n}\n\n\nShow more\nStreaming data from the server to the client \n\nData can be streamed from the server to the client by passing a Promise as a prop from a Server Component to a Client Component.\n\nimport { fetchMessage } from './lib.js';\n\nimport { Message } from './message.js';\n\n\n\nexport default function App() {\n\n  const messagePromise = fetchMessage();\n\n  return (\n\n    <Suspense fallback={<p>waiting for message...</p>}>\n\n      <Message messagePromise={messagePromise} />\n\n    </Suspense>\n\n  );\n\n}\n\nThe Client Component then takes the Promise it received as a prop and passes it to the use API. This allows the Client Component to read the value from the Promise that was initially created by the Server Component.\n\n// message.js\n\n'use client';\n\n\n\nimport { use } from 'react';\n\n\n\nexport function Message({ messagePromise }) {\n\n  const messageContent = use(messagePromise);\n\n  return <p>Here is the message: {messageContent}</p>;\n\n}\n\nBecause Message is wrapped in Suspense, the fallback will be displayed until the Promise is resolved. When the Promise is resolved, the value will be read by the use API and the Message component will replace the Suspense fallback.\n\nmessage.js\nReload\nClear\nFork\n\"use client\";\n\nimport { use, Suspense } from \"react\";\n\nfunction Message({ messagePromise }) {\n  const messageContent = use(messagePromise);\n  return <p>Here is the message: {messageContent}</p>;\n}\n\nexport function MessageContainer({ messagePromise }) {\n  return (\n    <Suspense fallback={<p>⌛Downloading message...</p>}>\n      <Message messagePromise={messagePromise} />\n    </Suspense>\n  );\n}\n\n\nShow more\nNote\n\nWhen passing a Promise from a Server Component to a Client Component, its resolved value must be serializable to pass between server and client. Data types like functions aren’t serializable and cannot be the resolved value of such a Promise.\n\nDEEP DIVE\nShould I resolve a Promise in a Server or Client Component? \nShow Details\nDealing with rejected Promises \n\nIn some cases a Promise passed to use could be rejected. You can handle rejected Promises by either:\n\nDisplaying an error to users with an Error Boundary.\nProviding an alternative value with Promise.catch\nPitfall\n\nuse cannot be called in a try-catch block. Instead of a try-catch block wrap your component in an Error Boundary, or provide an alternative value to use with the Promise’s .catch method.\n\nDisplaying an error to users with an Error Boundary \n\nIf you’d like to display an error to your users when a Promise is rejected, you can use an Error Boundary. To use an Error Boundary, wrap the component where you are calling the use API in an Error Boundary. If the Promise passed to use is rejected the fallback for the Error Boundary will be displayed.\n\nmessage.js\nReload\nClear\nFork\n\"use client\";\n\nimport { use, Suspense } from \"react\";\nimport { ErrorBoundary } from \"react-error-boundary\";\n\nexport function MessageContainer({ messagePromise }) {\n  return (\n    <ErrorBoundary fallback={<p>⚠️Something went wrong</p>}>\n      <Suspense fallback={<p>⌛Downloading message...</p>}>\n        <Message messagePromise={messagePromise} />\n      </Suspense>\n    </ErrorBoundary>\n  );\n}\n\nfunction Message({ messagePromise }) {\n  const content = use(messagePromise);\n  return <p>Here is the message: {content}</p>;\n}\n\n\nShow more\nProviding an alternative value with Promise.catch \n\nIf you’d like to provide an alternative value when the Promise passed to use is rejected you can use the Promise’s catch method.\n\nimport { Message } from './message.js';\n\n\n\nexport default function App() {\n\n  const messagePromise = new Promise((resolve, reject) => {\n\n    reject();\n\n  }).catch(() => {\n\n    return \"no new message found.\";\n\n  });\n\n\n\n  return (\n\n    <Suspense fallback={<p>waiting for message...</p>}>\n\n      <Message messagePromise={messagePromise} />\n\n    </Suspense>\n\n  );\n\n}\n\nTo use the Promise’s catch method, call catch on the Promise object. catch takes a single argument: a function that takes an error message as an argument. Whatever is returned by the function passed to catch will be used as the resolved value of the Promise.\n\nTroubleshooting \n“Suspense Exception: This is not a real error!” \n\nYou are either calling use outside of a React Component or Hook function, or calling use in a try–catch block. If you are calling use inside a try–catch block, wrap your component in an Error Boundary, or call the Promise’s catch to catch the error and resolve the Promise with another value. See these examples.\n\nIf you are calling use outside a React Component or Hook function, move the use call to a React Component or Hook function.\n\nfunction MessageComponent({messagePromise}) {\n\n  function download() {\n\n    // ❌ the function calling `use` is not a Component or Hook\n\n    const message = use(messagePromise);\n\n    // ...\n\nInstead, call use outside any component closures, where the function that calls use is a Component or Hook.\n\nfunction MessageComponent({messagePromise}) {\n\n  // ✅ `use` is being called from a component. \n\n  const message = use(messagePromise);\n\n  // ...\nPREVIOUS\nstartTransition\nNEXT\nexperimental_taintObjectReference"
  },
  {
    "title": "experimental_taintObjectReference – React",
    "url": "https://react.dev/reference/react/experimental_taintObjectReference",
    "html": "API REFERENCE\nAPIS\nexperimental_taintObjectReference\nExperimental Feature\n\nThis API is experimental and is not available in a stable version of React yet.\n\nYou can try it by upgrading React packages to the most recent experimental version:\n\nreact@experimental\nreact-dom@experimental\neslint-plugin-react-hooks@experimental\n\nExperimental versions of React may contain bugs. Don’t use them in production.\n\nThis API is only available inside React Server Components.\n\ntaintObjectReference lets you prevent a specific object instance from being passed to a Client Component like a user object.\n\nexperimental_taintObjectReference(message, object);\n\nTo prevent passing a key, hash or token, see taintUniqueValue.\n\nReference\ntaintObjectReference(message, object)\nUsage\nPrevent user data from unintentionally reaching the client\nReference \ntaintObjectReference(message, object) \n\nCall taintObjectReference with an object to register it with React as something that should not be allowed to be passed to the Client as is:\n\nimport {experimental_taintObjectReference} from 'react';\n\n\n\nexperimental_taintObjectReference(\n\n  'Do not pass ALL environment variables to the client.',\n\n  process.env\n\n);\n\nSee more examples below.\n\nParameters \n\nmessage: The message you want to display if the object gets passed to a Client Component. This message will be displayed as a part of the Error that will be thrown if the object gets passed to a Client Component.\n\nobject: The object to be tainted. Functions and class instances can be passed to taintObjectReference as object. Functions and classes are already blocked from being passed to Client Components but the React’s default error message will be replaced by what you defined in message. When a specific instance of a Typed Array is passed to taintObjectReference as object, any other copies of the Typed Array will not be tainted.\n\nReturns \n\nexperimental_taintObjectReference returns undefined.\n\nCaveats \nRecreating or cloning a tainted object creates a new untainted object which may contain sensitive data. For example, if you have a tainted user object, const userInfo = {name: user.name, ssn: user.ssn} or {...user} will create new objects which are not tainted. taintObjectReference only protects against simple mistakes when the object is passed through to a Client Component unchanged.\nPitfall\n\nDo not rely on just tainting for security. Tainting an object doesn’t prevent leaking of every possible derived value. For example, the clone of a tainted object will create a new untainted object. Using data from a tainted object (e.g. {secret: taintedObj.secret}) will create a new value or object that is not tainted. Tainting is a layer of protection; a secure app will have multiple layers of protection, well designed APIs, and isolation patterns.\n\nUsage \nPrevent user data from unintentionally reaching the client \n\nA Client Component should never accept objects that carry sensitive data. Ideally, the data fetching functions should not expose data that the current user should not have access to. Sometimes mistakes happen during refactoring. To protect against these mistakes happening down the line we can “taint” the user object in our data API.\n\nimport {experimental_taintObjectReference} from 'react';\n\n\n\nexport async function getUser(id) {\n\n  const user = await db`SELECT * FROM users WHERE id = ${id}`;\n\n  experimental_taintObjectReference(\n\n    'Do not pass the entire user object to the client. ' +\n\n      'Instead, pick off the specific properties you need for this use case.',\n\n    user,\n\n  );\n\n  return user;\n\n}\n\nNow whenever anyone tries to pass this object to a Client Component, an error will be thrown with the passed in error message instead.\n\nDEEP DIVE\nProtecting against leaks in data fetching \nShow Details\nPREVIOUS\nuse\nNEXT\nexperimental_taintUniqueValue"
  },
  {
    "title": "experimental_taintUniqueValue – React",
    "url": "https://react.dev/reference/react/experimental_taintUniqueValue",
    "html": "API REFERENCE\nAPIS\nexperimental_taintUniqueValue\nExperimental Feature\n\nThis API is experimental and is not available in a stable version of React yet.\n\nYou can try it by upgrading React packages to the most recent experimental version:\n\nreact@experimental\nreact-dom@experimental\neslint-plugin-react-hooks@experimental\n\nExperimental versions of React may contain bugs. Don’t use them in production.\n\nThis API is only available inside React Server Components.\n\ntaintUniqueValue lets you prevent unique values from being passed to Client Components like passwords, keys, or tokens.\n\ntaintUniqueValue(errMessage, lifetime, value)\n\nTo prevent passing an object containing sensitive data, see taintObjectReference.\n\nReference\ntaintUniqueValue(message, lifetime, value)\nUsage\nPrevent a token from being passed to Client Components\nReference \ntaintUniqueValue(message, lifetime, value) \n\nCall taintUniqueValue with a password, token, key or hash to register it with React as something that should not be allowed to be passed to the Client as is:\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nexperimental_taintUniqueValue(\n\n  'Do not pass secret keys to the client.',\n\n  process,\n\n  process.env.SECRET_KEY\n\n);\n\nSee more examples below.\n\nParameters \n\nmessage: The message you want to display if value is passed to a Client Component. This message will be displayed as a part of the Error that will be thrown if value is passed to a Client Component.\n\nlifetime: Any object that indicates how long value should be tainted. value will be blocked from being sent to any Client Component while this object still exists. For example, passing globalThis blocks the value for the lifetime of an app. lifetime is typically an object whose properties contains value.\n\nvalue: A string, bigint or TypedArray. value must be a unique sequence of characters or bytes with high entropy such as a cryptographic token, private key, hash, or a long password. value will be blocked from being sent to any Client Component.\n\nReturns \n\nexperimental_taintUniqueValue returns undefined.\n\nCaveats \nDeriving new values from tainted values can compromise tainting protection. New values created by uppercasing tainted values, concatenating tainted string values into a larger string, converting tainted values to base64, substringing tainted values, and other similar transformations are not tainted unless you explicitly call taintUniqueValue on these newly created values.\nDo not use taintUniqueValue to protect low-entropy values such as PIN codes or phone numbers. If any value in a request is controlled by an attacker, they could infer which value is tainted by enumerating all possible values of the secret.\nUsage \nPrevent a token from being passed to Client Components \n\nTo ensure that sensitive information such as passwords, session tokens, or other unique values do not inadvertently get passed to Client Components, the taintUniqueValue function provides a layer of protection. When a value is tainted, any attempt to pass it to a Client Component will result in an error.\n\nThe lifetime argument defines the duration for which the value remains tainted. For values that should remain tainted indefinitely, objects like globalThis or process can serve as the lifetime argument. These objects have a lifespan that spans the entire duration of your app’s execution.\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nexperimental_taintUniqueValue(\n\n  'Do not pass a user password to the client.',\n\n  globalThis,\n\n  process.env.SECRET_KEY\n\n);\n\nIf the tainted value’s lifespan is tied to a object, the lifetime should be the object that encapsulates the value. This ensures the tainted value remains protected for the lifetime of the encapsulating object.\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nexport async function getUser(id) {\n\n  const user = await db`SELECT * FROM users WHERE id = ${id}`;\n\n  experimental_taintUniqueValue(\n\n    'Do not pass a user session token to the client.',\n\n    user,\n\n    user.session.token\n\n  );\n\n  return user;\n\n}\n\nIn this example, the user object serves as the lifetime argument. If this object gets stored in a global cache or is accessible by another request, the session token remains tainted.\n\nPitfall\n\nDo not rely solely on tainting for security. Tainting a value doesn’t block every possible derived value. For example, creating a new value by upper casing a tainted string will not taint the new value.\n\nimport {experimental_taintUniqueValue} from 'react';\n\n\n\nconst password = 'correct horse battery staple';\n\n\n\nexperimental_taintUniqueValue(\n\n  'Do not pass the password to the client.',\n\n  globalThis,\n\n  password\n\n);\n\n\n\nconst uppercasePassword = password.toUpperCase() // `uppercasePassword` is not tainted\n\nIn this example, the constant password is tainted. Then password is used to create a new value uppercasePassword by calling the toUpperCase method on password. The newly created uppercasePassword is not tainted.\n\nOther similar ways of deriving new values from tainted values like concatenating it into a larger string, converting it to base64, or returning a substring create untained values.\n\nTainting only protects against simple mistakes like explicitly passing secret values to the client. Mistakes in calling the taintUniqueValue like using a global store outside of React, without the corresponding lifetime object, can cause the tainted value to become untainted. Tainting is a layer of protection; a secure app will have multiple layers of protection, well designed APIs, and isolation patterns.\n\nDEEP DIVE\nUsing server-only and taintUniqueValue to prevent leaking secrets \nShow Details\nPREVIOUS\nexperimental_taintObjectReference"
  },
  {
    "title": "Legacy React APIs – React",
    "url": "https://react.dev/reference/react/legacy",
    "html": "API REFERENCE\nLegacy React APIs\n\nThese APIs are exported from the react package, but they are not recommended for use in newly written code. See the linked individual API pages for the suggested alternatives.\n\nLegacy APIs \nChildren lets you manipulate and transform the JSX received as the children prop. See alternatives.\ncloneElement lets you create a React element using another element as a starting point. See alternatives.\nComponent lets you define a React component as a JavaScript class. See alternatives.\ncreateElement lets you create a React element. Typically, you’ll use JSX instead.\ncreateRef creates a ref object which can contain arbitrary value. See alternatives.\nforwardRef lets your component expose a DOM node to parent component with a ref.\nisValidElement checks whether a value is a React element. Typically used with cloneElement.\nPureComponent is similar to Component, but it skip re-renders with same props. See alternatives.\nRemoved APIs \n\nThese APIs were removed in React 19:\n\ncreateFactory: use JSX instead.\nClass Components: static contextTypes: use static contextType instead.\nClass Components: static childContextTypes: use static contextType instead.\nClass Components: static getChildContext: use Context instead.\nClass Components: static propTypes: use a type system like TypeScript instead.\nClass Components: this.refs: use createRef instead.\nNEXT\nChildren"
  },
  {
    "title": "Children – React",
    "url": "https://react.dev/reference/react/Children",
    "html": "API REFERENCE\nLEGACY REACT APIS\nChildren\nPitfall\n\nUsing Children is uncommon and can lead to fragile code. See common alternatives.\n\nChildren lets you manipulate and transform the JSX you received as the children prop.\n\nconst mappedChildren = Children.map(children, child =>\n\n  <div className=\"Row\">\n\n    {child}\n\n  </div>\n\n);\nReference\nChildren.count(children)\nChildren.forEach(children, fn, thisArg?)\nChildren.map(children, fn, thisArg?)\nChildren.only(children)\nChildren.toArray(children)\nUsage\nTransforming children\nRunning some code for each child\nCounting children\nConverting children to an array\nAlternatives\nExposing multiple components\nAccepting an array of objects as a prop\nCalling a render prop to customize rendering\nTroubleshooting\nI pass a custom component, but the Children methods don’t show its render result\nReference \nChildren.count(children) \n\nCall Children.count(children) to count the number of children in the children data structure.\n\nimport { Children } from 'react';\n\n\n\nfunction RowList({ children }) {\n\n  return (\n\n    <>\n\n      <h1>Total rows: {Children.count(children)}</h1>\n\n      ...\n\n    </>\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \nchildren: The value of the children prop received by your component.\nReturns \n\nThe number of nodes inside these children.\n\nCaveats \nEmpty nodes (null, undefined, and Booleans), strings, numbers, and React elements count as individual nodes. Arrays don’t count as individual nodes, but their children do. The traversal does not go deeper than React elements: they don’t get rendered, and their children aren’t traversed. Fragments don’t get traversed.\nChildren.forEach(children, fn, thisArg?) \n\nCall Children.forEach(children, fn, thisArg?) to run some code for each child in the children data structure.\n\nimport { Children } from 'react';\n\n\n\nfunction SeparatorList({ children }) {\n\n  const result = [];\n\n  Children.forEach(children, (child, index) => {\n\n    result.push(child);\n\n    result.push(<hr key={index} />);\n\n  });\n\n  // ...\n\nSee more examples below.\n\nParameters \nchildren: The value of the children prop received by your component.\nfn: The function you want to run for each child, similar to the array forEach method callback. It will be called with the child as the first argument and its index as the second argument. The index starts at 0 and increments on each call.\noptional thisArg: The this value with which the fn function should be called. If omitted, it’s undefined.\nReturns \n\nChildren.forEach returns undefined.\n\nCaveats \nEmpty nodes (null, undefined, and Booleans), strings, numbers, and React elements count as individual nodes. Arrays don’t count as individual nodes, but their children do. The traversal does not go deeper than React elements: they don’t get rendered, and their children aren’t traversed. Fragments don’t get traversed.\nChildren.map(children, fn, thisArg?) \n\nCall Children.map(children, fn, thisArg?) to map or transform each child in the children data structure.\n\nimport { Children } from 'react';\n\n\n\nfunction RowList({ children }) {\n\n  return (\n\n    <div className=\"RowList\">\n\n      {Children.map(children, child =>\n\n        <div className=\"Row\">\n\n          {child}\n\n        </div>\n\n      )}\n\n    </div>\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \nchildren: The value of the children prop received by your component.\nfn: The mapping function, similar to the array map method callback. It will be called with the child as the first argument and its index as the second argument. The index starts at 0 and increments on each call. You need to return a React node from this function. This may be an empty node (null, undefined, or a Boolean), a string, a number, a React element, or an array of other React nodes.\noptional thisArg: The this value with which the fn function should be called. If omitted, it’s undefined.\nReturns \n\nIf children is null or undefined, returns the same value.\n\nOtherwise, returns a flat array consisting of the nodes you’ve returned from the fn function. The returned array will contain all nodes you returned except for null and undefined.\n\nCaveats \n\nEmpty nodes (null, undefined, and Booleans), strings, numbers, and React elements count as individual nodes. Arrays don’t count as individual nodes, but their children do. The traversal does not go deeper than React elements: they don’t get rendered, and their children aren’t traversed. Fragments don’t get traversed.\n\nIf you return an element or an array of elements with keys from fn, the returned elements’ keys will be automatically combined with the key of the corresponding original item from children. When you return multiple elements from fn in an array, their keys only need to be unique locally amongst each other.\n\nChildren.only(children) \n\nCall Children.only(children) to assert that children represent a single React element.\n\nfunction Box({ children }) {\n\n  const element = Children.only(children);\n\n  // ...\nParameters \nchildren: The value of the children prop received by your component.\nReturns \n\nIf children is a valid element, returns that element.\n\nOtherwise, throws an error.\n\nCaveats \nThis method always throws if you pass an array (such as the return value of Children.map) as children. In other words, it enforces that children is a single React element, not that it’s an array with a single element.\nChildren.toArray(children) \n\nCall Children.toArray(children) to create an array out of the children data structure.\n\nimport { Children } from 'react';\n\n\n\nexport default function ReversedList({ children }) {\n\n  const result = Children.toArray(children);\n\n  result.reverse();\n\n  // ...\nParameters \nchildren: The value of the children prop received by your component.\nReturns \n\nReturns a flat array of elements in children.\n\nCaveats \nEmpty nodes (null, undefined, and Booleans) will be omitted in the returned array. The returned elements’ keys will be calculated from the original elements’ keys and their level of nesting and position. This ensures that flattening the array does not introduce changes in behavior.\nUsage \nTransforming children \n\nTo transform the children JSX that your component receives as the children prop, call Children.map:\n\nimport { Children } from 'react';\n\n\n\nfunction RowList({ children }) {\n\n  return (\n\n    <div className=\"RowList\">\n\n      {Children.map(children, child =>\n\n        <div className=\"Row\">\n\n          {child}\n\n        </div>\n\n      )}\n\n    </div>\n\n  );\n\n}\n\nIn the example above, the RowList wraps every child it receives into a <div className=\"Row\"> container. For example, let’s say the parent component passes three <p> tags as the children prop to RowList:\n\n<RowList>\n\n  <p>This is the first item.</p>\n\n  <p>This is the second item.</p>\n\n  <p>This is the third item.</p>\n\n</RowList>\n\nThen, with the RowList implementation above, the final rendered result will look like this:\n\n<div className=\"RowList\">\n\n  <div className=\"Row\">\n\n    <p>This is the first item.</p>\n\n  </div>\n\n  <div className=\"Row\">\n\n    <p>This is the second item.</p>\n\n  </div>\n\n  <div className=\"Row\">\n\n    <p>This is the third item.</p>\n\n  </div>\n\n</div>\n\nChildren.map is similar to to transforming arrays with map(). The difference is that the children data structure is considered opaque. This means that even if it’s sometimes an array, you should not assume it’s an array or any other particular data type. This is why you should use Children.map if you need to transform it.\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function RowList({ children }) {\n  return (\n    <div className=\"RowList\">\n      {Children.map(children, child =>\n        <div className=\"Row\">\n          {child}\n        </div>\n      )}\n    </div>\n  );\n}\n\n\nDEEP DIVE\nWhy is the children prop not always an array? \nShow Details\nPitfall\n\nThe children data structure does not include rendered output of the components you pass as JSX. In the example below, the children received by the RowList only contains two items rather than three:\n\n<p>This is the first item.</p>\n<MoreRows />\n\nThis is why only two row wrappers are generated in this example:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport RowList from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList>\n      <p>This is the first item.</p>\n      <MoreRows />\n    </RowList>\n  );\n}\n\nfunction MoreRows() {\n  return (\n    <>\n      <p>This is the second item.</p>\n      <p>This is the third item.</p>\n    </>\n  );\n}\n\n\nShow more\n\nThere is no way to get the rendered output of an inner component like <MoreRows /> when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nRunning some code for each child \n\nCall Children.forEach to iterate over each child in the children data structure. It does not return any value and is similar to the array forEach method. You can use it to run custom logic like constructing your own array.\n\nApp.js\nSeparatorList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function SeparatorList({ children }) {\n  const result = [];\n  Children.forEach(children, (child, index) => {\n    result.push(child);\n    result.push(<hr key={index} />);\n  });\n  result.pop(); // Remove the last separator\n  return result;\n}\n\n\nPitfall\n\nAs mentioned earlier, there is no way to get the rendered output of an inner component when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nCounting children \n\nCall Children.count(children) to calculate the number of children.\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function RowList({ children }) {\n  return (\n    <div className=\"RowList\">\n      <h1 className=\"RowListHeader\">\n        Total rows: {Children.count(children)}\n      </h1>\n      {Children.map(children, child =>\n        <div className=\"Row\">\n          {child}\n        </div>\n      )}\n    </div>\n  );\n}\n\n\nShow more\nPitfall\n\nAs mentioned earlier, there is no way to get the rendered output of an inner component when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nConverting children to an array \n\nCall Children.toArray(children) to turn the children data structure into a regular JavaScript array. This lets you manipulate the array with built-in array methods like filter, sort, or reverse.\n\nApp.js\nReversedList.js\nReload\nClear\nFork\nimport { Children } from 'react';\n\nexport default function ReversedList({ children }) {\n  const result = Children.toArray(children);\n  result.reverse();\n  return result;\n}\n\n\nPitfall\n\nAs mentioned earlier, there is no way to get the rendered output of an inner component when manipulating children. This is why it’s usually better to use one of the alternative solutions.\n\nAlternatives \nNote\n\nThis section describes alternatives to the Children API (with capital C) that’s imported like this:\n\nimport { Children } from 'react';\n\nDon’t confuse it with using the children prop (lowercase c), which is good and encouraged.\n\nExposing multiple components \n\nManipulating children with the Children methods often leads to fragile code. When you pass children to a component in JSX, you don’t usually expect the component to manipulate or transform the individual children.\n\nWhen you can, try to avoid using the Children methods. For example, if you want every child of RowList to be wrapped in <div className=\"Row\">, export a Row component, and manually wrap every row into it like this:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList>\n      <Row>\n        <p>This is the first item.</p>\n      </Row>\n      <Row>\n        <p>This is the second item.</p>\n      </Row>\n      <Row>\n        <p>This is the third item.</p>\n      </Row>\n    </RowList>\n  );\n}\n\n\nShow more\n\nUnlike using Children.map, this approach does not wrap every child automatically. However, this approach has a significant benefit compared to the earlier example with Children.map because it works even if you keep extracting more components. For example, it still works if you extract your own MoreRows component:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList>\n      <Row>\n        <p>This is the first item.</p>\n      </Row>\n      <MoreRows />\n    </RowList>\n  );\n}\n\nfunction MoreRows() {\n  return (\n    <>\n      <Row>\n        <p>This is the second item.</p>\n      </Row>\n      <Row>\n        <p>This is the third item.</p>\n      </Row>\n    </>\n  );\n}\n\n\nShow more\n\nThis wouldn’t work with Children.map because it would “see” <MoreRows /> as a single child (and a single row).\n\nAccepting an array of objects as a prop \n\nYou can also explicitly pass an array as a prop. For example, this RowList accepts a rows array as a prop:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList rows={[\n      { id: 'first', content: <p>This is the first item.</p> },\n      { id: 'second', content: <p>This is the second item.</p> },\n      { id: 'third', content: <p>This is the third item.</p> }\n    ]} />\n  );\n}\n\n\n\nSince rows is a regular JavaScript array, the RowList component can use built-in array methods like map on it.\n\nThis pattern is especially useful when you want to be able to pass more information as structured data together with children. In the below example, the TabSwitcher component receives an array of objects as the tabs prop:\n\nApp.js\nTabSwitcher.js\nReload\nClear\nFork\nimport TabSwitcher from './TabSwitcher.js';\n\nexport default function App() {\n  return (\n    <TabSwitcher tabs={[\n      {\n        id: 'first',\n        header: 'First',\n        content: <p>This is the first item.</p>\n      },\n      {\n        id: 'second',\n        header: 'Second',\n        content: <p>This is the second item.</p>\n      },\n      {\n        id: 'third',\n        header: 'Third',\n        content: <p>This is the third item.</p>\n      }\n    ]} />\n  );\n}\n\n\nShow more\n\nUnlike passing the children as JSX, this approach lets you associate some extra data like header with each item. Because you are working with the tabs directly, and it is an array, you do not need the Children methods.\n\nCalling a render prop to customize rendering \n\nInstead of producing JSX for every single item, you can also pass a function that returns JSX, and call that function when necessary. In this example, the App component passes a renderContent function to the TabSwitcher component. The TabSwitcher component calls renderContent only for the selected tab:\n\nApp.js\nTabSwitcher.js\nReload\nClear\nFork\nimport TabSwitcher from './TabSwitcher.js';\n\nexport default function App() {\n  return (\n    <TabSwitcher\n      tabIds={['first', 'second', 'third']}\n      getHeader={tabId => {\n        return tabId[0].toUpperCase() + tabId.slice(1);\n      }}\n      renderContent={tabId => {\n        return <p>This is the {tabId} item.</p>;\n      }}\n    />\n  );\n}\n\n\n\nA prop like renderContent is called a render prop because it is a prop that specifies how to render a piece of the user interface. However, there is nothing special about it: it is a regular prop which happens to be a function.\n\nRender props are functions, so you can pass information to them. For example, this RowList component passes the id and the index of each row to the renderRow render prop, which uses index to highlight even rows:\n\nApp.js\nRowList.js\nReload\nClear\nFork\nimport { RowList, Row } from './RowList.js';\n\nexport default function App() {\n  return (\n    <RowList\n      rowIds={['first', 'second', 'third']}\n      renderRow={(id, index) => {\n        return (\n          <Row isHighlighted={index % 2 === 0}>\n            <p>This is the {id} item.</p>\n          </Row> \n        );\n      }}\n    />\n  );\n}\n\n\nShow more\n\nThis is another example of how parent and child components can cooperate without manipulating the children.\n\nTroubleshooting \nI pass a custom component, but the Children methods don’t show its render result \n\nSuppose you pass two children to RowList like this:\n\n<RowList>\n\n  <p>First item</p>\n\n  <MoreRows />\n\n</RowList>\n\nIf you do Children.count(children) inside RowList, you will get 2. Even if MoreRows renders 10 different items, or if it returns null, Children.count(children) will still be 2. From the RowList’s perspective, it only “sees” the JSX it has received. It does not “see” the internals of the MoreRows component.\n\nThe limitation makes it hard to extract a component. This is why alternatives are preferred to using Children.\n\nPREVIOUS\nLegacy React APIs\nNEXT\ncloneElement"
  },
  {
    "title": "cloneElement – React",
    "url": "https://react.dev/reference/react/cloneElement",
    "html": "API REFERENCE\nLEGACY REACT APIS\ncloneElement\nPitfall\n\nUsing cloneElement is uncommon and can lead to fragile code. See common alternatives.\n\ncloneElement lets you create a new React element using another element as a starting point.\n\nconst clonedElement = cloneElement(element, props, ...children)\nReference\ncloneElement(element, props, ...children)\nUsage\nOverriding props of an element\nAlternatives\nPassing data with a render prop\nPassing data through context\nExtracting logic into a custom Hook\nReference \ncloneElement(element, props, ...children) \n\nCall cloneElement to create a React element based on the element, but with different props and children:\n\nimport { cloneElement } from 'react';\n\n\n\n// ...\n\nconst clonedElement = cloneElement(\n\n  <Row title=\"Cabbage\">\n\n    Hello\n\n  </Row>,\n\n  { isHighlighted: true },\n\n  'Goodbye'\n\n);\n\n\n\nconsole.log(clonedElement); // <Row title=\"Cabbage\" isHighlighted={true}>Goodbye</Row>\n\nSee more examples below.\n\nParameters \n\nelement: The element argument must be a valid React element. For example, it could be a JSX node like <Something />, the result of calling createElement, or the result of another cloneElement call.\n\nprops: The props argument must either be an object or null. If you pass null, the cloned element will retain all of the original element.props. Otherwise, for every prop in the props object, the returned element will “prefer” the value from props over the value from element.props. The rest of the props will be filled from the original element.props. If you pass props.key or props.ref, they will replace the original ones.\n\noptional ...children: Zero or more child nodes. They can be any React nodes, including React elements, strings, numbers, portals, empty nodes (null, undefined, true, and false), and arrays of React nodes. If you don’t pass any ...children arguments, the original element.props.children will be preserved.\n\nReturns \n\ncloneElement returns a React element object with a few properties:\n\ntype: Same as element.type.\nprops: The result of shallowly merging element.props with the overriding props you have passed.\nref: The original element.ref, unless it was overridden by props.ref.\nkey: The original element.key, unless it was overridden by props.key.\n\nUsually, you’ll return the element from your component or make it a child of another element. Although you may read the element’s properties, it’s best to treat every element as opaque after it’s created, and only render it.\n\nCaveats \n\nCloning an element does not modify the original element.\n\nYou should only pass children as multiple arguments to cloneElement if they are all statically known, like cloneElement(element, null, child1, child2, child3). If your children are dynamic, pass the entire array as the third argument: cloneElement(element, null, listItems). This ensures that React will warn you about missing keys for any dynamic lists. For static lists this is not necessary because they never reorder.\n\ncloneElement makes it harder to trace the data flow, so try the alternatives instead.\n\nUsage \nOverriding props of an element \n\nTo override the props of some React element, pass it to cloneElement with the props you want to override:\n\nimport { cloneElement } from 'react';\n\n\n\n// ...\n\nconst clonedElement = cloneElement(\n\n  <Row title=\"Cabbage\" />,\n\n  { isHighlighted: true }\n\n);\n\nHere, the resulting cloned element will be <Row title=\"Cabbage\" isHighlighted={true} />.\n\nLet’s walk through an example to see when it’s useful.\n\nImagine a List component that renders its children as a list of selectable rows with a “Next” button that changes which row is selected. The List component needs to render the selected Row differently, so it clones every <Row> child that it has received, and adds an extra isHighlighted: true or isHighlighted: false prop:\n\nexport default function List({ children }) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n  return (\n\n    <div className=\"List\">\n\n      {Children.map(children, (child, index) =>\n\n        cloneElement(child, {\n\n          isHighlighted: index === selectedIndex \n\n        })\n\n      )}\n\nLet’s say the original JSX received by List looks like this:\n\n<List>\n\n  <Row title=\"Cabbage\" />\n\n  <Row title=\"Garlic\" />\n\n  <Row title=\"Apple\" />\n\n</List>\n\nBy cloning its children, the List can pass extra information to every Row inside. The result looks like this:\n\n<List>\n\n  <Row\n\n    title=\"Cabbage\"\n\n    isHighlighted={true} \n\n  />\n\n  <Row\n\n    title=\"Garlic\"\n\n    isHighlighted={false} \n\n  />\n\n  <Row\n\n    title=\"Apple\"\n\n    isHighlighted={false} \n\n  />\n\n</List>\n\nNotice how pressing “Next” updates the state of the List, and highlights a different row:\n\nApp.js\nList.js\nRow.js\ndata.js\nReload\nClear\nFork\nimport { Children, cloneElement, useState } from 'react';\n\nexport default function List({ children }) {\n  const [selectedIndex, setSelectedIndex] = useState(0);\n  return (\n    <div className=\"List\">\n      {Children.map(children, (child, index) =>\n        cloneElement(child, {\n          isHighlighted: index === selectedIndex \n        })\n      )}\n      <hr />\n      <button onClick={() => {\n        setSelectedIndex(i =>\n          (i + 1) % Children.count(children)\n        );\n      }}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nTo summarize, the List cloned the <Row /> elements it received and added an extra prop to them.\n\nPitfall\n\nCloning children makes it hard to tell how the data flows through your app. Try one of the alternatives.\n\nAlternatives \nPassing data with a render prop \n\nInstead of using cloneElement, consider accepting a render prop like renderItem. Here, List receives renderItem as a prop. List calls renderItem for every item and passes isHighlighted as an argument:\n\nexport default function List({ items, renderItem }) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n  return (\n\n    <div className=\"List\">\n\n      {items.map((item, index) => {\n\n        const isHighlighted = index === selectedIndex;\n\n        return renderItem(item, isHighlighted);\n\n      })}\n\nThe renderItem prop is called a “render prop” because it’s a prop that specifies how to render something. For example, you can pass a renderItem implementation that renders a <Row> with the given isHighlighted value:\n\n<List\n\n  items={products}\n\n  renderItem={(product, isHighlighted) =>\n\n    <Row\n\n      key={product.id}\n\n      title={product.title}\n\n      isHighlighted={isHighlighted}\n\n    />\n\n  }\n\n/>\n\nThe end result is the same as with cloneElement:\n\n<List>\n\n  <Row\n\n    title=\"Cabbage\"\n\n    isHighlighted={true} \n\n  />\n\n  <Row\n\n    title=\"Garlic\"\n\n    isHighlighted={false} \n\n  />\n\n  <Row\n\n    title=\"Apple\"\n\n    isHighlighted={false} \n\n  />\n\n</List>\n\nHowever, you can clearly trace where the isHighlighted value is coming from.\n\nApp.js\nList.js\nRow.js\ndata.js\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function List({ items, renderItem }) {\n  const [selectedIndex, setSelectedIndex] = useState(0);\n  return (\n    <div className=\"List\">\n      {items.map((item, index) => {\n        const isHighlighted = index === selectedIndex;\n        return renderItem(item, isHighlighted);\n      })}\n      <hr />\n      <button onClick={() => {\n        setSelectedIndex(i =>\n          (i + 1) % items.length\n        );\n      }}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nThis pattern is preferred to cloneElement because it is more explicit.\n\nPassing data through context \n\nAnother alternative to cloneElement is to pass data through context.\n\nFor example, you can call createContext to define a HighlightContext:\n\nexport const HighlightContext = createContext(false);\n\nYour List component can wrap every item it renders into a HighlightContext provider:\n\nexport default function List({ items, renderItem }) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n  return (\n\n    <div className=\"List\">\n\n      {items.map((item, index) => {\n\n        const isHighlighted = index === selectedIndex;\n\n        return (\n\n          <HighlightContext key={item.id} value={isHighlighted}>\n\n            {renderItem(item)}\n\n          </HighlightContext>\n\n        );\n\n      })}\n\nWith this approach, Row does not need to receive an isHighlighted prop at all. Instead, it reads the context:\n\nexport default function Row({ title }) {\n\n  const isHighlighted = useContext(HighlightContext);\n\n  // ...\n\nThis allows the calling component to not know or worry about passing isHighlighted to <Row>:\n\n<List\n\n  items={products}\n\n  renderItem={product =>\n\n    <Row title={product.title} />\n\n  }\n\n/>\n\nInstead, List and Row coordinate the highlighting logic through context.\n\nApp.js\nList.js\nRow.js\nHighlightContext.js\ndata.js\nReload\nClear\nFork\nimport { useState } from 'react';\nimport { HighlightContext } from './HighlightContext.js';\n\nexport default function List({ items, renderItem }) {\n  const [selectedIndex, setSelectedIndex] = useState(0);\n  return (\n    <div className=\"List\">\n      {items.map((item, index) => {\n        const isHighlighted = index === selectedIndex;\n        return (\n          <HighlightContext\n            key={item.id}\n            value={isHighlighted}\n          >\n            {renderItem(item)}\n          </HighlightContext>\n        );\n      })}\n      <hr />\n      <button onClick={() => {\n        setSelectedIndex(i =>\n          (i + 1) % items.length\n        );\n      }}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nLearn more about passing data through context.\n\nExtracting logic into a custom Hook \n\nAnother approach you can try is to extract the “non-visual” logic into your own Hook, and use the information returned by your Hook to decide what to render. For example, you could write a useList custom Hook like this:\n\nimport { useState } from 'react';\n\n\n\nexport default function useList(items) {\n\n  const [selectedIndex, setSelectedIndex] = useState(0);\n\n\n\n  function onNext() {\n\n    setSelectedIndex(i =>\n\n      (i + 1) % items.length\n\n    );\n\n  }\n\n\n\n  const selected = items[selectedIndex];\n\n  return [selected, onNext];\n\n}\n\nThen you could use it like this:\n\nexport default function App() {\n\n  const [selected, onNext] = useList(products);\n\n  return (\n\n    <div className=\"List\">\n\n      {products.map(product =>\n\n        <Row\n\n          key={product.id}\n\n          title={product.title}\n\n          isHighlighted={selected === product}\n\n        />\n\n      )}\n\n      <hr />\n\n      <button onClick={onNext}>\n\n        Next\n\n      </button>\n\n    </div>\n\n  );\n\n}\n\nThe data flow is explicit, but the state is inside the useList custom Hook that you can use from any component:\n\nApp.js\nuseList.js\nRow.js\ndata.js\nReload\nClear\nFork\nimport Row from './Row.js';\nimport useList from './useList.js';\nimport { products } from './data.js';\n\nexport default function App() {\n  const [selected, onNext] = useList(products);\n  return (\n    <div className=\"List\">\n      {products.map(product =>\n        <Row\n          key={product.id}\n          title={product.title}\n          isHighlighted={selected === product}\n        />\n      )}\n      <hr />\n      <button onClick={onNext}>\n        Next\n      </button>\n    </div>\n  );\n}\n\n\nShow more\n\nThis approach is particularly useful if you want to reuse this logic between different components.\n\nPREVIOUS\nChildren\nNEXT\nComponent"
  },
  {
    "title": "Component – React",
    "url": "https://react.dev/reference/react/Component",
    "html": "API REFERENCE\nLEGACY REACT APIS\nComponent\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nComponent is the base class for the React components defined as JavaScript classes. Class components are still supported by React, but we don’t recommend using them in new code.\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\nReference\nComponent\ncontext\nprops\nstate\nconstructor(props)\ncomponentDidCatch(error, info)\ncomponentDidMount()\ncomponentDidUpdate(prevProps, prevState, snapshot?)\ncomponentWillMount()\ncomponentWillReceiveProps(nextProps)\ncomponentWillUpdate(nextProps, nextState)\ncomponentWillUnmount()\nforceUpdate(callback?)\ngetSnapshotBeforeUpdate(prevProps, prevState)\nrender()\nsetState(nextState, callback?)\nshouldComponentUpdate(nextProps, nextState, nextContext)\nUNSAFE_componentWillMount()\nUNSAFE_componentWillReceiveProps(nextProps, nextContext)\nUNSAFE_componentWillUpdate(nextProps, nextState)\nstatic contextType\nstatic defaultProps\nstatic getDerivedStateFromError(error)\nstatic getDerivedStateFromProps(props, state)\nUsage\nDefining a class component\nAdding state to a class component\nAdding lifecycle methods to a class component\nCatching rendering errors with an Error Boundary\nAlternatives\nMigrating a simple component from a class to a function\nMigrating a component with state from a class to a function\nMigrating a component with lifecycle methods from a class to a function\nMigrating a component with context from a class to a function\nReference \nComponent \n\nTo define a React component as a class, extend the built-in Component class and define a render method:\n\nimport { Component } from 'react';\n\n\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nOnly the render method is required, other methods are optional.\n\nSee more examples below.\n\ncontext \n\nThe context of a class component is available as this.context. It is only available if you specify which context you want to receive using static contextType.\n\nA class component can only read one context at a time.\n\nclass Button extends Component {\n\n  static contextType = ThemeContext;\n\n\n\n  render() {\n\n    const theme = this.context;\n\n    const className = 'button-' + theme;\n\n    return (\n\n      <button className={className}>\n\n        {this.props.children}\n\n      </button>\n\n    );\n\n  }\n\n}\nNote\n\nReading this.context in class components is equivalent to useContext in function components.\n\nSee how to migrate.\n\nprops \n\nThe props passed to a class component are available as this.props.\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\n\n\n<Greeting name=\"Taylor\" />\nNote\n\nReading this.props in class components is equivalent to declaring props in function components.\n\nSee how to migrate.\n\nstate \n\nThe state of a class component is available as this.state. The state field must be an object. Do not mutate the state directly. If you wish to change the state, call setState with the new state.\n\nclass Counter extends Component {\n\n  state = {\n\n    age: 42,\n\n  };\n\n\n\n  handleAgeChange = () => {\n\n    this.setState({\n\n      age: this.state.age + 1 \n\n    });\n\n  };\n\n\n\n  render() {\n\n    return (\n\n      <>\n\n        <button onClick={this.handleAgeChange}>\n\n        Increment age\n\n        </button>\n\n        <p>You are {this.state.age}.</p>\n\n      </>\n\n    );\n\n  }\n\n}\nNote\n\nDefining state in class components is equivalent to calling useState in function components.\n\nSee how to migrate.\n\nconstructor(props) \n\nThe constructor runs before your class component mounts (gets added to the screen). Typically, a constructor is only used for two purposes in React. It lets you declare state and bind your class methods to the class instance:\n\nclass Counter extends Component {\n\n  constructor(props) {\n\n    super(props);\n\n    this.state = { counter: 0 };\n\n    this.handleClick = this.handleClick.bind(this);\n\n  }\n\n\n\n  handleClick() {\n\n    // ...\n\n  }\n\nIf you use modern JavaScript syntax, constructors are rarely needed. Instead, you can rewrite this code above using the public class field syntax which is supported both by modern browsers and tools like Babel:\n\nclass Counter extends Component {\n\n  state = { counter: 0 };\n\n\n\n  handleClick = () => {\n\n    // ...\n\n  }\n\nA constructor should not contain any side effects or subscriptions.\n\nParameters \nprops: The component’s initial props.\nReturns \n\nconstructor should not return anything.\n\nCaveats \n\nDo not run any side effects or subscriptions in the constructor. Instead, use componentDidMount for that.\n\nInside a constructor, you need to call super(props) before any other statement. If you don’t do that, this.props will be undefined while the constructor runs, which can be confusing and cause bugs.\n\nConstructor is the only place where you can assign this.state directly. In all other methods, you need to use this.setState() instead. Do not call setState in the constructor.\n\nWhen you use server rendering, the constructor will run on the server too, followed by the render method. However, lifecycle methods like componentDidMount or componentWillUnmount will not run on the server.\n\nWhen Strict Mode is on, React will call constructor twice in development and then throw away one of the instances. This helps you notice the accidental side effects that need to be moved out of the constructor.\n\nNote\n\nThere is no exact equivalent for constructor in function components. To declare state in a function component, call useState. To avoid recalculating the initial state, pass a function to useState.\n\ncomponentDidCatch(error, info) \n\nIf you define componentDidCatch, React will call it when some child component (including distant children) throws an error during rendering. This lets you log that error to an error reporting service in production.\n\nTypically, it is used together with static getDerivedStateFromError which lets you update state in response to an error and display an error message to the user. A component with these methods is called an Error Boundary.\n\nSee an example.\n\nParameters \n\nerror: The error that was thrown. In practice, it will usually be an instance of Error but this is not guaranteed because JavaScript allows to throw any value, including strings or even null.\n\ninfo: An object containing additional information about the error. Its componentStack field contains a stack trace with the component that threw, as well as the names and source locations of all its parent components. In production, the component names will be minified. If you set up production error reporting, you can decode the component stack using sourcemaps the same way as you would do for regular JavaScript error stacks.\n\nReturns \n\ncomponentDidCatch should not return anything.\n\nCaveats \n\nIn the past, it was common to call setState inside componentDidCatch in order to update the UI and display the fallback error message. This is deprecated in favor of defining static getDerivedStateFromError.\n\nProduction and development builds of React slightly differ in the way componentDidCatch handles errors. In development, the errors will bubble up to window, which means that any window.onerror or window.addEventListener('error', callback) will intercept the errors that have been caught by componentDidCatch. In production, instead, the errors will not bubble up, which means any ancestor error handler will only receive errors not explicitly caught by componentDidCatch.\n\nNote\n\nThere is no direct equivalent for componentDidCatch in function components yet. If you’d like to avoid creating class components, write a single ErrorBoundary component like above and use it throughout your app. Alternatively, you can use the react-error-boundary package which does that for you.\n\ncomponentDidMount() \n\nIf you define the componentDidMount method, React will call it when your component is added (mounted) to the screen. This is a common place to start data fetching, set up subscriptions, or manipulate the DOM nodes.\n\nIf you implement componentDidMount, you usually need to implement other lifecycle methods to avoid bugs. For example, if componentDidMount reads some state or props, you also have to implement componentDidUpdate to handle their changes, and componentWillUnmount to clean up whatever componentDidMount was doing.\n\nclass ChatRoom extends Component {\n\n  state = {\n\n    serverUrl: 'https://localhost:1234'\n\n  };\n\n\n\n  componentDidMount() {\n\n    this.setupConnection();\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState) {\n\n    if (\n\n      this.props.roomId !== prevProps.roomId ||\n\n      this.state.serverUrl !== prevState.serverUrl\n\n    ) {\n\n      this.destroyConnection();\n\n      this.setupConnection();\n\n    }\n\n  }\n\n\n\n  componentWillUnmount() {\n\n    this.destroyConnection();\n\n  }\n\n\n\n  // ...\n\n}\n\nSee more examples.\n\nParameters \n\ncomponentDidMount does not take any parameters.\n\nReturns \n\ncomponentDidMount should not return anything.\n\nCaveats \n\nWhen Strict Mode is on, in development React will call componentDidMount, then immediately call componentWillUnmount, and then call componentDidMount again. This helps you notice if you forgot to implement componentWillUnmount or if its logic doesn’t fully “mirror” what componentDidMount does.\n\nAlthough you may call setState immediately in componentDidMount, it’s best to avoid that when you can. It will trigger an extra rendering, but it will happen before the browser updates the screen. This guarantees that even though the render will be called twice in this case, the user won’t see the intermediate state. Use this pattern with caution because it often causes performance issues. In most cases, you should be able to assign the initial state in the constructor instead. It can, however, be necessary for cases like modals and tooltips when you need to measure a DOM node before rendering something that depends on its size or position.\n\nNote\n\nFor many use cases, defining componentDidMount, componentDidUpdate, and componentWillUnmount together in class components is equivalent to calling useEffect in function components. In the rare cases where it’s important for the code to run before browser paint, useLayoutEffect is a closer match.\n\nSee how to migrate.\n\ncomponentDidUpdate(prevProps, prevState, snapshot?) \n\nIf you define the componentDidUpdate method, React will call it immediately after your component has been re-rendered with updated props or state.  This method is not called for the initial render.\n\nYou can use it to manipulate the DOM after an update. This is also a common place to do network requests as long as you compare the current props to previous props (e.g. a network request may not be necessary if the props have not changed). Typically, you’d use it together with componentDidMount and componentWillUnmount:\n\nclass ChatRoom extends Component {\n\n  state = {\n\n    serverUrl: 'https://localhost:1234'\n\n  };\n\n\n\n  componentDidMount() {\n\n    this.setupConnection();\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState) {\n\n    if (\n\n      this.props.roomId !== prevProps.roomId ||\n\n      this.state.serverUrl !== prevState.serverUrl\n\n    ) {\n\n      this.destroyConnection();\n\n      this.setupConnection();\n\n    }\n\n  }\n\n\n\n  componentWillUnmount() {\n\n    this.destroyConnection();\n\n  }\n\n\n\n  // ...\n\n}\n\nSee more examples.\n\nParameters \n\nprevProps: Props before the update. Compare prevProps to this.props to determine what changed.\n\nprevState: State before the update. Compare prevState to this.state to determine what changed.\n\nsnapshot: If you implemented getSnapshotBeforeUpdate, snapshot will contain the value you returned from that method. Otherwise, it will be undefined.\n\nReturns \n\ncomponentDidUpdate should not return anything.\n\nCaveats \n\ncomponentDidUpdate will not get called if shouldComponentUpdate is defined and returns false.\n\nThe logic inside componentDidUpdate should usually be wrapped in conditions comparing this.props with prevProps, and this.state with prevState. Otherwise, there’s a risk of creating infinite loops.\n\nAlthough you may call setState immediately in componentDidUpdate, it’s best to avoid that when you can. It will trigger an extra rendering, but it will happen before the browser updates the screen. This guarantees that even though the render will be called twice in this case, the user won’t see the intermediate state. This pattern often causes performance issues, but it may be necessary for rare cases like modals and tooltips when you need to measure a DOM node before rendering something that depends on its size or position.\n\nNote\n\nFor many use cases, defining componentDidMount, componentDidUpdate, and componentWillUnmount together in class components is equivalent to calling useEffect in function components. In the rare cases where it’s important for the code to run before browser paint, useLayoutEffect is a closer match.\n\nSee how to migrate.\n\ncomponentWillMount() \nDeprecated\n\nThis API has been renamed from componentWillMount to UNSAFE_componentWillMount. The old name has been deprecated. In a future major version of React, only the new name will work.\n\nRun the rename-unsafe-lifecycles codemod to automatically update your components.\n\ncomponentWillReceiveProps(nextProps) \nDeprecated\n\nThis API has been renamed from componentWillReceiveProps to UNSAFE_componentWillReceiveProps. The old name has been deprecated. In a future major version of React, only the new name will work.\n\nRun the rename-unsafe-lifecycles codemod to automatically update your components.\n\ncomponentWillUpdate(nextProps, nextState) \nDeprecated\n\nThis API has been renamed from componentWillUpdate to UNSAFE_componentWillUpdate. The old name has been deprecated. In a future major version of React, only the new name will work.\n\nRun the rename-unsafe-lifecycles codemod to automatically update your components.\n\ncomponentWillUnmount() \n\nIf you define the componentWillUnmount method, React will call it before your component is removed (unmounted) from the screen. This is a common place to cancel data fetching or remove subscriptions.\n\nThe logic inside componentWillUnmount should “mirror” the logic inside componentDidMount. For example, if componentDidMount sets up a subscription, componentWillUnmount should clean up that subscription. If the cleanup logic in your componentWillUnmount reads some props or state, you will usually also need to implement componentDidUpdate to clean up resources (such as subscriptions) corresponding to the old props and state.\n\nclass ChatRoom extends Component {\n\n  state = {\n\n    serverUrl: 'https://localhost:1234'\n\n  };\n\n\n\n  componentDidMount() {\n\n    this.setupConnection();\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState) {\n\n    if (\n\n      this.props.roomId !== prevProps.roomId ||\n\n      this.state.serverUrl !== prevState.serverUrl\n\n    ) {\n\n      this.destroyConnection();\n\n      this.setupConnection();\n\n    }\n\n  }\n\n\n\n  componentWillUnmount() {\n\n    this.destroyConnection();\n\n  }\n\n\n\n  // ...\n\n}\n\nSee more examples.\n\nParameters \n\ncomponentWillUnmount does not take any parameters.\n\nReturns \n\ncomponentWillUnmount should not return anything.\n\nCaveats \nWhen Strict Mode is on, in development React will call componentDidMount, then immediately call componentWillUnmount, and then call componentDidMount again. This helps you notice if you forgot to implement componentWillUnmount or if its logic doesn’t fully “mirror” what componentDidMount does.\nNote\n\nFor many use cases, defining componentDidMount, componentDidUpdate, and componentWillUnmount together in class components is equivalent to calling useEffect in function components. In the rare cases where it’s important for the code to run before browser paint, useLayoutEffect is a closer match.\n\nSee how to migrate.\n\nforceUpdate(callback?) \n\nForces a component to re-render.\n\nUsually, this is not necessary. If your component’s render method only reads from this.props, this.state, or this.context, it will re-render automatically when you call setState inside your component or one of its parents. However, if your component’s render method reads directly from an external data source, you have to tell React to update the user interface when that data source changes. That’s what forceUpdate lets you do.\n\nTry to avoid all uses of forceUpdate and only read from this.props and this.state in render.\n\nParameters \noptional callback If specified, React will call the callback you’ve provided after the update is committed.\nReturns \n\nforceUpdate does not return anything.\n\nCaveats \nIf you call forceUpdate, React will re-render without calling shouldComponentUpdate.\nNote\n\nReading an external data source and forcing class components to re-render in response to its changes with forceUpdate has been superseded by useSyncExternalStore in function components.\n\ngetSnapshotBeforeUpdate(prevProps, prevState) \n\nIf you implement getSnapshotBeforeUpdate, React will call it immediately before React updates the DOM. It enables your component to capture some information from the DOM (e.g. scroll position) before it is potentially changed. Any value returned by this lifecycle method will be passed as a parameter to componentDidUpdate.\n\nFor example, you can use it in a UI like a chat thread that needs to preserve its scroll position during updates:\n\nclass ScrollingList extends React.Component {\n\n  constructor(props) {\n\n    super(props);\n\n    this.listRef = React.createRef();\n\n  }\n\n\n\n  getSnapshotBeforeUpdate(prevProps, prevState) {\n\n    // Are we adding new items to the list?\n\n    // Capture the scroll position so we can adjust scroll later.\n\n    if (prevProps.list.length < this.props.list.length) {\n\n      const list = this.listRef.current;\n\n      return list.scrollHeight - list.scrollTop;\n\n    }\n\n    return null;\n\n  }\n\n\n\n  componentDidUpdate(prevProps, prevState, snapshot) {\n\n    // If we have a snapshot value, we've just added new items.\n\n    // Adjust scroll so these new items don't push the old ones out of view.\n\n    // (snapshot here is the value returned from getSnapshotBeforeUpdate)\n\n    if (snapshot !== null) {\n\n      const list = this.listRef.current;\n\n      list.scrollTop = list.scrollHeight - snapshot;\n\n    }\n\n  }\n\n\n\n  render() {\n\n    return (\n\n      <div ref={this.listRef}>{/* ...contents... */}</div>\n\n    );\n\n  }\n\n}\n\nIn the above example, it is important to read the scrollHeight property directly in getSnapshotBeforeUpdate. It is not safe to read it in render, UNSAFE_componentWillReceiveProps, or UNSAFE_componentWillUpdate because there is a potential time gap between these methods getting called and React updating the DOM.\n\nParameters \n\nprevProps: Props before the update. Compare prevProps to this.props to determine what changed.\n\nprevState: State before the update. Compare prevState to this.state to determine what changed.\n\nReturns \n\nYou should return a snapshot value of any type that you’d like, or null. The value you returned will be passed as the third argument to componentDidUpdate.\n\nCaveats \ngetSnapshotBeforeUpdate will not get called if shouldComponentUpdate is defined and returns false.\nNote\n\nAt the moment, there is no equivalent to getSnapshotBeforeUpdate for function components. This use case is very uncommon, but if you have the need for it, for now you’ll have to write a class component.\n\nrender() \n\nThe render method is the only required method in a class component.\n\nThe render method should specify what you want to appear on the screen, for example:\n\nimport { Component } from 'react';\n\n\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nReact may call render at any moment, so you shouldn’t assume that it runs at a particular time. Usually, the render method should return a piece of JSX, but a few other return types (like strings) are supported. To calculate the returned JSX, the render method can read this.props, this.state, and this.context.\n\nYou should write the render method as a pure function, meaning that it should return the same result if props, state, and context are the same. It also shouldn’t contain side effects (like setting up subscriptions) or interact with the browser APIs. Side effects should happen either in event handlers or methods like componentDidMount.\n\nParameters \n\nrender does not take any parameters.\n\nReturns \n\nrender can return any valid React node. This includes React elements such as <div />, strings, numbers, portals, empty nodes (null, undefined, true, and false), and arrays of React nodes.\n\nCaveats \n\nrender should be written as a pure function of props, state, and context. It should not have side effects.\n\nrender will not get called if shouldComponentUpdate is defined and returns false.\n\nWhen Strict Mode is on, React will call render twice in development and then throw away one of the results. This helps you notice the accidental side effects that need to be moved out of the render method.\n\nThere is no one-to-one correspondence between the render call and the subsequent componentDidMount or componentDidUpdate call. Some of the render call results may be discarded by React when it’s beneficial.\n\nsetState(nextState, callback?) \n\nCall setState to update the state of your React component.\n\nclass Form extends Component {\n\n  state = {\n\n    name: 'Taylor',\n\n  };\n\n\n\n  handleNameChange = (e) => {\n\n    const newName = e.target.value;\n\n    this.setState({\n\n      name: newName\n\n    });\n\n  }\n\n\n\n  render() {\n\n    return (\n\n      <>\n\n        <input value={this.state.name} onChange={this.handleNameChange} />\n\n        <p>Hello, {this.state.name}.</p>\n\n      </>\n\n    );\n\n  }\n\n}\n\nsetState enqueues changes to the component state. It tells React that this component and its children need to re-render with the new state. This is the main way you’ll update the user interface in response to interactions.\n\nPitfall\n\nCalling setState does not change the current state in the already executing code:\n\nfunction handleClick() {\n\n  console.log(this.state.name); // \"Taylor\"\n\n  this.setState({\n\n    name: 'Robin'\n\n  });\n\n  console.log(this.state.name); // Still \"Taylor\"!\n\n}\n\nIt only affects what this.state will return starting from the next render.\n\nYou can also pass a function to setState. It lets you update state based on the previous state:\n\n  handleIncreaseAge = () => {\n\n    this.setState(prevState => {\n\n      return {\n\n        age: prevState.age + 1\n\n      };\n\n    });\n\n  }\n\nYou don’t have to do this, but it’s handy if you want to update state multiple times during the same event.\n\nParameters \n\nnextState: Either an object or a function.\n\nIf you pass an object as nextState, it will be shallowly merged into this.state.\nIf you pass a function as nextState, it will be treated as an updater function. It must be pure, should take the pending state and props as arguments, and should return the object to be shallowly merged into this.state. React will put your updater function in a queue and re-render your component. During the next render, React will calculate the next state by applying all of the queued updaters to the previous state.\n\noptional callback: If specified, React will call the callback you’ve provided after the update is committed.\n\nReturns \n\nsetState does not return anything.\n\nCaveats \n\nThink of setState as a request rather than an immediate command to update the component. When multiple components update their state in response to an event, React will batch their updates and re-render them together in a single pass at the end of the event. In the rare case that you need to force a particular state update to be applied synchronously, you may wrap it in flushSync, but this may hurt performance.\n\nsetState does not update this.state immediately. This makes reading this.state right after calling setState a potential pitfall. Instead, use componentDidUpdate or the setState callback argument, either of which are guaranteed to fire after the update has been applied. If you need to set the state based on the previous state, you can pass a function to nextState as described above.\n\nNote\n\nCalling setState in class components is similar to calling a set function in function components.\n\nSee how to migrate.\n\nshouldComponentUpdate(nextProps, nextState, nextContext) \n\nIf you define shouldComponentUpdate, React will call it to determine whether a re-render can be skipped.\n\nIf you are confident you want to write it by hand, you may compare this.props with nextProps and this.state with nextState and return false to tell React the update can be skipped.\n\nclass Rectangle extends Component {\n\n  state = {\n\n    isHovered: false\n\n  };\n\n\n\n  shouldComponentUpdate(nextProps, nextState) {\n\n    if (\n\n      nextProps.position.x === this.props.position.x &&\n\n      nextProps.position.y === this.props.position.y &&\n\n      nextProps.size.width === this.props.size.width &&\n\n      nextProps.size.height === this.props.size.height &&\n\n      nextState.isHovered === this.state.isHovered\n\n    ) {\n\n      // Nothing has changed, so a re-render is unnecessary\n\n      return false;\n\n    }\n\n    return true;\n\n  }\n\n\n\n  // ...\n\n}\n\nReact calls shouldComponentUpdate before rendering when new props or state are being received. Defaults to true. This method is not called for the initial render or when forceUpdate is used.\n\nParameters \nnextProps: The next props that the component is about to render with. Compare nextProps to this.props to determine what changed.\nnextState: The next state that the component is about to render with. Compare nextState to this.state to determine what changed.\nnextContext: The next context that the component is about to render with. Compare nextContext to this.context to determine what changed. Only available if you specify static contextType.\nReturns \n\nReturn true if you want the component to re-render. That’s the default behavior.\n\nReturn false to tell React that re-rendering can be skipped.\n\nCaveats \n\nThis method only exists as a performance optimization. If your component breaks without it, fix that first.\n\nConsider using PureComponent instead of writing shouldComponentUpdate by hand. PureComponent shallowly compares props and state, and reduces the chance that you’ll skip a necessary update.\n\nWe do not recommend doing deep equality checks or using JSON.stringify in shouldComponentUpdate. It makes performance unpredictable and dependent on the data structure of every prop and state. In the best case, you risk introducing multi-second stalls to your application, and in the worst case you risk crashing it.\n\nReturning false does not prevent child components from re-rendering when their state changes.\n\nReturning false does not guarantee that the component will not re-render. React will use the return value as a hint but it may still choose to re-render your component if it makes sense to do for other reasons.\n\nNote\n\nOptimizing class components with shouldComponentUpdate is similar to optimizing function components with memo. Function components also offer more granular optimization with useMemo.\n\nUNSAFE_componentWillMount() \n\nIf you define UNSAFE_componentWillMount, React will call it immediately after the constructor. It only exists for historical reasons and should not be used in any new code. Instead, use one of the alternatives:\n\nTo initialize state, declare state as a class field or set this.state inside the constructor.\nIf you need to run a side effect or set up a subscription, move that logic to componentDidMount instead.\n\nSee examples of migrating away from unsafe lifecycles.\n\nParameters \n\nUNSAFE_componentWillMount does not take any parameters.\n\nReturns \n\nUNSAFE_componentWillMount should not return anything.\n\nCaveats \n\nUNSAFE_componentWillMount will not get called if the component implements static getDerivedStateFromProps or getSnapshotBeforeUpdate.\n\nDespite its naming, UNSAFE_componentWillMount does not guarantee that the component will get mounted if your app uses modern React features like Suspense. If a render attempt is suspended (for example, because the code for some child component has not loaded yet), React will throw the in-progress tree away and attempt to construct the component from scratch during the next attempt. This is why this method is “unsafe”. Code that relies on mounting (like adding a subscription) should go into componentDidMount.\n\nUNSAFE_componentWillMount is the only lifecycle method that runs during server rendering. For all practical purposes, it is identical to constructor, so you should use the constructor for this type of logic instead.\n\nNote\n\nCalling setState inside UNSAFE_componentWillMount in a class component to initialize state is equivalent to passing that state as the initial state to useState in a function component.\n\nUNSAFE_componentWillReceiveProps(nextProps, nextContext) \n\nIf you define UNSAFE_componentWillReceiveProps, React will call it when the component receives new props. It only exists for historical reasons and should not be used in any new code. Instead, use one of the alternatives:\n\nIf you need to run a side effect (for example, fetch data, run an animation, or reinitialize a subscription) in response to prop changes, move that logic to componentDidUpdate instead.\nIf you need to avoid re-computing some data only when a prop changes, use a memoization helper instead.\nIf you need to “reset” some state when a prop changes, consider either making a component fully controlled or fully uncontrolled with a key instead.\nIf you need to “adjust” some state when a prop changes, check whether you can compute all the necessary information from props alone during rendering. If you can’t, use static getDerivedStateFromProps instead.\n\nSee examples of migrating away from unsafe lifecycles.\n\nParameters \nnextProps: The next props that the component is about to receive from its parent component. Compare nextProps to this.props to determine what changed.\nnextContext: The next context that the component is about to receive from the closest provider. Compare nextContext to this.context to determine what changed. Only available if you specify static contextType.\nReturns \n\nUNSAFE_componentWillReceiveProps should not return anything.\n\nCaveats \n\nUNSAFE_componentWillReceiveProps will not get called if the component implements static getDerivedStateFromProps or getSnapshotBeforeUpdate.\n\nDespite its naming, UNSAFE_componentWillReceiveProps does not guarantee that the component will receive those props if your app uses modern React features like Suspense. If a render attempt is suspended (for example, because the code for some child component has not loaded yet), React will throw the in-progress tree away and attempt to construct the component from scratch during the next attempt. By the time of the next render attempt, the props might be different. This is why this method is “unsafe”. Code that should run only for committed updates (like resetting a subscription) should go into componentDidUpdate.\n\nUNSAFE_componentWillReceiveProps does not mean that the component has received different props than the last time. You need to compare nextProps and this.props yourself to check if something changed.\n\nReact doesn’t call UNSAFE_componentWillReceiveProps with initial props during mounting. It only calls this method if some of component’s props are going to be updated. For example, calling setState doesn’t generally trigger UNSAFE_componentWillReceiveProps inside the same component.\n\nNote\n\nCalling setState inside UNSAFE_componentWillReceiveProps in a class component to “adjust” state is equivalent to calling the set function from useState during rendering in a function component.\n\nUNSAFE_componentWillUpdate(nextProps, nextState) \n\nIf you define UNSAFE_componentWillUpdate, React will call it before rendering with the new props or state. It only exists for historical reasons and should not be used in any new code. Instead, use one of the alternatives:\n\nIf you need to run a side effect (for example, fetch data, run an animation, or reinitialize a subscription) in response to prop or state changes, move that logic to componentDidUpdate instead.\nIf you need to read some information from the DOM (for example, to save the current scroll position) so that you can use it in componentDidUpdate later, read it inside getSnapshotBeforeUpdate instead.\n\nSee examples of migrating away from unsafe lifecycles.\n\nParameters \nnextProps: The next props that the component is about to render with. Compare nextProps to this.props to determine what changed.\nnextState: The next state that the component is about to render with. Compare nextState to this.state to determine what changed.\nReturns \n\nUNSAFE_componentWillUpdate should not return anything.\n\nCaveats \n\nUNSAFE_componentWillUpdate will not get called if shouldComponentUpdate is defined and returns false.\n\nUNSAFE_componentWillUpdate will not get called if the component implements static getDerivedStateFromProps or getSnapshotBeforeUpdate.\n\nIt’s not supported to call setState (or any method that leads to setState being called, like dispatching a Redux action) during componentWillUpdate.\n\nDespite its naming, UNSAFE_componentWillUpdate does not guarantee that the component will update if your app uses modern React features like Suspense. If a render attempt is suspended (for example, because the code for some child component has not loaded yet), React will throw the in-progress tree away and attempt to construct the component from scratch during the next attempt. By the time of the next render attempt, the props and state might be different. This is why this method is “unsafe”. Code that should run only for committed updates (like resetting a subscription) should go into componentDidUpdate.\n\nUNSAFE_componentWillUpdate does not mean that the component has received different props or state than the last time. You need to compare nextProps with this.props and nextState with this.state yourself to check if something changed.\n\nReact doesn’t call UNSAFE_componentWillUpdate with initial props and state during mounting.\n\nNote\n\nThere is no direct equivalent to UNSAFE_componentWillUpdate in function components.\n\nstatic contextType \n\nIf you want to read this.context from your class component, you must specify which context it needs to read. The context you specify as the static contextType must be a value previously created by createContext.\n\nclass Button extends Component {\n\n  static contextType = ThemeContext;\n\n\n\n  render() {\n\n    const theme = this.context;\n\n    const className = 'button-' + theme;\n\n    return (\n\n      <button className={className}>\n\n        {this.props.children}\n\n      </button>\n\n    );\n\n  }\n\n}\nNote\n\nReading this.context in class components is equivalent to useContext in function components.\n\nSee how to migrate.\n\nstatic defaultProps \n\nYou can define static defaultProps to set the default props for the class. They will be used for undefined and missing props, but not for null props.\n\nFor example, here is how you define that the color prop should default to 'blue':\n\nclass Button extends Component {\n\n  static defaultProps = {\n\n    color: 'blue'\n\n  };\n\n\n\n  render() {\n\n    return <button className={this.props.color}>click me</button>;\n\n  }\n\n}\n\nIf the color prop is not provided or is undefined, it will be set by default to 'blue':\n\n<>\n\n  {/* this.props.color is \"blue\" */}\n\n  <Button />\n\n\n\n  {/* this.props.color is \"blue\" */}\n\n  <Button color={undefined} />\n\n\n\n  {/* this.props.color is null */}\n\n  <Button color={null} />\n\n\n\n  {/* this.props.color is \"red\" */}\n\n  <Button color=\"red\" />\n\n</>\nNote\n\nDefining defaultProps in class components is similar to using default values in function components.\n\nstatic getDerivedStateFromError(error) \n\nIf you define static getDerivedStateFromError, React will call it when a child component (including distant children) throws an error during rendering. This lets you display an error message instead of clearing the UI.\n\nTypically, it is used together with componentDidCatch which lets you send the error report to some analytics service. A component with these methods is called an Error Boundary.\n\nSee an example.\n\nParameters \nerror: The error that was thrown. In practice, it will usually be an instance of Error but this is not guaranteed because JavaScript allows to throw any value, including strings or even null.\nReturns \n\nstatic getDerivedStateFromError should return the state telling the component to display the error message.\n\nCaveats \nstatic getDerivedStateFromError should be a pure function. If you want to perform a side effect (for example, to call an analytics service), you need to also implement componentDidCatch.\nNote\n\nThere is no direct equivalent for static getDerivedStateFromError in function components yet. If you’d like to avoid creating class components, write a single ErrorBoundary component like above and use it throughout your app. Alternatively, use the react-error-boundary package which does that.\n\nstatic getDerivedStateFromProps(props, state) \n\nIf you define static getDerivedStateFromProps, React will call it right before calling render, both on the initial mount and on subsequent updates. It should return an object to update the state, or null to update nothing.\n\nThis method exists for rare use cases where the state depends on changes in props over time. For example, this Form component resets the email state when the userID prop changes:\n\nclass Form extends Component {\n\n  state = {\n\n    email: this.props.defaultEmail,\n\n    prevUserID: this.props.userID\n\n  };\n\n\n\n  static getDerivedStateFromProps(props, state) {\n\n    // Any time the current user changes,\n\n    // Reset any parts of state that are tied to that user.\n\n    // In this simple example, that's just the email.\n\n    if (props.userID !== state.prevUserID) {\n\n      return {\n\n        prevUserID: props.userID,\n\n        email: props.defaultEmail\n\n      };\n\n    }\n\n    return null;\n\n  }\n\n\n\n  // ...\n\n}\n\nNote that this pattern requires you to keep a previous value of the prop (like userID) in state (like prevUserID).\n\nPitfall\n\nDeriving state leads to verbose code and makes your components difficult to think about. Make sure you’re familiar with simpler alternatives:\n\nIf you need to perform a side effect (for example, data fetching or an animation) in response to a change in props, use componentDidUpdate method instead.\nIf you want to re-compute some data only when a prop changes, use a memoization helper instead.\nIf you want to “reset” some state when a prop changes, consider either making a component fully controlled or fully uncontrolled with a key instead.\nParameters \nprops: The next props that the component is about to render with.\nstate: The next state that the component is about to render with.\nReturns \n\nstatic getDerivedStateFromProps return an object to update the state, or null to update nothing.\n\nCaveats \n\nThis method is fired on every render, regardless of the cause. This is different from UNSAFE_componentWillReceiveProps, which only fires when the parent causes a re-render and not as a result of a local setState.\n\nThis method doesn’t have access to the component instance. If you’d like, you can reuse some code between static getDerivedStateFromProps and the other class methods by extracting pure functions of the component props and state outside the class definition.\n\nNote\n\nImplementing static getDerivedStateFromProps in a class component is equivalent to calling the set function from useState during rendering in a function component.\n\nUsage \nDefining a class component \n\nTo define a React component as a class, extend the built-in Component class and define a render method:\n\nimport { Component } from 'react';\n\n\n\nclass Greeting extends Component {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nReact will call your render method whenever it needs to figure out what to display on the screen. Usually, you will return some JSX from it. Your render method should be a pure function: it should only calculate the JSX.\n\nSimilarly to function components, a class component can receive information by props from its parent component. However, the syntax for reading props is different. For example, if the parent component renders <Greeting name=\"Taylor\" />, then you can read the name prop from this.props, like this.props.name:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nclass Greeting extends Component {\n  render() {\n    return <h1>Hello, {this.props.name}!</h1>;\n  }\n}\n\nexport default function App() {\n  return (\n    <>\n      <Greeting name=\"Sara\" />\n      <Greeting name=\"Cahal\" />\n      <Greeting name=\"Edite\" />\n    </>\n  );\n}\n\n\nShow more\n\nNote that Hooks (functions starting with use, like useState) are not supported inside class components.\n\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nAdding state to a class component \n\nTo add state to a class, assign an object to a property called state. To update state, call this.setState.\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nexport default class Counter extends Component {\n  state = {\n    name: 'Taylor',\n    age: 42,\n  };\n\n  handleNameChange = (e) => {\n    this.setState({\n      name: e.target.value\n    });\n  }\n\n  handleAgeChange = () => {\n    this.setState({\n      age: this.state.age + 1 \n    });\n  };\n\n  render() {\n    return (\n      <>\n        <input\n          value={this.state.name}\n          onChange={this.handleNameChange}\n        />\n        <button onClick={this.handleAgeChange}>\n          Increment age\n        </button>\n        <p>Hello, {this.state.name}. You are {this.state.age}.</p>\n      </>\n    );\n  }\n}\n\n\nShow more\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nAdding lifecycle methods to a class component \n\nThere are a few special methods you can define on your class.\n\nIf you define the componentDidMount method, React will call it when your component is added (mounted) to the screen. React will call componentDidUpdate after your component re-renders due to changed props or state. React will call componentWillUnmount after your component has been removed (unmounted) from the screen.\n\nIf you implement componentDidMount, you usually need to implement all three lifecycles to avoid bugs. For example, if componentDidMount reads some state or props, you also have to implement componentDidUpdate to handle their changes, and componentWillUnmount to clean up whatever componentDidMount was doing.\n\nFor example, this ChatRoom component keeps a chat connection synchronized with props and state:\n\nApp.js\nChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { Component } from 'react';\nimport { createConnection } from './chat.js';\n\nexport default class ChatRoom extends Component {\n  state = {\n    serverUrl: 'https://localhost:1234'\n  };\n\n  componentDidMount() {\n    this.setupConnection();\n  }\n\n  componentDidUpdate(prevProps, prevState) {\n    if (\n      this.props.roomId !== prevProps.roomId ||\n      this.state.serverUrl !== prevState.serverUrl\n    ) {\n      this.destroyConnection();\n      this.setupConnection();\n    }\n  }\n\n  componentWillUnmount() {\n    this.destroyConnection();\n  }\n\n  setupConnection() {\n    this.connection = createConnection(\n      this.state.serverUrl,\n      this.props.roomId\n    );\n    this.connection.connect();    \n  }\n\n  destroyConnection() {\n    this.connection.disconnect();\n    this.connection = null;\n  }\n\n  render() {\n    return (\n      <>\n        <label>\n          Server URL:{' '}\n          <input\n            value={this.state.serverUrl}\n            onChange={e => {\n              this.setState({\n                serverUrl: e.target.value\n              });\n            }}\n          />\n        </label>\n        <h1>Welcome to the {this.props.roomId} room!</h1>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nNote that in development when Strict Mode is on, React will call componentDidMount, immediately call componentWillUnmount, and then call componentDidMount again. This helps you notice if you forgot to implement componentWillUnmount or if its logic doesn’t fully “mirror” what componentDidMount does.\n\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nCatching rendering errors with an Error Boundary \n\nBy default, if your application throws an error during rendering, React will remove its UI from the screen. To prevent this, you can wrap a part of your UI into an Error Boundary. An Error Boundary is a special component that lets you display some fallback UI instead of the part that crashed—for example, an error message.\n\nTo implement an Error Boundary component, you need to provide static getDerivedStateFromError which lets you update state in response to an error and display an error message to the user. You can also optionally implement componentDidCatch to add some extra logic, for example, to log the error to an analytics service.\n\nWith captureOwnerStack you can include the Owner Stack during development.\n\nimport * as React from 'react';\n\n\n\nclass ErrorBoundary extends React.Component {\n\n  constructor(props) {\n\n    super(props);\n\n    this.state = { hasError: false };\n\n  }\n\n\n\n  static getDerivedStateFromError(error) {\n\n    // Update state so the next render will show the fallback UI.\n\n    return { hasError: true };\n\n  }\n\n\n\n  componentDidCatch(error, info) {\n\n    logErrorToMyService(\n\n      error,\n\n      // Example \"componentStack\":\n\n      //   in ComponentThatThrows (created by App)\n\n      //   in ErrorBoundary (created by App)\n\n      //   in div (created by App)\n\n      //   in App\n\n      info.componentStack,\n\n      // Warning: `captureOwnerStack` is not available in production.\n\n      React.captureOwnerStack(),\n\n    );\n\n  }\n\n\n\n  render() {\n\n    if (this.state.hasError) {\n\n      // You can render any custom fallback UI\n\n      return this.props.fallback;\n\n    }\n\n\n\n    return this.props.children;\n\n  }\n\n}\n\nThen you can wrap a part of your component tree with it:\n\n<ErrorBoundary fallback={<p>Something went wrong</p>}>\n\n  <Profile />\n\n</ErrorBoundary>\n\nIf Profile or its child component throws an error, ErrorBoundary will “catch” that error, display a fallback UI with the error message you’ve provided, and send a production error report to your error reporting service.\n\nYou don’t need to wrap every component into a separate Error Boundary. When you think about the granularity of Error Boundaries, consider where it makes sense to display an error message. For example, in a messaging app, it makes sense to place an Error Boundary around the list of conversations. It also makes sense to place one around every individual message. However, it wouldn’t make sense to place a boundary around every avatar.\n\nNote\n\nThere is currently no way to write an Error Boundary as a function component. However, you don’t have to write the Error Boundary class yourself. For example, you can use react-error-boundary instead.\n\nAlternatives \nMigrating a simple component from a class to a function \n\nTypically, you will define components as functions instead.\n\nFor example, suppose you’re converting this Greeting class component to a function:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nclass Greeting extends Component {\n  render() {\n    return <h1>Hello, {this.props.name}!</h1>;\n  }\n}\n\nexport default function App() {\n  return (\n    <>\n      <Greeting name=\"Sara\" />\n      <Greeting name=\"Cahal\" />\n      <Greeting name=\"Edite\" />\n    </>\n  );\n}\n\n\nShow more\n\nDefine a function called Greeting. This is where you will move the body of your render function.\n\nfunction Greeting() {\n\n  // ... move the code from the render method here ...\n\n}\n\nInstead of this.props.name, define the name prop using the destructuring syntax and read it directly:\n\nfunction Greeting({ name }) {\n\n  return <h1>Hello, {name}!</h1>;\n\n}\n\nHere is a complete example:\n\nApp.js\nDownload\nReload\nClear\nFork\nfunction Greeting({ name }) {\n  return <h1>Hello, {name}!</h1>;\n}\n\nexport default function App() {\n  return (\n    <>\n      <Greeting name=\"Sara\" />\n      <Greeting name=\"Cahal\" />\n      <Greeting name=\"Edite\" />\n    </>\n  );\n}\n\n\nMigrating a component with state from a class to a function \n\nSuppose you’re converting this Counter class component to a function:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component } from 'react';\n\nexport default class Counter extends Component {\n  state = {\n    name: 'Taylor',\n    age: 42,\n  };\n\n  handleNameChange = (e) => {\n    this.setState({\n      name: e.target.value\n    });\n  }\n\n  handleAgeChange = (e) => {\n    this.setState({\n      age: this.state.age + 1 \n    });\n  };\n\n  render() {\n    return (\n      <>\n        <input\n          value={this.state.name}\n          onChange={this.handleNameChange}\n        />\n        <button onClick={this.handleAgeChange}>\n          Increment age\n        </button>\n        <p>Hello, {this.state.name}. You are {this.state.age}.</p>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nStart by declaring a function with the necessary state variables:\n\nimport { useState } from 'react';\n\n\n\nfunction Counter() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n  // ...\n\nNext, convert the event handlers:\n\nfunction Counter() {\n\n  const [name, setName] = useState('Taylor');\n\n  const [age, setAge] = useState(42);\n\n\n\n  function handleNameChange(e) {\n\n    setName(e.target.value);\n\n  }\n\n\n\n  function handleAgeChange() {\n\n    setAge(age + 1);\n\n  }\n\n  // ...\n\nFinally, replace all references starting with this with the variables and functions you defined in your component. For example, replace this.state.age with age, and replace this.handleNameChange with handleNameChange.\n\nHere is a fully converted component:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useState } from 'react';\n\nexport default function Counter() {\n  const [name, setName] = useState('Taylor');\n  const [age, setAge] = useState(42);\n\n  function handleNameChange(e) {\n    setName(e.target.value);\n  }\n\n  function handleAgeChange() {\n    setAge(age + 1);\n  }\n\n  return (\n    <>\n      <input\n        value={name}\n        onChange={handleNameChange}\n      />\n      <button onClick={handleAgeChange}>\n        Increment age\n      </button>\n      <p>Hello, {name}. You are {age}.</p>\n    </>\n  )\n}\n\n\nShow more\nMigrating a component with lifecycle methods from a class to a function \n\nSuppose you’re converting this ChatRoom class component with lifecycle methods to a function:\n\nApp.js\nChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { Component } from 'react';\nimport { createConnection } from './chat.js';\n\nexport default class ChatRoom extends Component {\n  state = {\n    serverUrl: 'https://localhost:1234'\n  };\n\n  componentDidMount() {\n    this.setupConnection();\n  }\n\n  componentDidUpdate(prevProps, prevState) {\n    if (\n      this.props.roomId !== prevProps.roomId ||\n      this.state.serverUrl !== prevState.serverUrl\n    ) {\n      this.destroyConnection();\n      this.setupConnection();\n    }\n  }\n\n  componentWillUnmount() {\n    this.destroyConnection();\n  }\n\n  setupConnection() {\n    this.connection = createConnection(\n      this.state.serverUrl,\n      this.props.roomId\n    );\n    this.connection.connect();    \n  }\n\n  destroyConnection() {\n    this.connection.disconnect();\n    this.connection = null;\n  }\n\n  render() {\n    return (\n      <>\n        <label>\n          Server URL:{' '}\n          <input\n            value={this.state.serverUrl}\n            onChange={e => {\n              this.setState({\n                serverUrl: e.target.value\n              });\n            }}\n          />\n        </label>\n        <h1>Welcome to the {this.props.roomId} room!</h1>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nFirst, verify that your componentWillUnmount does the opposite of componentDidMount. In the above example, that’s true: it disconnects the connection that componentDidMount sets up. If such logic is missing, add it first.\n\nNext, verify that your componentDidUpdate method handles changes to any props and state you’re using in componentDidMount. In the above example, componentDidMount calls setupConnection which reads this.state.serverUrl and this.props.roomId. This is why componentDidUpdate checks whether this.state.serverUrl and this.props.roomId have changed, and resets the connection if they did. If your componentDidUpdate logic is missing or doesn’t handle changes to all relevant props and state, fix that first.\n\nIn the above example, the logic inside the lifecycle methods connects the component to a system outside of React (a chat server). To connect a component to an external system, describe this logic as a single Effect:\n\nimport { useState, useEffect } from 'react';\n\n\n\nfunction ChatRoom({ roomId }) {\n\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n\n\n  useEffect(() => {\n\n    const connection = createConnection(serverUrl, roomId);\n\n    connection.connect();\n\n    return () => {\n\n      connection.disconnect();\n\n    };\n\n  }, [serverUrl, roomId]);\n\n\n\n  // ...\n\n}\n\nThis useEffect call is equivalent to the logic in the lifecycle methods above. If your lifecycle methods do multiple unrelated things, split them into multiple independent Effects. Here is a complete example you can play with:\n\nApp.js\nChatRoom.js\nchat.js\nReload\nClear\nFork\nimport { useState, useEffect } from 'react';\nimport { createConnection } from './chat.js';\n\nexport default function ChatRoom({ roomId }) {\n  const [serverUrl, setServerUrl] = useState('https://localhost:1234');\n\n  useEffect(() => {\n    const connection = createConnection(serverUrl, roomId);\n    connection.connect();\n    return () => {\n      connection.disconnect();\n    };\n  }, [roomId, serverUrl]);\n\n  return (\n    <>\n      <label>\n        Server URL:{' '}\n        <input\n          value={serverUrl}\n          onChange={e => setServerUrl(e.target.value)}\n        />\n      </label>\n      <h1>Welcome to the {roomId} room!</h1>\n    </>\n  );\n}\n\n\nShow more\nNote\n\nIf your component does not synchronize with any external systems, you might not need an Effect.\n\nMigrating a component with context from a class to a function \n\nIn this example, the Panel and Button class components read context from this.context:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, Component } from 'react';\n\nconst ThemeContext = createContext(null);\n\nclass Panel extends Component {\n  static contextType = ThemeContext;\n\n  render() {\n    const theme = this.context;\n    const className = 'panel-' + theme;\n    return (\n      <section className={className}>\n        <h1>{this.props.title}</h1>\n        {this.props.children}\n      </section>\n    );    \n  }\n}\n\nclass Button extends Component {\n  static contextType = ThemeContext;\n\n  render() {\n    const theme = this.context;\n    const className = 'button-' + theme;\n    return (\n      <button className={className}>\n        {this.props.children}\n      </button>\n    );\n  }\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\n\nShow more\n\nWhen you convert them to function components, replace this.context with useContext calls:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createContext, useContext } from 'react';\n\nconst ThemeContext = createContext(null);\n\nfunction Panel({ title, children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'panel-' + theme;\n  return (\n    <section className={className}>\n      <h1>{title}</h1>\n      {children}\n    </section>\n  )\n}\n\nfunction Button({ children }) {\n  const theme = useContext(ThemeContext);\n  const className = 'button-' + theme;\n  return (\n    <button className={className}>\n      {children}\n    </button>\n  );\n}\n\nfunction Form() {\n  return (\n    <Panel title=\"Welcome\">\n      <Button>Sign up</Button>\n      <Button>Log in</Button>\n    </Panel>\n  );\n}\n\nexport default function MyApp() {\n  return (\n    <ThemeContext value=\"dark\">\n      <Form />\n    </ThemeContext>\n  )\n}\n\n\nShow more\nPREVIOUS\ncloneElement\nNEXT\ncreateElement"
  },
  {
    "title": "createElement – React",
    "url": "https://react.dev/reference/react/createElement",
    "html": "API REFERENCE\nLEGACY REACT APIS\ncreateElement\n\ncreateElement lets you create a React element. It serves as an alternative to writing JSX.\n\nconst element = createElement(type, props, ...children)\nReference\ncreateElement(type, props, ...children)\nUsage\nCreating an element without JSX\nReference \ncreateElement(type, props, ...children) \n\nCall createElement to create a React element with the given type, props, and children.\n\nimport { createElement } from 'react';\n\n\n\nfunction Greeting({ name }) {\n\n  return createElement(\n\n    'h1',\n\n    { className: 'greeting' },\n\n    'Hello'\n\n  );\n\n}\n\nSee more examples below.\n\nParameters \n\ntype: The type argument must be a valid React component type. For example, it could be a tag name string (such as 'div' or 'span'), or a React component (a function, a class, or a special component like Fragment).\n\nprops: The props argument must either be an object or null. If you pass null, it will be treated the same as an empty object. React will create an element with props matching the props you have passed. Note that ref and key from your props object are special and will not be available as element.props.ref and element.props.key on the returned element. They will be available as element.ref and element.key.\n\noptional ...children: Zero or more child nodes. They can be any React nodes, including React elements, strings, numbers, portals, empty nodes (null, undefined, true, and false), and arrays of React nodes.\n\nReturns \n\ncreateElement returns a React element object with a few properties:\n\ntype: The type you have passed.\nprops: The props you have passed except for ref and key.\nref: The ref you have passed. If missing, null.\nkey: The key you have passed, coerced to a string. If missing, null.\n\nUsually, you’ll return the element from your component or make it a child of another element. Although you may read the element’s properties, it’s best to treat every element as opaque after it’s created, and only render it.\n\nCaveats \n\nYou must treat React elements and their props as immutable and never change their contents after creation. In development, React will freeze the returned element and its props property shallowly to enforce this.\n\nWhen you use JSX, you must start a tag with a capital letter to render your own custom component. In other words, <Something /> is equivalent to createElement(Something), but <something /> (lowercase) is equivalent to createElement('something') (note it’s a string, so it will be treated as a built-in HTML tag).\n\nYou should only pass children as multiple arguments to createElement if they are all statically known, like createElement('h1', {}, child1, child2, child3). If your children are dynamic, pass the entire array as the third argument: createElement('ul', {}, listItems). This ensures that React will warn you about missing keys for any dynamic lists. For static lists this is not necessary because they never reorder.\n\nUsage \nCreating an element without JSX \n\nIf you don’t like JSX or can’t use it in your project, you can use createElement as an alternative.\n\nTo create an element without JSX, call createElement with some type, props, and children:\n\nimport { createElement } from 'react';\n\n\n\nfunction Greeting({ name }) {\n\n  return createElement(\n\n    'h1',\n\n    { className: 'greeting' },\n\n    'Hello ',\n\n    createElement('i', null, name),\n\n    '. Welcome!'\n\n  );\n\n}\n\nThe children are optional, and you can pass as many as you need (the example above has three children). This code will display a <h1> header with a greeting. For comparison, here is the same example rewritten with JSX:\n\nfunction Greeting({ name }) {\n\n  return (\n\n    <h1 className=\"greeting\">\n\n      Hello <i>{name}</i>. Welcome!\n\n    </h1>\n\n  );\n\n}\n\nTo render your own React component, pass a function like Greeting as the type instead of a string like 'h1':\n\nexport default function App() {\n\n  return createElement(Greeting, { name: 'Taylor' });\n\n}\n\nWith JSX, it would look like this:\n\nexport default function App() {\n\n  return <Greeting name=\"Taylor\" />;\n\n}\n\nHere is a complete example written with createElement:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { createElement } from 'react';\n\nfunction Greeting({ name }) {\n  return createElement(\n    'h1',\n    { className: 'greeting' },\n    'Hello ',\n    createElement('i', null, name),\n    '. Welcome!'\n  );\n}\n\nexport default function App() {\n  return createElement(\n    Greeting,\n    { name: 'Taylor' }\n  );\n}\n\n\nShow more\n\nAnd here is the same example written using JSX:\n\nApp.js\nDownload\nReload\nClear\nFork\nfunction Greeting({ name }) {\n  return (\n    <h1 className=\"greeting\">\n      Hello <i>{name}</i>. Welcome!\n    </h1>\n  );\n}\n\nexport default function App() {\n  return <Greeting name=\"Taylor\" />;\n}\n\n\n\nBoth coding styles are fine, so you can use whichever one you prefer for your project. The main benefit of using JSX compared to createElement is that it’s easy to see which closing tag corresponds to which opening tag.\n\nDEEP DIVE\nWhat is a React element, exactly? \nShow Details\nPREVIOUS\nComponent\nNEXT\ncreateRef"
  },
  {
    "title": "createRef – React",
    "url": "https://react.dev/reference/react/createRef",
    "html": "API REFERENCE\nLEGACY REACT APIS\ncreateRef\nPitfall\n\ncreateRef is mostly used for class components. Function components typically rely on useRef instead.\n\ncreateRef creates a ref object which can contain arbitrary value.\n\nclass MyInput extends Component {\n\n  inputRef = createRef();\n\n  // ...\n\n}\nReference\ncreateRef()\nUsage\nDeclaring a ref in a class component\nAlternatives\nMigrating from a class with createRef to a function with useRef\nReference \ncreateRef() \n\nCall createRef to declare a ref inside a class component.\n\nimport { createRef, Component } from 'react';\n\n\n\nclass MyComponent extends Component {\n\n  intervalRef = createRef();\n\n  inputRef = createRef();\n\n  // ...\n\nSee more examples below.\n\nParameters \n\ncreateRef takes no parameters.\n\nReturns \n\ncreateRef returns an object with a single property:\n\ncurrent: Initially, it’s set to the null. You can later set it to something else. If you pass the ref object to React as a ref attribute to a JSX node, React will set its current property.\nCaveats \ncreateRef always returns a different object. It’s equivalent to writing { current: null } yourself.\nIn a function component, you probably want useRef instead which always returns the same object.\nconst ref = useRef() is equivalent to const [ref, _] = useState(() => createRef(null)).\nUsage \nDeclaring a ref in a class component \n\nTo declare a ref inside a class component, call createRef and assign its result to a class field:\n\nimport { Component, createRef } from 'react';\n\n\n\nclass Form extends Component {\n\n  inputRef = createRef();\n\n\n\n  // ...\n\n}\n\nIf you now pass ref={this.inputRef} to an <input> in your JSX, React will populate this.inputRef.current with the input DOM node. For example, here is how you make a button that focuses the input:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component, createRef } from 'react';\n\nexport default class Form extends Component {\n  inputRef = createRef();\n\n  handleClick = () => {\n    this.inputRef.current.focus();\n  }\n\n  render() {\n    return (\n      <>\n        <input ref={this.inputRef} />\n        <button onClick={this.handleClick}>\n          Focus the input\n        </button>\n      </>\n    );\n  }\n}\n\n\nShow more\nPitfall\n\ncreateRef is mostly used for class components. Function components typically rely on useRef instead.\n\nAlternatives \nMigrating from a class with createRef to a function with useRef \n\nWe recommend using function components instead of class components in new code. If you have some existing class components using createRef, here is how you can convert them. This is the original code:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { Component, createRef } from 'react';\n\nexport default class Form extends Component {\n  inputRef = createRef();\n\n  handleClick = () => {\n    this.inputRef.current.focus();\n  }\n\n  render() {\n    return (\n      <>\n        <input ref={this.inputRef} />\n        <button onClick={this.handleClick}>\n          Focus the input\n        </button>\n      </>\n    );\n  }\n}\n\n\nShow more\n\nWhen you convert this component from a class to a function, replace calls to createRef with calls to useRef:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { useRef } from 'react';\n\nexport default function Form() {\n  const inputRef = useRef(null);\n\n  function handleClick() {\n    inputRef.current.focus();\n  }\n\n  return (\n    <>\n      <input ref={inputRef} />\n      <button onClick={handleClick}>\n        Focus the input\n      </button>\n    </>\n  );\n}\n\n\nShow more\nPREVIOUS\ncreateElement\nNEXT\nforwardRef"
  },
  {
    "title": "forwardRef – React",
    "url": "https://react.dev/reference/react/forwardRef",
    "html": "API REFERENCE\nLEGACY REACT APIS\nforwardRef\nDeprecated\n\nIn React 19, forwardRef is no longer necessary. Pass ref as a prop instead.\n\nforwardRef will be deprecated in a future release. Learn more here.\n\nforwardRef lets your component expose a DOM node to the parent component with a ref.\n\nconst SomeComponent = forwardRef(render)\nReference\nforwardRef(render)\nrender function\nUsage\nExposing a DOM node to the parent component\nForwarding a ref through multiple components\nExposing an imperative handle instead of a DOM node\nTroubleshooting\nMy component is wrapped in forwardRef, but the ref to it is always null\nReference \nforwardRef(render) \n\nCall forwardRef() to let your component receive a ref and forward it to a child component:\n\nimport { forwardRef } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  // ...\n\n});\n\nSee more examples below.\n\nParameters \nrender: The render function for your component. React calls this function with the props and ref that your component received from its parent. The JSX you return will be the output of your component.\nReturns \n\nforwardRef returns a React component that you can render in JSX. Unlike React components defined as plain functions, a component returned by forwardRef is also able to receive a ref prop.\n\nCaveats \nIn Strict Mode, React will call your render function twice in order to help you find accidental impurities. This is development-only behavior and does not affect production. If your render function is pure (as it should be), this should not affect the logic of your component. The result from one of the calls will be ignored.\nrender function \n\nforwardRef accepts a render function as an argument. React calls this function with props and ref:\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  return (\n\n    <label>\n\n      {props.label}\n\n      <input ref={ref} />\n\n    </label>\n\n  );\n\n});\nParameters \n\nprops: The props passed by the parent component.\n\nref:  The ref attribute passed by the parent component. The ref can be an object or a function. If the parent component has not passed a ref, it will be null. You should either pass the ref you receive to another component, or pass it to useImperativeHandle.\n\nReturns \n\nforwardRef returns a React component that you can render in JSX. Unlike React components defined as plain functions, the component returned by forwardRef is able to take a ref prop.\n\nUsage \nExposing a DOM node to the parent component \n\nBy default, each component’s DOM nodes are private. However, sometimes it’s useful to expose a DOM node to the parent—for example, to allow focusing it. To opt in, wrap your component definition into forwardRef():\n\nimport { forwardRef } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const { label, ...otherProps } = props;\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input {...otherProps} />\n\n    </label>\n\n  );\n\n});\n\nYou will receive a ref as the second argument after props. Pass it to the DOM node that you want to expose:\n\nimport { forwardRef } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const { label, ...otherProps } = props;\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input {...otherProps} ref={ref} />\n\n    </label>\n\n  );\n\n});\n\nThis lets the parent Form component access the <input> DOM node exposed by MyInput:\n\nfunction Form() {\n\n  const ref = useRef(null);\n\n\n\n  function handleClick() {\n\n    ref.current.focus();\n\n  }\n\n\n\n  return (\n\n    <form>\n\n      <MyInput label=\"Enter your name:\" ref={ref} />\n\n      <button type=\"button\" onClick={handleClick}>\n\n        Edit\n\n      </button>\n\n    </form>\n\n  );\n\n}\n\nThis Form component passes a ref to MyInput. The MyInput component forwards that ref to the <input> browser tag. As a result, the Form component can access that <input> DOM node and call focus() on it.\n\nKeep in mind that exposing a ref to the DOM node inside your component makes it harder to change your component’s internals later. You will typically expose DOM nodes from reusable low-level components like buttons or text inputs, but you won’t do it for application-level components like an avatar or a comment.\n\nExamples of forwarding a ref\n1. Focusing a text input\n2. Playing and pausing a video\nExample 1 of 2: Focusing a text input \n\nClicking the button will focus the input. The Form component defines a ref and passes it to the MyInput component. The MyInput component forwards that ref to the browser <input>. This lets the Form component focus the <input>.\n\nApp.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport MyInput from './MyInput.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n  }\n\n  return (\n    <form>\n      <MyInput label=\"Enter your name:\" ref={ref} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\nNext Example\nForwarding a ref through multiple components \n\nInstead of forwarding a ref to a DOM node, you can forward it to your own component like MyInput:\n\nconst FormField = forwardRef(function FormField(props, ref) {\n\n  // ...\n\n  return (\n\n    <>\n\n      <MyInput ref={ref} />\n\n      ...\n\n    </>\n\n  );\n\n});\n\nIf that MyInput component forwards a ref to its <input>, a ref to FormField will give you that <input>:\n\nfunction Form() {\n\n  const ref = useRef(null);\n\n\n\n  function handleClick() {\n\n    ref.current.focus();\n\n  }\n\n\n\n  return (\n\n    <form>\n\n      <FormField label=\"Enter your name:\" ref={ref} isRequired={true} />\n\n      <button type=\"button\" onClick={handleClick}>\n\n        Edit\n\n      </button>\n\n    </form>\n\n  );\n\n}\n\nThe Form component defines a ref and passes it to FormField. The FormField component forwards that ref to MyInput, which forwards it to a browser <input> DOM node. This is how Form accesses that DOM node.\n\nApp.js\nFormField.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport FormField from './FormField.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n  }\n\n  return (\n    <form>\n      <FormField label=\"Enter your name:\" ref={ref} isRequired={true} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\nExposing an imperative handle instead of a DOM node \n\nInstead of exposing an entire DOM node, you can expose a custom object, called an imperative handle, with a more constrained set of methods. To do this, you’d need to define a separate ref to hold the DOM node:\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const inputRef = useRef(null);\n\n\n\n  // ...\n\n\n\n  return <input {...props} ref={inputRef} />;\n\n});\n\nPass the ref you received to useImperativeHandle and specify the value you want to expose to the ref:\n\nimport { forwardRef, useRef, useImperativeHandle } from 'react';\n\n\n\nconst MyInput = forwardRef(function MyInput(props, ref) {\n\n  const inputRef = useRef(null);\n\n\n\n  useImperativeHandle(ref, () => {\n\n    return {\n\n      focus() {\n\n        inputRef.current.focus();\n\n      },\n\n      scrollIntoView() {\n\n        inputRef.current.scrollIntoView();\n\n      },\n\n    };\n\n  }, []);\n\n\n\n  return <input {...props} ref={inputRef} />;\n\n});\n\nIf some component gets a ref to MyInput, it will only receive your { focus, scrollIntoView } object instead of the DOM node. This lets you limit the information you expose about your DOM node to the minimum.\n\nApp.js\nMyInput.js\nReload\nClear\nFork\nimport { useRef } from 'react';\nimport MyInput from './MyInput.js';\n\nexport default function Form() {\n  const ref = useRef(null);\n\n  function handleClick() {\n    ref.current.focus();\n    // This won't work because the DOM node isn't exposed:\n    // ref.current.style.opacity = 0.5;\n  }\n\n  return (\n    <form>\n      <MyInput placeholder=\"Enter your name\" ref={ref} />\n      <button type=\"button\" onClick={handleClick}>\n        Edit\n      </button>\n    </form>\n  );\n}\n\n\nShow more\n\nRead more about using imperative handles.\n\nPitfall\n\nDo not overuse refs. You should only use refs for imperative behaviors that you can’t express as props: for example, scrolling to a node, focusing a node, triggering an animation, selecting text, and so on.\n\nIf you can express something as a prop, you should not use a ref. For example, instead of exposing an imperative handle like { open, close } from a Modal component, it is better to take isOpen as a prop like <Modal isOpen={isOpen} />. Effects can help you expose imperative behaviors via props.\n\nTroubleshooting \nMy component is wrapped in forwardRef, but the ref to it is always null \n\nThis usually means that you forgot to actually use the ref that you received.\n\nFor example, this component doesn’t do anything with its ref:\n\nconst MyInput = forwardRef(function MyInput({ label }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input />\n\n    </label>\n\n  );\n\n});\n\nTo fix it, pass the ref down to a DOM node or another component that can accept a ref:\n\nconst MyInput = forwardRef(function MyInput({ label }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      <input ref={ref} />\n\n    </label>\n\n  );\n\n});\n\nThe ref to MyInput could also be null if some of the logic is conditional:\n\nconst MyInput = forwardRef(function MyInput({ label, showInput }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      {showInput && <input ref={ref} />}\n\n    </label>\n\n  );\n\n});\n\nIf showInput is false, then the ref won’t be forwarded to any node, and a ref to MyInput will remain empty. This is particularly easy to miss if the condition is hidden inside another component, like Panel in this example:\n\nconst MyInput = forwardRef(function MyInput({ label, showInput }, ref) {\n\n  return (\n\n    <label>\n\n      {label}\n\n      <Panel isExpanded={showInput}>\n\n        <input ref={ref} />\n\n      </Panel>\n\n    </label>\n\n  );\n\n});\nPREVIOUS\ncreateRef\nNEXT\nisValidElement"
  },
  {
    "title": "isValidElement – React",
    "url": "https://react.dev/reference/react/isValidElement",
    "html": "API REFERENCE\nLEGACY REACT APIS\nisValidElement\n\nisValidElement checks whether a value is a React element.\n\nconst isElement = isValidElement(value)\nReference\nisValidElement(value)\nUsage\nChecking if something is a React element\nReference \nisValidElement(value) \n\nCall isValidElement(value) to check whether value is a React element.\n\nimport { isValidElement, createElement } from 'react';\n\n\n\n// ✅ React elements\n\nconsole.log(isValidElement(<p />)); // true\n\nconsole.log(isValidElement(createElement('p'))); // true\n\n\n\n// ❌ Not React elements\n\nconsole.log(isValidElement(25)); // false\n\nconsole.log(isValidElement('Hello')); // false\n\nconsole.log(isValidElement({ age: 42 })); // false\n\nSee more examples below.\n\nParameters \nvalue: The value you want to check. It can be any a value of any type.\nReturns \n\nisValidElement returns true if the value is a React element. Otherwise, it returns false.\n\nCaveats \nOnly JSX tags and objects returned by createElement are considered to be React elements. For example, even though a number like 42 is a valid React node (and can be returned from a component), it is not a valid React element. Arrays and portals created with createPortal are also not considered to be React elements.\nUsage \nChecking if something is a React element \n\nCall isValidElement to check if some value is a React element.\n\nReact elements are:\n\nValues produced by writing a JSX tag\nValues produced by calling createElement\n\nFor React elements, isValidElement returns true:\n\nimport { isValidElement, createElement } from 'react';\n\n\n\n// ✅ JSX tags are React elements\n\nconsole.log(isValidElement(<p />)); // true\n\nconsole.log(isValidElement(<MyComponent />)); // true\n\n\n\n// ✅ Values returned by createElement are React elements\n\nconsole.log(isValidElement(createElement('p'))); // true\n\nconsole.log(isValidElement(createElement(MyComponent))); // true\n\nAny other values, such as strings, numbers, or arbitrary objects and arrays, are not React elements.\n\nFor them, isValidElement returns false:\n\n// ❌ These are *not* React elements\n\nconsole.log(isValidElement(null)); // false\n\nconsole.log(isValidElement(25)); // false\n\nconsole.log(isValidElement('Hello')); // false\n\nconsole.log(isValidElement({ age: 42 })); // false\n\nconsole.log(isValidElement([<div />, <div />])); // false\n\nconsole.log(isValidElement(MyComponent)); // false\n\nIt is very uncommon to need isValidElement. It’s mostly useful if you’re calling another API that only accepts elements (like cloneElement does) and you want to avoid an error when your argument is not a React element.\n\nUnless you have some very specific reason to add an isValidElement check, you probably don’t need it.\n\nDEEP DIVE\nReact elements vs React nodes \nShow Details\nPREVIOUS\nforwardRef\nNEXT\nPureComponent"
  },
  {
    "title": "PureComponent – React",
    "url": "https://react.dev/reference/react/PureComponent",
    "html": "API REFERENCE\nLEGACY REACT APIS\nPureComponent\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nPureComponent is similar to Component but it skips re-renders for same props and state. Class components are still supported by React, but we don’t recommend using them in new code.\n\nclass Greeting extends PureComponent {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\nReference\nPureComponent\nUsage\nSkipping unnecessary re-renders for class components\nAlternatives\nMigrating from a PureComponent class component to a function\nReference \nPureComponent \n\nTo skip re-rendering a class component for same props and state, extend PureComponent instead of Component:\n\nimport { PureComponent } from 'react';\n\n\n\nclass Greeting extends PureComponent {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nPureComponent is a subclass of Component and supports all the Component APIs. Extending PureComponent is equivalent to defining a custom shouldComponentUpdate method that shallowly compares props and state.\n\nSee more examples below.\n\nUsage \nSkipping unnecessary re-renders for class components \n\nReact normally re-renders a component whenever its parent re-renders. As an optimization, you can create a component that React will not re-render when its parent re-renders so long as its new props and state are the same as the old props and state. Class components can opt into this behavior by extending PureComponent:\n\nclass Greeting extends PureComponent {\n\n  render() {\n\n    return <h1>Hello, {this.props.name}!</h1>;\n\n  }\n\n}\n\nA React component should always have pure rendering logic. This means that it must return the same output if its props, state, and context haven’t changed. By using PureComponent, you are telling React that your component complies with this requirement, so React doesn’t need to re-render as long as its props and state haven’t changed. However, your component will still re-render if a context that it’s using changes.\n\nIn this example, notice that the Greeting component re-renders whenever name is changed (because that’s one of its props), but not when address is changed (because it’s not passed to Greeting as a prop):\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { PureComponent, useState } from 'react';\n\nclass Greeting extends PureComponent {\n  render() {\n    console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n    return <h3>Hello{this.props.name && ', '}{this.props.name}!</h3>;\n  }\n}\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\n\nShow more\nPitfall\n\nWe recommend defining components as functions instead of classes. See how to migrate.\n\nAlternatives \nMigrating from a PureComponent class component to a function \n\nWe recommend using function components instead of class components in new code. If you have some existing class components using PureComponent, here is how you can convert them. This is the original code:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { PureComponent, useState } from 'react';\n\nclass Greeting extends PureComponent {\n  render() {\n    console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n    return <h3>Hello{this.props.name && ', '}{this.props.name}!</h3>;\n  }\n}\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\n\nShow more\n\nWhen you convert this component from a class to a function, wrap it in memo:\n\nApp.js\nDownload\nReload\nClear\nFork\nimport { memo, useState } from 'react';\n\nconst Greeting = memo(function Greeting({ name }) {\n  console.log(\"Greeting was rendered at\", new Date().toLocaleTimeString());\n  return <h3>Hello{name && ', '}{name}!</h3>;\n});\n\nexport default function MyApp() {\n  const [name, setName] = useState('');\n  const [address, setAddress] = useState('');\n  return (\n    <>\n      <label>\n        Name{': '}\n        <input value={name} onChange={e => setName(e.target.value)} />\n      </label>\n      <label>\n        Address{': '}\n        <input value={address} onChange={e => setAddress(e.target.value)} />\n      </label>\n      <Greeting name={name} />\n    </>\n  );\n}\n\n\nShow more\nNote\n\nUnlike PureComponent, memo does not compare the new and the old state. In function components, calling the set function with the same state already prevents re-renders by default, even without memo.\n\nPREVIOUS\nisValidElement"
  }
]
</file>

<file path="output/trpc/docs.json">
[
  {
    "title": "tRPC Client | tRPC",
    "url": "https://trpc.io/docs/client/vanilla",
    "html": "Client Usage\nVanilla Client\nVersion: 11.x\ntRPC Client\n\nThe \"Vanilla\" tRPC client can be used to call your API procedures as if they are local functions, enabling a seamless development experience.\n\nimport type { AppRouter } from '../path/to/server/trpc';\nconst bilbo = await client.getUser.query('id_bilbo');\n// => { id: 'id_bilbo', name: 'Bilbo' };\nCopy\nWhen to use the Vanilla Client?​\n\nYou are likely to use this client in two scenarios:\n\nWith a frontend framework for which we don't have an official integration\nWith a separate backend service written in TypeScript.\nWhen NOT to use the Vanilla Client?​\nWhile you can use the client to call procedures from a React component, you should usually use our React Query Integration. It offers many additional features such as the ability to manage loading and error state, caching, and invalidation.\nWe recommend you do not use this client when calling procedures of the same API instance, this is because the invocation has to pass through the network layer. For complete recommendations on invoking a procedure in the current API, you can read more here.\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/vanilla#__docusaurus_skipToContent_fallback",
    "html": "Client Usage\nVanilla Client\nVersion: 11.x\ntRPC Client\n\nThe \"Vanilla\" tRPC client can be used to call your API procedures as if they are local functions, enabling a seamless development experience.\n\nimport type { AppRouter } from '../path/to/server/trpc';\nconst bilbo = await client.getUser.query('id_bilbo');\n// => { id: 'id_bilbo', name: 'Bilbo' };\nCopy\nWhen to use the Vanilla Client?​\n\nYou are likely to use this client in two scenarios:\n\nWith a frontend framework for which we don't have an official integration\nWith a separate backend service written in TypeScript.\nWhen NOT to use the Vanilla Client?​\nWhile you can use the client to call procedures from a React component, you should usually use our React Query Integration. It offers many additional features such as the ability to manage loading and error state, caching, and invalidation.\nWe recommend you do not use this client when calling procedures of the same API instance, this is because the invocation has to pass through the network layer. For complete recommendations on invoking a procedure in the current API, you can read more here.\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs",
    "html": "Client Usage\nNext.js Integration\nVersion: 11.x\nNext.js Integration\ntRPC ❤️ Next.js​\n\nNext.js makes it easy to build a client and server together in one codebase. tRPC makes it easy to share types between them, ensuring typesafety for your application's data fetching.\n\nOur Next.js integration is built on top of our React Query Integration with some Next.js specific APIs, to handle both client and server side rendering.\n\nWhen using the Next.js integration, you'll get the following features:\n\nServer-side rendering - You can tell tRPC to render your pages on the server, and then hydrate them on the client. This way, you'll avoid an initial loading state, although time to first byte will be blocked by the server. Read more about Server-side rendering.\nStatic site generation - Prefetch queries on the server and generate static HTML files that are ready to be served. Read more about Static site generation.\nAutomatic Provider Wrapping - @trpc/next provides a higher-order component (HOC) that wraps your app with the necessary providers so you don't have to do it yourself.\nTIP\n\nIf you're using tRPC in a new project, consider using one of the example projects for reference: tRPC Example Projects\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query",
    "html": "📄️ Setup\n\nTanStack React Query setup\n\n📄️ Usage\n\nTanStack React Query usage\n\n📄️ Migrating\n\nMigrating from the classic React Client\n\n📄️ Server Components\n\nThis guide is an overview of how one may use tRPC with a React Server Components (RSC) framework such as Next.js App Router."
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react",
    "html": "Client Usage\nReact Query Integration (Classic)\nVersion: 11.x\nReact Query Integration (Classic)\nTIP\n\nThese are the docs for our 'Classic' React Query integration, which (while still supported) is not the recommended way to start new tRPC projects with TanStack React Query. We recommend using the new TanStack React Query Integration instead.\n\ntRPC offers a first class integration with React. Under the hood this is simply a wrapper around the very popular @tanstack/react-query, so we recommend that you familiarise yourself with React Query, as their docs go in to much greater depth on its usage.\n\nIf you are using Next.js we recommend using our integration with that instead.\n\n❓ Do I have to use an integration?\nThe tRPC React Query Integration​\n\nThis library enables usage directly within React components\n\npages/IndexPage.tsx\nimport { trpc } from '../utils/trpc';\nexport default function IndexPage() {\n  const helloQuery = trpc.hello.useQuery({ name: 'Bob' });\n  const goodbyeMutation = trpc.goodbye.useMutation();\n  return (\n    <div>\n      <p>{helloQuery.data?.greeting}</p>\n      <button onClick={() => goodbyeMutation.mutate()}>Say Goodbye</button>\n    </div>\n  );\n}\nCopy\nDifferences to vanilla React Query​\n\nThe wrapper abstracts some aspects of React Query for you:\n\nQuery Keys - these are generated and managed by tRPC on your behalf, based on the procedure inputs you provide\nIf you need the query key which tRPC calculates, you can use getQueryKey\nType safe by default - the types you provide in your tRPC Backend also drive the types of your React Query client, providing safety throughout your React app\nEdit this page"
  },
  {
    "title": "Set up a tRPC Client | tRPC",
    "url": "https://trpc.io/docs/client/vanilla/setup",
    "html": "Client Usage\nVanilla Client\nSetup\nVersion: 11.x\nSet up a tRPC Client\n1. Install the tRPC Client library​\n\nUse your preferred package manager to install the @trpc/client library, and also install @trpc/server which contains some required types.\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client\n2. Import your App Router​\n\nImport your AppRouter type into the client application. This type holds the shape of your entire API.\n\nutils/trpc.ts\nimport type { AppRouter } from '../server/router';\nCopy\nTIP\n\nBy using import type you ensure that the reference will be stripped at compile-time, meaning you don't inadvertently import server-side code into your client. For more information, see the Typescript docs.\n\n3. Initialize the tRPC client​\n\nCreate a tRPC client with the createTRPCClient method, and add a links array with a terminating link pointing at your API. To learn more about tRPC links, click here.\n\nclient.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from '../path/to/server/trpc';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000/trpc',\n      // You can pass any HTTP headers you wish here\n      async headers() {\n        return {\n          authorization: getAuthCookie(),\n        };\n      },\n    }),\n  ],\n});\nCopy\n4. Use the tRPC Client​\n\nUnder the hood this creates a typed JavaScript Proxy which allows you to interact with your tRPC API in a fully type-safe way:\n\nclient.ts\nconst bilbo = await client.getUser.query('id_bilbo');\n// => { id: 'id_bilbo', name: 'Bilbo' };\nconst frodo = await client.createUser.mutate({ name: 'Frodo' });\n// => { id: 'id_frodo', name: 'Frodo' };\nCopy\n\nYou're all set!\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/vanilla/infer-types",
    "html": "Client Usage\nVanilla Client\nInferring Types\nVersion: 11.x\nInferring Types\n\nIt is often useful to access the types of your API within your clients. For this purpose, you are able to infer the types contained in your AppRouter.\n\n@trpc/server exports the following helper types to assist with inferring these types from the AppRouter exported by your @trpc/server router:\n\ninferRouterInputs<TRouter>\ninferRouterOutputs<TRouter>\nInferring Input & Output Types​\n\nLet's assume we have this example router:\n\nserver.ts\n// @filename: server.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from \"zod\";\n \nconst t = initTRPC.create();\n \nconst appRouter = t.router({\n  post: t.router({\n    list: t.procedure\n      .query(() => {\n        // imaginary db call\n        return [{ id: 1, title: 'tRPC is the best!' }];\n    }),\n    byId: t.procedure\n      .input(z.string())\n      .query((opts) => {\n        // imaginary db call\n        return { id: 1, title: 'tRPC is the best!' };\n    }),\n    create: t.procedure\n      .input(z.object({ title: z.string(), text: z.string(), }))\n      .mutation((opts) => {\n        // imaginary db call\n        return { id: 1, ...opts.input };\n    }),\n  }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\n\nUsing the helpers, we can infer the types of our router. The following example shows how to infer the types of the post.create procedure:\n\nclient.ts\n// @filename: client.ts\nimport type { inferRouterInputs, inferRouterOutputs } from '@trpc/server';\nimport type { AppRouter } from './server';\n \ntype RouterInput = inferRouterInputs<AppRouter>;\ntype RouterOutput = inferRouterOutputs<AppRouter>;\n \ntype PostCreateInput = RouterInput['post']['create'];\n           \ntype PostCreateInput = {\n    title: string;\n    text: string;\n}\ntype PostCreateOutput = RouterOutput['post']['create'];\n            \ntype PostCreateOutput = {\n    title: string;\n    text: string;\n    id: number;\n}\nCopy\nInfer TRPCClientError types​\n\nIt's also useful to infer the error type for your AppRouter\n\nclient.ts\n// @filename: client.ts\nimport { TRPCClientError } from '@trpc/client';\nimport type { AppRouter } from './server';\nimport { trpc } from './trpc';\n \nexport function isTRPCClientError(\n  cause: unknown,\n): cause is TRPCClientError<AppRouter> {\n  return cause instanceof TRPCClientError;\n}\n \nasync function main() {\n  try {\n    await trpc.post.byId.query('1');\n  } catch (cause) {\n    if (isTRPCClientError(cause)) {\n      // `cause` is now typed as your router's `TRPCClientError`\n      console.log('data', cause.data);\n                                 \n(property) TRPCClientError<BuiltRouter<{ ctx: object; meta: object; errorShape: DefaultErrorShape; transformer: false; }, DecorateCreateRouterOptions<{ post: BuiltRouter<{ ctx: object; meta: object; errorShape: DefaultErrorShape; transformer: false; }, DecorateCreateRouterOptions<...>>; }>>>.data: Maybe<DefaultErrorData>\n    } else {\n      // [...]\n    }\n  }\n}\n \nmain();\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/vanilla/aborting-procedure-calls",
    "html": "Client Usage\nVanilla Client\nAborting Procedure Calls\nVersion: 11.x\nAborting Procedure Calls\n\ntRPC adheres to the industry standard when it comes to aborting procedures. All you have to do is pass an AbortSignal to the query or mutation options, and call the AbortController instance's abort method if you need to cancel the request.\n\nutils.ts\n// @filename: server.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from './server.ts';\n \nconst proxy = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000/trpc',\n    }),\n  ],\n});\n \n// 1. Create an AbortController instance - this is a standard javascript API\nconst ac = new AbortController();\n \n// 2. Pass the signal to a query or mutation\nconst query = proxy.userById.query('id_bilbo', { signal: ac.signal });\n \n// 3. Cancel the request if needed\nac.abort();\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links",
    "html": "Client Usage\nLinks\nVersion: 11.x\nLinks Overview\n\nLinks enable you to customize the flow of data between the tRPC Client and Server. A link should do only one thing, which can be either a self-contained modification to a tRPC operation (query, mutation, or subscription) or a side-effect based on the operation (such as logging).\n\nYou can compose links together into an array that you can provide to the tRPC client configuration via the links property, which represents a link chain. This means that the tRPC client will execute the links in the order they are added to the links array when doing a request and will execute them again in reverse when it's handling a response. Here's a visual representation of the link chain:\n\ntRPC Link Diagram. Based on Apollo's.\nNOTE\n\nThe below examples are assuming you use Next.js, but the same as below can be added if you use the vanilla tRPC client\n\nutils/trpc.ts\nimport { httpBatchLink, loggerLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nexport default createTRPCNext<AppRouter>({\n  config() {\n    const url = `http://localhost:3000`;\n    return {\n      links: [\n        loggerLink(),\n        httpBatchLink({\n          url,\n        }),\n      ],\n    };\n  },\n});\nCopy\nCreating a custom link​\n\nA link is a function that follows the TRPCLink type. Each link is composed of three parts:\n\nThe link returns a function that has a parameter with the TRPCClientRuntime type. This argument is passed by tRPC and it is used when creating a terminating link. If you're not creating a terminating link, you can just create a function that has no parameters. In such case, the link should be added to the links array without invoking (links: [..., myLink, httpBatchLink(...)]).\nThe function in step 1 returns another function that receives an object with two properties: op which is the Operation that is being executed by the client, and next which is the function we use to call the next link down the chain.\nThe function in step 2 returns a final function that returns the observable function provided by @trpc/server. The observable accepts a function that receives an observer which helps our link notify the next link up the chain how they should handle the operation result. In this function, we can just return next(op) and leave it as is, or we can subscribe to next, which enables our link to handle the operation result.\nExample​\nutils/customLink.ts\nimport { TRPCLink } from '@trpc/client';\nimport { observable } from '@trpc/server/observable';\nimport type { AppRouter } from '~/server/routers/_app';\nexport const customLink: TRPCLink<AppRouter> = () => {\n  // here we just got initialized in the app - this happens once per app\n  // useful for storing cache for instance\n  return ({ next, op }) => {\n    // this is when passing the result to the next link\n    // each link needs to return an observable which propagates results\n    return observable((observer) => {\n      console.log('performing operation:', op);\n      const unsubscribe = next(op).subscribe({\n        next(value) {\n          console.log('we received value', value);\n          observer.next(value);\n        },\n        error(err) {\n          console.log('we received error', err);\n          observer.error(err);\n        },\n        complete() {\n          observer.complete();\n        },\n      });\n      return unsubscribe;\n    });\n  };\n};\nCopy\nReferences​\n\nIf you need a more real reference for creating your custom link, you can check out some of the built-in links tRPC provides on GitHub.\n\nThe terminating link​\n\nThe terminating link is the last link in a link chain. Instead of calling the next function, the terminating link is responsible for sending your composed tRPC operation to the tRPC server and returning an OperationResultEnvelope.\n\nThe links array that you add to the tRPC client config should have at least one link, and that link should be a terminating link. If links don't have a terminating link at the end of them, the tRPC operation will not be sent to the tRPC server.\n\nhttpBatchLink is the recommended terminating link by tRPC.\n\nhttpLink, wsLink, and localLink are other examples of terminating links.\n\nManaging context​\n\nAs an operation moves along your link chain, it maintains a context that each link can read and modify. This allows links to pass metadata along the chain that other links use in their execution logic.\n\nObtain the current context object and modify it by accessing op.context.\n\nYou can set the context object's initial value for a particular operation by providing the context parameter to the query or useQuery hook (or mutation, subscription, etc.).\n\nFor an example use case, see Disable batching for certain requests.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/headers",
    "html": "Client Usage\nCreate Custom Header\nVersion: 11.x\nCustom header\n\nThe headers option can be customized in the config when using the httpBatchLink or the httpLink.\n\nheaders can be both an object or a function. If it's a function it will get called dynamically for every HTTP request.\n\nutils/trpc.ts\n// Import the router type from your server file\nimport type { AppRouter } from '@/server/routers/app';\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nlet token: string;\nexport function setToken(newToken: string) {\n  /**\n   * You can also save the token to cookies, and initialize from\n   * cookies above.\n   */\n  token = newToken;\n}\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    return {\n      links: [\n        httpBatchLink({\n          url: 'http://localhost:3000/api/trpc',\n          /**\n           * Headers will be called on each request.\n           */\n          headers() {\n            return {\n              Authorization: token,\n            };\n          },\n        }),\n      ],\n    };\n  },\n});\nCopy\nExample with auth login​\npages/auth.tsx\nconst loginMut = trpc.auth.login.useMutation({\n  onSuccess(opts) {\n    token = opts.accessToken;\n  },\n});\nCopy\n\nThe token can be whatever you want it to be. It's entirely up to you whether that's just a client-side variable that you update the value of on success or whether you store the token and pull it from local storage.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/cors",
    "html": "Client Usage\nCORS & Cookies\nVersion: 11.x\nSend cookies cross-origin\n\nIf your API resides on a different origin than your front-end and you wish to send cookies to it, you will need to enable CORS on your server and send cookies with your requests by providing the option {credentials: \"include\"} to fetch.\n\nThe arguments provided to the fetch function used by tRPC can be modified as follow.\n\napp.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'YOUR_SERVER_URL',\n      fetch(url, options) {\n        return fetch(url, {\n          ...options,\n          credentials: 'include',\n        });\n      },\n    }),\n  ],\n});\nCopy\nINFO\n\nYou also need to enable CORS on your server by modifying your adapter, or the HTTP server which fronts your API. The best way to do this varies adapter-by-adapter and based on your hosting infrastructure, and individual adapters generally document this process where applicable.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/starter-projects",
    "html": "Client Usage\nNext.js Integration\nStarter Projects\nVersion: 11.x\nStarter Projects\n\nGet started quickly with one of the sample projects! Copy the snippet from Quick start with create-next-app in the below list to clone the project.\n\nDescription\tURL\tLinks\n\n\nNext.js starter with Prisma, E2E testing, & ESLint.\n\n\n\n\nQuick start with create-next-app\n\tnextjs.trpc.io\t\nCodeSandbox\nSource\n\n\n\nzART-stack example (zero-API, TypeScript, React).\n\n\n\n\nMonorepo setup with React Native, Next.js, & Prisma\n\n\n\n\nQuick start with git clone\n\tn/a\t\nSource\n\n\n\nNext.js TodoMVC-example with SSG & Prisma.\n\n\n\n\nQuick start with create-next-app\n\ttodomvc.trpc.io\t\nCodeSandbox\nSource\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/setup",
    "html": "Client Usage\nNext.js Integration\nSetup\nVersion: 11.x\nSet up with Next.js Pages Router\nCAUTION\n\nThis guide is for Next.js Pages Router. If you are using Next.js App Router with React Server components, check out the RSC docs\n\nRecommended file structure​\n\nWe recommend a file structure like this one, although it is not enforced by tRPC. This is what you'll see in our examples. The rest of this page will take you through the process of adding tRPC in to this structure.\n\n.\n├── prisma  # <-- if prisma is added\n│   └── [..]\n├── src\n│   ├── pages\n│   │   ├── _app.tsx  # <-- add `withTRPC()`-HOC here\n│   │   ├── api\n│   │   │   └── trpc\n│   │   │       └── [trpc].ts  # <-- tRPC HTTP handler\n│   │   └── [..]\n│   ├── server\n│   │   ├── routers\n│   │   │   ├── _app.ts  # <-- main app router\n│   │   │   ├── post.ts  # <-- sub routers\n│   │   │   └── [..]\n│   │   ├── context.ts   # <-- create app context\n│   │   └── trpc.ts      # <-- procedure helpers\n│   └── utils\n│       └── trpc.ts  # <-- your typesafe tRPC hooks\n└── [..]\nCopy\nAdd tRPC to existing Next.js project​\n1. Install deps​\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/react-query @trpc/next @tanstack/react-query@latest zod\n\nThe Next.js integration is actually a combination of our React Query Integration and some Next.js specific integrations.\n\n2. Enable strict mode​\n\nIf you want to use Zod for input validation, make sure you have enabled strict mode in your tsconfig.json:\n\ntsconfig.json\n\"compilerOptions\": {\n+   \"strict\": true\n}\nCopy\n\nIf strict mode is too harsh, you'll at least want to enable strictNullChecks:\n\ntsconfig.json\n\"compilerOptions\": {\n+   \"strictNullChecks\": true\n}\nCopy\n3. Create a tRPC router​\n\nInitialize your tRPC backend in src/server/trpc.ts using the initTRPC function, and create your first router. We're going to make a simple \"hello world\" router and procedure here - but for deeper information on creating your tRPC API you should refer to:\n\nthe Quickstart guide and Backend usage docs for tRPC information\nthe Next.js Adapter docs for mounting tRPC within your Next.js server.\nView sample backend\nNOTE\n\nThe backend above is using the recommended file structure, but you can keep it simple and put everything in an API handler directly if you prefer.\n\n4. Create tRPC hooks​\n\nuse the createTRPCNext function to create a set of strongly-typed hooks from your API's type signature.\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport type { AppRouter } from '../server/routers/_app';\nfunction getBaseUrl() {\n  if (typeof window !== 'undefined')\n    // browser should use relative path\n    return '';\n  if (process.env.VERCEL_URL)\n    // reference for vercel.com\n    return `https://${process.env.VERCEL_URL}`;\n  if (process.env.RENDER_INTERNAL_HOSTNAME)\n    // reference for render.com\n    return `http://${process.env.RENDER_INTERNAL_HOSTNAME}:${process.env.PORT}`;\n  // assume localhost\n  return `http://localhost:${process.env.PORT ?? 3000}`;\n}\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    return {\n      links: [\n        httpBatchLink({\n          /**\n           * If you want to use SSR, you need to use the server's full URL\n           * @see https://trpc.io/docs/v11/ssr\n           **/\n          url: `${getBaseUrl()}/api/trpc`,\n          // You can pass any HTTP headers you wish here\n          async headers() {\n            return {\n              // authorization: getAuthCookie(),\n            };\n          },\n        }),\n      ],\n    };\n  },\n  /**\n   * @see https://trpc.io/docs/v11/ssr\n   **/\n  ssr: false,\n});\nCopy\nNOTE\n\ncreateTRPCNext does not work with the tRPC-v9 interop mode. If you are migrating from v9 using interop, you should continue using the old way of initializing tRPC.\n\n5. Configure _app.tsx​\n\nWrap your root app page in the trpc.withTRPC HOC, similar to this:\n\npages/_app.tsx\nimport type { AppType } from 'next/app';\nimport { trpc } from '../utils/trpc';\nconst MyApp: AppType = ({ Component, pageProps }) => {\n  return <Component {...pageProps} />;\n};\nexport default trpc.withTRPC(MyApp);\nCopy\n6. Make an API request​\n\nYou're all set!\n\nYou can now use the React hooks you have just created to invoke your API. For more detail see the React Query Integration\n\npages/index.tsx\nimport { trpc } from '../utils/trpc';\nexport default function IndexPage() {\n  const hello = trpc.hello.useQuery({ text: 'client' });\n  if (!hello.data) {\n    return <div>Loading...</div>;\n  }\n  return (\n    <div>\n      <p>{hello.data.greeting}</p>\n    </div>\n  );\n}\nCopy\ncreateTRPCNext() options​\nconfig-callback​\n\nThe config-argument is a function that returns an object that configures the tRPC and React Query clients. This function has a ctx input that gives you access to the Next.js req object, among other things. The returned value can contain the following properties:\n\nRequired:\nlinks to customize the flow of data between tRPC Client and the tRPC Server. Read more.\nOptional:\nqueryClientConfig: a configuration object for the React Query QueryClient used internally by the tRPC React hooks: QueryClient docs\nqueryClient: a React Query QueryClient instance\nNote: You can only provide either a queryClient or a queryClientConfig.\ntransformer: a transformer applied to outgoing payloads. Read more about Data Transformers\nabortOnUnmount: determines if in-flight requests will be cancelled on component unmount. This defaults to false.\noverrides: (default: undefined)​\n\nConfigure overrides for React Query's hooks.\n\nssr-boolean (default: false)​\n\nWhether tRPC should await queries when server-side rendering a page. Defaults to false.\n\nresponseMeta-callback​\n\nAbility to set request headers and HTTP status when server-side rendering.\n\nExample​\nutils/trpc.ts\nimport { createTRPCNext } from '@trpc/next';\nimport type { AppRouter } from '../pages/api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    /* [...] */\n  },\n});\nCopy\nNext steps​\n\nBrowse the rest of the docs to learn more about things like authorization, proxys, and error handling.\n\nYou can also find information about queries and mutations now that you're using @trpc/react-query.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/ssr",
    "html": "Client Usage\nNext.js Integration\nServer-Side Rendering (SSR)\nVersion: 11.x\nServer-Side Rendering\n\nTo enable SSR just set ssr: true in your createTRPCNext config callback.\n\nINFO\n\nWhen you enable SSR, tRPC will use getInitialProps to prefetch all queries on the server. This results in problems like this when you use getServerSideProps, and solving it is out of our hands.\n\n \nAlternatively, you can leave SSR disabled (the default) and use Server-Side Helpers to prefetch queries in getStaticProps or getServerSideProps.\n\nIn order to execute queries properly during the server-side render step we need to add extra logic inside our config:\n\nAdditionally, consider Response Caching.\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport { ssrPrepass } from '@trpc/next/ssrPrepass';\nimport superjson from 'superjson';\nimport type { AppRouter } from './api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  ssr: true,\n  ssrPrepass,\n  config(config) {\n    const { ctx } = opts;\n    if (typeof window !== 'undefined') {\n      // during client requests\n      return {\n        links: [\n          httpBatchLink({\n            url: '/api/trpc',\n          }),\n        ],\n      };\n    }\n    return {\n      links: [\n        httpBatchLink({\n          // The server needs to know your app's full url\n          url: `${getBaseUrl()}/api/trpc`,\n          /**\n           * Set custom request headers on every request from tRPC\n           * @see https://trpc.io/docs/v10/header\n           */\n          headers() {\n            if (!ctx?.req?.headers) {\n              return {};\n            }\n            // To use SSR properly, you need to forward client headers to the server\n            // This is so you can pass through things like cookies when we're server-side rendering\n            return {\n              cookie: ctx.req.headers.cookie,\n            };\n          },\n        }),\n      ],\n    };\n  },\n});\nCopy\n\nor, if you want to SSR conditional on a given request, you can pass a callback to ssr. This callback can return a boolean, or a Promise resolving to a boolean:\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport superjson from 'superjson';\nimport type { AppRouter } from './api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    const { ctx } = opts;\n    if (typeof window !== 'undefined') {\n      // during client requests\n      return {\n        links: [\n          httpBatchLink({\n            url: '/api/trpc',\n          }),\n        ],\n      };\n    }\n    return {\n      links: [\n        httpBatchLink({\n          // The server needs to know your app's full url\n          url: `${getBaseUrl()}/api/trpc`,\n          /**\n           * Set custom request headers on every request from tRPC\n           * @see https://trpc.io/docs/v10/header\n           */\n          headers() {\n            if (!ctx?.req?.headers) {\n              return {};\n            }\n            // To use SSR properly, you need to forward client headers to the server\n            // This is so you can pass through things like cookies when we're server-side rendering\n            return {\n              cookie: ctx.req.headers.cookie,\n            };\n          },\n        }),\n      ],\n    };\n  },\n  ssr(opts) {\n    // only SSR if the request is coming from a bot\n    return opts.ctx?.req?.headers['user-agent']?.includes('bot');\n  },\n});\nCopy\npages/_app.tsx\nimport { trpc } from '~/utils/trpc';\nimport type { AppProps } from 'next/app';\nimport React from 'react';\nconst MyApp: AppType = ({ Component, pageProps }: AppProps) => {\n  return <Component {...pageProps} />;\n};\nexport default trpc.withTRPC(MyApp);\nCopy\nFAQ​\nQ: Why do I need to forward the client's headers to the server manually? Why doesn't tRPC automatically do that for me?​\n\nWhile it's rare that you wouldn't want to forward the client's headers to the server when doing SSR, you might want to add things dynamically in the headers. Therefore, tRPC doesn't want to take responsibility for header keys colliding, etc.\n\nQ: Why do I need to delete the connection header when using SSR on Node 18?​\n\nIf you don't remove the connection header, the data fetching will fail with TRPCClientError: fetch failed because connection is a forbidden header name.\n\nQ: Why do I still see network requests being made in the Network tab?​\n\nBy default, @tanstack/react-query (which we use for the data fetching hooks) refetches data on mount and window refocus, even if it's already got initial data via SSR. This ensures data is always up-to-date. See the page on SSG if you'd like to disable this behavior.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/ssg",
    "html": "Client Usage\nNext.js Integration\nStatic Site Generation (SSG)\nVersion: 11.x\nStatic Site Generation\nTIP\n\nReference project: https://github.com/trpc/examples-next-prisma-todomvc\n\nStatic site generation requires executing tRPC queries inside getStaticProps on each page.\n\nThis can be done using server-side helpers to prefetch the queries, dehydrate them, and pass it to the page. The queries will then automatically pick up the trpcState and use it as an initial value.\n\nFetch data in getStaticProps​\npages/posts/[id].tsx\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport { prisma } from '~/server/context';\nimport { appRouter } from '~/server/routers/_app';\nimport { trpc } from '~/utils/trpc';\nimport {\n  GetStaticPaths,\n  GetStaticPropsContext,\n  InferGetStaticPropsType,\n} from 'next';\nimport superjson from 'superjson';\nexport async function getStaticProps(\n  context: GetStaticPropsContext<{ id: string }>,\n) {\n  const helpers = createServerSideHelpers({\n    router: appRouter,\n    ctx: {},\n    transformer: superjson, // optional - adds superjson serialization\n  });\n  const id = context.params?.id as string;\n  // prefetch `post.byId`\n  await helpers.post.byId.prefetch({ id });\n  return {\n    props: {\n      trpcState: helpers.dehydrate(),\n      id,\n    },\n    revalidate: 1,\n  };\n}\nexport const getStaticPaths: GetStaticPaths = async () => {\n  const posts = await prisma.post.findMany({\n    select: {\n      id: true,\n    },\n  });\n  return {\n    paths: posts.map((post) => ({\n      params: {\n        id: post.id,\n      },\n    })),\n    // https://nextjs.org/docs/pages/api-reference/functions/get-static-paths#fallback-blocking\n    fallback: 'blocking',\n  };\n};\nexport default function PostViewPage(\n  props: InferGetStaticPropsType<typeof getStaticProps>,\n) {\n  const { id } = props;\n  const postQuery = trpc.post.byId.useQuery({ id });\n  if (postQuery.status !== 'success') {\n    // won't happen since we're using `fallback: \"blocking\"`\n    return <>Loading...</>;\n  }\n  const { data } = postQuery;\n  return (\n    <>\n      <h1>{data.title}</h1>\n      <em>Created {data.createdAt.toLocaleDateString('en-us')}</em>\n      <p>{data.text}</p>\n      <h2>Raw data:</h2>\n      <pre>{JSON.stringify(data, null, 4)}</pre>\n    </>\n  );\n}\nCopy\n\nNote that the default behaviour of react-query is to refetch the data on the client-side when it mounts, so if you want to only fetch the data via getStaticProps, you need to set refetchOnMount and refetchOnWindowFocus to false in the query options.\n\nThis might be preferable if you want to minimize the number of requests to your API, which might be necessary if you're using a third-party rate-limited API for example.\n\nThis can be done per query:\n\nconst data = trpc.example.useQuery(\n  // if your query takes no input, make sure that you don't\n  // accidentally pass the query options as the first argument\n  undefined,\n  { refetchOnMount: false, refetchOnWindowFocus: false },\n);\nCopy\n\nOr globally, if every query across your app should behave the same way:\n\nutils/trpc.ts\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nimport superjson from 'superjson';\nimport type { AppRouter } from './api/trpc/[trpc]';\nexport const trpc = createTRPCNext<AppRouter>({\n  config(config) {\n    return {\n      links: [\n        httpBatchLink({\n          url: `${getBaseUrl()}/api/trpc`,\n        }),\n      ],\n      // Change options globally\n      queryClientConfig: {\n        defaultOptions: {\n          queries: {\n            refetchOnMount: false,\n            refetchOnWindowFocus: false,\n          },\n        },\n      },\n    },\n  },\n});\nCopy\n\nBe careful with this approach if your app has a mixture of static and dynamic queries.\n\nEdit this page"
  },
  {
    "title": "Server-Side Helpers | tRPC",
    "url": "https://trpc.io/docs/client/nextjs/server-side-helpers",
    "html": "Client Usage\nNext.js Integration\nServer-Side Helpers\nVersion: 11.x\nServer-Side Helpers\n\nThe server-side helpers provides you with a set of helper functions that you can use to prefetch queries on the server. This is useful for SSG, but also for SSR if you opt not to use ssr: true.\n\nPrefetching via the server-side helpers allows populating the query cache on the server, which means that these queries do not have to fetch on the client initially.\n\nThere are 2 ways to use the server-side helpers.​\n1. Internal router​\n\nThis method is used when you have direct access to your tRPC router. e.g. when developing a monolithic Next.js application.\n\nUsing the helpers makes tRPC call your procedures directly on the server, without an HTTP request, similar to server-side calls. That also means that you don't have the request and response at hand like you usually do. Make sure you're instantiating the server-side helpers with a context without req & res, which are typically filled via the context creation. We recommend the concept of \"inner\" and \"outer\" context in that scenario.\n\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport { createContext } from '~/server/context';\nimport superjson from 'superjson';\nconst helpers = createServerSideHelpers({\n  router: appRouter,\n  ctx: await createContext(),\n  transformer: superjson, // optional - adds superjson serialization\n});\nCopy\n2. External router​\n\nThis method is used when you don't have direct access to your tRPC router. e.g. when developing a Next.js application and a standalone API hosted separately.\n\nimport { createTRPCClient } from '@trpc/client';\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport superjson from 'superjson';\nconst proxyClient = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000/api/trpc',\n    }),\n  ],\n});\nconst helpers = createServerSideHelpers({\n  client: proxyClient,\n});\nCopy\nHelpers usage​\n\nThe server-side helpers methods return an object much like the tRPC client, with all of your routers as keys. However, rather than useQuery and useMutation, you get prefetch, fetch, prefetchInfinite, and fetchInfinite functions.\n\nThe primary difference between prefetch and fetch is that fetch acts much like a normal function call, returning the result of the query, whereas prefetch does not return the result and never throws - if you need that behavior, use fetch instead. Instead, prefetch will add the query to the cache, which you then dehydrate and send to the client.\n\nreturn {\n  props: {\n    // very important - use `trpcState` as the key\n    trpcState: helpers.dehydrate(),\n  },\n};\nCopy\n\nThe rule of thumb is prefetch for queries that you know you'll need on the client, and fetch for queries that you want to use the result of on the server.\n\nThe functions are all wrappers around react-query functions. Please check out their docs to learn more about them in detail.\n\nINFO\n\nFor a full example, see our E2E SSG test example\n\nNext.js Example​\npages/posts/[id].tsx\nimport { createServerSideHelpers } from '@trpc/react-query/server';\nimport { appRouter } from '~/server/routers/_app';\nimport { trpc } from '~/utils/trpc';\nimport { GetServerSidePropsContext, InferGetServerSidePropsType } from 'next';\nimport superjson from 'superjson';\nexport async function getServerSideProps(\n  context: GetServerSidePropsContext<{ id: string }>,\n) {\n  const helpers = createServerSideHelpers({\n    router: appRouter,\n    ctx: {},\n    transformer: superjson,\n  });\n  const id = context.params?.id as string;\n  /*\n   * Prefetching the `post.byId` query.\n   * `prefetch` does not return the result and never throws - if you need that behavior, use `fetch` instead.\n   */\n  await helpers.post.byId.prefetch({ id });\n  // Make sure to return { props: { trpcState: helpers.dehydrate() } }\n  return {\n    props: {\n      trpcState: helpers.dehydrate(),\n      id,\n    },\n  };\n}\nexport default function PostViewPage(\n  props: InferGetServerSidePropsType<typeof getServerSideProps>,\n) {\n  const { id } = props;\n  const postQuery = trpc.post.byId.useQuery({ id });\n  if (postQuery.status !== 'success') {\n    // won't happen since the query has been prefetched\n    return <>Loading...</>;\n  }\n  const { data } = postQuery;\n  return (\n    <>\n      <h1>{data.title}</h1>\n      <em>Created {data.createdAt.toLocaleDateString()}</em>\n      <p>{data.text}</p>\n      <h2>Raw data:</h2>\n      <pre>{JSON.stringify(data, null, 4)}</pre>\n    </>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/nextjs/aborting-procedure-calls",
    "html": "Client Usage\nNext.js Integration\nAborting Procedure Calls\nVersion: 11.x\nAborting Procedure Calls\n\nBy default, tRPC does not cancel requests on unmount. If you want to opt into this behavior, you can provide abortOnUnmount in your configuration callback.\n\nGlobally​\nclient.ts\n// @filename: utils.ts\nimport { createTRPCNext } from '@trpc/next';\n \nexport const trpc = createTRPCNext<AppRouter>({\n  config() {\n    return {\n      // ...\n      abortOnUnmount: true,\n    };\n  },\n});\nCopy\nPer-request​\n\nYou may also override this behavior at the request level.\n\nclient.ts\n// @filename: pages/posts/[id].tsx\nimport { trpc } from '~/utils/trpc';\n \nconst PostViewPage: NextPageWithLayout = () => {\n  const id = useRouter().query.id as string;\n  const postQuery = trpc.post.byId.useQuery({ id }, { trpc: { abortOnUnmount: true } });\n \n  return (...)\n}\nCopy\nEdit this page"
  },
  {
    "title": "Disabling Queries | tRPC",
    "url": "https://trpc.io/docs/client/react/disabling-queries",
    "html": "Client Usage\nReact Query Integration (Classic)\nDisabling Queries\nVersion: 11.x\nDisabling Queries\n\nTo disable queries, you can pass skipToken as the first argument to useQuery or useInfiniteQuery. This will prevent the query from being executed.\n\nTypesafe conditional queries using skipToken​\nimport { skipToken } from '@tanstack/react-query';\nexport function MyComponent() {\nconst [name, setName] = useState<string | undefined>();\nconst result = trpc.getUserByName.useQuery(name ? { name: name } : skipToken);\n  return (\n    ...\n  )\n}\nCopy\nEdit this page"
  },
  {
    "title": "TanStack React Query | tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/setup",
    "html": "Client Usage\nTanStack React Query (⭐️)\nSetup\nVersion: 11.x\nTanStack React Query\n\nCompared to our classic React Query Integration this client is simpler and more TanStack Query-native, providing factories for common TanStack React Query interfaces like QueryKeys, QueryOptions, and MutationOptions. We think it's the future and recommend using this over the classic client, read the announcement post for more information about this change.\n\nTIP\n\nYou can try this integration out on the homepage of tRPC.io: https://trpc.io/?try=minimal-react#try-it-out\n\n❓ Do I have to use an integration?\nSetup​\n1. Install dependencies​\n\nThe following dependencies should be installed\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/tanstack-react-query @tanstack/react-query\n2. Import your AppRouter​\n\nImport your AppRouter type into the client application. This type holds the shape of your entire API.\n\nutils/trpc.ts\nimport type { AppRouter } from '../server/router';\nCopy\nTIP\n\nBy using import type you ensure that the reference will be stripped at compile-time, meaning you don't inadvertently import server-side code into your client. For more information, see the Typescript docs.\n\n3a. Setup the tRPC context provider​\n\nIn cases where you rely on React context, such as when using server-side rendering in full-stack frameworks like Next.js, it's important to create a new QueryClient for each request so that your users don't end up sharing the same cache, you can use the createTRPCContext to create a set of type-safe context providers and consumers from your AppRouter type signature.\n\nutils/trpc.ts\nimport { createTRPCContext } from '@trpc/tanstack-react-query';\nimport type { AppRouter } from '../server/router';\n \nexport const { TRPCProvider, useTRPC, useTRPCClient } = createTRPCContext<AppRouter>();\nCopy\n\nThen, create a tRPC client, and wrap your application in the TRPCProvider, as below. You will also need to set up and connect React Query, which they document in more depth.\n\nTIP\n\nIf you already use React Query in your application, you should re-use the QueryClient and QueryClientProvider you already have. You can read more about the QueryClient initialization in the React Query docs.\n\ncomponents/App.tsx\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport { useState } from 'react';\nimport { TRPCProvider } from './utils/trpc';\nfunction makeQueryClient() {\n  return new QueryClient({\n    defaultOptions: {\n      queries: {\n        // With SSR, we usually want to set some default staleTime\n        // above 0 to avoid refetching immediately on the client\n        staleTime: 60 * 1000,\n      },\n    },\n  });\n}\nlet browserQueryClient: QueryClient | undefined = undefined;\nfunction getQueryClient() {\n  if (typeof window === 'undefined') {\n    // Server: always make a new query client\n    return makeQueryClient();\n  } else {\n    // Browser: make a new query client if we don't already have one\n    // This is very important, so we don't re-make a new client if React\n    // suspends during the initial render. This may not be needed if we\n    // have a suspense boundary BELOW the creation of the query client\n    if (!browserQueryClient) browserQueryClient = makeQueryClient();\n    return browserQueryClient;\n  }\n}\nexport function App() {\n  const queryClient = getQueryClient();\n  const [trpcClient] = useState(() =>\n    createTRPCClient<AppRouter>({\n      links: [\n        httpBatchLink({\n          url: 'http://localhost:2022',\n        }),\n      ],\n    }),\n  );\n  return (\n    <QueryClientProvider client={queryClient}>\n      <TRPCProvider trpcClient={trpcClient} queryClient={queryClient}>\n        {/* Your app here */}\n      </TRPCProvider>\n    </QueryClientProvider>\n  );\n}\nCopy\n3b. Setup without React context​\n\nWhen building an SPA using only client-side rendering with something like Vite, you can create the QueryClient and tRPC client outside of React context as singletons.\n\nutils/trpc.ts\nimport { QueryClient } from '@tanstack/react-query';\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport { createTRPCOptionsProxy } from '@trpc/tanstack-react-query';\nimport type { AppRouter } from '../server/router';\nexport const queryClient = new QueryClient();\nconst trpcClient = createTRPCClient<AppRouter>({\n  links: [httpBatchLink({ url: 'http://localhost:2022' })],\n});\nexport const trpc = createTRPCOptionsProxy<AppRouter>({\n  client: trpcClient,\n  queryClient,\n});\nCopy\ncomponents/App.tsx\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport React from 'react';\nimport { queryClient } from './utils/trpc';\nexport function App() {\n  return (\n    <QueryClientProvider client={queryClient}>\n      {/* Your app here */}\n    </QueryClientProvider>\n  );\n}\nCopy\n4. Fetch data​\n\nYou can now use the tRPC React Query integration to call queries and mutations on your API.\n\ncomponents/user-list.tsx\nimport { useMutation, useQuery } from '@tanstack/react-query';\nimport { useTRPC } from '../utils/trpc';\nexport default function UserList() {\n  const trpc = useTRPC(); // use `import { trpc } from './utils/trpc'` if you're using the singleton pattern\n  const userQuery = useQuery(trpc.getUser.queryOptions({ id: 'id_bilbo' }));\n  const userCreator = useMutation(trpc.createUser.mutationOptions());\n  return (\n    <div>\n      <p>{userQuery.data?.name}</p>\n      <button onClick={() => userCreator.mutate({ name: 'Frodo' })}>\n        Create Frodo\n      </button>\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/usage",
    "html": "Client Usage\nTanStack React Query (⭐️)\nUsage\nVersion: 11.x\nTanStack React Query\n\nCompared to our classic React Query Integration this client is simpler and more TanStack Query-native, providing factories for common TanStack React Query interfaces like QueryKeys, QueryOptions, and MutationOptions. We think it's the future and recommend using this over the classic client, read the announcement post for more information about this change.\n\nQuick example query​\nimport { useQuery } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const greetingQuery = useQuery(trpc.greeting.queryOptions({ name: 'Jerry' }));\n  // greetingQuery.data === 'Hello Jerry'\n}\nCopy\nUsage​\n\nThe philosophy of this client is to provide thin and type-safe factories which work natively and type-safely with Tanstack React Query. This means just by following the autocompletes the client gives you, you can focus on building just with the knowledge the TanStack React Query docs provide.\n\nexport default function Basics() {\n  const trpc = useTRPC();\n  const queryClient = useQueryClient();\n  // Create QueryOptions which can be passed to query hooks\n  const myQueryOptions = trpc.path.to.query.queryOptions({ /** inputs */ })\n  const myQuery = useQuery(myQueryOptions)\n  // or:\n  // useSuspenseQuery(myQueryOptions)\n  // useInfiniteQuery(myQueryOptions)\n  // Create MutationOptions which can be passed to useMutation\n  const myMutationOptions = trpc.path.to.mutation.mutationOptions()\n  const myMutation = useMutation(myMutationOptions)\n  // Create a QueryKey which can be used to manipulated many methods\n  // on TanStack's QueryClient in a type-safe manner\n  const myQueryKey = trpc.path.to.query.queryKey()\n  const invalidateMyQueryKey = () => {\n    queryClient.invalidateQueries({ queryKey: myQueryKey })\n  }\n  return (\n    // Your app here\n  )\n}\nCopy\n\nThe trpc object is fully type-safe and will provide autocompletes for all the procedures in your AppRouter. At the end of the proxy, the following methods are available:\n\nqueryOptions - querying data​\n\nAvailable for all query procedures. Provides a type-safe wrapper around Tanstack's queryOptions function. The first argument is the input for the procedure, and the second argument accepts any native Tanstack React Query options.\n\nconst queryOptions = trpc.path.to.query.queryOptions(\n  {\n    /** input */\n  },\n  {\n    // Any Tanstack React Query options\n    staleTime: 1000,\n  },\n);\nCopy\n\nYou can additionally provide a trpc object to the queryOptions function to provide tRPC request options to the client.\n\nconst queryOptions = trpc.path.to.query.queryOptions(\n  {\n    /** input */\n  },\n  {\n    trpc: {\n      // Provide tRPC request options to the client\n      context: {\n        // see https://trpc.io/docs/client/links#managing-context\n      },\n    },\n  },\n);\nCopy\n\nIf you want to disable a query in a type safe way, you can use skipToken:\n\nimport { skipToken } from '@tanstack/react-query';\nconst query = useQuery(\n  trpc.user.details.queryOptions(\n    user?.id && project?.id\n      ? {\n          userId: user.id,\n          projectId: project.id,\n        }\n      : skipToken,\n    {\n      staleTime: 1000,\n    },\n  ),\n);\nCopy\n\nThe result can be passed to useQuery or useSuspenseQuery hooks or query client methods like fetchQuery, prefetchQuery, prefetchInfiniteQuery, invalidateQueries, etc.\n\ninfiniteQueryOptions - querying infinite data​\n\nAvailable for all query procedures that takes a cursor input. Provides a type-safe wrapper around Tanstack's infiniteQueryOptions function. The first argument is the input for the procedure, and the second argument accepts any native Tanstack React Query options.\n\nconst infiniteQueryOptions = trpc.path.to.query.infiniteQueryOptions(\n  {\n    /** input */\n  },\n  {\n    // Any Tanstack React Query options\n    getNextPageParam: (lastPage, pages) => lastPage.nextCursor,\n  },\n);\nCopy\nqueryKey - getting the query key and performing operations on the query client​\n\nAvailable for all query procedures. Allows you to access the query key in a type-safe manner.\n\nconst queryKey = trpc.path.to.query.queryKey();\nCopy\n\nSince Tanstack React Query uses fuzzy matching for query keys, you can also create a partial query key for any sub-path to match all queries belonging to a router:\n\nconst queryKey = trpc.router.pathKey();\nCopy\n\nOr even the root path to match all tRPC queries:\n\nconst queryKey = trpc.pathKey();\nCopy\nqueryFilter - creating query filters​\n\nAvailable for all query procedures. Allows creating query filters in a type-safe manner.\n\nconst queryFilter = trpc.path.to.query.queryFilter(\n  {\n    /** input */\n  },\n  {\n    // Any Tanstack React Query filter\n    predicate: (query) => {\n      query.state.data;\n    },\n  },\n);\nCopy\n\nLike with query keys, if you want to run a filter across a whole router you can use pathFilter to target any sub-path.\n\nconst queryFilter = trpc.path.pathFilter({\n  // Any Tanstack React Query filter\n  predicate: (query) => {\n    query.state.data;\n  },\n});\nCopy\n\nUseful for creating filters that can be passed to client methods like queryClient.invalidateQueries etc.\n\nmutationOptions - creating mutation options​\n\nAvailable for all mutation procedures. Provides a type-safe identify function for constructing options that can be passed to useMutation.\n\nconst mutationOptions = trpc.path.to.mutation.mutationOptions({\n  // Any Tanstack React Query options\n  onSuccess: (data) => {\n    // do something with the data\n  },\n});\nCopy\nmutationKey - getting the mutation key​\n\nAvailable for all mutation procedures. Allows you to get the mutation key in a type-safe manner.\n\nconst mutationKey = trpc.path.to.mutation.mutationKey();\nCopy\nsubscriptionOptions - creating subscription options​\n\nTanStack does not provide a subscription hook, so we continue to expose our own abstraction here which works with a standard tRPC subscription setup. Available for all subscription procedures. Provides a type-safe identify function for constructing options that can be passed to useSubscription. Note that you need to have either the httpSubscriptionLink or wsLink configured in your tRPC client to use subscriptions.\n\nfunction SubscriptionExample() {\n  const trpc = useTRPC();\n  const subscription = useSubscription(\n    trpc.path.to.subscription.subscriptionOptions(\n      {\n        /** input */\n      },\n      {\n        enabled: true,\n        onStarted: () => {\n          // do something when the subscription is started\n        },\n        onData: (data) => {\n          // you can handle the data here\n        },\n        onError: (error) => {\n          // you can handle the error here\n        },\n        onConnectionStateChange: (state) => {\n          // you can handle the connection state here\n        },\n      },\n    ),\n  );\n  // Or you can handle the state here\n  subscription.data; // The lastly received data\n  subscription.error; // The lastly received error\n  /**\n   * The current status of the subscription.\n   * Will be one of: `'idle'`, `'connecting'`, `'pending'`, or `'error'`.\n   *\n   * - `idle`: subscription is disabled or ended\n   * - `connecting`: trying to establish a connection\n   * - `pending`: connected to the server, receiving data\n   * - `error`: an error occurred and the subscription is stopped\n   */\n  subscription.status;\n  // Reset the subscription (if you have an error etc)\n  subscription.reset();\n  return <>{/* ... */}</>;\n}\nCopy\nInferring Input and Output types​\n\nWhen you need to infer the input and output types for a procedure or router, there are 2 options available depending on the situation.\n\nInfer the input and output types of a full router\n\nimport type { inferRouterInputs, inferRouterOutputs } from '@trpc/server';\nimport { AppRouter } from './path/to/server';\nexport type Inputs = inferRouterInputs<AppRouter>;\nexport type Outputs = inferRouterOutputs<AppRouter>;\nCopy\n\nInfer types for a single procedure\n\nimport type { inferInput, inferOutput } from '@trpc/tanstack-react-query';\nfunction Component() {\n  const trpc = useTRPC();\n  type Input = inferInput<typeof trpc.path.to.procedure>;\n  type Output = inferOutput<typeof trpc.path.to.procedure>;\n}\nCopy\nAccessing the tRPC client​\n\nIf you used the setup with React Context, you can access the tRPC client using the useTRPCClient hook.\n\nimport { useTRPCClient } from './trpc';\nfunction Component() {\n  const trpcClient = useTRPCClient();\n  const result = await trpcClient.path.to.procedure.query({\n    /** input */\n  });\n}\nCopy\n\nIf you setup without React Context, you can import the global client instance directly instead.\n\nimport { client } from './trpc';\nconst result = await client.path.to.procedure.query({\n  /** input */\n});\nCopy\nEdit this page"
  },
  {
    "title": "Migrating from the classic React Client | tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/migrating",
    "html": "Client Usage\nTanStack React Query (⭐️)\nMigrating\nVersion: 11.x\nMigrating from the classic React Client\n\nThere are a few approaches to migrate over, and this library is a significant departure from the classic client, so we're not expecting anybody to do it in one shot. But you will probably want to try a combination of...\n\nCodemod migration​\nINFO\n\nThe codemod is a work in progress and we're looking for help to make it better. If you're interested in contributing to the codemod, please see Julius' comment here.\n\nWe're working on a codemod to help you migrate your existing codebase over to the new client. This is already available to try but we need your feedback and contributions to improve it. Codemods are very tricky to get right so we're looking for your help to make it as effective as possible.\n\nRun our upgrade CLI:\n\nnpx @trpc/upgrade\nCopy\n\nWhen prompted, select the transforms Migrate Hooks to xxxOptions API and Migrate context provider setup.\n\nGradual migration​\n\nThe new and classic clients are compatible with each other and can live together in the same application. This means you can start migrating by using the new client in new parts of your application, and gradually migrate over existing usage as you see fit. Most importantly, Query Keys are identical, which means you can use the new client and classic client together and still rely on TanStack Query's caching.\n\nMigrating Queries​\n\nA classic query would look like this\n\nimport { trpc } from './trpc';\nfunction Users() {\n  const greetingQuery = trpc.greeting.useQuery({ name: 'Jerry' });\n  // greetingQuery.data === 'Hello Jerry'\n}\nCopy\n\nand changes to\n\nimport { useQuery } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const greetingQuery = useQuery(trpc.greeting.queryOptions({ name: 'Jerry' }));\n  // greetingQuery.data === 'Hello Jerry'\n}\nCopy\nMigrating Invalidations and other QueryClient usages​\n\nA classic query would look like this\n\nimport { trpc } from './trpc';\nfunction Users() {\n  const utils = trpc.useUtils();\n  async function invalidateGreeting() {\n    await utils.greeting.invalidate({ name: 'Jerry' });\n  }\n}\nCopy\n\nand changes to\n\nimport { useQuery, useQueryClient } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const queryClient = useQueryClient();\n  async function invalidateGreeting() {\n    await queryClient.invalidateQueries(\n      trpc.greeting.queryFilter({ name: 'Jerry' }),\n    );\n  }\n}\nCopy\n\nThis is the same for any QueryClient usage, instead of using tRPC's useUtils you can now follow the TanStack documentation directly\n\nMigrating Mutations​\n\nA classic mutation might look like this\n\nimport { trpc } from './trpc';\nfunction Users() {\n  const createUserMutation = trpc.createUser.useMutation();\n  createUserMutation.mutate({ name: 'Jerry' });\n}\nCopy\n\nand changes to\n\nimport { useMutation } from '@tanstack/react-query';\nimport { useTRPC } from './trpc';\nfunction Users() {\n  const trpc = useTRPC();\n  const createUserMutation = useMutation(trpc.createUser.mutationOptions());\n  createUserMutation.mutate({ name: 'Jerry' });\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/tanstack-react-query/server-components",
    "html": "Client Usage\nTanStack React Query (⭐️)\nServer Components\nVersion: 11.x\nSet up with React Server Components\n\nThis guide is an overview of how one may use tRPC with a React Server Components (RSC) framework such as Next.js App Router. Be aware that RSC on its own solves a lot of the same problems tRPC was designed to solve, so you may not need tRPC at all.\n\nThere are also not a one-size-fits-all way to integrate tRPC with RSCs, so see this guide as a starting point and adjust it to your needs and preferences.\n\nINFO\n\nIf you're looking for how to use tRPC with Server Actions, check out this blog post by Julius.\n\nCAUTION\n\nPlease read React Query's Advanced Server Rendering docs before proceeding to understand the different types of server rendering and what footguns to avoid.\n\nAdd tRPC to existing projects​\n1. Install deps​\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/tanstack-react-query @tanstack/react-query@latest zod client-only server-only\n2. Create a tRPC router​\n\nInitialize your tRPC backend in trpc/init.ts using the initTRPC function, and create your first router. We're going to make a simple \"hello world\" router and procedure here - but for deeper information on creating your tRPC API you should refer to the Quickstart guide and Backend usage docs for tRPC information.\n\nINFO\n\nThe file names used here are not enforced by tRPC. You may use any file structure you wish.\n\nView sample backend\n3. Create a Query Client factory​\n\nCreate a shared file trpc/query-client.ts that exports a function that creates a QueryClient instance.\n\ntrpc/query-client.ts\nimport {\n  defaultShouldDehydrateQuery,\n  QueryClient,\n} from '@tanstack/react-query';\nimport superjson from 'superjson';\nexport function makeQueryClient() {\n  return new QueryClient({\n    defaultOptions: {\n      queries: {\n        staleTime: 30 * 1000,\n      },\n      dehydrate: {\n        // serializeData: superjson.serialize,\n        shouldDehydrateQuery: (query) =>\n          defaultShouldDehydrateQuery(query) ||\n          query.state.status === 'pending',\n      },\n      hydrate: {\n        // deserializeData: superjson.deserialize,\n      },\n    },\n  });\n}\nCopy\n\nWe're setting a few default options here:\n\nstaleTime: With SSR, we usually want to set some default staleTime above 0 to avoid refetching immediately on the client.\nshouldDehydrateQuery: This is a function that determines whether a query should be dehydrated or not. Since the RSC transport protocol supports hydrating promises over the network, we extend the defaultShouldDehydrateQuery function to also include queries that are still pending. This will allow us to start prefetching in a server component high up the tree, then consuming that promise in a client component further down.\nserializeData and deserializeData (optional): If you set up a data transformer in the previous step, set this option to make sure the data is serialized correctly when hydrating the query client over the server-client boundary.\n4. Create a tRPC client for Client Components​\n\nThe trpc/client.tsx is the entrypoint when consuming your tRPC API from client components. In here, import the type definition of your tRPC router and create typesafe hooks using createTRPCContext. We'll also export our context provider from this file.\n\ntrpc/client.tsx\n'use client';\n// ^-- to make sure we can mount the Provider from a server component\nimport type { QueryClient } from '@tanstack/react-query';\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport { createTRPCContext } from '@trpc/tanstack-react-query';\nimport { useState } from 'react';\nimport { makeQueryClient } from './query-client';\nimport type { AppRouter } from './routers/_app';\nexport const { TRPCProvider, useTRPC } = createTRPCContext<AppRouter>();\nlet browserQueryClient: QueryClient;\nfunction getQueryClient() {\n  if (typeof window === 'undefined') {\n    // Server: always make a new query client\n    return makeQueryClient();\n  }\n  // Browser: make a new query client if we don't already have one\n  // This is very important, so we don't re-make a new client if React\n  // suspends during the initial render. This may not be needed if we\n  // have a suspense boundary BELOW the creation of the query client\n  if (!browserQueryClient) browserQueryClient = makeQueryClient();\n  return browserQueryClient;\n}\nfunction getUrl() {\n  const base = (() => {\n    if (typeof window !== 'undefined') return '';\n    if (process.env.VERCEL_URL) return `https://${process.env.VERCEL_URL}`;\n    return 'http://localhost:3000';\n  })();\n  return `${base}/api/trpc`;\n}\nexport function TRPCReactProvider(\n  props: Readonly<{\n    children: React.ReactNode;\n  }>,\n) {\n  // NOTE: Avoid useState when initializing the query client if you don't\n  //       have a suspense boundary between this and the code that may\n  //       suspend because React will throw away the client on the initial\n  //       render if it suspends and there is no boundary\n  const queryClient = getQueryClient();\n  const [trpcClient] = useState(() =>\n    createTRPCClient<AppRouter>({\n      links: [\n        httpBatchLink({\n          // transformer: superjson, <-- if you use a data transformer\n          url: getUrl(),\n        }),\n      ],\n    }),\n  );\n  return (\n    <QueryClientProvider client={queryClient}>\n      <TRPCProvider trpcClient={trpcClient} queryClient={queryClient}>\n        {props.children}\n      </TRPCProvider>\n    </QueryClientProvider>\n  );\n}\nCopy\n\nMount the provider in the root of your application (e.g. app/layout.tsx when using Next.js).\n\n5. Create a tRPC caller for Server Components​\n\nTo prefetch queries from server components, we create a proxy from our router. You can also pass in a client if your router is on a separate server.\n\ntrpc/server.tsx\nimport 'server-only'; // <-- ensure this file cannot be imported from the client\nimport { createTRPCOptionsProxy } from '@trpc/tanstack-react-query';\nimport { cache } from 'react';\nimport { createTRPCContext } from './init';\nimport { makeQueryClient } from './query-client';\nimport { appRouter } from './routers/_app';\n// IMPORTANT: Create a stable getter for the query client that\n//            will return the same client during the same request.\nexport const getQueryClient = cache(makeQueryClient);\nexport const trpc = createTRPCOptionsProxy({\n  ctx: createTRPCContext,\n  router: appRouter,\n  queryClient: getQueryClient,\n});\n// If your router is on a separate server, pass a client:\ncreateTRPCOptionsProxy({\n  client: createTRPCClient({\n    links: [httpLink({ url: '...' })],\n  }),\n  queryClient: getQueryClient,\n});\nCopy\nUsing your API​\n\nNow you can use your tRPC API in your app. While you can use the React Query hooks in client components just like you would in any other React app, we can take advantage of the RSC capabilities by prefetching queries in a server component high up the tree. You may be familiar with this concept as \"render as you fetch\" commonly implemented as loaders. This means the request fires as soon as possible but without suspending until the data is needed by using the useQuery or useSuspenseQuery hooks.\n\nThis approach leverages Next.js App Router's streaming capabilities, initiating the query on the server and streaming data to the client as it becomes available. It optimizes both the time to first byte in the browser and the data fetch time, resulting in faster page loads. However, greeting.data may initially be undefined before the data streams in.\n\nIf you prefer to avoid this initial undefined state, you can await the prefetchQuery call. This ensures the query on the client always has data on first render, but it comes with a tradeoff - the page will load more slowly since the server must complete the query before sending HTML to the client.\n\napp/page.tsx\nimport { dehydrate, HydrationBoundary } from '@tanstack/react-query';\nimport { getQueryClient, trpc } from '~/trpc/server';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  const queryClient = getQueryClient();\n  void queryClient.prefetchQuery(\n    trpc.hello.queryOptions({\n      /** input */\n    }),\n  );\n  return (\n    <HydrationBoundary state={dehydrate(queryClient)}>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrationBoundary>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\n// <-- hooks can only be used in client components\nimport { useQuery } from '@tanstack/react-query';\nimport { useTRPC } from '~/trpc/client';\nexport function ClientGreeting() {\n  const trpc = useTRPC();\n  const greeting = useQuery(trpc.hello.queryOptions({ text: 'world' }));\n  if (!greeting.data) return <div>Loading...</div>;\n  return <div>{greeting.data.greeting}</div>;\n}\nCopy\nTIP\n\nYou can also create a prefetch and HydrateClient helper functions to make it a bit more consice and reusable:\n\ntrpc/server.tsx\nexport function HydrateClient(props: { children: React.ReactNode }) {\n  const queryClient = getQueryClient();\n  return (\n    <HydrationBoundary state={dehydrate(queryClient)}>\n      {props.children}\n    </HydrationBoundary>\n  );\n}\nexport function prefetch<T extends ReturnType<TRPCQueryOptions<any>>>(\n  queryOptions: T,\n) {\n  const queryClient = getQueryClient();\n  if (queryOptions.queryKey[1]?.type === 'infinite') {\n    void queryClient.prefetchInfiniteQuery(queryOptions as any);\n  } else {\n    void queryClient.prefetchQuery(queryOptions);\n  }\n}\nCopy\n\nThen you can use it like this:\n\nimport { HydrateClient, prefetch, trpc } from '~/trpc/server';\nfunction Home() {\n  prefetch(\n    trpc.hello.queryOptions({\n      /** input */\n    }),\n  );\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrateClient>\n  );\n}\nCopy\nLeveraging Suspense​\n\nYou may prefer handling loading and error states using Suspense and Error Boundaries. You can do this by using the useSuspenseQuery hook.\n\napp/page.tsx\nimport { HydrateClient, prefetch, trpc } from '~/trpc/server';\nimport { Suspense } from 'react';\nimport { ErrorBoundary } from 'react-error-boundary';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  prefetch(trpc.hello.queryOptions());\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ErrorBoundary fallback={<div>Something went wrong</div>}>\n        <Suspense fallback={<div>Loading...</div>}>\n          <ClientGreeting />\n        </Suspense>\n      </ErrorBoundary>\n    </HydrateClient>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\nimport { useSuspenseQuery } from '@tanstack/react-query';\nimport { trpc } from '~/trpc/client';\nexport function ClientGreeting() {\n  const trpc = useTRPC();\n  const { data } = useSuspenseQuery(trpc.hello.queryOptions());\n  return <div>{data.greeting}</div>;\n}\nCopy\nGetting data in a server component​\n\nIf you need access to the data in a server component, we recommend creating a server caller and using it directly. Please note that this method is detached from your query client and does not store the data in the cache. This means that you cannot use the data in a server component and expect it to be available in the client. This is intentional and explained in more detail in the Advanced Server Rendering guide.\n\ntrpc/server.tsx\n// ...\nexport const caller = appRouter.createCaller(createTRPCContext);\nCopy\napp/page.tsx\nimport { caller } from '~/trpc/server';\nexport default async function Home() {\n  const greeting = await caller.hello();\n  //    ^? { greeting: string }\n  return <div>{greeting.greeting}</div>;\n}\nCopy\n\nIf you really need to use the data both on the server as well as inside client components and understand the tradeoffs explained in the Advanced Server Rendering guide, you can use fetchQuery instead of prefetch to have the data both on the server as well as hydrating it down to the client:\n\napp/page.tsx\nimport { getQueryClient, HydrateClient, trpc } from '~/trpc/server';\nexport default async function Home() {\n  const queryClient = getQueryClient();\n  const greeting = await queryClient.fetchQuery(trpc.hello.queryOptions());\n  // Do something with greeting on the server\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrateClient>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/setup",
    "html": "Client Usage\nReact Query Integration (Classic)\nSetup\nVersion: 11.x\nSet up the React Query Integration\n1. Install dependencies​\n\nThe following dependencies should be installed\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/react-query @tanstack/react-query\n2. Import your AppRouter​\n\nImport your AppRouter type into the client application. This type holds the shape of your entire API.\n\nutils/trpc.ts\nimport type { AppRouter } from '../server/router';\nCopy\nTIP\n\nBy using import type you ensure that the reference will be stripped at compile-time, meaning you don't inadvertently import server-side code into your client. For more information, see the Typescript docs.\n\n3. Create tRPC hooks​\n\nCreate a set of strongly-typed React hooks from your AppRouter type signature with createTRPCReact.\n\nutils/trpc.ts\nimport { createTRPCReact } from '@trpc/react-query';\nimport type { AppRouter } from '../server/router';\n \nexport const trpc = createTRPCReact<AppRouter>();\nCopy\n4. Add tRPC providers​\n\nCreate a tRPC client, and wrap your application in the tRPC Provider, as below. You will also need to set up and connect React Query, which they document in more depth.\n\nTIP\n\nIf you already use React Query in your application, you should re-use the QueryClient and QueryClientProvider you already have.\n\nApp.tsx\nimport { QueryClient, QueryClientProvider } from '@tanstack/react-query';\nimport { httpBatchLink } from '@trpc/client';\nimport React, { useState } from 'react';\nimport { trpc } from './utils/trpc';\nexport function App() {\n  const [queryClient] = useState(() => new QueryClient());\n  const [trpcClient] = useState(() =>\n    trpc.createClient({\n      links: [\n        httpBatchLink({\n          url: 'http://localhost:3000/trpc',\n          // You can pass any HTTP headers you wish here\n          async headers() {\n            return {\n              authorization: getAuthCookie(),\n            };\n          },\n        }),\n      ],\n    }),\n  );\n  return (\n    <trpc.Provider client={trpcClient} queryClient={queryClient}>\n      <QueryClientProvider client={queryClient}>\n        {/* Your app here */}\n      </QueryClientProvider>\n    </trpc.Provider>\n  );\n}\nCopy\nNOTE\n\nThe reason for using useState in the creation of the queryClient and the TRPCClient, as opposed to declaring them outside of the component, is to ensure that each request gets a unique client when using SSR. If you use client side rendering then you can move them if you wish.\n\n5. Fetch data​\n\nYou can now use the tRPC React Query integration to call queries and mutations on your API.\n\npages/IndexPage.tsx\nimport { trpc } from '../utils/trpc';\n \nexport default function IndexPage() {\n  const userQuery = trpc.getUser.useQuery({ id: 'id_bilbo' });\n  const userCreator = trpc.createUser.useMutation();\n \n  return (\n    <div>\n      <p>{userQuery.data?.name}</p>\n \n      <button onClick={() => userCreator.mutate({ name: 'Frodo' })}>\n        Create Frodo\n      </button>\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "Set up with React Server Components | tRPC",
    "url": "https://trpc.io/docs/client/react/server-components",
    "html": "Client Usage\nReact Query Integration (Classic)\nServer Components\nVersion: 11.x\nSet up with React Server Components\nTIP\n\nThese are the docs for our 'Classic' React Query integration, which (while still supported) is not the recommended way to start new tRPC projects with TanStack React Query. We recommend using the new TanStack React Query Integration instead.\n\nThis guide is an overview of how one may use tRPC with a React Server Components (RSC) framework such as Next.js App Router. Be aware that RSC on its own solves a lot of the same problems tRPC was designed to solve, so you may not need tRPC at all.\n\nThere are also not a one-size-fits-all way to integrate tRPC with RSCs, so see this guide as a starting point and adjust it to your needs and preferences.\n\nINFO\n\nIf you're looking for how to use tRPC with Server Actions, check out this blog post by Julius.\n\nCAUTION\n\nPlease read React Query's Advanced Server Rendering docs before proceeding to understand the different types of server rendering and what footguns to avoid.\n\nAdd tRPC to existing projects​\n1. Install deps​\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install @trpc/server @trpc/client @trpc/react-query @tanstack/react-query@latest zod client-only server-only\n2. Create a tRPC router​\n\nInitialize your tRPC backend in trpc/init.ts using the initTRPC function, and create your first router. We're going to make a simple \"hello world\" router and procedure here - but for deeper information on creating your tRPC API you should refer to the Quickstart guide and Backend usage docs for tRPC information.\n\nINFO\n\nThe file names used here are not enforced by tRPC. You may use any file structure you wish.\n\nView sample backend\n3. Create a Query Client factory​\n\nCreate a shared file trpc/query-client.ts that exports a function that creates a QueryClient instance.\n\ntrpc/query-client.ts\nimport {\n  defaultShouldDehydrateQuery,\n  QueryClient,\n} from '@tanstack/react-query';\nimport superjson from 'superjson';\nexport function makeQueryClient() {\n  return new QueryClient({\n    defaultOptions: {\n      queries: {\n        staleTime: 30 * 1000,\n      },\n      dehydrate: {\n        // serializeData: superjson.serialize,\n        shouldDehydrateQuery: (query) =>\n          defaultShouldDehydrateQuery(query) ||\n          query.state.status === 'pending',\n      },\n      hydrate: {\n        // deserializeData: superjson.deserialize,\n      },\n    },\n  });\n}\nCopy\n\nWe're setting a few default options here:\n\nstaleTime: With SSR, we usually want to set some default staleTime above 0 to avoid refetching immediately on the client.\nshouldDehydrateQuery: This is a function that determines whether a query should be dehydrated or not. Since the RSC transport protocol supports hydrating promises over the network, we extend the defaultShouldDehydrateQuery function to also include queries that are still pending. This will allow us to start prefetching in a server component high up the tree, then consuming that promise in a client component further down.\nserializeData and deserializeData (optional): If you set up a data transformer in the previous step, set this option to make sure the data is serialized correctly when hydrating the query client over the server-client boundary.\n4. Create a tRPC client for Client Components​\n\nThe trpc/client.tsx is the entrypoint when consuming your tRPC API from client components. In here, import the type definition of your tRPC router and create typesafe hooks using createTRPCReact. We'll also export our context provider from this file.\n\ntrpc/client.tsx\n'use client';\n// ^-- to make sure we can mount the Provider from a server component\nimport type { QueryClient } from '@tanstack/react-query';\nimport { QueryClientProvider } from '@tanstack/react-query';\nimport { httpBatchLink } from '@trpc/client';\nimport { createTRPCReact } from '@trpc/react-query';\nimport { useState } from 'react';\nimport { makeQueryClient } from './query-client';\nimport type { AppRouter } from './routers/_app';\nexport const trpc = createTRPCReact<AppRouter>();\nlet clientQueryClientSingleton: QueryClient;\nfunction getQueryClient() {\n  if (typeof window === 'undefined') {\n    // Server: always make a new query client\n    return makeQueryClient();\n  }\n  // Browser: use singleton pattern to keep the same query client\n  return (clientQueryClientSingleton ??= makeQueryClient());\n}\nfunction getUrl() {\n  const base = (() => {\n    if (typeof window !== 'undefined') return '';\n    if (process.env.VERCEL_URL) return `https://${process.env.VERCEL_URL}`;\n    return 'http://localhost:3000';\n  })();\n  return `${base}/api/trpc`;\n}\nexport function TRPCProvider(\n  props: Readonly<{\n    children: React.ReactNode;\n  }>,\n) {\n  // NOTE: Avoid useState when initializing the query client if you don't\n  //       have a suspense boundary between this and the code that may\n  //       suspend because React will throw away the client on the initial\n  //       render if it suspends and there is no boundary\n  const queryClient = getQueryClient();\n  const [trpcClient] = useState(() =>\n    trpc.createClient({\n      links: [\n        httpBatchLink({\n          // transformer: superjson, <-- if you use a data transformer\n          url: getUrl(),\n        }),\n      ],\n    }),\n  );\n  return (\n    <trpc.Provider client={trpcClient} queryClient={queryClient}>\n      <QueryClientProvider client={queryClient}>\n        {props.children}\n      </QueryClientProvider>\n    </trpc.Provider>\n  );\n}\nCopy\n\nMount the provider in the root of your application (e.g. app/layout.tsx when using Next.js).\n\n5. Create a tRPC caller for Server Components​\n\nTo prefetch queries from server components, we use a tRPC caller. The @trpc/react-query/rsc module exports a thin wrapper around createCaller that integrates with your React Query client.\n\ntrpc/server.tsx\nimport 'server-only'; // <-- ensure this file cannot be imported from the client\nimport { createHydrationHelpers } from '@trpc/react-query/rsc';\nimport { cache } from 'react';\nimport { createCallerFactory, createTRPCContext } from './init';\nimport { makeQueryClient } from './query-client';\nimport { appRouter } from './routers/_app';\n// IMPORTANT: Create a stable getter for the query client that\n//            will return the same client during the same request.\nexport const getQueryClient = cache(makeQueryClient);\nconst caller = createCallerFactory(appRouter)(createTRPCContext);\nexport const { trpc, HydrateClient } = createHydrationHelpers<typeof appRouter>(\n  caller,\n  getQueryClient,\n);\nCopy\nUsing your API​\n\nNow you can use your tRPC API in your app. While you can use the React Query hooks in client components just like you would in any other React app, we can take advantage of the RSC capabilities by prefetching queries in a server component high up the tree. You may be familiar with this concept as \"render as you fetch\" commonly implemented as loaders. This means the request fires as soon as possible but without suspending until the data is needed by using the useQuery or useSuspenseQuery hooks.\n\napp/page.tsx\nimport { trpc } from '~/trpc/server';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  void trpc.hello.prefetch();\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ClientGreeting />\n    </HydrateClient>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\n// <-- hooks can only be used in client components\nimport { trpc } from '~/trpc/client';\nexport function ClientGreeting() {\n  const greeting = trpc.hello.useQuery();\n  if (!greeting.data) return <div>Loading...</div>;\n  return <div>{greeting.data.greeting}</div>;\n}\nCopy\nLeveraging Suspense​\n\nYou may prefer handling loading and error states using Suspense and Error Boundaries. You can do this by using the useSuspenseQuery hook.\n\napp/page.tsx\nimport { trpc } from '~/trpc/server';\nimport { Suspense } from 'react';\nimport { ErrorBoundary } from 'react-error-boundary';\nimport { ClientGreeting } from './client-greeting';\nexport default async function Home() {\n  void trpc.hello.prefetch();\n  return (\n    <HydrateClient>\n      <div>...</div>\n      {/** ... */}\n      <ErrorBoundary fallback={<div>Something went wrong</div>}>\n        <Suspense fallback={<div>Loading...</div>}>\n          <ClientGreeting />\n        </Suspense>\n      </ErrorBoundary>\n    </HydrateClient>\n  );\n}\nCopy\napp/client-greeting.tsx\n'use client';\nimport { trpc } from '~/trpc/client';\nexport function ClientGreeting() {\n  const [data] = trpc.hello.useSuspenseQuery();\n  return <div>{data.greeting}</div>;\n}\nCopy\nGetting data in a server component​\n\nIf you need access to the data in a server component, you can invoke the procedure directly instead of using .prefetch(), just like you use the normal server caller. Please note that this method is de-attached from your query client and does not store the data in the cache. This means that you cannot use the data in a server component and expect it to be available in the client. This is intentional and explained in more detail in the Advanced Server Rendering guide.\n\napp/page.tsx\nimport { trpc } from '~/trpc/server';\nexport default async function Home() {\n  // Use the caller directly without using `.prefetch()`\n  const greeting = await trpc.hello();\n  //    ^? { greeting: string }\n  return <div>{greeting.greeting}</div>;\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/infer-types",
    "html": "Client Usage\nReact Query Integration (Classic)\nInferring Types\nVersion: 11.x\nInferring Types\n\nIn addition to the type inference made available by @trpc/server (see here) this integration also provides some inference helpers for usage purely in React.\n\nInfer React Query options based on your router​\n\nWhen creating custom hooks around tRPC procedures, it's sometimes necessary to have the types of the options inferred from the router. You can do so via the inferReactQueryProcedureOptions helper exported from @trpc/react-query.\n\ntrpc.ts\nimport {\n  createTRPCReact,\n  type inferReactQueryProcedureOptions,\n} from '@trpc/react-query';\nimport type { inferRouterInputs, inferRouterOutputs } from '@trpc/server';\nimport type { AppRouter } from './server';\n \n// infer the types for your router\nexport type ReactQueryOptions = inferReactQueryProcedureOptions<AppRouter>;\nexport type RouterInputs = inferRouterInputs<AppRouter>;\nexport type RouterOutputs = inferRouterOutputs<AppRouter>;\n \nexport const trpc = createTRPCReact<AppRouter>();\nCopy\nusePostCreate.ts\nimport {\n  trpc,\n  type ReactQueryOptions,\n  type RouterInputs,\n  type RouterOutputs,\n} from './trpc';\n \ntype PostCreateOptions = ReactQueryOptions['post']['create'];\n \nfunction usePostCreate(options?: PostCreateOptions) {\n  const utils = trpc.useUtils();\n \n  return trpc.post.create.useMutation({\n    ...options,\n    onSuccess(post) {\n      // invalidate all queries on the post router\n      // when a new post is created\n      utils.post.invalidate();\n      options?.onSuccess?.(post);\n    },\n  });\n}\nCopy\nusePostById.ts\nimport { ReactQueryOptions, RouterInputs, trpc } from './trpc';\n \ntype PostByIdOptions = ReactQueryOptions['post']['byId'];\ntype PostByIdInput = RouterInputs['post']['byId'];\n \nfunction usePostById(input: PostByIdInput, options?: PostByIdOptions) {\n  return trpc.post.byId.useQuery(input, options);\n}\nCopy\nInfer abstract types from a \"Router Factory\"​\n\nIf you write a factory which creates a similar router interface several times in your application, you may wish to share client code between usages of the factory. @trpc/react-query/shared exports several types which can be used to generate abstract types for a router factory, and build common React components which are passed the router as a prop.\n\napi/factory.ts\nimport { t, publicProcedure } from './trpc';\n \n// @trpc/react-query/shared exports several **Like types which can be used to generate abstract types\nimport { RouterLike, UtilsLike } from '@trpc/react-query/shared';\n \n// Factory function written by you, however you need,\n// so long as you can infer the resulting type of t.router() later\nexport function createMyRouter() {\n  return t.router({\n    createThing: publicProcedure\n      .input(ThingRequest)\n      .output(Thing)\n      .mutation(/* do work */),\n    listThings: publicProcedure\n      .input(ThingQuery)\n      .output(ThingArray)\n      .query(/* do work */),\n  })\n}\n \n// Infer the type of your router, and then generate the abstract types for use in the client\ntype MyRouterType = ReturnType<typeof createMyRouter>\nexport MyRouterLike = RouterLike<MyRouterType>\nexport MyRouterUtilsLike = UtilsLike<MyRouterType>\nCopy\napi/server.ts\nexport type AppRouter = typeof appRouter;\n \n// Export your MyRouter types to the client\nexport type { MyRouterLike, MyRouterUtilsLike } from './factory';\nCopy\nfrontend/usePostCreate.ts\nimport type { MyRouterLike, MyRouterUtilsLike, trpc, useUtils } from './trpc';\n \ntype MyGenericComponentProps = {\n  route: MyRouterLike;\n  utils: MyRouterUtilsLike;\n};\n \nfunction MyGenericComponent(props: MyGenericComponentProps) {\n  const { route } = props;\n  const thing = route.listThings.useQuery({\n    filter: 'qwerty',\n  });\n \n  const mutation = route.doThing.useMutation({\n    onSuccess() {\n      props.utils.listThings.invalidate();\n    },\n  });\n \n  function handleClick() {\n    mutation.mutate({\n      name: 'Thing 1',\n    });\n  }\n \n  return; /* ui */\n}\n \nfunction MyPageComponent() {\n  const utils = useUtils();\n \n  return (\n    <MyGenericComponent\n      route={trpc.deep.route.things}\n      utils={utils.deep.route.things}\n    />\n  );\n}\n \nfunction MyOtherPageComponent() {\n  const utils = useUtils();\n \n  return (\n    <MyGenericComponent\n      route={trpc.different.things}\n      utils={utils.different.things}\n    />\n  );\n}\nCopy\n\nA more complete working example can be found here\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useQuery",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseQuery()\nVersion: 11.x\nuseQuery()\n\nuseQuery is the primary hook for data fetching, it works similarly to @tanstack/react-query's useQuery, but with some trpc specific options and additional features like streaming.\n\nNOTE\n\nFor in-depth information about options and usage patterns, refer to the TanStack Query docs on queries.\n\nSignature​\nfunction useQuery(\n  input: TInput | SkipToken,\n  opts?: UseTRPCQueryOptions;\n)\ninterface UseTRPCQueryOptions\n  extends UseQueryOptions {\n  trpc: {\n    ssr?: boolean;\n    abortOnUnmount?: boolean;\n    context?: Record<string, unknown>;\n  }\n}\nCopy\n\nSince UseTRPCQueryOptions extends @tanstack/react-query's UseQueryOptions, you can use any of their options here such as enabled, refetchOnWindowFocus, etc. We also have some trpc specific options that let you opt in or out of certain behaviors on a per-procedure level:\n\ntrpc.ssr: If you have ssr: true in your global config, you can set this to false to disable ssr for this particular query. Note that this does not work the other way around, i.e., you can not enable ssr on a procedure if your global config is set to false.\ntrpc.abortOnUnmount: Override the global config and opt in or out of aborting queries on unmount.\ntrpc.context: Add extra meta data that could be used in Links.\nTIP\n\nIf you need to set any options but don't want to pass any input, you can pass undefined instead.\n\nYou'll notice that you get autocompletion on the input based on what you have set in your input schema on your backend.\n\nExample usage​\nBackend code\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  // input is optional, so we don't have to pass second argument\n  const helloNoArgs = trpc.hello.useQuery();\n  const helloWithArgs = trpc.hello.useQuery({ text: 'client' });\n  return (\n    <div>\n      <h1>Hello World Example</h1>\n      <ul>\n        <li>\n          helloNoArgs ({helloNoArgs.status}):{' '}\n          <pre>{JSON.stringify(helloNoArgs.data, null, 2)}</pre>\n        </li>\n        <li>\n          helloWithArgs ({helloWithArgs.status}):{' '}\n          <pre>{JSON.stringify(helloWithArgs.data, null, 2)}</pre>\n        </li>\n      </ul>\n    </div>\n  );\n}\nCopy\nStreaming responses using async generators​\nINFO\n\nSince v11 we now support streaming queries when using the httpBatchStreamLink.\n\nWhen returning an async generators in a query, you will:\n\nGet the results of the iterator in the data-property as an array which updates as the response comes in\nThe status will be success as soon as the first chunk is received.\nThe fetchStatus property which will be fetching until the last chunk is received.\nExample​\nserver/routers/_app.ts\nimport { publicProcedure, router } from './trpc';\nconst appRouter = router({\n  iterable: publicProcedure.query(async function* () {\n    for (let i = 0; i < 3; i++) {\n      await new Promise((resolve) => setTimeout(resolve, 500));\n      yield i;\n    }\n  }),\n});\nexport type AppRouter = typeof appRouter;\nCopy\ncomponents/MyComponent.tsx\nimport { trpc } from '~/utils';\nexport function MyComponent() {\n  const result = trpc.iterable.useQuery();\n  return (\n    <div>\n      {result.data?.map((chunk, index) => (\n        <Fragment key={index}>{chunk}</Fragment>\n      ))}\n    </div>\n  );\n}\nCopy\n\nresult properties while streaming:\n\nstatus\tfetchStatus\tdata\n'pending'\t'fetching'\tundefined\n'success'\t'fetching'\t[]\n'success'\t'fetching'\t[1]\n'success'\t'fetching'\t[1, 2]\n'success'\t'fetching'\t[1, 2, 3]\n'success'\t'idle'\t[1, 2, 3]\nEdit this page"
  },
  {
    "title": "useMutation() | tRPC",
    "url": "https://trpc.io/docs/client/react/useMutation",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseMutation()\nVersion: 11.x\nuseMutation()\nNOTE\n\nThe hooks provided by @trpc/react-query are a thin wrapper around @tanstack/react-query. For in-depth information about options and usage patterns, refer to their docs on mutations.\n\nWorks like react-query's mutations - see their docs.\n\nExample​\nBackend code\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const mutation = trpc.login.useMutation();\n  const handleLogin = () => {\n    const name = 'John Doe';\n    mutation.mutate({ name });\n  };\n  return (\n    <div>\n      <h1>Login Form</h1>\n      <button onClick={handleLogin} disabled={mutation.isPending}>\n        Login\n      </button>\n      {mutation.error && <p>Something went wrong! {mutation.error.message}</p>}\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "useInfiniteQuery | tRPC",
    "url": "https://trpc.io/docs/client/react/useInfiniteQuery",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseInfiniteQuery()\nVersion: 11.x\nuseInfiniteQuery\nINFO\nYour procedure needs to accept a cursor input of any type (string, number, etc) to expose this hook.\nFor more details on infinite queries read the react-query docs\nIn this example we're using Prisma - see their docs on cursor-based pagination\nExample Procedure​\nserver/routers/_app.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\nimport { Context } from './[trpc]';\nexport const t = initTRPC.create();\nexport const appRouter = t.router({\n  infinitePosts: t.procedure\n    .input(\n      z.object({\n        limit: z.number().min(1).max(100).nullish(),\n        cursor: z.number().nullish(), // <-- \"cursor\" needs to exist, but can be any type\n        direction: z.enum(['forward', 'backward']), // optional, useful for bi-directional query\n      }),\n    )\n    .query(async (opts) => {\n      const { input } = opts;\n      const limit = input.limit ?? 50;\n      const { cursor } = input;\n      const items = await prisma.post.findMany({\n        take: limit + 1, // get an extra item at the end which we'll use as next cursor\n        where: {\n          title: {\n            contains: 'Prisma' /* Optional filter */,\n          },\n        },\n        cursor: cursor ? { myCursor: cursor } : undefined,\n        orderBy: {\n          myCursor: 'asc',\n        },\n      });\n      let nextCursor: typeof cursor | undefined = undefined;\n      if (items.length > limit) {\n        const nextItem = items.pop();\n        nextCursor = nextItem!.myCursor;\n      }\n      return {\n        items,\n        nextCursor,\n      };\n    }),\n});\nCopy\nExample React Component​\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const myQuery = trpc.infinitePosts.useInfiniteQuery(\n    {\n      limit: 10,\n    },\n    {\n      getNextPageParam: (lastPage) => lastPage.nextCursor,\n      // initialCursor: 1, // <-- optional you can pass an initialCursor\n    },\n  );\n  // [...]\n}\nCopy\nHelpers​\ngetInfiniteData()​\n\nThis helper gets the currently cached data from an existing infinite query\n\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const utils = trpc.useUtils();\n  const myMutation = trpc.infinitePosts.add.useMutation({\n    async onMutate(opts) {\n      await utils.infinitePosts.cancel();\n      const allPosts = utils.infinitePosts.getInfiniteData({ limit: 10 });\n      // [...]\n    },\n  });\n}\nCopy\nsetInfiniteData()​\n\nThis helper allows you to update a query's cached data\n\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const utils = trpc.useUtils();\n  const myMutation = trpc.infinitePosts.delete.useMutation({\n    async onMutate(opts) {\n      await utils.infinitePosts.cancel();\n      utils.infinitePosts.setInfiniteData({ limit: 10 }, (data) => {\n        if (!data) {\n          return {\n            pages: [],\n            pageParams: [],\n          };\n        }\n        return {\n          ...data,\n          pages: data.pages.map((page) => ({\n            ...page,\n            items: page.items.filter((item) => item.status === 'published'),\n          })),\n        };\n      });\n    },\n  });\n  // [...]\n}\nCopy\nEdit this page"
  },
  {
    "title": "useSubscription() | tRPC",
    "url": "https://trpc.io/docs/client/react/useSubscription",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseSubscription()\nVersion: 11.x\nuseSubscription()\n\nThe useSubscription hook can be used to subscribe to a subscription procedure on the server.\n\nSignature​\nOptions​\nTIP\nIf you need to set any options but don't want to pass any input, you can pass undefined instead.\nIf you pass skipToken from @tanstack/react-query, the subscription will be paused.\nHave a look at our SSE example for a complete example of how to use subscriptions\nfunction useSubscription<TOutput, TError>(\n  input: TInput | SkipToken,\n  opts?: UseTRPCSubscriptionOptions<TOutput, TError>,\n): TRPCSubscriptionResult<TOutput, TError>;\ninterface UseTRPCSubscriptionOptions<TOutput, TError> {\n  /**\n   * Callback invoked when the subscription starts.\n   */\n  onStarted?: () => void;\n  /**\n   * Callback invoked when new data is received from the subscription.\n   * @param data - The data received.\n   */\n  onData?: (data: TOutput) => void;\n  /**\n   * Callback invoked when an **unrecoverable error** occurs and the subscription is stopped.\n   */\n  onError?: (error: TError) => void;\n  /**\n   * Callback invoked when the subscription is completed.\n   */\n  onComplete?: () => void;\n  /**\n   * @deprecated Use a `skipToken` from `@tanstack/react-query` instead.\n   * This will be removed in a future version.\n   */\n  enabled?: boolean;\n}\nCopy\nReturn type​\ntype TRPCSubscriptionResult<TOutput, TError> = {\n  /**\n   * The current status of the subscription.\n   * Will be one of: `'idle'`, `'connecting'`, `'pending'`, or `'error'`.\n   *\n   * - `idle`: subscription is disabled or ended\n   * - `connecting`: trying to establish a connection\n   * - `pending`: connected to the server, receiving data\n   * - `error`: an error occurred and the subscription is stopped\n   */\n  status: 'idle' | 'connecting' | 'pending' | 'error';\n  /**\n   * The last data received from the subscription.\n   */\n  data: TOutput | undefined;\n  /**\n   * The last error received - will be `null` whenever the status is `'pending'` or `'idle'`\n   * - has a value only when the status is `'error'`\n   * - *may* have a value when the status is `'connecting'`\n   */\n  error: TRPCClientError | null;\n  /**\n   * Function to reset the subscription.\n   */\n  reset: () => void;\n};\nCopy\nExample​\ncomponents/MyComponent.tsx\nimport { trpc } from '../utils/trpc';\nexport function MyComponent() {\n  const [numbers, setNumbers] = React.useState<number[]>([]);\n  const result = trpc.onNumber.useSubscription(undefined, {\n    onData: (num) => {\n      setNumbers((prev) => [...prev, num]);\n    },\n  });\n  return (\n    <div>\n      <h1>Subscription Example</h1>\n      <p>\n        {result.status}: <pre>{JSON.stringify(result.data, null, 2)}</pre>\n      </p>\n      <h2>Previous numbers:</h2>\n      <ul>\n        {numbers.map((num, i) => (\n          <li key={i}>{num}</li>\n        ))}\n      </ul>\n      {result.status === 'error' && (\n        <button onClick={() => result.reset()}>\n          Something went wrong - restart the subscription\n        </button>\n      )}\n    </div>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useUtils",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseUtils()\nVersion: 11.x\nuseUtils\n\nuseUtils is a hook that gives you access to helpers that let you manage the cached data of the queries you execute via @trpc/react-query. These helpers are actually thin wrappers around @tanstack/react-query's queryClient methods. If you want more in-depth information about options and usage patterns for useContext helpers than what we provide here, we will link to their respective @tanstack/react-query docs so you can refer to them accordingly.\n\nNOTE\n\nThis hook was called useContext() until 10.41.0 (and is still aliased for the foreseeable future)\n\nUsage​\n\nuseUtils returns an object with all the available queries you have in your routers. You use it the same way as your trpc client object. Once you reach a query, you'll have access to the query helpers. For example, let's say you have a post router with an all query:\n\nserver.ts\n// @filename: server.ts\nimport { initTRPC } from '@trpc/server';\nimport { z } from 'zod';\n \nconst t = initTRPC.create();\n \nconst appRouter = t.router({\n  post: t.router({\n    all: t.procedure.query(() => {\n      return {\n        posts: [\n          { id: 1, title: 'everlong' },\n          { id: 2, title: 'After Dark' },\n        ],\n      };\n    }),\n  }),\n});\n \nexport type AppRouter = typeof appRouter;\nCopy\n\nNow in our component, when we navigate the object useUtils gives us and reach the post.all query, we'll get access to our query helpers!\n\nMyComponent.tsx\nfunction MyComponent() {\n  const utils = trpc.useUtils();\n  utils.post.all.f;\n                  \nfetch\nfetchInfinite\n  // [...]\n}\nCopy\nHelpers​\n\nThese are the helpers you'll get access to via useUtils. The table below will help you know which tRPC helper wraps which @tanstack/react-query helper method. Each react-query method will link to its respective docs/guide:\n\ntRPC helper wrapper\t@tanstack/react-query helper method\nfetch\tqueryClient.fetchQuery\nprefetch\tqueryClient.prefetchQuery\nfetchInfinite\tqueryClient.fetchInfiniteQuery\nprefetchInfinite\tqueryClient.prefetchInfiniteQuery\nensureData\tqueryClient.ensureData\ninvalidate\tqueryClient.invalidateQueries\nrefetch\tqueryClient.refetchQueries\ncancel\tqueryClient.cancelQueries\nsetData\tqueryClient.setQueryData\nsetQueriesData\tqueryClient.setQueriesData\ngetData\tqueryClient.getQueryData\nsetInfiniteData\tqueryClient.setInfiniteQueryData\ngetInfiniteData\tqueryClient.getInfiniteData\nsetMutationDefaults\tqueryClient.setMutationDefaults\ngetMutationDefaults\tqueryClient.getMutationDefaults\nisMutating\tqueryClient.isMutating\n❓ The function I want isn't here!​\n\n@tanstack/react-query has a lot of functions that we haven't put in the tRPC context yet. If you need a function that isn't here, feel free to open a feature request requesting it.\n\nIn the meantime, you can import and use the function directly from @tanstack/react-query. We also provide a getQueryKey which you can use to get the correct queryKey on the filters when using these functions.\n\nProxy client​\n\nIn addition to the above react-query helpers, the context also exposes your tRPC proxy client. This lets you call your procedures with async/await without needing to create an additional vanilla client.\n\nimport { trpc } from '../utils/trpc';\nfunction MyComponent() {\n  const [apiKey, setApiKey] = useState();\n  const utils = trpc.useUtils();\n  return (\n    <Form\n      handleSubmit={async (event) => {\n        const apiKey = await utils.client.apiKey.create.mutate(event);\n        setApiKey(apiKey);\n      }}\n    >\n      ...\n    </Form>\n  );\n}\nCopy\nQuery Invalidation​\n\nYou invalidate queries via the invalidate helper. invalidate is actually a special helper given that, unlike the other helpers, it's available at every level of the router map. This means you can either run invalidate on a single query, a whole router, or every router if you want. We get more in detail in the sections below.\n\nInvalidating a single query​\n\nYou can invalidate a query relating to a single procedure and even filter based on the input passed to it to prevent unnecessary calls to the back end.\n\nExample code​\nimport { trpc } from '../utils/trpc';\nfunction MyComponent() {\n  const utils = trpc.useUtils();\n  const mutation = trpc.post.edit.useMutation({\n    onSuccess(input) {\n      utils.post.all.invalidate();\n      utils.post.byId.invalidate({ id: input.id }); // Will not invalidate queries for other id's 👍\n    },\n  });\n  // [...]\n}\nCopy\nInvalidating across whole routers​\n\nIt is also possible to invalidate queries across an entire router rather then just one query.\n\nExample code​\nBackend code\nimport { trpc } from '../utils/trpc';\nfunction MyComponent() {\n  const utils = trpc.useUtils();\n  const invalidateAllQueriesAcrossAllRouters = () => {\n    // 1️⃣\n    // All queries on all routers will be invalidated 🔥\n    utils.invalidate();\n  };\n  const invalidateAllPostQueries = () => {\n    // 2️⃣\n    // All post queries will be invalidated 📭\n    utils.post.invalidate();\n  };\n  const invalidatePostById = () => {\n    // 3️⃣\n    // All queries in the post router with input {id:1} invalidated 📭\n    utils.post.byId.invalidate({ id: 1 });\n  };\n  // Example queries\n  trpc.user.all.useQuery(); // Would only be validated by 1️⃣ only.\n  trpc.post.all.useQuery(); // Would be invalidated by 1️⃣ & 2️⃣\n  trpc.post.byId.useQuery({ id: 1 }); // Would be invalidated by 1️⃣, 2️⃣ and 3️⃣\n  trpc.post.byId.useQuery({ id: 2 }); // would be invalidated by 1️⃣ and 2️⃣ but NOT 3️⃣!\n  // [...]\n}\nCopy\nInvalidate full cache on every mutation​\n\nKeeping track of exactly what queries a mutation should invalidate is hard, therefore, it can be a pragmatic solution to invalidate the full cache as a side-effect on any mutation. Since we have request batching, this invalidation will simply refetch all queries on the page you're looking at in one single request.\n\nWe have added a feature to help with this:\n\nexport const trpc = createTRPCReact<AppRouter, SSRContext>({\n  overrides: {\n    useMutation: {\n      /**\n       * This function is called whenever a `.useMutation` succeeds\n       **/\n      async onSuccess(opts) {\n        /**\n         * @note that order here matters:\n         * The order here allows route changes in `onSuccess` without\n         * having a flash of content change whilst redirecting.\n         **/\n        // Calls the `onSuccess` defined in the `useQuery()`-options:\n        await opts.originalFn();\n        // Invalidate all queries in the react-query cache:\n        await opts.queryClient.invalidateQueries();\n      },\n    },\n  },\n});\nCopy\nAdditional Options​\n\nAside from the query helpers, the object useUtils returns also contains the following properties:\n\ninterface ProxyTRPCContextProps<TRouter extends AnyRouter, TSSRContext> {\n  /**\n   * The `TRPCClient`\n   */\n  client: TRPCClient<TRouter>;\n  /**\n   * The SSR context when server-side rendering\n   * @default null\n   */\n  ssrContext?: TSSRContext | null;\n  /**\n   * State of SSR hydration.\n   * - `false` if not using SSR.\n   * - `prepass` when doing a prepass to fetch queries' data\n   * - `mounting` before TRPCProvider has been rendered on the client\n   * - `mounted` when the TRPCProvider has been rendered on the client\n   * @default false\n   */\n  ssrState?: SSRState;\n  /**\n   * Abort loading query calls when unmounting a component - usually when navigating to a new page\n   * @default false\n   */\n  abortOnUnmount?: boolean;\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/createTRPCQueryUtils",
    "html": "Client Usage\nReact Query Integration (Classic)\ncreateTRPCQueryUtils()\nVersion: 11.x\ncreateTRPCQueryUtils\n\nThe use case for createTRPCQueryUtils is when you need to use the helpers outside of a React Component, for example in react-routers loaders.\n\nSimilar to useUtils, createTRPCQueryUtils is a function that gives you access to helpers that let you manage the cached data of the queries you execute via @trpc/react-query. These helpers are actually thin wrappers around @tanstack/react-query's queryClient methods. If you want more in-depth information about options and usage patterns for useUtils helpers than what we provide here, we will link to their respective @tanstack/react-query docs so you can refer to them accordingly.\n\nThe difference between useUtils and createTRPCQueryUtils is that useUtils is a react hook that uses useQueryClient under the hood. This means that it is able to work better within React Components.\n\nIf you need access to the client directly, you can use the client object that you passed to createTRPCQueryUtils during creation.\n\nCAUTION\n\nYou should avoid using createTRPCQueryUtils in React Components. Instead, use useUtils which is a React hook that implements useCallback and useQueryClient under the hood.\n\nUsage​\n\ncreateTRPCQueryUtils returns an object with all the available queries you have in your routers. You use it the same way as your trpc client object. Once you reach a query, you'll have access to the query helpers. For example, let's say you have a post router with an all query:\n\nNow in our component, when we navigate the object createTRPCQueryUtils gives us and reach the post.all query, we'll get access to our query helpers!\n\nMyPage.tsx\nimport { QueryClient } from '@tanstack/react-query';\nimport { createTRPCQueryUtils, createTRPCReact } from '@trpc/react-query';\nimport { useLoaderData } from 'react-router-dom';\nimport type { AppRouter } from './server';\nconst trpc = createTRPCReact<AppRouter>();\nconst trpcClient = trpc.createClient({ links: [] });\nconst queryClient = new QueryClient();\nconst clientUtils = createTRPCQueryUtils({ queryClient, client: trpcClient });\n// This is a react-router loader\nexport async function loader() {\n  const allPostsData = await clientUtils.post.all.ensureData(); // Fetches data if it doesn't exist in the cache\n  return {\n    allPostsData,\n  };\n}\n// This is a react component\nexport function Component() {\n  const loaderData = useLoaderData() as Awaited<ReturnType<typeof loader>>;\n  const allPostQuery = trpc.post.all.useQuery({\n    initialData: loaderData.allPostsData, // Uses the data from the loader\n  });\n  return (\n    <div>\n      {allPostQuery.data.posts.map((post) => (\n        <div key={post.id}>{post.title}</div>\n      ))}\n    </div>\n  );\n}\nCopy\nNOTE\n\nIf you were using Remix Run or SSR you wouldn't re-use the same queryClient for every request. Instead, you would create a new queryClient for every request so that there's no cross-request data leakage.\n\nHelpers​\n\nMuch like useUtils, createTRPCQueryUtils gives you access to same set of helpers. The only difference is that you need to pass in the queryClient and client objects.\n\nYou can see them on the useUtils-page.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/useQueries",
    "html": "Client Usage\nReact Query Integration (Classic)\nuseQueries()\nVersion: 11.x\nuseQueries()\n\nThe useQueries hook can be used to fetch a variable number of queries at the same time using only one hook call.\n\nThe main use case for such a hook is to be able to fetch a number of queries, usually of the same type. For example if you fetch a list of todo ids, you can then map over them in a useQueries hook calling a byId endpoint that would fetch the details of each todo.\n\nNOTE\n\nWhile fetching multiple types in a useQueries hook is possible, there is not much of an advantage compared to using multiple useQuery calls unless you use the suspense option as that useQueries can trigger suspense in parallel while multiple useQuery calls would waterfall.\n\nUsage​\n\nThe useQueries hook is the same as that of @tanstack/query useQueries. The only difference is that you pass in a function that returns an array of queries instead of an array of queries inside an object parameter.\n\nTIP\n\nWhen you're using the httpBatchLink or wsLink, the below will end up being only 1 HTTP call to your server. Additionally, if the underlying procedure is using something like Prisma's findUnique() it will automatically batch & do exactly 1 database query as a well.\n\nconst Component = (props: { postIds: string[] }) => {\n  const postQueries = trpc.useQueries((t) =>\n    props.postIds.map((id) => t.post.byId({ id })),\n  );\n  return <>{/* [...] */}</>;\n};\nCopy\nProviding options to individual queries​\n\nYou can also pass in any normal query options to the second parameter of any of the query calls in the array such as enabled, suspense, refetchOnWindowFocus...etc. For a complete overview of all the available options, see the tanstack useQuery documentation.\n\nconst Component = () => {\n  const [post, greeting] = trpc.useQueries((t) => [\n    t.post.byId({ id: '1' }, { enabled: false }),\n    t.greeting({ text: 'world' }),\n  ]);\n  const onButtonClick = () => {\n    post.refetch();\n  };\n  return (\n    <div>\n      <h1>{post.data && post.data.title}</h1>\n      <p>{greeting.data.message}</p>\n      <button onClick={onButtonClick}>Click to fetch</button>\n    </div>\n  );\n};\nCopy\nContext​\n\nYou can also pass in an optional React Query context to override the default.\n\nconst [post, greeting] = trpc.useQueries(\n  (t) => [t.post.byId({ id: '1' }), t.greeting({ text: 'world' })],\n  myCustomContext,\n);\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/react/suspense",
    "html": "Client Usage\nReact Query Integration (Classic)\nSuspense\nVersion: 11.x\nSuspense\nINFO\nEnsure you're on the latest version of React\nIf you use suspense with tRPC's automatic SSR in Next.js, the full page will crash on the server if a query fails, even if you have an <ErrorBoundary />\nUsage​\nTIP\n\nuseSuspenseQuery & useSuspenseInfiniteQuery both return a [data, query]-tuple, to make it easy to directly use your data and renaming the variable to something descriptive\n\nuseSuspenseQuery()​\n// @filename: pages/index.tsx\nimport React from 'react';\nimport { trpc } from '../utils/trpc';\n \nfunction PostView() {\n  const [post, postQuery] = trpc.post.byId.useSuspenseQuery({ id: '1' });\n          \nconst post: {\n    id: string;\n    title: string;\n}\n \n  return <>{/* ... */}</>;\n}\nCopy\nuseSuspenseInfiniteQuery()​\n// @filename: pages/index.tsx\nimport React from 'react';\nimport { trpc } from '../utils/trpc';\nfunction PostView() {\n  const [{ pages }, allPostsQuery] = trpc.post.all.useSuspenseInfiniteQuery(\n    {},\n    {\n      getNextPageParam(lastPage) {\n        return lastPage.nextCursor;\n      },\n    },\n  );\n  const { isFetching, isFetchingNextPage, fetchNextPage, hasNextPage } =\n    allPostsQuery;\n  return <>{/* ... */}</>;\n}\nCopy\nuseSuspenseQueries()​\n\nSuspense equivalent of useQueries().\n\nconst Component = (props: { postIds: string[] }) => {\n  const [posts, postQueries] = trpc.useSuspenseQueries((t) =>\n    props.postIds.map((id) => t.post.byId({ id })),\n  );\n  return <>{/* [...] */}</>;\n};\nCopy\nPrefetching​\n\nThe performance of suspense queries can be improved by prefetching the query data before the Suspense component is rendered (this is sometimes called \"render-as-you-fetch\").\n\nNOTE\nPrefetching and the render-as-you-fetch model are very dependent on the framework and router you are using. We recommend reading your frameworks router docs along with the @tanstack/react-query docs to understand how to implement these patterns.\nIf you are using Next.js please look at the docs on Server-Side Helpers to implement server-side prefetching.\nRoute-level prefetching​\nconst utils = createTRPCQueryUtils({ queryClient, client: trpcClient });\n// tanstack router/ react router loader\nconst loader = async (params: { id: string }) =>\n  utils.post.byId.ensureQueryData({ id: params.id });\nCopy\nComponent-level prefetching with usePrefetchQuery​\nimport { trpc } from '../utils/trpc';\nfunction PostViewPage(props: { postId: string }) {\n  trpc.post.byId.usePrefetchQuery({ id: props.postId });\n  return (\n    <Suspense>\n      <PostView postId={props.postId} />\n    </Suspense>\n  );\n}\nCopy\nComponent-level prefetching with usePrefetchInfiniteQuery​\nimport { trpc } from '../utils/trpc';\n// will have to be passed to the child PostView `useSuspenseInfiniteQuery`\nexport const getNextPageParam = (lastPage) => lastPage.nextCursor;\nfunction PostViewPage(props: { postId: string }) {\n  trpc.post.all.usePrefetchInfiniteQuery({}, { getNextPageParam });\n  return (\n    <Suspense>\n      <PostView postId={props.postId} />\n    </Suspense>\n  );\n}\nCopy\nEdit this page"
  },
  {
    "title": "getQueryKey | tRPC",
    "url": "https://trpc.io/docs/client/react/getQueryKey",
    "html": "Client Usage\nReact Query Integration (Classic)\ngetQueryKey()\nVersion: 11.x\ngetQueryKey\n\nWe provide a getQueryKey helper that accepts a router or procedure so that you can easily provide the native function the correct query key.\n\n// Queries\nfunction getQueryKey(\n  procedure: AnyQueryProcedure,\n  input?: DeepPartial<TInput>,\n  type?: QueryType; /** @default 'any' */\n): TRPCQueryKey;\n// Routers\nfunction getQueryKey(\n  router: AnyRouter,\n): TRPCQueryKey;\ntype QueryType = \"query\" | \"infinite\" | \"any\";\n// for useQuery ──┘         │            │\n// for useInfiniteQuery ────┘            │\n// will match all ───────────────────────┘\nCopy\nNOTE\n\nThe query type any will match all queries in the cache only if the react query method where it's used uses fuzzy matching. See TanStack/query#5111 (comment) for more context.\n\nimport { useIsFetching, useQueryClient } from '@tanstack/react-query';\nimport { getQueryKey } from '@trpc/react-query';\nimport { trpc } from '~/utils/trpc';\nfunction MyComponent() {\n  const queryClient = useQueryClient();\n  const posts = trpc.post.list.useQuery();\n  // See if a query is fetching\n  const postListKey = getQueryKey(trpc.post.list, undefined, 'query');\n  const isFetching = useIsFetching(postListKey);\n  // Set some query defaults for an entire router\n  const postKey = getQueryKey(trpc.post);\n  queryClient.setQueryDefaults(postKey, { staleTime: 30 * 60 * 1000 });\n  // ...\n}\nCopy\nMutations​\n\nSimilarly to queries, we provide a getMutationKey for mutations. The underlying function is the same as getQueryKey (in fact, you could technically use getQueryKey for mutations as well), the only difference is in semantics.\n\nfunction getMutationKey(procedure: AnyMutationProcedure): TRPCMutationKey;\nCopy\nEdit this page"
  },
  {
    "title": "Aborting Procedure Calls | tRPC",
    "url": "https://trpc.io/docs/client/react/aborting-procedure-calls",
    "html": "Client Usage\nReact Query Integration (Classic)\nAborting Procedure Calls\nVersion: 11.x\nAborting Procedure Calls\n\nBy default, tRPC does not cancel requests via React Query. If you want to opt into this behaviour, you can provide abortOnUnmount in your configuration.\n\nNOTE\n\n@tanstack/react-query only supports aborting queries.\n\nGlobally​\nclient.ts\n// @filename: utils.ts\nimport { createTRPCReact } from '@trpc/react-query';\n \nexport const trpc = createTRPCReact<AppRouter>({\n  abortOnUnmount: true,\n});\n \ntrpc.createClient({\n  // ...\n});\nCopy\nPer-request​\n\nYou may also override this behaviour at the query level.\n\npages/post/[id].tsx\nimport { trpc } from '../utils/trpc';\n \nfunction PostViewPage() {\n  const { query } = useRouter();\n  const postQuery = trpc.post.byId.useQuery(\n    { id: query.id },\n    { trpc: { abortOnUnmount: true } }\n  );\n \n  // ...\n}\nCopy\nEdit this page"
  },
  {
    "title": "HTTP Link | tRPC",
    "url": "https://trpc.io/docs/client/links/httpLink",
    "html": "Client Usage\nLinks\nHTTP Link\nVersion: 11.x\nHTTP Link\n\nhttpLink is a terminating link that sends a tRPC operation to a tRPC procedure over HTTP.\n\nhttpLink supports both POST and GET requests.\n\nUsage​\n\nYou can import and add the httpLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpLink({\n      url: 'http://localhost:3000',\n      // transformer,\n    }),\n  ],\n});\nCopy\nhttpLink Options​\n\nThe httpLink function takes an options object that has the HTTPLinkOptions shape.\n\nexport interface HTTPLinkOptions {\n  url: string;\n  /**\n   * Add ponyfill for fetch\n   */\n  fetch?: typeof fetch;\n  /**\n   * Add ponyfill for AbortController\n   */\n  AbortController?: typeof AbortController | null;\n  /**\n   * Data transformer\n   * @see https://trpc.io/docs/v11/data-transformers\n   **/\n  transformer?: DataTransformerOptions;\n  /**\n   * Headers to be set on outgoing requests or a callback that of said headers\n   * @see http://trpc.io/docs/v10/header\n   */\n  headers?:\n    | HTTPHeaders\n    | ((opts: { op: Operation }) => HTTPHeaders | Promise<HTTPHeaders>);\n  /**\n   * Send all requests as POSTS requests regardless of the procedure type\n   * The server must separately allow overriding the method. See:\n   * @see https://trpc.io/docs/rpc\n   */\n  methodOverride?: 'POST';\n}\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/httpBatchLink",
    "html": "Client Usage\nLinks\nHTTP Batch Link\nVersion: 11.x\nHTTP Batch Link\n\nhttpBatchLink is a terminating link that batches an array of individual tRPC operations into a single HTTP request that's sent to a single tRPC procedure.\n\nUsage​\n\nYou can import and add the httpBatchLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000',\n    }),\n    // transformer,\n  ],\n});\nCopy\n\nAfter that, you can make use of batching by setting all your procedures in a Promise.all. The code below will produce exactly one HTTP request and on the server exactly one database query:\n\nconst somePosts = await Promise.all([\n  trpc.post.byId.query(1),\n  trpc.post.byId.query(2),\n  trpc.post.byId.query(3),\n]);\nCopy\nhttpBatchLink Options​\n\nThe httpBatchLink function takes an options object that has the HTTPBatchLinkOptions shape.\n\nexport interface HTTPBatchLinkOptions extends HTTPLinkOptions {\n  /**\n   * Maximum length of HTTP URL allowed before operations are split into multiple requests\n   * @default Infinity\n   */\n  maxURLLength?: number;\n  /**\n   * Maximum number of operations allowed in a single batch request\n   * @default Infinity\n   */\n  maxItems?: number;\n}\nexport interface HTTPLinkOptions {\n  url: string;\n  /**\n   * Add ponyfill for fetch\n   */\n  fetch?: typeof fetch;\n  /**\n   * Add ponyfill for AbortController\n   */\n  AbortController?: typeof AbortController | null;\n  /**\n   * Data transformer\n   * @see https://trpc.io/docs/data-transformers\n   **/\n  transformer?: DataTransformerOptions;\n  /**\n   * Headers to be set on outgoing requests or a callback that of said headers\n   * @see http://trpc.io/docs/header\n   */\n  headers?:\n    | HTTPHeaders\n    | ((opts: { opList: Operation[] }) => HTTPHeaders | Promise<HTTPHeaders>);\n}\nCopy\nSetting a maximum URL length​\n\nWhen sending batch requests, sometimes the URL can become too large causing HTTP errors like 413 Payload Too Large, 414 URI Too Long, and 404 Not Found. The maxURLLength option will limit the number of requests that can be sent together in a batch.\n\nAn alternative way of doing this is to\n\nclient/index.ts\nimport { createTRPCClient, httpBatchLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchLink({\n      url: 'http://localhost:3000',\n      maxURLLength: 2083, // a suitable size\n      // alternatively, you can make all RPC-calls to be called with POST\n      // methodOverride: 'POST',\n    }),\n  ],\n});\nCopy\nDisabling request batching​\n1. Disable batching on your server:​\nserver.ts\nimport { createHTTPServer } from '@trpc/server/adapters/standalone';\ncreateHTTPServer({\n  // [...]\n  // 👇 disable batching\n  allowBatching: false,\n});\nCopy\n\nor, if you're using Next.js:\n\npages/api/trpc/[trpc].ts\nexport default trpcNext.createNextApiHandler({\n  // [...]\n  // 👇 disable batching\n  allowBatching: false,\n});\nCopy\n2. Replace httpBatchLink with httpLink in your tRPC Client​\nclient/index.ts\nimport { createTRPCClient, httpLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nor, if you're using Next.js:\n\nutils/trpc.ts\nimport type { AppRouter } from '@/server/routers/app';\nimport { httpLink } from '@trpc/client';\nimport { createTRPCNext } from '@trpc/next';\nexport const trpc = createTRPCNext<AppRouter>({\n  config() {\n    return {\n      links: [\n        httpLink({\n          url: '/api/trpc',\n        }),\n      ],\n    };\n  },\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/httpBatchStreamLink",
    "html": "Client Usage\nLinks\nHTTP Batch Stream Link\nVersion: 11.x\nHTTP Batch Stream Link\n\nhttpBatchStreamLink is a terminating link that batches an array of individual tRPC operations into a single HTTP request that's sent to a single tRPC procedure (equivalent to httpBatchLink), but doesn't wait for all the responses of the batch to be ready and streams the responses as soon as any data is available.\n\nOptions​\n\nOptions are identical to httpBatchLink options.\n\nUsage​\n\nAll usage and options are identical to httpBatchLink.\n\nNOTE\n\nIf you require the ability to change/set response headers (which includes cookies) from within your procedures, make sure to use httpBatchLink instead! This is due to the fact that httpBatchStreamLink does not support setting headers once the stream has begun. Read more.\n\nYou can import and add the httpBatchStreamLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpBatchStreamLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchStreamLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nAfter that, you can make use of batching by setting all your procedures in a Promise.all. The code below will produce exactly one HTTP request and on the server exactly one database query:\n\nconst somePosts = await Promise.all([\n  trpc.post.byId.query(1),\n  trpc.post.byId.query(2),\n  trpc.post.byId.query(3),\n]);\nCopy\nStreaming mode​\n\nWhen batching requests together, the behavior of a regular httpBatchLink is to wait for all requests to finish before sending the response. If you want to send responses as soon as they are ready, you can use httpBatchStreamLink instead. This is useful for long-running requests.\n\nclient/index.ts\nimport { createTRPCClient, httpBatchStreamLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchStreamLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nCompared to a regular httpBatchLink, a httpBatchStreamLink will:\n\nCause the requests to be sent with a trpc-accept: application/jsonl header\nCause the response to be sent with a transfer-encoding: chunked and content-type: application/jsonl\nRemove the data key from the argument object passed to responseMeta (because with a streamed response, the headers are sent before the data is available)\nAsync generators and deferred promises​\n\nYou can try this out on the homepage of tRPC.io: https://trpc.io/?try=minimal#try-it-out\n\n// @filename: server.ts\nimport { publicProcedure, router } from './trpc';\n \nconst appRouter = router({\n  examples: {\n    iterable: publicProcedure.query(async function* () {\n      for (let i = 0; i < 3; i++) {\n        await new Promise((resolve) => setTimeout(resolve, 500));\n        yield i;\n      }\n    }),\n  },\n});\n \nexport type AppRouter = typeof appRouter;\n \n \n// @filename: client.ts\nimport { createTRPCClient, httpBatchStreamLink } from '@trpc/client';\nimport type { AppRouter } from './server';\n \nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    httpBatchStreamLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nconst iterable = await trpc.examples.iterable.query();\n         \nconst iterable: AsyncIterable<number, never, unknown>\n \nfor await (const value of iterable) {\n  console.log('Iterable:', value);\n                            \nconst value: number\n}\nCopy\nCompatibility (client-side)​\nBrowsers​\n\nBrowser support should be identical to fetch support.\n\nNode.js / Deno​\n\nFor runtimes other than the browser ones, the fetch implementation should support streaming, meaning that the response obtained by await fetch(...) should have a body property of type ReadableStream<Uint8Array> | NodeJS.ReadableStream, meaning that:\n\neither response.body.getReader is a function that returns a ReadableStreamDefaultReader<Uint8Array> object\nor response.body is a Uint8Array Buffer\n\nThis includes support for undici, node-fetch, native Node.js fetch implementation, and WebAPI fetch implementation (browsers).\n\nReact Native​\n\nReceiving the stream relies on the TextDecoder and TextDecoderStream APIs, which is not available in React Native. It's important to note that if your TextDecoderStream polyfill does not automatically polyfill ReadableStream and WritableStream those will also need to be polyfilled. If you still want to enable streaming, you need to polyfill those.\n\nYou will also need to overide the default fetch in the httpBatchStreamLink configuration options. In the below example we will be using the Expo fetch package for the fetch implementation.\n\nhttpBatchStreamLink({\n  fetch: (url, opts) =>\n    fetch(url, {\n      ...opts,\n      reactNative: { textStreaming: true },\n    }),\n  ...restOfConfig,\n});\nCopy\nCompatibility (server-side)​\n\n⚠️ for aws lambda, httpBatchStreamLink is not supported (will simply behave like a regular httpBatchLink). It should not break anything if enabled, but will not have any effect.\n\n⚠️ for cloudflare workers, you need to enable the ReadableStream API through a feature flag: streams_enable_constructors\n\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nConfigure a ping option to keep the connection alive​\n\nWhen setting up your root config, you can pass in a jsonl option to configure a ping option to keep the connection alive.\n\nimport { initTRPC } from '@trpc/server';\nconst t = initTRPC.create({\n  jsonl: {\n    pingMs: 1000,\n  },\n});\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/httpSubscriptionLink",
    "html": "Client Usage\nLinks\nHTTP Subscription Link\nVersion: 11.x\nHTTP Subscription Link\n\nhttpSubscriptionLink is a terminating link that's uses Server-sent Events (SSE) for subscriptions.\n\nSSE is a good option for real-time as it's a bit easier than setting up a WebSockets-server.\n\nSetup​\nINFO\n\nIf your client's environment doesn't support EventSource, you need an EventSource polyfill. For React Native specific instructions please defer to the compatibility section.\n\nTo use httpSubscriptionLink, you need to use a splitLink to make it explicit that we want to use SSE for subscriptions.\n\nclient/index.ts\nimport type { TRPCLink } from '@trpc/client';\nimport {\n  httpBatchLink,\n  httpSubscriptionLink,\n  loggerLink,\n  splitLink,\n} from '@trpc/client';\nconst trpcClient = createTRPCClient<AppRouter>({\n  /**\n   * @see https://trpc.io/docs/v11/client/links\n   */\n  links: [\n    // adds pretty logs to your console in development and logs errors in production\n    loggerLink(),\n    splitLink({\n      // uses the httpSubscriptionLink for subscriptions\n      condition: (op) => op.type === 'subscription',\n      true: httpSubscriptionLink({\n        url: `/api/trpc`,\n      }),\n      false: httpBatchLink({\n        url: `/api/trpc`,\n      }),\n    }),\n  ],\n});\nCopy\nTIP\n\nThe document here outlines the specific details of using httpSubscriptionLink. For general usage of subscriptions, see our subscriptions guide.\n\nHeaders and authorization / authentication​\nWeb apps​\nSame domain​\n\nIf you're doing a web application, cookies are sent as part of the request as long as your client is on the same domain as the server.\n\nCross-domain​\n\nIf the client and server are not on the same domain, you can use withCredentials: true (read more on MDN here).\n\nExample:\n\n// [...]\nhttpSubscriptionLink({\n  url: 'https://example.com/api/trpc',\n  eventSourceOptions() {\n    return {\n      withCredentials: true, // <---\n    };\n  },\n});\nCopy\nCustom headers through ponyfill​\n\nRecommended for non-web environments\n\nYou can ponyfill EventSource and use the eventSourceOptions -callback to populate headers.\n\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpSubscriptionLink,\n  splitLink,\n} from '@trpc/client';\nimport { EventSourcePolyfill } from 'event-source-polyfill';\nimport type { AppRouter } from '../server/index.js';\n// Initialize the tRPC client\nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition: (op) => op.type === 'subscription',\n      true: httpSubscriptionLink({\n        url: 'http://localhost:3000',\n        // ponyfill EventSource\n        EventSource: EventSourcePolyfill,\n        // options to pass to the EventSourcePolyfill constructor\n        eventSourceOptions: async ({ op }) => {\n          //                          ^ Includes the operation that's being executed\n          // you can use this to generate a signature for the operation\n          const signature = await getSignature(op);\n          return {\n            headers: {\n              authorization: 'Bearer supersecret',\n              'x-signature': signature,\n            },\n          };\n        },\n      }),\n      false: httpBatchLink({\n        url: 'http://localhost:3000',\n      }),\n    }),\n  ],\n});\nCopy\nUpdating configuration on an active connection​\n\nhttpSubscriptionLink leverages SSE through EventSource, ensuring that connections encountering errors like network failures or bad response codes are automatically retried. However, EventSource does not allow re-execution of the eventSourceOptions() or url() options to update its configuration, which is particularly important in scenarios where authentication has expired since the last connection.\n\nTo address this limitation, you can use a retryLink in conjunction with httpSubscriptionLink. This approach ensures that the connection is re-established with the latest configuration, including any updated authentication details.\n\nCAUTION\n\nPlease note that restarting the connection will result in the EventSource being recreated from scratch, which means any previously tracked events will be lost.\n\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpSubscriptionLink,\n  retryLink,\n  splitLink,\n} from '@trpc/client';\nimport {\n  EventSourcePolyfill,\n  EventSourcePolyfillInit,\n} from 'event-source-polyfill';\nimport type { AppRouter } from '../server/index.js';\n// Initialize the tRPC client\nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition: (op) => op.type === 'subscription',\n      false: httpBatchLink({\n        url: 'http://localhost:3000',\n      }),\n      true: [\n        retryLink({\n          retry: (opts) => {\n            opts.op.type;\n            //       ^? will always be 'subscription' since we're in a splitLink\n            const code = opts.error.data?.code;\n            if (!code) {\n              // This shouldn't happen as our httpSubscriptionLink will automatically retry within when there's a non-parsable response\n              console.error('No error code found, retrying', opts);\n              return true;\n            }\n            if (code === 'UNAUTHORIZED' || code === 'FORBIDDEN') {\n              console.log('Retrying due to 401/403 error');\n              return true;\n            }\n            return false;\n          },\n        }),\n        httpSubscriptionLink({\n          url: async () => {\n            // calculate the latest URL if needed...\n            return getAuthenticatedUri();\n          },\n          // ponyfill EventSource\n          EventSource: EventSourcePolyfill,\n          eventSourceOptions: async () => {\n            // ...or maybe renew an access token\n            const token = await auth.getOrRenewToken();\n            return {\n              headers: {\n                authorization: `Bearer ${token}`,\n              },\n            };\n          },\n        }),\n      ],\n    }),\n  ],\n});\nCopy\nConnection params​\n\nIn order to authenticate with EventSource, you can define connectionParams in httpSubscriptionLink. This will be sent as part of the URL, which is why other methods are preferred).\n\nserver/context.ts\nimport type { CreateHTTPContextOptions } from '@trpc/server/adapters/standalone';\n \nexport const createContext = async (opts: CreateHTTPContextOptions) => {\n  const token = opts.info.connectionParams?.token;\n         \nconst token: string | undefined\n \n  // [... authenticate]\n \n  return {};\n};\n \nexport type Context = Awaited<ReturnType<typeof createContext>>;\nCopy\nclient/trpc.ts\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpSubscriptionLink,\n  splitLink,\n} from '@trpc/client';\nimport type { AppRouter } from '../server/index.js';\n// Initialize the tRPC client\nconst trpc = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition: (op) => op.type === 'subscription',\n      true: httpSubscriptionLink({\n        url: 'http://localhost:3000',\n        connectionParams: async () => {\n          // Will be serialized as part of the URL\n          return {\n            token: 'supersecret',\n          };\n        },\n      }),\n      false: httpBatchLink({\n        url: 'http://localhost:3000',\n      }),\n    }),\n  ],\n});\nCopy\nTimeout Configuration​\n\nThe httpSubscriptionLink supports configuring a timeout for inactivity through the reconnectAfterInactivityMs option. If no messages (including ping messages) are received within the specified timeout period, the connection will be marked as \"connecting\" and automatically attempt to reconnect.\n\nThe timeout configuration is set on the server side when initializing tRPC:\n\nserver/trpc.ts\nimport { initTRPC } from '@trpc/server';\nexport const t = initTRPC.create({\n  sse: {\n    client: {\n      reconnectAfterInactivityMs: 3_000,\n    },\n  },\n});\nCopy\nServer Ping Configuration​\n\nThe server can be configured to send periodic ping messages to keep the connection alive and prevent timeout disconnections. This is particularly useful when combined with the reconnectAfterInactivityMs-option.\n\nserver/trpc.ts\nimport { initTRPC } from '@trpc/server';\nexport const t = initTRPC.create({\n  sse: {\n    // Maximum duration of a single SSE connection in milliseconds\n    // maxDurationMs: 60_00,\n    ping: {\n      // Enable periodic ping messages to keep connection alive\n      enabled: true,\n      // Send ping message every 2s\n      intervalMs: 2_000,\n    },\n    // client: {\n    //   reconnectAfterInactivityMs: 3_000\n    // }\n  },\n});\nCopy\nCompatibility (React Native)​\n\nThe httpSubscriptionLink makes use of the EventSource API, Streams API, and AsyncIterators, these are not natively supported by React Native and will have to be ponyfilled.\n\nTo ponyfill EventSource we recommend to use a polyfill that utilizes the networking library exposed by React Native, over using a polyfill that using the XMLHttpRequest API. Libraries that polyfill EventSource using XMLHttpRequest fail to reconnect after the app has been in the background. Consider using the rn-eventsource-reborn package.\n\nThe Streams API can be ponyfilled using the web-streams-polyfill package.\n\nAsyncIterators can be polyfilled using the @azure/core-asynciterator-polyfill package.\n\nInstallation​\n\nInstall the required polyfills:\n\nnpm\nyarn\npnpm\nbun\ndeno\nnpm install rn-eventsource-reborn web-streams-polyfill @azure/core-asynciterator-polyfill\n\nAdd the polyfills to your project before the link is used (e.g. where you add your TRPCReact.Provider):\n\nutils/api.tsx\nimport '@azure/core-asynciterator-polyfill';\nimport { RNEventSource } from 'rn-eventsource-reborn';\nimport { ReadableStream, TransformStream } from 'web-streams-polyfill';\nglobalThis.ReadableStream = globalThis.ReadableStream || ReadableStream;\nglobalThis.TransformStream = globalThis.TransformStream || TransformStream;\nCopy\n\nOnce the ponyfills are added, you can continue setting up the httpSubscriptionLink as described in the setup section.\n\nhttpSubscriptionLink Options​\ntype HTTPSubscriptionLinkOptions<\n  TRoot extends AnyClientTypes,\n  TEventSource extends EventSourceLike.AnyConstructor = typeof EventSource,\n> = {\n  /**\n   * EventSource ponyfill\n   */\n  EventSource?: TEventSource;\n  /**\n   * EventSource options or a callback that returns them\n   */\n  eventSourceOptions?:\n    | EventSourceLike.InitDictOf<TEventSource>\n    | ((opts: {\n        op: Operation;\n      }) =>\n        | EventSourceLike.InitDictOf<TEventSource>\n        | Promise<EventSourceLike.InitDictOf<TEventSource>>);\n};\nCopy\nSSE Options on the server​\nexport interface SSEStreamProducerOptions<TValue = unknown> {\n  ping?: {\n    /**\n     * Enable ping comments sent from the server\n     * @default false\n     */\n    enabled: boolean;\n    /**\n     * Interval in milliseconds\n     * @default 1000\n     */\n    intervalMs?: number;\n  };\n  /**\n   * Maximum duration in milliseconds for the request before ending the stream\n   * @default undefined\n   */\n  maxDurationMs?: number;\n  /**\n   * End the request immediately after data is sent\n   * Only useful for serverless runtimes that do not support streaming responses\n   * @default false\n   */\n  emitAndEndImmediately?: boolean;\n  /**\n   * Client-specific options - these will be sent to the client as part of the first message\n   * @default {}\n   */\n  client?: {\n    /**\n     * Timeout and reconnect after inactivity in milliseconds\n     * @default undefined\n     */\n    reconnectAfterInactivityMs?: number;\n  };\n}\nCopy\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/localLink",
    "html": "Client Usage\nLinks\nLocal Link\nVersion: 11.x\nLocal Link\n\nlocalLink is a terminating link that allows you to make tRPC procedure calls directly in your application without going through HTTP.\n\nINFO\n\nWe have prefixed this as unstable_ as it's a new API, but you're safe to use it! Read more.\n\nUsage​\nimport { createTRPCClient, unstable_localLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    unstable_localLink({\n      router: appRouter,\n      createContext: async () => {\n        // Create your context here\n        return {};\n      },\n      onError: (opts) => {\n        // Log errors here, similarly to how you would in an API route\n        console.error('Error:', opts.error);\n      },\n    }),\n  ],\n});\nCopy\nFeatures​\nDirect procedure calls without HTTP overhead\nFull support for queries, mutations, and subscriptions\nAutomatic error handling and transformation\nSupport for abort signals\nType-safe context creation\nOptions​\n\nThe localLink accepts the following options:\n\ntype LocalLinkOptions<TRouter extends AnyRouter> = {\n  router: TRouter;\n  createContext: () => Promise<inferRouterContext<TRouter>>;\n  onError?: (opts: ErrorHandlerOptions<inferRouterContext<TRouter>>) => void;\n} & TransformerOptions<inferClientTypes<TRouter>>;\nCopy\nrouter​\n\nThe tRPC router instance to use for procedure calls.\n\ncreateContext​\n\nA function that creates the context for each procedure call. This is called for each request and should return a promise that resolves to the context object.\n\nonError​\n\nAn optional error handler that is called when an error occurs during a procedure call. It receives the error, operation type, path, input, and context.\n\ntransformer​\n\nOptional input/output transformers for serialization/deserialization of data.\n\nNotes​\nIt's recommended to use this link in scenarios where you need direct procedure calls without HTTP\nFor most client-side applications, you should use the httpLink or other HTTP-based links instead\nThe link supports all tRPC features including queries, mutations, and subscriptions\nError handling and transformation are handled automatically, just like with HTTP-based links\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/wsLink",
    "html": "Client Usage\nLinks\nWebSocket Link\nVersion: 11.x\nWebSocket Link\n\nwsLink is a terminating link that's used when using tRPC's WebSockets Client and Subscriptions, which you can learn more about here).\n\nUsage​\n\nTo use wsLink, you need to pass it a TRPCWebSocketClient, which you can create with createWSClient:\n\nclient/index.ts\nimport { createTRPCClient, createWSClient, wsLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst wsClient = createWSClient({\n  url: 'ws://localhost:3000',\n});\nconst trpcClient = createTRPCClient<AppRouter>({\n  links: [wsLink<AppRouter>({ client: wsClient })],\n});\nCopy\nAuthentication / Connection params​\n\nSee more here\n\nwsLink / createWSClient Options​\n\nThe wsLink function requires a TRPCWebSocketClient to be passed, which can be configured with the fields defined in WebSocketClientOptions:\n\nexport interface WebSocketLinkOptions {\n  client: TRPCWebSocketClient;\n  /**\n   * Data transformer\n   * @see https://trpc.io/docs/v11/data-transformers\n   **/\n  transformer?: DataTransformerOptions;\n}\nfunction createWSClient(opts: WebSocketClientOptions) => TRPCWebSocketClient\nexport interface WebSocketClientOptions {\n  /**\n   * The URL to connect to (can be a function that returns a URL)\n   */\n  url: string | (() => MaybePromise<string>);\n  /**\n   * Connection params that are available in `createContext()`\n   * These are sent as the first message\n   */\n  connectionParams: string | (() => MaybePromise<string>);\n  /**\n   * Ponyfill which WebSocket implementation to use\n   */\n  WebSocket?: typeof WebSocket;\n  /**\n   * The number of milliseconds before a reconnect is attempted.\n   * @default {@link exponentialBackoff}\n   */\n  retryDelayMs?: typeof exponentialBackoff;\n  /**\n   * Triggered when a WebSocket connection is established\n   */\n  onOpen?: () => void;\n  /**\n   * Triggered when a WebSocket connection encounters an error\n   */\n  onError?: (evt?: Event) => void;\n  /**\n   * Triggered when a WebSocket connection is closed\n   */\n  onClose?: (cause?: { code?: number }) => void;\n  /**\n   * Lazy mode will close the WebSocket automatically after a period of inactivity (no messages sent or received and no pending requests)\n   */\n  lazy?: {\n    /**\n     * Enable lazy mode\n     * @default false\n     */\n    enabled: boolean;\n    /**\n     * Close the WebSocket after this many milliseconds\n     * @default 0\n     */\n    closeMs: number;\n  };\n  /**\n   * Send ping messages to the server and kill the connection if no pong message is returned\n   */\n  keepAlive?: {\n    /**\n     * @default false\n     */\n    enabled: boolean;\n    /**\n     * Send a ping message every this many milliseconds\n     * @default 5_000\n     */\n    intervalMs?: number;\n    /**\n     * Close the WebSocket after this many milliseconds if the server does not respond\n     * @default 1_000\n     */\n    pongTimeoutMs?: number;\n  };\n}\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "Split Link | tRPC",
    "url": "https://trpc.io/docs/client/links/splitLink",
    "html": "Client Usage\nLinks\nSplit Link\nVersion: 11.x\nSplit Link\n\nsplitLink is a link that allows you to branch your link chain's execution depending on a given condition. Both the true and false branches are required. You can provide just one link, or multiple links per branch via an array.\n\nIt's important to note that when you provide links for splitLink to execute, splitLink will create an entirely new link chain based on the links you passed. Therefore, you need to use a terminating link if you only provide one link or add the terminating link at the end of the array if you provide multiple links to be executed on a branch. Here's a visual representation of how splitLink works:\n\ntRPC Client\nOperation\nLink\nLink\nsplitLink\nInitiated\nCompleted\ndown\ndown\nup\nup\nTerminating Link\nRequest\nResponse\nRequest\ntRPC Server\npasses \ncondition?\nLink\nTerminating Link\nLink\ntrue\nBranch\nfalse\nBranch\ndown\nup\nResponse\nYES\nNO\ndown\nup\ndown\nup\nUsage Example​\nDisable batching for certain requests​\n\nLet's say you're using httpBatchLink as the terminating link in your tRPC client config. This means request batching is enabled in every request. However, if you need to disable batching only for certain requests, you would need to change the terminating link in your tRPC client config dynamically between httpLink and httpBatchLink. This is a perfect opportunity for splitLink to be used:\n\n1. Configure client / utils/trpc.ts​\nclient/index.ts\nimport {\n  createTRPCClient,\n  httpBatchLink,\n  httpLink,\n  splitLink,\n} from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst url = `http://localhost:3000`;\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    splitLink({\n      condition(op) {\n        // check for context property `skipBatch`\n        return Boolean(op.context.skipBatch);\n      },\n      // when condition is true, use normal request\n      true: httpLink({\n        url,\n      }),\n      // when condition is false, use batching\n      false: httpBatchLink({\n        url,\n      }),\n    }),\n  ],\n});\nCopy\n2. Perform request without batching​\nclient.ts\nconst postResult = proxy.posts.query(null, {\n  context: {\n    skipBatch: true,\n  },\n});\nCopy\n\nor:\n\nMyComponent.tsx\nexport function MyComponent() {\n  const postsQuery = proxy.posts.useQuery(undefined, {\n    trpc: {\n      context: {\n        skipBatch: true,\n      },\n    }\n  });\n  return (\n    <pre>{JSON.stringify(postsQuery.data ?? null, null, 4)}</pre>\n  )\n})\nCopy\nsplitLink Options​\n\nThe splitLink function takes an options object that has three fields: condition, true, and false.\n\nfunction splitLink<TRouter extends AnyRouter = AnyRouter>(opts: {\n  condition: (op: Operation) => boolean;\n  /**\n   * The link to execute next if the test function returns `true`.\n   */\n  true: TRPCLink<TRouter> | TRPCLink<TRouter>[];\n  /**\n   * The link to execute next if the test function returns `false`.\n   */\n  false: TRPCLink<TRouter> | TRPCLink<TRouter>[];\n}) => TRPCLink<TRouter>\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "tRPC",
    "url": "https://trpc.io/docs/client/links/loggerLink",
    "html": "Client Usage\nLinks\nLogger Link\nVersion: 11.x\nLogger Link\n\nloggerLink is a link that lets you implement a logger for your tRPC client. It allows you to see more clearly what operations are queries, mutations, or subscriptions, their requests, and responses. The link, by default, prints a prettified log to the browser's console. However, you can customize the logging behavior and the way it prints to the console with your own implementations.\n\nUsage​\n\nYou can import and add the loggerLink to the links array as such:\n\nclient/index.ts\nimport { createTRPCClient, httpBatchLink, loggerLink } from '@trpc/client';\nimport type { AppRouter } from '../server';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    /**\n     * The function passed to enabled is an example in case you want to the link to\n     * log to your console in development and only log errors in production\n     */\n    loggerLink({\n      enabled: (opts) =>\n        (process.env.NODE_ENV === 'development' &&\n          typeof window !== 'undefined') ||\n        (opts.direction === 'down' && opts.result instanceof Error),\n    }),\n    httpBatchLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\nloggerLink Options​\n\nThe loggerLink function takes an options object that has the LoggerLinkOptions shape:\n\ntype LoggerLinkOptions<TRouter extends AnyRouter> = {\n  logger?: LogFn<TRouter>;\n  /**\n   * It is a function that returns a condition that determines whether to enable the logger.\n   * It is true by default.\n   */\n  enabled?: EnabledFn<TRouter>;\n  /**\n   * Used in the built-in defaultLogger\n   */\n  console?: ConsoleEsque;\n  /**\n   * Color mode used in the default logger.\n   * @default typeof window === 'undefined' ? 'ansi' : 'css'\n   */\n  colorMode?: 'ansi' | 'css';\n};\nCopy\nReference​\n\nYou can check out the source code for this link on GitHub.\n\nEdit this page"
  },
  {
    "title": "Retry Link | tRPC",
    "url": "https://trpc.io/docs/client/links/retryLink",
    "html": "Client Usage\nLinks\nRetry Link\nVersion: 11.x\nRetry Link\n\nretryLink is a link that allows you to retry failed operations in your tRPC client. It provides a customizable way to handle transient errors, such as network failures or server errors, by automatically retrying the failed requests based on specified conditions.\n\nTIP\n\nIf you use @trpc/react-query you will generally not need this link as it's built into the useQuery() and the useMutation() hooks from @tanstack/react-query.\n\nUsage​\n\nYou can import and add the retryLink to the links array when creating your tRPC client. This link can be placed before or after other links in your setup, depending on your requirements.\n\nimport { createTRPCClient, retryLink } from '@trpc/client';\nconst client = createTRPCClient<AppRouter>({\n  links: [\n    retryLink({\n      retry(opts) {\n        if (\n          opts.error.data &&\n          opts.error.data.code !== 'INTERNAL_SERVER_ERROR'\n        ) {\n          // Don't retry on non-500s\n          return false;\n        }\n        if (opts.op.type !== 'query') {\n          // Only retry queries\n          return false;\n        }\n        // Retry up to 3 times\n        return opts.attempts <= 3;\n      },\n      // Double every attempt, with max of 30 seconds (starting at 1 second)\n      retryDelayMs: (attemptIndex) => Math.min(1000 * 2 ** attemptIndex, 30000),\n    }),\n    httpBatchLink({\n      url: 'http://localhost:3000',\n    }),\n  ],\n});\nCopy\n\nIn the example above, we add the retryLink before the httpBatchLink. By default, retryLink will:\n\nRetry the request if the error is a TRPCClientError with a status code of 500 or if we couldn't get a valid TRPC error.\nRetry the request up to 3 times.\n\nYou can customize the retry logic by providing a custom retry function.\n\nOptions​\ninterface RetryLinkOptions<TInferrable extends InferrableClientTypes> {\n  /**\n   * The retry function\n   */\n  retry: (opts: RetryFnOptions<TInferrable>) => boolean;\n  /**\n   * The delay between retries in ms (defaults to 0)\n   */\n  retryDelayMs?: (attempt: number) => number;\n}\ninterface RetryFnOptions<TInferrable extends InferrableClientTypes> {\n  /**\n   * The operation that failed\n   */\n  op: Operation;\n  /**\n   * The error that occurred\n   */\n  error: TRPCClientError<TInferrable>;\n  /**\n   * The number of attempts that have been made (including the first call)\n   */\n  attempts: number;\n}\nCopy\nHandling tracked() events​\n\nWhen using retryLink with subscriptions that use tracked(), the link will automatically include the last known event ID when retrying. This ensures that when a subscription reconnects, it can resume from where it left off without missing any events.\n\nFor example, if you're using Server-sent Events (SSE) with httpSubscriptionLink, the retryLink will automatically handle reconnecting with the last event ID when errors like 401 Unauthorized occur.\n\nEdit this page"
  }
]
</file>

</files>
